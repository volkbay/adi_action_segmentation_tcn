Sun Oct 30 12:47:42 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.23, 0.24, 0.23, 0.25, 0.05], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': 'new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'lastLayerInitUniform': False, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 71.20315581854044, 'maxValidationTrainNo': 64, 'modelVersion': 17, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [5, 10, 20, 25], 'trainNo': 68, 'validationAccThr': 75, 'warmStartConfig': {'checkpointFile': './sav/model17_trainNo60_at_epoch_197_with_acc_71_60_checkpoint.pth.tar', 'checkpointModelNo': 17, 'freezeSpatialCNN': False, 'warmStartFlag': False}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Train set length:  3547
I - Label distribution: [ 697.  578.  734.  538. 1000.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Loading file: dataset_test_background00_no_samples180.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test/new_background
I - New label distribution: [ 88.  78.  75.  86. 180.]

I - Test set length:  507
I - Label distribution: [ 88.  78.  75.  86. 180.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([  5170,    608, 145907, 187480, 176761,     10,    515,    759,  93976,
        174572, 191266,  71334, 178273, 126537, 134932,   1049])
I - Initializing model TCNv17
I - Number of Model Parameters: 640096
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv17                                   [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         6
│    └─ReLU: 2-1719                      [16, 128, 64, 64]         --
│    └─Conv2d: 2-2                       --                        6,272
│    └─BatchNorm2d: 2-1717               [16, 128, 64, 64]         --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-1718                    [16, 128, 64, 64]         --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [128, 48, 1, 1]           --
│    └─Empty: 2-9                        [128, 48, 1, 1]           --
│    └─Empty: 2-10                       [128]                     --
│    └─Empty: 2-11                       [128]                     --
│    └─BatchNorm2d: 2-12                 [16, 128, 64, 64]         --
│    └─Scaler: 2-13                      [16, 128, 64, 64]         --
│    └─ReLU: 2-14                        [16, 128, 64, 64]         --
│    └─Empty: 2-15                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-172        [16, 128, 32, 32]         (recursive)
│    └─ReLU: 2-1734                      [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-1722                 [16, 128, 32, 32]         --
│    └─Conv2d: 2-18                      --                        147,584
│    └─BatchNorm2d: 2-1732               [16, 128, 32, 32]         (recursive)
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-20                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-3          [16, 128, 32, 32]         147,846
│    └─Scaler: 2-1733                    [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-22                   [16, 128, 32, 32]         --
│    └─Empty: 2-23                       [16, 128, 32, 32]         --
│    └─Empty: 2-24                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [128, 128, 3, 3]          --
│    └─Empty: 2-29                       [128, 128, 3, 3]          --
│    └─Empty: 2-30                       [128]                     --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1749                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1737                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-33                      --                        147,584
│    └─BatchNorm2d: 2-1747               [16, 128, 16, 16]         (recursive)
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-35                       [128]                     --
│    └─BatchNorm2d: 2-36                 [16, 128, 32, 32]         256
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1748                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-38                      [16, 128, 32, 32]         --
│    └─ReLU: 2-39                        [16, 128, 32, 32]         --
│    └─Empty: 2-40                       [16, 128, 32, 32]         --
│    └─Clamp: 2-41                       [16, 128, 32, 32]         --
├─Dropout2d: 1-5                         [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-6          [16, 128, 16, 16]         131,078
│    └─MaxPool2d: 2-42                   [16, 128, 16, 16]         --
│    └─Empty: 2-1738                     [16, 128, 16, 16]         --
│    └─Empty: 2-1739                     [16, 128, 16, 16]         --
│    └─Empty: 2-45                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1761                      [16, 128, 16, 16]         --
│    └─Conv2d: 2-47                      --                        16,512
│    └─BatchNorm2d: 2-1759               [16, 128, 16, 16]         (recursive)
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-49                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-50          --                        --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1760                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-52                         [1]                       --
│    └─OutputScale: 2-53                 --                        --
│    └─Empty: 2-54                       [128, 128, 3, 3]          --
│    └─Empty: 2-55                       [128, 128, 3, 3]          --
│    └─Empty: 2-56                       [128]                     --
│    └─Empty: 2-57                       [128]                     --
│    └─BatchNorm2d: 2-58                 [16, 128, 16, 16]         256
│    └─Scaler: 2-59                      [16, 128, 16, 16]         --
│    └─ReLU: 2-60                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1776                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1764                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-63                      --                        147,584
│    └─BatchNorm2d: 2-1774               [16, 128, 16, 16]         (recursive)
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-65                       [16, 128, 16, 16]         --
│    └─Clamp: 2-66                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1775                    [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-8                 [16, 128, 16, 16]         16,518
│    └─OutputShiftSqueeze: 2-68          --                        --
│    └─One: 2-69                         [1]                       --
│    └─OutputScale: 2-70                 --                        --
│    └─Empty: 2-71                       [128, 128, 1, 1]          --
│    └─Empty: 2-72                       [128, 128, 1, 1]          --
│    └─Empty: 2-73                       [128]                     --
│    └─Empty: 2-74                       [128]                     --
│    └─BatchNorm2d: 2-75                 [16, 128, 16, 16]         256
├─FusedMaxPoolConv2dBNReLU: 1-178        [16, 128, 8, 8]           (recursive)
│    └─ReLU: 2-1791                      [16, 128, 8, 8]           --
│    └─MaxPool2d: 2-1779                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-78                      --                        147,584
│    └─BatchNorm2d: 2-1789               [16, 128, 8, 8]           (recursive)
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-80                      [16, 128, 16, 16]         --
│    └─ReLU: 2-81                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1790                    [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-83                       [16, 128, 16, 16]         --
│    └─Clamp: 2-84                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-10         [16, 128, 16, 16]         145,526
│    └─MaxPool2d: 2-85                   [16, 128, 16, 16]         --
│    └─Empty: 2-86                       [16, 128, 16, 16]         --
│    └─Empty: 2-87                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-88          --                        --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1780                     [16, 128, 8, 8]           --
│    └─Empty: 2-1781                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-91                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1803                      [16, 16, 8, 8]            --
│    └─Conv2d: 2-93                      --                        2,064
│    └─BatchNorm2d: 2-1801               [16, 16, 8, 8]            (recursive)
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [128, 128, 3, 3]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1802                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-98                       [128, 128, 3, 3]          --
│    └─Empty: 2-99                       [128]                     --
│    └─Empty: 2-100                      [128]                     --
│    └─BatchNorm2d: 2-101                [16, 128, 16, 16]         256
│    └─Scaler: 2-102                     [16, 128, 16, 16]         --
│    └─ReLU: 2-103                       [16, 128, 16, 16]         --
│    └─Empty: 2-104                      [16, 128, 16, 16]         --
│    └─Clamp: 2-105                      [16, 128, 16, 16]         --
├─Dropout2d: 1-11                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 16, 8, 8]            (recursive)
│    └─ReLU: 2-1818                      [16, 16, 8, 8]            --
│    └─MaxPool2d: 2-1806                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-108                     --                        18,448
│    └─BatchNorm2d: 2-1816               [16, 16, 8, 8]            (recursive)
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-110                  [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1817                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-112                      [16, 128, 8, 8]           --
│    └─Empty: 2-113                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-114         --                        --
│    └─One: 2-115                        [1]                       --
│    └─OutputScale: 2-116                --                        --
│    └─Empty: 2-117                      [128, 128, 3, 3]          --
│    └─Empty: 2-118                      [128, 128, 3, 3]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1807                     [16, 128, 8, 8]           --
│    └─Empty: 2-1808                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-121                      [128]                     --
│    └─Empty: 2-122                      [128]                     --
│    └─BatchNorm2d: 2-123                [16, 128, 8, 8]           256
│    └─Scaler: 2-124                     [16, 128, 8, 8]           --
│    └─ReLU: 2-125                       [16, 128, 8, 8]           --
│    └─Empty: 2-126                      [16, 128, 8, 8]           --
│    └─Clamp: 2-127                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-14                [16, 16, 8, 8]            2,070
├─Linear: 1                              --                        --
│    └─Scaler: 2-128                     --                        --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-129         --                        --
│    └─One: 2-130                        [1]                       --
│    └─OutputScale: 2-131                --                        --
│    └─Empty: 2-132                      [16, 128, 1, 1]           --
│    └─Empty: 2-133                      [16, 128, 1, 1]           --
│    └─Empty: 2-134                      [16]                      --
│    └─Empty: 2-135                      [16]                      --
│    └─BatchNorm2d: 2-136                [16, 16, 8, 8]            32
│    └─Scaler: 2-137                     [16, 16, 8, 8]            --
│    └─ReLU: 2-138                       [16, 16, 8, 8]            --
│    └─Empty: 2-139                      [16, 16, 8, 8]            --
│    └─Clamp: 2-140                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 16, 8, 8]            18,454
│    └─MaxPool2d: 2-141                  [16, 128, 8, 8]           --
│    └─Empty: 2-142                      [16, 128, 8, 8]           --
│    └─Empty: 2-143                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-144         --                        --
│    └─One: 2-145                        [1]                       --
│    └─OutputScale: 2-146                --                        --
│    └─Empty: 2-147                      [16, 128, 3, 3]           --
│    └─Empty: 2-148                      [16, 128, 3, 3]           --
│    └─Empty: 2-149                      [16]                      --
│    └─Empty: 2-150                      [16]                      --
│    └─BatchNorm2d: 2-151                [16, 16, 8, 8]            32
│    └─Scaler: 2-152                     [16, 16, 8, 8]            --
│    └─ReLU: 2-153                       [16, 16, 8, 8]            --
│    └─Empty: 2-154                      [16, 16, 8, 8]            --
│    └─Clamp: 2-155                      [16, 16, 8, 8]            --
├─Dropout2d: 1-16                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-17                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-156         --                        --
│    └─One: 2-157                        [1]                       --
│    └─OutputScale: 2-158                --                        --
│    └─Empty: 2-159                      [128, 48, 1, 1]           --
│    └─Empty: 2-160                      [128, 48, 1, 1]           --
│    └─Empty: 2-161                      [128]                     --
│    └─Empty: 2-162                      [128]                     --
│    └─BatchNorm2d: 2-163                [16, 128, 64, 64]         --
│    └─Scaler: 2-164                     [16, 128, 64, 64]         --
│    └─ReLU: 2-165                       [16, 128, 64, 64]         --
│    └─Empty: 2-166                      [16, 128, 64, 64]         --
│    └─Clamp: 2-167                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-18         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-168                  [16, 128, 32, 32]         --
│    └─Empty: 2-169                      [16, 128, 32, 32]         --
│    └─Empty: 2-170                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-171         --                        --
│    └─One: 2-172                        [1]                       --
│    └─OutputScale: 2-173                --                        --
│    └─Empty: 2-174                      [128, 128, 3, 3]          --
│    └─Empty: 2-175                      [128, 128, 3, 3]          --
│    └─Empty: 2-176                      [128]                     --
│    └─Empty: 2-177                      [128]                     --
│    └─BatchNorm2d: 2-178                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-179                     [16, 128, 32, 32]         --
│    └─ReLU: 2-180                       [16, 128, 32, 32]         --
│    └─Empty: 2-181                      [16, 128, 32, 32]         --
│    └─Clamp: 2-182                      [16, 128, 32, 32]         --
├─Dropout2d: 1-19                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-20         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-183                  [16, 128, 16, 16]         --
│    └─Empty: 2-184                      [16, 128, 16, 16]         --
│    └─Empty: 2-185                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-186         --                        --
│    └─One: 2-187                        [1]                       --
│    └─OutputScale: 2-188                --                        --
│    └─Empty: 2-189                      [128, 128, 3, 3]          --
│    └─Empty: 2-190                      [128, 128, 3, 3]          --
│    └─Empty: 2-191                      [128]                     --
│    └─Empty: 2-192                      [128]                     --
│    └─BatchNorm2d: 2-193                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-194                     [16, 128, 16, 16]         --
│    └─ReLU: 2-195                       [16, 128, 16, 16]         --
│    └─Empty: 2-196                      [16, 128, 16, 16]         --
│    └─Clamp: 2-197                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-21                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-198         --                        --
│    └─One: 2-199                        [1]                       --
│    └─OutputScale: 2-200                --                        --
│    └─Empty: 2-201                      [128, 128, 1, 1]          --
│    └─Empty: 2-202                      [128, 128, 1, 1]          --
│    └─Empty: 2-203                      [128]                     --
│    └─Empty: 2-204                      [128]                     --
│    └─BatchNorm2d: 2-205                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-206                     [16, 128, 16, 16]         --
│    └─ReLU: 2-207                       [16, 128, 16, 16]         --
│    └─Empty: 2-208                      [16, 128, 16, 16]         --
│    └─Clamp: 2-209                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-210                  [16, 128, 16, 16]         --
│    └─Empty: 2-211                      [16, 128, 16, 16]         --
│    └─Empty: 2-212                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-213         --                        --
│    └─One: 2-214                        [1]                       --
│    └─OutputScale: 2-215                --                        --
│    └─Empty: 2-216                      [128, 128, 3, 3]          --
│    └─Empty: 2-217                      [128, 128, 3, 3]          --
│    └─Empty: 2-218                      [128]                     --
│    └─Empty: 2-219                      [128]                     --
│    └─BatchNorm2d: 2-220                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-221                     [16, 128, 16, 16]         --
│    └─ReLU: 2-222                       [16, 128, 16, 16]         --
│    └─Empty: 2-223                      [16, 128, 16, 16]         --
│    └─Clamp: 2-224                      [16, 128, 16, 16]         --
├─Dropout2d: 1-23                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-225                  [16, 128, 8, 8]           --
│    └─Empty: 2-226                      [16, 128, 8, 8]           --
│    └─Empty: 2-227                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-228         --                        --
│    └─One: 2-229                        [1]                       --
│    └─OutputScale: 2-230                --                        --
│    └─Empty: 2-231                      [128, 128, 3, 3]          --
│    └─Empty: 2-232                      [128, 128, 3, 3]          --
│    └─Empty: 2-233                      [128]                     --
│    └─Empty: 2-234                      [128]                     --
│    └─BatchNorm2d: 2-235                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-236                     [16, 128, 8, 8]           --
│    └─ReLU: 2-237                       [16, 128, 8, 8]           --
│    └─Empty: 2-238                      [16, 128, 8, 8]           --
│    └─Clamp: 2-239                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-25                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-240         --                        --
│    └─One: 2-241                        [1]                       --
│    └─OutputScale: 2-242                --                        --
│    └─Empty: 2-243                      [16, 128, 1, 1]           --
│    └─Empty: 2-244                      [16, 128, 1, 1]           --
│    └─Empty: 2-245                      [16]                      --
│    └─Empty: 2-246                      [16]                      --
│    └─BatchNorm2d: 2-247                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-248                     [16, 16, 8, 8]            --
│    └─ReLU: 2-249                       [16, 16, 8, 8]            --
│    └─Empty: 2-250                      [16, 16, 8, 8]            --
│    └─Clamp: 2-251                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-252                  [16, 128, 8, 8]           --
│    └─Empty: 2-253                      [16, 128, 8, 8]           --
│    └─Empty: 2-254                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-255         --                        --
│    └─One: 2-256                        [1]                       --
│    └─OutputScale: 2-257                --                        --
│    └─Empty: 2-258                      [16, 128, 3, 3]           --
│    └─Empty: 2-259                      [16, 128, 3, 3]           --
│    └─Empty: 2-260                      [16]                      --
│    └─Empty: 2-261                      [16]                      --
│    └─BatchNorm2d: 2-262                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-263                     [16, 16, 8, 8]            --
│    └─ReLU: 2-264                       [16, 16, 8, 8]            --
│    └─Empty: 2-265                      [16, 16, 8, 8]            --
│    └─Clamp: 2-266                      [16, 16, 8, 8]            --
├─Dropout2d: 1-27                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-28                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-267         --                        --
│    └─One: 2-268                        [1]                       --
│    └─OutputScale: 2-269                --                        --
│    └─Empty: 2-270                      [128, 48, 1, 1]           --
│    └─Empty: 2-271                      [128, 48, 1, 1]           --
│    └─Empty: 2-272                      [128]                     --
│    └─Empty: 2-273                      [128]                     --
│    └─BatchNorm2d: 2-274                [16, 128, 64, 64]         --
│    └─Scaler: 2-275                     [16, 128, 64, 64]         --
│    └─ReLU: 2-276                       [16, 128, 64, 64]         --
│    └─Empty: 2-277                      [16, 128, 64, 64]         --
│    └─Clamp: 2-278                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-279                  [16, 128, 32, 32]         --
│    └─Empty: 2-280                      [16, 128, 32, 32]         --
│    └─Empty: 2-281                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-282         --                        --
│    └─One: 2-283                        [1]                       --
│    └─OutputScale: 2-284                --                        --
│    └─Empty: 2-285                      [128, 128, 3, 3]          --
│    └─Empty: 2-286                      [128, 128, 3, 3]          --
│    └─Empty: 2-287                      [128]                     --
│    └─Empty: 2-288                      [128]                     --
│    └─BatchNorm2d: 2-289                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-290                     [16, 128, 32, 32]         --
│    └─ReLU: 2-291                       [16, 128, 32, 32]         --
│    └─Empty: 2-292                      [16, 128, 32, 32]         --
│    └─Clamp: 2-293                      [16, 128, 32, 32]         --
├─Dropout2d: 1-30                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-294                  [16, 128, 16, 16]         --
│    └─Empty: 2-295                      [16, 128, 16, 16]         --
│    └─Empty: 2-296                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-297         --                        --
│    └─One: 2-298                        [1]                       --
│    └─OutputScale: 2-299                --                        --
│    └─Empty: 2-300                      [128, 128, 3, 3]          --
│    └─Empty: 2-301                      [128, 128, 3, 3]          --
│    └─Empty: 2-302                      [128]                     --
│    └─Empty: 2-303                      [128]                     --
│    └─BatchNorm2d: 2-304                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-305                     [16, 128, 16, 16]         --
│    └─ReLU: 2-306                       [16, 128, 16, 16]         --
│    └─Empty: 2-307                      [16, 128, 16, 16]         --
│    └─Clamp: 2-308                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-32                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-309         --                        --
│    └─One: 2-310                        [1]                       --
│    └─OutputScale: 2-311                --                        --
│    └─Empty: 2-312                      [128, 128, 1, 1]          --
│    └─Empty: 2-313                      [128, 128, 1, 1]          --
│    └─Empty: 2-314                      [128]                     --
│    └─Empty: 2-315                      [128]                     --
│    └─BatchNorm2d: 2-316                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-317                     [16, 128, 16, 16]         --
│    └─ReLU: 2-318                       [16, 128, 16, 16]         --
│    └─Empty: 2-319                      [16, 128, 16, 16]         --
│    └─Clamp: 2-320                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-321                  [16, 128, 16, 16]         --
│    └─Empty: 2-322                      [16, 128, 16, 16]         --
│    └─Empty: 2-323                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-324         --                        --
│    └─One: 2-325                        [1]                       --
│    └─OutputScale: 2-326                --                        --
│    └─Empty: 2-327                      [128, 128, 3, 3]          --
│    └─Empty: 2-328                      [128, 128, 3, 3]          --
│    └─Empty: 2-329                      [128]                     --
│    └─Empty: 2-330                      [128]                     --
│    └─BatchNorm2d: 2-331                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-332                     [16, 128, 16, 16]         --
│    └─ReLU: 2-333                       [16, 128, 16, 16]         --
│    └─Empty: 2-334                      [16, 128, 16, 16]         --
│    └─Clamp: 2-335                      [16, 128, 16, 16]         --
├─Dropout2d: 1-34                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-35         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-336                  [16, 128, 8, 8]           --
│    └─Empty: 2-337                      [16, 128, 8, 8]           --
│    └─Empty: 2-338                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-339         --                        --
│    └─One: 2-340                        [1]                       --
│    └─OutputScale: 2-341                --                        --
│    └─Empty: 2-342                      [128, 128, 3, 3]          --
│    └─Empty: 2-343                      [128, 128, 3, 3]          --
│    └─Empty: 2-344                      [128]                     --
│    └─Empty: 2-345                      [128]                     --
│    └─BatchNorm2d: 2-346                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-347                     [16, 128, 8, 8]           --
│    └─ReLU: 2-348                       [16, 128, 8, 8]           --
│    └─Empty: 2-349                      [16, 128, 8, 8]           --
│    └─Clamp: 2-350                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-36                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-351         --                        --
│    └─One: 2-352                        [1]                       --
│    └─OutputScale: 2-353                --                        --
│    └─Empty: 2-354                      [16, 128, 1, 1]           --
│    └─Empty: 2-355                      [16, 128, 1, 1]           --
│    └─Empty: 2-356                      [16]                      --
│    └─Empty: 2-357                      [16]                      --
│    └─BatchNorm2d: 2-358                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-359                     [16, 16, 8, 8]            --
│    └─ReLU: 2-360                       [16, 16, 8, 8]            --
│    └─Empty: 2-361                      [16, 16, 8, 8]            --
│    └─Clamp: 2-362                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-37         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-363                  [16, 128, 8, 8]           --
│    └─Empty: 2-364                      [16, 128, 8, 8]           --
│    └─Empty: 2-365                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-366         --                        --
│    └─One: 2-367                        [1]                       --
│    └─OutputScale: 2-368                --                        --
│    └─Empty: 2-369                      [16, 128, 3, 3]           --
│    └─Empty: 2-370                      [16, 128, 3, 3]           --
│    └─Empty: 2-371                      [16]                      --
│    └─Empty: 2-372                      [16]                      --
│    └─BatchNorm2d: 2-373                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-374                     [16, 16, 8, 8]            --
│    └─ReLU: 2-375                       [16, 16, 8, 8]            --
│    └─Empty: 2-376                      [16, 16, 8, 8]            --
│    └─Clamp: 2-377                      [16, 16, 8, 8]            --
├─Dropout2d: 1-38                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-39                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-378         --                        --
│    └─One: 2-379                        [1]                       --
│    └─OutputScale: 2-380                --                        --
│    └─Empty: 2-381                      [128, 48, 1, 1]           --
│    └─Empty: 2-382                      [128, 48, 1, 1]           --
│    └─Empty: 2-383                      [128]                     --
│    └─Empty: 2-384                      [128]                     --
│    └─BatchNorm2d: 2-385                [16, 128, 64, 64]         --
│    └─Scaler: 2-386                     [16, 128, 64, 64]         --
│    └─ReLU: 2-387                       [16, 128, 64, 64]         --
│    └─Empty: 2-388                      [16, 128, 64, 64]         --
│    └─Clamp: 2-389                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-40         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-390                  [16, 128, 32, 32]         --
│    └─Empty: 2-391                      [16, 128, 32, 32]         --
│    └─Empty: 2-392                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-393         --                        --
│    └─One: 2-394                        [1]                       --
│    └─OutputScale: 2-395                --                        --
│    └─Empty: 2-396                      [128, 128, 3, 3]          --
│    └─Empty: 2-397                      [128, 128, 3, 3]          --
│    └─Empty: 2-398                      [128]                     --
│    └─Empty: 2-399                      [128]                     --
│    └─BatchNorm2d: 2-400                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-401                     [16, 128, 32, 32]         --
│    └─ReLU: 2-402                       [16, 128, 32, 32]         --
│    └─Empty: 2-403                      [16, 128, 32, 32]         --
│    └─Clamp: 2-404                      [16, 128, 32, 32]         --
├─Dropout2d: 1-41                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-42         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-405                  [16, 128, 16, 16]         --
│    └─Empty: 2-406                      [16, 128, 16, 16]         --
│    └─Empty: 2-407                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-408         --                        --
│    └─One: 2-409                        [1]                       --
│    └─OutputScale: 2-410                --                        --
│    └─Empty: 2-411                      [128, 128, 3, 3]          --
│    └─Empty: 2-412                      [128, 128, 3, 3]          --
│    └─Empty: 2-413                      [128]                     --
│    └─Empty: 2-414                      [128]                     --
│    └─BatchNorm2d: 2-415                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-416                     [16, 128, 16, 16]         --
│    └─ReLU: 2-417                       [16, 128, 16, 16]         --
│    └─Empty: 2-418                      [16, 128, 16, 16]         --
│    └─Clamp: 2-419                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-43                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-420         --                        --
│    └─One: 2-421                        [1]                       --
│    └─OutputScale: 2-422                --                        --
│    └─Empty: 2-423                      [128, 128, 1, 1]          --
│    └─Empty: 2-424                      [128, 128, 1, 1]          --
│    └─Empty: 2-425                      [128]                     --
│    └─Empty: 2-426                      [128]                     --
│    └─BatchNorm2d: 2-427                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-428                     [16, 128, 16, 16]         --
│    └─ReLU: 2-429                       [16, 128, 16, 16]         --
│    └─Empty: 2-430                      [16, 128, 16, 16]         --
│    └─Clamp: 2-431                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-44         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-432                  [16, 128, 16, 16]         --
│    └─Empty: 2-433                      [16, 128, 16, 16]         --
│    └─Empty: 2-434                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-435         --                        --
│    └─One: 2-436                        [1]                       --
│    └─OutputScale: 2-437                --                        --
│    └─Empty: 2-438                      [128, 128, 3, 3]          --
│    └─Empty: 2-439                      [128, 128, 3, 3]          --
│    └─Empty: 2-440                      [128]                     --
│    └─Empty: 2-441                      [128]                     --
│    └─BatchNorm2d: 2-442                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-443                     [16, 128, 16, 16]         --
│    └─ReLU: 2-444                       [16, 128, 16, 16]         --
│    └─Empty: 2-445                      [16, 128, 16, 16]         --
│    └─Clamp: 2-446                      [16, 128, 16, 16]         --
├─Dropout2d: 1-45                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-447                  [16, 128, 8, 8]           --
│    └─Empty: 2-448                      [16, 128, 8, 8]           --
│    └─Empty: 2-449                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-450         --                        --
│    └─One: 2-451                        [1]                       --
│    └─OutputScale: 2-452                --                        --
│    └─Empty: 2-453                      [128, 128, 3, 3]          --
│    └─Empty: 2-454                      [128, 128, 3, 3]          --
│    └─Empty: 2-455                      [128]                     --
│    └─Empty: 2-456                      [128]                     --
│    └─BatchNorm2d: 2-457                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-458                     [16, 128, 8, 8]           --
│    └─ReLU: 2-459                       [16, 128, 8, 8]           --
│    └─Empty: 2-460                      [16, 128, 8, 8]           --
│    └─Clamp: 2-461                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-47                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-462         --                        --
│    └─One: 2-463                        [1]                       --
│    └─OutputScale: 2-464                --                        --
│    └─Empty: 2-465                      [16, 128, 1, 1]           --
│    └─Empty: 2-466                      [16, 128, 1, 1]           --
│    └─Empty: 2-467                      [16]                      --
│    └─Empty: 2-468                      [16]                      --
│    └─BatchNorm2d: 2-469                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-470                     [16, 16, 8, 8]            --
│    └─ReLU: 2-471                       [16, 16, 8, 8]            --
│    └─Empty: 2-472                      [16, 16, 8, 8]            --
│    └─Clamp: 2-473                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-474                  [16, 128, 8, 8]           --
│    └─Empty: 2-475                      [16, 128, 8, 8]           --
│    └─Empty: 2-476                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-477         --                        --
│    └─One: 2-478                        [1]                       --
│    └─OutputScale: 2-479                --                        --
│    └─Empty: 2-480                      [16, 128, 3, 3]           --
│    └─Empty: 2-481                      [16, 128, 3, 3]           --
│    └─Empty: 2-482                      [16]                      --
│    └─Empty: 2-483                      [16]                      --
│    └─BatchNorm2d: 2-484                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-485                     [16, 16, 8, 8]            --
│    └─ReLU: 2-486                       [16, 16, 8, 8]            --
│    └─Empty: 2-487                      [16, 16, 8, 8]            --
│    └─Clamp: 2-488                      [16, 16, 8, 8]            --
├─Dropout2d: 1-49                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-50                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-489         --                        --
│    └─One: 2-490                        [1]                       --
│    └─OutputScale: 2-491                --                        --
│    └─Empty: 2-492                      [128, 48, 1, 1]           --
│    └─Empty: 2-493                      [128, 48, 1, 1]           --
│    └─Empty: 2-494                      [128]                     --
│    └─Empty: 2-495                      [128]                     --
│    └─BatchNorm2d: 2-496                [16, 128, 64, 64]         --
│    └─Scaler: 2-497                     [16, 128, 64, 64]         --
│    └─ReLU: 2-498                       [16, 128, 64, 64]         --
│    └─Empty: 2-499                      [16, 128, 64, 64]         --
│    └─Clamp: 2-500                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-501                  [16, 128, 32, 32]         --
│    └─Empty: 2-502                      [16, 128, 32, 32]         --
│    └─Empty: 2-503                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-504         --                        --
│    └─One: 2-505                        [1]                       --
│    └─OutputScale: 2-506                --                        --
│    └─Empty: 2-507                      [128, 128, 3, 3]          --
│    └─Empty: 2-508                      [128, 128, 3, 3]          --
│    └─Empty: 2-509                      [128]                     --
│    └─Empty: 2-510                      [128]                     --
│    └─BatchNorm2d: 2-511                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-512                     [16, 128, 32, 32]         --
│    └─ReLU: 2-513                       [16, 128, 32, 32]         --
│    └─Empty: 2-514                      [16, 128, 32, 32]         --
│    └─Clamp: 2-515                      [16, 128, 32, 32]         --
├─Dropout2d: 1-52                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-53         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-516                  [16, 128, 16, 16]         --
│    └─Empty: 2-517                      [16, 128, 16, 16]         --
│    └─Empty: 2-518                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-519         --                        --
│    └─One: 2-520                        [1]                       --
│    └─OutputScale: 2-521                --                        --
│    └─Empty: 2-522                      [128, 128, 3, 3]          --
│    └─Empty: 2-523                      [128, 128, 3, 3]          --
│    └─Empty: 2-524                      [128]                     --
│    └─Empty: 2-525                      [128]                     --
│    └─BatchNorm2d: 2-526                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-527                     [16, 128, 16, 16]         --
│    └─ReLU: 2-528                       [16, 128, 16, 16]         --
│    └─Empty: 2-529                      [16, 128, 16, 16]         --
│    └─Clamp: 2-530                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-54                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-531         --                        --
│    └─One: 2-532                        [1]                       --
│    └─OutputScale: 2-533                --                        --
│    └─Empty: 2-534                      [128, 128, 1, 1]          --
│    └─Empty: 2-535                      [128, 128, 1, 1]          --
│    └─Empty: 2-536                      [128]                     --
│    └─Empty: 2-537                      [128]                     --
│    └─BatchNorm2d: 2-538                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-539                     [16, 128, 16, 16]         --
│    └─ReLU: 2-540                       [16, 128, 16, 16]         --
│    └─Empty: 2-541                      [16, 128, 16, 16]         --
│    └─Clamp: 2-542                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-543                  [16, 128, 16, 16]         --
│    └─Empty: 2-544                      [16, 128, 16, 16]         --
│    └─Empty: 2-545                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-546         --                        --
│    └─One: 2-547                        [1]                       --
│    └─OutputScale: 2-548                --                        --
│    └─Empty: 2-549                      [128, 128, 3, 3]          --
│    └─Empty: 2-550                      [128, 128, 3, 3]          --
│    └─Empty: 2-551                      [128]                     --
│    └─Empty: 2-552                      [128]                     --
│    └─BatchNorm2d: 2-553                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-554                     [16, 128, 16, 16]         --
│    └─ReLU: 2-555                       [16, 128, 16, 16]         --
│    └─Empty: 2-556                      [16, 128, 16, 16]         --
│    └─Clamp: 2-557                      [16, 128, 16, 16]         --
├─Dropout2d: 1-56                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-57         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-558                  [16, 128, 8, 8]           --
│    └─Empty: 2-559                      [16, 128, 8, 8]           --
│    └─Empty: 2-560                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-561         --                        --
│    └─One: 2-562                        [1]                       --
│    └─OutputScale: 2-563                --                        --
│    └─Empty: 2-564                      [128, 128, 3, 3]          --
│    └─Empty: 2-565                      [128, 128, 3, 3]          --
│    └─Empty: 2-566                      [128]                     --
│    └─Empty: 2-567                      [128]                     --
│    └─BatchNorm2d: 2-568                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-569                     [16, 128, 8, 8]           --
│    └─ReLU: 2-570                       [16, 128, 8, 8]           --
│    └─Empty: 2-571                      [16, 128, 8, 8]           --
│    └─Clamp: 2-572                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-58                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-573         --                        --
│    └─One: 2-574                        [1]                       --
│    └─OutputScale: 2-575                --                        --
│    └─Empty: 2-576                      [16, 128, 1, 1]           --
│    └─Empty: 2-577                      [16, 128, 1, 1]           --
│    └─Empty: 2-578                      [16]                      --
│    └─Empty: 2-579                      [16]                      --
│    └─BatchNorm2d: 2-580                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-581                     [16, 16, 8, 8]            --
│    └─ReLU: 2-582                       [16, 16, 8, 8]            --
│    └─Empty: 2-583                      [16, 16, 8, 8]            --
│    └─Clamp: 2-584                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-59         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-585                  [16, 128, 8, 8]           --
│    └─Empty: 2-586                      [16, 128, 8, 8]           --
│    └─Empty: 2-587                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-588         --                        --
│    └─One: 2-589                        [1]                       --
│    └─OutputScale: 2-590                --                        --
│    └─Empty: 2-591                      [16, 128, 3, 3]           --
│    └─Empty: 2-592                      [16, 128, 3, 3]           --
│    └─Empty: 2-593                      [16]                      --
│    └─Empty: 2-594                      [16]                      --
│    └─BatchNorm2d: 2-595                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-596                     [16, 16, 8, 8]            --
│    └─ReLU: 2-597                       [16, 16, 8, 8]            --
│    └─Empty: 2-598                      [16, 16, 8, 8]            --
│    └─Clamp: 2-599                      [16, 16, 8, 8]            --
├─Dropout2d: 1-60                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-600         --                        --
│    └─One: 2-601                        [1]                       --
│    └─OutputScale: 2-602                --                        --
│    └─Empty: 2-603                      [128, 48, 1, 1]           --
│    └─Empty: 2-604                      [128, 48, 1, 1]           --
│    └─Empty: 2-605                      [128]                     --
│    └─Empty: 2-606                      [128]                     --
│    └─BatchNorm2d: 2-607                [16, 128, 64, 64]         --
│    └─Scaler: 2-608                     [16, 128, 64, 64]         --
│    └─ReLU: 2-609                       [16, 128, 64, 64]         --
│    └─Empty: 2-610                      [16, 128, 64, 64]         --
│    └─Clamp: 2-611                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-612                  [16, 128, 32, 32]         --
│    └─Empty: 2-613                      [16, 128, 32, 32]         --
│    └─Empty: 2-614                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-615         --                        --
│    └─One: 2-616                        [1]                       --
│    └─OutputScale: 2-617                --                        --
│    └─Empty: 2-618                      [128, 128, 3, 3]          --
│    └─Empty: 2-619                      [128, 128, 3, 3]          --
│    └─Empty: 2-620                      [128]                     --
│    └─Empty: 2-621                      [128]                     --
│    └─BatchNorm2d: 2-622                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-623                     [16, 128, 32, 32]         --
│    └─ReLU: 2-624                       [16, 128, 32, 32]         --
│    └─Empty: 2-625                      [16, 128, 32, 32]         --
│    └─Clamp: 2-626                      [16, 128, 32, 32]         --
├─Dropout2d: 1-63                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-64         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-627                  [16, 128, 16, 16]         --
│    └─Empty: 2-628                      [16, 128, 16, 16]         --
│    └─Empty: 2-629                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-630         --                        --
│    └─One: 2-631                        [1]                       --
│    └─OutputScale: 2-632                --                        --
│    └─Empty: 2-633                      [128, 128, 3, 3]          --
│    └─Empty: 2-634                      [128, 128, 3, 3]          --
│    └─Empty: 2-635                      [128]                     --
│    └─Empty: 2-636                      [128]                     --
│    └─BatchNorm2d: 2-637                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-638                     [16, 128, 16, 16]         --
│    └─ReLU: 2-639                       [16, 128, 16, 16]         --
│    └─Empty: 2-640                      [16, 128, 16, 16]         --
│    └─Clamp: 2-641                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-65                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-642         --                        --
│    └─One: 2-643                        [1]                       --
│    └─OutputScale: 2-644                --                        --
│    └─Empty: 2-645                      [128, 128, 1, 1]          --
│    └─Empty: 2-646                      [128, 128, 1, 1]          --
│    └─Empty: 2-647                      [128]                     --
│    └─Empty: 2-648                      [128]                     --
│    └─BatchNorm2d: 2-649                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-650                     [16, 128, 16, 16]         --
│    └─ReLU: 2-651                       [16, 128, 16, 16]         --
│    └─Empty: 2-652                      [16, 128, 16, 16]         --
│    └─Clamp: 2-653                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-654                  [16, 128, 16, 16]         --
│    └─Empty: 2-655                      [16, 128, 16, 16]         --
│    └─Empty: 2-656                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-657         --                        --
│    └─One: 2-658                        [1]                       --
│    └─OutputScale: 2-659                --                        --
│    └─Empty: 2-660                      [128, 128, 3, 3]          --
│    └─Empty: 2-661                      [128, 128, 3, 3]          --
│    └─Empty: 2-662                      [128]                     --
│    └─Empty: 2-663                      [128]                     --
│    └─BatchNorm2d: 2-664                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-665                     [16, 128, 16, 16]         --
│    └─ReLU: 2-666                       [16, 128, 16, 16]         --
│    └─Empty: 2-667                      [16, 128, 16, 16]         --
│    └─Clamp: 2-668                      [16, 128, 16, 16]         --
├─Dropout2d: 1-67                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-669                  [16, 128, 8, 8]           --
│    └─Empty: 2-670                      [16, 128, 8, 8]           --
│    └─Empty: 2-671                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-672         --                        --
│    └─One: 2-673                        [1]                       --
│    └─OutputScale: 2-674                --                        --
│    └─Empty: 2-675                      [128, 128, 3, 3]          --
│    └─Empty: 2-676                      [128, 128, 3, 3]          --
│    └─Empty: 2-677                      [128]                     --
│    └─Empty: 2-678                      [128]                     --
│    └─BatchNorm2d: 2-679                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-680                     [16, 128, 8, 8]           --
│    └─ReLU: 2-681                       [16, 128, 8, 8]           --
│    └─Empty: 2-682                      [16, 128, 8, 8]           --
│    └─Clamp: 2-683                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-69                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-684         --                        --
│    └─One: 2-685                        [1]                       --
│    └─OutputScale: 2-686                --                        --
│    └─Empty: 2-687                      [16, 128, 1, 1]           --
│    └─Empty: 2-688                      [16, 128, 1, 1]           --
│    └─Empty: 2-689                      [16]                      --
│    └─Empty: 2-690                      [16]                      --
│    └─BatchNorm2d: 2-691                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-692                     [16, 16, 8, 8]            --
│    └─ReLU: 2-693                       [16, 16, 8, 8]            --
│    └─Empty: 2-694                      [16, 16, 8, 8]            --
│    └─Clamp: 2-695                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-70         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-696                  [16, 128, 8, 8]           --
│    └─Empty: 2-697                      [16, 128, 8, 8]           --
│    └─Empty: 2-698                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-699         --                        --
│    └─One: 2-700                        [1]                       --
│    └─OutputScale: 2-701                --                        --
│    └─Empty: 2-702                      [16, 128, 3, 3]           --
│    └─Empty: 2-703                      [16, 128, 3, 3]           --
│    └─Empty: 2-704                      [16]                      --
│    └─Empty: 2-705                      [16]                      --
│    └─BatchNorm2d: 2-706                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-707                     [16, 16, 8, 8]            --
│    └─ReLU: 2-708                       [16, 16, 8, 8]            --
│    └─Empty: 2-709                      [16, 16, 8, 8]            --
│    └─Clamp: 2-710                      [16, 16, 8, 8]            --
├─Dropout2d: 1-71                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-72                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-711         --                        --
│    └─One: 2-712                        [1]                       --
│    └─OutputScale: 2-713                --                        --
│    └─Empty: 2-714                      [128, 48, 1, 1]           --
│    └─Empty: 2-715                      [128, 48, 1, 1]           --
│    └─Empty: 2-716                      [128]                     --
│    └─Empty: 2-717                      [128]                     --
│    └─BatchNorm2d: 2-718                [16, 128, 64, 64]         --
│    └─Scaler: 2-719                     [16, 128, 64, 64]         --
│    └─ReLU: 2-720                       [16, 128, 64, 64]         --
│    └─Empty: 2-721                      [16, 128, 64, 64]         --
│    └─Clamp: 2-722                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-723                  [16, 128, 32, 32]         --
│    └─Empty: 2-724                      [16, 128, 32, 32]         --
│    └─Empty: 2-725                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-726         --                        --
│    └─One: 2-727                        [1]                       --
│    └─OutputScale: 2-728                --                        --
│    └─Empty: 2-729                      [128, 128, 3, 3]          --
│    └─Empty: 2-730                      [128, 128, 3, 3]          --
│    └─Empty: 2-731                      [128]                     --
│    └─Empty: 2-732                      [128]                     --
│    └─BatchNorm2d: 2-733                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-734                     [16, 128, 32, 32]         --
│    └─ReLU: 2-735                       [16, 128, 32, 32]         --
│    └─Empty: 2-736                      [16, 128, 32, 32]         --
│    └─Clamp: 2-737                      [16, 128, 32, 32]         --
├─Dropout2d: 1-74                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-738                  [16, 128, 16, 16]         --
│    └─Empty: 2-739                      [16, 128, 16, 16]         --
│    └─Empty: 2-740                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-741         --                        --
│    └─One: 2-742                        [1]                       --
│    └─OutputScale: 2-743                --                        --
│    └─Empty: 2-744                      [128, 128, 3, 3]          --
│    └─Empty: 2-745                      [128, 128, 3, 3]          --
│    └─Empty: 2-746                      [128]                     --
│    └─Empty: 2-747                      [128]                     --
│    └─BatchNorm2d: 2-748                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-749                     [16, 128, 16, 16]         --
│    └─ReLU: 2-750                       [16, 128, 16, 16]         --
│    └─Empty: 2-751                      [16, 128, 16, 16]         --
│    └─Clamp: 2-752                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-76                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-753         --                        --
│    └─One: 2-754                        [1]                       --
│    └─OutputScale: 2-755                --                        --
│    └─Empty: 2-756                      [128, 128, 1, 1]          --
│    └─Empty: 2-757                      [128, 128, 1, 1]          --
│    └─Empty: 2-758                      [128]                     --
│    └─Empty: 2-759                      [128]                     --
│    └─BatchNorm2d: 2-760                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-761                     [16, 128, 16, 16]         --
│    └─ReLU: 2-762                       [16, 128, 16, 16]         --
│    └─Empty: 2-763                      [16, 128, 16, 16]         --
│    └─Clamp: 2-764                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-765                  [16, 128, 16, 16]         --
│    └─Empty: 2-766                      [16, 128, 16, 16]         --
│    └─Empty: 2-767                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-768         --                        --
│    └─One: 2-769                        [1]                       --
│    └─OutputScale: 2-770                --                        --
│    └─Empty: 2-771                      [128, 128, 3, 3]          --
│    └─Empty: 2-772                      [128, 128, 3, 3]          --
│    └─Empty: 2-773                      [128]                     --
│    └─Empty: 2-774                      [128]                     --
│    └─BatchNorm2d: 2-775                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-776                     [16, 128, 16, 16]         --
│    └─ReLU: 2-777                       [16, 128, 16, 16]         --
│    └─Empty: 2-778                      [16, 128, 16, 16]         --
│    └─Clamp: 2-779                      [16, 128, 16, 16]         --
├─Dropout2d: 1-78                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-780                  [16, 128, 8, 8]           --
│    └─Empty: 2-781                      [16, 128, 8, 8]           --
│    └─Empty: 2-782                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [128, 128, 3, 3]          --
│    └─Empty: 2-787                      [128, 128, 3, 3]          --
│    └─Empty: 2-788                      [128]                     --
│    └─Empty: 2-789                      [128]                     --
│    └─BatchNorm2d: 2-790                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-791                     [16, 128, 8, 8]           --
│    └─ReLU: 2-792                       [16, 128, 8, 8]           --
│    └─Empty: 2-793                      [16, 128, 8, 8]           --
│    └─Clamp: 2-794                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-80                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-795         --                        --
│    └─One: 2-796                        [1]                       --
│    └─OutputScale: 2-797                --                        --
│    └─Empty: 2-798                      [16, 128, 1, 1]           --
│    └─Empty: 2-799                      [16, 128, 1, 1]           --
│    └─Empty: 2-800                      [16]                      --
│    └─Empty: 2-801                      [16]                      --
│    └─BatchNorm2d: 2-802                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-803                     [16, 16, 8, 8]            --
│    └─ReLU: 2-804                       [16, 16, 8, 8]            --
│    └─Empty: 2-805                      [16, 16, 8, 8]            --
│    └─Clamp: 2-806                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-807                  [16, 128, 8, 8]           --
│    └─Empty: 2-808                      [16, 128, 8, 8]           --
│    └─Empty: 2-809                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [16, 128, 3, 3]           --
│    └─Empty: 2-814                      [16, 128, 3, 3]           --
│    └─Empty: 2-815                      [16]                      --
│    └─Empty: 2-816                      [16]                      --
│    └─BatchNorm2d: 2-817                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-818                     [16, 16, 8, 8]            --
│    └─ReLU: 2-819                       [16, 16, 8, 8]            --
│    └─Empty: 2-820                      [16, 16, 8, 8]            --
│    └─Clamp: 2-821                      [16, 16, 8, 8]            --
├─Dropout2d: 1-82                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-83                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-822         --                        --
│    └─One: 2-823                        [1]                       --
│    └─OutputScale: 2-824                --                        --
│    └─Empty: 2-825                      [128, 48, 1, 1]           --
│    └─Empty: 2-826                      [128, 48, 1, 1]           --
│    └─Empty: 2-827                      [128]                     --
│    └─Empty: 2-828                      [128]                     --
│    └─BatchNorm2d: 2-829                [16, 128, 64, 64]         --
│    └─Scaler: 2-830                     [16, 128, 64, 64]         --
│    └─ReLU: 2-831                       [16, 128, 64, 64]         --
│    └─Empty: 2-832                      [16, 128, 64, 64]         --
│    └─Clamp: 2-833                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-84         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-834                  [16, 128, 32, 32]         --
│    └─Empty: 2-835                      [16, 128, 32, 32]         --
│    └─Empty: 2-836                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-837         --                        --
│    └─One: 2-838                        [1]                       --
│    └─OutputScale: 2-839                --                        --
│    └─Empty: 2-840                      [128, 128, 3, 3]          --
│    └─Empty: 2-841                      [128, 128, 3, 3]          --
│    └─Empty: 2-842                      [128]                     --
│    └─Empty: 2-843                      [128]                     --
│    └─BatchNorm2d: 2-844                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-845                     [16, 128, 32, 32]         --
│    └─ReLU: 2-846                       [16, 128, 32, 32]         --
│    └─Empty: 2-847                      [16, 128, 32, 32]         --
│    └─Clamp: 2-848                      [16, 128, 32, 32]         --
├─Dropout2d: 1-85                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-86         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-849                  [16, 128, 16, 16]         --
│    └─Empty: 2-850                      [16, 128, 16, 16]         --
│    └─Empty: 2-851                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-852         --                        --
│    └─One: 2-853                        [1]                       --
│    └─OutputScale: 2-854                --                        --
│    └─Empty: 2-855                      [128, 128, 3, 3]          --
│    └─Empty: 2-856                      [128, 128, 3, 3]          --
│    └─Empty: 2-857                      [128]                     --
│    └─Empty: 2-858                      [128]                     --
│    └─BatchNorm2d: 2-859                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-860                     [16, 128, 16, 16]         --
│    └─ReLU: 2-861                       [16, 128, 16, 16]         --
│    └─Empty: 2-862                      [16, 128, 16, 16]         --
│    └─Clamp: 2-863                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-87                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-864         --                        --
│    └─One: 2-865                        [1]                       --
│    └─OutputScale: 2-866                --                        --
│    └─Empty: 2-867                      [128, 128, 1, 1]          --
│    └─Empty: 2-868                      [128, 128, 1, 1]          --
│    └─Empty: 2-869                      [128]                     --
│    └─Empty: 2-870                      [128]                     --
│    └─BatchNorm2d: 2-871                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-872                     [16, 128, 16, 16]         --
│    └─ReLU: 2-873                       [16, 128, 16, 16]         --
│    └─Empty: 2-874                      [16, 128, 16, 16]         --
│    └─Clamp: 2-875                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-88         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-876                  [16, 128, 16, 16]         --
│    └─Empty: 2-877                      [16, 128, 16, 16]         --
│    └─Empty: 2-878                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-879         --                        --
│    └─One: 2-880                        [1]                       --
│    └─OutputScale: 2-881                --                        --
│    └─Empty: 2-882                      [128, 128, 3, 3]          --
│    └─Empty: 2-883                      [128, 128, 3, 3]          --
│    └─Empty: 2-884                      [128]                     --
│    └─Empty: 2-885                      [128]                     --
│    └─BatchNorm2d: 2-886                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-887                     [16, 128, 16, 16]         --
│    └─ReLU: 2-888                       [16, 128, 16, 16]         --
│    └─Empty: 2-889                      [16, 128, 16, 16]         --
│    └─Clamp: 2-890                      [16, 128, 16, 16]         --
├─Dropout2d: 1-89                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-891                  [16, 128, 8, 8]           --
│    └─Empty: 2-892                      [16, 128, 8, 8]           --
│    └─Empty: 2-893                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-894         --                        --
│    └─One: 2-895                        [1]                       --
│    └─OutputScale: 2-896                --                        --
│    └─Empty: 2-897                      [128, 128, 3, 3]          --
│    └─Empty: 2-898                      [128, 128, 3, 3]          --
│    └─Empty: 2-899                      [128]                     --
│    └─Empty: 2-900                      [128]                     --
│    └─BatchNorm2d: 2-901                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-902                     [16, 128, 8, 8]           --
│    └─ReLU: 2-903                       [16, 128, 8, 8]           --
│    └─Empty: 2-904                      [16, 128, 8, 8]           --
│    └─Clamp: 2-905                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-91                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-906         --                        --
│    └─One: 2-907                        [1]                       --
│    └─OutputScale: 2-908                --                        --
│    └─Empty: 2-909                      [16, 128, 1, 1]           --
│    └─Empty: 2-910                      [16, 128, 1, 1]           --
│    └─Empty: 2-911                      [16]                      --
│    └─Empty: 2-912                      [16]                      --
│    └─BatchNorm2d: 2-913                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-914                     [16, 16, 8, 8]            --
│    └─ReLU: 2-915                       [16, 16, 8, 8]            --
│    └─Empty: 2-916                      [16, 16, 8, 8]            --
│    └─Clamp: 2-917                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-918                  [16, 128, 8, 8]           --
│    └─Empty: 2-919                      [16, 128, 8, 8]           --
│    └─Empty: 2-920                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [16, 128, 3, 3]           --
│    └─Empty: 2-925                      [16, 128, 3, 3]           --
│    └─Empty: 2-926                      [16]                      --
│    └─Empty: 2-927                      [16]                      --
│    └─BatchNorm2d: 2-928                [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-929                     [16, 16, 8, 8]            --
│    └─ReLU: 2-930                       [16, 16, 8, 8]            --
│    └─Empty: 2-931                      [16, 16, 8, 8]            --
│    └─Clamp: 2-932                      [16, 16, 8, 8]            --
├─Dropout2d: 1-93                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-94                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [128, 48, 1, 1]           --
│    └─Empty: 2-937                      [128, 48, 1, 1]           --
│    └─Empty: 2-938                      [128]                     --
│    └─Empty: 2-939                      [128]                     --
│    └─BatchNorm2d: 2-940                [16, 128, 64, 64]         --
│    └─Scaler: 2-941                     [16, 128, 64, 64]         --
│    └─ReLU: 2-942                       [16, 128, 64, 64]         --
│    └─Empty: 2-943                      [16, 128, 64, 64]         --
│    └─Clamp: 2-944                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-945                  [16, 128, 32, 32]         --
│    └─Empty: 2-946                      [16, 128, 32, 32]         --
│    └─Empty: 2-947                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-948         --                        --
│    └─One: 2-949                        [1]                       --
│    └─OutputScale: 2-950                --                        --
│    └─Empty: 2-951                      [128, 128, 3, 3]          --
│    └─Empty: 2-952                      [128, 128, 3, 3]          --
│    └─Empty: 2-953                      [128]                     --
│    └─Empty: 2-954                      [128]                     --
│    └─BatchNorm2d: 2-955                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-956                     [16, 128, 32, 32]         --
│    └─ReLU: 2-957                       [16, 128, 32, 32]         --
│    └─Empty: 2-958                      [16, 128, 32, 32]         --
│    └─Clamp: 2-959                      [16, 128, 32, 32]         --
├─Dropout2d: 1-96                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-960                  [16, 128, 16, 16]         --
│    └─Empty: 2-961                      [16, 128, 16, 16]         --
│    └─Empty: 2-962                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-963         --                        --
│    └─One: 2-964                        [1]                       --
│    └─OutputScale: 2-965                --                        --
│    └─Empty: 2-966                      [128, 128, 3, 3]          --
│    └─Empty: 2-967                      [128, 128, 3, 3]          --
│    └─Empty: 2-968                      [128]                     --
│    └─Empty: 2-969                      [128]                     --
│    └─BatchNorm2d: 2-970                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-971                     [16, 128, 16, 16]         --
│    └─ReLU: 2-972                       [16, 128, 16, 16]         --
│    └─Empty: 2-973                      [16, 128, 16, 16]         --
│    └─Clamp: 2-974                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-98                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-975         --                        --
│    └─One: 2-976                        [1]                       --
│    └─OutputScale: 2-977                --                        --
│    └─Empty: 2-978                      [128, 128, 1, 1]          --
│    └─Empty: 2-979                      [128, 128, 1, 1]          --
│    └─Empty: 2-980                      [128]                     --
│    └─Empty: 2-981                      [128]                     --
│    └─BatchNorm2d: 2-982                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-983                     [16, 128, 16, 16]         --
│    └─ReLU: 2-984                       [16, 128, 16, 16]         --
│    └─Empty: 2-985                      [16, 128, 16, 16]         --
│    └─Clamp: 2-986                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-987                  [16, 128, 16, 16]         --
│    └─Empty: 2-988                      [16, 128, 16, 16]         --
│    └─Empty: 2-989                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-990         --                        --
│    └─One: 2-991                        [1]                       --
│    └─OutputScale: 2-992                --                        --
│    └─Empty: 2-993                      [128, 128, 3, 3]          --
│    └─Empty: 2-994                      [128, 128, 3, 3]          --
│    └─Empty: 2-995                      [128]                     --
│    └─Empty: 2-996                      [128]                     --
│    └─BatchNorm2d: 2-997                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-998                     [16, 128, 16, 16]         --
│    └─ReLU: 2-999                       [16, 128, 16, 16]         --
│    └─Empty: 2-1000                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1001                     [16, 128, 16, 16]         --
├─Dropout2d: 1-100                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-101        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1002                 [16, 128, 8, 8]           --
│    └─Empty: 2-1003                     [16, 128, 8, 8]           --
│    └─Empty: 2-1004                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1005        --                        --
│    └─One: 2-1006                       [1]                       --
│    └─OutputScale: 2-1007               --                        --
│    └─Empty: 2-1008                     [128, 128, 3, 3]          --
│    └─Empty: 2-1009                     [128, 128, 3, 3]          --
│    └─Empty: 2-1010                     [128]                     --
│    └─Empty: 2-1011                     [128]                     --
│    └─BatchNorm2d: 2-1012               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1013                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1014                      [16, 128, 8, 8]           --
│    └─Empty: 2-1015                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1016                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-102               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1017        --                        --
│    └─One: 2-1018                       [1]                       --
│    └─OutputScale: 2-1019               --                        --
│    └─Empty: 2-1020                     [16, 128, 1, 1]           --
│    └─Empty: 2-1021                     [16, 128, 1, 1]           --
│    └─Empty: 2-1022                     [16]                      --
│    └─Empty: 2-1023                     [16]                      --
│    └─BatchNorm2d: 2-1024               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1025                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1026                      [16, 16, 8, 8]            --
│    └─Empty: 2-1027                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1028                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1029                 [16, 128, 8, 8]           --
│    └─Empty: 2-1030                     [16, 128, 8, 8]           --
│    └─Empty: 2-1031                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1032        --                        --
│    └─One: 2-1033                       [1]                       --
│    └─OutputScale: 2-1034               --                        --
│    └─Empty: 2-1035                     [16, 128, 3, 3]           --
│    └─Empty: 2-1036                     [16, 128, 3, 3]           --
│    └─Empty: 2-1037                     [16]                      --
│    └─Empty: 2-1038                     [16]                      --
│    └─BatchNorm2d: 2-1039               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1040                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1041                      [16, 16, 8, 8]            --
│    └─Empty: 2-1042                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1043                     [16, 16, 8, 8]            --
├─Dropout2d: 1-104                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-105               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1044        --                        --
│    └─One: 2-1045                       [1]                       --
│    └─OutputScale: 2-1046               --                        --
│    └─Empty: 2-1047                     [128, 48, 1, 1]           --
│    └─Empty: 2-1048                     [128, 48, 1, 1]           --
│    └─Empty: 2-1049                     [128]                     --
│    └─Empty: 2-1050                     [128]                     --
│    └─BatchNorm2d: 2-1051               [16, 128, 64, 64]         --
│    └─Scaler: 2-1052                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1053                      [16, 128, 64, 64]         --
│    └─Empty: 2-1054                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1055                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-106        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1056                 [16, 128, 32, 32]         --
│    └─Empty: 2-1057                     [16, 128, 32, 32]         --
│    └─Empty: 2-1058                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1059        --                        --
│    └─One: 2-1060                       [1]                       --
│    └─OutputScale: 2-1061               --                        --
│    └─Empty: 2-1062                     [128, 128, 3, 3]          --
│    └─Empty: 2-1063                     [128, 128, 3, 3]          --
│    └─Empty: 2-1064                     [128]                     --
│    └─Empty: 2-1065                     [128]                     --
│    └─BatchNorm2d: 2-1066               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1067                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1068                      [16, 128, 32, 32]         --
│    └─Empty: 2-1069                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1070                     [16, 128, 32, 32]         --
├─Dropout2d: 1-107                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-108        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1071                 [16, 128, 16, 16]         --
│    └─Empty: 2-1072                     [16, 128, 16, 16]         --
│    └─Empty: 2-1073                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1074        --                        --
│    └─One: 2-1075                       [1]                       --
│    └─OutputScale: 2-1076               --                        --
│    └─Empty: 2-1077                     [128, 128, 3, 3]          --
│    └─Empty: 2-1078                     [128, 128, 3, 3]          --
│    └─Empty: 2-1079                     [128]                     --
│    └─Empty: 2-1080                     [128]                     --
│    └─BatchNorm2d: 2-1081               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1082                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1083                      [16, 128, 16, 16]         --
│    └─Empty: 2-1084                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1085                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-109               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1086        --                        --
│    └─One: 2-1087                       [1]                       --
│    └─OutputScale: 2-1088               --                        --
│    └─Empty: 2-1089                     [128, 128, 1, 1]          --
│    └─Empty: 2-1090                     [128, 128, 1, 1]          --
│    └─Empty: 2-1091                     [128]                     --
│    └─Empty: 2-1092                     [128]                     --
│    └─BatchNorm2d: 2-1093               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1094                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1095                      [16, 128, 16, 16]         --
│    └─Empty: 2-1096                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1097                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-110        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1098                 [16, 128, 16, 16]         --
│    └─Empty: 2-1099                     [16, 128, 16, 16]         --
│    └─Empty: 2-1100                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1101        --                        --
│    └─One: 2-1102                       [1]                       --
│    └─OutputScale: 2-1103               --                        --
│    └─Empty: 2-1104                     [128, 128, 3, 3]          --
│    └─Empty: 2-1105                     [128, 128, 3, 3]          --
│    └─Empty: 2-1106                     [128]                     --
│    └─Empty: 2-1107                     [128]                     --
│    └─BatchNorm2d: 2-1108               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1109                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1110                      [16, 128, 16, 16]         --
│    └─Empty: 2-1111                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1112                     [16, 128, 16, 16]         --
├─Dropout2d: 1-111                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-112        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1113                 [16, 128, 8, 8]           --
│    └─Empty: 2-1114                     [16, 128, 8, 8]           --
│    └─Empty: 2-1115                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1116        --                        --
│    └─One: 2-1117                       [1]                       --
│    └─OutputScale: 2-1118               --                        --
│    └─Empty: 2-1119                     [128, 128, 3, 3]          --
│    └─Empty: 2-1120                     [128, 128, 3, 3]          --
│    └─Empty: 2-1121                     [128]                     --
│    └─Empty: 2-1122                     [128]                     --
│    └─BatchNorm2d: 2-1123               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1124                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1125                      [16, 128, 8, 8]           --
│    └─Empty: 2-1126                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1127                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-113               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1128        --                        --
│    └─One: 2-1129                       [1]                       --
│    └─OutputScale: 2-1130               --                        --
│    └─Empty: 2-1131                     [16, 128, 1, 1]           --
│    └─Empty: 2-1132                     [16, 128, 1, 1]           --
│    └─Empty: 2-1133                     [16]                      --
│    └─Empty: 2-1134                     [16]                      --
│    └─BatchNorm2d: 2-1135               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1136                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1137                      [16, 16, 8, 8]            --
│    └─Empty: 2-1138                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1139                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1140                 [16, 128, 8, 8]           --
│    └─Empty: 2-1141                     [16, 128, 8, 8]           --
│    └─Empty: 2-1142                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1143        --                        --
│    └─One: 2-1144                       [1]                       --
│    └─OutputScale: 2-1145               --                        --
│    └─Empty: 2-1146                     [16, 128, 3, 3]           --
│    └─Empty: 2-1147                     [16, 128, 3, 3]           --
│    └─Empty: 2-1148                     [16]                      --
│    └─Empty: 2-1149                     [16]                      --
│    └─BatchNorm2d: 2-1150               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1151                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1152                      [16, 16, 8, 8]            --
│    └─Empty: 2-1153                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1154                     [16, 16, 8, 8]            --
├─Dropout2d: 1-115                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-116               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1155        --                        --
│    └─One: 2-1156                       [1]                       --
│    └─OutputScale: 2-1157               --                        --
│    └─Empty: 2-1158                     [128, 48, 1, 1]           --
│    └─Empty: 2-1159                     [128, 48, 1, 1]           --
│    └─Empty: 2-1160                     [128]                     --
│    └─Empty: 2-1161                     [128]                     --
│    └─BatchNorm2d: 2-1162               [16, 128, 64, 64]         --
│    └─Scaler: 2-1163                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1164                      [16, 128, 64, 64]         --
│    └─Empty: 2-1165                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1166                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1167                 [16, 128, 32, 32]         --
│    └─Empty: 2-1168                     [16, 128, 32, 32]         --
│    └─Empty: 2-1169                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1170        --                        --
│    └─One: 2-1171                       [1]                       --
│    └─OutputScale: 2-1172               --                        --
│    └─Empty: 2-1173                     [128, 128, 3, 3]          --
│    └─Empty: 2-1174                     [128, 128, 3, 3]          --
│    └─Empty: 2-1175                     [128]                     --
│    └─Empty: 2-1176                     [128]                     --
│    └─BatchNorm2d: 2-1177               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1178                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1179                      [16, 128, 32, 32]         --
│    └─Empty: 2-1180                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1181                     [16, 128, 32, 32]         --
├─Dropout2d: 1-118                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1182                 [16, 128, 16, 16]         --
│    └─Empty: 2-1183                     [16, 128, 16, 16]         --
│    └─Empty: 2-1184                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1185        --                        --
│    └─One: 2-1186                       [1]                       --
│    └─OutputScale: 2-1187               --                        --
│    └─Empty: 2-1188                     [128, 128, 3, 3]          --
│    └─Empty: 2-1189                     [128, 128, 3, 3]          --
│    └─Empty: 2-1190                     [128]                     --
│    └─Empty: 2-1191                     [128]                     --
│    └─BatchNorm2d: 2-1192               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1193                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1194                      [16, 128, 16, 16]         --
│    └─Empty: 2-1195                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1196                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-120               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1197        --                        --
│    └─One: 2-1198                       [1]                       --
│    └─OutputScale: 2-1199               --                        --
│    └─Empty: 2-1200                     [128, 128, 1, 1]          --
│    └─Empty: 2-1201                     [128, 128, 1, 1]          --
│    └─Empty: 2-1202                     [128]                     --
│    └─Empty: 2-1203                     [128]                     --
│    └─BatchNorm2d: 2-1204               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1205                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1206                      [16, 128, 16, 16]         --
│    └─Empty: 2-1207                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1208                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1209                 [16, 128, 16, 16]         --
│    └─Empty: 2-1210                     [16, 128, 16, 16]         --
│    └─Empty: 2-1211                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1212        --                        --
│    └─One: 2-1213                       [1]                       --
│    └─OutputScale: 2-1214               --                        --
│    └─Empty: 2-1215                     [128, 128, 3, 3]          --
│    └─Empty: 2-1216                     [128, 128, 3, 3]          --
│    └─Empty: 2-1217                     [128]                     --
│    └─Empty: 2-1218                     [128]                     --
│    └─BatchNorm2d: 2-1219               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1220                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1221                      [16, 128, 16, 16]         --
│    └─Empty: 2-1222                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1223                     [16, 128, 16, 16]         --
├─Dropout2d: 1-122                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-123        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1224                 [16, 128, 8, 8]           --
│    └─Empty: 2-1225                     [16, 128, 8, 8]           --
│    └─Empty: 2-1226                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1227        --                        --
│    └─One: 2-1228                       [1]                       --
│    └─OutputScale: 2-1229               --                        --
│    └─Empty: 2-1230                     [128, 128, 3, 3]          --
│    └─Empty: 2-1231                     [128, 128, 3, 3]          --
│    └─Empty: 2-1232                     [128]                     --
│    └─Empty: 2-1233                     [128]                     --
│    └─BatchNorm2d: 2-1234               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1235                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1236                      [16, 128, 8, 8]           --
│    └─Empty: 2-1237                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1238                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-124               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1239        --                        --
│    └─One: 2-1240                       [1]                       --
│    └─OutputScale: 2-1241               --                        --
│    └─Empty: 2-1242                     [16, 128, 1, 1]           --
│    └─Empty: 2-1243                     [16, 128, 1, 1]           --
│    └─Empty: 2-1244                     [16]                      --
│    └─Empty: 2-1245                     [16]                      --
│    └─BatchNorm2d: 2-1246               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1247                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1248                      [16, 16, 8, 8]            --
│    └─Empty: 2-1249                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1250                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-125        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1251                 [16, 128, 8, 8]           --
│    └─Empty: 2-1252                     [16, 128, 8, 8]           --
│    └─Empty: 2-1253                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1254        --                        --
│    └─One: 2-1255                       [1]                       --
│    └─OutputScale: 2-1256               --                        --
│    └─Empty: 2-1257                     [16, 128, 3, 3]           --
│    └─Empty: 2-1258                     [16, 128, 3, 3]           --
│    └─Empty: 2-1259                     [16]                      --
│    └─Empty: 2-1260                     [16]                      --
│    └─BatchNorm2d: 2-1261               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1262                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1263                      [16, 16, 8, 8]            --
│    └─Empty: 2-1264                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1265                     [16, 16, 8, 8]            --
├─Dropout2d: 1-126                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-127               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1266        --                        --
│    └─One: 2-1267                       [1]                       --
│    └─OutputScale: 2-1268               --                        --
│    └─Empty: 2-1269                     [128, 48, 1, 1]           --
│    └─Empty: 2-1270                     [128, 48, 1, 1]           --
│    └─Empty: 2-1271                     [128]                     --
│    └─Empty: 2-1272                     [128]                     --
│    └─BatchNorm2d: 2-1273               [16, 128, 64, 64]         --
│    └─Scaler: 2-1274                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1275                      [16, 128, 64, 64]         --
│    └─Empty: 2-1276                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1277                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1278                 [16, 128, 32, 32]         --
│    └─Empty: 2-1279                     [16, 128, 32, 32]         --
│    └─Empty: 2-1280                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1281        --                        --
│    └─One: 2-1282                       [1]                       --
│    └─OutputScale: 2-1283               --                        --
│    └─Empty: 2-1284                     [128, 128, 3, 3]          --
│    └─Empty: 2-1285                     [128, 128, 3, 3]          --
│    └─Empty: 2-1286                     [128]                     --
│    └─Empty: 2-1287                     [128]                     --
│    └─BatchNorm2d: 2-1288               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1289                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1290                      [16, 128, 32, 32]         --
│    └─Empty: 2-1291                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1292                     [16, 128, 32, 32]         --
├─Dropout2d: 1-129                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1293                 [16, 128, 16, 16]         --
│    └─Empty: 2-1294                     [16, 128, 16, 16]         --
│    └─Empty: 2-1295                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1296        --                        --
│    └─One: 2-1297                       [1]                       --
│    └─OutputScale: 2-1298               --                        --
│    └─Empty: 2-1299                     [128, 128, 3, 3]          --
│    └─Empty: 2-1300                     [128, 128, 3, 3]          --
│    └─Empty: 2-1301                     [128]                     --
│    └─Empty: 2-1302                     [128]                     --
│    └─BatchNorm2d: 2-1303               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1304                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1305                      [16, 128, 16, 16]         --
│    └─Empty: 2-1306                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1307                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-131               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1308        --                        --
│    └─One: 2-1309                       [1]                       --
│    └─OutputScale: 2-1310               --                        --
│    └─Empty: 2-1311                     [128, 128, 1, 1]          --
│    └─Empty: 2-1312                     [128, 128, 1, 1]          --
│    └─Empty: 2-1313                     [128]                     --
│    └─Empty: 2-1314                     [128]                     --
│    └─BatchNorm2d: 2-1315               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1316                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1317                      [16, 128, 16, 16]         --
│    └─Empty: 2-1318                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1319                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1320                 [16, 128, 16, 16]         --
│    └─Empty: 2-1321                     [16, 128, 16, 16]         --
│    └─Empty: 2-1322                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1323        --                        --
│    └─One: 2-1324                       [1]                       --
│    └─OutputScale: 2-1325               --                        --
│    └─Empty: 2-1326                     [128, 128, 3, 3]          --
│    └─Empty: 2-1327                     [128, 128, 3, 3]          --
│    └─Empty: 2-1328                     [128]                     --
│    └─Empty: 2-1329                     [128]                     --
│    └─BatchNorm2d: 2-1330               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1331                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1332                      [16, 128, 16, 16]         --
│    └─Empty: 2-1333                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1334                     [16, 128, 16, 16]         --
├─Dropout2d: 1-133                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1335                 [16, 128, 8, 8]           --
│    └─Empty: 2-1336                     [16, 128, 8, 8]           --
│    └─Empty: 2-1337                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1338        --                        --
│    └─One: 2-1339                       [1]                       --
│    └─OutputScale: 2-1340               --                        --
│    └─Empty: 2-1341                     [128, 128, 3, 3]          --
│    └─Empty: 2-1342                     [128, 128, 3, 3]          --
│    └─Empty: 2-1343                     [128]                     --
│    └─Empty: 2-1344                     [128]                     --
│    └─BatchNorm2d: 2-1345               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1346                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1347                      [16, 128, 8, 8]           --
│    └─Empty: 2-1348                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1349                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-135               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1350        --                        --
│    └─One: 2-1351                       [1]                       --
│    └─OutputScale: 2-1352               --                        --
│    └─Empty: 2-1353                     [16, 128, 1, 1]           --
│    └─Empty: 2-1354                     [16, 128, 1, 1]           --
│    └─Empty: 2-1355                     [16]                      --
│    └─Empty: 2-1356                     [16]                      --
│    └─BatchNorm2d: 2-1357               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1358                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1359                      [16, 16, 8, 8]            --
│    └─Empty: 2-1360                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1361                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1362                 [16, 128, 8, 8]           --
│    └─Empty: 2-1363                     [16, 128, 8, 8]           --
│    └─Empty: 2-1364                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1365        --                        --
│    └─One: 2-1366                       [1]                       --
│    └─OutputScale: 2-1367               --                        --
│    └─Empty: 2-1368                     [16, 128, 3, 3]           --
│    └─Empty: 2-1369                     [16, 128, 3, 3]           --
│    └─Empty: 2-1370                     [16]                      --
│    └─Empty: 2-1371                     [16]                      --
│    └─BatchNorm2d: 2-1372               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1373                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1374                      [16, 16, 8, 8]            --
│    └─Empty: 2-1375                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1376                     [16, 16, 8, 8]            --
├─Dropout2d: 1-137                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-138               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1377        --                        --
│    └─One: 2-1378                       [1]                       --
│    └─OutputScale: 2-1379               --                        --
│    └─Empty: 2-1380                     [128, 48, 1, 1]           --
│    └─Empty: 2-1381                     [128, 48, 1, 1]           --
│    └─Empty: 2-1382                     [128]                     --
│    └─Empty: 2-1383                     [128]                     --
│    └─BatchNorm2d: 2-1384               [16, 128, 64, 64]         --
│    └─Scaler: 2-1385                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1386                      [16, 128, 64, 64]         --
│    └─Empty: 2-1387                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1388                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-139        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1389                 [16, 128, 32, 32]         --
│    └─Empty: 2-1390                     [16, 128, 32, 32]         --
│    └─Empty: 2-1391                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1392        --                        --
│    └─One: 2-1393                       [1]                       --
│    └─OutputScale: 2-1394               --                        --
│    └─Empty: 2-1395                     [128, 128, 3, 3]          --
│    └─Empty: 2-1396                     [128, 128, 3, 3]          --
│    └─Empty: 2-1397                     [128]                     --
│    └─Empty: 2-1398                     [128]                     --
│    └─BatchNorm2d: 2-1399               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1400                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1401                      [16, 128, 32, 32]         --
│    └─Empty: 2-1402                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1403                     [16, 128, 32, 32]         --
├─Dropout2d: 1-140                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1404                 [16, 128, 16, 16]         --
│    └─Empty: 2-1405                     [16, 128, 16, 16]         --
│    └─Empty: 2-1406                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1407        --                        --
│    └─One: 2-1408                       [1]                       --
│    └─OutputScale: 2-1409               --                        --
│    └─Empty: 2-1410                     [128, 128, 3, 3]          --
│    └─Empty: 2-1411                     [128, 128, 3, 3]          --
│    └─Empty: 2-1412                     [128]                     --
│    └─Empty: 2-1413                     [128]                     --
│    └─BatchNorm2d: 2-1414               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1415                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1416                      [16, 128, 16, 16]         --
│    └─Empty: 2-1417                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1418                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-142               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1419        --                        --
│    └─One: 2-1420                       [1]                       --
│    └─OutputScale: 2-1421               --                        --
│    └─Empty: 2-1422                     [128, 128, 1, 1]          --
│    └─Empty: 2-1423                     [128, 128, 1, 1]          --
│    └─Empty: 2-1424                     [128]                     --
│    └─Empty: 2-1425                     [128]                     --
│    └─BatchNorm2d: 2-1426               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1427                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1428                      [16, 128, 16, 16]         --
│    └─Empty: 2-1429                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1430                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1431                 [16, 128, 16, 16]         --
│    └─Empty: 2-1432                     [16, 128, 16, 16]         --
│    └─Empty: 2-1433                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1434        --                        --
│    └─One: 2-1435                       [1]                       --
│    └─OutputScale: 2-1436               --                        --
│    └─Empty: 2-1437                     [128, 128, 3, 3]          --
│    └─Empty: 2-1438                     [128, 128, 3, 3]          --
│    └─Empty: 2-1439                     [128]                     --
│    └─Empty: 2-1440                     [128]                     --
│    └─BatchNorm2d: 2-1441               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1442                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1443                      [16, 128, 16, 16]         --
│    └─Empty: 2-1444                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1445                     [16, 128, 16, 16]         --
├─Dropout2d: 1-144                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1446                 [16, 128, 8, 8]           --
│    └─Empty: 2-1447                     [16, 128, 8, 8]           --
│    └─Empty: 2-1448                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1449        --                        --
│    └─One: 2-1450                       [1]                       --
│    └─OutputScale: 2-1451               --                        --
│    └─Empty: 2-1452                     [128, 128, 3, 3]          --
│    └─Empty: 2-1453                     [128, 128, 3, 3]          --
│    └─Empty: 2-1454                     [128]                     --
│    └─Empty: 2-1455                     [128]                     --
│    └─BatchNorm2d: 2-1456               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1457                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1458                      [16, 128, 8, 8]           --
│    └─Empty: 2-1459                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1460                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-146               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1461        --                        --
│    └─One: 2-1462                       [1]                       --
│    └─OutputScale: 2-1463               --                        --
│    └─Empty: 2-1464                     [16, 128, 1, 1]           --
│    └─Empty: 2-1465                     [16, 128, 1, 1]           --
│    └─Empty: 2-1466                     [16]                      --
│    └─Empty: 2-1467                     [16]                      --
│    └─BatchNorm2d: 2-1468               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1469                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1470                      [16, 16, 8, 8]            --
│    └─Empty: 2-1471                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1472                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1473                 [16, 128, 8, 8]           --
│    └─Empty: 2-1474                     [16, 128, 8, 8]           --
│    └─Empty: 2-1475                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1476        --                        --
│    └─One: 2-1477                       [1]                       --
│    └─OutputScale: 2-1478               --                        --
│    └─Empty: 2-1479                     [16, 128, 3, 3]           --
│    └─Empty: 2-1480                     [16, 128, 3, 3]           --
│    └─Empty: 2-1481                     [16]                      --
│    └─Empty: 2-1482                     [16]                      --
│    └─BatchNorm2d: 2-1483               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1484                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1485                      [16, 16, 8, 8]            --
│    └─Empty: 2-1486                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1487                     [16, 16, 8, 8]            --
├─Dropout2d: 1-148                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-149               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1488        --                        --
│    └─One: 2-1489                       [1]                       --
│    └─OutputScale: 2-1490               --                        --
│    └─Empty: 2-1491                     [128, 48, 1, 1]           --
│    └─Empty: 2-1492                     [128, 48, 1, 1]           --
│    └─Empty: 2-1493                     [128]                     --
│    └─Empty: 2-1494                     [128]                     --
│    └─BatchNorm2d: 2-1495               [16, 128, 64, 64]         --
│    └─Scaler: 2-1496                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1497                      [16, 128, 64, 64]         --
│    └─Empty: 2-1498                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1499                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1500                 [16, 128, 32, 32]         --
│    └─Empty: 2-1501                     [16, 128, 32, 32]         --
│    └─Empty: 2-1502                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1503        --                        --
│    └─One: 2-1504                       [1]                       --
│    └─OutputScale: 2-1505               --                        --
│    └─Empty: 2-1506                     [128, 128, 3, 3]          --
│    └─Empty: 2-1507                     [128, 128, 3, 3]          --
│    └─Empty: 2-1508                     [128]                     --
│    └─Empty: 2-1509                     [128]                     --
│    └─BatchNorm2d: 2-1510               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1511                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1512                      [16, 128, 32, 32]         --
│    └─Empty: 2-1513                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1514                     [16, 128, 32, 32]         --
├─Dropout2d: 1-151                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-152        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1515                 [16, 128, 16, 16]         --
│    └─Empty: 2-1516                     [16, 128, 16, 16]         --
│    └─Empty: 2-1517                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1518        --                        --
│    └─One: 2-1519                       [1]                       --
│    └─OutputScale: 2-1520               --                        --
│    └─Empty: 2-1521                     [128, 128, 3, 3]          --
│    └─Empty: 2-1522                     [128, 128, 3, 3]          --
│    └─Empty: 2-1523                     [128]                     --
│    └─Empty: 2-1524                     [128]                     --
│    └─BatchNorm2d: 2-1525               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1526                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1527                      [16, 128, 16, 16]         --
│    └─Empty: 2-1528                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1529                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-153               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1530        --                        --
│    └─One: 2-1531                       [1]                       --
│    └─OutputScale: 2-1532               --                        --
│    └─Empty: 2-1533                     [128, 128, 1, 1]          --
│    └─Empty: 2-1534                     [128, 128, 1, 1]          --
│    └─Empty: 2-1535                     [128]                     --
│    └─Empty: 2-1536                     [128]                     --
│    └─BatchNorm2d: 2-1537               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1538                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1539                      [16, 128, 16, 16]         --
│    └─Empty: 2-1540                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1541                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-154        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1542                 [16, 128, 16, 16]         --
│    └─Empty: 2-1543                     [16, 128, 16, 16]         --
│    └─Empty: 2-1544                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1545        --                        --
│    └─One: 2-1546                       [1]                       --
│    └─OutputScale: 2-1547               --                        --
│    └─Empty: 2-1548                     [128, 128, 3, 3]          --
│    └─Empty: 2-1549                     [128, 128, 3, 3]          --
│    └─Empty: 2-1550                     [128]                     --
│    └─Empty: 2-1551                     [128]                     --
│    └─BatchNorm2d: 2-1552               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1553                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1554                      [16, 128, 16, 16]         --
│    └─Empty: 2-1555                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1556                     [16, 128, 16, 16]         --
├─Dropout2d: 1-155                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-156        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1557                 [16, 128, 8, 8]           --
│    └─Empty: 2-1558                     [16, 128, 8, 8]           --
│    └─Empty: 2-1559                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1560        --                        --
│    └─One: 2-1561                       [1]                       --
│    └─OutputScale: 2-1562               --                        --
│    └─Empty: 2-1563                     [128, 128, 3, 3]          --
│    └─Empty: 2-1564                     [128, 128, 3, 3]          --
│    └─Empty: 2-1565                     [128]                     --
│    └─Empty: 2-1566                     [128]                     --
│    └─BatchNorm2d: 2-1567               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1568                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1569                      [16, 128, 8, 8]           --
│    └─Empty: 2-1570                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1571                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-157               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1572        --                        --
│    └─One: 2-1573                       [1]                       --
│    └─OutputScale: 2-1574               --                        --
│    └─Empty: 2-1575                     [16, 128, 1, 1]           --
│    └─Empty: 2-1576                     [16, 128, 1, 1]           --
│    └─Empty: 2-1577                     [16]                      --
│    └─Empty: 2-1578                     [16]                      --
│    └─BatchNorm2d: 2-1579               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1580                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1581                      [16, 16, 8, 8]            --
│    └─Empty: 2-1582                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1583                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1584                 [16, 128, 8, 8]           --
│    └─Empty: 2-1585                     [16, 128, 8, 8]           --
│    └─Empty: 2-1586                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1587        --                        --
│    └─One: 2-1588                       [1]                       --
│    └─OutputScale: 2-1589               --                        --
│    └─Empty: 2-1590                     [16, 128, 3, 3]           --
│    └─Empty: 2-1591                     [16, 128, 3, 3]           --
│    └─Empty: 2-1592                     [16]                      --
│    └─Empty: 2-1593                     [16]                      --
│    └─BatchNorm2d: 2-1594               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1595                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1596                      [16, 16, 8, 8]            --
│    └─Empty: 2-1597                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1598                     [16, 16, 8, 8]            --
├─Dropout2d: 1-159                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-160               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1599        --                        --
│    └─One: 2-1600                       [1]                       --
│    └─OutputScale: 2-1601               --                        --
│    └─Empty: 2-1602                     [128, 48, 1, 1]           --
│    └─Empty: 2-1603                     [128, 48, 1, 1]           --
│    └─Empty: 2-1604                     [128]                     --
│    └─Empty: 2-1605                     [128]                     --
│    └─BatchNorm2d: 2-1606               [16, 128, 64, 64]         --
│    └─Scaler: 2-1607                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1608                      [16, 128, 64, 64]         --
│    └─Empty: 2-1609                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1610                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-161        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1611                 [16, 128, 32, 32]         --
│    └─Empty: 2-1612                     [16, 128, 32, 32]         --
│    └─Empty: 2-1613                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1614        --                        --
│    └─One: 2-1615                       [1]                       --
│    └─OutputScale: 2-1616               --                        --
│    └─Empty: 2-1617                     [128, 128, 3, 3]          --
│    └─Empty: 2-1618                     [128, 128, 3, 3]          --
│    └─Empty: 2-1619                     [128]                     --
│    └─Empty: 2-1620                     [128]                     --
│    └─BatchNorm2d: 2-1621               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1622                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1623                      [16, 128, 32, 32]         --
│    └─Empty: 2-1624                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1625                     [16, 128, 32, 32]         --
├─Dropout2d: 1-162                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-163        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1626                 [16, 128, 16, 16]         --
│    └─Empty: 2-1627                     [16, 128, 16, 16]         --
│    └─Empty: 2-1628                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [128, 128, 3, 3]          --
│    └─Empty: 2-1633                     [128, 128, 3, 3]          --
│    └─Empty: 2-1634                     [128]                     --
│    └─Empty: 2-1635                     [128]                     --
│    └─BatchNorm2d: 2-1636               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1637                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1638                      [16, 128, 16, 16]         --
│    └─Empty: 2-1639                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1640                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-164               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [128, 128, 1, 1]          --
│    └─Empty: 2-1645                     [128, 128, 1, 1]          --
│    └─Empty: 2-1646                     [128]                     --
│    └─Empty: 2-1647                     [128]                     --
│    └─BatchNorm2d: 2-1648               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1649                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1650                      [16, 128, 16, 16]         --
│    └─Empty: 2-1651                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1652                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1653                 [16, 128, 16, 16]         --
│    └─Empty: 2-1654                     [16, 128, 16, 16]         --
│    └─Empty: 2-1655                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [128, 128, 3, 3]          --
│    └─Empty: 2-1660                     [128, 128, 3, 3]          --
│    └─Empty: 2-1661                     [128]                     --
│    └─Empty: 2-1662                     [128]                     --
│    └─BatchNorm2d: 2-1663               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1664                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1665                      [16, 128, 16, 16]         --
│    └─Empty: 2-1666                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1667                     [16, 128, 16, 16]         --
├─Dropout2d: 1-166                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1668                 [16, 128, 8, 8]           --
│    └─Empty: 2-1669                     [16, 128, 8, 8]           --
│    └─Empty: 2-1670                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1671        --                        --
│    └─One: 2-1672                       [1]                       --
│    └─OutputScale: 2-1673               --                        --
│    └─Empty: 2-1674                     [128, 128, 3, 3]          --
│    └─Empty: 2-1675                     [128, 128, 3, 3]          --
│    └─Empty: 2-1676                     [128]                     --
│    └─Empty: 2-1677                     [128]                     --
│    └─BatchNorm2d: 2-1678               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1679                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1680                      [16, 128, 8, 8]           --
│    └─Empty: 2-1681                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1682                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-168               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [16, 128, 1, 1]           --
│    └─Empty: 2-1687                     [16, 128, 1, 1]           --
│    └─Empty: 2-1688                     [16]                      --
│    └─Empty: 2-1689                     [16]                      --
│    └─BatchNorm2d: 2-1690               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1691                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1692                      [16, 16, 8, 8]            --
│    └─Empty: 2-1693                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1694                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-169        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1695                 [16, 128, 8, 8]           --
│    └─Empty: 2-1696                     [16, 128, 8, 8]           --
│    └─Empty: 2-1697                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1698        --                        --
│    └─One: 2-1699                       [1]                       --
│    └─OutputScale: 2-1700               --                        --
│    └─Empty: 2-1701                     [16, 128, 3, 3]           --
│    └─Empty: 2-1702                     [16, 128, 3, 3]           --
│    └─Empty: 2-1703                     [16]                      --
│    └─Empty: 2-1704                     [16]                      --
│    └─BatchNorm2d: 2-1705               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1706                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1707                      [16, 16, 8, 8]            --
│    └─Empty: 2-1708                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1709                     [16, 16, 8, 8]            --
├─Dropout2d: 1-170                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-171               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [128, 48, 1, 1]           --
│    └─Empty: 2-1714                     [128, 48, 1, 1]           --
│    └─Empty: 2-1715                     [128]                     --
│    └─Empty: 2-1716                     [128]                     --
│    └─BatchNorm2d: 2-1717               [16, 128, 64, 64]         --
│    └─Scaler: 2-1718                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1719                      [16, 128, 64, 64]         --
│    └─Empty: 2-1720                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1721                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-172        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1722                 [16, 128, 32, 32]         --
│    └─Empty: 2-1723                     [16, 128, 32, 32]         --
│    └─Empty: 2-1724                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1725        --                        --
│    └─One: 2-1726                       [1]                       --
│    └─OutputScale: 2-1727               --                        --
│    └─Empty: 2-1728                     [128, 128, 3, 3]          --
│    └─Empty: 2-1729                     [128, 128, 3, 3]          --
│    └─Empty: 2-1730                     [128]                     --
│    └─Empty: 2-1731                     [128]                     --
│    └─BatchNorm2d: 2-1732               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1733                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1734                      [16, 128, 32, 32]         --
│    └─Empty: 2-1735                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1736                     [16, 128, 32, 32]         --
├─Dropout2d: 1-173                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1737                 [16, 128, 16, 16]         --
│    └─Empty: 2-1738                     [16, 128, 16, 16]         --
│    └─Empty: 2-1739                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1740        --                        --
│    └─One: 2-1741                       [1]                       --
│    └─OutputScale: 2-1742               --                        --
│    └─Empty: 2-1743                     [128, 128, 3, 3]          --
│    └─Empty: 2-1744                     [128, 128, 3, 3]          --
│    └─Empty: 2-1745                     [128]                     --
│    └─Empty: 2-1746                     [128]                     --
│    └─BatchNorm2d: 2-1747               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1748                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1749                      [16, 128, 16, 16]         --
│    └─Empty: 2-1750                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1751                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-175               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1752        --                        --
│    └─One: 2-1753                       [1]                       --
│    └─OutputScale: 2-1754               --                        --
│    └─Empty: 2-1755                     [128, 128, 1, 1]          --
│    └─Empty: 2-1756                     [128, 128, 1, 1]          --
│    └─Empty: 2-1757                     [128]                     --
│    └─Empty: 2-1758                     [128]                     --
│    └─BatchNorm2d: 2-1759               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1760                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1761                      [16, 128, 16, 16]         --
│    └─Empty: 2-1762                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1763                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1764                 [16, 128, 16, 16]         --
│    └─Empty: 2-1765                     [16, 128, 16, 16]         --
│    └─Empty: 2-1766                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1767        --                        --
│    └─One: 2-1768                       [1]                       --
│    └─OutputScale: 2-1769               --                        --
│    └─Empty: 2-1770                     [128, 128, 3, 3]          --
│    └─Empty: 2-1771                     [128, 128, 3, 3]          --
│    └─Empty: 2-1772                     [128]                     --
│    └─Empty: 2-1773                     [128]                     --
│    └─BatchNorm2d: 2-1774               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1775                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1776                      [16, 128, 16, 16]         --
│    └─Empty: 2-1777                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1778                     [16, 128, 16, 16]         --
├─Dropout2d: 1-177                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-178        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1779                 [16, 128, 8, 8]           --
│    └─Empty: 2-1780                     [16, 128, 8, 8]           --
│    └─Empty: 2-1781                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1782        --                        --
│    └─One: 2-1783                       [1]                       --
│    └─OutputScale: 2-1784               --                        --
│    └─Empty: 2-1785                     [128, 128, 3, 3]          --
│    └─Empty: 2-1786                     [128, 128, 3, 3]          --
│    └─Empty: 2-1787                     [128]                     --
│    └─Empty: 2-1788                     [128]                     --
│    └─BatchNorm2d: 2-1789               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1790                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1791                      [16, 128, 8, 8]           --
│    └─Empty: 2-1792                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1793                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-179               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1794        --                        --
│    └─One: 2-1795                       [1]                       --
│    └─OutputScale: 2-1796               --                        --
│    └─Empty: 2-1797                     [16, 128, 1, 1]           --
│    └─Empty: 2-1798                     [16, 128, 1, 1]           --
│    └─Empty: 2-1799                     [16]                      --
│    └─Empty: 2-1800                     [16]                      --
│    └─BatchNorm2d: 2-1801               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1802                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1803                      [16, 16, 8, 8]            --
│    └─Empty: 2-1804                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1805                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1806                 [16, 128, 8, 8]           --
│    └─Empty: 2-1807                     [16, 128, 8, 8]           --
│    └─Empty: 2-1808                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1809        --                        --
│    └─One: 2-1810                       [1]                       --
│    └─OutputScale: 2-1811               --                        --
│    └─Empty: 2-1812                     [16, 128, 3, 3]           --
│    └─Empty: 2-1813                     [16, 128, 3, 3]           --
│    └─Empty: 2-1814                     [16]                      --
│    └─Empty: 2-1815                     [16]                      --
│    └─BatchNorm2d: 2-1816               [16, 16, 8, 8]            (recursive)
│    └─Scaler: 2-1817                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1818                      [16, 16, 8, 8]            --
│    └─Empty: 2-1819                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1820                     [16, 16, 8, 8]            --
├─Dropout2d: 1-181                       [16, 16, 8, 8]            --
├─Linear: 1-182                          [16, 5]                   5,126
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [5, 1024]                 --
│    └─Empty: 2-1825                     [5, 1024]                 --
│    └─Empty: 2-1826                     [16, 5]                   --
│    └─Empty: 2-1827                     [16, 5]                   --
│    └─Clamp: 2-1828                     [16, 5]                   --
├─Linear: 1-183                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1829        --                        --
│    └─One: 2-1830                       [1]                       --
│    └─OutputScale: 2-1831               --                        --
│    └─Empty: 2-1832                     [5, 1024]                 --
│    └─Empty: 2-1833                     [5, 1024]                 --
│    └─Empty: 2-1834                     [16, 5]                   --
│    └─Empty: 2-1835                     [16, 5]                   --
│    └─Clamp: 2-1836                     [16, 5]                   --
├─Linear: 1-184                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1837        --                        --
│    └─One: 2-1838                       [1]                       --
│    └─OutputScale: 2-1839               --                        --
│    └─Empty: 2-1840                     [5, 1024]                 --
│    └─Empty: 2-1841                     [5, 1024]                 --
│    └─Empty: 2-1842                     [16, 5]                   --
│    └─Empty: 2-1843                     [16, 5]                   --
│    └─Clamp: 2-1844                     [16, 5]                   --
├─Linear: 1-185                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1845        --                        --
│    └─One: 2-1846                       [1]                       --
│    └─OutputScale: 2-1847               --                        --
│    └─Empty: 2-1848                     [5, 1024]                 --
│    └─Empty: 2-1849                     [5, 1024]                 --
│    └─Empty: 2-1850                     [16, 5]                   --
│    └─Empty: 2-1851                     [16, 5]                   --
│    └─Clamp: 2-1852                     [16, 5]                   --
├─Linear: 1-186                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1853        --                        --
│    └─One: 2-1854                       [1]                       --
│    └─OutputScale: 2-1855               --                        --
│    └─Empty: 2-1856                     [5, 1024]                 --
│    └─Empty: 2-1857                     [5, 1024]                 --
│    └─Empty: 2-1858                     [16, 5]                   --
│    └─Empty: 2-1859                     [16, 5]                   --
│    └─Clamp: 2-1860                     [16, 5]                   --
├─Linear: 1-187                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1861        --                        --
│    └─One: 2-1862                       [1]                       --
│    └─OutputScale: 2-1863               --                        --
│    └─Empty: 2-1864                     [5, 1024]                 --
│    └─Empty: 2-1865                     [5, 1024]                 --
│    └─Empty: 2-1866                     [16, 5]                   --
│    └─Empty: 2-1867                     [16, 5]                   --
│    └─Clamp: 2-1868                     [16, 5]                   --
├─Linear: 1-188                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1869        --                        --
│    └─One: 2-1870                       [1]                       --
│    └─OutputScale: 2-1871               --                        --
│    └─Empty: 2-1872                     [5, 1024]                 --
│    └─Empty: 2-1873                     [5, 1024]                 --
│    └─Empty: 2-1874                     [16, 5]                   --
│    └─Empty: 2-1875                     [16, 5]                   --
│    └─Clamp: 2-1876                     [16, 5]                   --
├─Linear: 1-189                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1877        --                        --
│    └─One: 2-1878                       [1]                       --
│    └─OutputScale: 2-1879               --                        --
│    └─Empty: 2-1880                     [5, 1024]                 --
│    └─Empty: 2-1881                     [5, 1024]                 --
│    └─Empty: 2-1882                     [16, 5]                   --
│    └─Empty: 2-1883                     [16, 5]                   --
│    └─Clamp: 2-1884                     [16, 5]                   --
├─Linear: 1-190                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1885        --                        --
│    └─One: 2-1886                       [1]                       --
│    └─OutputScale: 2-1887               --                        --
│    └─Empty: 2-1888                     [5, 1024]                 --
│    └─Empty: 2-1889                     [5, 1024]                 --
│    └─Empty: 2-1890                     [16, 5]                   --
│    └─Empty: 2-1891                     [16, 5]                   --
│    └─Clamp: 2-1892                     [16, 5]                   --
├─Linear: 1-191                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1893        --                        --
│    └─One: 2-1894                       [1]                       --
│    └─OutputScale: 2-1895               --                        --
│    └─Empty: 2-1896                     [5, 1024]                 --
│    └─Empty: 2-1897                     [5, 1024]                 --
│    └─Empty: 2-1898                     [16, 5]                   --
│    └─Empty: 2-1899                     [16, 5]                   --
│    └─Clamp: 2-1900                     [16, 5]                   --
├─Linear: 1-192                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1901        --                        --
│    └─One: 2-1902                       [1]                       --
│    └─OutputScale: 2-1903               --                        --
│    └─Empty: 2-1904                     [5, 1024]                 --
│    └─Empty: 2-1905                     [5, 1024]                 --
│    └─Empty: 2-1906                     [16, 5]                   --
│    └─Empty: 2-1907                     [16, 5]                   --
│    └─Clamp: 2-1908                     [16, 5]                   --
├─Linear: 1-193                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1909        --                        --
│    └─One: 2-1910                       [1]                       --
│    └─OutputScale: 2-1911               --                        --
│    └─Empty: 2-1912                     [5, 1024]                 --
│    └─Empty: 2-1913                     [5, 1024]                 --
│    └─Empty: 2-1914                     [16, 5]                   --
│    └─Empty: 2-1915                     [16, 5]                   --
│    └─Clamp: 2-1916                     [16, 5]                   --
├─Linear: 1-194                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1917        --                        --
│    └─One: 2-1918                       [1]                       --
│    └─OutputScale: 2-1919               --                        --
│    └─Empty: 2-1920                     [5, 1024]                 --
│    └─Empty: 2-1921                     [5, 1024]                 --
│    └─Empty: 2-1922                     [16, 5]                   --
│    └─Empty: 2-1923                     [16, 5]                   --
│    └─Clamp: 2-1924                     [16, 5]                   --
├─Linear: 1-195                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1925        --                        --
│    └─One: 2-1926                       [1]                       --
│    └─OutputScale: 2-1927               --                        --
│    └─Empty: 2-1928                     [5, 1024]                 --
│    └─Empty: 2-1929                     [5, 1024]                 --
│    └─Empty: 2-1930                     [16, 5]                   --
│    └─Empty: 2-1931                     [16, 5]                   --
│    └─Clamp: 2-1932                     [16, 5]                   --
├─Linear: 1-196                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1933        --                        --
│    └─One: 2-1934                       [1]                       --
│    └─OutputScale: 2-1935               --                        --
│    └─Empty: 2-1936                     [5, 1024]                 --
│    └─Empty: 2-1937                     [5, 1024]                 --
│    └─Empty: 2-1938                     [16, 5]                   --
│    └─Empty: 2-1939                     [16, 5]                   --
│    └─Clamp: 2-1940                     [16, 5]                   --
├─Linear: 1-197                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-1941        --                        --
│    └─One: 2-1942                       [1]                       --
│    └─OutputScale: 2-1943               --                        --
│    └─Empty: 2-1944                     [5, 1024]                 --
│    └─Empty: 2-1945                     [5, 1024]                 --
│    └─Empty: 2-1946                     [16, 5]                   --
│    └─Empty: 2-1947                     [16, 5]                   --
│    └─Clamp: 2-1948                     [16, 5]                   --
==========================================================================================
Total params: 640,150
Trainable params: 640,096
Non-trainable params: 54
Total mult-adds (M): 0.37
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 30.67
Params size (MB): 2.54
Estimated Total Size (MB): 234.54
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.482 | Acc: 24.000% | Wgt Acc: 30.425%
	I - Batch: 100 | Loss: 1.426 | Acc: 27.625% | Wgt Acc: 35.399%
	I - Batch: 150 | Loss: 1.362 | Acc: 31.125% | Wgt Acc: 39.843%
	I - Batch: 200 | Loss: 1.322 | Acc: 32.656% | Wgt Acc: 41.656%
I - num batch: 222
I - Train -- Loss: 1.312 | Acc: 33.183% | Wgt Acc: 42.298% | LR: 1.000000e-03 | Dur: 132.69s
I - Confusion Matrix: [row->prediction - col->label]
[[378.  51. 105. 210. 222.]
 [ 34. 196. 138.  39. 202.]
 [125. 270. 410.  99. 477.]
 [160.  61.  80. 190.  96.]
 [  0.   0.   1.   0.   3.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.541 | Acc: 33.531% | Wgt Acc: 45.877% | Dur: 14.00s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  6.  7. 37. 33.]
 [ 7. 34. 16. 10. 49.]
 [10. 37. 49. 13. 91.]
 [11.  1.  3. 26.  6.]
 [ 0.  0.  0.  0.  1.]]

I - Local maximum validation set accuracy:  33.53

I - Validation set results: 
[14-1-2-1.14][50-3-1-0.76][124-2-2-0.75][127-0-0-2.74][443-2-2-1.68][567-0-0-1.05][573-1-1-1.32][615-0-0-0.88][695-1-2-0.14][722-3-3-1.73]
[826-0-0-2.28][878-0-0-1.84][1103-0-2-0.31][1212-3-2-0.06][1368-0-0-1.10][2181-2-3-0.10][2476-2-2-0.76][2721-2-2-1.03][2818-1-2-0.23][2886-2-2-1.38]
[3231-2-2-1.86][3333-2-2-0.44][3482-2-2-1.26][3536-3-1-0.07][3625-1-1-1.50][3909-0-2-0.07][4035-0-3-1.40][4140-0-0-0.50][4214-1-0-1.10][4346-1-0-0.49]
[4581-2-2-1.47][4708-3-2-0.71][4838-3-1-0.36][4845-1-2-1.35][4868-0-0-1.96][4939-0-2-1.14][4984-2-0-0.46][5078-1-1-1.18][5396-0-0-4.00][5479-1-1-1.23]
[5717-0-1--0.13][5843-1-1-1.89][5949-3-0-1.71][5987-2-1-0.91][6014-3-3--0.14][6033-3-0-1.40][6313-0-0-0.89][6421-3-3-0.74][6500-1-1-0.88][6583-3-3-0.23]
[6683-3-2-0.15][6825-2-3-0.61][6998-3-2-1.60][7049-3-2--0.02][7517-1-1-1.91][7521-1-1-0.65][7528-1-2-0.13][7949-1-2-1.49][8135-1-0-0.23][8185-3-0-2.12]
[8269-3-2-0.32][8273-3-0-1.60][8543-3-0-1.51][8666-1-3-0.17][8672-0-0-3.35][8903-1-2-0.97][9001-2-1-1.69][9036-2-2-1.75][9281-3-1-0.56][9300-2-2-0.90]
[9571-0-0-0.12][9617-1-1-0.72][9644-2-2-1.62][9705-2-1-0.52][9801-0-3-1.25][9803-3-3-0.49][9865-3-0-2.39][9896-2-2-1.25][10314-1-2-1.04][10337-3-3-2.06]
[10403-0-2-1.29][10653-2-1-1.08][10704-2-1-0.70][10719-1-1-1.44][10727-1-2-1.00][10836-0-0-2.93][10969-2-1-0.01][11042-0-0-1.18][11088-1-2-1.79][11322-0-0-2.78]
[11398-2-2-2.49][11499-0-0--0.21][11502-3-0-0.08][11512-3-1-1.23][11608-1-1-2.34][11610-0-3-1.58][11692-0-0-1.43][11905-0-0-2.80][11993-1-2-1.66][12002-2-3-0.56]
[12052-0-0-1.42][12201-0-0-1.92][12235-2-2-1.48][12320-1-0-0.34][12377-2-2-0.67][12398-2-0-0.20][12503-1-2-1.22][12617-0-1-1.61][12685-3-3--0.13][12738-2-2-0.62]
[12742-2-2-2.42][12823-0-3-1.70][13110-1-2-1.46][13240-3-0-0.78][13253-1-1-1.24][13273-0-0-4.04][13634-1-1-0.83][13763-2-2-0.53][13905-3-0-1.58][14060-2-1-1.54]
[14065-3-0-2.21][14147-3-3-0.49][14595-2-2-1.53][14687-2-2-1.31][14788-2-2-1.62][14869-1-1-1.25][14872-3-0-0.98][14877-1-2-1.10][14927-0-3-1.39][15066-0-0-3.04]
[15175-1-2-0.79][15178-2-0-0.04][15375-3-0-0.13][15389-3-0-1.21][15568-2-1-0.88][15675-3-0-0.14][15869-1-2-1.62][16207-3-0-0.26][16236-0-0-0.17][16302-3-0-1.19]
[16331-2-2-2.65][16381-0-0-1.26][16488-1-1-1.65][16495-0-0-0.54][16650-0-0-2.80][16719-1-1-0.10][16801-0-0-2.77][16828-0-0-1.38][17137-3-0-0.59][17245-1-2-1.01]
[17278-3-3-0.16][17282-0-1-0.80][17311-2-2-2.01][17336-2-2-1.40][17608-3-3-1.94][17627-0-0--0.06][17877-3-2-1.61][17924-1-2-0.60][17984-3-0-2.47][18211-0-1-0.39]
[18276-3-0-2.24][18287-1-1-0.95][18394-0-0-2.48][18428-0-0-1.10][18442-0-3-1.14][18478-3-0-1.56][18607-0-2-0.56][18616-0-3-0.13][18663-0-3-0.26][18718-0-0-2.45]
[18766-2-2-1.32][18824-2-2-1.28][18890-3-2-0.92][18930-3-2-0.73][18938-3-0-0.95][19817-1-2-1.58][19839-0-2-0.26][19930-3-1-0.08][19944-0-2-0.43][20036-2-2-1.27]
[20101-3-1-0.57][20474-1-2-1.61][20547-3-0-0.73][20929-2-2-1.87][21245-1-1-1.33][21257-3-1-0.20][21293-1-1-2.04][21316-1-1-1.38][21384-1-1-1.06][21448-1-2-1.39]
[21483-0-0-1.42][21487-2-2-1.21][21714-0-0-0.48][21943-3-2-1.45][21947-0-0-0.75][21948-0-0-1.76][21965-2-1-0.82][21998-1-2-1.06][22025-0-3-0.25][22228-3-0-1.00]
[22446-1-1-1.79][22494-3-0-0.98][22757-0-0-2.40][22811-3-3-1.85][22976-3-2-1.20][22985-3-0-1.38][23014-0-0-1.38][23112-1-2-1.39][23144-3-0-2.27][23168-2-0-1.07]
[23219-0-0-0.03][23363-3-3-0.71][23470-0-2-0.53][23486-2-2-0.51][23497-0-0-3.29][23516-0-0-3.23][23690-1-1-0.51][23921-2-2-1.59][23936-1-2-1.25][24040-3-0-0.12]
[24111-1-1-0.78][24182-0-0-3.17][24238-3-3-1.62][24290-2-0-1.14][24345-0-0-0.27][24364-1-2-0.75][24427-3-3-0.22][24477-2-2-1.67][24495-2-1-1.37][24893-2-2-1.66]
[25012-1-2-0.20][25121-2-2-0.57][25165-3-0-0.51][25183-0-0-1.00][25297-3-3-0.52][25398-0-0-0.38][25574-2-2-1.01][25644-1-2-1.08][25718-1-1-0.90][25774-2-2-0.40]
[26032-3-3-1.78][26051-3-0-2.08][26120-0-0-0.44][26321-1-2-0.10][26732-1-1-0.82][26784-3-3-2.38][26827-3-3-0.55][26833-0-3-1.86][26838-2-2-0.03][26860-1-2-0.43]
[26948-0-0-0.97][27049-3-0-1.25][27098-1-2-0.94][27526-0-0-1.39][27639-3-3-0.75][27698-3-3-1.05][27772-0-0-3.33][27890-1-1-1.20][28040-0-2-0.13][28503-2-2-2.62]
[28577-1-1-1.07][28959-0-0-4.13][29198-3-1-1.04][29777-0-0-4.07][29877-2-2-0.92][30035-1-2-1.24][30098-0-0-2.19][30326-1-1-1.48][30572-2-2-0.72][30716-0-1-0.12]
[30806-2-1-0.10][30906-1-1-0.92][31007-0-0-0.55][31181-3-3-0.59][31238-0-0-0.43][31347-0-3-1.77][31422-2-1-1.10][31429-3-0-0.34][31431-0-0-1.69][31432-1-1-0.60]
[31477-0-0-2.98][31524-1-0-0.25][31597-1-2-2.10][31619-1-2-0.23][31701-0-0-1.07][31755-0-0-0.70][31854-3-3-0.62][32074-1-2-0.93][32078-3-3-0.89][32111-1-1-1.10]
[32127-1-2-2.49][32140-3-0-0.86][32263-2-2-0.23][32365-0-0-0.22][32411-2-0-3.17][32429-3-0-2.94][32473-3-0-0.88][32574-3-0-3.03][32584-0-2-0.16][32622-0-1-0.88]
[32858-3-0-0.61][32969-3-0-2.43][33016-2-2-1.51][33031-1-0--0.01][33035-2-2-2.04][33133-2-2-0.70][33173-2-1-1.03][33175-3-2-1.69][33306-3-1-0.73][33309-2-1-0.45]
[33474-0-1--0.10][33478-2-0-0.21][33618-1-1-0.95][33712-0-0-0.99][33782-2-2-1.78][33914-3-3-0.68][34076-3-2-0.25][34112-2-1-0.72][34138-2-2-0.82][34239-1-2-1.22]
[34364-2-1-1.55][34617-1-1-1.17][34751-3-3-1.48][34783-2-2-0.96][35015-3-3-0.23][35018-1-2-1.19][35288-2-2-0.58][0-4-2-0.73][1-4-0-0.79][2-4-0-0.13]
[3-4-1-0.07][4-4-3-0.10][5-4-1-1.16][6-4-1--0.01][7-4-1-0.43][8-4-2-0.63][9-4-1-1.00][10-4-1-0.21][11-4-2-1.69][12-4-1-0.57]
[14-4-0-0.13][15-4-0-1.43][16-4-2--0.10][17-4-1-0.47][18-4-1-0.96][19-4-0-1.92][20-4-0-0.31][21-4-2-1.35][22-4-2-0.80][23-4-1-0.65]
[24-4-2-0.17][25-4-2-0.14][26-4-1-0.37][27-4-0-0.73][28-4-2-0.46][29-4-2-1.84][30-4-0-0.48][31-4-2-0.68][32-4-2-1.67][33-4-2-0.55]
[34-4-2-0.44][35-4-0-2.58][37-4-2-0.72][39-4-0-2.99][40-4-2-0.45][41-4-2-1.49][42-4-1-1.47][43-4-2-1.94][45-4-2-0.94][46-4-2-1.18]
[47-4-2-0.60][48-4-2-0.70][51-4-2-0.63][52-4-2-0.95][53-4-2-0.99][54-4-0-0.10][55-4-0-0.49][56-4-1-1.10][57-4-0-2.24][58-4-2-1.69]
[59-4-0-0.34][60-4-1-0.72][61-4-1-1.05][62-4-2-0.39][63-4-2-1.43][64-4-1-0.45][65-4-2-0.81][66-4-1-1.96][67-4-2-0.24][68-4-1-1.41]
[69-4-2-0.34][70-4-2-0.88][72-4-2-1.28][73-4-1-1.05][74-4-2-1.33][75-4-0-0.10][77-4-1-0.99][78-4-2-1.41][79-4-2-1.09][80-4-1-1.52]
[81-4-2-1.64][82-4-2-0.56][83-4-1-0.95][84-4-2-1.05][85-4-1-0.87][86-4-1-0.75][87-4-2-0.70][88-4-0-0.03][89-4-2-0.83][90-4-2-0.11]
[91-4-2-0.56][92-4-1-0.17][93-4-2-0.31][94-4-2-0.56][95-4-2-0.33][96-4-1-0.37][97-4-2-1.23][98-4-2-1.81][99-4-2-0.21][100-4-2-1.32]
[101-4-2-0.88][102-4-2-1.58][103-4-3-0.55][104-4-2-1.12][105-4-2-0.83][106-4-1-1.25][107-4-0-0.03][108-4-2-1.93][109-4-1-0.94][110-4-1-0.73]
[111-4-0-2.68][112-4-2-0.46][113-4-1-0.78][114-4-0-0.34][115-4-0-0.16][116-4-2-1.09][117-4-1-0.80][119-4-2-1.80][121-4-2-0.98][122-4-3-0.41]
[124-4-2-1.20][125-4-2-0.85][126-4-1-0.04][127-4-2-0.84][128-4-0--0.06][129-4-1-0.96][130-4-2-0.38][131-4-2-0.64][132-4-2-0.12][133-4-0-3.94]
[135-4-2-1.41][136-4-1-0.63][137-4-1-0.41][138-4-0-0.47][139-4-0-0.40][140-4-2-0.66][141-4-3-1.02][142-4-2-0.36][143-4-2-0.61][144-4-1-0.52]
[145-4-2-0.83][148-4-0-1.38][149-4-2-1.19][150-4-1-1.21][151-4-2-1.30][152-4-1-1.10][153-4-1-0.88][154-4-1-1.15][155-4-1-0.21][156-4-0-0.24]
[157-4-0-1.44][158-4-2-0.16][160-4-1-0.87][161-4-1-0.32][162-4-2-0.98][164-4-2-1.47][165-4-1-0.34][167-4-0-0.50][168-4-2-0.31][170-4-3-1.04]
[171-4-1-0.64][172-4-2-0.89][173-4-0-0.03][174-4-0-1.07][175-4-1-0.81][177-4-0-1.98][178-4-2-0.90][179-4-1-0.84][180-4-4-0.37][181-4-3-0.67]
[182-4-2-0.70][183-4-2-0.33][184-4-2-0.74][186-4-0-0.42][187-4-1-1.63][188-4-2-0.91][189-4-2-0.55][190-4-1-0.82][191-4-2-1.29][192-4-2-0.99]
[193-4-2-2.30][194-4-0-0.67][195-4-2-0.78][196-4-2-0.31][197-4-2-1.19][198-4-2-0.53][199-4-2-0.30]
---------------------------
I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.094 | Acc: 45.250% | Wgt Acc: 58.208%
	I - Batch: 100 | Loss: 1.109 | Acc: 44.312% | Wgt Acc: 55.763%
	I - Batch: 150 | Loss: 1.113 | Acc: 44.500% | Wgt Acc: 55.677%
	I - Batch: 200 | Loss: 1.104 | Acc: 45.156% | Wgt Acc: 56.046%
I - num batch: 222
I - Train -- Loss: 1.102 | Acc: 45.137% | Wgt Acc: 55.958% | LR: 1.000000e-03 | Dur: 134.57s
I - Confusion Matrix: [row->prediction - col->label]
[[475.  29.  33. 166. 169.]
 [ 37. 319. 134.  46. 235.]
 [ 53. 190. 496.  77. 443.]
 [128.  33.  63. 248.  90.]
 [  4.   7.   8.   1.  63.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.478 | Acc: 38.462% | Wgt Acc: 51.863% | Dur: 14.02s
I - Confusion Matrix: [row->prediction - col->label]
[[58. 10. 10. 28. 34.]
 [ 3. 44. 17.  4. 68.]
 [ 2. 22. 39.  7. 45.]
 [24.  1.  9. 47. 26.]
 [ 1.  1.  0.  0.  7.]]

I - Local maximum validation set accuracy:  38.46

I - Validation set results: 
[14-1-2-0.46][50-3-1-0.32][124-2-2-0.39][127-0-0-3.39][443-2-2-0.34][567-0-0-1.89][573-1-1-0.35][615-0-0-1.36][695-1-0-0.83][722-3-0-2.37]
[826-0-3-1.91][878-0-0-2.01][1103-0-4--0.03][1212-3-3-0.78][1368-0-0-2.65][2181-2-3--0.00][2476-2-1-0.04][2721-2-2-0.48][2818-1-1-0.42][2886-2-1-1.19]
[3231-2-2-1.87][3333-2-3-0.95][3482-2-2-1.35][3536-3-3-1.15][3625-1-1-1.99][3909-0-0-0.74][4035-0-0-1.28][4140-0-0-2.31][4214-1-1-0.22][4346-1-0-0.66]
[4581-2-2-0.99][4708-3-3-1.12][4838-3-0--0.09][4845-1-2-0.74][4868-0-0-3.16][4939-0-0--0.06][4984-2-3-0.46][5078-1-1-0.31][5396-0-0-4.29][5479-1-1-1.08]
[5717-0-0-2.12][5843-1-1-1.30][5949-3-3-1.37][5987-2-1-1.29][6014-3-3-0.36][6033-3-0-2.15][6313-0-0-1.64][6421-3-3-1.44][6500-1-1-0.06][6583-3-3-0.64]
[6683-3-3-0.09][6825-2-0-1.12][6998-3-2-0.18][7049-3-3-0.95][7517-1-1-1.39][7521-1-1-0.44][7528-1-3-0.69][7949-1-2-1.15][8135-1-0-1.35][8185-3-0-2.27]
[8269-3-2-1.11][8273-3-3-0.63][8543-3-0-2.94][8666-1-1-0.11][8672-0-0-3.38][8903-1-0-0.05][9001-2-1-2.03][9036-2-2-1.11][9281-3-3-0.17][9300-2-2-0.44]
[9571-0-3-0.74][9617-1-1-0.39][9644-2-2-1.37][9705-2-0-0.13][9801-0-3-1.75][9803-3-3-0.88][9865-3-0-2.29][9896-2-2-0.40][10314-1-1-0.65][10337-3-3-2.36]
[10403-0-2-0.16][10653-2-1-0.97][10704-2-1-0.48][10719-1-1-1.34][10727-1-1-0.63][10836-0-0-3.35][10969-2-3-0.02][11042-0-0-1.67][11088-1-2-1.29][11322-0-0-2.44]
[11398-2-2-1.51][11499-0-3-0.66][11502-3-3-1.35][11512-3-3-0.40][11608-1-1-2.29][11610-0-0-0.90][11692-0-0-1.82][11905-0-3-2.65][11993-1-2-1.00][12002-2-0-2.69]
[12052-0-0-2.34][12201-0-3-1.90][12235-2-2-1.19][12320-1-0-0.54][12377-2-1-0.69][12398-2-2-0.25][12503-1-1-1.48][12617-0-1-1.60][12685-3-3-0.20][12738-2-0-0.13]
[12742-2-2-1.20][12823-0-3-1.64][13110-1-2-0.69][13240-3-3-1.11][13253-1-1-1.06][13273-0-0-3.75][13634-1-2-1.00][13763-2-3-0.71][13905-3-0-1.83][14060-2-1-1.23]
[14065-3-0-1.76][14147-3-3-0.78][14595-2-2-0.36][14687-2-2-0.99][14788-2-2-0.81][14869-1-1-0.90][14872-3-0-1.44][14877-1-2-0.88][14927-0-3-2.27][15066-0-0-3.94]
[15175-1-2-0.61][15178-2-0-0.44][15375-3-3-0.38][15389-3-3-1.93][15568-2-1-0.47][15675-3-3-0.82][15869-1-2-1.47][16207-3-0-0.32][16236-0-3-0.45][16302-3-0-0.36]
[16331-2-2-1.24][16381-0-0-1.48][16488-1-1-1.51][16495-0-0-1.20][16650-0-0-2.76][16719-1-1-0.60][16801-0-0-3.87][16828-0-0-2.27][17137-3-0-1.16][17245-1-2--0.13]
[17278-3-3-0.05][17282-0-2-0.17][17311-2-2-0.97][17336-2-1-0.76][17608-3-3-2.35][17627-0-3-1.02][17877-3-1-0.37][17924-1-0-0.09][17984-3-0-3.67][18211-0-3-1.19]
[18276-3-0-2.14][18287-1-1-0.02][18394-0-0-3.09][18428-0-0-2.25][18442-0-3-1.38][18478-3-0-1.81][18607-0-1-0.28][18616-0-3-0.82][18663-0-3-0.19][18718-0-0-2.90]
[18766-2-2-1.20][18824-2-2-0.55][18890-3-2-0.90][18930-3-2-0.35][18938-3-3-1.34][19817-1-2-1.27][19839-0-0-0.23][19930-3-3-1.32][19944-0-0-1.51][20036-2-2-1.80]
[20101-3-0-0.73][20474-1-2-1.27][20547-3-0-0.92][20929-2-2-1.94][21245-1-2-0.69][21257-3-0-0.36][21293-1-1-1.92][21316-1-1-0.93][21384-1-1-0.96][21448-1-1-1.09]
[21483-0-0-2.65][21487-2-2-0.85][21714-0-0-0.56][21943-3-2-1.02][21947-0-0-2.72][21948-0-0-3.23][21965-2-2-1.36][21998-1-1-0.18][22025-0-3-1.12][22228-3-3-1.38]
[22446-1-1-2.19][22494-3-0-1.39][22757-0-0-2.33][22811-3-3-1.84][22976-3-1-1.31][22985-3-3-1.98][23014-0-3-1.76][23112-1-1-1.49][23144-3-3-2.10][23168-2-0--0.06]
[23219-0-0-1.34][23363-3-3-1.75][23470-0-0-0.06][23486-2-3-0.55][23497-0-3-2.91][23516-0-0-3.88][23690-1-1-1.14][23921-2-2-0.76][23936-1-2-0.11][24040-3-0-0.44]
[24111-1-4-1.14][24182-0-3-2.52][24238-3-3-1.94][24290-2-0-1.90][24345-0-0-2.15][24364-1-2-0.59][24427-3-3-1.41][24477-2-2-0.94][24495-2-1-0.58][24893-2-2-1.11]
[25012-1-2-0.02][25121-2-2-0.70][25165-3-3-0.98][25183-0-0-0.67][25297-3-3-1.55][25398-0-0-1.71][25574-2-2-0.87][25644-1-1-1.65][25718-1-1-0.54][25774-2-1-0.53]
[26032-3-3-1.24][26051-3-3-2.07][26120-0-0-0.98][26321-1-1-0.38][26732-1-1-0.33][26784-3-3-3.16][26827-3-3-1.75][26833-0-3-2.10][26838-2-3--0.12][26860-1-0-0.22]
[26948-0-0-1.89][27049-3-0-2.12][27098-1-0-0.38][27526-0-0-1.32][27639-3-3-1.79][27698-3-3-1.19][27772-0-0-3.25][27890-1-1-0.99][28040-0-0-1.06][28503-2-2-1.05]
[28577-1-1-1.23][28959-0-0-4.50][29198-3-1-0.54][29777-0-0-3.94][29877-2-2-0.68][30035-1-2-1.13][30098-0-0-1.89][30326-1-1-1.27][30572-2-2-0.66][30716-0-0-0.41]
[30806-2-3-0.24][30906-1-1-1.18][31007-0-0-1.27][31181-3-3-0.88][31238-0-3-0.58][31347-0-3-2.05][31422-2-2-0.20][31429-3-0-1.13][31431-0-0-0.74][31432-1-1-1.09]
[31477-0-0-2.63][31524-1-0-0.54][31597-1-2-1.49][31619-1-0-0.59][31701-0-0-1.80][31755-0-0-1.43][31854-3-0-1.31][32074-1-1-0.00][32078-3-3-1.16][32111-1-1-0.58]
[32127-1-2-1.41][32140-3-3-1.59][32263-2-0-0.27][32365-0-0-1.26][32411-2-0-3.00][32429-3-0-3.76][32473-3-0-0.77][32574-3-0-2.63][32584-0-3--0.01][32622-0-1-0.42]
[32858-3-0-1.61][32969-3-0-2.45][33016-2-2-1.91][33031-1-1-0.39][33035-2-2-1.51][33133-2-2-0.67][33173-2-1-0.96][33175-3-2-0.62][33306-3-2-0.41][33309-2-1-0.17]
[33474-0-3-0.11][33478-2-0-0.41][33618-1-1-1.07][33712-0-3-1.28][33782-2-1-1.08][33914-3-3-0.63][34076-3-3-0.39][34112-2-1-0.65][34138-2-3-0.53][34239-1-2-0.32]
[34364-2-2-1.08][34617-1-2-0.83][34751-3-3-2.43][34783-2-1-0.90][35015-3-3-0.48][35018-1-1-1.22][35288-2-2-0.15][0-4-2-0.50][1-4-3-0.75][2-4-0-0.27]
[3-4-2-0.64][4-4-3-0.47][5-4-1-0.95][6-4-3-1.09][7-4-2-0.20][8-4-0-0.06][9-4-0--0.16][10-4-4-0.42][11-4-2-1.38][12-4-1-0.67]
[14-4-0-0.25][15-4-3-2.29][16-4-1-0.05][17-4-1-0.88][18-4-2-0.17][19-4-3-1.88][20-4-0-0.23][21-4-2-1.20][22-4-4-0.94][23-4-1-0.45]
[24-4-4-0.84][25-4-3-0.61][26-4-1-0.39][27-4-0-1.69][28-4-1-1.32][29-4-1-0.24][30-4-0-1.32][31-4-2-0.93][32-4-1-1.09][33-4-3-0.53]
[34-4-2-0.03][35-4-0-0.81][37-4-2-0.39][39-4-0-2.37][40-4-0-0.80][41-4-2-0.11][42-4-2-0.97][43-4-2-0.37][45-4-2-0.89][46-4-2-0.93]
[47-4-4-0.68][48-4-0-0.22][51-4-1-0.93][52-4-2-0.19][53-4-1-0.98][54-4-1-0.09][55-4-2-0.88][56-4-1-1.32][57-4-3-1.70][58-4-2-1.72]
[59-4-0-0.28][60-4-1-0.29][61-4-1-0.75][62-4-2-0.34][63-4-2-1.21][64-4-1-0.47][65-4-1-1.42][66-4-1-1.97][67-4-3-0.61][68-4-2-0.81]
[69-4-0-1.88][70-4-1-0.34][72-4-1-0.90][73-4-1-1.28][74-4-2-0.25][75-4-0-0.82][77-4-1-1.07][78-4-2-0.33][79-4-1-1.16][80-4-1-1.45]
[81-4-1-0.78][82-4-0-0.15][83-4-1-0.48][84-4-0-0.82][85-4-1-0.65][86-4-0-0.11][87-4-1-1.16][88-4-0-0.27][89-4-3-0.04][90-4-1--0.17]
[91-4-2-0.37][92-4-1-0.06][93-4-0-0.77][94-4-1-0.64][95-4-2--0.05][96-4-1-1.19][97-4-1-1.24][98-4-2-0.48][99-4-1-0.60][100-4-1-0.65]
[101-4-3-0.47][102-4-2-0.03][103-4-3-0.94][104-4-2-0.52][105-4-1-1.41][106-4-1-1.55][107-4-1-0.34][108-4-0-0.01][109-4-3--0.02][110-4-1-0.61]
[111-4-3-2.16][112-4-0-1.18][113-4-3-0.75][114-4-2-0.22][115-4-0-0.45][116-4-1-0.50][117-4-1-1.38][119-4-2-1.66][121-4-1-0.87][122-4-3-0.82]
[124-4-3-0.12][125-4-1-1.48][126-4-1-0.15][127-4-1-0.65][128-4-0-0.43][129-4-0--0.24][130-4-1-0.67][131-4-2-1.15][132-4-1-1.23][133-4-3-1.28]
[135-4-2-0.89][136-4-1-0.49][137-4-1-0.51][138-4-2-0.21][139-4-3-1.27][140-4-3-0.19][141-4-3-1.41][142-4-1-0.66][143-4-1-0.88][144-4-4-1.04]
[145-4-1-1.12][148-4-0-2.12][149-4-2-0.56][150-4-2-0.92][151-4-1-1.12][152-4-1-0.95][153-4-1-1.58][154-4-2-0.81][155-4-1-0.30][156-4-0-0.97]
[157-4-0-0.49][158-4-3-0.58][160-4-1-0.75][161-4-2-0.22][162-4-2-0.07][164-4-2-0.22][165-4-1-0.03][167-4-0-1.53][168-4-1-0.36][170-4-3-1.64]
[171-4-1-0.13][172-4-1-0.92][173-4-0-0.72][174-4-0-1.27][175-4-1-0.41][177-4-3-1.72][178-4-1-1.33][179-4-1-0.12][180-4-4-0.71][181-4-3-0.75]
[182-4-2-0.73][183-4-1-0.61][184-4-2-0.54][186-4-2-0.08][187-4-1-1.22][188-4-2-0.26][189-4-0-0.19][190-4-1-0.44][191-4-3-0.20][192-4-0-0.32]
[193-4-2-2.07][194-4-0--0.06][195-4-0-2.01][196-4-2-0.43][197-4-1-1.61][198-4-4-1.08][199-4-2-0.13]
---------------------------
I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.998 | Acc: 48.375% | Wgt Acc: 60.101%
	I - Batch: 100 | Loss: 1.028 | Acc: 47.938% | Wgt Acc: 58.302%
	I - Batch: 150 | Loss: 1.017 | Acc: 49.083% | Wgt Acc: 59.451%
	I - Batch: 200 | Loss: 1.023 | Acc: 49.312% | Wgt Acc: 59.441%
I - num batch: 222
I - Train -- Loss: 1.026 | Acc: 49.253% | Wgt Acc: 59.457% | LR: 1.000000e-03 | Dur: 133.53s
I - Confusion Matrix: [row->prediction - col->label]
[[491.  32.  29. 147. 191.]
 [ 26. 330. 127.  39. 212.]
 [ 50. 177. 518.  68. 364.]
 [129.  34.  48. 281. 106.]
 [  1.   5.  12.   3. 127.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.337 | Acc: 43.787% | Wgt Acc: 47.261% | Dur: 14.27s
I - Confusion Matrix: [row->prediction - col->label]
[[48.  5.  2. 17. 20.]
 [ 7. 44. 23. 15. 38.]
 [ 8. 20. 36. 20. 49.]
 [19.  0.  4. 32. 11.]
 [ 6.  9. 10.  2. 62.]]

I - Local maximum validation set accuracy:  43.79

I - Validation set results: 
[14-1-1-0.85][50-3-1-0.60][124-2-2-2.18][127-0-0-2.19][443-2-2-1.02][567-0-0-0.10][573-1-1-1.27][615-0-0-0.36][695-1-1-0.73][722-3-3-1.72]
[826-0-0-0.39][878-0-0-1.12][1103-0-0-0.23][1212-3-2-1.77][1368-0-0-2.52][2181-2-3-0.07][2476-2-1-0.55][2721-2-2-0.82][2818-1-0-0.39][2886-2-4-0.75]
[3231-2-2-1.99][3333-2-1-1.04][3482-2-2-2.13][3536-3-1-0.08][3625-1-1-1.35][3909-0-0-1.03][4035-0-3-0.95][4140-0-0-0.92][4214-1-2-1.04][4346-1-0-0.58]
[4581-2-2-0.72][4708-3-2-0.65][4838-3-0--0.05][4845-1-1-1.14][4868-0-0-1.68][4939-0-4-0.26][4984-2-2-1.86][5078-1-1-0.84][5396-0-0-1.83][5479-1-1-1.98]
[5717-0-0-1.23][5843-1-1-1.37][5949-3-3-0.85][5987-2-4-1.32][6014-3-1-1.13][6033-3-0--0.04][6313-0-0-0.77][6421-3-2-0.92][6500-1-1-1.08][6583-3-2--0.21]
[6683-3-1-0.13][6825-2-1-0.58][6998-3-1-0.45][7049-3-2-0.89][7517-1-1-1.26][7521-1-1--0.07][7528-1-2-0.04][7949-1-2-1.01][8135-1-0-0.56][8185-3-3-0.28]
[8269-3-2-0.62][8273-3-0-1.33][8543-3-0-1.67][8666-1-1-1.18][8672-0-3-1.05][8903-1-2-1.35][9001-2-1-1.06][9036-2-2-1.32][9281-3-1-0.14][9300-2-4-0.74]
[9571-0-1--0.08][9617-1-1-0.76][9644-2-2-1.35][9705-2-3--0.16][9801-0-3-0.78][9803-3-3-0.37][9865-3-3-1.22][9896-2-4-0.87][10314-1-4-0.47][10337-3-3-1.52]
[10403-0-4-0.34][10653-2-1-0.73][10704-2-1-0.69][10719-1-1-1.04][10727-1-4-0.50][10836-0-0-3.57][10969-2-2-0.46][11042-0-0-0.21][11088-1-1-2.41][11322-0-0-2.18]
[11398-2-2-0.71][11499-0-0-0.64][11502-3-2-0.11][11512-3-2-1.16][11608-1-1-1.41][11610-0-0-1.80][11692-0-3-0.54][11905-0-3-1.19][11993-1-2-0.77][12002-2-3-0.20]
[12052-0-0-2.35][12201-0-3-0.46][12235-2-1-0.73][12320-1-2-0.18][12377-2-4-0.76][12398-2-2-0.70][12503-1-4-1.62][12617-0-1-0.73][12685-3-1-1.00][12738-2-2-0.16]
[12742-2-2-1.65][12823-0-3-1.48][13110-1-1-1.10][13240-3-0-0.19][13253-1-4-0.97][13273-0-0-2.10][13634-1-1-0.73][13763-2-1-0.35][13905-3-4--0.13][14060-2-1-1.71]
[14065-3-3-1.28][14147-3-3--0.46][14595-2-2-0.87][14687-2-2-2.90][14788-2-2-1.90][14869-1-1-1.45][14872-3-0-0.57][14877-1-1-1.01][14927-0-3-1.49][15066-0-0-1.73]
[15175-1-1-0.39][15178-2-2-0.60][15375-3-1--0.06][15389-3-3-0.26][15568-2-1-0.55][15675-3-1-0.69][15869-1-2-1.41][16207-3-2-0.22][16236-0-2-0.71][16302-3-2-0.38]
[16331-2-2-2.14][16381-0-2-0.01][16488-1-1-1.79][16495-0-0-1.02][16650-0-0-1.54][16719-1-4-0.01][16801-0-0-2.98][16828-0-0-1.87][17137-3-0-0.37][17245-1-1-1.84]
[17278-3-0-0.31][17282-0-1-0.06][17311-2-2-2.36][17336-2-1-1.08][17608-3-3-1.44][17627-0-1-0.67][17877-3-1-0.86][17924-1-1-0.84][17984-3-0-2.03][18211-0-3-0.35]
[18276-3-0-0.55][18287-1-0-0.00][18394-0-0-1.01][18428-0-0-1.08][18442-0-3-1.07][18478-3-3-0.13][18607-0-0-1.06][18616-0-0-0.29][18663-0-2--0.06][18718-0-0-1.45]
[18766-2-2-2.00][18824-2-4-0.71][18890-3-2-0.32][18930-3-2-0.59][18938-3-3-0.03][19817-1-2-0.99][19839-0-4-0.61][19930-3-1-0.70][19944-0-4-1.23][20036-2-2-1.30]
[20101-3-3-0.13][20474-1-1-1.71][20547-3-0-0.74][20929-2-2-1.74][21245-1-1-1.20][21257-3-0-0.29][21293-1-1-2.58][21316-1-1-2.26][21384-1-1-0.92][21448-1-1-1.25]
[21483-0-0-1.10][21487-2-2-1.30][21714-0-2-0.17][21943-3-2-1.42][21947-0-0-0.47][21948-0-0-2.25][21965-2-2-1.36][21998-1-1-0.77][22025-0-2-0.23][22228-3-3-0.42]
[22446-1-1-2.20][22494-3-3-1.60][22757-0-3-1.83][22811-3-3-1.95][22976-3-2-1.02][22985-3-3-0.52][23014-0-3-1.18][23112-1-1-0.96][23144-3-3-0.80][23168-2-0-0.40]
[23219-0-2-0.16][23363-3-3-1.37][23470-0-1-0.26][23486-2-2-1.11][23497-0-3-2.79][23516-0-0-2.32][23690-1-4-1.88][23921-2-2-1.64][23936-1-2-1.34][24040-3-0-0.14]
[24111-1-4-1.33][24182-0-0-2.46][24238-3-3-1.25][24290-2-0-0.67][24345-0-0-1.15][24364-1-1-1.34][24427-3-3-0.79][24477-2-2-1.06][24495-2-1-0.53][24893-2-1-0.94]
[25012-1-2-0.22][25121-2-4-1.07][25165-3-3-0.18][25183-0-0-1.75][25297-3-1-0.26][25398-0-0-0.51][25574-2-1-1.02][25644-1-1-1.29][25718-1-1-0.43][25774-2-2-1.00]
[26032-3-3-0.95][26051-3-3-1.42][26120-0-0-1.41][26321-1-1-1.13][26732-1-2-0.82][26784-3-3-2.13][26827-3-2-0.23][26833-0-3-1.79][26838-2-1-0.58][26860-1-2-0.71]
[26948-0-0-0.26][27049-3-0-0.96][27098-1-0-0.15][27526-0-0-0.66][27639-3-3-0.14][27698-3-3-0.98][27772-0-3-2.35][27890-1-1-0.72][28040-0-1-0.21][28503-2-2-2.07]
[28577-1-1-1.48][28959-0-0-3.13][29198-3-1-0.60][29777-0-0-3.03][29877-2-1-1.17][30035-1-2-0.87][30098-0-0-0.63][30326-1-1-1.75][30572-2-2-1.36][30716-0-4-1.25]
[30806-2-1-0.70][30906-1-4-1.12][31007-0-0-0.49][31181-3-3-0.30][31238-0-3-0.33][31347-0-0-0.99][31422-2-1-0.57][31429-3-1-0.84][31431-0-3-0.33][31432-1-1-1.83]
[31477-0-3-1.49][31524-1-2-1.26][31597-1-2-2.40][31619-1-2-0.50][31701-0-2-0.03][31755-0-4-0.03][31854-3-1-0.38][32074-1-2-0.93][32078-3-3-0.39][32111-1-4-0.97]
[32127-1-2-2.18][32140-3-2-0.13][32263-2-4-0.55][32365-0-0-1.57][32411-2-3-1.46][32429-3-0-2.62][32473-3-0-0.50][32574-3-3-1.66][32584-0-2--0.18][32622-0-1-1.17]
[32858-3-0-0.67][32969-3-3-0.37][33016-2-4-0.99][33031-1-1-0.18][33035-2-2-2.66][33133-2-2-1.61][33173-2-1-0.58][33175-3-4-1.56][33306-3-2-1.18][33309-2-1-0.04]
[33474-0-3-0.27][33478-2-1-0.51][33618-1-1-1.09][33712-0-0-0.11][33782-2-4-1.46][33914-3-2-0.98][34076-3-2-0.56][34112-2-1-0.67][34138-2-1-0.41][34239-1-1-0.74]
[34364-2-2-1.82][34617-1-2-1.16][34751-3-3-0.75][34783-2-2-0.86][35015-3-2-1.42][35018-1-2-0.98][35288-2-2-1.01][0-4-2-0.42][1-4-4-0.41][2-4-4-0.06]
[3-4-4-0.79][4-4-2--0.17][5-4-1-0.23][6-4-0-1.63][7-4-1-0.16][8-4-4-0.02][9-4-1-1.35][10-4-3-0.14][11-4-2-2.40][12-4-1-0.61]
[14-4-0-0.99][15-4-3-0.47][16-4-0-0.74][17-4-1-0.30][18-4-2-0.79][19-4-3-1.36][20-4-0-0.03][21-4-2-0.92][22-4-4-0.63][23-4-1-1.03]
[24-4-4-0.45][25-4-2-1.11][26-4-1-0.32][27-4-2-0.07][28-4-4-0.79][29-4-2-1.00][30-4-0-0.22][31-4-2-1.68][32-4-4-1.36][33-4-2-2.01]
[34-4-2-0.55][35-4-3-0.85][37-4-2-1.08][39-4-3-1.47][40-4-2-0.44][41-4-2-1.02][42-4-2-0.72][43-4-1-0.26][45-4-2-0.02][46-4-2-1.67]
[47-4-4-1.47][48-4-4-0.76][51-4-4-1.40][52-4-4-0.39][53-4-1-1.05][54-4-0-0.04][55-4-2-0.25][56-4-1-0.89][57-4-3-0.40][58-4-2-1.66]
[59-4-0-0.57][60-4-1-0.27][61-4-4-0.74][62-4-2-0.61][63-4-2-1.69][64-4-1-0.19][65-4-4-1.27][66-4-4-1.92][67-4-1-0.42][68-4-1-2.18]
[69-4-2-0.33][70-4-4-0.96][72-4-4-0.73][73-4-1-0.65][74-4-2-1.17][75-4-2--0.17][77-4-4-1.69][78-4-1-1.04][79-4-4-1.05][80-4-1-1.21]
[81-4-4-1.49][82-4-1-0.21][83-4-1-1.45][84-4-4-0.97][85-4-4-1.72][86-4-0-0.39][87-4-4-1.39][88-4-4-0.84][89-4-2-1.04][90-4-0--0.16]
[91-4-2-1.06][92-4-3-0.22][93-4-0-1.65][94-4-4-1.11][95-4-2-0.31][96-4-4-0.65][97-4-4-1.20][98-4-1-1.26][99-4-4-1.11][100-4-4-0.51]
[101-4-4-1.83][102-4-2-0.65][103-4-1-0.94][104-4-4-0.93][105-4-4-1.38][106-4-4-0.63][107-4-1-0.59][108-4-4-0.41][109-4-1-0.87][110-4-4-0.61]
[111-4-3-2.12][112-4-0-0.56][113-4-2-0.33][114-4-2-0.86][115-4-1--0.09][116-4-4-0.48][117-4-4-0.91][119-4-2-2.02][121-4-1-0.98][122-4-4--0.03]
[124-4-2-1.29][125-4-4-1.19][126-4-0-0.08][127-4-2-0.61][128-4-2--0.05][129-4-2-0.38][130-4-4-0.54][131-4-2-2.16][132-4-2-0.69][133-4-0-2.18]
[135-4-2-1.25][136-4-1-0.50][137-4-1-0.34][138-4-2-1.02][139-4-2-1.19][140-4-1-0.40][141-4-3-0.52][142-4-4-1.64][143-4-4-0.73][144-4-4-1.22]
[145-4-4-1.47][148-4-0-2.94][149-4-4-0.71][150-4-1-1.12][151-4-4-1.09][152-4-1-0.61][153-4-2-1.41][154-4-4-1.36][155-4-4-0.50][156-4-0-0.39]
[157-4-0--0.08][158-4-2-0.58][160-4-4-0.49][161-4-2--0.01][162-4-4-0.50][164-4-2-0.71][165-4-4-0.80][167-4-0-0.28][168-4-4-0.81][170-4-3-0.06]
[171-4-1-0.74][172-4-4-1.32][173-4-4-0.23][174-4-0-1.05][175-4-4-0.43][177-4-3-0.31][178-4-4-1.48][179-4-1-0.53][180-4-4-1.12][181-4-2-0.55]
[182-4-2-0.62][183-4-1-0.63][184-4-2-1.15][186-4-0--0.04][187-4-1-1.33][188-4-4-0.85][189-4-4-0.82][190-4-1-0.65][191-4-2-0.65][192-4-4-0.34]
[193-4-1-2.12][194-4-1-0.09][195-4-0-0.95][196-4-1-1.41][197-4-4-1.16][198-4-4-1.55][199-4-2-0.71]
---------------------------
I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.944 | Acc: 54.125% | Wgt Acc: 62.168%
	I - Batch: 100 | Loss: 0.960 | Acc: 52.875% | Wgt Acc: 61.036%
	I - Batch: 150 | Loss: 0.988 | Acc: 51.458% | Wgt Acc: 59.950%
	I - Batch: 200 | Loss: 0.983 | Acc: 51.594% | Wgt Acc: 59.994%
I - num batch: 222
I - Train -- Loss: 0.977 | Acc: 51.959% | Wgt Acc: 60.353% | LR: 1.000000e-03 | Dur: 132.87s
I - Confusion Matrix: [row->prediction - col->label]
[[493.  22.  31. 153. 195.]
 [ 31. 342. 122.  40. 158.]
 [ 38. 169. 508.  58. 339.]
 [123.  32.  48. 282.  90.]
 [ 12.  13.  25.   5. 218.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.284 | Acc: 50.296% | Wgt Acc: 57.294% | Dur: 14.16s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  7.  5. 22. 29.]
 [ 3. 39.  9.  5. 24.]
 [ 2. 22. 53. 13. 55.]
 [20.  2.  4. 45. 15.]
 [ 2.  8.  4.  1. 57.]]

I - Local maximum validation set accuracy:  50.30

I - Validation set results: 
[14-1-2-0.52][50-3-0--0.03][124-2-2-2.41][127-0-0-3.06][443-2-2-0.72][567-0-0-2.30][573-1-2-0.86][615-0-0-1.48][695-1-2-0.27][722-3-0-1.69]
[826-0-0-1.24][878-0-0-1.82][1103-0-0-0.53][1212-3-2-0.79][1368-0-0-3.47][2181-2-2--0.01][2476-2-2--0.21][2721-2-2-1.44][2818-1-0-0.32][2886-2-1-1.01]
[3231-2-2-2.38][3333-2-3-0.84][3482-2-2-1.50][3536-3-3-0.82][3625-1-1-1.50][3909-0-0-0.79][4035-0-3-1.08][4140-0-0-1.36][4214-1-2-0.62][4346-1-0-0.65]
[4581-2-2-1.34][4708-3-2-0.21][4838-3-0-0.58][4845-1-2-1.03][4868-0-0-2.48][4939-0-4-0.76][4984-2-2-1.08][5078-1-1-0.37][5396-0-0-3.42][5479-1-1-1.60]
[5717-0-0-1.78][5843-1-1-1.83][5949-3-3-1.33][5987-2-4-1.00][6014-3-3-0.68][6033-3-0-1.42][6313-0-0-2.26][6421-3-3-1.74][6500-1-1-0.03][6583-3-2-0.52]
[6683-3-3-0.26][6825-2-3-0.85][6998-3-1--0.10][7049-3-3-0.76][7517-1-2-1.83][7521-1-1-1.23][7528-1-3-0.54][7949-1-4-0.82][8135-1-0-2.21][8185-3-3-1.50]
[8269-3-2-0.54][8273-3-3-0.72][8543-3-0-3.08][8666-1-1-1.25][8672-0-0-2.85][8903-1-1-1.34][9001-2-2-1.07][9036-2-2-1.43][9281-3-3--0.16][9300-2-4-0.36]
[9571-0-0-0.58][9617-1-1-0.38][9644-2-2-0.78][9705-2-1-0.44][9801-0-3-0.93][9803-3-3-1.23][9865-3-3-1.76][9896-2-2-1.34][10314-1-4-0.67][10337-3-3-2.25]
[10403-0-0-0.57][10653-2-1-0.78][10704-2-2-0.16][10719-1-1-1.64][10727-1-1-0.56][10836-0-0-3.64][10969-2-2-0.19][11042-0-0-1.56][11088-1-1-2.03][11322-0-0-3.21]
[11398-2-2-2.77][11499-0-0-0.76][11502-3-3-1.16][11512-3-1-0.47][11608-1-1-1.87][11610-0-0-1.20][11692-0-3-1.19][11905-0-0-2.20][11993-1-2-0.83][12002-2-3-0.12]
[12052-0-0-2.34][12201-0-3-1.88][12235-2-2-1.08][12320-1-4-0.49][12377-2-4-0.60][12398-2-2-0.25][12503-1-4-1.48][12617-0-1-1.01][12685-3-2-0.03][12738-2-2-0.38]
[12742-2-2-2.52][12823-0-3-1.60][13110-1-1-0.39][13240-3-3-0.60][13253-1-1-1.13][13273-0-0-3.52][13634-1-1-0.94][13763-2-3-0.61][13905-3-3-0.39][14060-2-1-1.17]
[14065-3-3-0.78][14147-3-3-0.17][14595-2-2-1.26][14687-2-2-1.68][14788-2-2-0.68][14869-1-2-1.23][14872-3-0-0.62][14877-1-1-1.18][14927-0-3-1.72][15066-0-0-3.71]
[15175-1-2-0.68][15178-2-0-0.60][15375-3-3-1.58][15389-3-3-2.00][15568-2-1-1.13][15675-3-3-1.17][15869-1-2-0.31][16207-3-3-0.25][16236-0-3-0.25][16302-3-0-0.30]
[16331-2-2-2.17][16381-0-0-2.04][16488-1-1-2.79][16495-0-0-1.31][16650-0-0-2.90][16719-1-2--0.11][16801-0-0-3.57][16828-0-0-1.57][17137-3-0-1.05][17245-1-1-0.69]
[17278-3-0--0.28][17282-0-0-0.05][17311-2-2-1.95][17336-2-2-0.76][17608-3-3-2.45][17627-0-0-0.91][17877-3-1-0.44][17924-1-1-1.06][17984-3-0-2.30][18211-0-3-1.13]
[18276-3-0-2.14][18287-1-1-0.73][18394-0-0-2.39][18428-0-1-0.03][18442-0-3-1.31][18478-3-3-1.66][18607-0-0-1.06][18616-0-0-0.72][18663-0-3-0.64][18718-0-0-2.75]
[18766-2-2-1.48][18824-2-2-0.65][18890-3-2-0.36][18930-3-4-0.20][18938-3-3-0.84][19817-1-2-1.09][19839-0-2-0.24][19930-3-3-0.75][19944-0-2-0.76][20036-2-2-2.10]
[20101-3-0-0.41][20474-1-1-1.71][20547-3-0-1.76][20929-2-2-1.46][21245-1-2-1.39][21257-3-3-0.20][21293-1-1-2.31][21316-1-1-2.13][21384-1-1-1.30][21448-1-1-0.93]
[21483-0-0-2.07][21487-2-2-2.12][21714-0-0-0.16][21943-3-2-1.08][21947-0-0-2.56][21948-0-0-3.48][21965-2-2-1.95][21998-1-1-1.25][22025-0-3-0.39][22228-3-3-1.78]
[22446-1-1-1.48][22494-3-3-1.37][22757-0-3-1.99][22811-3-3-1.37][22976-3-1-0.74][22985-3-3-1.57][23014-0-3-2.02][23112-1-1-1.17][23144-3-3-1.82][23168-2-0-1.13]
[23219-0-3-0.42][23363-3-3-1.82][23470-0-0-0.62][23486-2-2-1.04][23497-0-3-2.29][23516-0-0-3.08][23690-1-4-1.11][23921-2-2-1.65][23936-1-2-0.38][24040-3-2-0.08]
[24111-1-4-1.83][24182-0-0-2.64][24238-3-3-1.38][24290-2-0-1.63][24345-0-0-2.49][24364-1-2-1.58][24427-3-0-1.10][24477-2-2-2.60][24495-2-1-0.24][24893-2-2-0.88]
[25012-1-0--0.12][25121-2-4-1.30][25165-3-3-1.13][25183-0-0-1.40][25297-3-3-1.21][25398-0-0-1.01][25574-2-2-1.13][25644-1-1-2.05][25718-1-1--0.18][25774-2-2-0.47]
[26032-3-3-1.29][26051-3-3-1.55][26120-0-0-2.66][26321-1-1-0.74][26732-1-0--0.21][26784-3-3-2.66][26827-3-3-1.31][26833-0-3-1.68][26838-2-2--0.06][26860-1-2-0.64]
[26948-0-0-1.21][27049-3-0-1.91][27098-1-0-0.09][27526-0-0-2.54][27639-3-3-0.89][27698-3-3-0.99][27772-0-0-2.41][27890-1-1-0.92][28040-0-0-1.45][28503-2-2-2.79]
[28577-1-1-1.30][28959-0-0-4.33][29198-3-1-0.49][29777-0-0-3.24][29877-2-1-0.66][30035-1-2-0.80][30098-0-0-1.92][30326-1-1-1.57][30572-2-2-1.66][30716-0-4-0.70]
[30806-2-2-0.21][30906-1-4-1.50][31007-0-0-1.43][31181-3-2-0.75][31238-0-3-0.70][31347-0-3-1.63][31422-2-2-0.40][31429-3-0-0.05][31431-0-0-0.58][31432-1-1-1.58]
[31477-0-3-2.20][31524-1-2-0.41][31597-1-2-2.33][31619-1-2-0.34][31701-0-3-0.35][31755-0-0-0.85][31854-3-0-1.36][32074-1-0-0.46][32078-3-3-0.80][32111-1-4-0.84]
[32127-1-2-2.18][32140-3-3-1.92][32263-2-0-0.45][32365-0-0-2.61][32411-2-0-2.02][32429-3-0-2.76][32473-3-0-0.48][32574-3-0-2.29][32584-0-0-0.56][32622-0-1-0.68]
[32858-3-0-0.39][32969-3-0-1.88][33016-2-2-1.82][33031-1-3-0.86][33035-2-2-2.15][33133-2-2-1.10][33173-2-1-0.81][33175-3-2-1.27][33306-3-2-0.78][33309-2-2--0.14]
[33474-0-0-0.25][33478-2-2--0.34][33618-1-1-1.15][33712-0-0-1.67][33782-2-2-2.26][33914-3-3-1.57][34076-3-2-1.23][34112-2-2-0.60][34138-2-2-1.01][34239-1-1-0.81]
[34364-2-2-2.65][34617-1-2-0.70][34751-3-3-2.08][34783-2-1-1.33][35015-3-2-0.72][35018-1-1-0.98][35288-2-2-0.28][0-4-3-0.33][1-4-4-0.94][2-4-0-0.65]
[3-4-4-0.24][4-4-2-0.45][5-4-1-0.48][6-4-4-1.44][7-4-4-0.82][8-4-2-0.72][9-4-2-0.86][10-4-4-1.80][11-4-2-3.32][12-4-2-0.49]
[14-4-0-0.57][15-4-3-1.97][16-4-4-0.37][17-4-2--0.08][18-4-4-0.99][19-4-3-1.29][20-4-0-0.83][21-4-2-1.16][22-4-4-1.44][23-4-1-0.29]
[24-4-4-1.25][25-4-2-0.32][26-4-3--0.14][27-4-0-0.21][28-4-4-1.10][29-4-1-1.01][30-4-0-0.57][31-4-2-1.74][32-4-4-1.00][33-4-3-0.48]
[34-4-2-0.60][35-4-3-0.71][37-4-2-0.81][39-4-3-1.50][40-4-0-0.38][41-4-1--0.09][42-4-2-1.14][43-4-2-1.36][45-4-2-1.24][46-4-4-1.01]
[47-4-4-1.29][48-4-4-0.54][51-4-4-1.05][52-4-1-0.44][53-4-2-0.42][54-4-0-0.04][55-4-2-0.55][56-4-1-0.58][57-4-3-0.77][58-4-2-2.16]
[59-4-0-1.47][60-4-1--0.02][61-4-4-1.55][62-4-2-0.93][63-4-2-2.14][64-4-0-0.04][65-4-4-1.59][66-4-4-1.46][67-4-1-0.02][68-4-1-0.90]
[69-4-0-0.24][70-4-4-0.54][72-4-4-0.88][73-4-2-0.46][74-4-2-1.75][75-4-0-0.66][77-4-4-1.76][78-4-2-0.59][79-4-2-0.83][80-4-4-1.02]
[81-4-4-1.51][82-4-4-0.52][83-4-1-1.31][84-4-0-0.15][85-4-4-1.25][86-4-4-0.29][87-4-4-1.03][88-4-4-0.57][89-4-2-1.03][90-4-4--0.04]
[91-4-2-0.51][92-4-2-0.25][93-4-4-0.63][94-4-4-0.96][95-4-3--0.17][96-4-2-0.04][97-4-4-0.87][98-4-2-0.85][99-4-4-0.46][100-4-1-0.65]
[101-4-4-1.56][102-4-2-0.96][103-4-3-0.76][104-4-4-0.70][105-4-4-2.22][106-4-2-0.53][107-4-1-0.53][108-4-2-1.25][109-4-0-0.28][110-4-4-0.19]
[111-4-0-2.15][112-4-0-1.01][113-4-2-0.48][114-4-3-0.49][115-4-4-0.05][116-4-0-0.68][117-4-1-1.01][119-4-2-2.29][121-4-1-0.63][122-4-4-0.12]
[124-4-2-0.27][125-4-1-1.35][126-4-4-0.50][127-4-2-0.48][128-4-2--0.14][129-4-2-0.25][130-4-4-0.56][131-4-2-2.11][132-4-0-0.10][133-4-0-1.22]
[135-4-2-1.75][136-4-0-0.49][137-4-1-0.49][138-4-2-1.09][139-4-0-0.45][140-4-2-0.13][141-4-3-0.86][142-4-4-2.08][143-4-4-1.08][144-4-4-2.07]
[145-4-1-1.31][148-4-0-2.03][149-4-2-1.03][150-4-1-0.82][151-4-4-1.03][152-4-2--0.21][153-4-2-1.96][154-4-4-1.09][155-4-4-0.60][156-4-0-0.93]
[157-4-0-1.19][158-4-0--0.06][160-4-1-0.77][161-4-1-0.66][162-4-2-0.98][164-4-2-0.52][165-4-0-0.27][167-4-0-1.38][168-4-4-1.00][170-4-3-0.37]
[171-4-1-0.87][172-4-4-0.69][173-4-4-0.09][174-4-0-1.45][175-4-4-0.01][177-4-0-1.09][178-4-4-2.18][179-4-0-0.14][180-4-4-1.60][181-4-3-0.46]
[182-4-3-0.04][183-4-4-0.24][184-4-2-0.87][186-4-2--0.03][187-4-1-1.39][188-4-2-0.69][189-4-2-0.58][190-4-1-0.30][191-4-4-0.78][192-4-2-0.56]
[193-4-2-2.40][194-4-2-1.77][195-4-1-0.53][196-4-2-0.26][197-4-4-1.01][198-4-4-1.45][199-4-2-0.89]
---------------------------
I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.914 | Acc: 53.500% | Wgt Acc: 64.155%
	I - Batch: 100 | Loss: 0.913 | Acc: 53.938% | Wgt Acc: 63.621%
	I - Batch: 150 | Loss: 0.903 | Acc: 54.583% | Wgt Acc: 64.012%
	I - Batch: 200 | Loss: 0.903 | Acc: 54.781% | Wgt Acc: 64.403%
I - num batch: 222
I - Train -- Loss: 0.910 | Acc: 54.553% | Wgt Acc: 64.045% | LR: 1.000000e-03 | Dur: 135.53s
I - Confusion Matrix: [row->prediction - col->label]
[[517.  14.  29. 147. 205.]
 [ 27. 377. 100.  23. 140.]
 [ 26. 142. 532.  56. 334.]
 [115.  34.  47. 303. 115.]
 [ 12.  11.  26.   9. 206.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.270 | Acc: 47.535% | Wgt Acc: 58.182% | Dur: 16.49s
I - Confusion Matrix: [row->prediction - col->label]
[[55.  3.  3. 14. 23.]
 [ 2. 38.  9.  1. 18.]
 [ 3. 31. 56. 14. 88.]
 [25.  4.  5. 56. 15.]
 [ 3.  2.  2.  1. 36.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.805 | Acc: 58.625% | Wgt Acc: 70.831%
	I - Batch: 100 | Loss: 0.824 | Acc: 58.312% | Wgt Acc: 69.205%
	I - Batch: 150 | Loss: 0.844 | Acc: 57.083% | Wgt Acc: 67.634%
	I - Batch: 200 | Loss: 0.835 | Acc: 57.688% | Wgt Acc: 67.943%
I - num batch: 222
I - Train -- Loss: 0.833 | Acc: 57.852% | Wgt Acc: 67.885% | LR: 5.000000e-04 | Dur: 134.37s
I - Confusion Matrix: [row->prediction - col->label]
[[540.  20.  28. 112. 140.]
 [ 16. 407.  88.  31. 161.]
 [ 29. 116. 544.  55. 374.]
 [102.  27.  44. 339. 103.]
 [ 10.   8.  30.   1. 222.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.219 | Acc: 50.099% | Wgt Acc: 55.495% | Dur: 14.10s
I - Confusion Matrix: [row->prediction - col->label]
[[48.  1.  2. 10. 11.]
 [ 8. 44. 16. 10. 34.]
 [ 5. 23. 49. 15. 55.]
 [19.  1.  3. 48. 15.]
 [ 8.  9.  5.  3. 65.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.788 | Acc: 60.125% | Wgt Acc: 70.103%
	I - Batch: 100 | Loss: 0.783 | Acc: 60.500% | Wgt Acc: 70.299%
	I - Batch: 150 | Loss: 0.777 | Acc: 61.167% | Wgt Acc: 71.161%
	I - Batch: 200 | Loss: 0.779 | Acc: 61.125% | Wgt Acc: 71.042%
I - num batch: 222
I - Train -- Loss: 0.781 | Acc: 60.840% | Wgt Acc: 71.008% | LR: 5.000000e-04 | Dur: 133.57s
I - Confusion Matrix: [row->prediction - col->label]
[[560.  14.  24. 105. 175.]
 [ 24. 426.  80.  28. 149.]
 [ 23. 112. 571.  43. 318.]
 [ 80.  18.  35. 354. 111.]
 [ 10.   8.  24.   8. 247.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.209 | Acc: 52.465% | Wgt Acc: 58.771% | Dur: 14.68s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  3.  3. 19. 21.]
 [ 2. 44. 15.  4. 25.]
 [ 4. 21. 47. 11. 57.]
 [17.  4.  5. 52. 12.]
 [ 7.  6.  5.  0. 65.]]

I - Local maximum validation set accuracy:  52.47

I - Validation set results: 
[14-1-2-1.45][50-3-3--0.08][124-2-2-1.66][127-0-0-3.85][443-2-2-1.83][567-0-0-1.18][573-1-1-0.26][615-0-0-1.01][695-1-1-0.35][722-3-0-3.42]
[826-0-0-1.66][878-0-3-1.80][1103-0-0-0.39][1212-3-2-0.65][1368-0-0-3.44][2181-2-2-0.01][2476-2-2--0.01][2721-2-2-1.71][2818-1-4-0.24][2886-2-1-1.87]
[3231-2-1-2.66][3333-2-1-0.54][3482-2-2-1.87][3536-3-3-0.33][3625-1-1-2.91][3909-0-0-2.10][4035-0-3-0.70][4140-0-0-1.03][4214-1-2-0.07][4346-1-0-0.42]
[4581-2-2-2.22][4708-3-2-1.52][4838-3-3-0.61][4845-1-2-0.30][4868-0-0-2.82][4939-0-4-0.28][4984-2-2-2.30][5078-1-4-0.62][5396-0-0-3.53][5479-1-1-2.37]
[5717-0-0-1.23][5843-1-1-1.60][5949-3-3-0.50][5987-2-4-1.26][6014-3-3-0.97][6033-3-0--0.24][6313-0-0-1.82][6421-3-3-1.62][6500-1-1-0.40][6583-3-2-1.19]
[6683-3-3-0.16][6825-2-3-0.98][6998-3-1--0.47][7049-3-3-1.00][7517-1-2-2.60][7521-1-1-1.17][7528-1-3-0.82][7949-1-2-1.26][8135-1-0-2.94][8185-3-0-2.11]
[8269-3-1-2.83][8273-3-3-0.84][8543-3-0-4.21][8666-1-1-1.36][8672-0-0-2.33][8903-1-2-1.64][9001-2-1-1.58][9036-2-2-3.22][9281-3-3-0.50][9300-2-2-2.57]
[9571-0-3-0.02][9617-1-1-0.65][9644-2-1-0.70][9705-2-1-1.16][9801-0-3-0.56][9803-3-3-1.71][9865-3-3-1.99][9896-2-2-1.81][10314-1-1-1.16][10337-3-3-3.44]
[10403-0-4-0.48][10653-2-1-1.05][10704-2-2-0.82][10719-1-1-3.10][10727-1-2-1.09][10836-0-0-5.12][10969-2-3-0.63][11042-0-0-0.85][11088-1-1-3.97][11322-0-0-4.37]
[11398-2-2-0.70][11499-0-0-0.85][11502-3-3-0.32][11512-3-3-0.49][11608-1-1-3.30][11610-0-0-1.18][11692-0-0-0.90][11905-0-0-1.34][11993-1-2-1.10][12002-2-2-0.65]
[12052-0-0-3.52][12201-0-3-2.23][12235-2-2-1.15][12320-1-4-0.34][12377-2-4-1.61][12398-2-2-0.32][12503-1-1-1.21][12617-0-2-0.85][12685-3-3-0.32][12738-2-2-0.46]
[12742-2-2-3.28][12823-0-0-1.82][13110-1-1-1.02][13240-3-3-0.76][13253-1-1-2.15][13273-0-0-4.47][13634-1-1-1.07][13763-2-3-0.28][13905-3-2--0.02][14060-2-1-1.20]
[14065-3-0-0.49][14147-3-3-0.47][14595-2-2-2.28][14687-2-2-3.36][14788-2-2-1.69][14869-1-1-3.04][14872-3-0-1.25][14877-1-1-2.32][14927-0-0-0.46][15066-0-0-4.73]
[15175-1-1-1.45][15178-2-3-0.17][15375-3-3-1.43][15389-3-3-0.81][15568-2-1-1.06][15675-3-3-1.93][15869-1-2-0.53][16207-3-3--0.09][16236-0-2--0.23][16302-3-2-0.33]
[16331-2-2-4.03][16381-0-0-1.75][16488-1-1-4.16][16495-0-0-2.35][16650-0-0-3.04][16719-1-2-0.76][16801-0-0-4.63][16828-0-0-3.41][17137-3-0-1.51][17245-1-2-0.83]
[17278-3-0--0.32][17282-0-2-0.29][17311-2-2-2.84][17336-2-1-1.85][17608-3-3-1.75][17627-0-1-1.34][17877-3-0-0.07][17924-1-1-1.86][17984-3-0-3.35][18211-0-3-1.96]
[18276-3-0-1.28][18287-1-1-0.39][18394-0-0-2.17][18428-0-0-2.75][18442-0-3-1.62][18478-3-3-1.58][18607-0-0-1.89][18616-0-0-0.50][18663-0-3-0.32][18718-0-0-2.44]
[18766-2-2-1.83][18824-2-4-0.65][18890-3-3-1.20][18930-3-2-0.77][18938-3-3-0.80][19817-1-2-1.88][19839-0-4-0.48][19930-3-3-0.56][19944-0-4-0.98][20036-2-2-2.89]
[20101-3-3-1.32][20474-1-1-2.23][20547-3-0-1.43][20929-2-2-2.70][21245-1-1-1.51][21257-3-1--0.18][21293-1-1-2.99][21316-1-1-3.99][21384-1-1-1.46][21448-1-2-1.16]
[21483-0-0-2.13][21487-2-2-2.57][21714-0-2--0.22][21943-3-2-0.16][21947-0-0-1.52][21948-0-0-5.13][21965-2-2-1.90][21998-1-1-1.36][22025-0-3-0.99][22228-3-3-3.01]
[22446-1-1-2.84][22494-3-3-1.32][22757-0-0-2.64][22811-3-3-1.78][22976-3-2-1.13][22985-3-3-2.29][23014-0-3-1.20][23112-1-1-1.31][23144-3-3-2.00][23168-2-0-0.25]
[23219-0-3-0.80][23363-3-3-1.94][23470-0-1-0.73][23486-2-2-0.65][23497-0-0-3.04][23516-0-0-3.21][23690-1-4-1.31][23921-2-2-1.66][23936-1-2-0.80][24040-3-1-0.07]
[24111-1-4-2.32][24182-0-0-3.37][24238-3-3-1.22][24290-2-0-2.35][24345-0-0-1.16][24364-1-1-0.84][24427-3-3-1.32][24477-2-2-2.64][24495-2-1-1.64][24893-2-2-1.88]
[25012-1-2-0.30][25121-2-4-1.58][25165-3-3-1.30][25183-0-0-2.60][25297-3-3-0.86][25398-0-0-1.48][25574-2-2-1.69][25644-1-1-2.56][25718-1-1-1.18][25774-2-2-0.47]
[26032-3-3-1.35][26051-3-0-1.74][26120-0-4-0.37][26321-1-1-2.14][26732-1-1-1.32][26784-3-3-2.16][26827-3-3-1.28][26833-0-3-1.93][26838-2-2-0.52][26860-1-2-0.79]
[26948-0-0-2.15][27049-3-0-1.79][27098-1-0-0.26][27526-0-0-0.97][27639-3-3-0.24][27698-3-3-1.27][27772-0-0-1.71][27890-1-1-0.77][28040-0-0-1.11][28503-2-2-3.86]
[28577-1-1-3.10][28959-0-0-4.55][29198-3-3-1.08][29777-0-0-4.54][29877-2-2-0.62][30035-1-2-1.52][30098-0-0-1.41][30326-1-1-2.62][30572-2-2-1.53][30716-0-4-1.56]
[30806-2-2-0.66][30906-1-4-1.48][31007-0-4-0.38][31181-3-3-1.13][31238-0-3-1.06][31347-0-0-1.25][31422-2-2-0.95][31429-3-3--0.04][31431-0-3-0.26][31432-1-1-2.49]
[31477-0-0-1.78][31524-1-2-0.59][31597-1-2-2.22][31619-1-2-0.26][31701-0-3-0.51][31755-0-0-0.41][31854-3-3-0.18][32074-1-3-0.75][32078-3-3-0.96][32111-1-1-2.45]
[32127-1-2-1.68][32140-3-3-1.78][32263-2-4-0.09][32365-0-0-2.37][32411-2-0-2.70][32429-3-0-3.06][32473-3-0-0.14][32574-3-0-2.84][32584-0-0-1.23][32622-0-3--0.33]
[32858-3-0-0.57][32969-3-0-1.59][33016-2-2-0.85][33031-1-3-1.43][33035-2-2-2.61][33133-2-2-1.69][33173-2-1-1.30][33175-3-2-1.29][33306-3-2-0.45][33309-2-3-0.68]
[33474-0-3-0.28][33478-2-1-0.25][33618-1-1-1.73][33712-0-0-1.73][33782-2-1-2.68][33914-3-3-1.25][34076-3-2-0.78][34112-2-2-2.64][34138-2-1-1.27][34239-1-1-1.99]
[34364-2-2-3.03][34617-1-3-0.13][34751-3-3-2.09][34783-2-2-1.34][35015-3-3-0.79][35018-1-1-1.26][35288-2-2-1.68][0-4-2-1.60][1-4-4-1.24][2-4-4-0.59]
[3-4-4-1.42][4-4-2-0.76][5-4-1-0.22][6-4-4-1.63][7-4-2-0.61][8-4-2-0.67][9-4-1-1.22][10-4-4-0.75][11-4-2-3.89][12-4-1-1.34]
[14-4-0-1.11][15-4-3-0.98][16-4-4-1.52][17-4-2--0.25][18-4-4-1.67][19-4-3-0.89][20-4-0-0.54][21-4-2-0.84][22-4-4-1.24][23-4-1-0.46]
[24-4-4-2.15][25-4-3-0.52][26-4-4--0.38][27-4-0-0.08][28-4-4-1.64][29-4-2-1.72][30-4-2-0.07][31-4-2-1.36][32-4-4-1.86][33-4-3-1.00]
[34-4-2-1.00][35-4-3-0.72][37-4-2-0.92][39-4-0-2.77][40-4-4-0.60][41-4-2--0.00][42-4-2-1.14][43-4-2-2.29][45-4-2--0.19][46-4-4-1.54]
[47-4-4-1.83][48-4-2-1.00][51-4-4-1.42][52-4-2-0.74][53-4-4-0.22][54-4-0-0.97][55-4-2-1.68][56-4-2-0.47][57-4-3-0.79][58-4-2-1.82]
[59-4-0-1.41][60-4-1--0.26][61-4-4-1.19][62-4-2-2.22][63-4-2-2.14][64-4-4-0.29][65-4-4-1.66][66-4-4-1.54][67-4-1-0.13][68-4-1-2.27]
[69-4-0-0.46][70-4-4-1.30][72-4-4-1.36][73-4-2-0.37][74-4-2-1.66][75-4-0-0.61][77-4-4-2.62][78-4-2-0.53][79-4-2-1.68][80-4-4-2.21]
[81-4-4-2.87][82-4-1-0.26][83-4-1-1.53][84-4-4-1.33][85-4-4-1.72][86-4-1-0.71][87-4-4-1.89][88-4-4-0.86][89-4-2-1.62][90-4-0--0.19]
[91-4-2-0.73][92-4-4--0.08][93-4-0-2.82][94-4-4-1.62][95-4-3-0.08][96-4-2-0.75][97-4-4-1.11][98-4-2-1.18][99-4-4-1.01][100-4-1-2.19]
[101-4-4-2.25][102-4-2-0.50][103-4-3-0.63][104-4-4-1.33][105-4-4-2.23][106-4-4-1.21][107-4-0-0.87][108-4-2-1.04][109-4-4-0.08][110-4-4-0.62]
[111-4-0-2.63][112-4-0-0.73][113-4-2-1.04][114-4-3-1.37][115-4-4-0.41][116-4-2-0.93][117-4-4-1.28][119-4-2-0.61][121-4-1-0.78][122-4-4-0.69]
[124-4-2-1.20][125-4-4-1.87][126-4-4-1.29][127-4-2-1.84][128-4-2--0.29][129-4-3--0.43][130-4-2-0.61][131-4-2-1.76][132-4-1-1.41][133-4-4-1.89]
[135-4-2-1.19][136-4-1-0.51][137-4-1--0.31][138-4-1-0.59][139-4-2-1.14][140-4-2-1.29][141-4-2-1.05][142-4-4-1.85][143-4-4-1.77][144-4-4-1.78]
[145-4-4-1.52][148-4-0-3.57][149-4-2-0.45][150-4-4-1.14][151-4-4-1.43][152-4-4-0.50][153-4-1-1.16][154-4-4-1.71][155-4-4-1.25][156-4-0-0.73]
[157-4-0-1.50][158-4-4-0.50][160-4-1-1.15][161-4-2-1.33][162-4-4-0.52][164-4-2-1.52][165-4-4-1.31][167-4-0-1.51][168-4-4-0.84][170-4-3-0.63]
[171-4-2-0.41][172-4-4-1.29][173-4-0-0.73][174-4-0-1.17][175-4-4-0.52][177-4-4-1.07][178-4-2-1.35][179-4-0-0.39][180-4-4-2.29][181-4-3-0.17]
[182-4-1-1.31][183-4-4-0.95][184-4-2-1.18][186-4-0-0.36][187-4-1-2.09][188-4-2-1.05][189-4-2-0.86][190-4-2-0.61][191-4-2-1.98][192-4-1-0.99]
[193-4-1-3.07][194-4-1-2.14][195-4-1-1.27][196-4-2-0.56][197-4-1-1.15][198-4-4-2.54][199-4-2-0.66]
---------------------------
I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.814 | Acc: 60.500% | Wgt Acc: 70.016%
	I - Batch: 100 | Loss: 0.778 | Acc: 60.000% | Wgt Acc: 70.267%
	I - Batch: 150 | Loss: 0.784 | Acc: 60.542% | Wgt Acc: 70.572%
	I - Batch: 200 | Loss: 0.772 | Acc: 60.656% | Wgt Acc: 70.713%
I - num batch: 222
I - Train -- Loss: 0.773 | Acc: 60.756% | Wgt Acc: 70.661% | LR: 5.000000e-04 | Dur: 135.22s
I - Confusion Matrix: [row->prediction - col->label]
[[538.  20.  26. 108. 180.]
 [ 18. 437.  73.  24. 152.]
 [ 29.  90. 563.  40. 297.]
 [ 97.  19.  49. 360. 114.]
 [ 15.  12.  23.   6. 257.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.243 | Acc: 52.465% | Wgt Acc: 60.708% | Dur: 15.96s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  7. 25. 35.]
 [ 2. 48. 16.  2. 32.]
 [ 1. 13. 37.  2. 37.]
 [ 9.  6. 10. 53. 20.]
 [ 4.  6.  5.  4. 56.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.740 | Acc: 63.000% | Wgt Acc: 72.202%
	I - Batch: 100 | Loss: 0.730 | Acc: 63.812% | Wgt Acc: 73.282%
	I - Batch: 150 | Loss: 0.726 | Acc: 63.000% | Wgt Acc: 72.894%
	I - Batch: 200 | Loss: 0.723 | Acc: 62.531% | Wgt Acc: 72.626%
I - num batch: 222
I - Train -- Loss: 0.723 | Acc: 62.701% | Wgt Acc: 72.754% | LR: 5.000000e-04 | Dur: 135.43s
I - Confusion Matrix: [row->prediction - col->label]
[[545.  13.  27. 101. 174.]
 [ 18. 453.  62.  22. 160.]
 [ 25.  87. 588.  37. 281.]
 [ 87.  15.  34. 367. 114.]
 [ 22.  10.  23.  11. 271.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.239 | Acc: 54.635% | Wgt Acc: 61.319% | Dur: 14.25s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  8.  6. 26. 30.]
 [ 1. 44. 13.  6. 16.]
 [ 2. 18. 48.  8. 54.]
 [ 9.  2.  3. 45. 14.]
 [ 2.  6.  5.  1. 66.]]

I - Local maximum validation set accuracy:  54.64

I - Validation set results: 
[14-1-2-2.10][50-3-3--0.33][124-2-2-1.13][127-0-0-4.43][443-2-2-2.36][567-0-0-1.80][573-1-1-0.90][615-0-0-1.44][695-1-1-0.57][722-3-0-2.70]
[826-0-0-4.03][878-0-0-3.04][1103-0-0-0.84][1212-3-3-0.34][1368-0-0-4.51][2181-2-2-0.09][2476-2-2-0.43][2721-2-2-1.37][2818-1-0-0.71][2886-2-1-1.36]
[3231-2-2-2.94][3333-2-1-2.00][3482-2-2-2.75][3536-3-3-0.99][3625-1-1-3.25][3909-0-0-3.60][4035-0-0-0.37][4140-0-0-1.97][4214-1-1-1.54][4346-1-0-1.52]
[4581-2-1-2.01][4708-3-2-0.65][4838-3-0-0.97][4845-1-2-0.48][4868-0-0-3.55][4939-0-0--0.49][4984-2-2-1.89][5078-1-4-0.45][5396-0-0-4.70][5479-1-1-2.61]
[5717-0-0-3.74][5843-1-2-1.39][5949-3-3-1.57][5987-2-4-1.63][6014-3-1-0.35][6033-3-2--0.43][6313-0-0-2.16][6421-3-3-1.99][6500-1-3-0.15][6583-3-2-1.13]
[6683-3-0-0.40][6825-2-1-0.36][6998-3-0-0.27][7049-3-3-0.87][7517-1-1-2.16][7521-1-1-1.65][7528-1-3-0.55][7949-1-2-2.01][8135-1-0-1.91][8185-3-0-2.29]
[8269-3-1-2.83][8273-3-3-1.09][8543-3-0-4.19][8666-1-1-1.87][8672-0-0-2.59][8903-1-2-1.76][9001-2-2-0.74][9036-2-2-3.76][9281-3-3-0.05][9300-2-2-2.93]
[9571-0-3-1.45][9617-1-1-0.24][9644-2-2-1.55][9705-2-0-0.27][9801-0-0-1.00][9803-3-3-0.91][9865-3-3-2.34][9896-2-2-2.31][10314-1-1-0.92][10337-3-3-2.53]
[10403-0-0-0.35][10653-2-4-0.55][10704-2-2-1.22][10719-1-1-2.01][10727-1-2-0.56][10836-0-0-6.86][10969-2-3-0.14][11042-0-0-1.29][11088-1-1-2.54][11322-0-0-4.32]
[11398-2-2-2.17][11499-0-0-2.22][11502-3-3-1.14][11512-3-3-0.95][11608-1-1-1.99][11610-0-0-3.82][11692-0-0-0.44][11905-0-3-2.01][11993-1-1-1.85][12002-2-3-2.83]
[12052-0-0-3.19][12201-0-3-2.52][12235-2-2-1.93][12320-1-4-0.38][12377-2-4-1.09][12398-2-2-0.91][12503-1-4-1.82][12617-0-2--0.06][12685-3-2-0.11][12738-2-2--0.36]
[12742-2-2-3.16][12823-0-0-1.62][13110-1-1-1.89][13240-3-0-1.23][13253-1-4-0.85][13273-0-0-5.20][13634-1-1-0.54][13763-2-2-0.73][13905-3-3--0.37][14060-2-1-1.75]
[14065-3-0-1.18][14147-3-0--0.43][14595-2-2-1.70][14687-2-2-3.18][14788-2-2-2.17][14869-1-1-1.67][14872-3-0-0.80][14877-1-1-1.04][14927-0-0-1.63][15066-0-0-4.20]
[15175-1-1-0.72][15178-2-0-0.44][15375-3-0-2.14][15389-3-3-2.52][15568-2-1-0.10][15675-3-3-1.12][15869-1-2-0.82][16207-3-0-0.99][16236-0-0--0.02][16302-3-0-0.58]
[16331-2-2-4.86][16381-0-0-2.78][16488-1-1-2.80][16495-0-0-2.89][16650-0-0-4.96][16719-1-2-2.09][16801-0-0-5.12][16828-0-0-2.51][17137-3-0-0.62][17245-1-1-0.92]
[17278-3-0-0.57][17282-0-0-0.88][17311-2-2-2.54][17336-2-1-1.53][17608-3-3-2.53][17627-0-1-0.19][17877-3-0-0.72][17924-1-1-0.98][17984-3-0-2.94][18211-0-3-1.86]
[18276-3-0-1.58][18287-1-0--0.06][18394-0-0-3.26][18428-0-0-0.94][18442-0-3-1.55][18478-3-3-1.63][18607-0-0-2.62][18616-0-0-1.14][18663-0-0-0.56][18718-0-0-3.15]
[18766-2-2-1.99][18824-2-2-1.35][18890-3-3-0.68][18930-3-4-0.33][18938-3-3-1.33][19817-1-2-1.38][19839-0-0-0.62][19930-3-3-0.96][19944-0-4-0.54][20036-2-2-3.78]
[20101-3-3-1.27][20474-1-1-3.96][20547-3-0-1.66][20929-2-2-3.90][21245-1-1-0.99][21257-3-1--0.62][21293-1-1-3.27][21316-1-1-2.95][21384-1-1-1.29][21448-1-2-1.01]
[21483-0-0-3.56][21487-2-2-1.90][21714-0-2--0.13][21943-3-2-0.90][21947-0-0-2.38][21948-0-0-6.03][21965-2-2-2.89][21998-1-2-0.73][22025-0-3--0.11][22228-3-3-2.51]
[22446-1-1-0.84][22494-3-0-1.86][22757-0-0-2.81][22811-3-3-2.25][22976-3-2-1.85][22985-3-3-3.05][23014-0-3-2.25][23112-1-1-1.88][23144-3-3-2.90][23168-2-0-0.39]
[23219-0-0-1.51][23363-3-3-1.73][23470-0-0-1.14][23486-2-2-0.25][23497-0-0-2.97][23516-0-0-4.52][23690-1-4-0.06][23921-2-1-0.61][23936-1-2-0.42][24040-3-0-0.23]
[24111-1-4-2.05][24182-0-0-4.07][24238-3-3-1.72][24290-2-0-2.13][24345-0-0-1.13][24364-1-2-2.15][24427-3-0-2.38][24477-2-2-3.04][24495-2-1-0.60][24893-2-2-2.36]
[25012-1-2-0.44][25121-2-4-1.27][25165-3-3-0.72][25183-0-0-2.96][25297-3-3-0.92][25398-0-0-2.37][25574-2-2-2.64][25644-1-1-2.67][25718-1-1-0.55][25774-2-2-1.17]
[26032-3-3-0.28][26051-3-3-2.11][26120-0-0-1.24][26321-1-1-3.03][26732-1-1-1.23][26784-3-3-3.16][26827-3-3-1.47][26833-0-3-2.70][26838-2-2-0.39][26860-1-2-0.26]
[26948-0-0-2.59][27049-3-0-2.34][27098-1-1-0.89][27526-0-0-2.93][27639-3-3-0.94][27698-3-3-1.43][27772-0-0-3.13][27890-1-1-0.62][28040-0-0-0.11][28503-2-2-3.78]
[28577-1-1-2.92][28959-0-0-4.82][29198-3-0-0.44][29777-0-0-4.67][29877-2-1-0.95][30035-1-1-1.91][30098-0-0-2.10][30326-1-1-2.31][30572-2-2-2.17][30716-0-4-1.13]
[30806-2-2-0.28][30906-1-1-1.89][31007-0-0-1.19][31181-3-3-0.64][31238-0-3-0.84][31347-0-0-2.70][31422-2-2-0.70][31429-3-1--0.42][31431-0-0-0.40][31432-1-1-1.76]
[31477-0-0-2.95][31524-1-0-0.03][31597-1-2-1.48][31619-1-0-0.52][31701-0-0-3.41][31755-0-0-1.59][31854-3-3-1.17][32074-1-0--0.53][32078-3-3-1.68][32111-1-1-2.48]
[32127-1-2-2.40][32140-3-3-2.34][32263-2-0-0.01][32365-0-0-3.61][32411-2-0-4.17][32429-3-0-1.96][32473-3-2-0.36][32574-3-3-3.08][32584-0-0-1.79][32622-0-0--0.06]
[32858-3-0-1.66][32969-3-3-1.65][33016-2-2-3.06][33031-1-0-1.52][33035-2-2-2.75][33133-2-2-1.94][33173-2-1-0.84][33175-3-1-0.70][33306-3-1--0.12][33309-2-3-0.02]
[33474-0-0-0.66][33478-2-1--0.52][33618-1-1-0.94][33712-0-0-1.23][33782-2-2-2.64][33914-3-3-2.03][34076-3-3-0.26][34112-2-2-2.48][34138-2-1-1.08][34239-1-1-1.14]
[34364-2-2-3.15][34617-1-2-0.24][34751-3-3-2.23][34783-2-4-0.82][35015-3-2-0.98][35018-1-1-1.65][35288-2-2-0.76][0-4-2-2.02][1-4-4-0.85][2-4-4-0.48]
[3-4-4-0.68][4-4-2-0.18][5-4-1-0.75][6-4-4-1.88][7-4-2-0.68][8-4-2-0.15][9-4-0-0.46][10-4-4-1.03][11-4-2-3.55][12-4-2-0.94]
[14-4-0-2.08][15-4-3-2.26][16-4-4-0.86][17-4-4-0.11][18-4-4-1.23][19-4-3-1.35][20-4-0-0.47][21-4-2-2.28][22-4-4-1.37][23-4-1-1.07]
[24-4-4-1.63][25-4-3-0.68][26-4-2--0.27][27-4-2-0.35][28-4-4-1.97][29-4-1-1.23][30-4-0-0.43][31-4-2-0.84][32-4-2-1.12][33-4-2-0.39]
[34-4-2-0.52][35-4-0-1.15][37-4-2-1.53][39-4-0-4.34][40-4-4-0.43][41-4-2-0.26][42-4-2-0.66][43-4-2-1.33][45-4-3-0.92][46-4-4-1.42]
[47-4-4-2.05][48-4-2-1.14][51-4-4-1.18][52-4-4-0.14][53-4-4-0.20][54-4-4--0.25][55-4-2-1.64][56-4-2-0.37][57-4-3-1.14][58-4-2-1.75]
[59-4-0-1.99][60-4-0-0.75][61-4-4-1.47][62-4-2-2.42][63-4-2-2.54][64-4-4--0.12][65-4-4-1.93][66-4-4-1.55][67-4-0-0.53][68-4-1-0.64]
[69-4-0-1.48][70-4-4-1.04][72-4-4-1.01][73-4-2-0.40][74-4-2-1.13][75-4-0-0.45][77-4-4-3.49][78-4-1-0.44][79-4-2-2.19][80-4-4-1.08]
[81-4-1-1.57][82-4-1-0.58][83-4-2-0.37][84-4-2-0.42][85-4-4-0.93][86-4-4-0.31][87-4-4-1.52][88-4-4-0.93][89-4-2-0.46][90-4-0-0.57]
[91-4-2-1.39][92-4-3-0.53][93-4-0-3.17][94-4-4-1.56][95-4-2--0.24][96-4-2-1.28][97-4-0-0.77][98-4-2-0.80][99-4-4-0.78][100-4-1-1.39]
[101-4-4-1.67][102-4-2-0.61][103-4-3-0.22][104-4-4-0.87][105-4-4-3.01][106-4-4-0.61][107-4-4-0.67][108-4-2-0.22][109-4-2-0.45][110-4-4-0.14]
[111-4-0-4.09][112-4-0-0.58][113-4-3-0.18][114-4-3-0.54][115-4-4-0.61][116-4-0-0.19][117-4-4-1.42][119-4-2-1.57][121-4-4-0.15][122-4-0-0.64]
[124-4-2-0.24][125-4-4-2.12][126-4-4-1.48][127-4-2-1.03][128-4-0-0.55][129-4-4--0.53][130-4-2-0.14][131-4-2-1.27][132-4-0--0.02][133-4-0-2.75]
[135-4-2-0.21][136-4-1-0.18][137-4-1-0.17][138-4-4-0.13][139-4-3--0.22][140-4-2-0.40][141-4-3-1.29][142-4-4-1.88][143-4-4-1.86][144-4-4-2.81]
[145-4-4-1.85][148-4-0-3.78][149-4-2--0.02][150-4-4-1.00][151-4-4-1.40][152-4-4-0.36][153-4-2-2.41][154-4-4-2.19][155-4-4-0.89][156-4-0-0.65]
[157-4-0-0.84][158-4-3-0.51][160-4-1-1.14][161-4-1-0.57][162-4-4-0.32][164-4-2-1.11][165-4-4--0.06][167-4-0-1.79][168-4-4-1.05][170-4-0-1.78]
[171-4-4--0.03][172-4-4-1.52][173-4-0-2.24][174-4-0-2.22][175-4-2-0.35][177-4-0-2.65][178-4-4-1.98][179-4-0-0.67][180-4-4-2.63][181-4-3-1.11]
[182-4-1-1.63][183-4-4-1.00][184-4-4-0.51][186-4-2-0.09][187-4-1-0.89][188-4-2-0.73][189-4-4-0.21][190-4-2--0.57][191-4-2-0.92][192-4-1--0.05]
[193-4-2-3.02][194-4-3-0.28][195-4-1-0.74][196-4-2-0.75][197-4-4-1.14][198-4-4-2.80][199-4-2-0.74]
---------------------------
I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.635 | Acc: 65.500% | Wgt Acc: 76.226%
	I - Batch: 100 | Loss: 0.649 | Acc: 65.938% | Wgt Acc: 76.047%
	I - Batch: 150 | Loss: 0.670 | Acc: 64.833% | Wgt Acc: 74.904%
	I - Batch: 200 | Loss: 0.680 | Acc: 64.469% | Wgt Acc: 74.534%
I - num batch: 222
I - Train -- Loss: 0.676 | Acc: 64.872% | Wgt Acc: 74.860% | LR: 5.000000e-04 | Dur: 135.01s
I - Confusion Matrix: [row->prediction - col->label]
[[561.  12.  17.  88. 182.]
 [ 19. 470.  54.  22. 128.]
 [ 16.  77. 599.  37. 266.]
 [ 85.   6.  38. 376. 129.]
 [ 16.  13.  26.  15. 295.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.289 | Acc: 47.337% | Wgt Acc: 57.375% | Dur: 18.15s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  7.  5. 22. 47.]
 [ 0. 39.  9.  0. 17.]
 [ 3. 16. 40.  1. 45.]
 [20. 11. 19. 59. 32.]
 [ 2.  5.  2.  4. 39.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.619 | Acc: 66.250% | Wgt Acc: 77.468%
	I - Batch: 100 | Loss: 0.614 | Acc: 67.688% | Wgt Acc: 78.558%
	I - Batch: 150 | Loss: 0.611 | Acc: 67.458% | Wgt Acc: 78.521%
	I - Batch: 200 | Loss: 0.607 | Acc: 67.938% | Wgt Acc: 78.892%
I - num batch: 222
I - Train -- Loss: 0.607 | Acc: 68.086% | Wgt Acc: 79.060% | LR: 2.500000e-04 | Dur: 137.07s
I - Confusion Matrix: [row->prediction - col->label]
[[583.  11.  24.  74. 172.]
 [ 12. 494.  37.  13. 133.]
 [ 19.  52. 630.  25. 281.]
 [ 68.  13.  28. 414. 120.]
 [ 15.   8.  15.  12. 294.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.158 | Acc: 57.199% | Wgt Acc: 63.626% | Dur: 14.28s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  4.  8. 20. 33.]
 [ 1. 45. 13.  1. 25.]
 [ 2. 13. 38.  2. 28.]
 [ 7.  9. 12. 58. 21.]
 [ 2.  7.  4.  5. 73.]]

I - Local maximum validation set accuracy:  57.20

I - Validation set results: 
[14-1-2-0.21][50-3-3-0.17][124-2-2-1.41][127-0-0-5.44][443-2-2-1.40][567-0-0-3.72][573-1-3-0.09][615-0-0-1.85][695-1-2-0.44][722-3-0-3.88]
[826-0-0-4.14][878-0-0-3.71][1103-0-0-2.25][1212-3-3-0.23][1368-0-0-4.88][2181-2-0-0.08][2476-2-3--0.08][2721-2-2-3.02][2818-1-3-0.04][2886-2-1-1.45]
[3231-2-1-2.99][3333-2-1-1.67][3482-2-2-1.67][3536-3-3-2.43][3625-1-1-4.20][3909-0-0-3.36][4035-0-0-1.77][4140-0-0-2.24][4214-1-1-1.62][4346-1-0-1.29]
[4581-2-2-2.09][4708-3-2-0.27][4838-3-0-1.22][4845-1-3-0.41][4868-0-0-3.77][4939-0-2--0.11][4984-2-2-1.59][5078-1-4-0.75][5396-0-0-5.79][5479-1-1-1.77]
[5717-0-0-3.40][5843-1-1-1.50][5949-3-3-1.96][5987-2-4-1.29][6014-3-3-1.33][6033-3-0--0.04][6313-0-0-2.82][6421-3-3-2.72][6500-1-3-0.85][6583-3-3-1.47]
[6683-3-3-1.14][6825-2-3-0.77][6998-3-3-0.01][7049-3-3-1.25][7517-1-1-1.87][7521-1-1-0.01][7528-1-3-0.92][7949-1-2-1.25][8135-1-0-1.62][8185-3-0-5.08]
[8269-3-1-2.78][8273-3-3-1.26][8543-3-0-5.50][8666-1-1-3.03][8672-0-0-5.74][8903-1-1-2.13][9001-2-2-2.24][9036-2-2-3.41][9281-3-3-0.06][9300-2-2-1.62]
[9571-0-0-1.55][9617-1-4--0.52][9644-2-1-0.98][9705-2-0-0.04][9801-0-0-1.35][9803-3-3-1.41][9865-3-3-3.15][9896-2-2-2.39][10314-1-2-1.28][10337-3-3-3.21]
[10403-0-0-1.08][10653-2-1-0.17][10704-2-1-0.75][10719-1-1-3.30][10727-1-2-0.57][10836-0-0-7.13][10969-2-3-1.28][11042-0-0-1.79][11088-1-1-4.53][11322-0-0-5.20]
[11398-2-2-1.27][11499-0-0-2.25][11502-3-0-0.66][11512-3-3-1.22][11608-1-2-1.63][11610-0-0-0.70][11692-0-0-2.57][11905-0-0-3.87][11993-1-1-1.93][12002-2-0-3.70]
[12052-0-0-4.29][12201-0-3-3.19][12235-2-1-1.53][12320-1-4-0.69][12377-2-4-1.02][12398-2-3--0.01][12503-1-4-1.76][12617-0-2-1.51][12685-3-3--0.31][12738-2-2-0.15]
[12742-2-2-3.05][12823-0-0-3.26][13110-1-1-1.93][13240-3-3-2.17][13253-1-1-1.27][13273-0-0-6.72][13634-1-1-1.20][13763-2-3-1.08][13905-3-3-0.80][14060-2-1-0.59]
[14065-3-0-2.44][14147-3-3-1.40][14595-2-2-2.00][14687-2-2-1.67][14788-2-3-1.13][14869-1-1-4.27][14872-3-0-1.16][14877-1-1-1.96][14927-0-0-1.28][15066-0-0-5.31]
[15175-1-1-1.45][15178-2-0-0.77][15375-3-3-0.63][15389-3-3-1.74][15568-2-4-0.29][15675-3-3-2.69][15869-1-3-0.03][16207-3-0-0.93][16236-0-0-0.27][16302-3-0-1.26]
[16331-2-2-4.08][16381-0-0-3.21][16488-1-1-2.65][16495-0-0-2.87][16650-0-0-5.17][16719-1-2-1.76][16801-0-0-5.46][16828-0-0-2.99][17137-3-3-0.74][17245-1-3--0.14]
[17278-3-0-1.17][17282-0-0-0.77][17311-2-2-1.39][17336-2-1-2.34][17608-3-3-2.42][17627-0-0-0.72][17877-3-4-1.23][17924-1-3-0.47][17984-3-0-4.28][18211-0-3-1.83]
[18276-3-0-2.45][18287-1-1-0.15][18394-0-0-4.30][18428-0-0-5.68][18442-0-3-1.55][18478-3-3-1.68][18607-0-0-2.00][18616-0-0-0.43][18663-0-0-1.30][18718-0-0-4.87]
[18766-2-2-1.94][18824-2-2-1.35][18890-3-3-1.33][18930-3-4-0.33][18938-3-3-2.48][19817-1-1-1.76][19839-0-0-0.36][19930-3-3-2.18][19944-0-4-0.59][20036-2-2-3.26]
[20101-3-3-2.15][20474-1-1-3.69][20547-3-4-0.83][20929-2-2-3.59][21245-1-1-1.60][21257-3-3--0.49][21293-1-1-3.35][21316-1-1-3.93][21384-1-1-2.45][21448-1-1-1.98]
[21483-0-0-4.59][21487-2-2-2.20][21714-0-3-0.54][21943-3-3-0.55][21947-0-0-4.04][21948-0-0-7.14][21965-2-1-2.22][21998-1-1-0.52][22025-0-3--0.10][22228-3-3-4.11]
[22446-1-1-2.19][22494-3-0-3.03][22757-0-0-4.16][22811-3-3-2.54][22976-3-2-0.44][22985-3-3-3.12][23014-0-0-3.00][23112-1-1-2.66][23144-3-3-2.59][23168-2-0-0.16]
[23219-0-0-1.51][23363-3-3-1.84][23470-0-0-0.70][23486-2-3-0.95][23497-0-0-4.00][23516-0-0-5.36][23690-1-4-0.53][23921-2-2-0.39][23936-1-2-0.44][24040-3-4-0.19]
[24111-1-4-2.25][24182-0-0-5.09][24238-3-3-1.73][24290-2-0-2.84][24345-0-0-2.64][24364-1-2-1.38][24427-3-0-2.35][24477-2-2-2.64][24495-2-1-0.93][24893-2-2-1.71]
[25012-1-1--0.24][25121-2-2-1.89][25165-3-3-1.12][25183-0-0-3.41][25297-3-3-1.65][25398-0-0-3.24][25574-2-2-2.33][25644-1-1-3.78][25718-1-0--0.38][25774-2-3--0.06]
[26032-3-3-1.24][26051-3-3-2.60][26120-0-0-1.71][26321-1-1-3.08][26732-1-1-2.43][26784-3-3-2.76][26827-3-3-2.10][26833-0-3-2.74][26838-2-4-0.23][26860-1-4-0.32]
[26948-0-0-2.71][27049-3-0-3.12][27098-1-1-1.07][27526-0-0-4.33][27639-3-3-0.22][27698-3-3-3.08][27772-0-0-4.42][27890-1-1-0.87][28040-0-0-0.44][28503-2-2-3.53]
[28577-1-1-4.35][28959-0-0-5.82][29198-3-3-1.32][29777-0-0-6.78][29877-2-1-0.42][30035-1-2-3.12][30098-0-0-2.88][30326-1-1-3.39][30572-2-2-1.09][30716-0-4-1.37]
[30806-2-3-0.67][30906-1-1-3.19][31007-0-0-1.75][31181-3-3-1.42][31238-0-3-1.65][31347-0-0-3.76][31422-2-2-0.69][31429-3-3-0.75][31431-0-0-2.57][31432-1-1-2.45]
[31477-0-0-4.41][31524-1-2-0.37][31597-1-2-0.60][31619-1-0-0.54][31701-0-0-3.35][31755-0-0-3.38][31854-3-3-2.30][32074-1-1-0.86][32078-3-3-3.35][32111-1-1-2.55]
[32127-1-1-2.12][32140-3-3-3.21][32263-2-0-1.08][32365-0-0-3.50][32411-2-0-4.86][32429-3-0-2.95][32473-3-0-1.50][32574-3-3-3.05][32584-0-0-2.01][32622-0-1--0.14]
[32858-3-0-2.04][32969-3-0-3.52][33016-2-2-2.30][33031-1-3-1.82][33035-2-2-1.83][33133-2-2-1.28][33173-2-2-0.90][33175-3-4-1.08][33306-3-3-0.01][33309-2-3-1.54]
[33474-0-0-0.86][33478-2-1-0.21][33618-1-1-2.06][33712-0-0-1.96][33782-2-2-1.35][33914-3-3-0.38][34076-3-3-1.42][34112-2-2-2.15][34138-2-3-0.75][34239-1-1-1.05]
[34364-2-2-2.18][34617-1-2-0.15][34751-3-3-3.15][34783-2-2-1.10][35015-3-3-1.33][35018-1-1-2.08][35288-2-3--0.41][0-4-4-1.31][1-4-4-1.48][2-4-0-0.98]
[3-4-1-1.00][4-4-1-0.85][5-4-1--0.39][6-4-4-3.14][7-4-2--0.18][8-4-2-0.84][9-4-1-0.72][10-4-4-1.41][11-4-2-2.24][12-4-1-0.33]
[14-4-3-1.01][15-4-3-1.64][16-4-4-1.63][17-4-4--0.02][18-4-4-1.97][19-4-0-2.76][20-4-0-0.33][21-4-2-1.23][22-4-4-1.50][23-4-4--0.19]
[24-4-4-4.24][25-4-3-1.59][26-4-1--0.49][27-4-2--0.39][28-4-4-1.72][29-4-1-1.92][30-4-0-1.01][31-4-1-0.12][32-4-4-1.84][33-4-3--0.07]
[34-4-3-0.31][35-4-0-2.91][37-4-3-0.32][39-4-0-2.43][40-4-0-0.81][41-4-4--0.30][42-4-4--0.24][43-4-2-0.54][45-4-2-1.61][46-4-4-2.07]
[47-4-4-2.37][48-4-1-0.49][51-4-4-0.77][52-4-4-0.73][53-4-1--0.08][54-4-4-0.32][55-4-3-0.38][56-4-1-1.06][57-4-3-1.13][58-4-2-2.44]
[59-4-0-3.41][60-4-4-0.20][61-4-4-2.36][62-4-3-0.61][63-4-2-2.06][64-4-0-0.70][65-4-4-2.24][66-4-4-2.22][67-4-2-0.49][68-4-1-0.73]
[69-4-0-1.72][70-4-2-1.48][72-4-2-1.25][73-4-1-0.43][74-4-2-1.50][75-4-0-1.51][77-4-4-3.89][78-4-3-0.00][79-4-2-0.84][80-4-4-3.09]
[81-4-4-3.08][82-4-1-0.84][83-4-1--0.05][84-4-0-0.95][85-4-4-1.18][86-4-4-0.83][87-4-4-2.14][88-4-4-0.96][89-4-2--0.37][90-4-0-0.28]
[91-4-2-1.35][92-4-0--0.45][93-4-0-1.20][94-4-4-1.82][95-4-3-0.51][96-4-1-0.98][97-4-4-2.19][98-4-4-0.11][99-4-4-1.34][100-4-1-1.36]
[101-4-4-2.62][102-4-4--0.18][103-4-3-0.81][104-4-4-0.53][105-4-4-3.44][106-4-1-0.70][107-4-0-1.39][108-4-2-1.08][109-4-0-0.85][110-4-4-0.50]
[111-4-0-4.26][112-4-0-1.17][113-4-4-0.44][114-4-3-0.61][115-4-4-0.28][116-4-0-0.72][117-4-4-1.34][119-4-2-0.74][121-4-4-0.39][122-4-4-1.49]
[124-4-3-0.49][125-4-4-2.74][126-4-4-1.61][127-4-1-1.00][128-4-0-0.60][129-4-3--0.15][130-4-4--0.01][131-4-2-0.79][132-4-4-1.07][133-4-4-3.27]
[135-4-2-0.00][136-4-0-0.72][137-4-3--0.28][138-4-1-0.13][139-4-4-0.40][140-4-1-0.30][141-4-0-1.28][142-4-4-1.75][143-4-4-3.01][144-4-4-3.88]
[145-4-1-2.42][148-4-0-4.19][149-4-4-0.52][150-4-4-0.85][151-4-4-2.37][152-4-4-0.08][153-4-2-1.89][154-4-4-3.13][155-4-4-1.63][156-4-0-1.16]
[157-4-0-0.31][158-4-3-1.21][160-4-1-0.03][161-4-2-1.13][162-4-4-0.46][164-4-3-0.07][165-4-4--0.18][167-4-0-3.25][168-4-4-0.92][170-4-0-1.89]
[171-4-4-0.71][172-4-4-1.33][173-4-4-1.49][174-4-0-3.85][175-4-4-0.64][177-4-0-2.74][178-4-4-2.35][179-4-0-0.17][180-4-4-3.10][181-4-3-1.87]
[182-4-1-1.50][183-4-4-1.62][184-4-2-1.19][186-4-0-1.13][187-4-2-0.58][188-4-2-0.86][189-4-2-1.06][190-4-4-0.07][191-4-0-1.25][192-4-4-0.21]
[193-4-1-2.30][194-4-3-1.19][195-4-2--0.04][196-4-3-0.24][197-4-4-0.92][198-4-4-2.99][199-4-2-1.03]
---------------------------
I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.567 | Acc: 73.375% | Wgt Acc: 83.219%
	I - Batch: 100 | Loss: 0.577 | Acc: 71.875% | Wgt Acc: 81.629%
	I - Batch: 150 | Loss: 0.573 | Acc: 71.542% | Wgt Acc: 81.314%
	I - Batch: 200 | Loss: 0.569 | Acc: 71.562% | Wgt Acc: 81.378%
I - num batch: 222
I - Train -- Loss: 0.566 | Acc: 71.694% | Wgt Acc: 81.357% | LR: 2.500000e-04 | Dur: 136.99s
I - Confusion Matrix: [row->prediction - col->label]
[[598.  13.  20.  75. 144.]
 [ 11. 510.  36.  11. 109.]
 [ 16.  39. 638.  27. 264.]
 [ 54.   7.  25. 421. 107.]
 [ 18.   9.  15.   4. 376.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.267 | Acc: 52.465% | Wgt Acc: 60.720% | Dur: 14.26s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  4.  4. 11. 26.]
 [ 1. 37.  9.  0. 15.]
 [ 2. 26. 47.  4. 55.]
 [24.  9. 13. 68. 27.]
 [ 4.  2.  2.  3. 57.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.523 | Acc: 72.125% | Wgt Acc: 82.688%
	I - Batch: 100 | Loss: 0.519 | Acc: 73.062% | Wgt Acc: 83.733%
	I - Batch: 150 | Loss: 0.521 | Acc: 72.958% | Wgt Acc: 83.283%
	I - Batch: 200 | Loss: 0.529 | Acc: 72.844% | Wgt Acc: 82.934%
I - num batch: 222
I - Train -- Loss: 0.534 | Acc: 72.794% | Wgt Acc: 82.557% | LR: 2.500000e-04 | Dur: 146.55s
I - Confusion Matrix: [row->prediction - col->label]
[[598.   8.  11.  58. 148.]
 [ 12. 514.  30.  10. 114.]
 [ 12.  40. 642.  17. 232.]
 [ 60.  11.  26. 443. 121.]
 [ 15.   5.  25.  10. 385.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.060 | Acc: 58.974% | Wgt Acc: 62.438% | Dur: 16.63s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  7. 27. 27.]
 [ 1. 45. 11.  3. 18.]
 [ 2. 18. 43.  4. 38.]
 [ 6.  3.  6. 47.  8.]
 [ 4.  7.  8.  5. 89.]]

I - Local maximum validation set accuracy:  58.97

I - Validation set results: 
[14-1-2-0.53][50-3-4-0.61][124-2-1-1.45][127-0-0-4.65][443-2-2-2.68][567-0-0-2.24][573-1-1-1.67][615-0-0-2.27][695-1-2-1.03][722-3-0-3.15]
[826-0-0-5.02][878-0-0-4.49][1103-0-0-1.90][1212-3-3--0.23][1368-0-0-3.42][2181-2-0-0.37][2476-2-0--0.22][2721-2-2-2.05][2818-1-0-1.32][2886-2-4-1.31]
[3231-2-2-3.31][3333-2-1-2.16][3482-2-2-2.08][3536-3-0-0.83][3625-1-1-4.88][3909-0-0-4.68][4035-0-0-1.77][4140-0-0-2.32][4214-1-1-1.18][4346-1-0-1.07]
[4581-2-2-1.72][4708-3-2-0.20][4838-3-0--0.31][4845-1-2-0.03][4868-0-0-3.20][4939-0-4--0.03][4984-2-2-2.77][5078-1-4-1.21][5396-0-0-5.26][5479-1-1-1.30]
[5717-0-0-3.98][5843-1-1-2.84][5949-3-3-1.32][5987-2-4-2.16][6014-3-3-0.52][6033-3-3--0.07][6313-0-3-1.41][6421-3-3-1.99][6500-1-3-0.50][6583-3-2-1.00]
[6683-3-3-0.81][6825-2-1-1.37][6998-3-0--0.04][7049-3-3-0.51][7517-1-2-1.35][7521-1-1-0.14][7528-1-3-1.53][7949-1-2-1.67][8135-1-0-1.35][8185-3-0-4.25]
[8269-3-4-1.38][8273-3-3-0.90][8543-3-0-5.38][8666-1-1-2.82][8672-0-0-3.51][8903-1-2-1.72][9001-2-2-1.51][9036-2-2-4.07][9281-3-0--0.48][9300-2-2-3.61]
[9571-0-0-0.65][9617-1-1--0.10][9644-2-1-0.49][9705-2-0-0.98][9801-0-0-2.07][9803-3-3-0.95][9865-3-3-2.61][9896-2-2-2.43][10314-1-2-0.66][10337-3-3-1.49]
[10403-0-0-0.79][10653-2-4-0.21][10704-2-1-0.36][10719-1-1-2.34][10727-1-1-0.45][10836-0-0-7.50][10969-2-3-0.59][11042-0-0-1.63][11088-1-1-3.18][11322-0-0-5.18]
[11398-2-2-0.72][11499-0-0-3.50][11502-3-0-0.96][11512-3-3-0.32][11608-1-1-2.47][11610-0-0-2.46][11692-0-0-2.07][11905-0-0-1.16][11993-1-1-1.01][12002-2-2-0.42]
[12052-0-0-3.87][12201-0-0-2.41][12235-2-2-1.07][12320-1-0-1.22][12377-2-4-1.75][12398-2-3-0.75][12503-1-1-1.91][12617-0-2-0.30][12685-3-3-0.30][12738-2-0-0.62]
[12742-2-2-2.67][12823-0-0-3.11][13110-1-1-1.54][13240-3-0-1.74][13253-1-4-1.26][13273-0-0-6.41][13634-1-1-1.03][13763-2-2-0.72][13905-3-3-1.09][14060-2-1--0.21]
[14065-3-0-1.52][14147-3-3-0.58][14595-2-2-2.12][14687-2-2-3.26][14788-2-2-1.03][14869-1-1-2.96][14872-3-0-0.44][14877-1-1-2.03][14927-0-0-1.69][15066-0-0-3.45]
[15175-1-1-0.88][15178-2-3-1.16][15375-3-1-0.09][15389-3-3-1.94][15568-2-1-1.22][15675-3-3-2.70][15869-1-4--0.63][16207-3-3--0.22][16236-0-0-0.12][16302-3-0-0.13]
[16331-2-2-5.05][16381-0-0-2.43][16488-1-1-3.20][16495-0-0-4.29][16650-0-0-5.46][16719-1-2-1.74][16801-0-0-6.12][16828-0-0-3.64][17137-3-0-2.64][17245-1-1--0.11]
[17278-3-0-0.12][17282-0-0-1.03][17311-2-2-2.27][17336-2-1-1.24][17608-3-3-2.47][17627-0-0-0.82][17877-3-0-0.80][17924-1-1--0.29][17984-3-0-2.21][18211-0-3-1.06]
[18276-3-0-2.27][18287-1-2-0.58][18394-0-0-3.65][18428-0-0-2.99][18442-0-3-1.81][18478-3-3-1.57][18607-0-0-2.41][18616-0-0-1.19][18663-0-0-1.69][18718-0-0-4.14]
[18766-2-2-0.55][18824-2-2-2.30][18890-3-3-0.91][18930-3-4-1.16][18938-3-3-1.49][19817-1-1-1.15][19839-0-0-0.82][19930-3-3-1.73][19944-0-1-0.55][20036-2-2-4.34]
[20101-3-3-1.23][20474-1-1-3.47][20547-3-3-1.83][20929-2-2-3.84][21245-1-1-0.92][21257-3-3-0.80][21293-1-1-2.97][21316-1-1-4.48][21384-1-1-1.35][21448-1-2-0.71]
[21483-0-0-3.81][21487-2-2-3.57][21714-0-3-0.87][21943-3-2-0.65][21947-0-0-3.34][21948-0-0-7.20][21965-2-2-2.51][21998-1-1-2.37][22025-0-2--0.33][22228-3-3-3.45]
[22446-1-1-1.52][22494-3-0-2.32][22757-0-0-3.35][22811-3-3-1.19][22976-3-2-1.41][22985-3-3-2.45][23014-0-0-3.11][23112-1-1-2.39][23144-3-3-2.08][23168-2-0-1.34]
[23219-0-0-0.69][23363-3-3-2.06][23470-0-0-0.10][23486-2-3-0.70][23497-0-0-3.98][23516-0-0-4.95][23690-1-4-1.51][23921-2-1-0.76][23936-1-2-0.02][24040-3-4-0.19]
[24111-1-4-2.27][24182-0-0-5.41][24238-3-0-1.61][24290-2-0-1.93][24345-0-0-2.54][24364-1-2-2.12][24427-3-0-2.61][24477-2-2-3.10][24495-2-4--0.39][24893-2-2-1.81]
[25012-1-4-0.05][25121-2-4-1.55][25165-3-3-0.56][25183-0-0-3.70][25297-3-3-0.75][25398-0-0-3.01][25574-2-2-1.51][25644-1-1-2.98][25718-1-0--0.29][25774-2-2--0.58]
[26032-3-3-0.77][26051-3-3-1.87][26120-0-4-0.83][26321-1-1-0.25][26732-1-1-2.81][26784-3-3-2.57][26827-3-3-0.97][26833-0-3-2.57][26838-2-3-0.53][26860-1-1-0.90]
[26948-0-0-2.82][27049-3-0-2.68][27098-1-1-0.21][27526-0-0-3.19][27639-3-0-0.04][27698-3-3-2.89][27772-0-0-4.66][27890-1-1-1.88][28040-0-0-1.87][28503-2-2-3.34]
[28577-1-1-3.91][28959-0-0-4.57][29198-3-0-0.46][29777-0-0-5.66][29877-2-2--0.13][30035-1-2-2.73][30098-0-0-2.55][30326-1-1-3.27][30572-2-2-3.00][30716-0-4-2.35]
[30806-2-2-0.16][30906-1-1-2.10][31007-0-0-2.17][31181-3-0--0.09][31238-0-0-1.59][31347-0-0-4.44][31422-2-2-1.11][31429-3-3-0.40][31431-0-0-1.55][31432-1-1-2.78]
[31477-0-0-4.00][31524-1-1-2.05][31597-1-2-0.79][31619-1-2-0.24][31701-0-0-4.11][31755-0-0-1.82][31854-3-3-2.91][32074-1-2-0.65][32078-3-3-1.28][32111-1-4-1.11]
[32127-1-2-1.77][32140-3-3-3.18][32263-2-4-0.21][32365-0-0-3.23][32411-2-0-4.46][32429-3-0-1.38][32473-3-0-1.41][32574-3-3-2.60][32584-0-0-1.91][32622-0-4--0.26]
[32858-3-0-1.51][32969-3-3-2.17][33016-2-2-1.85][33031-1-3-1.37][33035-2-2-1.85][33133-2-2-1.34][33173-2-2-0.04][33175-3-4-0.85][33306-3-1-0.79][33309-2-3-1.21]
[33474-0-0-0.48][33478-2-1--0.98][33618-1-1-2.22][33712-0-3-2.48][33782-2-2-2.17][33914-3-3-3.13][34076-3-1-0.29][34112-2-2-1.94][34138-2-1-0.70][34239-1-1-1.23]
[34364-2-2-3.38][34617-1-2-1.47][34751-3-3-2.93][34783-2-4-0.65][35015-3-3-0.50][35018-1-1-2.14][35288-2-2-1.04][0-4-4-1.45][1-4-4-1.43][2-4-4-1.67]
[3-4-4-1.53][4-4-2-0.31][5-4-1--0.36][6-4-4-1.95][7-4-4-2.68][8-4-2--0.19][9-4-1-1.37][10-4-4-2.08][11-4-2-2.68][12-4-1--0.13]
[14-4-0-0.32][15-4-0-0.92][16-4-4-1.63][17-4-4--0.29][18-4-4-2.46][19-4-0-2.16][20-4-0-0.32][21-4-2-0.33][22-4-4-2.08][23-4-4-0.88]
[24-4-4-4.22][25-4-3-0.34][26-4-4-0.12][27-4-2--0.20][28-4-4-1.42][29-4-1-2.62][30-4-0-0.53][31-4-2-0.47][32-4-4-1.92][33-4-2--0.18]
[34-4-0-0.47][35-4-0-1.92][37-4-2--0.07][39-4-0-4.50][40-4-4-0.50][41-4-2--0.45][42-4-1-0.47][43-4-2-0.43][45-4-3-0.47][46-4-4-3.65]
[47-4-4-3.47][48-4-4-2.48][51-4-4-2.58][52-4-4-1.47][53-4-1-0.02][54-4-3-0.58][55-4-2--0.13][56-4-4-0.49][57-4-3-1.00][58-4-2-1.73]
[59-4-0-3.11][60-4-4--0.27][61-4-4-2.93][62-4-2-0.27][63-4-2-1.81][64-4-4-0.33][65-4-4-3.02][66-4-4-3.28][67-4-4--0.06][68-4-1-0.28]
[69-4-0-1.55][70-4-4-1.96][72-4-4-1.49][73-4-1--0.47][74-4-2-1.26][75-4-0-0.50][77-4-4-3.63][78-4-3-0.70][79-4-4-1.93][80-4-4-2.55]
[81-4-1-1.10][82-4-1-0.62][83-4-1--0.24][84-4-4-1.91][85-4-4-1.97][86-4-4-1.56][87-4-4-1.94][88-4-4-2.22][89-4-2-0.30][90-4-0-0.65]
[91-4-2-1.99][92-4-0-1.13][93-4-4-0.85][94-4-4-2.28][95-4-3-0.06][96-4-4-0.72][97-4-4-1.52][98-4-2-0.64][99-4-4-0.23][100-4-1-0.98]
[101-4-4-4.07][102-4-2--0.12][103-4-0-0.31][104-4-4-0.96][105-4-2-1.57][106-4-4-2.36][107-4-1-1.10][108-4-2-0.22][109-4-4-0.84][110-4-4-1.16]
[111-4-0-4.99][112-4-0-0.65][113-4-2--0.26][114-4-3-0.32][115-4-4-0.74][116-4-4-0.52][117-4-4-1.64][119-4-2-1.10][121-4-4-1.03][122-4-4-1.95]
[124-4-2--0.44][125-4-4-3.02][126-4-4-2.93][127-4-4-0.89][128-4-0-0.19][129-4-4--0.58][130-4-2-0.07][131-4-2-0.32][132-4-4-0.36][133-4-4-3.96]
[135-4-2-0.84][136-4-2--0.11][137-4-0--0.31][138-4-1-1.22][139-4-4-0.65][140-4-1-0.38][141-4-0-2.40][142-4-4-3.41][143-4-4-1.84][144-4-4-3.87]
[145-4-1-1.69][148-4-0-5.04][149-4-2--0.04][150-4-4-1.65][151-4-4-2.17][152-4-4-1.49][153-4-4-1.49][154-4-4-2.73][155-4-4-1.66][156-4-3-0.32]
[157-4-0-2.39][158-4-4-0.54][160-4-4-0.15][161-4-2-1.01][162-4-4-0.13][164-4-2-0.48][165-4-4-0.47][167-4-0-2.26][168-4-4-1.13][170-4-0-0.69]
[171-4-4-1.03][172-4-4-1.85][173-4-0-1.90][174-4-0-2.55][175-4-4-1.62][177-4-0-2.05][178-4-2-1.30][179-4-0-0.33][180-4-4-2.98][181-4-2--0.55]
[182-4-1-0.62][183-4-4-1.79][184-4-4-1.24][186-4-4-0.38][187-4-2-0.85][188-4-2-0.68][189-4-4-1.00][190-4-4--0.42][191-4-4-1.48][192-4-4-0.54]
[193-4-2-2.90][194-4-2-1.13][195-4-1-0.05][196-4-4-0.93][197-4-4-1.67][198-4-4-4.44][199-4-2-0.81]
---------------------------
I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.505 | Acc: 73.500% | Wgt Acc: 83.643%
	I - Batch: 100 | Loss: 0.487 | Acc: 74.625% | Wgt Acc: 84.584%
	I - Batch: 150 | Loss: 0.498 | Acc: 73.667% | Wgt Acc: 83.876%
	I - Batch: 200 | Loss: 0.512 | Acc: 73.156% | Wgt Acc: 83.243%
I - num batch: 222
I - Train -- Loss: 0.517 | Acc: 72.766% | Wgt Acc: 82.988% | LR: 2.500000e-04 | Dur: 135.44s
I - Confusion Matrix: [row->prediction - col->label]
[[603.   8.  13.  69. 161.]
 [ 13. 526.  26.  10. 121.]
 [ 15.  35. 658.  25. 224.]
 [ 47.   4.  18. 427. 127.]
 [ 19.   5.  19.   7. 367.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.259 | Acc: 56.410% | Wgt Acc: 61.792% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[79.  9.  9. 36. 54.]
 [ 0. 46.  8.  2. 15.]
 [ 1. 11. 44.  3. 21.]
 [ 5.  6. 10. 42. 15.]
 [ 3.  6.  4.  3. 75.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.527 | Acc: 72.000% | Wgt Acc: 81.487%
	I - Batch: 100 | Loss: 0.504 | Acc: 73.375% | Wgt Acc: 83.226%
	I - Batch: 150 | Loss: 0.493 | Acc: 74.042% | Wgt Acc: 84.023%
	I - Batch: 200 | Loss: 0.500 | Acc: 73.500% | Wgt Acc: 83.773%
I - num batch: 222
I - Train -- Loss: 0.500 | Acc: 73.612% | Wgt Acc: 83.739% | LR: 2.500000e-04 | Dur: 135.13s
I - Confusion Matrix: [row->prediction - col->label]
[[601.  13.  13.  68. 156.]
 [ 12. 534.  21.  10. 114.]
 [ 13.  25. 666.  22. 246.]
 [ 53.   4.  20. 431. 105.]
 [ 18.   2.  14.   7. 379.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.063 | Acc: 62.327% | Wgt Acc: 64.987% | Dur: 14.49s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  3.  3. 17. 18.]
 [ 1. 41.  9.  1. 12.]
 [ 1. 21. 52.  8. 40.]
 [11.  5.  6. 54. 11.]
 [ 5.  8.  5.  6. 99.]]

I - Local maximum validation set accuracy:  62.33

I - Validation set results: 
[14-1-2-1.74][50-3-4-0.92][124-2-2-0.32][127-0-0-5.03][443-2-2-3.10][567-0-0-3.49][573-1-1-1.32][615-0-0-2.04][695-1-2-1.28][722-3-0-2.91]
[826-0-0-4.27][878-0-0-3.22][1103-0-0-0.53][1212-3-3-0.43][1368-0-0-4.01][2181-2-2-1.01][2476-2-2-0.37][2721-2-2-1.54][2818-1-4--0.21][2886-2-4-1.32]
[3231-2-2-4.52][3333-2-1-1.28][3482-2-2-2.94][3536-3-3-1.85][3625-1-1-5.27][3909-0-0-2.82][4035-0-0-1.89][4140-0-0-2.69][4214-1-1-1.64][4346-1-0-0.60]
[4581-2-2-1.88][4708-3-2-2.21][4838-3-3-0.06][4845-1-2-0.65][4868-0-0-4.41][4939-0-1-0.77][4984-2-2-2.56][5078-1-4-1.44][5396-0-0-5.78][5479-1-1-2.33]
[5717-0-0-4.40][5843-1-2-1.50][5949-3-3-2.01][5987-2-4-1.85][6014-3-3-1.21][6033-3-0-0.37][6313-0-3-1.64][6421-3-3-2.82][6500-1-2-1.04][6583-3-2-1.41]
[6683-3-3-0.87][6825-2-1-0.50][6998-3-0-0.90][7049-3-3-1.06][7517-1-1-2.81][7521-1-1-0.62][7528-1-2-0.78][7949-1-2-2.50][8135-1-4-0.40][8185-3-0-3.93]
[8269-3-2-1.00][8273-3-3-0.47][8543-3-0-5.93][8666-1-1-3.29][8672-0-0-5.44][8903-1-1-1.35][9001-2-1-1.09][9036-2-2-3.86][9281-3-3--0.41][9300-2-2-5.37]
[9571-0-0-0.28][9617-1-1-0.37][9644-2-2-0.94][9705-2-0-0.56][9801-0-3-1.23][9803-3-3-1.88][9865-3-3-3.63][9896-2-2-1.15][10314-1-2-1.17][10337-3-3-2.73]
[10403-0-4-0.69][10653-2-4-1.04][10704-2-2-1.80][10719-1-1-3.12][10727-1-4-0.58][10836-0-0-8.70][10969-2-3-0.67][11042-0-0-0.39][11088-1-1-2.44][11322-0-0-4.59]
[11398-2-2-1.73][11499-0-0-2.83][11502-3-3-1.80][11512-3-3-0.89][11608-1-1-2.62][11610-0-0-1.37][11692-0-0-1.49][11905-0-0-2.86][11993-1-1-1.51][12002-2-3-0.19]
[12052-0-0-2.57][12201-0-3-2.73][12235-2-2-1.61][12320-1-4-2.15][12377-2-2-1.52][12398-2-2-0.69][12503-1-2-2.05][12617-0-2-0.53][12685-3-2-0.29][12738-2-1--0.03]
[12742-2-2-4.32][12823-0-0-1.73][13110-1-1-0.21][13240-3-3-1.72][13253-1-4-1.35][13273-0-0-6.27][13634-1-1-1.28][13763-2-2-1.69][13905-3-3-0.77][14060-2-2-1.16]
[14065-3-0-1.52][14147-3-3-1.22][14595-2-2-1.64][14687-2-2-3.26][14788-2-2-1.92][14869-1-1-3.06][14872-3-0-0.89][14877-1-1-1.91][14927-0-3-0.87][15066-0-0-5.22]
[15175-1-1-1.60][15178-2-3-0.49][15375-3-0--0.29][15389-3-3-2.16][15568-2-1-1.88][15675-3-3-2.80][15869-1-2-0.48][16207-3-0-0.89][16236-0-0-0.73][16302-3-3-0.05]
[16331-2-2-5.47][16381-0-0-1.47][16488-1-1-3.18][16495-0-0-3.22][16650-0-0-5.51][16719-1-2-1.85][16801-0-0-5.75][16828-0-0-2.84][17137-3-0-1.51][17245-1-1-0.06]
[17278-3-1--0.39][17282-0-0-1.07][17311-2-2-2.08][17336-2-2-0.86][17608-3-3-3.48][17627-0-0-1.48][17877-3-4-0.68][17924-1-1-0.27][17984-3-0-3.89][18211-0-3-1.57]
[18276-3-0-1.99][18287-1-1-0.03][18394-0-0-4.09][18428-0-0-5.06][18442-0-3-1.80][18478-3-3-2.35][18607-0-0-2.25][18616-0-0-0.70][18663-0-0-1.37][18718-0-0-4.83]
[18766-2-2-2.74][18824-2-2-2.11][18890-3-3-1.24][18930-3-4-0.57][18938-3-3-1.74][19817-1-1-2.34][19839-0-0-0.62][19930-3-3-1.50][19944-0-4-0.52][20036-2-2-4.97]
[20101-3-4-0.06][20474-1-1-3.08][20547-3-0-0.97][20929-2-2-4.97][21245-1-2-0.90][21257-3-2-0.73][21293-1-2-2.94][21316-1-1-2.11][21384-1-1-1.64][21448-1-2-1.63]
[21483-0-0-3.74][21487-2-2-3.58][21714-0-3--0.14][21943-3-2-0.93][21947-0-0-2.61][21948-0-0-6.81][21965-2-2-2.59][21998-1-1-2.01][22025-0-3-0.36][22228-3-3-3.86]
[22446-1-1-3.01][22494-3-0-2.11][22757-0-0-2.51][22811-3-3-2.77][22976-3-2-1.34][22985-3-3-2.80][23014-0-0-2.64][23112-1-1-1.77][23144-3-3-3.83][23168-2-3-0.73]
[23219-0-0-1.28][23363-3-3-2.61][23470-0-0-0.17][23486-2-2-1.38][23497-0-3-4.20][23516-0-0-5.68][23690-1-3-1.12][23921-2-1-0.47][23936-1-2-0.91][24040-3-4-0.24]
[24111-1-4-1.95][24182-0-0-5.36][24238-3-3-1.92][24290-2-0-2.12][24345-0-0-0.19][24364-1-2-2.29][24427-3-0-1.67][24477-2-2-2.34][24495-2-1-1.04][24893-2-2-1.94]
[25012-1-2--0.16][25121-2-2-1.36][25165-3-3-1.41][25183-0-0-3.10][25297-3-3-2.12][25398-0-0-2.72][25574-2-2-2.53][25644-1-1-2.91][25718-1-3-0.02][25774-2-2-1.09]
[26032-3-3-1.25][26051-3-3-3.01][26120-0-4-1.57][26321-1-1-3.49][26732-1-1-2.13][26784-3-3-3.80][26827-3-3-2.32][26833-0-3-3.07][26838-2-2-0.59][26860-1-2-0.28]
[26948-0-0-1.38][27049-3-0-2.79][27098-1-0-0.47][27526-0-0-3.73][27639-3-3-1.25][27698-3-3-1.21][27772-0-0-3.48][27890-1-1-0.87][28040-0-0-1.13][28503-2-2-4.24]
[28577-1-1-4.13][28959-0-0-5.61][29198-3-3-0.83][29777-0-0-6.10][29877-2-2-0.47][30035-1-1-2.44][30098-0-0-2.26][30326-1-1-2.99][30572-2-2-2.96][30716-0-4-1.90]
[30806-2-2-0.59][30906-1-1-2.60][31007-0-0-1.24][31181-3-3-0.95][31238-0-0-1.44][31347-0-0-3.48][31422-2-2-1.86][31429-3-3-1.50][31431-0-0-2.59][31432-1-1-1.51]
[31477-0-0-4.27][31524-1-3-0.32][31597-1-2-1.40][31619-1-0-0.39][31701-0-0-3.09][31755-0-0-1.77][31854-3-3-1.07][32074-1-3-1.48][32078-3-3-1.21][32111-1-1-1.00]
[32127-1-2-1.55][32140-3-3-4.07][32263-2-4--0.04][32365-0-0-3.62][32411-2-0-3.96][32429-3-3-1.82][32473-3-0-0.07][32574-3-3-2.55][32584-0-0-0.86][32622-0-4-0.47]
[32858-3-3-0.65][32969-3-3-2.87][33016-2-2-3.57][33031-1-3-1.58][33035-2-2-2.41][33133-2-2-1.88][33173-2-2-0.62][33175-3-2-0.91][33306-3-3-0.39][33309-2-3-1.21]
[33474-0-0--0.39][33478-2-3--0.35][33618-1-1-2.05][33712-0-3-2.09][33782-2-2-2.79][33914-3-3-0.89][34076-3-4-0.43][34112-2-2-4.71][34138-2-1-0.29][34239-1-1-0.78]
[34364-2-2-3.82][34617-1-2-1.00][34751-3-3-3.03][34783-2-4-1.38][35015-3-3-1.32][35018-1-4-1.31][35288-2-1--0.03][0-4-2-1.93][1-4-4-1.28][2-4-4-1.66]
[3-4-4-1.15][4-4-1-0.17][5-4-1-0.46][6-4-0-3.08][7-4-4-0.75][8-4-2-0.38][9-4-0-1.01][10-4-4-3.12][11-4-2-2.22][12-4-1-0.31]
[14-4-4-0.57][15-4-3-2.48][16-4-4-1.05][17-4-4-0.69][18-4-4-2.42][19-4-0-1.67][20-4-2-0.48][21-4-4-0.58][22-4-4-1.75][23-4-4--0.08]
[24-4-4-4.59][25-4-3-1.05][26-4-1-0.03][27-4-4-0.17][28-4-4-1.99][29-4-1-0.76][30-4-3-0.81][31-4-2-1.50][32-4-4-1.54][33-4-2-0.05]
[34-4-4-0.40][35-4-0-1.64][37-4-4-1.07][39-4-3-1.53][40-4-4-0.39][41-4-2--0.36][42-4-2-1.64][43-4-2-1.45][45-4-2-1.80][46-4-4-3.16]
[47-4-4-2.96][48-4-4-1.52][51-4-4-1.78][52-4-4-0.42][53-4-4-0.14][54-4-4-0.34][55-4-2-0.10][56-4-2-0.41][57-4-3-1.12][58-4-2-3.11]
[59-4-0-1.64][60-4-4-0.55][61-4-4-2.39][62-4-2-0.69][63-4-2-2.92][64-4-4-0.36][65-4-4-2.93][66-4-4-1.46][67-4-3-0.23][68-4-1-1.11]
[69-4-0-1.78][70-4-4-1.03][72-4-4-1.69][73-4-4-0.33][74-4-2-1.43][75-4-0-0.52][77-4-4-3.58][78-4-3-0.35][79-4-4-1.35][80-4-4-1.89]
[81-4-4-2.28][82-4-1-0.19][83-4-1--0.48][84-4-4-2.05][85-4-4-1.98][86-4-4-0.47][87-4-4-1.96][88-4-4-2.15][89-4-2-0.82][90-4-0--0.14]
[91-4-2-0.43][92-4-3-0.14][93-4-4-1.28][94-4-4-2.40][95-4-2-1.14][96-4-4-0.97][97-4-4-2.27][98-4-2-1.43][99-4-4-1.05][100-4-4-1.30]
[101-4-4-3.76][102-4-4-0.83][103-4-2-0.66][104-4-4-1.47][105-4-4-3.19][106-4-4-1.53][107-4-1-2.02][108-4-2-1.42][109-4-4-0.47][110-4-4-1.60]
[111-4-0-3.93][112-4-0-0.57][113-4-2-0.70][114-4-3-1.26][115-4-4-0.71][116-4-4-0.67][117-4-4-1.29][119-4-2-2.17][121-4-4-1.64][122-4-4-0.88]
[124-4-2-1.39][125-4-4-2.14][126-4-4-1.84][127-4-2-2.70][128-4-0--0.27][129-4-4-0.26][130-4-4-0.85][131-4-2-1.96][132-4-4-0.01][133-4-4-3.28]
[135-4-2-1.38][136-4-0-0.06][137-4-4-0.37][138-4-4--0.14][139-4-4-0.38][140-4-1-0.50][141-4-2-0.60][142-4-4-3.07][143-4-4-1.74][144-4-4-3.61]
[145-4-2-2.02][148-4-0-3.51][149-4-2-0.75][150-4-4-2.90][151-4-4-2.17][152-4-4-1.52][153-4-2-3.30][154-4-4-1.83][155-4-4-1.95][156-4-3-1.07]
[157-4-0-1.62][158-4-4-1.27][160-4-2-1.47][161-4-2-0.89][162-4-4-0.92][164-4-4-0.96][165-4-4-0.64][167-4-0-1.49][168-4-4-0.86][170-4-0-0.99]
[171-4-4-1.04][172-4-4-1.95][173-4-4-2.08][174-4-0-2.13][175-4-4-0.76][177-4-4--0.26][178-4-2-1.88][179-4-4-0.35][180-4-4-3.19][181-4-3-0.41]
[182-4-1-0.85][183-4-4-1.55][184-4-2-1.84][186-4-4-0.94][187-4-4-0.94][188-4-2-2.15][189-4-4-0.70][190-4-4-1.27][191-4-4-1.37][192-4-4-0.11]
[193-4-1-2.09][194-4-2-0.10][195-4-0-1.07][196-4-2-0.65][197-4-4-1.51][198-4-4-5.00][199-4-2-1.28]
---------------------------
I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.441 | Acc: 78.125% | Wgt Acc: 86.966%
	I - Batch: 100 | Loss: 0.432 | Acc: 77.312% | Wgt Acc: 86.841%
	I - Batch: 150 | Loss: 0.444 | Acc: 77.083% | Wgt Acc: 86.467%
	I - Batch: 200 | Loss: 0.444 | Acc: 76.781% | Wgt Acc: 86.186%
I - num batch: 222
I - Train -- Loss: 0.444 | Acc: 76.769% | Wgt Acc: 86.165% | LR: 2.500000e-04 | Dur: 138.81s
I - Confusion Matrix: [row->prediction - col->label]
[[611.   6.   7.  47. 154.]
 [  9. 535.  13.   7.  94.]
 [ 16.  24. 684.  18. 220.]
 [ 45.   4.  14. 456.  95.]
 [ 16.   9.  16.  10. 437.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.183 | Acc: 55.424% | Wgt Acc: 61.538% | Dur: 15.89s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  1.  1. 14. 15.]
 [ 5. 47. 15.  5. 33.]
 [ 4. 20. 53. 13. 45.]
 [15.  5.  3. 52. 16.]
 [ 6.  5.  3.  2. 71.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 71.750% | Wgt Acc: 83.130%
	I - Batch: 100 | Loss: 0.452 | Acc: 75.000% | Wgt Acc: 85.473%
	I - Batch: 150 | Loss: 0.434 | Acc: 75.917% | Wgt Acc: 85.795%
	I - Batch: 200 | Loss: 0.436 | Acc: 75.938% | Wgt Acc: 85.735%
I - num batch: 222
I - Train -- Loss: 0.436 | Acc: 76.008% | Wgt Acc: 85.676% | LR: 2.500000e-04 | Dur: 133.95s
I - Confusion Matrix: [row->prediction - col->label]
[[608.   7.  16.  51. 144.]
 [  6. 533.  18.   9. 104.]
 [ 15.  21. 680.  16. 225.]
 [ 50.   6.   7. 455. 107.]
 [ 18.  11.  13.   7. 420.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.167 | Acc: 57.988% | Wgt Acc: 63.176% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  1.  2. 15. 23.]
 [ 1. 42. 11.  0. 11.]
 [ 0. 16. 42.  3. 37.]
 [19. 11. 16. 66. 28.]
 [ 5.  8.  4.  2. 81.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.409 | Acc: 76.375% | Wgt Acc: 87.020%
	I - Batch: 100 | Loss: 0.423 | Acc: 76.500% | Wgt Acc: 86.671%
	I - Batch: 150 | Loss: 0.413 | Acc: 77.625% | Wgt Acc: 87.543%
	I - Batch: 200 | Loss: 0.422 | Acc: 77.188% | Wgt Acc: 86.768%
I - num batch: 222
I - Train -- Loss: 0.422 | Acc: 77.248% | Wgt Acc: 86.848% | LR: 2.500000e-04 | Dur: 137.62s
I - Confusion Matrix: [row->prediction - col->label]
[[616.   4.   6.  42. 142.]
 [  7. 539.  15.   6.  97.]
 [ 15.  20. 687.  16. 211.]
 [ 44.   8.  14. 463. 115.]
 [ 15.   7.  12.  11. 435.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.117 | Acc: 59.172% | Wgt Acc: 64.606% | Dur: 17.22s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  3.  3. 15. 21.]
 [ 0. 44. 10.  1. 17.]
 [ 2. 20. 45.  6. 44.]
 [12.  8. 13. 58. 17.]
 [ 2.  3.  4.  6. 81.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.425 | Acc: 78.000% | Wgt Acc: 86.556%
	I - Batch: 100 | Loss: 0.415 | Acc: 77.500% | Wgt Acc: 86.480%
	I - Batch: 150 | Loss: 0.416 | Acc: 77.583% | Wgt Acc: 86.388%
	I - Batch: 200 | Loss: 0.418 | Acc: 76.969% | Wgt Acc: 86.107%
I - num batch: 222
I - Train -- Loss: 0.424 | Acc: 76.910% | Wgt Acc: 86.112% | LR: 2.500000e-04 | Dur: 134.74s
I - Confusion Matrix: [row->prediction - col->label]
[[613.   6.   8.  41. 145.]
 [  8. 539.  18.  10.  91.]
 [ 15.  16. 670.  16. 215.]
 [ 44.   5.  16. 460. 103.]
 [ 17.  12.  22.  11. 446.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.098 | Acc: 60.750% | Wgt Acc: 64.652% | Dur: 14.16s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  1.  2. 14. 15.]
 [ 2. 46. 10.  4. 21.]
 [ 3. 19. 51.  7. 38.]
 [14.  6.  7. 57. 15.]
 [ 6.  6.  5.  4. 91.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.378 | Acc: 80.875% | Wgt Acc: 89.110%
	I - Batch: 100 | Loss: 0.385 | Acc: 79.688% | Wgt Acc: 88.270%
	I - Batch: 150 | Loss: 0.386 | Acc: 78.792% | Wgt Acc: 88.177%
	I - Batch: 200 | Loss: 0.385 | Acc: 78.844% | Wgt Acc: 88.202%
I - num batch: 222
I - Train -- Loss: 0.381 | Acc: 78.996% | Wgt Acc: 88.454% | LR: 2.500000e-04 | Dur: 134.47s
I - Confusion Matrix: [row->prediction - col->label]
[[632.   2.   6.  42. 152.]
 [  2. 549.  10.   8.  93.]
 [ 10.  14. 697.  12. 187.]
 [ 37.   4.   9. 467. 111.]
 [ 16.   9.  12.   9. 457.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.179 | Acc: 58.185% | Wgt Acc: 63.499% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  4.  5. 17. 28.]
 [ 0. 39.  7.  0. 13.]
 [ 1. 18. 44.  3. 33.]
 [13. 10. 15. 61. 26.]
 [ 3.  7.  4.  5. 80.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.322 | Acc: 81.000% | Wgt Acc: 91.371%
	I - Batch: 100 | Loss: 0.319 | Acc: 81.562% | Wgt Acc: 91.289%
	I - Batch: 150 | Loss: 0.322 | Acc: 81.875% | Wgt Acc: 91.044%
	I - Batch: 200 | Loss: 0.324 | Acc: 81.781% | Wgt Acc: 90.790%
I - num batch: 222
I - Train -- Loss: 0.329 | Acc: 81.646% | Wgt Acc: 90.640% | LR: 1.250000e-04 | Dur: 137.38s
I - Confusion Matrix: [row->prediction - col->label]
[[635.   4.   5.  33. 150.]
 [  5. 559.   5.   3.  66.]
 [  7.  10. 711.   5. 191.]
 [ 30.   1.   6. 490.  92.]
 [ 20.   4.   7.   7. 501.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.103 | Acc: 61.736% | Wgt Acc: 63.222% | Dur: 14.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   5.   4.  18.  30.]
 [  0.  35.   6.   1.   6.]
 [  0.  17.  43.   3.  21.]
 [ 11.  10.  13.  60.  19.]
 [  6.  11.   9.   4. 104.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.301 | Acc: 82.250% | Wgt Acc: 90.984%
	I - Batch: 100 | Loss: 0.304 | Acc: 81.625% | Wgt Acc: 91.176%
	I - Batch: 150 | Loss: 0.309 | Acc: 81.833% | Wgt Acc: 91.041%
	I - Batch: 200 | Loss: 0.311 | Acc: 81.844% | Wgt Acc: 91.019%
I - num batch: 222
I - Train -- Loss: 0.307 | Acc: 82.210% | Wgt Acc: 91.227% | LR: 1.250000e-04 | Dur: 134.51s
I - Confusion Matrix: [row->prediction - col->label]
[[642.   6.   4.  27. 153.]
 [  2. 564.   8.   3.  87.]
 [  8.   6. 710.   4. 156.]
 [ 30.   0.   3. 494.  98.]
 [ 15.   2.   9.  10. 506.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.074 | Acc: 62.722% | Wgt Acc: 64.237% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   3.  15.  16.]
 [  1.  40.   4.   1.   8.]
 [  0.  17.  45.   5.  33.]
 [ 16.  11.  15.  62.  17.]
 [  6.   7.   8.   3. 106.]]

I - Local maximum validation set accuracy:  62.72

I - Validation set results: 
[14-1-2-1.59][50-3-4-0.52][124-2-2-2.80][127-0-0-5.68][443-2-2-3.04][567-0-0-2.86][573-1-1-2.41][615-0-0-2.82][695-1-2-2.42][722-3-0-2.91]
[826-0-0-4.79][878-0-0-4.09][1103-0-4-0.86][1212-3-3-1.31][1368-0-0-3.76][2181-2-3-0.77][2476-2-2-2.49][2721-2-2-3.05][2818-1-3-1.24][2886-2-1-1.88]
[3231-2-2-5.31][3333-2-3-1.22][3482-2-2-3.01][3536-3-3-2.17][3625-1-1-5.46][3909-0-0-3.97][4035-0-0-2.28][4140-0-0-2.22][4214-1-1-1.62][4346-1-3-1.29]
[4581-2-2-2.84][4708-3-2-1.51][4838-3-0-0.65][4845-1-3-0.40][4868-0-0-4.16][4939-0-1--0.17][4984-2-2-3.58][5078-1-4-1.27][5396-0-0-5.71][5479-1-1-2.41]
[5717-0-0-2.60][5843-1-1-0.84][5949-3-3-3.50][5987-2-4-1.74][6014-3-3-2.08][6033-3-3--0.07][6313-0-3-2.33][6421-3-3-3.57][6500-1-3-0.72][6583-3-3-2.78]
[6683-3-3-1.43][6825-2-1-0.73][6998-3-3-0.46][7049-3-3-1.07][7517-1-1-3.02][7521-1-1-0.93][7528-1-3-2.19][7949-1-2-3.11][8135-1-4-0.70][8185-3-0-5.51]
[8269-3-1-4.67][8273-3-3-2.58][8543-3-0-3.79][8666-1-1-2.47][8672-0-0-5.73][8903-1-1-2.42][9001-2-4-0.57][9036-2-2-3.64][9281-3-0-0.29][9300-2-2-6.43]
[9571-0-3-1.33][9617-1-1-0.27][9644-2-2-0.06][9705-2-0-0.37][9801-0-3-2.68][9803-3-3-1.65][9865-3-3-5.01][9896-2-2-3.35][10314-1-2-0.33][10337-3-3-4.34]
[10403-0-0-0.98][10653-2-3-0.79][10704-2-2-1.14][10719-1-1-4.03][10727-1-1-1.06][10836-0-0-8.40][10969-2-3-1.56][11042-0-0-0.16][11088-1-1-6.60][11322-0-0-6.00]
[11398-2-2-4.87][11499-0-0-3.15][11502-3-3-0.96][11512-3-3-3.31][11608-1-1-3.38][11610-0-0-1.82][11692-0-0-1.42][11905-0-0-2.98][11993-1-1-3.38][12002-2-3-2.65]
[12052-0-0-4.59][12201-0-3-4.03][12235-2-2-1.86][12320-1-4-2.65][12377-2-4-2.11][12398-2-3-0.09][12503-1-1-0.32][12617-0-3-0.86][12685-3-3--0.17][12738-2-4-0.77]
[12742-2-2-5.86][12823-0-3-2.89][13110-1-1-2.35][13240-3-3-3.42][13253-1-1-2.92][13273-0-0-6.97][13634-1-1-0.64][13763-2-2-1.22][13905-3-3-0.10][14060-2-2--0.13]
[14065-3-3-2.00][14147-3-3-3.06][14595-2-2-3.54][14687-2-2-3.30][14788-2-3-0.95][14869-1-1-3.05][14872-3-4-0.44][14877-1-1-3.43][14927-0-3-1.27][15066-0-0-4.03]
[15175-1-1-2.02][15178-2-0-0.31][15375-3-3-1.37][15389-3-3-3.68][15568-2-1-0.29][15675-3-3-4.44][15869-1-0-0.69][16207-3-0-0.71][16236-0-0-1.46][16302-3-0-0.24]
[16331-2-2-7.18][16381-0-0-1.28][16488-1-1-3.93][16495-0-0-5.27][16650-0-0-5.07][16719-1-2-1.70][16801-0-0-7.13][16828-0-0-3.42][17137-3-0-2.47][17245-1-2-0.24]
[17278-3-0-0.42][17282-0-0-0.01][17311-2-2-2.42][17336-2-1-1.07][17608-3-3-5.27][17627-0-0--0.17][17877-3-0-0.98][17924-1-3-0.67][17984-3-0-3.46][18211-0-3-2.66]
[18276-3-3-2.06][18287-1-2-1.00][18394-0-0-4.00][18428-0-0-1.90][18442-0-3-3.30][18478-3-3-3.59][18607-0-0-2.87][18616-0-0-1.43][18663-0-0-2.32][18718-0-0-4.38]
[18766-2-2-3.39][18824-2-2-2.49][18890-3-3-1.26][18930-3-4-1.22][18938-3-3-4.37][19817-1-2-2.27][19839-0-0-0.75][19930-3-3-2.08][19944-0-4-1.40][20036-2-2-4.92]
[20101-3-3-1.54][20474-1-1-3.98][20547-3-3-1.03][20929-2-2-5.08][21245-1-2-1.52][21257-3-3--0.03][21293-1-2-3.26][21316-1-1-1.62][21384-1-1-3.73][21448-1-2-1.61]
[21483-0-0-3.91][21487-2-2-5.37][21714-0-3-1.09][21943-3-2-0.52][21947-0-0-2.63][21948-0-0-7.30][21965-2-2-4.03][21998-1-1-2.69][22025-0-4-0.20][22228-3-3-5.31]
[22446-1-1-3.70][22494-3-0-3.31][22757-0-0-4.79][22811-3-3-4.91][22976-3-2-1.42][22985-3-3-3.97][23014-0-3-3.40][23112-1-1-3.57][23144-3-3-4.99][23168-2-3--0.15]
[23219-0-4-1.57][23363-3-3-4.57][23470-0-0-2.10][23486-2-2-0.71][23497-0-3-4.59][23516-0-0-4.86][23690-1-3-1.41][23921-2-2-2.96][23936-1-2-0.80][24040-3-2-0.20]
[24111-1-4-1.82][24182-0-0-4.39][24238-3-3-3.11][24290-2-0-3.13][24345-0-0-2.00][24364-1-2-1.15][24427-3-0-3.15][24477-2-2-4.90][24495-2-4-0.05][24893-2-2-2.01]
[25012-1-3--0.26][25121-2-2-2.24][25165-3-3-0.98][25183-0-0-3.97][25297-3-3-2.44][25398-0-0-2.30][25574-2-2-3.05][25644-1-1-3.79][25718-1-0--0.35][25774-2-3-0.66]
[26032-3-3-2.74][26051-3-3-4.06][26120-0-4-3.47][26321-1-4-0.14][26732-1-1-3.21][26784-3-3-5.98][26827-3-3-2.78][26833-0-3-3.87][26838-2-3-1.39][26860-1-2-1.07]
[26948-0-0-2.82][27049-3-0-2.28][27098-1-0-0.61][27526-0-0-4.31][27639-3-3-2.06][27698-3-3-4.65][27772-0-0-4.49][27890-1-1-2.39][28040-0-0-1.09][28503-2-2-5.55]
[28577-1-1-5.35][28959-0-0-5.04][29198-3-3-0.82][29777-0-0-7.49][29877-2-2-0.78][30035-1-1-3.73][30098-0-3-1.90][30326-1-1-3.20][30572-2-2-3.12][30716-0-4-1.97]
[30806-2-3-1.08][30906-1-1-4.44][31007-0-0-1.60][31181-3-3-1.41][31238-0-3-2.12][31347-0-0-4.35][31422-2-2-2.15][31429-3-3-0.62][31431-0-0-2.43][31432-1-1-3.02]
[31477-0-0-3.85][31524-1-3-0.36][31597-1-4-0.50][31619-1-4-0.30][31701-0-0-4.79][31755-0-0-2.99][31854-3-3-4.29][32074-1-3-2.35][32078-3-3-4.35][32111-1-1-1.46]
[32127-1-2-1.67][32140-3-3-4.26][32263-2-4-0.45][32365-0-0-3.40][32411-2-3-3.93][32429-3-3-2.51][32473-3-0-0.83][32574-3-3-4.16][32584-0-0-2.38][32622-0-0--0.39]
[32858-3-3-2.19][32969-3-3-2.50][33016-2-2-3.18][33031-1-3-2.56][33035-2-2-2.84][33133-2-2-2.10][33173-2-2-0.38][33175-3-2-0.51][33306-3-3-1.24][33309-2-3-1.36]
[33474-0-0-0.46][33478-2-3--0.35][33618-1-1-2.30][33712-0-3-2.21][33782-2-4-1.76][33914-3-3-5.04][34076-3-3-1.59][34112-2-2-2.63][34138-2-3-0.74][34239-1-1-0.99]
[34364-2-2-4.49][34617-1-2-1.70][34751-3-3-4.46][34783-2-4-1.46][35015-3-3-1.28][35018-1-2-1.21][35288-2-2-0.21][0-4-4-2.48][1-4-4-1.56][2-4-4-1.53]
[3-4-4-2.18][4-4-4-0.36][5-4-1-1.42][6-4-4-3.62][7-4-4-3.59][8-4-4-0.57][9-4-0-0.16][10-4-4-3.58][11-4-4-3.18][12-4-2--0.20]
[14-4-3-1.28][15-4-3-3.07][16-4-4-1.81][17-4-4--0.12][18-4-4-3.05][19-4-0-2.37][20-4-3-0.76][21-4-4-0.99][22-4-4-1.78][23-4-4-0.22]
[24-4-4-5.19][25-4-3-1.70][26-4-3-0.49][27-4-4-0.40][28-4-4-1.71][29-4-2-1.09][30-4-4-0.49][31-4-2-0.45][32-4-4-1.27][33-4-4-0.13]
[34-4-4-0.53][35-4-0-2.81][37-4-0-2.00][39-4-0-1.76][40-4-4-0.16][41-4-4-0.77][42-4-4-0.82][43-4-2-0.70][45-4-2-2.47][46-4-4-3.82]
[47-4-4-3.69][48-4-4-1.78][51-4-4-2.46][52-4-4-1.27][53-4-2-0.43][54-4-3-0.96][55-4-2-1.57][56-4-1-0.84][57-4-3-1.84][58-4-2-4.29]
[59-4-0-1.73][60-4-4-2.06][61-4-4-2.03][62-4-2-1.36][63-4-2-4.17][64-4-4-0.61][65-4-4-3.59][66-4-4-2.05][67-4-3-0.04][68-4-4-0.03]
[69-4-0-1.23][70-4-4-2.29][72-4-2-1.44][73-4-1-0.29][74-4-2-2.69][75-4-0-0.39][77-4-4-3.53][78-4-3--0.02][79-4-4-2.14][80-4-4-2.28]
[81-4-4-2.81][82-4-1-0.85][83-4-4-1.10][84-4-4-2.33][85-4-4-2.76][86-4-4-0.88][87-4-4-2.87][88-4-4-1.66][89-4-2--0.39][90-4-4-0.58]
[91-4-4-0.91][92-4-4--0.06][93-4-0-1.38][94-4-4-2.11][95-4-4-0.56][96-4-4-0.79][97-4-4-2.29][98-4-2-1.92][99-4-4-0.27][100-4-1-1.04]
[101-4-4-4.49][102-4-4-1.25][103-4-0-0.11][104-4-4-1.12][105-4-2-1.78][106-4-4-1.92][107-4-0-1.38][108-4-4-1.05][109-4-4-1.03][110-4-4-2.40]
[111-4-0-3.66][112-4-4-0.60][113-4-3-0.43][114-4-3-0.11][115-4-4-0.88][116-4-2-0.67][117-4-4-2.13][119-4-4-1.04][121-4-4-1.59][122-4-4-1.70]
[124-4-3-0.12][125-4-4-1.48][126-4-4-3.54][127-4-2-2.48][128-4-0-0.15][129-4-4-1.14][130-4-4-1.23][131-4-2-0.75][132-4-2-0.96][133-4-4-2.67]
[135-4-4-1.27][136-4-4-0.95][137-4-4-0.68][138-4-4-0.99][139-4-4-1.21][140-4-1-0.69][141-4-2-1.00][142-4-4-4.00][143-4-4-1.81][144-4-4-2.62]
[145-4-2-1.58][148-4-0-3.91][149-4-4-1.93][150-4-4-3.42][151-4-4-1.46][152-4-4-2.19][153-4-2-2.89][154-4-4-2.36][155-4-4-1.72][156-4-3-1.54]
[157-4-2-0.24][158-4-3-1.42][160-4-1-0.45][161-4-2-1.90][162-4-2-0.96][164-4-4-1.04][165-4-4-0.98][167-4-4-1.91][168-4-4-0.98][170-4-3-1.71]
[171-4-4-1.32][172-4-4-2.25][173-4-4-2.98][174-4-0-2.29][175-4-4-1.69][177-4-4-0.29][178-4-2-1.29][179-4-4-0.39][180-4-4-2.60][181-4-3-2.53]
[182-4-1-1.08][183-4-4-1.63][184-4-2-1.74][186-4-0-0.95][187-4-2-1.43][188-4-2-1.47][189-4-4-0.94][190-4-4-0.35][191-4-4-2.63][192-4-4-0.56]
[193-4-2-2.98][194-4-3-1.42][195-4-2-1.04][196-4-2-1.03][197-4-4-1.84][198-4-4-5.70][199-4-2-1.20]
---------------------------
I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.311 | Acc: 82.875% | Wgt Acc: 92.333%
	I - Batch: 100 | Loss: 0.302 | Acc: 82.812% | Wgt Acc: 92.326%
	I - Batch: 150 | Loss: 0.299 | Acc: 83.458% | Wgt Acc: 92.169%
	I - Batch: 200 | Loss: 0.306 | Acc: 82.656% | Wgt Acc: 91.615%
I - num batch: 222
I - Train -- Loss: 0.303 | Acc: 82.690% | Wgt Acc: 91.610% | LR: 1.250000e-04 | Dur: 137.59s
I - Confusion Matrix: [row->prediction - col->label]
[[651.   1.   3.  27. 133.]
 [  4. 565.   5.   3.  73.]
 [  4.   5. 708.   5. 174.]
 [ 23.   2.   5. 495. 106.]
 [ 15.   5.  13.   8. 514.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.082 | Acc: 61.144% | Wgt Acc: 66.451% | Dur: 18.77s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  3.  2. 11. 16.]
 [ 1. 42. 10.  2. 19.]
 [ 2. 18. 51.  4. 37.]
 [16. 10. 10. 69. 22.]
 [ 7.  5.  2.  0. 86.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.279 | Acc: 84.125% | Wgt Acc: 92.616%
	I - Batch: 100 | Loss: 0.279 | Acc: 83.625% | Wgt Acc: 92.366%
	I - Batch: 150 | Loss: 0.284 | Acc: 84.167% | Wgt Acc: 92.611%
	I - Batch: 200 | Loss: 0.293 | Acc: 83.844% | Wgt Acc: 92.198%
I - num batch: 222
I - Train -- Loss: 0.291 | Acc: 83.620% | Wgt Acc: 92.220% | LR: 1.250000e-04 | Dur: 134.26s
I - Confusion Matrix: [row->prediction - col->label]
[[651.   0.   2.  26. 144.]
 [  2. 570.   3.   0.  72.]
 [  5.   6. 709.   4. 155.]
 [ 26.   0.   6. 501.  94.]
 [ 13.   2.  14.   7. 535.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.118 | Acc: 58.777% | Wgt Acc: 64.814% | Dur: 14.26s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  2.  2. 16. 20.]
 [ 2. 48. 13.  0. 21.]
 [ 3. 18. 48.  8. 46.]
 [16.  7.  7. 61. 15.]
 [ 4.  3.  5.  1. 78.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.264 | Acc: 84.375% | Wgt Acc: 92.764%
	I - Batch: 100 | Loss: 0.286 | Acc: 82.938% | Wgt Acc: 91.914%
	I - Batch: 150 | Loss: 0.283 | Acc: 82.667% | Wgt Acc: 91.989%
	I - Batch: 200 | Loss: 0.286 | Acc: 82.500% | Wgt Acc: 91.675%
I - num batch: 222
I - Train -- Loss: 0.288 | Acc: 82.379% | Wgt Acc: 91.693% | LR: 1.250000e-04 | Dur: 135.68s
I - Confusion Matrix: [row->prediction - col->label]
[[652.   2.   5.  22. 136.]
 [  3. 564.   4.   3.  82.]
 [  3.   6. 713.   7. 169.]
 [ 20.   3.   2. 496. 116.]
 [ 19.   3.  10.  10. 497.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.068 | Acc: 61.144% | Wgt Acc: 63.314% | Dur: 19.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   2.   2.  12.  16.]
 [  3.  38.   7.   0.   4.]
 [  2.  23.  52.   7.  45.]
 [ 16.   6.   9.  61.  15.]
 [  8.   9.   5.   6. 100.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.240 | Acc: 84.500% | Wgt Acc: 93.458%
	I - Batch: 100 | Loss: 0.246 | Acc: 84.188% | Wgt Acc: 93.119%
	I - Batch: 150 | Loss: 0.256 | Acc: 84.292% | Wgt Acc: 93.134%
	I - Batch: 200 | Loss: 0.258 | Acc: 84.219% | Wgt Acc: 93.191%
I - num batch: 222
I - Train -- Loss: 0.260 | Acc: 84.184% | Wgt Acc: 93.106% | LR: 6.250000e-05 | Dur: 133.56s
I - Confusion Matrix: [row->prediction - col->label]
[[662.   0.   0.  22. 121.]
 [  3. 570.   4.   1.  78.]
 [  1.   3. 719.   4. 171.]
 [ 18.   3.   3. 506. 101.]
 [ 13.   2.   8.   5. 529.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.043 | Acc: 62.130% | Wgt Acc: 64.837% | Dur: 14.19s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  2. 14. 20.]
 [ 0. 41. 10.  1.  8.]
 [ 2. 19. 47.  5. 36.]
 [11.  7. 10. 59. 17.]
 [ 6.  6.  6.  7. 99.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.242 | Acc: 87.750% | Wgt Acc: 94.976%
	I - Batch: 100 | Loss: 0.238 | Acc: 87.000% | Wgt Acc: 94.660%
	I - Batch: 150 | Loss: 0.241 | Acc: 86.000% | Wgt Acc: 94.144%
	I - Batch: 200 | Loss: 0.239 | Acc: 86.375% | Wgt Acc: 94.330%
I - num batch: 208
I - Train -- Loss: 0.238 | Acc: 86.418% | Wgt Acc: 94.398% | LR: 6.250000e-05 | Dur: 126.41s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   1.   3.  13. 111.]
 [  0. 573.   0.   2.  71.]
 [  6.   4. 720.   2. 131.]
 [ 11.   0.   5. 513.  68.]
 [ 10.   0.   6.   8. 400.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.031 | Acc: 61.933% | Wgt Acc: 63.903% | Dur: 14.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   2.   3.  11.  11.]
 [  1.  43.   7.   0.  11.]
 [  2.  16.  44.   5.  35.]
 [ 16.   9.  12.  65.  20.]
 [ 10.   8.   9.   5. 103.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.222 | Acc: 85.375% | Wgt Acc: 94.606%
	I - Batch: 100 | Loss: 0.236 | Acc: 85.750% | Wgt Acc: 94.384%
	I - Batch: 150 | Loss: 0.239 | Acc: 86.125% | Wgt Acc: 94.588%
	I - Batch: 200 | Loss: 0.237 | Acc: 86.344% | Wgt Acc: 94.591%
I - num batch: 222
I - Train -- Loss: 0.236 | Acc: 86.637% | Wgt Acc: 94.681% | LR: 6.250000e-05 | Dur: 138.19s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   1.   1.  10. 128.]
 [  2. 570.   0.   1.  54.]
 [  3.   6. 725.   0. 137.]
 [  9.   0.   0. 523.  96.]
 [ 13.   1.   8.   4. 585.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.055 | Acc: 63.314% | Wgt Acc: 64.664% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   2.  13.  14.]
 [  2.  42.   7.   2.   9.]
 [  1.  17.  45.   2.  28.]
 [ 13.   9.  17.  63.  21.]
 [  9.   6.   4.   6. 108.]]

I - Local maximum validation set accuracy:  63.31

I - Validation set results: 
[14-1-2-1.05][50-3-4-0.84][124-2-2-1.56][127-0-0-6.89][443-2-2-3.57][567-0-0-2.92][573-1-1-3.02][615-0-0-2.49][695-1-2-2.00][722-3-0-4.36]
[826-0-0-5.04][878-0-0-3.02][1103-0-0-1.08][1212-3-3-0.41][1368-0-0-3.82][2181-2-3-0.88][2476-2-2-1.26][2721-2-2-1.85][2818-1-4-1.01][2886-2-1-2.36]
[3231-2-2-4.49][3333-2-1-0.93][3482-2-2-2.99][3536-3-3-2.78][3625-1-1-5.51][3909-0-0-3.52][4035-0-0-3.44][4140-0-0-1.83][4214-1-3-1.45][4346-1-3-1.58]
[4581-2-2-1.81][4708-3-2-1.18][4838-3-4--0.48][4845-1-3-0.58][4868-0-0-6.49][4939-0-1-0.17][4984-2-2-2.87][5078-1-2-1.00][5396-0-0-6.75][5479-1-1-2.55]
[5717-0-0-4.45][5843-1-1-1.67][5949-3-3-3.32][5987-2-4-2.35][6014-3-3-2.20][6033-3-3-0.91][6313-0-3-2.24][6421-3-3-3.26][6500-1-2-0.26][6583-3-3-3.05]
[6683-3-3-1.66][6825-2-1-1.23][6998-3-0-0.59][7049-3-3-1.06][7517-1-1-3.72][7521-1-1-0.57][7528-1-3-1.71][7949-1-2-3.16][8135-1-3-0.65][8185-3-0-6.10]
[8269-3-1-1.84][8273-3-3-2.41][8543-3-0-5.79][8666-1-1-3.60][8672-0-0-6.75][8903-1-2-1.95][9001-2-1-1.96][9036-2-2-3.46][9281-3-3-0.26][9300-2-2-7.09]
[9571-0-3-0.59][9617-1-4-1.56][9644-2-2-1.39][9705-2-0-0.60][9801-0-3-2.44][9803-3-3-1.66][9865-3-3-5.23][9896-2-2-1.50][10314-1-1--0.25][10337-3-3-3.99]
[10403-0-4-1.09][10653-2-2-0.15][10704-2-2-0.74][10719-1-1-4.36][10727-1-1-0.67][10836-0-0-10.53][10969-2-3-1.24][11042-0-0-1.70][11088-1-1-4.03][11322-0-0-6.14]
[11398-2-2-4.86][11499-0-0-3.66][11502-3-3-0.74][11512-3-3-1.52][11608-1-1-4.11][11610-0-0-2.60][11692-0-0-2.41][11905-0-3-1.87][11993-1-1-2.55][12002-2-3-0.50]
[12052-0-0-5.49][12201-0-3-3.64][12235-2-2-0.59][12320-1-4-2.98][12377-2-4-1.94][12398-2-3-0.44][12503-1-2-2.40][12617-0-3-0.74][12685-3-3-1.81][12738-2-3-0.22]
[12742-2-2-5.09][12823-0-0-4.06][13110-1-1-0.23][13240-3-3-2.77][13253-1-1-2.61][13273-0-0-7.39][13634-1-1-0.34][13763-2-3-0.68][13905-3-3-0.90][14060-2-1-1.72]
[14065-3-0-2.08][14147-3-3-3.45][14595-2-2-1.72][14687-2-2-3.38][14788-2-3-1.38][14869-1-1-2.53][14872-3-4-1.10][14877-1-1-4.13][14927-0-0-1.71][15066-0-0-5.38]
[15175-1-1-2.20][15178-2-3-0.63][15375-3-0-1.81][15389-3-3-3.76][15568-2-1-1.19][15675-3-3-3.85][15869-1-0-1.05][16207-3-0-1.22][16236-0-0-0.57][16302-3-3-0.29]
[16331-2-2-7.72][16381-0-4-0.93][16488-1-1-3.85][16495-0-0-4.48][16650-0-0-4.52][16719-1-2-2.58][16801-0-0-6.79][16828-0-0-3.96][17137-3-0-2.73][17245-1-2--0.32]
[17278-3-1--0.30][17282-0-2-2.16][17311-2-2-2.51][17336-2-3--0.46][17608-3-3-4.38][17627-0-0-2.31][17877-3-0-2.12][17924-1-3-1.82][17984-3-0-4.64][18211-0-3-2.27]
[18276-3-3-1.32][18287-1-2-0.67][18394-0-0-3.63][18428-0-0-6.65][18442-0-3-3.00][18478-3-3-3.44][18607-0-0-2.38][18616-0-0-1.86][18663-0-0-3.18][18718-0-0-5.03]
[18766-2-2-0.42][18824-2-2-2.37][18890-3-3-1.56][18930-3-4-1.02][18938-3-3-4.07][19817-1-1-3.56][19839-0-0-1.06][19930-3-3-2.57][19944-0-4-1.20][20036-2-2-6.18]
[20101-3-3-1.49][20474-1-1-3.59][20547-3-3-1.40][20929-2-2-4.63][21245-1-2-1.54][21257-3-3-1.77][21293-1-1-3.92][21316-1-1-0.90][21384-1-1-2.46][21448-1-2-1.37]
[21483-0-0-3.32][21487-2-2-3.11][21714-0-3-0.52][21943-3-3-0.93][21947-0-0-4.51][21948-0-0-7.47][21965-2-2-2.38][21998-1-1-2.11][22025-0-4-0.09][22228-3-3-5.69]
[22446-1-1-2.82][22494-3-0-2.57][22757-0-0-4.15][22811-3-3-5.07][22976-3-4-1.70][22985-3-3-3.81][23014-0-0-4.20][23112-1-1-3.37][23144-3-3-5.25][23168-2-3-0.81]
[23219-0-0-1.13][23363-3-3-4.19][23470-0-0-1.77][23486-2-2-1.21][23497-0-3-4.70][23516-0-0-5.16][23690-1-4-2.61][23921-2-2-0.74][23936-1-0--0.43][24040-3-4--0.10]
[24111-1-4-1.89][24182-0-0-7.37][24238-3-3-2.95][24290-2-0-2.54][24345-0-4-0.10][24364-1-2-2.27][24427-3-0-2.68][24477-2-2-3.17][24495-2-1-1.67][24893-2-2-1.32]
[25012-1-2-0.21][25121-2-2-2.26][25165-3-3-0.89][25183-0-0-4.81][25297-3-3-2.75][25398-0-0-3.23][25574-2-2-1.66][25644-1-1-3.06][25718-1-3-0.72][25774-2-3-0.15]
[26032-3-3-2.89][26051-3-3-4.71][26120-0-4-2.37][26321-1-1-6.04][26732-1-1-1.79][26784-3-3-6.41][26827-3-3-2.44][26833-0-3-3.44][26838-2-3-1.05][26860-1-2-0.94]
[26948-0-0-2.76][27049-3-0-2.99][27098-1-0-0.95][27526-0-0-4.86][27639-3-3-1.67][27698-3-3-4.66][27772-0-0-4.95][27890-1-1-3.16][28040-0-4-2.29][28503-2-2-4.26]
[28577-1-1-4.82][28959-0-0-5.57][29198-3-3-0.68][29777-0-0-7.84][29877-2-2-0.28][30035-1-1-3.36][30098-0-0-1.59][30326-1-1-3.43][30572-2-2-1.16][30716-0-4-2.14]
[30806-2-3-0.52][30906-1-1-4.89][31007-0-0-2.16][31181-3-3-1.14][31238-0-0-2.20][31347-0-0-5.06][31422-2-2-0.75][31429-3-3-1.45][31431-0-0--0.17][31432-1-1-1.65]
[31477-0-3-3.60][31524-1-0-0.43][31597-1-4-0.56][31619-1-2-0.58][31701-0-0-4.94][31755-0-0-4.01][31854-3-3-3.87][32074-1-3-0.05][32078-3-3-4.14][32111-1-1-1.61]
[32127-1-1-2.60][32140-3-3-4.74][32263-2-4-0.33][32365-0-0-5.35][32411-2-3-3.35][32429-3-3-3.23][32473-3-3-0.55][32574-3-3-3.80][32584-0-0-2.30][32622-0-1-0.50]
[32858-3-3-2.17][32969-3-3-2.72][33016-2-2-3.06][33031-1-3-2.71][33035-2-2-3.80][33133-2-2-1.03][33173-2-2-0.14][33175-3-2-0.19][33306-3-3-1.73][33309-2-3-1.47]
[33474-0-4-0.23][33478-2-3-0.05][33618-1-1-2.34][33712-0-3-2.12][33782-2-4-1.21][33914-3-3-3.66][34076-3-3-1.66][34112-2-2-4.29][34138-2-3-0.65][34239-1-1-1.11]
[34364-2-2-3.01][34617-1-2-2.76][34751-3-3-4.11][34783-2-2-1.26][35015-3-3-1.29][35018-1-1-0.86][35288-2-2-0.16][0-4-4-2.13][1-4-4-3.63][2-4-4-1.75]
[3-4-4-3.27][4-4-4-1.80][5-4-1-0.65][6-4-4-2.62][7-4-4-1.47][8-4-3-0.53][9-4-1--0.01][10-4-4-4.48][11-4-2-1.95][12-4-4-0.73]
[14-4-3-1.36][15-4-3-2.58][16-4-4-2.17][17-4-4-1.30][18-4-4-3.99][19-4-3-1.83][20-4-0-1.60][21-4-2-0.62][22-4-4-2.09][23-4-4-0.81]
[24-4-4-5.70][25-4-3-1.50][26-4-3-0.89][27-4-4-0.83][28-4-4-1.66][29-4-1-1.20][30-4-0-0.80][31-4-2-0.77][32-4-4-1.59][33-4-2-0.46]
[34-4-4-0.87][35-4-0-2.53][37-4-4-1.01][39-4-0-5.38][40-4-2-0.35][41-4-4--0.17][42-4-4-0.18][43-4-4--0.20][45-4-2-1.92][46-4-4-4.47]
[47-4-4-4.08][48-4-4-2.15][51-4-4-3.72][52-4-4-2.20][53-4-2-0.67][54-4-4-0.34][55-4-3-0.54][56-4-1-1.37][57-4-3-1.98][58-4-2-3.16]
[59-4-0-2.97][60-4-2--0.38][61-4-4-2.46][62-4-2-0.66][63-4-4-1.80][64-4-2-0.01][65-4-4-3.89][66-4-4-2.13][67-4-3-0.10][68-4-3-0.46]
[69-4-3-0.62][70-4-4-2.79][72-4-4-1.44][73-4-1-1.46][74-4-2-2.30][75-4-3--0.24][77-4-4-3.50][78-4-3-1.06][79-4-2-2.40][80-4-4-1.81]
[81-4-4-3.05][82-4-1-1.03][83-4-4-0.70][84-4-4-4.02][85-4-4-3.01][86-4-1-0.07][87-4-4-3.02][88-4-4-2.44][89-4-4-1.97][90-4-4-1.77]
[91-4-4-2.07][92-4-4-0.50][93-4-0-1.26][94-4-4-2.85][95-4-3-0.00][96-4-2-0.77][97-4-4-2.62][98-4-2-1.40][99-4-4-1.69][100-4-4-1.06]
[101-4-4-5.81][102-4-4-0.58][103-4-3-0.75][104-4-4-1.34][105-4-4-1.56][106-4-4-3.01][107-4-1-0.73][108-4-4-0.89][109-4-4-0.48][110-4-4-1.91]
[111-4-0-3.78][112-4-4-0.59][113-4-2-0.35][114-4-3-0.64][115-4-4-1.25][116-4-0-0.68][117-4-4-2.50][119-4-4-0.33][121-4-4-2.22][122-4-4-2.44]
[124-4-4--0.31][125-4-4-2.05][126-4-4-4.26][127-4-2-2.68][128-4-0-0.82][129-4-4-1.35][130-4-4-1.42][131-4-2-1.23][132-4-4-1.43][133-4-4-4.50]
[135-4-2-0.18][136-4-4--0.15][137-4-4-0.99][138-4-4-0.34][139-4-4-1.97][140-4-1-2.03][141-4-3-0.93][142-4-4-4.84][143-4-4-1.81][144-4-4-3.01]
[145-4-4-2.45][148-4-0-3.88][149-4-4-1.86][150-4-4-3.18][151-4-4-1.69][152-4-4-2.31][153-4-4-2.30][154-4-4-5.21][155-4-4-2.53][156-4-3-1.37]
[157-4-0-0.41][158-4-4-1.57][160-4-2-0.64][161-4-2-1.03][162-4-2--0.10][164-4-4-0.97][165-4-4-1.03][167-4-4-2.44][168-4-4-1.46][170-4-4-0.31]
[171-4-4-1.80][172-4-4-2.04][173-4-4-4.37][174-4-0-2.57][175-4-4-1.24][177-4-4-3.58][178-4-2-1.60][179-4-4-0.86][180-4-4-3.14][181-4-3-2.46]
[182-4-3-1.18][183-4-4-1.83][184-4-2-2.07][186-4-0-0.01][187-4-2-0.84][188-4-2-0.95][189-4-4-0.70][190-4-4--0.14][191-4-4-1.37][192-4-0-0.33]
[193-4-2-2.64][194-4-3-1.54][195-4-4--0.05][196-4-4-1.16][197-4-4-1.19][198-4-4-6.05][199-4-2-0.80]
---------------------------
I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.226 | Acc: 87.000% | Wgt Acc: 95.370%
	I - Batch: 100 | Loss: 0.230 | Acc: 86.688% | Wgt Acc: 94.552%
	I - Batch: 150 | Loss: 0.233 | Acc: 86.292% | Wgt Acc: 94.266%
	I - Batch: 200 | Loss: 0.234 | Acc: 86.312% | Wgt Acc: 94.295%
I - num batch: 222
I - Train -- Loss: 0.233 | Acc: 86.665% | Wgt Acc: 94.440% | LR: 6.250000e-05 | Dur: 136.24s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   0.   2.  15. 107.]
 [  0. 574.   0.   2.  65.]
 [  3.   0. 723.   2. 140.]
 [  9.   0.   1. 512.  94.]
 [ 14.   4.   8.   7. 594.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.075 | Acc: 62.327% | Wgt Acc: 64.445% | Dur: 17.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   4.   4.  11.  22.]
 [  2.  44.   9.   0.   8.]
 [  1.  14.  42.   4.  28.]
 [ 17.  11.  14.  65.  19.]
 [  6.   5.   6.   6. 103.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.210 | Acc: 87.875% | Wgt Acc: 95.653%
	I - Batch: 100 | Loss: 0.227 | Acc: 86.500% | Wgt Acc: 94.962%
	I - Batch: 150 | Loss: 0.229 | Acc: 86.542% | Wgt Acc: 94.761%
	I - Batch: 200 | Loss: 0.229 | Acc: 86.531% | Wgt Acc: 94.741%
I - num batch: 222
I - Train -- Loss: 0.229 | Acc: 86.326% | Wgt Acc: 94.540% | LR: 6.250000e-05 | Dur: 137.92s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   1.   1.   8. 132.]
 [  1. 569.   3.   2.  64.]
 [  3.   4. 724.   1. 144.]
 [  8.   1.   3. 523.  84.]
 [ 15.   3.   3.   4. 576.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.060 | Acc: 62.525% | Wgt Acc: 65.932% | Dur: 14.92s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  3.  2. 11. 15.]
 [ 2. 46.  9.  1. 17.]
 [ 1. 16. 54.  6. 39.]
 [19.  6.  5. 63. 12.]
 [ 9.  7.  5.  5. 97.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.245 | Acc: 85.750% | Wgt Acc: 93.282%
	I - Batch: 100 | Loss: 0.242 | Acc: 85.500% | Wgt Acc: 93.565%
	I - Batch: 150 | Loss: 0.232 | Acc: 86.417% | Wgt Acc: 94.320%
	I - Batch: 200 | Loss: 0.231 | Acc: 86.562% | Wgt Acc: 94.438%
I - num batch: 222
I - Train -- Loss: 0.230 | Acc: 86.496% | Wgt Acc: 94.477% | LR: 6.250000e-05 | Dur: 137.42s
I - Confusion Matrix: [row->prediction - col->label]
[[673.   1.   4.  15. 134.]
 [  0. 570.   2.   1.  58.]
 [  1.   1. 726.   1. 149.]
 [  8.   1.   1. 514.  74.]
 [ 15.   5.   1.   7. 585.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 64.892% | Wgt Acc: 65.494% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   3.  14.  19.]
 [  0.  42.   5.   0.   9.]
 [  1.  10.  46.   2.  23.]
 [ 14.   9.  13.  61.  15.]
 [  7.  13.   8.   9. 114.]]

I - Local maximum validation set accuracy:  64.89

I - Validation set results: 
[14-1-2-0.50][50-3-4-1.21][124-2-2-1.69][127-0-0-6.13][443-2-2-3.99][567-0-0-3.06][573-1-1-3.33][615-0-0-2.59][695-1-2-1.57][722-3-0-4.01]
[826-0-0-3.86][878-0-0-5.81][1103-0-0-1.24][1212-3-3-0.57][1368-0-0-4.51][2181-2-3-1.27][2476-2-2-1.50][2721-2-2-1.71][2818-1-4-0.35][2886-2-1-1.50]
[3231-2-2-4.14][3333-2-3-0.28][3482-2-2-2.74][3536-3-3-2.14][3625-1-1-4.92][3909-0-0-2.80][4035-0-0-2.65][4140-0-0-2.16][4214-1-3-1.73][4346-1-3-1.74]
[4581-2-2-2.03][4708-3-2-1.00][4838-3-0--0.17][4845-1-3-0.63][4868-0-0-5.05][4939-0-3--0.20][4984-2-2-3.96][5078-1-4-0.95][5396-0-0-6.15][5479-1-1-1.86]
[5717-0-0-2.11][5843-1-1-3.18][5949-3-3-3.16][5987-2-4-1.95][6014-3-3-1.80][6033-3-3-0.55][6313-0-3-1.98][6421-3-3-2.44][6500-1-2-1.45][6583-3-3-3.16]
[6683-3-3-1.97][6825-2-1-1.68][6998-3-0-1.70][7049-3-3-0.91][7517-1-1-3.93][7521-1-0--0.14][7528-1-3-1.99][7949-1-2-2.87][8135-1-3-0.67][8185-3-0-5.54]
[8269-3-4-1.02][8273-3-3-2.43][8543-3-0-4.24][8666-1-1-2.73][8672-0-0-4.95][8903-1-1-1.22][9001-2-2-1.28][9036-2-2-4.67][9281-3-0-1.42][9300-2-2-6.70]
[9571-0-3-0.54][9617-1-4-1.16][9644-2-2-0.68][9705-2-0-0.58][9801-0-3-2.29][9803-3-3-2.46][9865-3-3-4.08][9896-2-2-1.21][10314-1-4-0.58][10337-3-3-4.46]
[10403-0-4-1.14][10653-2-1-0.28][10704-2-2-1.11][10719-1-1-4.32][10727-1-4-0.40][10836-0-0-9.46][10969-2-3-1.75][11042-0-0-2.57][11088-1-1-5.86][11322-0-0-6.30]
[11398-2-2-3.92][11499-0-0-4.10][11502-3-3-0.28][11512-3-3-2.36][11608-1-1-3.84][11610-0-0-3.85][11692-0-0-2.13][11905-0-0-2.91][11993-1-1-3.27][12002-2-2-1.02]
[12052-0-0-4.85][12201-0-3-2.97][12235-2-2-0.74][12320-1-0-2.63][12377-2-4-1.83][12398-2-3-0.04][12503-1-1-0.47][12617-0-3-0.69][12685-3-3-1.89][12738-2-3-0.06]
[12742-2-2-4.49][12823-0-0-4.05][13110-1-1-2.14][13240-3-3-2.64][13253-1-4-1.28][13273-0-0-7.24][13634-1-1--0.06][13763-2-3-0.62][13905-3-3-0.45][14060-2-2-0.73]
[14065-3-0-2.72][14147-3-3-3.20][14595-2-2-1.50][14687-2-2-3.13][14788-2-2-1.93][14869-1-1-1.97][14872-3-4-1.16][14877-1-1-3.83][14927-0-3-1.32][15066-0-0-4.84]
[15175-1-1-2.10][15178-2-3-0.32][15375-3-0-0.68][15389-3-3-3.38][15568-2-4-1.40][15675-3-3-4.91][15869-1-0-0.78][16207-3-0-1.03][16236-0-0-1.29][16302-3-2-1.47]
[16331-2-2-7.31][16381-0-3-0.66][16488-1-1-5.57][16495-0-0-4.58][16650-0-0-5.54][16719-1-2-1.92][16801-0-0-7.44][16828-0-0-4.19][17137-3-0-1.49][17245-1-4--0.10]
[17278-3-0-0.77][17282-0-2-2.15][17311-2-2-1.45][17336-2-1-0.39][17608-3-3-2.86][17627-0-0-0.86][17877-3-4-1.91][17924-1-3-1.28][17984-3-0-4.90][18211-0-3-2.22]
[18276-3-3-1.73][18287-1-1-1.15][18394-0-0-3.65][18428-0-0-2.18][18442-0-3-2.35][18478-3-3-2.88][18607-0-0-2.31][18616-0-0-3.03][18663-0-0-2.82][18718-0-0-4.49]
[18766-2-2-2.43][18824-2-2-2.17][18890-3-3-1.82][18930-3-4-1.04][18938-3-3-3.40][19817-1-1-2.36][19839-0-0-0.89][19930-3-3-2.32][19944-0-4-0.49][20036-2-2-6.22]
[20101-3-3-3.09][20474-1-1-4.07][20547-3-3-1.45][20929-2-2-5.20][21245-1-2-0.52][21257-3-3-1.70][21293-1-1-2.73][21316-1-1-5.13][21384-1-1-3.61][21448-1-1-2.07]
[21483-0-0-3.03][21487-2-2-2.77][21714-0-3-0.60][21943-3-3-1.02][21947-0-0-1.85][21948-0-0-7.87][21965-2-2-3.48][21998-1-1-3.99][22025-0-4-0.60][22228-3-3-5.84]
[22446-1-1-3.92][22494-3-3-2.77][22757-0-0-3.83][22811-3-3-5.02][22976-3-4-1.37][22985-3-3-3.94][23014-0-0-3.13][23112-1-1-2.26][23144-3-3-4.72][23168-2-3-0.31]
[23219-0-4-1.25][23363-3-3-4.52][23470-0-0-1.60][23486-2-4-0.19][23497-0-3-4.79][23516-0-0-5.30][23690-1-4-1.49][23921-2-2-1.09][23936-1-2-0.78][24040-3-4--0.10]
[24111-1-4-1.52][24182-0-0-5.44][24238-3-3-2.68][24290-2-0-3.03][24345-0-0-2.92][24364-1-2-2.29][24427-3-0-1.62][24477-2-2-4.46][24495-2-4-0.32][24893-2-2-0.90]
[25012-1-2-0.26][25121-2-2-2.68][25165-3-3-0.84][25183-0-0-4.82][25297-3-3-2.79][25398-0-0-2.87][25574-2-4-1.52][25644-1-1-2.75][25718-1-3-0.58][25774-2-3-0.22]
[26032-3-3-1.60][26051-3-3-3.82][26120-0-0-2.87][26321-1-1-5.30][26732-1-1-2.34][26784-3-3-5.85][26827-3-3-2.05][26833-0-3-2.75][26838-2-2-0.43][26860-1-4-0.35]
[26948-0-0-2.73][27049-3-0-3.44][27098-1-0-1.49][27526-0-0-1.95][27639-3-3-1.10][27698-3-3-4.77][27772-0-0-4.62][27890-1-1-3.44][28040-0-4-1.44][28503-2-2-4.00]
[28577-1-1-4.68][28959-0-0-5.41][29198-3-3-0.71][29777-0-0-7.69][29877-2-2-0.29][30035-1-1-2.44][30098-0-0-2.57][30326-1-1-2.67][30572-2-2-1.05][30716-0-4-1.95]
[30806-2-3-1.08][30906-1-1-3.00][31007-0-0-2.03][31181-3-3-2.09][31238-0-3-2.24][31347-0-0-4.64][31422-2-2-3.24][31429-3-3-1.89][31431-0-4-0.23][31432-1-1-3.43]
[31477-0-0-3.14][31524-1-1-1.26][31597-1-4-1.37][31619-1-4-0.09][31701-0-0-3.76][31755-0-0-3.00][31854-3-3-5.17][32074-1-3-0.67][32078-3-3-4.35][32111-1-1-1.16]
[32127-1-1-1.93][32140-3-3-4.01][32263-2-4-0.46][32365-0-0-5.30][32411-2-0-3.57][32429-3-3-3.03][32473-3-3-0.45][32574-3-3-3.94][32584-0-0-1.76][32622-0-0--0.04]
[32858-3-3-2.42][32969-3-3-2.09][33016-2-2-1.63][33031-1-3-2.83][33035-2-2-3.61][33133-2-2-1.88][33173-2-2-0.57][33175-3-4-0.36][33306-3-3-1.70][33309-2-3-1.78]
[33474-0-0-0.23][33478-2-3-0.31][33618-1-1-2.12][33712-0-0-1.40][33782-2-4-1.82][33914-3-3-4.53][34076-3-4-1.58][34112-2-2-3.50][34138-2-3-1.23][34239-1-1-0.68]
[34364-2-2-3.35][34617-1-2-2.38][34751-3-3-3.85][34783-2-2-0.72][35015-3-3-1.36][35018-1-4-1.00][35288-2-1-0.23][0-4-4-2.44][1-4-4-2.49][2-4-0-2.25]
[3-4-4-2.75][4-4-4-0.07][5-4-1-1.39][6-4-4-3.71][7-4-4-1.47][8-4-4-0.24][9-4-1-0.85][10-4-4-3.73][11-4-4-2.95][12-4-0-0.75]
[14-4-4-1.01][15-4-3-2.34][16-4-4-1.93][17-4-4-0.45][18-4-4-3.76][19-4-0-2.98][20-4-0-1.40][21-4-4-2.04][22-4-4-1.75][23-4-4-1.04]
[24-4-4-5.86][25-4-3-1.82][26-4-4-0.40][27-4-4-1.39][28-4-4-3.18][29-4-1-1.75][30-4-3-1.05][31-4-2-1.41][32-4-4-2.05][33-4-4-0.44]
[34-4-4-0.83][35-4-0-2.56][37-4-4-1.39][39-4-0-5.19][40-4-4-0.53][41-4-2--0.09][42-4-2-0.96][43-4-4--0.16][45-4-4-2.37][46-4-4-3.85]
[47-4-4-4.45][48-4-4-1.78][51-4-4-2.88][52-4-4-1.32][53-4-2-0.27][54-4-3-1.00][55-4-4-1.28][56-4-1-1.80][57-4-3-1.71][58-4-2-4.67]
[59-4-0-4.30][60-4-4-1.54][61-4-4-3.77][62-4-4-0.49][63-4-2-1.81][64-4-4-0.21][65-4-4-3.74][66-4-4-2.84][67-4-3-0.44][68-4-3--0.15]
[69-4-0-0.48][70-4-4-1.71][72-4-4-1.21][73-4-1-0.14][74-4-2-2.30][75-4-0-0.81][77-4-4-1.76][78-4-3-0.47][79-4-4-2.54][80-4-4-2.58]
[81-4-4-0.79][82-4-1-0.54][83-4-4-0.24][84-4-4-3.33][85-4-4-3.06][86-4-4-0.47][87-4-4-3.05][88-4-4-2.55][89-4-2--0.08][90-4-3-0.19]
[91-4-4-1.50][92-4-4-0.71][93-4-0-1.66][94-4-4-2.61][95-4-4-0.98][96-4-4-0.66][97-4-4-1.96][98-4-2-0.46][99-4-4-1.12][100-4-4-1.08]
[101-4-4-5.54][102-4-4-1.45][103-4-0-0.91][104-4-4-1.25][105-4-4-2.54][106-4-4-2.75][107-4-4-1.25][108-4-4-0.69][109-4-4-1.34][110-4-4-2.08]
[111-4-0-3.98][112-4-3-0.60][113-4-3-0.30][114-4-3-1.41][115-4-4-1.11][116-4-0-0.72][117-4-4-2.52][119-4-2-0.92][121-4-4-2.09][122-4-4-2.35]
[124-4-3--0.18][125-4-4-2.89][126-4-4-3.02][127-4-2-1.37][128-4-0-1.40][129-4-4-0.16][130-4-4-0.76][131-4-2-1.59][132-4-4-0.92][133-4-4-3.28]
[135-4-4-0.64][136-4-4-0.18][137-4-4-1.18][138-4-4-1.16][139-4-4-1.82][140-4-1-1.62][141-4-0-2.44][142-4-4-4.87][143-4-4-2.42][144-4-4-3.60]
[145-4-2-1.82][148-4-0-4.66][149-4-4-1.41][150-4-4-3.61][151-4-4-2.22][152-4-4-2.78][153-4-2-1.77][154-4-4-3.11][155-4-4-2.65][156-4-3-1.05]
[157-4-2-0.05][158-4-4-1.53][160-4-2-0.82][161-4-2-1.98][162-4-4-0.81][164-4-4-1.30][165-4-4-1.35][167-4-4-2.36][168-4-4-1.69][170-4-4-0.74]
[171-4-4-1.78][172-4-4-2.42][173-4-4-3.86][174-4-0-2.16][175-4-4-2.39][177-4-4-3.43][178-4-2-1.25][179-4-1-0.83][180-4-4-3.34][181-4-3-2.35]
[182-4-1-0.76][183-4-4-1.83][184-4-2-2.30][186-4-4-0.62][187-4-2-0.61][188-4-4-1.69][189-4-4-0.99][190-4-4-1.03][191-4-4-3.02][192-4-0-0.85]
[193-4-2-1.97][194-4-4-0.71][195-4-0-0.00][196-4-2-1.56][197-4-4-1.85][198-4-4-5.73][199-4-2-1.43]
---------------------------
I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.225 | Acc: 86.125% | Wgt Acc: 93.692%
	I - Batch: 100 | Loss: 0.210 | Acc: 86.938% | Wgt Acc: 94.672%
	I - Batch: 150 | Loss: 0.220 | Acc: 86.708% | Wgt Acc: 94.421%
	I - Batch: 200 | Loss: 0.221 | Acc: 86.844% | Wgt Acc: 94.619%
I - num batch: 222
I - Train -- Loss: 0.220 | Acc: 86.975% | Wgt Acc: 94.583% | LR: 6.250000e-05 | Dur: 132.81s
I - Confusion Matrix: [row->prediction - col->label]
[[674.   0.   0.  15. 136.]
 [  0. 574.   3.   0.  56.]
 [  1.   1. 721.   1. 125.]
 [ 13.   1.   2. 513.  80.]
 [  9.   2.   8.   9. 603.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.055 | Acc: 64.300% | Wgt Acc: 64.456% | Dur: 14.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   3.  13.  17.]
 [  1.  37.   6.   0.   5.]
 [  1.  18.  49.   6.  28.]
 [ 16.   8.  12.  62.  15.]
 [  7.  11.   5.   5. 115.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.198 | Acc: 88.750% | Wgt Acc: 95.880%
	I - Batch: 100 | Loss: 0.202 | Acc: 88.125% | Wgt Acc: 95.363%
	I - Batch: 150 | Loss: 0.209 | Acc: 87.958% | Wgt Acc: 95.250%
	I - Batch: 200 | Loss: 0.211 | Acc: 87.688% | Wgt Acc: 95.129%
I - num batch: 222
I - Train -- Loss: 0.210 | Acc: 87.708% | Wgt Acc: 95.136% | LR: 6.250000e-05 | Dur: 138.68s
I - Confusion Matrix: [row->prediction - col->label]
[[673.   0.   1.  10. 117.]
 [  0. 573.   2.   1.  57.]
 [  1.   3. 727.   1. 141.]
 [ 10.   0.   1. 521.  68.]
 [ 13.   2.   3.   5. 617.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.140 | Acc: 61.736% | Wgt Acc: 62.530% | Dur: 14.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   1.  12.  23.]
 [  0.  35.   3.   0.   7.]
 [  2.  17.  41.   4.  17.]
 [ 20.  13.  21.  66.  25.]
 [  3.   9.   9.   4. 108.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.197 | Acc: 88.125% | Wgt Acc: 95.207%
	I - Batch: 100 | Loss: 0.209 | Acc: 87.125% | Wgt Acc: 94.844%
	I - Batch: 150 | Loss: 0.217 | Acc: 86.542% | Wgt Acc: 94.546%
	I - Batch: 200 | Loss: 0.211 | Acc: 86.781% | Wgt Acc: 94.751%
I - num batch: 222
I - Train -- Loss: 0.210 | Acc: 87.031% | Wgt Acc: 94.813% | LR: 6.250000e-05 | Dur: 138.21s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   1.   1.   9. 131.]
 [  1. 572.   0.   1.  51.]
 [  1.   1. 725.   3. 136.]
 [ 13.   0.   3. 521.  84.]
 [ 11.   4.   5.   4. 598.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.096 | Acc: 63.314% | Wgt Acc: 64.964% | Dur: 14.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   5.   5.  20.  27.]
 [  0.  42.   4.   0.  10.]
 [  0.  13.  43.   2.  19.]
 [ 12.   9.  15.  58.  18.]
 [  4.   9.   8.   6. 106.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.212 | Acc: 87.375% | Wgt Acc: 95.025%
	I - Batch: 100 | Loss: 0.206 | Acc: 88.250% | Wgt Acc: 95.143%
	I - Batch: 150 | Loss: 0.208 | Acc: 87.917% | Wgt Acc: 95.055%
	I - Batch: 200 | Loss: 0.214 | Acc: 87.469% | Wgt Acc: 94.636%
I - num batch: 222
I - Train -- Loss: 0.215 | Acc: 87.454% | Wgt Acc: 94.598% | LR: 6.250000e-05 | Dur: 136.64s
I - Confusion Matrix: [row->prediction - col->label]
[[673.   1.   0.  15. 116.]
 [  2. 569.   3.   1.  59.]
 [  0.   0. 722.   2. 115.]
 [  7.   1.   3. 514.  86.]
 [ 15.   7.   6.   6. 624.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 63.905% | Wgt Acc: 64.479% | Dur: 15.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   6.   4.  19.  24.]
 [  1.  41.  11.   0.   8.]
 [  2.  15.  44.   4.  25.]
 [ 10.   5.  11.  57.  11.]
 [  5.  11.   5.   6. 112.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.206 | Acc: 86.000% | Wgt Acc: 94.392%
	I - Batch: 100 | Loss: 0.200 | Acc: 87.438% | Wgt Acc: 95.020%
	I - Batch: 150 | Loss: 0.195 | Acc: 88.000% | Wgt Acc: 95.206%
	I - Batch: 200 | Loss: 0.201 | Acc: 87.562% | Wgt Acc: 94.938%
I - num batch: 222
I - Train -- Loss: 0.199 | Acc: 87.764% | Wgt Acc: 95.158% | LR: 6.250000e-05 | Dur: 134.17s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   1.   0.   8. 121.]
 [  1. 571.   0.   1.  60.]
 [  0.   4. 727.   0. 115.]
 [  9.   1.   2. 524.  85.]
 [ 15.   1.   5.   5. 619.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 67.061% | Wgt Acc: 65.679% | Dur: 14.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   2.   8.  18.]
 [  1.  43.   8.   2.   7.]
 [  1.  10.  41.   3.  16.]
 [ 17.  11.  13.  68.  11.]
 [  9.  13.  11.   5. 128.]]

I - Local maximum validation set accuracy:  67.06

I - Validation set results: 
[14-1-2-1.16][50-3-4-1.62][124-2-2-1.34][127-0-0-6.43][443-2-2-4.56][567-0-0-2.82][573-1-1-4.44][615-0-0-1.83][695-1-2-2.88][722-3-3-3.68]
[826-0-0-5.22][878-0-0-5.71][1103-0-4-1.52][1212-3-3-1.54][1368-0-0-4.48][2181-2-3-0.52][2476-2-2-1.67][2721-2-2-2.60][2818-1-4-1.15][2886-2-1-2.03]
[3231-2-2-5.98][3333-2-3-0.44][3482-2-2-2.81][3536-3-3-1.51][3625-1-1-5.82][3909-0-0-3.75][4035-0-0-1.87][4140-0-0-1.99][4214-1-3-3.24][4346-1-3-0.69]
[4581-2-2-2.65][4708-3-2-1.66][4838-3-3--0.53][4845-1-3-0.41][4868-0-0-5.59][4939-0-1--0.34][4984-2-2-2.76][5078-1-4-1.12][5396-0-0-7.60][5479-1-1-3.28]
[5717-0-0-5.56][5843-1-1-0.87][5949-3-3-2.73][5987-2-4-2.47][6014-3-3-2.26][6033-3-3-0.79][6313-0-3-1.91][6421-3-3-2.92][6500-1-2-0.11][6583-3-3-3.30]
[6683-3-3-2.23][6825-2-1-1.70][6998-3-3-1.58][7049-3-3-1.66][7517-1-1-3.29][7521-1-1-0.73][7528-1-3-1.28][7949-1-2-3.89][8135-1-3-0.60][8185-3-0-6.05]
[8269-3-1-4.55][8273-3-3-2.74][8543-3-0-6.85][8666-1-1-3.48][8672-0-0-6.35][8903-1-2-1.77][9001-2-1-2.23][9036-2-2-5.01][9281-3-3-0.77][9300-2-2-8.31]
[9571-0-3-0.56][9617-1-4-0.18][9644-2-2-0.12][9705-2-0-0.01][9801-0-3-3.17][9803-3-3-2.28][9865-3-3-5.92][9896-2-2-3.38][10314-1-4-0.51][10337-3-3-3.92]
[10403-0-4-1.73][10653-2-4-0.90][10704-2-2-1.83][10719-1-1-4.60][10727-1-4-1.01][10836-0-0-9.48][10969-2-3-1.47][11042-0-0-1.96][11088-1-1-5.52][11322-0-0-6.42]
[11398-2-2-4.93][11499-0-0-3.56][11502-3-3-1.41][11512-3-3-2.78][11608-1-1-3.87][11610-0-0-2.93][11692-0-0-2.57][11905-0-3-1.54][11993-1-1-3.63][12002-2-3-1.45]
[12052-0-0-4.50][12201-0-3-3.26][12235-2-4-1.16][12320-1-4-3.31][12377-2-4-2.56][12398-2-3-0.64][12503-1-1-0.49][12617-0-3-0.01][12685-3-3-1.72][12738-2-4-1.04]
[12742-2-2-5.71][12823-0-3-3.51][13110-1-1-2.10][13240-3-3-3.03][13253-1-1-3.03][13273-0-0-7.19][13634-1-1-0.86][13763-2-2-0.56][13905-3-3-0.58][14060-2-1-1.57]
[14065-3-0-2.65][14147-3-3-1.80][14595-2-2-2.34][14687-2-2-3.07][14788-2-2-2.33][14869-1-1-3.00][14872-3-4-0.34][14877-1-1-4.02][14927-0-3-1.39][15066-0-0-4.41]
[15175-1-1-2.66][15178-2-3-1.09][15375-3-0-1.56][15389-3-3-4.09][15568-2-1-1.46][15675-3-3-6.09][15869-1-3-0.91][16207-3-0-0.71][16236-0-0-3.05][16302-3-3-0.82]
[16331-2-2-8.21][16381-0-3-1.48][16488-1-1-3.03][16495-0-0-4.25][16650-0-0-5.65][16719-1-1-1.79][16801-0-0-7.34][16828-0-0-3.95][17137-3-3-0.52][17245-1-1-0.96]
[17278-3-1--0.28][17282-0-2-0.44][17311-2-2-2.71][17336-2-1-1.41][17608-3-3-3.49][17627-0-0-1.18][17877-3-0-3.06][17924-1-3-1.35][17984-3-0-2.23][18211-0-3-1.19]
[18276-3-3-1.41][18287-1-1-0.36][18394-0-0-5.15][18428-0-0-1.44][18442-0-3-3.27][18478-3-3-3.25][18607-0-0-3.15][18616-0-0-1.75][18663-0-0-2.78][18718-0-0-4.19]
[18766-2-2-3.19][18824-2-4-1.88][18890-3-3-1.18][18930-3-4-1.32][18938-3-3-3.57][19817-1-2-3.03][19839-0-0-0.93][19930-3-3-2.42][19944-0-4-0.39][20036-2-2-6.09]
[20101-3-3-1.43][20474-1-1-4.04][20547-3-3-1.24][20929-2-2-6.34][21245-1-2-0.67][21257-3-3-1.05][21293-1-2-3.30][21316-1-1-5.93][21384-1-4-2.19][21448-1-1-2.83]
[21483-0-0-3.81][21487-2-2-4.34][21714-0-3-0.13][21943-3-2-0.47][21947-0-0-2.96][21948-0-0-7.53][21965-2-2-5.25][21998-1-1-1.60][22025-0-4-0.47][22228-3-3-6.42]
[22446-1-1-2.58][22494-3-3-2.52][22757-0-0-3.54][22811-3-3-3.18][22976-3-2-0.48][22985-3-3-3.81][23014-0-0-4.46][23112-1-1-3.34][23144-3-3-5.93][23168-2-3--0.43]
[23219-0-0-1.87][23363-3-3-4.79][23470-0-0-2.21][23486-2-2-0.65][23497-0-3-4.61][23516-0-0-5.30][23690-1-3-1.34][23921-2-1-0.80][23936-1-0-0.35][24040-3-4-0.02]
[24111-1-4-1.86][24182-0-0-4.37][24238-3-3-3.28][24290-2-0-2.80][24345-0-0-1.40][24364-1-2-1.43][24427-3-3-1.52][24477-2-2-3.74][24495-2-4-0.89][24893-2-2-1.83]
[25012-1-4--0.03][25121-2-2-2.20][25165-3-3-1.13][25183-0-0-4.91][25297-3-3-4.36][25398-0-0-2.60][25574-2-2-2.17][25644-1-1-3.09][25718-1-3--0.23][25774-2-4--0.48]
[26032-3-3-3.14][26051-3-3-4.47][26120-0-4-2.32][26321-1-4--0.06][26732-1-1-2.28][26784-3-3-6.87][26827-3-3-3.07][26833-0-3-3.65][26838-2-2-0.82][26860-1-4-0.49]
[26948-0-0-1.80][27049-3-0-3.76][27098-1-1-0.21][27526-0-0-3.58][27639-3-3-1.39][27698-3-3-5.14][27772-0-0-3.19][27890-1-1-2.45][28040-0-4-2.58][28503-2-2-4.09]
[28577-1-1-5.58][28959-0-0-5.70][29198-3-3-0.90][29777-0-0-8.23][29877-2-3-0.23][30035-1-1-4.60][30098-0-0-2.25][30326-1-1-3.02][30572-2-2-1.99][30716-0-4-2.13]
[30806-2-3-0.54][30906-1-1-2.51][31007-0-0-0.87][31181-3-3-2.19][31238-0-3-2.35][31347-0-0-4.53][31422-2-2-3.68][31429-3-3-0.59][31431-0-0-0.74][31432-1-1-4.05]
[31477-0-3-3.36][31524-1-3-0.37][31597-1-4-1.25][31619-1-4-0.05][31701-0-0-5.32][31755-0-0-4.83][31854-3-3-3.39][32074-1-1-2.01][32078-3-3-4.75][32111-1-1-1.63]
[32127-1-1-3.08][32140-3-3-4.75][32263-2-4-0.80][32365-0-0-4.97][32411-2-3-3.56][32429-3-3-2.84][32473-3-3-0.55][32574-3-3-3.83][32584-0-0-2.62][32622-0-4--0.04]
[32858-3-3-2.30][32969-3-3-2.84][33016-2-2-3.47][33031-1-3-3.53][33035-2-2-2.61][33133-2-2-1.20][33173-2-2-1.14][33175-3-4-0.62][33306-3-3-1.16][33309-2-3-2.34]
[33474-0-4-0.63][33478-2-3-0.57][33618-1-1-2.22][33712-0-3-2.30][33782-2-4-1.41][33914-3-3-2.67][34076-3-3-1.60][34112-2-2-3.93][34138-2-3-0.89][34239-1-1-2.29]
[34364-2-2-5.08][34617-1-2-2.15][34751-3-3-3.30][34783-2-4-1.64][35015-3-3-1.93][35018-1-1-1.41][35288-2-1-0.32][0-4-2-0.98][1-4-4-2.05][2-4-4-2.43]
[3-4-4-1.67][4-4-4-1.35][5-4-1-0.43][6-4-0-3.47][7-4-4-1.59][8-4-4-0.77][9-4-4-0.23][10-4-4-5.02][11-4-4-2.90][12-4-4-0.04]
[14-4-4-0.69][15-4-3-3.05][16-4-4-2.47][17-4-4-2.11][18-4-4-3.87][19-4-0-1.42][20-4-0-1.40][21-4-4-1.46][22-4-4-2.34][23-4-4-0.86]
[24-4-4-6.34][25-4-3-2.10][26-4-4-0.64][27-4-4-1.94][28-4-4-2.42][29-4-1-0.39][30-4-4-1.06][31-4-2-0.67][32-4-4-2.16][33-4-4-0.98]
[34-4-4-1.29][35-4-0-3.30][37-4-4-1.98][39-4-0-2.47][40-4-4-0.69][41-4-4-0.25][42-4-2-1.06][43-4-4-0.95][45-4-3-0.65][46-4-4-4.27]
[47-4-4-4.68][48-4-4-2.10][51-4-4-3.72][52-4-4-2.12][53-4-4-1.01][54-4-3-0.98][55-4-3-0.18][56-4-4-0.01][57-4-3-1.16][58-4-2-4.02]
[59-4-0-3.49][60-4-4-0.09][61-4-4-3.63][62-4-2-1.25][63-4-4-1.14][64-4-2-0.45][65-4-4-4.09][66-4-4-3.39][67-4-4-0.29][68-4-3--0.26]
[69-4-0-0.59][70-4-4-2.54][72-4-4-2.15][73-4-1-1.18][74-4-2-2.43][75-4-0--0.11][77-4-4-3.93][78-4-3-0.62][79-4-4-2.24][80-4-4-1.40]
[81-4-4-2.76][82-4-1-1.06][83-4-4-0.82][84-4-4-3.23][85-4-4-3.11][86-4-4-0.21][87-4-4-3.45][88-4-4-2.98][89-4-0--0.12][90-4-4-1.99]
[91-4-4-2.01][92-4-4-0.26][93-4-0-1.14][94-4-4-3.07][95-4-4-0.34][96-4-4-1.39][97-4-4-2.99][98-4-2-1.58][99-4-4-2.25][100-4-4-1.93]
[101-4-4-5.10][102-4-4-1.96][103-4-0-1.25][104-4-4-1.78][105-4-4-2.66][106-4-4-3.21][107-4-1-1.22][108-4-4-1.31][109-4-4-1.99][110-4-4-3.05]
[111-4-0-3.73][112-4-4-0.73][113-4-2-0.24][114-4-3-1.40][115-4-4-1.63][116-4-4-0.79][117-4-4-2.76][119-4-4-1.31][121-4-4-2.55][122-4-4-1.97]
[124-4-2-0.09][125-4-4-2.71][126-4-4-4.37][127-4-2-3.61][128-4-4-0.03][129-4-4-0.75][130-4-4-0.61][131-4-4-0.76][132-4-4-0.23][133-4-4-3.46]
[135-4-4-1.50][136-4-4-1.94][137-4-4-1.72][138-4-4-0.89][139-4-4-1.66][140-4-4-0.51][141-4-0-2.25][142-4-4-4.65][143-4-4-2.17][144-4-4-1.72]
[145-4-4-2.31][148-4-0-4.33][149-4-4-2.43][150-4-4-4.39][151-4-4-2.37][152-4-4-2.81][153-4-2-2.26][154-4-4-4.60][155-4-4-3.26][156-4-3-1.98]
[157-4-2-0.08][158-4-4-1.57][160-4-0--0.06][161-4-2-2.30][162-4-4-1.05][164-4-4-2.14][165-4-4-1.44][167-4-0-3.81][168-4-4-2.16][170-4-3-1.35]
[171-4-4-1.94][172-4-4-2.59][173-4-4-4.99][174-4-0-1.33][175-4-4-1.55][177-4-4-3.09][178-4-4-2.44][179-4-4-1.17][180-4-4-3.30][181-4-4-0.57]
[182-4-1-0.58][183-4-4-2.14][184-4-2-1.93][186-4-4-1.89][187-4-2-0.94][188-4-4-2.30][189-4-4-1.40][190-4-4-1.23][191-4-4-3.92][192-4-4-1.36]
[193-4-1-1.99][194-4-4-1.36][195-4-0-3.06][196-4-4-1.07][197-4-4-1.61][198-4-4-7.16][199-4-4-1.00]
---------------------------
I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.201 | Acc: 87.750% | Wgt Acc: 95.028%
	I - Batch: 100 | Loss: 0.203 | Acc: 87.750% | Wgt Acc: 95.119%
	I - Batch: 150 | Loss: 0.201 | Acc: 88.167% | Wgt Acc: 95.303%
	I - Batch: 200 | Loss: 0.202 | Acc: 88.125% | Wgt Acc: 95.228%
I - num batch: 222
I - Train -- Loss: 0.203 | Acc: 88.046% | Wgt Acc: 95.056% | LR: 6.250000e-05 | Dur: 138.44s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   0.   1.   9. 110.]
 [  0. 573.   2.   0.  54.]
 [  1.   0. 725.   3. 116.]
 [ 13.   2.   2. 519.  85.]
 [ 12.   3.   4.   7. 635.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.085 | Acc: 64.694% | Wgt Acc: 64.145% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   7.   3.  14.  23.]
 [  1.  36.   2.   1.   3.]
 [  2.  13.  43.   3.  21.]
 [ 14.   9.  16.  62.  14.]
 [  3.  13.  11.   6. 119.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.183 | Acc: 88.500% | Wgt Acc: 95.821%
	I - Batch: 100 | Loss: 0.189 | Acc: 88.312% | Wgt Acc: 95.705%
	I - Batch: 150 | Loss: 0.185 | Acc: 88.750% | Wgt Acc: 95.752%
	I - Batch: 200 | Loss: 0.186 | Acc: 88.688% | Wgt Acc: 95.627%
I - num batch: 222
I - Train -- Loss: 0.183 | Acc: 88.807% | Wgt Acc: 95.749% | LR: 6.250000e-05 | Dur: 131.73s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   1.   2.   7. 108.]
 [  0. 572.   1.   1.  47.]
 [  1.   3. 726.   2. 105.]
 [  5.   1.   1. 525.  95.]
 [  9.   1.   4.   3. 645.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.159 | Acc: 62.327% | Wgt Acc: 63.499% | Dur: 14.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   5.  11.  20.]
 [  0.  34.   3.   1.   1.]
 [  1.  20.  43.   6.  29.]
 [ 15.  12.  18.  65.  23.]
 [  5.   8.   6.   3. 107.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.179 | Acc: 88.125% | Wgt Acc: 95.552%
	I - Batch: 100 | Loss: 0.184 | Acc: 88.188% | Wgt Acc: 95.666%
	I - Batch: 150 | Loss: 0.188 | Acc: 87.958% | Wgt Acc: 95.567%
	I - Batch: 200 | Loss: 0.190 | Acc: 88.312% | Wgt Acc: 95.406%
I - num batch: 222
I - Train -- Loss: 0.191 | Acc: 88.046% | Wgt Acc: 95.318% | LR: 6.250000e-05 | Dur: 135.46s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   1.   1.   4. 121.]
 [  0. 572.   1.   0.  49.]
 [  2.   2. 729.   1. 131.]
 [ 10.   1.   2. 524.  73.]
 [ 13.   2.   1.   9. 626.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 64.694% | Wgt Acc: 64.733% | Dur: 17.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   5.   1.  10.  18.]
 [  2.  43.   9.   0.  10.]
 [  0.  13.  42.   3.  18.]
 [ 18.   7.  16.  66.  17.]
 [  8.  10.   7.   7. 117.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.196 | Acc: 88.125% | Wgt Acc: 95.420%
	I - Batch: 100 | Loss: 0.193 | Acc: 88.250% | Wgt Acc: 95.527%
	I - Batch: 150 | Loss: 0.192 | Acc: 88.250% | Wgt Acc: 95.481%
	I - Batch: 200 | Loss: 0.186 | Acc: 88.406% | Wgt Acc: 95.587%
I - num batch: 222
I - Train -- Loss: 0.184 | Acc: 88.638% | Wgt Acc: 95.743% | LR: 6.250000e-05 | Dur: 135.06s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   0.   0.   6. 120.]
 [  1. 574.   0.   0.  59.]
 [  2.   2. 726.   0. 109.]
 [  4.   1.   3. 528.  74.]
 [ 12.   1.   5.   4. 638.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 66.272% | Wgt Acc: 65.944% | Dur: 14.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   3.  10.  17.]
 [  0.  38.   5.   0.   6.]
 [  2.  19.  46.   5.  23.]
 [ 12.   7.  12.  65.  13.]
 [  8.  11.   9.   6. 121.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.173 | Acc: 88.750% | Wgt Acc: 95.994%
	I - Batch: 100 | Loss: 0.172 | Acc: 89.438% | Wgt Acc: 95.911%
	I - Batch: 150 | Loss: 0.176 | Acc: 88.750% | Wgt Acc: 95.647%
	I - Batch: 200 | Loss: 0.185 | Acc: 88.094% | Wgt Acc: 95.421%
I - num batch: 222
I - Train -- Loss: 0.187 | Acc: 87.821% | Wgt Acc: 95.260% | LR: 6.250000e-05 | Dur: 135.84s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   1.   0.   7. 115.]
 [  1. 574.   3.   0.  61.]
 [  2.   0. 727.   0. 118.]
 [  9.   1.   2. 524.  88.]
 [ 13.   2.   2.   7. 618.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.078 | Acc: 64.300% | Wgt Acc: 64.203% | Dur: 15.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   4.  15.  22.]
 [  0.  39.   8.   1.  11.]
 [  0.  14.  43.   5.  18.]
 [ 13.   8.  12.  59.  13.]
 [  6.  12.   8.   6. 116.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.192 | Acc: 86.875% | Wgt Acc: 94.402%
	I - Batch: 100 | Loss: 0.184 | Acc: 87.875% | Wgt Acc: 95.135%
	I - Batch: 150 | Loss: 0.174 | Acc: 88.417% | Wgt Acc: 95.617%
	I - Batch: 200 | Loss: 0.179 | Acc: 88.438% | Wgt Acc: 95.655%
I - num batch: 222
I - Train -- Loss: 0.180 | Acc: 88.582% | Wgt Acc: 95.582% | LR: 6.250000e-05 | Dur: 134.62s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   1.   0.   9. 132.]
 [  0. 577.   2.   2.  50.]
 [  2.   0. 728.   0. 107.]
 [  7.   0.   0. 524.  70.]
 [ 16.   0.   4.   3. 641.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 65.483% | Wgt Acc: 65.506% | Dur: 15.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   3.   3.  11.  17.]
 [  0.  42.   6.   0.   7.]
 [  1.  15.  46.   6.  23.]
 [ 18.   8.  12.  63.  15.]
 [  6.  10.   8.   6. 118.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.170 | Acc: 88.500% | Wgt Acc: 95.983%
	I - Batch: 100 | Loss: 0.164 | Acc: 89.562% | Wgt Acc: 96.460%
	I - Batch: 150 | Loss: 0.170 | Acc: 89.625% | Wgt Acc: 96.313%
	I - Batch: 200 | Loss: 0.174 | Acc: 88.812% | Wgt Acc: 95.871%
I - num batch: 222
I - Train -- Loss: 0.174 | Acc: 88.751% | Wgt Acc: 95.798% | LR: 6.250000e-05 | Dur: 134.54s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   1.   1.   4. 108.]
 [  2. 572.   0.   0.  52.]
 [  0.   0. 730.   0. 119.]
 [  7.   0.   1. 528.  80.]
 [ 11.   5.   2.   6. 641.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.083 | Acc: 66.075% | Wgt Acc: 64.733% | Dur: 14.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   6.   4.  15.  23.]
 [  0.  40.   6.   0.   6.]
 [  1.  12.  41.   3.  15.]
 [  8.   8.  13.  59.  11.]
 [  9.  12.  11.   9. 125.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.154 | Acc: 90.875% | Wgt Acc: 96.516%
	I - Batch: 100 | Loss: 0.166 | Acc: 90.812% | Wgt Acc: 96.516%
	I - Batch: 150 | Loss: 0.163 | Acc: 90.500% | Wgt Acc: 96.547%
	I - Batch: 200 | Loss: 0.163 | Acc: 90.594% | Wgt Acc: 96.608%
I - num batch: 222
I - Train -- Loss: 0.162 | Acc: 90.640% | Wgt Acc: 96.651% | LR: 6.250000e-05 | Dur: 136.38s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   6. 102.]
 [  0. 577.   0.   1.  42.]
 [  3.   1. 731.   0.  99.]
 [  2.   0.   1. 528.  61.]
 [  9.   0.   2.   3. 696.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 65.483% | Wgt Acc: 65.067% | Dur: 16.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   5.  15.  18.]
 [  0.  40.   6.   1.   9.]
 [  1.  12.  41.   3.  18.]
 [ 11.  10.  11.  63.  15.]
 [  8.  13.  12.   4. 120.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.168 | Acc: 89.250% | Wgt Acc: 96.408%
	I - Batch: 100 | Loss: 0.178 | Acc: 89.125% | Wgt Acc: 96.181%
	I - Batch: 150 | Loss: 0.173 | Acc: 89.667% | Wgt Acc: 96.196%
	I - Batch: 200 | Loss: 0.169 | Acc: 89.906% | Wgt Acc: 96.323%
I - num batch: 222
I - Train -- Loss: 0.170 | Acc: 89.822% | Wgt Acc: 96.301% | LR: 6.250000e-05 | Dur: 137.90s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   0.   6. 110.]
 [  0. 574.   0.   0.  45.]
 [  0.   1. 730.   1. 100.]
 [  3.   2.   0. 524.  74.]
 [  7.   0.   4.   7. 671.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.031 | Acc: 65.878% | Wgt Acc: 66.901% | Dur: 19.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   3.  11.  23.]
 [  1.  41.   8.   1.   9.]
 [  1.  12.  45.   4.  22.]
 [ 12.  11.  12.  65.  12.]
 [  5.  10.   7.   5. 114.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.161 | Acc: 89.500% | Wgt Acc: 96.300%
	I - Batch: 100 | Loss: 0.165 | Acc: 89.188% | Wgt Acc: 95.871%
	I - Batch: 150 | Loss: 0.161 | Acc: 89.375% | Wgt Acc: 96.078%
	I - Batch: 200 | Loss: 0.162 | Acc: 89.594% | Wgt Acc: 96.089%
I - num batch: 222
I - Train -- Loss: 0.161 | Acc: 89.766% | Wgt Acc: 96.183% | LR: 6.250000e-05 | Dur: 134.83s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   1.   1.   7. 106.]
 [  0. 575.   0.   0.  52.]
 [  2.   1. 727.   1.  97.]
 [  2.   0.   1. 526.  72.]
 [ 10.   1.   5.   4. 673.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.076 | Acc: 64.892% | Wgt Acc: 66.486% | Dur: 13.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   5.  14.  17.]
 [  0.  42.   6.   1.   9.]
 [  2.  17.  50.   7.  29.]
 [ 12.   7.   6.  59.  16.]
 [  5.   9.   8.   5. 109.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.159 | Acc: 88.500% | Wgt Acc: 95.977%
	I - Batch: 100 | Loss: 0.158 | Acc: 90.250% | Wgt Acc: 96.337%
	I - Batch: 150 | Loss: 0.153 | Acc: 90.250% | Wgt Acc: 96.387%
	I - Batch: 200 | Loss: 0.157 | Acc: 90.062% | Wgt Acc: 96.278%
I - num batch: 222
I - Train -- Loss: 0.157 | Acc: 90.161% | Wgt Acc: 96.240% | LR: 6.250000e-05 | Dur: 133.59s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   3. 105.]
 [  0. 572.   1.   0.  41.]
 [  0.   1. 727.   0.  95.]
 [  4.   1.   2. 529.  70.]
 [ 12.   4.   4.   6. 689.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.112 | Acc: 63.511% | Wgt Acc: 62.726% | Dur: 14.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   4.  11.  17.]
 [  0.  37.   6.   1.   4.]
 [  2.  16.  44.   6.  24.]
 [ 16.  12.  12.  60.  17.]
 [  7.   9.   9.   8. 118.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.154 | Acc: 90.750% | Wgt Acc: 96.270%
	I - Batch: 100 | Loss: 0.160 | Acc: 90.000% | Wgt Acc: 96.112%
	I - Batch: 150 | Loss: 0.164 | Acc: 89.542% | Wgt Acc: 96.054%
	I - Batch: 200 | Loss: 0.162 | Acc: 89.688% | Wgt Acc: 96.158%
I - num batch: 222
I - Train -- Loss: 0.161 | Acc: 89.738% | Wgt Acc: 96.180% | LR: 6.250000e-05 | Dur: 139.55s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   0.   0.   6. 116.]
 [  0. 576.   1.   0.  39.]
 [  2.   2. 730.   1.  96.]
 [  8.   0.   0. 527.  77.]
 [  9.   0.   3.   4. 672.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.984 | Acc: 69.034% | Wgt Acc: 64.710% | Dur: 15.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   2.  14.  10.]
 [  0.  43.   7.   1.   4.]
 [  2.  13.  47.   3.  17.]
 [ 13.   6.   9.  55.   5.]
 [ 12.  14.  10.  13. 144.]]

I - Local maximum validation set accuracy:  69.03

I - Validation set results: 
[14-1-2-1.36][50-3-4-1.94][124-2-2-1.90][127-0-0-8.01][443-2-2-4.48][567-0-0-2.39][573-1-1-0.33][615-0-0-2.61][695-1-2-3.68][722-3-0-3.44]
[826-0-0-4.61][878-0-0-3.88][1103-0-4-1.56][1212-3-4-0.77][1368-0-0-5.37][2181-2-3-1.62][2476-2-2-2.87][2721-2-2-2.13][2818-1-4--0.08][2886-2-1-1.73]
[3231-2-2-5.43][3333-2-1-0.20][3482-2-2-3.26][3536-3-3-1.28][3625-1-1-3.33][3909-0-0-2.62][4035-0-0-3.36][4140-0-0-2.74][4214-1-3-2.12][4346-1-3-0.67]
[4581-2-2-1.42][4708-3-2-1.88][4838-3-2--0.15][4845-1-3-0.89][4868-0-0-4.53][4939-0-2-0.47][4984-2-2-2.37][5078-1-4-1.39][5396-0-0-7.42][5479-1-1-2.51]
[5717-0-0-5.52][5843-1-1-1.15][5949-3-3-3.49][5987-2-4-2.44][6014-3-3-1.68][6033-3-3-0.60][6313-0-0-1.98][6421-3-3-1.66][6500-1-2-1.26][6583-3-3-3.29]
[6683-3-3-1.94][6825-2-1-2.07][6998-3-3-0.96][7049-3-3-1.27][7517-1-1-3.78][7521-1-1-0.62][7528-1-3-0.52][7949-1-2-4.67][8135-1-4-0.78][8185-3-0-6.48]
[8269-3-1-3.16][8273-3-3-1.79][8543-3-0-6.35][8666-1-1-3.93][8672-0-0-7.80][8903-1-1-0.29][9001-2-1-2.22][9036-2-2-3.98][9281-3-0-0.66][9300-2-2-7.62]
[9571-0-4-1.13][9617-1-4-2.03][9644-2-2-0.26][9705-2-3-0.24][9801-0-3-2.77][9803-3-3-1.43][9865-3-3-4.99][9896-2-2-2.41][10314-1-4-0.78][10337-3-3-3.63]
[10403-0-4-1.02][10653-2-4-1.04][10704-2-2-2.42][10719-1-1-3.16][10727-1-4-1.11][10836-0-0-10.38][10969-2-3-0.62][11042-0-0-2.59][11088-1-1-3.33][11322-0-0-6.16]
[11398-2-2-2.32][11499-0-0-3.36][11502-3-3-0.58][11512-3-3-1.56][11608-1-2-2.93][11610-0-0-1.04][11692-0-0-2.98][11905-0-0-1.87][11993-1-1-3.76][12002-2-2-0.26]
[12052-0-0-5.08][12201-0-0-2.75][12235-2-2-2.56][12320-1-4-2.52][12377-2-4-2.67][12398-2-2-0.83][12503-1-2-1.94][12617-0-3-0.39][12685-3-4-0.86][12738-2-4--0.01]
[12742-2-2-5.91][12823-0-0-3.94][13110-1-1-1.18][13240-3-3-2.65][13253-1-1-2.46][13273-0-0-7.91][13634-1-4-0.76][13763-2-2--0.00][13905-3-3--0.26][14060-2-2-1.06]
[14065-3-0-2.62][14147-3-3-2.14][14595-2-2-1.63][14687-2-2-3.91][14788-2-2-1.95][14869-1-1-2.17][14872-3-0-1.71][14877-1-1-3.86][14927-0-3-1.52][15066-0-0-4.82]
[15175-1-1-2.14][15178-2-3-0.60][15375-3-0-0.06][15389-3-3-2.68][15568-2-1-2.40][15675-3-3-5.40][15869-1-0-0.51][16207-3-0-0.76][16236-0-0-1.88][16302-3-4-0.33]
[16331-2-2-8.03][16381-0-3-0.82][16488-1-1-6.98][16495-0-0-2.58][16650-0-0-5.91][16719-1-2-3.85][16801-0-0-7.55][16828-0-0-4.09][17137-3-0-0.80][17245-1-4-1.81]
[17278-3-4-0.67][17282-0-2-0.64][17311-2-2-3.31][17336-2-1-0.34][17608-3-3-3.31][17627-0-0--0.91][17877-3-0-1.79][17924-1-3-1.04][17984-3-0-2.39][18211-0-3-1.97]
[18276-3-3-1.02][18287-1-1-0.94][18394-0-0-2.77][18428-0-0-0.95][18442-0-3-3.66][18478-3-3-2.45][18607-0-0-2.85][18616-0-0-1.82][18663-0-0-2.97][18718-0-0-4.44]
[18766-2-2-1.23][18824-2-4-2.95][18890-3-3-0.87][18930-3-4-1.61][18938-3-3-4.60][19817-1-1-2.71][19839-0-0-0.85][19930-3-3-1.78][19944-0-0-2.67][20036-2-2-6.62]
[20101-3-3-3.02][20474-1-1-2.96][20547-3-4-1.46][20929-2-2-4.80][21245-1-2-1.61][21257-3-3-2.57][21293-1-2-3.24][21316-1-1-3.11][21384-1-1-3.56][21448-1-1-2.42]
[21483-0-0-1.86][21487-2-2-5.62][21714-0-3-0.51][21943-3-4-1.68][21947-0-0-3.85][21948-0-0-7.50][21965-2-2-3.99][21998-1-1-4.39][22025-0-4-2.22][22228-3-3-5.79]
[22446-1-1-2.55][22494-3-3-2.10][22757-0-0-4.14][22811-3-3-5.33][22976-3-2-1.28][22985-3-3-2.43][23014-0-3-2.76][23112-1-1-3.52][23144-3-3-4.57][23168-2-3--0.05]
[23219-0-4-3.05][23363-3-3-3.25][23470-0-0-0.12][23486-2-4-2.07][23497-0-3-4.62][23516-0-0-6.02][23690-1-4-1.53][23921-2-2-2.23][23936-1-0-0.23][24040-3-0-0.35]
[24111-1-4-2.00][24182-0-0-5.13][24238-3-3-3.44][24290-2-0-3.34][24345-0-0-2.72][24364-1-2-1.92][24427-3-0-3.13][24477-2-2-4.62][24495-2-2-0.78][24893-2-2-0.10]
[25012-1-2-0.09][25121-2-2-2.86][25165-3-3-0.90][25183-0-0-3.72][25297-3-3-3.40][25398-0-0-2.92][25574-2-2-2.63][25644-1-1-2.03][25718-1-4-0.46][25774-2-4-0.67]
[26032-3-3-2.92][26051-3-3-3.99][26120-0-4-2.47][26321-1-1-7.52][26732-1-1-3.70][26784-3-3-6.64][26827-3-3-1.75][26833-0-3-2.17][26838-2-3-1.14][26860-1-2-0.63]
[26948-0-0-1.51][27049-3-0-3.70][27098-1-1--0.10][27526-0-0-6.32][27639-3-3-1.32][27698-3-3-3.09][27772-0-0-3.36][27890-1-1-2.37][28040-0-4-1.76][28503-2-2-3.64]
[28577-1-1-5.05][28959-0-0-6.66][29198-3-4-1.33][29777-0-0-7.92][29877-2-2-0.87][30035-1-1-4.61][30098-0-0-2.32][30326-1-1-3.23][30572-2-2-2.76][30716-0-4-2.37]
[30806-2-3--0.01][30906-1-1-4.67][31007-0-0-1.71][31181-3-3-1.54][31238-0-3-1.85][31347-0-3-2.82][31422-2-2-4.09][31429-3-3-0.81][31431-0-0-0.82][31432-1-1-2.18]
[31477-0-3-3.17][31524-1-1-2.65][31597-1-4-2.10][31619-1-4-0.90][31701-0-0-3.52][31755-0-0-2.73][31854-3-3-3.89][32074-1-1-2.42][32078-3-3-3.94][32111-1-1-1.39]
[32127-1-1-2.53][32140-3-3-3.99][32263-2-4-1.19][32365-0-0-3.81][32411-2-0-3.20][32429-3-3-3.96][32473-3-4-1.20][32574-3-3-3.45][32584-0-4-2.53][32622-0-4-0.74]
[32858-3-3-3.25][32969-3-3-2.12][33016-2-2-3.82][33031-1-3-3.31][33035-2-2-2.73][33133-2-2-1.56][33173-2-2-1.65][33175-3-4-0.96][33306-3-3-1.45][33309-2-3-1.96]
[33474-0-4-1.12][33478-2-4-0.09][33618-1-1-1.96][33712-0-4-2.29][33782-2-4-1.04][33914-3-3-3.98][34076-3-4-2.69][34112-2-2-5.31][34138-2-3-0.42][34239-1-1-1.47]
[34364-2-2-5.30][34617-1-2-3.01][34751-3-3-2.65][34783-2-2-1.39][35015-3-4-1.46][35018-1-1-1.27][35288-2-1-0.22][0-4-2-1.25][1-4-4-3.61][2-4-4-3.25]
[3-4-4-3.18][4-4-4-1.91][5-4-1--0.99][6-4-0-3.96][7-4-4-2.92][8-4-4-1.18][9-4-4-0.95][10-4-4-4.59][11-4-4-2.93][12-4-4-1.33]
[14-4-4-1.73][15-4-3-1.90][16-4-4-2.71][17-4-4-0.68][18-4-4-2.33][19-4-0-1.99][20-4-0-1.01][21-4-4-1.28][22-4-4-2.01][23-4-4-1.55]
[24-4-4-5.97][25-4-4-1.95][26-4-4-0.82][27-4-4-2.42][28-4-4-3.70][29-4-2-1.18][30-4-4-0.46][31-4-4-1.68][32-4-4-2.27][33-4-4-2.64]
[34-4-4-1.68][35-4-0-2.75][37-4-4-3.24][39-4-0-4.20][40-4-4-1.14][41-4-4-0.07][42-4-4-1.80][43-4-4-1.74][45-4-2-2.48][46-4-4-5.39]
[47-4-4-5.46][48-4-4-1.78][51-4-4-3.64][52-4-4-1.82][53-4-2-0.87][54-4-3-0.67][55-4-4-1.02][56-4-4-1.13][57-4-3-1.23][58-4-2-3.28]
[59-4-4-1.90][60-4-4-1.00][61-4-4-4.47][62-4-4-0.37][63-4-2-3.14][64-4-2-1.01][65-4-4-4.31][66-4-4-1.84][67-4-4-0.67][68-4-4-0.31]
[69-4-4-1.02][70-4-4-3.13][72-4-4-2.28][73-4-1-2.40][74-4-2-2.09][75-4-4--0.79][77-4-4-4.33][78-4-4-0.75][79-4-2-2.07][80-4-4-3.27]
[81-4-4-3.24][82-4-4-0.76][83-4-4-1.38][84-4-4-3.72][85-4-4-5.70][86-4-4-0.92][87-4-4-3.61][88-4-4-2.38][89-4-4--0.00][90-4-4-1.37]
[91-4-4-3.34][92-4-4-1.71][93-4-4-1.29][94-4-4-2.90][95-4-4-0.79][96-4-4-1.30][97-4-4-4.44][98-4-2-1.68][99-4-4-1.98][100-4-4-2.55]
[101-4-4-5.95][102-4-4-3.04][103-4-3--0.15][104-4-4-2.00][105-4-2-1.17][106-4-4-3.81][107-4-0-0.39][108-4-4-1.46][109-4-4-1.69][110-4-4-2.51]
[111-4-0-2.64][112-4-4-1.13][113-4-4-0.22][114-4-4-0.61][115-4-4-2.04][116-4-4-1.37][117-4-4-3.03][119-4-4-1.41][121-4-4-3.11][122-4-4-2.75]
[124-4-4-1.44][125-4-4-3.22][126-4-4-5.02][127-4-2-1.58][128-4-4-0.34][129-4-4-1.60][130-4-4-2.44][131-4-4-2.27][132-4-4-1.13][133-4-4-4.18]
[135-4-4-2.95][136-4-4-0.18][137-4-4-1.64][138-4-4-1.71][139-4-4-3.17][140-4-1-2.08][141-4-4-0.33][142-4-4-4.48][143-4-4-2.84][144-4-4-2.25]
[145-4-4-1.91][148-4-0-3.28][149-4-4-3.42][150-4-4-5.41][151-4-4-3.69][152-4-4-4.11][153-4-4-1.75][154-4-4-5.08][155-4-4-3.53][156-4-4-1.80]
[157-4-0-2.19][158-4-4-2.84][160-4-1-0.84][161-4-2-0.95][162-4-4-0.37][164-4-4-2.49][165-4-4-1.75][167-4-4-3.06][168-4-4-2.27][170-4-4-1.44]
[171-4-4-3.19][172-4-4-3.05][173-4-4-4.93][174-4-0-1.88][175-4-4-3.18][177-4-4-4.91][178-4-4-2.85][179-4-4-1.02][180-4-4-2.71][181-4-4-1.94]
[182-4-3-1.73][183-4-4-3.16][184-4-2-1.96][186-4-4-0.56][187-4-2-1.00][188-4-4-1.71][189-4-4-1.37][190-4-4-0.86][191-4-4-2.43][192-4-4-0.68]
[193-4-2-2.40][194-4-4-0.40][195-4-2-1.60][196-4-4-2.16][197-4-4-1.97][198-4-4-5.62][199-4-4-1.75]
---------------------------
I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.139 | Acc: 92.000% | Wgt Acc: 97.245%
	I - Batch: 100 | Loss: 0.142 | Acc: 91.500% | Wgt Acc: 96.945%
	I - Batch: 150 | Loss: 0.151 | Acc: 91.375% | Wgt Acc: 96.949%
	I - Batch: 200 | Loss: 0.159 | Acc: 90.969% | Wgt Acc: 96.686%
I - num batch: 222
I - Train -- Loss: 0.160 | Acc: 90.584% | Wgt Acc: 96.511% | LR: 6.250000e-05 | Dur: 138.84s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   6. 105.]
 [  0. 574.   1.   0.  49.]
 [  0.   2. 730.   1.  80.]
 [  3.   0.   2. 525.  68.]
 [  8.   2.   1.   6. 698.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 67.061% | Wgt Acc: 63.672% | Dur: 14.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   5.   5.  14.  18.]
 [  0.  33.   3.   1.   4.]
 [  1.  14.  42.   4.  12.]
 [  9.  10.  14.  58.  10.]
 [  7.  16.  11.   9. 136.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 90.625% | Wgt Acc: 96.314%
	I - Batch: 100 | Loss: 0.144 | Acc: 90.812% | Wgt Acc: 96.668%
	I - Batch: 150 | Loss: 0.152 | Acc: 90.292% | Wgt Acc: 96.328%
	I - Batch: 200 | Loss: 0.150 | Acc: 90.438% | Wgt Acc: 96.520%
I - num batch: 222
I - Train -- Loss: 0.154 | Acc: 90.161% | Wgt Acc: 96.398% | LR: 6.250000e-05 | Dur: 136.65s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   6. 113.]
 [  1. 577.   0.   0.  32.]
 [  1.   0. 731.   1.  90.]
 [  5.   0.   0. 524.  82.]
 [  7.   1.   3.   7. 683.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.156 | Acc: 64.892% | Wgt Acc: 63.926% | Dur: 14.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   5.   5.  20.  22.]
 [  0.  40.   2.   0.   5.]
 [  0.  12.  37.   2.  12.]
 [  8.   8.  15.  57.  20.]
 [  6.  13.  16.   7. 121.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.169 | Acc: 90.125% | Wgt Acc: 96.490%
	I - Batch: 100 | Loss: 0.156 | Acc: 90.875% | Wgt Acc: 96.810%
	I - Batch: 150 | Loss: 0.151 | Acc: 91.000% | Wgt Acc: 96.832%
	I - Batch: 200 | Loss: 0.154 | Acc: 90.469% | Wgt Acc: 96.613%
I - num batch: 222
I - Train -- Loss: 0.156 | Acc: 90.414% | Wgt Acc: 96.635% | LR: 6.250000e-05 | Dur: 136.10s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   0.   6. 114.]
 [  0. 575.   0.   1.  43.]
 [  0.   1. 733.   0.  92.]
 [  1.   0.   0. 526.  65.]
 [  9.   1.   1.   5. 686.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.091 | Acc: 63.116% | Wgt Acc: 64.641% | Dur: 16.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   6.   3.  13.  25.]
 [  0.  41.   6.   0.   8.]
 [  0.  12.  40.   2.  14.]
 [ 17.   9.  17.  65.  26.]
 [  4.  10.   9.   6. 107.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.155 | Acc: 91.000% | Wgt Acc: 96.387%
	I - Batch: 100 | Loss: 0.151 | Acc: 90.688% | Wgt Acc: 96.503%
	I - Batch: 150 | Loss: 0.146 | Acc: 90.792% | Wgt Acc: 96.727%
	I - Batch: 200 | Loss: 0.150 | Acc: 90.562% | Wgt Acc: 96.572%
I - num batch: 222
I - Train -- Loss: 0.151 | Acc: 90.386% | Wgt Acc: 96.548% | LR: 6.250000e-05 | Dur: 133.93s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   1.   0.   6.  94.]
 [  0. 577.   1.   0.  46.]
 [  0.   0. 729.   1.  97.]
 [  3.   0.   1. 526.  75.]
 [  8.   0.   3.   5. 688.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.988 | Acc: 66.864% | Wgt Acc: 64.860% | Dur: 14.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   2.  10.  17.]
 [  0.  43.   9.   0.   6.]
 [  1.  12.  43.   4.  17.]
 [ 14.   7.  11.  62.  10.]
 [ 12.  14.  10.  10. 130.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.148 | Acc: 90.750% | Wgt Acc: 96.657%
	I - Batch: 100 | Loss: 0.152 | Acc: 89.938% | Wgt Acc: 96.255%
	I - Batch: 150 | Loss: 0.145 | Acc: 90.417% | Wgt Acc: 96.470%
	I - Batch: 200 | Loss: 0.151 | Acc: 90.188% | Wgt Acc: 96.304%
I - num batch: 222
I - Train -- Loss: 0.151 | Acc: 90.245% | Wgt Acc: 96.284% | LR: 6.250000e-05 | Dur: 141.67s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   1.   0.   6.  94.]
 [  2. 574.   0.   0.  42.]
 [  2.   0. 730.   0. 101.]
 [  3.   0.   0. 526.  72.]
 [ 10.   3.   4.   6. 691.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.090 | Acc: 65.680% | Wgt Acc: 63.361% | Dur: 15.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   7.   5.  14.  16.]
 [  1.  41.   8.   1.  13.]
 [  0.   8.  37.   2.  14.]
 [ 14.   9.  11.  58.   8.]
 [  5.  13.  14.  11. 129.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.147 | Acc: 91.375% | Wgt Acc: 96.885%
	I - Batch: 100 | Loss: 0.138 | Acc: 91.375% | Wgt Acc: 97.047%
	I - Batch: 150 | Loss: 0.130 | Acc: 92.375% | Wgt Acc: 97.441%
	I - Batch: 200 | Loss: 0.135 | Acc: 92.000% | Wgt Acc: 97.139%
I - num batch: 208
I - Train -- Loss: 0.136 | Acc: 91.827% | Wgt Acc: 97.094% | LR: 6.250000e-05 | Dur: 127.72s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   1.   0.   3.  80.]
 [  0. 576.   0.   0.  39.]
 [  0.   0. 729.   1.  78.]
 [  2.   0.   2. 530.  48.]
 [ 10.   1.   3.   4. 536.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.099 | Acc: 62.130% | Wgt Acc: 63.095% | Dur: 14.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   6.   4.  16.  26.]
 [  1.  40.   7.   0.   8.]
 [  2.  16.  45.   7.  21.]
 [ 14.   8.  11.  56.  18.]
 [  4.   8.   8.   7. 107.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.145 | Acc: 90.250% | Wgt Acc: 96.750%
	I - Batch: 100 | Loss: 0.144 | Acc: 90.250% | Wgt Acc: 96.655%
	I - Batch: 150 | Loss: 0.148 | Acc: 90.625% | Wgt Acc: 96.761%
	I - Batch: 200 | Loss: 0.145 | Acc: 90.656% | Wgt Acc: 96.809%
I - num batch: 222
I - Train -- Loss: 0.144 | Acc: 90.866% | Wgt Acc: 96.905% | LR: 6.250000e-05 | Dur: 141.82s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   6.  92.]
 [  0. 577.   0.   0.  42.]
 [  0.   0. 734.   1.  87.]
 [  3.   1.   0. 528.  82.]
 [  7.   0.   0.   3. 697.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.064 | Acc: 64.694% | Wgt Acc: 60.777% | Dur: 15.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   5.   1.  12.  15.]
 [  1.  36.   5.   0.   7.]
 [  1.  10.  38.   1.  13.]
 [ 13.   7.  14.  60.  10.]
 [ 14.  20.  17.  13. 135.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.125 | Acc: 92.750% | Wgt Acc: 97.850%
	I - Batch: 100 | Loss: 0.127 | Acc: 92.438% | Wgt Acc: 97.735%
	I - Batch: 150 | Loss: 0.133 | Acc: 91.875% | Wgt Acc: 97.256%
	I - Batch: 200 | Loss: 0.137 | Acc: 91.812% | Wgt Acc: 97.171%
I - num batch: 222
I - Train -- Loss: 0.134 | Acc: 91.824% | Wgt Acc: 97.199% | LR: 6.250000e-05 | Dur: 133.44s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   2.   0.   4.  91.]
 [  1. 575.   0.   0.  30.]
 [  0.   0. 731.   0.  99.]
 [  0.   0.   1. 531.  50.]
 [  6.   1.   2.   3. 730.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.083 | Acc: 64.497% | Wgt Acc: 62.369% | Dur: 14.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   6.   3.  15.  18.]
 [  0.  39.   6.   0.   6.]
 [  2.  17.  42.   4.  18.]
 [ 13.   6.  11.  58.  12.]
 [ 11.  10.  13.   9. 126.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.155 | Acc: 90.375% | Wgt Acc: 96.432%
	I - Batch: 100 | Loss: 0.148 | Acc: 91.000% | Wgt Acc: 96.726%
	I - Batch: 150 | Loss: 0.143 | Acc: 91.125% | Wgt Acc: 96.806%
	I - Batch: 200 | Loss: 0.141 | Acc: 91.375% | Wgt Acc: 96.919%
I - num batch: 222
I - Train -- Loss: 0.142 | Acc: 91.176% | Wgt Acc: 96.833% | LR: 6.250000e-05 | Dur: 133.12s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   3.  99.]
 [  0. 575.   0.   0.  31.]
 [  1.   1. 730.   0.  87.]
 [  2.   0.   0. 532.  69.]
 [ 11.   2.   4.   3. 714.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.070 | Acc: 64.694% | Wgt Acc: 60.408% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   3.  16.  18.]
 [  0.  34.   6.   2.   3.]
 [  2.  16.  40.   2.  15.]
 [ 11.   8.  12.  54.   8.]
 [ 11.  16.  14.  12. 136.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.147 | Acc: 89.625% | Wgt Acc: 95.964%
	I - Batch: 100 | Loss: 0.147 | Acc: 90.500% | Wgt Acc: 96.391%
	I - Batch: 150 | Loss: 0.144 | Acc: 90.667% | Wgt Acc: 96.414%
	I - Batch: 200 | Loss: 0.143 | Acc: 91.094% | Wgt Acc: 96.673%
I - num batch: 222
I - Train -- Loss: 0.143 | Acc: 90.978% | Wgt Acc: 96.684% | LR: 6.250000e-05 | Dur: 140.84s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   0.   0.   4. 100.]
 [  1. 577.   0.   0.  38.]
 [  1.   0. 731.   1.  93.]
 [  3.   0.   1. 527.  59.]
 [ 10.   1.   2.   6. 710.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.039 | Acc: 66.272% | Wgt Acc: 62.726% | Dur: 14.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   6.   2.  12.  16.]
 [  0.  37.   6.   1.   4.]
 [  0.  13.  40.   4.  14.]
 [ 16.  10.  14.  61.  10.]
 [ 10.  12.  13.   8. 136.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 91.500% | Wgt Acc: 97.398%
	I - Batch: 100 | Loss: 0.141 | Acc: 91.312% | Wgt Acc: 96.957%
	I - Batch: 150 | Loss: 0.137 | Acc: 91.458% | Wgt Acc: 97.017%
	I - Batch: 200 | Loss: 0.136 | Acc: 91.188% | Wgt Acc: 96.870%
I - num batch: 222
I - Train -- Loss: 0.135 | Acc: 91.091% | Wgt Acc: 96.859% | LR: 6.250000e-05 | Dur: 131.80s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   1.   0.   4. 110.]
 [  0. 575.   2.   0.  35.]
 [  1.   1. 729.   1.  90.]
 [  2.   0.   0. 530.  56.]
 [  6.   1.   3.   3. 709.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.062 | Acc: 66.469% | Wgt Acc: 65.713% | Dur: 14.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   1.   8.  14.]
 [  0.  41.   7.   1.   6.]
 [  0.  15.  43.   1.  14.]
 [ 19.  11.  14.  69.  22.]
 [  9.   9.  10.   7. 124.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 90.875% | Wgt Acc: 96.810%
	I - Batch: 100 | Loss: 0.130 | Acc: 91.438% | Wgt Acc: 96.962%
	I - Batch: 150 | Loss: 0.132 | Acc: 91.333% | Wgt Acc: 96.983%
	I - Batch: 200 | Loss: 0.131 | Acc: 91.656% | Wgt Acc: 97.036%
I - num batch: 222
I - Train -- Loss: 0.131 | Acc: 91.683% | Wgt Acc: 97.084% | LR: 6.250000e-05 | Dur: 132.44s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   2.  98.]
 [  0. 577.   0.   1.  40.]
 [  0.   0. 732.   0.  77.]
 [  0.   0.   0. 532.  57.]
 [ 14.   1.   2.   3. 728.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.093 | Acc: 65.286% | Wgt Acc: 62.749% | Dur: 13.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   5.   2.  11.  14.]
 [  0.  38.   4.   0.   6.]
 [  1.  11.  41.   2.  14.]
 [ 20.   9.  17.  65.  16.]
 [ 10.  15.  11.   8. 130.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.130 | Acc: 91.250% | Wgt Acc: 96.772%
	I - Batch: 100 | Loss: 0.134 | Acc: 91.312% | Wgt Acc: 96.932%
	I - Batch: 150 | Loss: 0.135 | Acc: 91.375% | Wgt Acc: 96.981%
	I - Batch: 200 | Loss: 0.135 | Acc: 91.406% | Wgt Acc: 96.967%
I - num batch: 222
I - Train -- Loss: 0.135 | Acc: 91.401% | Wgt Acc: 96.945% | LR: 6.250000e-05 | Dur: 137.54s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   3.  98.]
 [  0. 574.   0.   0.  38.]
 [  0.   1. 730.   0.  79.]
 [  2.   0.   1. 531.  65.]
 [  8.   3.   3.   4. 720.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.044 | Acc: 68.442% | Wgt Acc: 64.479% | Dur: 19.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   5.   2.   8.  10.]
 [  0.  40.   3.   0.   2.]
 [  0.  10.  39.   1.  12.]
 [ 12.   7.  12.  63.  14.]
 [ 13.  16.  19.  14. 142.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.135 | Acc: 91.125% | Wgt Acc: 96.629%
	I - Batch: 100 | Loss: 0.138 | Acc: 90.625% | Wgt Acc: 96.635%
	I - Batch: 150 | Loss: 0.136 | Acc: 90.875% | Wgt Acc: 96.618%
	I - Batch: 200 | Loss: 0.133 | Acc: 91.188% | Wgt Acc: 96.849%
I - num batch: 222
I - Train -- Loss: 0.132 | Acc: 91.401% | Wgt Acc: 96.887% | LR: 6.250000e-05 | Dur: 134.97s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   3.  78.]
 [  0. 574.   1.   0.  37.]
 [  1.   0. 731.   0.  90.]
 [  0.   0.   0. 530.  73.]
 [ 11.   4.   2.   5. 722.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.024 | Acc: 68.639% | Wgt Acc: 64.618% | Dur: 14.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   2.  14.  11.]
 [  1.  41.   8.   1.   5.]
 [  1.  14.  42.   2.  12.]
 [ 10.   9.  10.  57.  10.]
 [ 10.  11.  13.  12. 142.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.113 | Acc: 93.000% | Wgt Acc: 97.537%
	I - Batch: 100 | Loss: 0.121 | Acc: 92.688% | Wgt Acc: 97.379%
	I - Batch: 150 | Loss: 0.119 | Acc: 92.708% | Wgt Acc: 97.393%
	I - Batch: 200 | Loss: 0.120 | Acc: 92.688% | Wgt Acc: 97.327%
I - num batch: 222
I - Train -- Loss: 0.120 | Acc: 92.529% | Wgt Acc: 97.301% | LR: 6.250000e-05 | Dur: 134.51s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   4.  86.]
 [  0. 576.   0.   0.  31.]
 [  0.   0. 732.   0.  62.]
 [  2.   0.   0. 528.  63.]
 [  7.   2.   2.   6. 758.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.069 | Acc: 66.667% | Wgt Acc: 62.023% | Dur: 14.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   3.   3.   8.  10.]
 [  0.  34.   6.   1.   3.]
 [  1.  14.  41.   1.  14.]
 [ 16.  10.  12.  63.  11.]
 [ 13.  17.  13.  13. 142.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.122 | Acc: 90.875% | Wgt Acc: 96.897%
	I - Batch: 100 | Loss: 0.121 | Acc: 91.750% | Wgt Acc: 97.126%
	I - Batch: 150 | Loss: 0.121 | Acc: 91.708% | Wgt Acc: 97.059%
	I - Batch: 200 | Loss: 0.118 | Acc: 92.125% | Wgt Acc: 97.264%
I - num batch: 222
I - Train -- Loss: 0.120 | Acc: 91.993% | Wgt Acc: 97.255% | LR: 6.250000e-05 | Dur: 135.74s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   1.  92.]
 [  0. 575.   0.   1.  45.]
 [  0.   0. 732.   0.  70.]
 [  2.   1.   0. 534.  57.]
 [  9.   2.   2.   2. 736.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.986 | Acc: 68.442% | Wgt Acc: 64.548% | Dur: 17.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   4.   1.   7.   8.]
 [  0.  38.   4.   1.   4.]
 [  0.  16.  51.   4.  21.]
 [ 15.   9.   8.  58.   6.]
 [ 14.  11.  11.  16. 141.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.119 | Acc: 92.250% | Wgt Acc: 97.504%
	I - Batch: 100 | Loss: 0.122 | Acc: 92.000% | Wgt Acc: 97.375%
	I - Batch: 150 | Loss: 0.117 | Acc: 92.125% | Wgt Acc: 97.348%
	I - Batch: 200 | Loss: 0.118 | Acc: 91.875% | Wgt Acc: 97.281%
I - num batch: 222
I - Train -- Loss: 0.119 | Acc: 91.965% | Wgt Acc: 97.291% | LR: 6.250000e-05 | Dur: 133.58s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   1.   1.  93.]
 [  0. 576.   1.   0.  36.]
 [  0.   1. 730.   0.  79.]
 [  0.   0.   0. 530.  59.]
 [  4.   1.   2.   7. 733.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 68.245% | Wgt Acc: 65.829% | Dur: 14.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   3.   5.  10.  11.]
 [  2.  44.  10.   2.   7.]
 [  0.  12.  46.   5.  19.]
 [ 14.   7.   8.  59.   9.]
 [  9.  12.   6.  10. 134.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.114 | Acc: 93.375% | Wgt Acc: 97.724%
	I - Batch: 100 | Loss: 0.113 | Acc: 93.000% | Wgt Acc: 97.716%
	I - Batch: 150 | Loss: 0.125 | Acc: 92.667% | Wgt Acc: 97.444%
	I - Batch: 200 | Loss: 0.124 | Acc: 92.750% | Wgt Acc: 97.544%
I - num batch: 222
I - Train -- Loss: 0.123 | Acc: 92.726% | Wgt Acc: 97.507% | LR: 6.250000e-05 | Dur: 135.89s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   1.  85.]
 [  0. 576.   0.   0.  37.]
 [  1.   0. 729.   0.  61.]
 [  0.   0.   1. 533.  57.]
 [  5.   2.   4.   4. 760.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 66.469% | Wgt Acc: 65.529% | Dur: 14.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   4.  10.  15.]
 [  0.  39.   7.   2.   4.]
 [  2.  16.  49.   3.  24.]
 [ 13.   9.   7.  62.  13.]
 [ 10.  10.   8.   9. 124.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.104 | Acc: 93.000% | Wgt Acc: 98.012%
	I - Batch: 100 | Loss: 0.112 | Acc: 92.500% | Wgt Acc: 97.508%
	I - Batch: 150 | Loss: 0.120 | Acc: 92.250% | Wgt Acc: 97.366%
	I - Batch: 200 | Loss: 0.122 | Acc: 92.188% | Wgt Acc: 97.285%
I - num batch: 222
I - Train -- Loss: 0.122 | Acc: 92.191% | Wgt Acc: 97.262% | LR: 6.250000e-05 | Dur: 136.78s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   2.   1. 103.]
 [  0. 577.   0.   0.  41.]
 [  0.   0. 728.   0.  67.]
 [  1.   0.   0. 536.  44.]
 [ 12.   1.   4.   1. 745.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.145 | Acc: 63.511% | Wgt Acc: 60.789% | Dur: 14.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   5.   2.  15.  18.]
 [  0.  37.   7.   1.   5.]
 [  1.  15.  36.   2.  16.]
 [ 12.   6.  12.  57.  14.]
 [ 10.  15.  18.  11. 127.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 91.875% | Wgt Acc: 96.838%
	I - Batch: 100 | Loss: 0.127 | Acc: 91.750% | Wgt Acc: 96.940%
	I - Batch: 150 | Loss: 0.121 | Acc: 91.958% | Wgt Acc: 97.237%
	I - Batch: 200 | Loss: 0.119 | Acc: 92.062% | Wgt Acc: 97.381%
I - num batch: 222
I - Train -- Loss: 0.120 | Acc: 92.162% | Wgt Acc: 97.406% | LR: 6.250000e-05 | Dur: 137.12s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  82.]
 [  0. 578.   0.   1.  35.]
 [  0.   0. 733.   1.  73.]
 [  1.   0.   0. 531.  72.]
 [  7.   0.   1.   5. 738.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.076 | Acc: 66.864% | Wgt Acc: 61.792% | Dur: 14.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   3.  11.  12.]
 [  0.  31.   3.   0.   2.]
 [  0.  14.  41.   3.   9.]
 [ 16.  10.  10.  61.  13.]
 [ 10.  20.  18.  11. 144.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.115 | Acc: 93.750% | Wgt Acc: 97.906%
	I - Batch: 100 | Loss: 0.112 | Acc: 93.750% | Wgt Acc: 97.977%
	I - Batch: 150 | Loss: 0.113 | Acc: 93.250% | Wgt Acc: 97.870%
	I - Batch: 200 | Loss: 0.110 | Acc: 93.188% | Wgt Acc: 97.866%
I - num batch: 222
I - Train -- Loss: 0.109 | Acc: 93.065% | Wgt Acc: 97.855% | LR: 6.250000e-05 | Dur: 134.97s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  91.]
 [  0. 575.   0.   0.  30.]
 [  0.   1. 734.   0.  74.]
 [  1.   1.   0. 536.  42.]
 [  3.   1.   0.   2. 763.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.055 | Acc: 68.245% | Wgt Acc: 64.018% | Dur: 17.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   2.   6.  15.]
 [  0.  39.   4.   1.   1.]
 [  0.  13.  37.   2.   8.]
 [ 19.   7.  14.  64.  13.]
 [  6.  17.  18.  13. 143.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.118 | Acc: 93.000% | Wgt Acc: 97.207%
	I - Batch: 100 | Loss: 0.113 | Acc: 93.125% | Wgt Acc: 97.269%
	I - Batch: 150 | Loss: 0.120 | Acc: 92.292% | Wgt Acc: 96.977%
	I - Batch: 200 | Loss: 0.122 | Acc: 91.938% | Wgt Acc: 96.978%
I - num batch: 222
I - Train -- Loss: 0.121 | Acc: 91.937% | Wgt Acc: 97.002% | LR: 6.250000e-05 | Dur: 136.17s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   1.   0.   5.  86.]
 [  0. 574.   0.   0.  36.]
 [  0.   0. 728.   0.  84.]
 [  1.   0.   0. 529.  52.]
 [  8.   3.   6.   4. 742.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.081 | Acc: 65.483% | Wgt Acc: 63.003% | Dur: 14.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   4.  18.  19.]
 [  0.  39.   5.   1.   7.]
 [  1.  12.  37.   3.  13.]
 [  8.   9.  13.  55.  12.]
 [  7.  14.  16.   9. 129.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.117 | Acc: 92.375% | Wgt Acc: 97.035%
	I - Batch: 100 | Loss: 0.111 | Acc: 92.750% | Wgt Acc: 97.347%
	I - Batch: 150 | Loss: 0.107 | Acc: 93.292% | Wgt Acc: 97.735%
	I - Batch: 200 | Loss: 0.106 | Acc: 93.375% | Wgt Acc: 97.785%
I - num batch: 222
I - Train -- Loss: 0.105 | Acc: 93.375% | Wgt Acc: 97.825% | LR: 6.250000e-05 | Dur: 136.17s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  83.]
 [  0. 576.   1.   0.  17.]
 [  1.   1. 732.   1.  68.]
 [  0.   1.   0. 534.  54.]
 [  4.   0.   1.   3. 778.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.103 | Acc: 65.483% | Wgt Acc: 61.931% | Dur: 15.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   8.   3.  18.  19.]
 [  1.  36.   6.   1.   3.]
 [  1.  13.  39.   2.  17.]
 [  8.   6.  10.  55.   7.]
 [ 10.  15.  17.  10. 134.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.111 | Acc: 93.125% | Wgt Acc: 97.876%
	I - Batch: 100 | Loss: 0.118 | Acc: 92.562% | Wgt Acc: 97.403%
	I - Batch: 150 | Loss: 0.115 | Acc: 93.083% | Wgt Acc: 97.623%
	I - Batch: 200 | Loss: 0.112 | Acc: 93.406% | Wgt Acc: 97.773%
I - num batch: 222
I - Train -- Loss: 0.113 | Acc: 93.036% | Wgt Acc: 97.652% | LR: 6.250000e-05 | Dur: 143.41s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   1.   0.   2.  82.]
 [  0. 575.   0.   0.  33.]
 [  0.   0. 733.   0.  57.]
 [  3.   0.   0. 535.  59.]
 [  6.   2.   1.   1. 769.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 65.680% | Wgt Acc: 62.288% | Dur: 15.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   5.  16.  19.]
 [  1.  42.  10.   0.   5.]
 [  1.   9.  32.   2.  12.]
 [ 10.   6.  12.  56.  10.]
 [  7.  16.  16.  12. 134.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.106 | Acc: 93.125% | Wgt Acc: 97.508%
	I - Batch: 100 | Loss: 0.105 | Acc: 93.125% | Wgt Acc: 97.456%
	I - Batch: 150 | Loss: 0.108 | Acc: 92.708% | Wgt Acc: 97.432%
	I - Batch: 200 | Loss: 0.110 | Acc: 92.688% | Wgt Acc: 97.451%
I - num batch: 222
I - Train -- Loss: 0.109 | Acc: 92.867% | Wgt Acc: 97.518% | LR: 6.250000e-05 | Dur: 137.25s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   2.  70.]
 [  0. 574.   0.   0.  35.]
 [  0.   1. 732.   0.  69.]
 [  2.   1.   1. 534.  60.]
 [  7.   2.   1.   2. 766.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.078 | Acc: 64.694% | Wgt Acc: 63.568% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   2.   8.  18.]
 [  0.  40.   9.   2.  10.]
 [  0.  14.  40.   4.  17.]
 [ 15.   8.  11.  62.  13.]
 [  9.  12.  13.  10. 122.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 92.125% | Wgt Acc: 97.447%
	I - Batch: 100 | Loss: 0.110 | Acc: 92.625% | Wgt Acc: 97.348%
	I - Batch: 150 | Loss: 0.108 | Acc: 92.792% | Wgt Acc: 97.571%
	I - Batch: 200 | Loss: 0.109 | Acc: 92.719% | Wgt Acc: 97.599%
I - num batch: 222
I - Train -- Loss: 0.109 | Acc: 92.839% | Wgt Acc: 97.673% | LR: 6.250000e-05 | Dur: 138.60s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   2.  63.]
 [  0. 574.   0.   0.  39.]
 [  0.   1. 734.   0.  77.]
 [  1.   0.   0. 533.  62.]
 [  3.   3.   0.   3. 759.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.062 | Acc: 68.442% | Wgt Acc: 66.359% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   2.   8.  23.]
 [  0.  43.   7.   2.   4.]
 [  0.  11.  41.   2.   9.]
 [ 13.  10.  13.  62.  11.]
 [  7.  11.  12.  12. 133.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.105 | Acc: 92.625% | Wgt Acc: 97.354%
	I - Batch: 100 | Loss: 0.107 | Acc: 93.000% | Wgt Acc: 97.638%
	I - Batch: 150 | Loss: 0.107 | Acc: 93.083% | Wgt Acc: 97.725%
	I - Batch: 200 | Loss: 0.107 | Acc: 92.906% | Wgt Acc: 97.669%
I - num batch: 222
I - Train -- Loss: 0.109 | Acc: 92.783% | Wgt Acc: 97.586% | LR: 6.250000e-05 | Dur: 134.44s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   1.  89.]
 [  0. 577.   0.   0.  29.]
 [  1.   0. 731.   0.  68.]
 [  4.   0.   0. 535.  54.]
 [  4.   1.   3.   2. 760.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.056 | Acc: 67.456% | Wgt Acc: 63.822% | Dur: 14.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   2.  10.  12.]
 [  0.  40.   7.   0.   5.]
 [  1.  12.  43.   4.  16.]
 [ 11.   6.   9.  56.   9.]
 [ 11.  17.  14.  16. 138.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.096 | Acc: 92.875% | Wgt Acc: 97.811%
	I - Batch: 100 | Loss: 0.097 | Acc: 92.938% | Wgt Acc: 97.956%
	I - Batch: 150 | Loss: 0.104 | Acc: 92.958% | Wgt Acc: 97.706%
	I - Batch: 200 | Loss: 0.105 | Acc: 93.094% | Wgt Acc: 97.687%
I - num batch: 222
I - Train -- Loss: 0.106 | Acc: 93.036% | Wgt Acc: 97.710% | LR: 6.250000e-05 | Dur: 140.35s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  92.]
 [  0. 577.   0.   0.  31.]
 [  0.   0. 732.   0.  64.]
 [  2.   0.   0. 535.  46.]
 [  6.   1.   2.   2. 767.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.047 | Acc: 67.061% | Wgt Acc: 62.438% | Dur: 14.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   1.   3.  13.  11.]
 [  0.  38.   4.   1.   7.]
 [  3.  13.  42.   3.  13.]
 [ 11.   5.   7.  56.   7.]
 [ 12.  21.  19.  13. 142.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.099 | Acc: 93.625% | Wgt Acc: 98.128%
	I - Batch: 100 | Loss: 0.101 | Acc: 93.688% | Wgt Acc: 98.028%
	I - Batch: 150 | Loss: 0.099 | Acc: 93.792% | Wgt Acc: 98.016%
	I - Batch: 200 | Loss: 0.099 | Acc: 93.656% | Wgt Acc: 97.928%
I - num batch: 222
I - Train -- Loss: 0.098 | Acc: 93.769% | Wgt Acc: 97.937% | LR: 6.250000e-05 | Dur: 132.91s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   2.  75.]
 [  0. 577.   0.   0.  27.]
 [  1.   1. 730.   0.  57.]
 [  0.   0.   0. 535.  49.]
 [  4.   0.   4.   1. 792.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.111 | Acc: 66.864% | Wgt Acc: 62.876% | Dur: 14.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   3.  12.  17.]
 [  0.  41.   7.   0.   5.]
 [  1.   8.  36.   1.  12.]
 [ 13.   9.  13.  58.   7.]
 [  9.  17.  16.  15. 139.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.104 | Acc: 93.000% | Wgt Acc: 97.576%
	I - Batch: 100 | Loss: 0.104 | Acc: 93.438% | Wgt Acc: 97.777%
	I - Batch: 150 | Loss: 0.102 | Acc: 93.250% | Wgt Acc: 97.752%
	I - Batch: 200 | Loss: 0.103 | Acc: 93.469% | Wgt Acc: 97.720%
I - num batch: 222
I - Train -- Loss: 0.102 | Acc: 93.487% | Wgt Acc: 97.774% | LR: 6.250000e-05 | Dur: 135.37s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   1.  80.]
 [  0. 577.   0.   0.  32.]
 [  0.   0. 730.   0.  56.]
 [  0.   0.   1. 534.  47.]
 [  7.   1.   3.   3. 785.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.053 | Acc: 66.667% | Wgt Acc: 63.049% | Dur: 16.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   3.   8.  14.]
 [  0.  39.   5.   1.   6.]
 [  1.  12.  38.   1.  16.]
 [ 12.   7.  12.  60.   7.]
 [ 11.  15.  17.  16. 137.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 93.125% | Wgt Acc: 97.527%
	I - Batch: 100 | Loss: 0.097 | Acc: 93.750% | Wgt Acc: 97.990%
	I - Batch: 150 | Loss: 0.101 | Acc: 93.542% | Wgt Acc: 97.738%
	I - Batch: 200 | Loss: 0.102 | Acc: 93.500% | Wgt Acc: 97.749%
I - num batch: 222
I - Train -- Loss: 0.102 | Acc: 93.459% | Wgt Acc: 97.740% | LR: 6.250000e-05 | Dur: 137.80s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  80.]
 [  0. 576.   0.   0.  34.]
 [  1.   0. 730.   0.  50.]
 [  1.   0.   0. 535.  51.]
 [  6.   2.   4.   2. 785.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.114 | Acc: 65.680% | Wgt Acc: 60.893% | Dur: 14.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   5.  16.  16.]
 [  1.  37.   5.   0.   5.]
 [  2.  11.  38.   3.  12.]
 [ 10.   7.  12.  52.   7.]
 [  9.  20.  15.  15. 140.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.094 | Acc: 93.125% | Wgt Acc: 97.917%
	I - Batch: 100 | Loss: 0.103 | Acc: 92.500% | Wgt Acc: 97.584%
	I - Batch: 150 | Loss: 0.101 | Acc: 93.000% | Wgt Acc: 97.770%
	I - Batch: 200 | Loss: 0.099 | Acc: 93.344% | Wgt Acc: 97.815%
I - num batch: 222
I - Train -- Loss: 0.100 | Acc: 93.403% | Wgt Acc: 97.811% | LR: 6.250000e-05 | Dur: 133.97s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   1.  78.]
 [  0. 578.   0.   0.  30.]
 [  1.   0. 733.   0.  63.]
 [  1.   0.   0. 535.  49.]
 [  8.   0.   1.   2. 780.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.052 | Acc: 66.667% | Wgt Acc: 63.314% | Dur: 15.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   6.   5.  21.  22.]
 [  0.  44.   7.   0.   4.]
 [  1.   9.  35.   1.  11.]
 [  6.   5.  11.  51.   8.]
 [  8.  14.  17.  13. 135.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.085 | Acc: 94.125% | Wgt Acc: 98.221%
	I - Batch: 100 | Loss: 0.086 | Acc: 94.062% | Wgt Acc: 98.206%
	I - Batch: 150 | Loss: 0.085 | Acc: 94.375% | Wgt Acc: 98.294%
	I - Batch: 200 | Loss: 0.087 | Acc: 94.406% | Wgt Acc: 98.330%
I - num batch: 208
I - Train -- Loss: 0.086 | Acc: 94.471% | Wgt Acc: 98.360% | LR: 6.250000e-05 | Dur: 122.85s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   2.  60.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 733.   0.  55.]
 [  0.   0.   0. 535.  43.]
 [  3.   0.   1.   1. 604.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.150 | Acc: 65.483% | Wgt Acc: 61.873% | Dur: 13.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   4.  16.  23.]
 [  0.  33.   2.   0.   2.]
 [  1.  15.  40.   2.  13.]
 [  9.   4.  11.  54.   8.]
 [  7.  22.  18.  14. 134.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 93.750% | Wgt Acc: 97.817%
	I - Batch: 100 | Loss: 0.106 | Acc: 92.750% | Wgt Acc: 97.322%
	I - Batch: 150 | Loss: 0.110 | Acc: 93.167% | Wgt Acc: 97.444%
	I - Batch: 200 | Loss: 0.104 | Acc: 93.375% | Wgt Acc: 97.610%
I - num batch: 222
I - Train -- Loss: 0.102 | Acc: 93.459% | Wgt Acc: 97.647% | LR: 6.250000e-05 | Dur: 139.23s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   4.  79.]
 [  0. 577.   0.   0.  30.]
 [  0.   0. 732.   0.  54.]
 [  4.   0.   0. 531.  49.]
 [  6.   1.   2.   3. 788.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 65.680% | Wgt Acc: 60.316% | Dur: 17.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  12.  11.]
 [  1.  39.   6.   2.   5.]
 [  1.  11.  38.   3.  18.]
 [  9.   4.   9.  53.   3.]
 [ 17.  22.  20.  16. 143.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.081 | Acc: 95.500% | Wgt Acc: 98.689%
	I - Batch: 100 | Loss: 0.085 | Acc: 94.938% | Wgt Acc: 98.499%
	I - Batch: 150 | Loss: 0.093 | Acc: 94.083% | Wgt Acc: 97.972%
	I - Batch: 200 | Loss: 0.096 | Acc: 93.625% | Wgt Acc: 97.704%
I - num batch: 222
I - Train -- Loss: 0.095 | Acc: 93.600% | Wgt Acc: 97.750% | LR: 6.250000e-05 | Dur: 134.44s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  74.]
 [  1. 577.   0.   0.  25.]
 [  1.   1. 729.   0.  59.]
 [  0.   0.   0. 534.  51.]
 [  6.   0.   5.   3. 791.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.106 | Acc: 66.864% | Wgt Acc: 62.403% | Dur: 14.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   6.   4.  12.  20.]
 [  0.  40.   5.   1.   5.]
 [  2.  11.  35.   1.   8.]
 [ 13.   5.  10.  56.   6.]
 [  6.  16.  21.  16. 141.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.093 | Acc: 93.750% | Wgt Acc: 98.072%
	I - Batch: 100 | Loss: 0.090 | Acc: 93.938% | Wgt Acc: 98.105%
	I - Batch: 150 | Loss: 0.093 | Acc: 93.542% | Wgt Acc: 97.873%
	I - Batch: 200 | Loss: 0.094 | Acc: 93.438% | Wgt Acc: 97.843%
I - num batch: 222
I - Train -- Loss: 0.095 | Acc: 93.431% | Wgt Acc: 97.872% | LR: 6.250000e-05 | Dur: 136.62s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   1.  80.]
 [  0. 575.   0.   0.  25.]
 [  0.   0. 732.   0.  64.]
 [  1.   0.   0. 536.  52.]
 [  4.   3.   2.   1. 779.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 68.245% | Wgt Acc: 62.611% | Dur: 19.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   3.   6.  12.  10.]
 [  0.  37.   3.   0.   5.]
 [  1.  10.  41.   1.  10.]
 [ 15.   4.   7.  58.   6.]
 [ 11.  24.  18.  15. 149.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.091 | Acc: 93.750% | Wgt Acc: 98.293%
	I - Batch: 100 | Loss: 0.090 | Acc: 93.875% | Wgt Acc: 98.212%
	I - Batch: 150 | Loss: 0.090 | Acc: 93.792% | Wgt Acc: 98.101%
	I - Batch: 200 | Loss: 0.091 | Acc: 93.906% | Wgt Acc: 98.037%
I - num batch: 222
I - Train -- Loss: 0.092 | Acc: 93.741% | Wgt Acc: 97.986% | LR: 6.250000e-05 | Dur: 135.42s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   1.  71.]
 [  0. 576.   0.   0.  28.]
 [  0.   1. 733.   0.  63.]
 [  0.   0.   0. 536.  49.]
 [  6.   1.   1.   1. 789.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 67.258% | Wgt Acc: 60.916% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   5.   3.  17.  13.]
 [  0.  41.   4.   1.   2.]
 [  1.   8.  36.   1.  11.]
 [  8.   4.   9.  49.   4.]
 [ 14.  20.  23.  18. 150.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.092 | Acc: 93.750% | Wgt Acc: 97.808%
	I - Batch: 100 | Loss: 0.097 | Acc: 93.500% | Wgt Acc: 97.790%
	I - Batch: 150 | Loss: 0.101 | Acc: 92.875% | Wgt Acc: 97.469%
	I - Batch: 200 | Loss: 0.101 | Acc: 93.125% | Wgt Acc: 97.628%
I - num batch: 222
I - Train -- Loss: 0.100 | Acc: 93.290% | Wgt Acc: 97.699% | LR: 6.250000e-05 | Dur: 134.43s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   0.  84.]
 [  0. 577.   1.   0.  26.]
 [  0.   0. 731.   0.  60.]
 [  1.   0.   0. 536.  51.]
 [ 10.   1.   2.   2. 779.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.138 | Acc: 66.469% | Wgt Acc: 63.142% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   6.   4.  11.  20.]
 [  0.  42.   7.   0.   4.]
 [  1.  13.  38.   4.  12.]
 [  9.   8.  11.  56.   9.]
 [ 12.   9.  15.  15. 135.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.100 | Acc: 93.500% | Wgt Acc: 97.987%
	I - Batch: 100 | Loss: 0.090 | Acc: 94.250% | Wgt Acc: 98.224%
	I - Batch: 150 | Loss: 0.094 | Acc: 93.875% | Wgt Acc: 98.016%
	I - Batch: 200 | Loss: 0.095 | Acc: 93.719% | Wgt Acc: 98.004%
I - num batch: 222
I - Train -- Loss: 0.094 | Acc: 93.741% | Wgt Acc: 98.036% | LR: 6.250000e-05 | Dur: 135.08s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   3.  78.]
 [  1. 577.   1.   0.  29.]
 [  0.   0. 732.   0.  60.]
 [  0.   0.   0. 534.  46.]
 [  1.   1.   1.   1. 787.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.114 | Acc: 69.034% | Wgt Acc: 64.641% | Dur: 14.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   3.   7.  15.]
 [  0.  35.   3.   0.   4.]
 [  1.  13.  39.   2.   8.]
 [ 14.   8.  11.  65.   8.]
 [  7.  17.  19.  12. 145.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.098 | Acc: 93.875% | Wgt Acc: 97.820%
	I - Batch: 100 | Loss: 0.089 | Acc: 94.312% | Wgt Acc: 98.203%
	I - Batch: 150 | Loss: 0.090 | Acc: 94.042% | Wgt Acc: 98.049%
	I - Batch: 200 | Loss: 0.091 | Acc: 93.812% | Wgt Acc: 98.017%
I - num batch: 222
I - Train -- Loss: 0.093 | Acc: 93.628% | Wgt Acc: 97.808% | LR: 6.250000e-05 | Dur: 135.36s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   2.  65.]
 [  0. 576.   0.   0.  26.]
 [  0.   0. 731.   0.  62.]
 [  0.   0.   0. 533.  57.]
 [  6.   2.   3.   3. 790.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.095 | Acc: 65.680% | Wgt Acc: 59.935% | Dur: 16.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   4.   2.   9.  11.]
 [  1.  38.   4.   2.   7.]
 [  2.   9.  36.   2.  10.]
 [  9.   5.  10.  55.   7.]
 [ 17.  22.  23.  18. 145.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 94.625% | Wgt Acc: 98.255%
	I - Batch: 100 | Loss: 0.089 | Acc: 94.188% | Wgt Acc: 98.015%
	I - Batch: 150 | Loss: 0.087 | Acc: 94.375% | Wgt Acc: 98.165%
