Sat Oct 29 02:09:29 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.23, 0.24, 0.23, 0.25, 0.05], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': 'new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.6, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'lastLayerInitUniform': False, 'learningRate': 0.0001, 'logBatchAt': 50, 'maxValidationAcc': 70.80867850098619, 'maxValidationTrainNo': 61, 'modelVersion': 18, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 64, 'validationAccThr': 70, 'warmStartConfig': {'checkpointFile': './sav/model17_trainNo60_at_epoch_197_with_acc_71_60_checkpoint.pth.tar', 'checkpointModelNo': 17, 'freezeSpatialCNN': False, 'warmStartFlag': True}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Train set length:  3547
I - Label distribution: [ 697.  578.  734.  538. 1000.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Loading file: dataset_test_background00_no_samples180.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test/new_background
I - New label distribution: [ 88.  78.  75.  86. 180.]

I - Test set length:  507
I - Label distribution: [ 88.  78.  75.  86. 180.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([   808,  59440,  69032,    103, 117138,  66599, 131027,  26204,  99882,
           695,  46835,  85717,    773,    414,    463,    530])
I - Initializing model TCNv18
I - Number of Model Parameters: 659237
I - Warm start initiated
I - Initializing model TCNv17
I - Warm Start: Missing Keys ['tcn0.output_shift', 'tcn0.weight_bits', 'tcn0.bias_bits', 'tcn0.quantize_activation', 'tcn0.adjust_output_shift', 'tcn0.shift_quantile', 'tcn0.op.weight', 'tcn0.op.bias']
I - Warm Start: Unexpected Keys ['fc.output_shift', 'fc.weight_bits', 'fc.bias_bits', 'fc.quantize_activation', 'fc.adjust_output_shift', 'fc.shift_quantile', 'fc.op.weight']
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv18                                   [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         6
│    └─ReLU: 2-1719                      [16, 128, 64, 64]         --
│    └─Conv2d: 2-2                       --                        6,272
│    └─BatchNorm2d: 2-1717               [16, 128, 64, 64]         --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-1718                    [16, 128, 64, 64]         --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [128, 48, 1, 1]           --
│    └─Empty: 2-9                        [128, 48, 1, 1]           --
│    └─Empty: 2-10                       [128]                     --
│    └─Empty: 2-11                       [128]                     --
│    └─BatchNorm2d: 2-12                 [16, 128, 64, 64]         --
│    └─Scaler: 2-13                      [16, 128, 64, 64]         --
│    └─ReLU: 2-14                        [16, 128, 64, 64]         --
│    └─Empty: 2-15                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-172        [16, 128, 32, 32]         (recursive)
│    └─ReLU: 2-1734                      [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-1722                 [16, 128, 32, 32]         --
│    └─Conv2d: 2-18                      --                        147,584
│    └─BatchNorm2d: 2-1732               [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-20                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-3          [16, 128, 32, 32]         147,590
│    └─Scaler: 2-1733                    [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-22                   [16, 128, 32, 32]         --
│    └─Empty: 2-23                       [16, 128, 32, 32]         --
│    └─Empty: 2-24                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [128, 128, 3, 3]          --
│    └─Empty: 2-29                       [128, 128, 3, 3]          --
│    └─Empty: 2-30                       [128]                     --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1749                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1737                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-33                      --                        147,584
│    └─BatchNorm2d: 2-1747               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-35                       [128]                     --
│    └─BatchNorm2d: 2-36                 [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1748                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-38                      [16, 128, 32, 32]         --
│    └─ReLU: 2-39                        [16, 128, 32, 32]         --
│    └─Empty: 2-40                       [16, 128, 32, 32]         --
│    └─Clamp: 2-41                       [16, 128, 32, 32]         --
├─Dropout2d: 1-5                         [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-6          [16, 128, 16, 16]         131,078
│    └─MaxPool2d: 2-42                   [16, 128, 16, 16]         --
│    └─Empty: 2-1738                     [16, 128, 16, 16]         --
│    └─Empty: 2-1739                     [16, 128, 16, 16]         --
│    └─Empty: 2-45                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1761                      [16, 128, 16, 16]         --
│    └─Conv2d: 2-47                      --                        16,512
│    └─BatchNorm2d: 2-1759               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-49                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-50          --                        --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1760                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-52                         [1]                       --
│    └─OutputScale: 2-53                 --                        --
│    └─Empty: 2-54                       [128, 128, 3, 3]          --
│    └─Empty: 2-55                       [128, 128, 3, 3]          --
│    └─Empty: 2-56                       [128]                     --
│    └─Empty: 2-57                       [128]                     --
│    └─BatchNorm2d: 2-58                 [16, 128, 16, 16]         --
│    └─Scaler: 2-59                      [16, 128, 16, 16]         --
│    └─ReLU: 2-60                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1776                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1764                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-63                      --                        147,584
│    └─BatchNorm2d: 2-1774               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-65                       [16, 128, 16, 16]         --
│    └─Clamp: 2-66                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1775                    [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-8                 [16, 128, 16, 16]         16,518
│    └─OutputShiftSqueeze: 2-68          --                        --
│    └─One: 2-69                         [1]                       --
│    └─OutputScale: 2-70                 --                        --
│    └─Empty: 2-71                       [128, 128, 1, 1]          --
│    └─Empty: 2-72                       [128, 128, 1, 1]          --
│    └─Empty: 2-73                       [128]                     --
│    └─Empty: 2-74                       [128]                     --
│    └─BatchNorm2d: 2-75                 [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-178        [16, 128, 8, 8]           (recursive)
│    └─ReLU: 2-1791                      [16, 128, 8, 8]           --
│    └─MaxPool2d: 2-1779                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-78                      --                        147,584
│    └─BatchNorm2d: 2-1789               [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-80                      [16, 128, 16, 16]         --
│    └─ReLU: 2-81                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1790                    [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-83                       [16, 128, 16, 16]         --
│    └─Clamp: 2-84                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-10         [16, 128, 16, 16]         145,526
│    └─MaxPool2d: 2-85                   [16, 128, 16, 16]         --
│    └─Empty: 2-86                       [16, 128, 16, 16]         --
│    └─Empty: 2-87                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-88          --                        --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1780                     [16, 128, 8, 8]           --
│    └─Empty: 2-1781                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-91                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1803                      [16, 16, 8, 8]            --
│    └─Conv2d: 2-93                      --                        2,064
│    └─BatchNorm2d: 2-1801               [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [128, 128, 3, 3]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1802                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-98                       [128, 128, 3, 3]          --
│    └─Empty: 2-99                       [128]                     --
│    └─Empty: 2-100                      [128]                     --
│    └─BatchNorm2d: 2-101                [16, 128, 16, 16]         --
│    └─Scaler: 2-102                     [16, 128, 16, 16]         --
│    └─ReLU: 2-103                       [16, 128, 16, 16]         --
│    └─Empty: 2-104                      [16, 128, 16, 16]         --
│    └─Clamp: 2-105                      [16, 128, 16, 16]         --
├─Dropout2d: 1-11                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 16, 8, 8]            (recursive)
│    └─ReLU: 2-1818                      [16, 16, 8, 8]            --
│    └─MaxPool2d: 2-1806                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-108                     --                        18,448
│    └─BatchNorm2d: 2-1816               [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-110                  [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1817                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-112                      [16, 128, 8, 8]           --
│    └─Empty: 2-113                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-114         --                        --
│    └─One: 2-115                        [1]                       --
│    └─OutputScale: 2-116                --                        --
│    └─Empty: 2-117                      [128, 128, 3, 3]          --
│    └─Empty: 2-118                      [128, 128, 3, 3]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1807                     [16, 128, 8, 8]           --
│    └─Empty: 2-1808                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-121                      [128]                     --
│    └─Empty: 2-122                      [128]                     --
│    └─BatchNorm2d: 2-123                [16, 128, 8, 8]           --
│    └─Scaler: 2-124                     [16, 128, 8, 8]           --
│    └─ReLU: 2-125                       [16, 128, 8, 8]           --
│    └─Empty: 2-126                      [16, 128, 8, 8]           --
│    └─Clamp: 2-127                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-14                [16, 16, 8, 8]            2,070
├─Conv1d: 1                              --                        --
│    └─Scaler: 2-1828                    [16, 5, 16]               --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-129         --                        --
│    └─One: 2-130                        [1]                       --
│    └─OutputScale: 2-131                --                        --
│    └─Empty: 2-132                      [16, 128, 1, 1]           --
│    └─Empty: 2-133                      [16, 128, 1, 1]           --
│    └─Empty: 2-134                      [16]                      --
│    └─Empty: 2-135                      [16]                      --
│    └─BatchNorm2d: 2-136                [16, 16, 8, 8]            --
│    └─Scaler: 2-137                     [16, 16, 8, 8]            --
│    └─ReLU: 2-138                       [16, 16, 8, 8]            --
│    └─Empty: 2-139                      [16, 16, 8, 8]            --
│    └─Clamp: 2-140                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 16, 8, 8]            18,454
│    └─MaxPool2d: 2-141                  [16, 128, 8, 8]           --
│    └─Empty: 2-142                      [16, 128, 8, 8]           --
│    └─Empty: 2-143                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-144         --                        --
│    └─One: 2-145                        [1]                       --
│    └─OutputScale: 2-146                --                        --
│    └─Empty: 2-147                      [16, 128, 3, 3]           --
│    └─Empty: 2-148                      [16, 128, 3, 3]           --
│    └─Empty: 2-149                      [16]                      --
│    └─Empty: 2-150                      [16]                      --
│    └─BatchNorm2d: 2-151                [16, 16, 8, 8]            --
│    └─Scaler: 2-152                     [16, 16, 8, 8]            --
│    └─ReLU: 2-153                       [16, 16, 8, 8]            --
│    └─Empty: 2-154                      [16, 16, 8, 8]            --
│    └─Clamp: 2-155                      [16, 16, 8, 8]            --
├─Dropout2d: 1-16                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-17                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-156         --                        --
│    └─One: 2-157                        [1]                       --
│    └─OutputScale: 2-158                --                        --
│    └─Empty: 2-159                      [128, 48, 1, 1]           --
│    └─Empty: 2-160                      [128, 48, 1, 1]           --
│    └─Empty: 2-161                      [128]                     --
│    └─Empty: 2-162                      [128]                     --
│    └─BatchNorm2d: 2-163                [16, 128, 64, 64]         --
│    └─Scaler: 2-164                     [16, 128, 64, 64]         --
│    └─ReLU: 2-165                       [16, 128, 64, 64]         --
│    └─Empty: 2-166                      [16, 128, 64, 64]         --
│    └─Clamp: 2-167                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-18         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-168                  [16, 128, 32, 32]         --
│    └─Empty: 2-169                      [16, 128, 32, 32]         --
│    └─Empty: 2-170                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-171         --                        --
│    └─One: 2-172                        [1]                       --
│    └─OutputScale: 2-173                --                        --
│    └─Empty: 2-174                      [128, 128, 3, 3]          --
│    └─Empty: 2-175                      [128, 128, 3, 3]          --
│    └─Empty: 2-176                      [128]                     --
│    └─Empty: 2-177                      [128]                     --
│    └─BatchNorm2d: 2-178                [16, 128, 32, 32]         --
│    └─Scaler: 2-179                     [16, 128, 32, 32]         --
│    └─ReLU: 2-180                       [16, 128, 32, 32]         --
│    └─Empty: 2-181                      [16, 128, 32, 32]         --
│    └─Clamp: 2-182                      [16, 128, 32, 32]         --
├─Dropout2d: 1-19                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-20         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-183                  [16, 128, 16, 16]         --
│    └─Empty: 2-184                      [16, 128, 16, 16]         --
│    └─Empty: 2-185                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-186         --                        --
│    └─One: 2-187                        [1]                       --
│    └─OutputScale: 2-188                --                        --
│    └─Empty: 2-189                      [128, 128, 3, 3]          --
│    └─Empty: 2-190                      [128, 128, 3, 3]          --
│    └─Empty: 2-191                      [128]                     --
│    └─Empty: 2-192                      [128]                     --
│    └─BatchNorm2d: 2-193                [16, 128, 16, 16]         --
│    └─Scaler: 2-194                     [16, 128, 16, 16]         --
│    └─ReLU: 2-195                       [16, 128, 16, 16]         --
│    └─Empty: 2-196                      [16, 128, 16, 16]         --
│    └─Clamp: 2-197                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-21                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-198         --                        --
│    └─One: 2-199                        [1]                       --
│    └─OutputScale: 2-200                --                        --
│    └─Empty: 2-201                      [128, 128, 1, 1]          --
│    └─Empty: 2-202                      [128, 128, 1, 1]          --
│    └─Empty: 2-203                      [128]                     --
│    └─Empty: 2-204                      [128]                     --
│    └─BatchNorm2d: 2-205                [16, 128, 16, 16]         --
│    └─Scaler: 2-206                     [16, 128, 16, 16]         --
│    └─ReLU: 2-207                       [16, 128, 16, 16]         --
│    └─Empty: 2-208                      [16, 128, 16, 16]         --
│    └─Clamp: 2-209                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-210                  [16, 128, 16, 16]         --
│    └─Empty: 2-211                      [16, 128, 16, 16]         --
│    └─Empty: 2-212                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-213         --                        --
│    └─One: 2-214                        [1]                       --
│    └─OutputScale: 2-215                --                        --
│    └─Empty: 2-216                      [128, 128, 3, 3]          --
│    └─Empty: 2-217                      [128, 128, 3, 3]          --
│    └─Empty: 2-218                      [128]                     --
│    └─Empty: 2-219                      [128]                     --
│    └─BatchNorm2d: 2-220                [16, 128, 16, 16]         --
│    └─Scaler: 2-221                     [16, 128, 16, 16]         --
│    └─ReLU: 2-222                       [16, 128, 16, 16]         --
│    └─Empty: 2-223                      [16, 128, 16, 16]         --
│    └─Clamp: 2-224                      [16, 128, 16, 16]         --
├─Dropout2d: 1-23                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-225                  [16, 128, 8, 8]           --
│    └─Empty: 2-226                      [16, 128, 8, 8]           --
│    └─Empty: 2-227                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-228         --                        --
│    └─One: 2-229                        [1]                       --
│    └─OutputScale: 2-230                --                        --
│    └─Empty: 2-231                      [128, 128, 3, 3]          --
│    └─Empty: 2-232                      [128, 128, 3, 3]          --
│    └─Empty: 2-233                      [128]                     --
│    └─Empty: 2-234                      [128]                     --
│    └─BatchNorm2d: 2-235                [16, 128, 8, 8]           --
│    └─Scaler: 2-236                     [16, 128, 8, 8]           --
│    └─ReLU: 2-237                       [16, 128, 8, 8]           --
│    └─Empty: 2-238                      [16, 128, 8, 8]           --
│    └─Clamp: 2-239                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-25                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-240         --                        --
│    └─One: 2-241                        [1]                       --
│    └─OutputScale: 2-242                --                        --
│    └─Empty: 2-243                      [16, 128, 1, 1]           --
│    └─Empty: 2-244                      [16, 128, 1, 1]           --
│    └─Empty: 2-245                      [16]                      --
│    └─Empty: 2-246                      [16]                      --
│    └─BatchNorm2d: 2-247                [16, 16, 8, 8]            --
│    └─Scaler: 2-248                     [16, 16, 8, 8]            --
│    └─ReLU: 2-249                       [16, 16, 8, 8]            --
│    └─Empty: 2-250                      [16, 16, 8, 8]            --
│    └─Clamp: 2-251                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-252                  [16, 128, 8, 8]           --
│    └─Empty: 2-253                      [16, 128, 8, 8]           --
│    └─Empty: 2-254                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-255         --                        --
│    └─One: 2-256                        [1]                       --
│    └─OutputScale: 2-257                --                        --
│    └─Empty: 2-258                      [16, 128, 3, 3]           --
│    └─Empty: 2-259                      [16, 128, 3, 3]           --
│    └─Empty: 2-260                      [16]                      --
│    └─Empty: 2-261                      [16]                      --
│    └─BatchNorm2d: 2-262                [16, 16, 8, 8]            --
│    └─Scaler: 2-263                     [16, 16, 8, 8]            --
│    └─ReLU: 2-264                       [16, 16, 8, 8]            --
│    └─Empty: 2-265                      [16, 16, 8, 8]            --
│    └─Clamp: 2-266                      [16, 16, 8, 8]            --
├─Dropout2d: 1-27                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-28                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-267         --                        --
│    └─One: 2-268                        [1]                       --
│    └─OutputScale: 2-269                --                        --
│    └─Empty: 2-270                      [128, 48, 1, 1]           --
│    └─Empty: 2-271                      [128, 48, 1, 1]           --
│    └─Empty: 2-272                      [128]                     --
│    └─Empty: 2-273                      [128]                     --
│    └─BatchNorm2d: 2-274                [16, 128, 64, 64]         --
│    └─Scaler: 2-275                     [16, 128, 64, 64]         --
│    └─ReLU: 2-276                       [16, 128, 64, 64]         --
│    └─Empty: 2-277                      [16, 128, 64, 64]         --
│    └─Clamp: 2-278                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-279                  [16, 128, 32, 32]         --
│    └─Empty: 2-280                      [16, 128, 32, 32]         --
│    └─Empty: 2-281                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-282         --                        --
│    └─One: 2-283                        [1]                       --
│    └─OutputScale: 2-284                --                        --
│    └─Empty: 2-285                      [128, 128, 3, 3]          --
│    └─Empty: 2-286                      [128, 128, 3, 3]          --
│    └─Empty: 2-287                      [128]                     --
│    └─Empty: 2-288                      [128]                     --
│    └─BatchNorm2d: 2-289                [16, 128, 32, 32]         --
│    └─Scaler: 2-290                     [16, 128, 32, 32]         --
│    └─ReLU: 2-291                       [16, 128, 32, 32]         --
│    └─Empty: 2-292                      [16, 128, 32, 32]         --
│    └─Clamp: 2-293                      [16, 128, 32, 32]         --
├─Dropout2d: 1-30                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-294                  [16, 128, 16, 16]         --
│    └─Empty: 2-295                      [16, 128, 16, 16]         --
│    └─Empty: 2-296                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-297         --                        --
│    └─One: 2-298                        [1]                       --
│    └─OutputScale: 2-299                --                        --
│    └─Empty: 2-300                      [128, 128, 3, 3]          --
│    └─Empty: 2-301                      [128, 128, 3, 3]          --
│    └─Empty: 2-302                      [128]                     --
│    └─Empty: 2-303                      [128]                     --
│    └─BatchNorm2d: 2-304                [16, 128, 16, 16]         --
│    └─Scaler: 2-305                     [16, 128, 16, 16]         --
│    └─ReLU: 2-306                       [16, 128, 16, 16]         --
│    └─Empty: 2-307                      [16, 128, 16, 16]         --
│    └─Clamp: 2-308                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-32                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-309         --                        --
│    └─One: 2-310                        [1]                       --
│    └─OutputScale: 2-311                --                        --
│    └─Empty: 2-312                      [128, 128, 1, 1]          --
│    └─Empty: 2-313                      [128, 128, 1, 1]          --
│    └─Empty: 2-314                      [128]                     --
│    └─Empty: 2-315                      [128]                     --
│    └─BatchNorm2d: 2-316                [16, 128, 16, 16]         --
│    └─Scaler: 2-317                     [16, 128, 16, 16]         --
│    └─ReLU: 2-318                       [16, 128, 16, 16]         --
│    └─Empty: 2-319                      [16, 128, 16, 16]         --
│    └─Clamp: 2-320                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-321                  [16, 128, 16, 16]         --
│    └─Empty: 2-322                      [16, 128, 16, 16]         --
│    └─Empty: 2-323                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-324         --                        --
│    └─One: 2-325                        [1]                       --
│    └─OutputScale: 2-326                --                        --
│    └─Empty: 2-327                      [128, 128, 3, 3]          --
│    └─Empty: 2-328                      [128, 128, 3, 3]          --
│    └─Empty: 2-329                      [128]                     --
│    └─Empty: 2-330                      [128]                     --
│    └─BatchNorm2d: 2-331                [16, 128, 16, 16]         --
│    └─Scaler: 2-332                     [16, 128, 16, 16]         --
│    └─ReLU: 2-333                       [16, 128, 16, 16]         --
│    └─Empty: 2-334                      [16, 128, 16, 16]         --
│    └─Clamp: 2-335                      [16, 128, 16, 16]         --
├─Dropout2d: 1-34                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-35         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-336                  [16, 128, 8, 8]           --
│    └─Empty: 2-337                      [16, 128, 8, 8]           --
│    └─Empty: 2-338                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-339         --                        --
│    └─One: 2-340                        [1]                       --
│    └─OutputScale: 2-341                --                        --
│    └─Empty: 2-342                      [128, 128, 3, 3]          --
│    └─Empty: 2-343                      [128, 128, 3, 3]          --
│    └─Empty: 2-344                      [128]                     --
│    └─Empty: 2-345                      [128]                     --
│    └─BatchNorm2d: 2-346                [16, 128, 8, 8]           --
│    └─Scaler: 2-347                     [16, 128, 8, 8]           --
│    └─ReLU: 2-348                       [16, 128, 8, 8]           --
│    └─Empty: 2-349                      [16, 128, 8, 8]           --
│    └─Clamp: 2-350                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-36                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-351         --                        --
│    └─One: 2-352                        [1]                       --
│    └─OutputScale: 2-353                --                        --
│    └─Empty: 2-354                      [16, 128, 1, 1]           --
│    └─Empty: 2-355                      [16, 128, 1, 1]           --
│    └─Empty: 2-356                      [16]                      --
│    └─Empty: 2-357                      [16]                      --
│    └─BatchNorm2d: 2-358                [16, 16, 8, 8]            --
│    └─Scaler: 2-359                     [16, 16, 8, 8]            --
│    └─ReLU: 2-360                       [16, 16, 8, 8]            --
│    └─Empty: 2-361                      [16, 16, 8, 8]            --
│    └─Clamp: 2-362                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-37         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-363                  [16, 128, 8, 8]           --
│    └─Empty: 2-364                      [16, 128, 8, 8]           --
│    └─Empty: 2-365                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-366         --                        --
│    └─One: 2-367                        [1]                       --
│    └─OutputScale: 2-368                --                        --
│    └─Empty: 2-369                      [16, 128, 3, 3]           --
│    └─Empty: 2-370                      [16, 128, 3, 3]           --
│    └─Empty: 2-371                      [16]                      --
│    └─Empty: 2-372                      [16]                      --
│    └─BatchNorm2d: 2-373                [16, 16, 8, 8]            --
│    └─Scaler: 2-374                     [16, 16, 8, 8]            --
│    └─ReLU: 2-375                       [16, 16, 8, 8]            --
│    └─Empty: 2-376                      [16, 16, 8, 8]            --
│    └─Clamp: 2-377                      [16, 16, 8, 8]            --
├─Dropout2d: 1-38                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-39                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-378         --                        --
│    └─One: 2-379                        [1]                       --
│    └─OutputScale: 2-380                --                        --
│    └─Empty: 2-381                      [128, 48, 1, 1]           --
│    └─Empty: 2-382                      [128, 48, 1, 1]           --
│    └─Empty: 2-383                      [128]                     --
│    └─Empty: 2-384                      [128]                     --
│    └─BatchNorm2d: 2-385                [16, 128, 64, 64]         --
│    └─Scaler: 2-386                     [16, 128, 64, 64]         --
│    └─ReLU: 2-387                       [16, 128, 64, 64]         --
│    └─Empty: 2-388                      [16, 128, 64, 64]         --
│    └─Clamp: 2-389                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-40         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-390                  [16, 128, 32, 32]         --
│    └─Empty: 2-391                      [16, 128, 32, 32]         --
│    └─Empty: 2-392                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-393         --                        --
│    └─One: 2-394                        [1]                       --
│    └─OutputScale: 2-395                --                        --
│    └─Empty: 2-396                      [128, 128, 3, 3]          --
│    └─Empty: 2-397                      [128, 128, 3, 3]          --
│    └─Empty: 2-398                      [128]                     --
│    └─Empty: 2-399                      [128]                     --
│    └─BatchNorm2d: 2-400                [16, 128, 32, 32]         --
│    └─Scaler: 2-401                     [16, 128, 32, 32]         --
│    └─ReLU: 2-402                       [16, 128, 32, 32]         --
│    └─Empty: 2-403                      [16, 128, 32, 32]         --
│    └─Clamp: 2-404                      [16, 128, 32, 32]         --
├─Dropout2d: 1-41                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-42         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-405                  [16, 128, 16, 16]         --
│    └─Empty: 2-406                      [16, 128, 16, 16]         --
│    └─Empty: 2-407                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-408         --                        --
│    └─One: 2-409                        [1]                       --
│    └─OutputScale: 2-410                --                        --
│    └─Empty: 2-411                      [128, 128, 3, 3]          --
│    └─Empty: 2-412                      [128, 128, 3, 3]          --
│    └─Empty: 2-413                      [128]                     --
│    └─Empty: 2-414                      [128]                     --
│    └─BatchNorm2d: 2-415                [16, 128, 16, 16]         --
│    └─Scaler: 2-416                     [16, 128, 16, 16]         --
│    └─ReLU: 2-417                       [16, 128, 16, 16]         --
│    └─Empty: 2-418                      [16, 128, 16, 16]         --
│    └─Clamp: 2-419                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-43                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-420         --                        --
│    └─One: 2-421                        [1]                       --
│    └─OutputScale: 2-422                --                        --
│    └─Empty: 2-423                      [128, 128, 1, 1]          --
│    └─Empty: 2-424                      [128, 128, 1, 1]          --
│    └─Empty: 2-425                      [128]                     --
│    └─Empty: 2-426                      [128]                     --
│    └─BatchNorm2d: 2-427                [16, 128, 16, 16]         --
│    └─Scaler: 2-428                     [16, 128, 16, 16]         --
│    └─ReLU: 2-429                       [16, 128, 16, 16]         --
│    └─Empty: 2-430                      [16, 128, 16, 16]         --
│    └─Clamp: 2-431                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-44         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-432                  [16, 128, 16, 16]         --
│    └─Empty: 2-433                      [16, 128, 16, 16]         --
│    └─Empty: 2-434                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-435         --                        --
│    └─One: 2-436                        [1]                       --
│    └─OutputScale: 2-437                --                        --
│    └─Empty: 2-438                      [128, 128, 3, 3]          --
│    └─Empty: 2-439                      [128, 128, 3, 3]          --
│    └─Empty: 2-440                      [128]                     --
│    └─Empty: 2-441                      [128]                     --
│    └─BatchNorm2d: 2-442                [16, 128, 16, 16]         --
│    └─Scaler: 2-443                     [16, 128, 16, 16]         --
│    └─ReLU: 2-444                       [16, 128, 16, 16]         --
│    └─Empty: 2-445                      [16, 128, 16, 16]         --
│    └─Clamp: 2-446                      [16, 128, 16, 16]         --
├─Dropout2d: 1-45                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-447                  [16, 128, 8, 8]           --
│    └─Empty: 2-448                      [16, 128, 8, 8]           --
│    └─Empty: 2-449                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-450         --                        --
│    └─One: 2-451                        [1]                       --
│    └─OutputScale: 2-452                --                        --
│    └─Empty: 2-453                      [128, 128, 3, 3]          --
│    └─Empty: 2-454                      [128, 128, 3, 3]          --
│    └─Empty: 2-455                      [128]                     --
│    └─Empty: 2-456                      [128]                     --
│    └─BatchNorm2d: 2-457                [16, 128, 8, 8]           --
│    └─Scaler: 2-458                     [16, 128, 8, 8]           --
│    └─ReLU: 2-459                       [16, 128, 8, 8]           --
│    └─Empty: 2-460                      [16, 128, 8, 8]           --
│    └─Clamp: 2-461                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-47                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-462         --                        --
│    └─One: 2-463                        [1]                       --
│    └─OutputScale: 2-464                --                        --
│    └─Empty: 2-465                      [16, 128, 1, 1]           --
│    └─Empty: 2-466                      [16, 128, 1, 1]           --
│    └─Empty: 2-467                      [16]                      --
│    └─Empty: 2-468                      [16]                      --
│    └─BatchNorm2d: 2-469                [16, 16, 8, 8]            --
│    └─Scaler: 2-470                     [16, 16, 8, 8]            --
│    └─ReLU: 2-471                       [16, 16, 8, 8]            --
│    └─Empty: 2-472                      [16, 16, 8, 8]            --
│    └─Clamp: 2-473                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-474                  [16, 128, 8, 8]           --
│    └─Empty: 2-475                      [16, 128, 8, 8]           --
│    └─Empty: 2-476                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-477         --                        --
│    └─One: 2-478                        [1]                       --
│    └─OutputScale: 2-479                --                        --
│    └─Empty: 2-480                      [16, 128, 3, 3]           --
│    └─Empty: 2-481                      [16, 128, 3, 3]           --
│    └─Empty: 2-482                      [16]                      --
│    └─Empty: 2-483                      [16]                      --
│    └─BatchNorm2d: 2-484                [16, 16, 8, 8]            --
│    └─Scaler: 2-485                     [16, 16, 8, 8]            --
│    └─ReLU: 2-486                       [16, 16, 8, 8]            --
│    └─Empty: 2-487                      [16, 16, 8, 8]            --
│    └─Clamp: 2-488                      [16, 16, 8, 8]            --
├─Dropout2d: 1-49                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-50                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-489         --                        --
│    └─One: 2-490                        [1]                       --
│    └─OutputScale: 2-491                --                        --
│    └─Empty: 2-492                      [128, 48, 1, 1]           --
│    └─Empty: 2-493                      [128, 48, 1, 1]           --
│    └─Empty: 2-494                      [128]                     --
│    └─Empty: 2-495                      [128]                     --
│    └─BatchNorm2d: 2-496                [16, 128, 64, 64]         --
│    └─Scaler: 2-497                     [16, 128, 64, 64]         --
│    └─ReLU: 2-498                       [16, 128, 64, 64]         --
│    └─Empty: 2-499                      [16, 128, 64, 64]         --
│    └─Clamp: 2-500                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-501                  [16, 128, 32, 32]         --
│    └─Empty: 2-502                      [16, 128, 32, 32]         --
│    └─Empty: 2-503                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-504         --                        --
│    └─One: 2-505                        [1]                       --
│    └─OutputScale: 2-506                --                        --
│    └─Empty: 2-507                      [128, 128, 3, 3]          --
│    └─Empty: 2-508                      [128, 128, 3, 3]          --
│    └─Empty: 2-509                      [128]                     --
│    └─Empty: 2-510                      [128]                     --
│    └─BatchNorm2d: 2-511                [16, 128, 32, 32]         --
│    └─Scaler: 2-512                     [16, 128, 32, 32]         --
│    └─ReLU: 2-513                       [16, 128, 32, 32]         --
│    └─Empty: 2-514                      [16, 128, 32, 32]         --
│    └─Clamp: 2-515                      [16, 128, 32, 32]         --
├─Dropout2d: 1-52                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-53         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-516                  [16, 128, 16, 16]         --
│    └─Empty: 2-517                      [16, 128, 16, 16]         --
│    └─Empty: 2-518                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-519         --                        --
│    └─One: 2-520                        [1]                       --
│    └─OutputScale: 2-521                --                        --
│    └─Empty: 2-522                      [128, 128, 3, 3]          --
│    └─Empty: 2-523                      [128, 128, 3, 3]          --
│    └─Empty: 2-524                      [128]                     --
│    └─Empty: 2-525                      [128]                     --
│    └─BatchNorm2d: 2-526                [16, 128, 16, 16]         --
│    └─Scaler: 2-527                     [16, 128, 16, 16]         --
│    └─ReLU: 2-528                       [16, 128, 16, 16]         --
│    └─Empty: 2-529                      [16, 128, 16, 16]         --
│    └─Clamp: 2-530                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-54                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-531         --                        --
│    └─One: 2-532                        [1]                       --
│    └─OutputScale: 2-533                --                        --
│    └─Empty: 2-534                      [128, 128, 1, 1]          --
│    └─Empty: 2-535                      [128, 128, 1, 1]          --
│    └─Empty: 2-536                      [128]                     --
│    └─Empty: 2-537                      [128]                     --
│    └─BatchNorm2d: 2-538                [16, 128, 16, 16]         --
│    └─Scaler: 2-539                     [16, 128, 16, 16]         --
│    └─ReLU: 2-540                       [16, 128, 16, 16]         --
│    └─Empty: 2-541                      [16, 128, 16, 16]         --
│    └─Clamp: 2-542                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-543                  [16, 128, 16, 16]         --
│    └─Empty: 2-544                      [16, 128, 16, 16]         --
│    └─Empty: 2-545                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-546         --                        --
│    └─One: 2-547                        [1]                       --
│    └─OutputScale: 2-548                --                        --
│    └─Empty: 2-549                      [128, 128, 3, 3]          --
│    └─Empty: 2-550                      [128, 128, 3, 3]          --
│    └─Empty: 2-551                      [128]                     --
│    └─Empty: 2-552                      [128]                     --
│    └─BatchNorm2d: 2-553                [16, 128, 16, 16]         --
│    └─Scaler: 2-554                     [16, 128, 16, 16]         --
│    └─ReLU: 2-555                       [16, 128, 16, 16]         --
│    └─Empty: 2-556                      [16, 128, 16, 16]         --
│    └─Clamp: 2-557                      [16, 128, 16, 16]         --
├─Dropout2d: 1-56                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-57         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-558                  [16, 128, 8, 8]           --
│    └─Empty: 2-559                      [16, 128, 8, 8]           --
│    └─Empty: 2-560                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-561         --                        --
│    └─One: 2-562                        [1]                       --
│    └─OutputScale: 2-563                --                        --
│    └─Empty: 2-564                      [128, 128, 3, 3]          --
│    └─Empty: 2-565                      [128, 128, 3, 3]          --
│    └─Empty: 2-566                      [128]                     --
│    └─Empty: 2-567                      [128]                     --
│    └─BatchNorm2d: 2-568                [16, 128, 8, 8]           --
│    └─Scaler: 2-569                     [16, 128, 8, 8]           --
│    └─ReLU: 2-570                       [16, 128, 8, 8]           --
│    └─Empty: 2-571                      [16, 128, 8, 8]           --
│    └─Clamp: 2-572                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-58                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-573         --                        --
│    └─One: 2-574                        [1]                       --
│    └─OutputScale: 2-575                --                        --
│    └─Empty: 2-576                      [16, 128, 1, 1]           --
│    └─Empty: 2-577                      [16, 128, 1, 1]           --
│    └─Empty: 2-578                      [16]                      --
│    └─Empty: 2-579                      [16]                      --
│    └─BatchNorm2d: 2-580                [16, 16, 8, 8]            --
│    └─Scaler: 2-581                     [16, 16, 8, 8]            --
│    └─ReLU: 2-582                       [16, 16, 8, 8]            --
│    └─Empty: 2-583                      [16, 16, 8, 8]            --
│    └─Clamp: 2-584                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-59         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-585                  [16, 128, 8, 8]           --
│    └─Empty: 2-586                      [16, 128, 8, 8]           --
│    └─Empty: 2-587                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-588         --                        --
│    └─One: 2-589                        [1]                       --
│    └─OutputScale: 2-590                --                        --
│    └─Empty: 2-591                      [16, 128, 3, 3]           --
│    └─Empty: 2-592                      [16, 128, 3, 3]           --
│    └─Empty: 2-593                      [16]                      --
│    └─Empty: 2-594                      [16]                      --
│    └─BatchNorm2d: 2-595                [16, 16, 8, 8]            --
│    └─Scaler: 2-596                     [16, 16, 8, 8]            --
│    └─ReLU: 2-597                       [16, 16, 8, 8]            --
│    └─Empty: 2-598                      [16, 16, 8, 8]            --
│    └─Clamp: 2-599                      [16, 16, 8, 8]            --
├─Dropout2d: 1-60                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-600         --                        --
│    └─One: 2-601                        [1]                       --
│    └─OutputScale: 2-602                --                        --
│    └─Empty: 2-603                      [128, 48, 1, 1]           --
│    └─Empty: 2-604                      [128, 48, 1, 1]           --
│    └─Empty: 2-605                      [128]                     --
│    └─Empty: 2-606                      [128]                     --
│    └─BatchNorm2d: 2-607                [16, 128, 64, 64]         --
│    └─Scaler: 2-608                     [16, 128, 64, 64]         --
│    └─ReLU: 2-609                       [16, 128, 64, 64]         --
│    └─Empty: 2-610                      [16, 128, 64, 64]         --
│    └─Clamp: 2-611                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-612                  [16, 128, 32, 32]         --
│    └─Empty: 2-613                      [16, 128, 32, 32]         --
│    └─Empty: 2-614                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-615         --                        --
│    └─One: 2-616                        [1]                       --
│    └─OutputScale: 2-617                --                        --
│    └─Empty: 2-618                      [128, 128, 3, 3]          --
│    └─Empty: 2-619                      [128, 128, 3, 3]          --
│    └─Empty: 2-620                      [128]                     --
│    └─Empty: 2-621                      [128]                     --
│    └─BatchNorm2d: 2-622                [16, 128, 32, 32]         --
│    └─Scaler: 2-623                     [16, 128, 32, 32]         --
│    └─ReLU: 2-624                       [16, 128, 32, 32]         --
│    └─Empty: 2-625                      [16, 128, 32, 32]         --
│    └─Clamp: 2-626                      [16, 128, 32, 32]         --
├─Dropout2d: 1-63                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-64         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-627                  [16, 128, 16, 16]         --
│    └─Empty: 2-628                      [16, 128, 16, 16]         --
│    └─Empty: 2-629                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-630         --                        --
│    └─One: 2-631                        [1]                       --
│    └─OutputScale: 2-632                --                        --
│    └─Empty: 2-633                      [128, 128, 3, 3]          --
│    └─Empty: 2-634                      [128, 128, 3, 3]          --
│    └─Empty: 2-635                      [128]                     --
│    └─Empty: 2-636                      [128]                     --
│    └─BatchNorm2d: 2-637                [16, 128, 16, 16]         --
│    └─Scaler: 2-638                     [16, 128, 16, 16]         --
│    └─ReLU: 2-639                       [16, 128, 16, 16]         --
│    └─Empty: 2-640                      [16, 128, 16, 16]         --
│    └─Clamp: 2-641                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-65                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-642         --                        --
│    └─One: 2-643                        [1]                       --
│    └─OutputScale: 2-644                --                        --
│    └─Empty: 2-645                      [128, 128, 1, 1]          --
│    └─Empty: 2-646                      [128, 128, 1, 1]          --
│    └─Empty: 2-647                      [128]                     --
│    └─Empty: 2-648                      [128]                     --
│    └─BatchNorm2d: 2-649                [16, 128, 16, 16]         --
│    └─Scaler: 2-650                     [16, 128, 16, 16]         --
│    └─ReLU: 2-651                       [16, 128, 16, 16]         --
│    └─Empty: 2-652                      [16, 128, 16, 16]         --
│    └─Clamp: 2-653                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-654                  [16, 128, 16, 16]         --
│    └─Empty: 2-655                      [16, 128, 16, 16]         --
│    └─Empty: 2-656                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-657         --                        --
│    └─One: 2-658                        [1]                       --
│    └─OutputScale: 2-659                --                        --
│    └─Empty: 2-660                      [128, 128, 3, 3]          --
│    └─Empty: 2-661                      [128, 128, 3, 3]          --
│    └─Empty: 2-662                      [128]                     --
│    └─Empty: 2-663                      [128]                     --
│    └─BatchNorm2d: 2-664                [16, 128, 16, 16]         --
│    └─Scaler: 2-665                     [16, 128, 16, 16]         --
│    └─ReLU: 2-666                       [16, 128, 16, 16]         --
│    └─Empty: 2-667                      [16, 128, 16, 16]         --
│    └─Clamp: 2-668                      [16, 128, 16, 16]         --
├─Dropout2d: 1-67                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-669                  [16, 128, 8, 8]           --
│    └─Empty: 2-670                      [16, 128, 8, 8]           --
│    └─Empty: 2-671                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-672         --                        --
│    └─One: 2-673                        [1]                       --
│    └─OutputScale: 2-674                --                        --
│    └─Empty: 2-675                      [128, 128, 3, 3]          --
│    └─Empty: 2-676                      [128, 128, 3, 3]          --
│    └─Empty: 2-677                      [128]                     --
│    └─Empty: 2-678                      [128]                     --
│    └─BatchNorm2d: 2-679                [16, 128, 8, 8]           --
│    └─Scaler: 2-680                     [16, 128, 8, 8]           --
│    └─ReLU: 2-681                       [16, 128, 8, 8]           --
│    └─Empty: 2-682                      [16, 128, 8, 8]           --
│    └─Clamp: 2-683                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-69                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-684         --                        --
│    └─One: 2-685                        [1]                       --
│    └─OutputScale: 2-686                --                        --
│    └─Empty: 2-687                      [16, 128, 1, 1]           --
│    └─Empty: 2-688                      [16, 128, 1, 1]           --
│    └─Empty: 2-689                      [16]                      --
│    └─Empty: 2-690                      [16]                      --
│    └─BatchNorm2d: 2-691                [16, 16, 8, 8]            --
│    └─Scaler: 2-692                     [16, 16, 8, 8]            --
│    └─ReLU: 2-693                       [16, 16, 8, 8]            --
│    └─Empty: 2-694                      [16, 16, 8, 8]            --
│    └─Clamp: 2-695                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-70         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-696                  [16, 128, 8, 8]           --
│    └─Empty: 2-697                      [16, 128, 8, 8]           --
│    └─Empty: 2-698                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-699         --                        --
│    └─One: 2-700                        [1]                       --
│    └─OutputScale: 2-701                --                        --
│    └─Empty: 2-702                      [16, 128, 3, 3]           --
│    └─Empty: 2-703                      [16, 128, 3, 3]           --
│    └─Empty: 2-704                      [16]                      --
│    └─Empty: 2-705                      [16]                      --
│    └─BatchNorm2d: 2-706                [16, 16, 8, 8]            --
│    └─Scaler: 2-707                     [16, 16, 8, 8]            --
│    └─ReLU: 2-708                       [16, 16, 8, 8]            --
│    └─Empty: 2-709                      [16, 16, 8, 8]            --
│    └─Clamp: 2-710                      [16, 16, 8, 8]            --
├─Dropout2d: 1-71                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-72                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-711         --                        --
│    └─One: 2-712                        [1]                       --
│    └─OutputScale: 2-713                --                        --
│    └─Empty: 2-714                      [128, 48, 1, 1]           --
│    └─Empty: 2-715                      [128, 48, 1, 1]           --
│    └─Empty: 2-716                      [128]                     --
│    └─Empty: 2-717                      [128]                     --
│    └─BatchNorm2d: 2-718                [16, 128, 64, 64]         --
│    └─Scaler: 2-719                     [16, 128, 64, 64]         --
│    └─ReLU: 2-720                       [16, 128, 64, 64]         --
│    └─Empty: 2-721                      [16, 128, 64, 64]         --
│    └─Clamp: 2-722                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-723                  [16, 128, 32, 32]         --
│    └─Empty: 2-724                      [16, 128, 32, 32]         --
│    └─Empty: 2-725                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-726         --                        --
│    └─One: 2-727                        [1]                       --
│    └─OutputScale: 2-728                --                        --
│    └─Empty: 2-729                      [128, 128, 3, 3]          --
│    └─Empty: 2-730                      [128, 128, 3, 3]          --
│    └─Empty: 2-731                      [128]                     --
│    └─Empty: 2-732                      [128]                     --
│    └─BatchNorm2d: 2-733                [16, 128, 32, 32]         --
│    └─Scaler: 2-734                     [16, 128, 32, 32]         --
│    └─ReLU: 2-735                       [16, 128, 32, 32]         --
│    └─Empty: 2-736                      [16, 128, 32, 32]         --
│    └─Clamp: 2-737                      [16, 128, 32, 32]         --
├─Dropout2d: 1-74                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-738                  [16, 128, 16, 16]         --
│    └─Empty: 2-739                      [16, 128, 16, 16]         --
│    └─Empty: 2-740                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-741         --                        --
│    └─One: 2-742                        [1]                       --
│    └─OutputScale: 2-743                --                        --
│    └─Empty: 2-744                      [128, 128, 3, 3]          --
│    └─Empty: 2-745                      [128, 128, 3, 3]          --
│    └─Empty: 2-746                      [128]                     --
│    └─Empty: 2-747                      [128]                     --
│    └─BatchNorm2d: 2-748                [16, 128, 16, 16]         --
│    └─Scaler: 2-749                     [16, 128, 16, 16]         --
│    └─ReLU: 2-750                       [16, 128, 16, 16]         --
│    └─Empty: 2-751                      [16, 128, 16, 16]         --
│    └─Clamp: 2-752                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-76                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-753         --                        --
│    └─One: 2-754                        [1]                       --
│    └─OutputScale: 2-755                --                        --
│    └─Empty: 2-756                      [128, 128, 1, 1]          --
│    └─Empty: 2-757                      [128, 128, 1, 1]          --
│    └─Empty: 2-758                      [128]                     --
│    └─Empty: 2-759                      [128]                     --
│    └─BatchNorm2d: 2-760                [16, 128, 16, 16]         --
│    └─Scaler: 2-761                     [16, 128, 16, 16]         --
│    └─ReLU: 2-762                       [16, 128, 16, 16]         --
│    └─Empty: 2-763                      [16, 128, 16, 16]         --
│    └─Clamp: 2-764                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-765                  [16, 128, 16, 16]         --
│    └─Empty: 2-766                      [16, 128, 16, 16]         --
│    └─Empty: 2-767                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-768         --                        --
│    └─One: 2-769                        [1]                       --
│    └─OutputScale: 2-770                --                        --
│    └─Empty: 2-771                      [128, 128, 3, 3]          --
│    └─Empty: 2-772                      [128, 128, 3, 3]          --
│    └─Empty: 2-773                      [128]                     --
│    └─Empty: 2-774                      [128]                     --
│    └─BatchNorm2d: 2-775                [16, 128, 16, 16]         --
│    └─Scaler: 2-776                     [16, 128, 16, 16]         --
│    └─ReLU: 2-777                       [16, 128, 16, 16]         --
│    └─Empty: 2-778                      [16, 128, 16, 16]         --
│    └─Clamp: 2-779                      [16, 128, 16, 16]         --
├─Dropout2d: 1-78                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-780                  [16, 128, 8, 8]           --
│    └─Empty: 2-781                      [16, 128, 8, 8]           --
│    └─Empty: 2-782                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [128, 128, 3, 3]          --
│    └─Empty: 2-787                      [128, 128, 3, 3]          --
│    └─Empty: 2-788                      [128]                     --
│    └─Empty: 2-789                      [128]                     --
│    └─BatchNorm2d: 2-790                [16, 128, 8, 8]           --
│    └─Scaler: 2-791                     [16, 128, 8, 8]           --
│    └─ReLU: 2-792                       [16, 128, 8, 8]           --
│    └─Empty: 2-793                      [16, 128, 8, 8]           --
│    └─Clamp: 2-794                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-80                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-795         --                        --
│    └─One: 2-796                        [1]                       --
│    └─OutputScale: 2-797                --                        --
│    └─Empty: 2-798                      [16, 128, 1, 1]           --
│    └─Empty: 2-799                      [16, 128, 1, 1]           --
│    └─Empty: 2-800                      [16]                      --
│    └─Empty: 2-801                      [16]                      --
│    └─BatchNorm2d: 2-802                [16, 16, 8, 8]            --
│    └─Scaler: 2-803                     [16, 16, 8, 8]            --
│    └─ReLU: 2-804                       [16, 16, 8, 8]            --
│    └─Empty: 2-805                      [16, 16, 8, 8]            --
│    └─Clamp: 2-806                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-807                  [16, 128, 8, 8]           --
│    └─Empty: 2-808                      [16, 128, 8, 8]           --
│    └─Empty: 2-809                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [16, 128, 3, 3]           --
│    └─Empty: 2-814                      [16, 128, 3, 3]           --
│    └─Empty: 2-815                      [16]                      --
│    └─Empty: 2-816                      [16]                      --
│    └─BatchNorm2d: 2-817                [16, 16, 8, 8]            --
│    └─Scaler: 2-818                     [16, 16, 8, 8]            --
│    └─ReLU: 2-819                       [16, 16, 8, 8]            --
│    └─Empty: 2-820                      [16, 16, 8, 8]            --
│    └─Clamp: 2-821                      [16, 16, 8, 8]            --
├─Dropout2d: 1-82                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-83                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-822         --                        --
│    └─One: 2-823                        [1]                       --
│    └─OutputScale: 2-824                --                        --
│    └─Empty: 2-825                      [128, 48, 1, 1]           --
│    └─Empty: 2-826                      [128, 48, 1, 1]           --
│    └─Empty: 2-827                      [128]                     --
│    └─Empty: 2-828                      [128]                     --
│    └─BatchNorm2d: 2-829                [16, 128, 64, 64]         --
│    └─Scaler: 2-830                     [16, 128, 64, 64]         --
│    └─ReLU: 2-831                       [16, 128, 64, 64]         --
│    └─Empty: 2-832                      [16, 128, 64, 64]         --
│    └─Clamp: 2-833                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-84         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-834                  [16, 128, 32, 32]         --
│    └─Empty: 2-835                      [16, 128, 32, 32]         --
│    └─Empty: 2-836                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-837         --                        --
│    └─One: 2-838                        [1]                       --
│    └─OutputScale: 2-839                --                        --
│    └─Empty: 2-840                      [128, 128, 3, 3]          --
│    └─Empty: 2-841                      [128, 128, 3, 3]          --
│    └─Empty: 2-842                      [128]                     --
│    └─Empty: 2-843                      [128]                     --
│    └─BatchNorm2d: 2-844                [16, 128, 32, 32]         --
│    └─Scaler: 2-845                     [16, 128, 32, 32]         --
│    └─ReLU: 2-846                       [16, 128, 32, 32]         --
│    └─Empty: 2-847                      [16, 128, 32, 32]         --
│    └─Clamp: 2-848                      [16, 128, 32, 32]         --
├─Dropout2d: 1-85                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-86         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-849                  [16, 128, 16, 16]         --
│    └─Empty: 2-850                      [16, 128, 16, 16]         --
│    └─Empty: 2-851                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-852         --                        --
│    └─One: 2-853                        [1]                       --
│    └─OutputScale: 2-854                --                        --
│    └─Empty: 2-855                      [128, 128, 3, 3]          --
│    └─Empty: 2-856                      [128, 128, 3, 3]          --
│    └─Empty: 2-857                      [128]                     --
│    └─Empty: 2-858                      [128]                     --
│    └─BatchNorm2d: 2-859                [16, 128, 16, 16]         --
│    └─Scaler: 2-860                     [16, 128, 16, 16]         --
│    └─ReLU: 2-861                       [16, 128, 16, 16]         --
│    └─Empty: 2-862                      [16, 128, 16, 16]         --
│    └─Clamp: 2-863                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-87                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-864         --                        --
│    └─One: 2-865                        [1]                       --
│    └─OutputScale: 2-866                --                        --
│    └─Empty: 2-867                      [128, 128, 1, 1]          --
│    └─Empty: 2-868                      [128, 128, 1, 1]          --
│    └─Empty: 2-869                      [128]                     --
│    └─Empty: 2-870                      [128]                     --
│    └─BatchNorm2d: 2-871                [16, 128, 16, 16]         --
│    └─Scaler: 2-872                     [16, 128, 16, 16]         --
│    └─ReLU: 2-873                       [16, 128, 16, 16]         --
│    └─Empty: 2-874                      [16, 128, 16, 16]         --
│    └─Clamp: 2-875                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-88         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-876                  [16, 128, 16, 16]         --
│    └─Empty: 2-877                      [16, 128, 16, 16]         --
│    └─Empty: 2-878                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-879         --                        --
│    └─One: 2-880                        [1]                       --
│    └─OutputScale: 2-881                --                        --
│    └─Empty: 2-882                      [128, 128, 3, 3]          --
│    └─Empty: 2-883                      [128, 128, 3, 3]          --
│    └─Empty: 2-884                      [128]                     --
│    └─Empty: 2-885                      [128]                     --
│    └─BatchNorm2d: 2-886                [16, 128, 16, 16]         --
│    └─Scaler: 2-887                     [16, 128, 16, 16]         --
│    └─ReLU: 2-888                       [16, 128, 16, 16]         --
│    └─Empty: 2-889                      [16, 128, 16, 16]         --
│    └─Clamp: 2-890                      [16, 128, 16, 16]         --
├─Dropout2d: 1-89                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-891                  [16, 128, 8, 8]           --
│    └─Empty: 2-892                      [16, 128, 8, 8]           --
│    └─Empty: 2-893                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-894         --                        --
│    └─One: 2-895                        [1]                       --
│    └─OutputScale: 2-896                --                        --
│    └─Empty: 2-897                      [128, 128, 3, 3]          --
│    └─Empty: 2-898                      [128, 128, 3, 3]          --
│    └─Empty: 2-899                      [128]                     --
│    └─Empty: 2-900                      [128]                     --
│    └─BatchNorm2d: 2-901                [16, 128, 8, 8]           --
│    └─Scaler: 2-902                     [16, 128, 8, 8]           --
│    └─ReLU: 2-903                       [16, 128, 8, 8]           --
│    └─Empty: 2-904                      [16, 128, 8, 8]           --
│    └─Clamp: 2-905                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-91                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-906         --                        --
│    └─One: 2-907                        [1]                       --
│    └─OutputScale: 2-908                --                        --
│    └─Empty: 2-909                      [16, 128, 1, 1]           --
│    └─Empty: 2-910                      [16, 128, 1, 1]           --
│    └─Empty: 2-911                      [16]                      --
│    └─Empty: 2-912                      [16]                      --
│    └─BatchNorm2d: 2-913                [16, 16, 8, 8]            --
│    └─Scaler: 2-914                     [16, 16, 8, 8]            --
│    └─ReLU: 2-915                       [16, 16, 8, 8]            --
│    └─Empty: 2-916                      [16, 16, 8, 8]            --
│    └─Clamp: 2-917                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-918                  [16, 128, 8, 8]           --
│    └─Empty: 2-919                      [16, 128, 8, 8]           --
│    └─Empty: 2-920                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [16, 128, 3, 3]           --
│    └─Empty: 2-925                      [16, 128, 3, 3]           --
│    └─Empty: 2-926                      [16]                      --
│    └─Empty: 2-927                      [16]                      --
│    └─BatchNorm2d: 2-928                [16, 16, 8, 8]            --
│    └─Scaler: 2-929                     [16, 16, 8, 8]            --
│    └─ReLU: 2-930                       [16, 16, 8, 8]            --
│    └─Empty: 2-931                      [16, 16, 8, 8]            --
│    └─Clamp: 2-932                      [16, 16, 8, 8]            --
├─Dropout2d: 1-93                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-94                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [128, 48, 1, 1]           --
│    └─Empty: 2-937                      [128, 48, 1, 1]           --
│    └─Empty: 2-938                      [128]                     --
│    └─Empty: 2-939                      [128]                     --
│    └─BatchNorm2d: 2-940                [16, 128, 64, 64]         --
│    └─Scaler: 2-941                     [16, 128, 64, 64]         --
│    └─ReLU: 2-942                       [16, 128, 64, 64]         --
│    └─Empty: 2-943                      [16, 128, 64, 64]         --
│    └─Clamp: 2-944                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-945                  [16, 128, 32, 32]         --
│    └─Empty: 2-946                      [16, 128, 32, 32]         --
│    └─Empty: 2-947                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-948         --                        --
│    └─One: 2-949                        [1]                       --
│    └─OutputScale: 2-950                --                        --
│    └─Empty: 2-951                      [128, 128, 3, 3]          --
│    └─Empty: 2-952                      [128, 128, 3, 3]          --
│    └─Empty: 2-953                      [128]                     --
│    └─Empty: 2-954                      [128]                     --
│    └─BatchNorm2d: 2-955                [16, 128, 32, 32]         --
│    └─Scaler: 2-956                     [16, 128, 32, 32]         --
│    └─ReLU: 2-957                       [16, 128, 32, 32]         --
│    └─Empty: 2-958                      [16, 128, 32, 32]         --
│    └─Clamp: 2-959                      [16, 128, 32, 32]         --
├─Dropout2d: 1-96                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-960                  [16, 128, 16, 16]         --
│    └─Empty: 2-961                      [16, 128, 16, 16]         --
│    └─Empty: 2-962                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-963         --                        --
│    └─One: 2-964                        [1]                       --
│    └─OutputScale: 2-965                --                        --
│    └─Empty: 2-966                      [128, 128, 3, 3]          --
│    └─Empty: 2-967                      [128, 128, 3, 3]          --
│    └─Empty: 2-968                      [128]                     --
│    └─Empty: 2-969                      [128]                     --
│    └─BatchNorm2d: 2-970                [16, 128, 16, 16]         --
│    └─Scaler: 2-971                     [16, 128, 16, 16]         --
│    └─ReLU: 2-972                       [16, 128, 16, 16]         --
│    └─Empty: 2-973                      [16, 128, 16, 16]         --
│    └─Clamp: 2-974                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-98                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-975         --                        --
│    └─One: 2-976                        [1]                       --
│    └─OutputScale: 2-977                --                        --
│    └─Empty: 2-978                      [128, 128, 1, 1]          --
│    └─Empty: 2-979                      [128, 128, 1, 1]          --
│    └─Empty: 2-980                      [128]                     --
│    └─Empty: 2-981                      [128]                     --
│    └─BatchNorm2d: 2-982                [16, 128, 16, 16]         --
│    └─Scaler: 2-983                     [16, 128, 16, 16]         --
│    └─ReLU: 2-984                       [16, 128, 16, 16]         --
│    └─Empty: 2-985                      [16, 128, 16, 16]         --
│    └─Clamp: 2-986                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-987                  [16, 128, 16, 16]         --
│    └─Empty: 2-988                      [16, 128, 16, 16]         --
│    └─Empty: 2-989                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-990         --                        --
│    └─One: 2-991                        [1]                       --
│    └─OutputScale: 2-992                --                        --
│    └─Empty: 2-993                      [128, 128, 3, 3]          --
│    └─Empty: 2-994                      [128, 128, 3, 3]          --
│    └─Empty: 2-995                      [128]                     --
│    └─Empty: 2-996                      [128]                     --
│    └─BatchNorm2d: 2-997                [16, 128, 16, 16]         --
│    └─Scaler: 2-998                     [16, 128, 16, 16]         --
│    └─ReLU: 2-999                       [16, 128, 16, 16]         --
│    └─Empty: 2-1000                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1001                     [16, 128, 16, 16]         --
├─Dropout2d: 1-100                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-101        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1002                 [16, 128, 8, 8]           --
│    └─Empty: 2-1003                     [16, 128, 8, 8]           --
│    └─Empty: 2-1004                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1005        --                        --
│    └─One: 2-1006                       [1]                       --
│    └─OutputScale: 2-1007               --                        --
│    └─Empty: 2-1008                     [128, 128, 3, 3]          --
│    └─Empty: 2-1009                     [128, 128, 3, 3]          --
│    └─Empty: 2-1010                     [128]                     --
│    └─Empty: 2-1011                     [128]                     --
│    └─BatchNorm2d: 2-1012               [16, 128, 8, 8]           --
│    └─Scaler: 2-1013                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1014                      [16, 128, 8, 8]           --
│    └─Empty: 2-1015                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1016                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-102               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1017        --                        --
│    └─One: 2-1018                       [1]                       --
│    └─OutputScale: 2-1019               --                        --
│    └─Empty: 2-1020                     [16, 128, 1, 1]           --
│    └─Empty: 2-1021                     [16, 128, 1, 1]           --
│    └─Empty: 2-1022                     [16]                      --
│    └─Empty: 2-1023                     [16]                      --
│    └─BatchNorm2d: 2-1024               [16, 16, 8, 8]            --
│    └─Scaler: 2-1025                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1026                      [16, 16, 8, 8]            --
│    └─Empty: 2-1027                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1028                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1029                 [16, 128, 8, 8]           --
│    └─Empty: 2-1030                     [16, 128, 8, 8]           --
│    └─Empty: 2-1031                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1032        --                        --
│    └─One: 2-1033                       [1]                       --
│    └─OutputScale: 2-1034               --                        --
│    └─Empty: 2-1035                     [16, 128, 3, 3]           --
│    └─Empty: 2-1036                     [16, 128, 3, 3]           --
│    └─Empty: 2-1037                     [16]                      --
│    └─Empty: 2-1038                     [16]                      --
│    └─BatchNorm2d: 2-1039               [16, 16, 8, 8]            --
│    └─Scaler: 2-1040                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1041                      [16, 16, 8, 8]            --
│    └─Empty: 2-1042                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1043                     [16, 16, 8, 8]            --
├─Dropout2d: 1-104                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-105               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1044        --                        --
│    └─One: 2-1045                       [1]                       --
│    └─OutputScale: 2-1046               --                        --
│    └─Empty: 2-1047                     [128, 48, 1, 1]           --
│    └─Empty: 2-1048                     [128, 48, 1, 1]           --
│    └─Empty: 2-1049                     [128]                     --
│    └─Empty: 2-1050                     [128]                     --
│    └─BatchNorm2d: 2-1051               [16, 128, 64, 64]         --
│    └─Scaler: 2-1052                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1053                      [16, 128, 64, 64]         --
│    └─Empty: 2-1054                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1055                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-106        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1056                 [16, 128, 32, 32]         --
│    └─Empty: 2-1057                     [16, 128, 32, 32]         --
│    └─Empty: 2-1058                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1059        --                        --
│    └─One: 2-1060                       [1]                       --
│    └─OutputScale: 2-1061               --                        --
│    └─Empty: 2-1062                     [128, 128, 3, 3]          --
│    └─Empty: 2-1063                     [128, 128, 3, 3]          --
│    └─Empty: 2-1064                     [128]                     --
│    └─Empty: 2-1065                     [128]                     --
│    └─BatchNorm2d: 2-1066               [16, 128, 32, 32]         --
│    └─Scaler: 2-1067                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1068                      [16, 128, 32, 32]         --
│    └─Empty: 2-1069                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1070                     [16, 128, 32, 32]         --
├─Dropout2d: 1-107                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-108        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1071                 [16, 128, 16, 16]         --
│    └─Empty: 2-1072                     [16, 128, 16, 16]         --
│    └─Empty: 2-1073                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1074        --                        --
│    └─One: 2-1075                       [1]                       --
│    └─OutputScale: 2-1076               --                        --
│    └─Empty: 2-1077                     [128, 128, 3, 3]          --
│    └─Empty: 2-1078                     [128, 128, 3, 3]          --
│    └─Empty: 2-1079                     [128]                     --
│    └─Empty: 2-1080                     [128]                     --
│    └─BatchNorm2d: 2-1081               [16, 128, 16, 16]         --
│    └─Scaler: 2-1082                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1083                      [16, 128, 16, 16]         --
│    └─Empty: 2-1084                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1085                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-109               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1086        --                        --
│    └─One: 2-1087                       [1]                       --
│    └─OutputScale: 2-1088               --                        --
│    └─Empty: 2-1089                     [128, 128, 1, 1]          --
│    └─Empty: 2-1090                     [128, 128, 1, 1]          --
│    └─Empty: 2-1091                     [128]                     --
│    └─Empty: 2-1092                     [128]                     --
│    └─BatchNorm2d: 2-1093               [16, 128, 16, 16]         --
│    └─Scaler: 2-1094                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1095                      [16, 128, 16, 16]         --
│    └─Empty: 2-1096                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1097                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-110        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1098                 [16, 128, 16, 16]         --
│    └─Empty: 2-1099                     [16, 128, 16, 16]         --
│    └─Empty: 2-1100                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1101        --                        --
│    └─One: 2-1102                       [1]                       --
│    └─OutputScale: 2-1103               --                        --
│    └─Empty: 2-1104                     [128, 128, 3, 3]          --
│    └─Empty: 2-1105                     [128, 128, 3, 3]          --
│    └─Empty: 2-1106                     [128]                     --
│    └─Empty: 2-1107                     [128]                     --
│    └─BatchNorm2d: 2-1108               [16, 128, 16, 16]         --
│    └─Scaler: 2-1109                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1110                      [16, 128, 16, 16]         --
│    └─Empty: 2-1111                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1112                     [16, 128, 16, 16]         --
├─Dropout2d: 1-111                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-112        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1113                 [16, 128, 8, 8]           --
│    └─Empty: 2-1114                     [16, 128, 8, 8]           --
│    └─Empty: 2-1115                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1116        --                        --
│    └─One: 2-1117                       [1]                       --
│    └─OutputScale: 2-1118               --                        --
│    └─Empty: 2-1119                     [128, 128, 3, 3]          --
│    └─Empty: 2-1120                     [128, 128, 3, 3]          --
│    └─Empty: 2-1121                     [128]                     --
│    └─Empty: 2-1122                     [128]                     --
│    └─BatchNorm2d: 2-1123               [16, 128, 8, 8]           --
│    └─Scaler: 2-1124                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1125                      [16, 128, 8, 8]           --
│    └─Empty: 2-1126                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1127                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-113               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1128        --                        --
│    └─One: 2-1129                       [1]                       --
│    └─OutputScale: 2-1130               --                        --
│    └─Empty: 2-1131                     [16, 128, 1, 1]           --
│    └─Empty: 2-1132                     [16, 128, 1, 1]           --
│    └─Empty: 2-1133                     [16]                      --
│    └─Empty: 2-1134                     [16]                      --
│    └─BatchNorm2d: 2-1135               [16, 16, 8, 8]            --
│    └─Scaler: 2-1136                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1137                      [16, 16, 8, 8]            --
│    └─Empty: 2-1138                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1139                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1140                 [16, 128, 8, 8]           --
│    └─Empty: 2-1141                     [16, 128, 8, 8]           --
│    └─Empty: 2-1142                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1143        --                        --
│    └─One: 2-1144                       [1]                       --
│    └─OutputScale: 2-1145               --                        --
│    └─Empty: 2-1146                     [16, 128, 3, 3]           --
│    └─Empty: 2-1147                     [16, 128, 3, 3]           --
│    └─Empty: 2-1148                     [16]                      --
│    └─Empty: 2-1149                     [16]                      --
│    └─BatchNorm2d: 2-1150               [16, 16, 8, 8]            --
│    └─Scaler: 2-1151                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1152                      [16, 16, 8, 8]            --
│    └─Empty: 2-1153                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1154                     [16, 16, 8, 8]            --
├─Dropout2d: 1-115                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-116               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1155        --                        --
│    └─One: 2-1156                       [1]                       --
│    └─OutputScale: 2-1157               --                        --
│    └─Empty: 2-1158                     [128, 48, 1, 1]           --
│    └─Empty: 2-1159                     [128, 48, 1, 1]           --
│    └─Empty: 2-1160                     [128]                     --
│    └─Empty: 2-1161                     [128]                     --
│    └─BatchNorm2d: 2-1162               [16, 128, 64, 64]         --
│    └─Scaler: 2-1163                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1164                      [16, 128, 64, 64]         --
│    └─Empty: 2-1165                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1166                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1167                 [16, 128, 32, 32]         --
│    └─Empty: 2-1168                     [16, 128, 32, 32]         --
│    └─Empty: 2-1169                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1170        --                        --
│    └─One: 2-1171                       [1]                       --
│    └─OutputScale: 2-1172               --                        --
│    └─Empty: 2-1173                     [128, 128, 3, 3]          --
│    └─Empty: 2-1174                     [128, 128, 3, 3]          --
│    └─Empty: 2-1175                     [128]                     --
│    └─Empty: 2-1176                     [128]                     --
│    └─BatchNorm2d: 2-1177               [16, 128, 32, 32]         --
│    └─Scaler: 2-1178                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1179                      [16, 128, 32, 32]         --
│    └─Empty: 2-1180                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1181                     [16, 128, 32, 32]         --
├─Dropout2d: 1-118                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1182                 [16, 128, 16, 16]         --
│    └─Empty: 2-1183                     [16, 128, 16, 16]         --
│    └─Empty: 2-1184                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1185        --                        --
│    └─One: 2-1186                       [1]                       --
│    └─OutputScale: 2-1187               --                        --
│    └─Empty: 2-1188                     [128, 128, 3, 3]          --
│    └─Empty: 2-1189                     [128, 128, 3, 3]          --
│    └─Empty: 2-1190                     [128]                     --
│    └─Empty: 2-1191                     [128]                     --
│    └─BatchNorm2d: 2-1192               [16, 128, 16, 16]         --
│    └─Scaler: 2-1193                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1194                      [16, 128, 16, 16]         --
│    └─Empty: 2-1195                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1196                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-120               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1197        --                        --
│    └─One: 2-1198                       [1]                       --
│    └─OutputScale: 2-1199               --                        --
│    └─Empty: 2-1200                     [128, 128, 1, 1]          --
│    └─Empty: 2-1201                     [128, 128, 1, 1]          --
│    └─Empty: 2-1202                     [128]                     --
│    └─Empty: 2-1203                     [128]                     --
│    └─BatchNorm2d: 2-1204               [16, 128, 16, 16]         --
│    └─Scaler: 2-1205                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1206                      [16, 128, 16, 16]         --
│    └─Empty: 2-1207                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1208                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1209                 [16, 128, 16, 16]         --
│    └─Empty: 2-1210                     [16, 128, 16, 16]         --
│    └─Empty: 2-1211                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1212        --                        --
│    └─One: 2-1213                       [1]                       --
│    └─OutputScale: 2-1214               --                        --
│    └─Empty: 2-1215                     [128, 128, 3, 3]          --
│    └─Empty: 2-1216                     [128, 128, 3, 3]          --
│    └─Empty: 2-1217                     [128]                     --
│    └─Empty: 2-1218                     [128]                     --
│    └─BatchNorm2d: 2-1219               [16, 128, 16, 16]         --
│    └─Scaler: 2-1220                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1221                      [16, 128, 16, 16]         --
│    └─Empty: 2-1222                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1223                     [16, 128, 16, 16]         --
├─Dropout2d: 1-122                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-123        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1224                 [16, 128, 8, 8]           --
│    └─Empty: 2-1225                     [16, 128, 8, 8]           --
│    └─Empty: 2-1226                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1227        --                        --
│    └─One: 2-1228                       [1]                       --
│    └─OutputScale: 2-1229               --                        --
│    └─Empty: 2-1230                     [128, 128, 3, 3]          --
│    └─Empty: 2-1231                     [128, 128, 3, 3]          --
│    └─Empty: 2-1232                     [128]                     --
│    └─Empty: 2-1233                     [128]                     --
│    └─BatchNorm2d: 2-1234               [16, 128, 8, 8]           --
│    └─Scaler: 2-1235                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1236                      [16, 128, 8, 8]           --
│    └─Empty: 2-1237                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1238                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-124               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1239        --                        --
│    └─One: 2-1240                       [1]                       --
│    └─OutputScale: 2-1241               --                        --
│    └─Empty: 2-1242                     [16, 128, 1, 1]           --
│    └─Empty: 2-1243                     [16, 128, 1, 1]           --
│    └─Empty: 2-1244                     [16]                      --
│    └─Empty: 2-1245                     [16]                      --
│    └─BatchNorm2d: 2-1246               [16, 16, 8, 8]            --
│    └─Scaler: 2-1247                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1248                      [16, 16, 8, 8]            --
│    └─Empty: 2-1249                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1250                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-125        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1251                 [16, 128, 8, 8]           --
│    └─Empty: 2-1252                     [16, 128, 8, 8]           --
│    └─Empty: 2-1253                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1254        --                        --
│    └─One: 2-1255                       [1]                       --
│    └─OutputScale: 2-1256               --                        --
│    └─Empty: 2-1257                     [16, 128, 3, 3]           --
│    └─Empty: 2-1258                     [16, 128, 3, 3]           --
│    └─Empty: 2-1259                     [16]                      --
│    └─Empty: 2-1260                     [16]                      --
│    └─BatchNorm2d: 2-1261               [16, 16, 8, 8]            --
│    └─Scaler: 2-1262                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1263                      [16, 16, 8, 8]            --
│    └─Empty: 2-1264                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1265                     [16, 16, 8, 8]            --
├─Dropout2d: 1-126                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-127               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1266        --                        --
│    └─One: 2-1267                       [1]                       --
│    └─OutputScale: 2-1268               --                        --
│    └─Empty: 2-1269                     [128, 48, 1, 1]           --
│    └─Empty: 2-1270                     [128, 48, 1, 1]           --
│    └─Empty: 2-1271                     [128]                     --
│    └─Empty: 2-1272                     [128]                     --
│    └─BatchNorm2d: 2-1273               [16, 128, 64, 64]         --
│    └─Scaler: 2-1274                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1275                      [16, 128, 64, 64]         --
│    └─Empty: 2-1276                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1277                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1278                 [16, 128, 32, 32]         --
│    └─Empty: 2-1279                     [16, 128, 32, 32]         --
│    └─Empty: 2-1280                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1281        --                        --
│    └─One: 2-1282                       [1]                       --
│    └─OutputScale: 2-1283               --                        --
│    └─Empty: 2-1284                     [128, 128, 3, 3]          --
│    └─Empty: 2-1285                     [128, 128, 3, 3]          --
│    └─Empty: 2-1286                     [128]                     --
│    └─Empty: 2-1287                     [128]                     --
│    └─BatchNorm2d: 2-1288               [16, 128, 32, 32]         --
│    └─Scaler: 2-1289                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1290                      [16, 128, 32, 32]         --
│    └─Empty: 2-1291                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1292                     [16, 128, 32, 32]         --
├─Dropout2d: 1-129                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1293                 [16, 128, 16, 16]         --
│    └─Empty: 2-1294                     [16, 128, 16, 16]         --
│    └─Empty: 2-1295                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1296        --                        --
│    └─One: 2-1297                       [1]                       --
│    └─OutputScale: 2-1298               --                        --
│    └─Empty: 2-1299                     [128, 128, 3, 3]          --
│    └─Empty: 2-1300                     [128, 128, 3, 3]          --
│    └─Empty: 2-1301                     [128]                     --
│    └─Empty: 2-1302                     [128]                     --
│    └─BatchNorm2d: 2-1303               [16, 128, 16, 16]         --
│    └─Scaler: 2-1304                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1305                      [16, 128, 16, 16]         --
│    └─Empty: 2-1306                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1307                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-131               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1308        --                        --
│    └─One: 2-1309                       [1]                       --
│    └─OutputScale: 2-1310               --                        --
│    └─Empty: 2-1311                     [128, 128, 1, 1]          --
│    └─Empty: 2-1312                     [128, 128, 1, 1]          --
│    └─Empty: 2-1313                     [128]                     --
│    └─Empty: 2-1314                     [128]                     --
│    └─BatchNorm2d: 2-1315               [16, 128, 16, 16]         --
│    └─Scaler: 2-1316                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1317                      [16, 128, 16, 16]         --
│    └─Empty: 2-1318                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1319                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1320                 [16, 128, 16, 16]         --
│    └─Empty: 2-1321                     [16, 128, 16, 16]         --
│    └─Empty: 2-1322                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1323        --                        --
│    └─One: 2-1324                       [1]                       --
│    └─OutputScale: 2-1325               --                        --
│    └─Empty: 2-1326                     [128, 128, 3, 3]          --
│    └─Empty: 2-1327                     [128, 128, 3, 3]          --
│    └─Empty: 2-1328                     [128]                     --
│    └─Empty: 2-1329                     [128]                     --
│    └─BatchNorm2d: 2-1330               [16, 128, 16, 16]         --
│    └─Scaler: 2-1331                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1332                      [16, 128, 16, 16]         --
│    └─Empty: 2-1333                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1334                     [16, 128, 16, 16]         --
├─Dropout2d: 1-133                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1335                 [16, 128, 8, 8]           --
│    └─Empty: 2-1336                     [16, 128, 8, 8]           --
│    └─Empty: 2-1337                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1338        --                        --
│    └─One: 2-1339                       [1]                       --
│    └─OutputScale: 2-1340               --                        --
│    └─Empty: 2-1341                     [128, 128, 3, 3]          --
│    └─Empty: 2-1342                     [128, 128, 3, 3]          --
│    └─Empty: 2-1343                     [128]                     --
│    └─Empty: 2-1344                     [128]                     --
│    └─BatchNorm2d: 2-1345               [16, 128, 8, 8]           --
│    └─Scaler: 2-1346                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1347                      [16, 128, 8, 8]           --
│    └─Empty: 2-1348                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1349                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-135               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1350        --                        --
│    └─One: 2-1351                       [1]                       --
│    └─OutputScale: 2-1352               --                        --
│    └─Empty: 2-1353                     [16, 128, 1, 1]           --
│    └─Empty: 2-1354                     [16, 128, 1, 1]           --
│    └─Empty: 2-1355                     [16]                      --
│    └─Empty: 2-1356                     [16]                      --
│    └─BatchNorm2d: 2-1357               [16, 16, 8, 8]            --
│    └─Scaler: 2-1358                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1359                      [16, 16, 8, 8]            --
│    └─Empty: 2-1360                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1361                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1362                 [16, 128, 8, 8]           --
│    └─Empty: 2-1363                     [16, 128, 8, 8]           --
│    └─Empty: 2-1364                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1365        --                        --
│    └─One: 2-1366                       [1]                       --
│    └─OutputScale: 2-1367               --                        --
│    └─Empty: 2-1368                     [16, 128, 3, 3]           --
│    └─Empty: 2-1369                     [16, 128, 3, 3]           --
│    └─Empty: 2-1370                     [16]                      --
│    └─Empty: 2-1371                     [16]                      --
│    └─BatchNorm2d: 2-1372               [16, 16, 8, 8]            --
│    └─Scaler: 2-1373                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1374                      [16, 16, 8, 8]            --
│    └─Empty: 2-1375                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1376                     [16, 16, 8, 8]            --
├─Dropout2d: 1-137                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-138               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1377        --                        --
│    └─One: 2-1378                       [1]                       --
│    └─OutputScale: 2-1379               --                        --
│    └─Empty: 2-1380                     [128, 48, 1, 1]           --
│    └─Empty: 2-1381                     [128, 48, 1, 1]           --
│    └─Empty: 2-1382                     [128]                     --
│    └─Empty: 2-1383                     [128]                     --
│    └─BatchNorm2d: 2-1384               [16, 128, 64, 64]         --
│    └─Scaler: 2-1385                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1386                      [16, 128, 64, 64]         --
│    └─Empty: 2-1387                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1388                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-139        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1389                 [16, 128, 32, 32]         --
│    └─Empty: 2-1390                     [16, 128, 32, 32]         --
│    └─Empty: 2-1391                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1392        --                        --
│    └─One: 2-1393                       [1]                       --
│    └─OutputScale: 2-1394               --                        --
│    └─Empty: 2-1395                     [128, 128, 3, 3]          --
│    └─Empty: 2-1396                     [128, 128, 3, 3]          --
│    └─Empty: 2-1397                     [128]                     --
│    └─Empty: 2-1398                     [128]                     --
│    └─BatchNorm2d: 2-1399               [16, 128, 32, 32]         --
│    └─Scaler: 2-1400                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1401                      [16, 128, 32, 32]         --
│    └─Empty: 2-1402                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1403                     [16, 128, 32, 32]         --
├─Dropout2d: 1-140                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1404                 [16, 128, 16, 16]         --
│    └─Empty: 2-1405                     [16, 128, 16, 16]         --
│    └─Empty: 2-1406                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1407        --                        --
│    └─One: 2-1408                       [1]                       --
│    └─OutputScale: 2-1409               --                        --
│    └─Empty: 2-1410                     [128, 128, 3, 3]          --
│    └─Empty: 2-1411                     [128, 128, 3, 3]          --
│    └─Empty: 2-1412                     [128]                     --
│    └─Empty: 2-1413                     [128]                     --
│    └─BatchNorm2d: 2-1414               [16, 128, 16, 16]         --
│    └─Scaler: 2-1415                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1416                      [16, 128, 16, 16]         --
│    └─Empty: 2-1417                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1418                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-142               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1419        --                        --
│    └─One: 2-1420                       [1]                       --
│    └─OutputScale: 2-1421               --                        --
│    └─Empty: 2-1422                     [128, 128, 1, 1]          --
│    └─Empty: 2-1423                     [128, 128, 1, 1]          --
│    └─Empty: 2-1424                     [128]                     --
│    └─Empty: 2-1425                     [128]                     --
│    └─BatchNorm2d: 2-1426               [16, 128, 16, 16]         --
│    └─Scaler: 2-1427                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1428                      [16, 128, 16, 16]         --
│    └─Empty: 2-1429                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1430                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1431                 [16, 128, 16, 16]         --
│    └─Empty: 2-1432                     [16, 128, 16, 16]         --
│    └─Empty: 2-1433                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1434        --                        --
│    └─One: 2-1435                       [1]                       --
│    └─OutputScale: 2-1436               --                        --
│    └─Empty: 2-1437                     [128, 128, 3, 3]          --
│    └─Empty: 2-1438                     [128, 128, 3, 3]          --
│    └─Empty: 2-1439                     [128]                     --
│    └─Empty: 2-1440                     [128]                     --
│    └─BatchNorm2d: 2-1441               [16, 128, 16, 16]         --
│    └─Scaler: 2-1442                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1443                      [16, 128, 16, 16]         --
│    └─Empty: 2-1444                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1445                     [16, 128, 16, 16]         --
├─Dropout2d: 1-144                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1446                 [16, 128, 8, 8]           --
│    └─Empty: 2-1447                     [16, 128, 8, 8]           --
│    └─Empty: 2-1448                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1449        --                        --
│    └─One: 2-1450                       [1]                       --
│    └─OutputScale: 2-1451               --                        --
│    └─Empty: 2-1452                     [128, 128, 3, 3]          --
│    └─Empty: 2-1453                     [128, 128, 3, 3]          --
│    └─Empty: 2-1454                     [128]                     --
│    └─Empty: 2-1455                     [128]                     --
│    └─BatchNorm2d: 2-1456               [16, 128, 8, 8]           --
│    └─Scaler: 2-1457                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1458                      [16, 128, 8, 8]           --
│    └─Empty: 2-1459                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1460                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-146               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1461        --                        --
│    └─One: 2-1462                       [1]                       --
│    └─OutputScale: 2-1463               --                        --
│    └─Empty: 2-1464                     [16, 128, 1, 1]           --
│    └─Empty: 2-1465                     [16, 128, 1, 1]           --
│    └─Empty: 2-1466                     [16]                      --
│    └─Empty: 2-1467                     [16]                      --
│    └─BatchNorm2d: 2-1468               [16, 16, 8, 8]            --
│    └─Scaler: 2-1469                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1470                      [16, 16, 8, 8]            --
│    └─Empty: 2-1471                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1472                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1473                 [16, 128, 8, 8]           --
│    └─Empty: 2-1474                     [16, 128, 8, 8]           --
│    └─Empty: 2-1475                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1476        --                        --
│    └─One: 2-1477                       [1]                       --
│    └─OutputScale: 2-1478               --                        --
│    └─Empty: 2-1479                     [16, 128, 3, 3]           --
│    └─Empty: 2-1480                     [16, 128, 3, 3]           --
│    └─Empty: 2-1481                     [16]                      --
│    └─Empty: 2-1482                     [16]                      --
│    └─BatchNorm2d: 2-1483               [16, 16, 8, 8]            --
│    └─Scaler: 2-1484                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1485                      [16, 16, 8, 8]            --
│    └─Empty: 2-1486                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1487                     [16, 16, 8, 8]            --
├─Dropout2d: 1-148                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-149               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1488        --                        --
│    └─One: 2-1489                       [1]                       --
│    └─OutputScale: 2-1490               --                        --
│    └─Empty: 2-1491                     [128, 48, 1, 1]           --
│    └─Empty: 2-1492                     [128, 48, 1, 1]           --
│    └─Empty: 2-1493                     [128]                     --
│    └─Empty: 2-1494                     [128]                     --
│    └─BatchNorm2d: 2-1495               [16, 128, 64, 64]         --
│    └─Scaler: 2-1496                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1497                      [16, 128, 64, 64]         --
│    └─Empty: 2-1498                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1499                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1500                 [16, 128, 32, 32]         --
│    └─Empty: 2-1501                     [16, 128, 32, 32]         --
│    └─Empty: 2-1502                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1503        --                        --
│    └─One: 2-1504                       [1]                       --
│    └─OutputScale: 2-1505               --                        --
│    └─Empty: 2-1506                     [128, 128, 3, 3]          --
│    └─Empty: 2-1507                     [128, 128, 3, 3]          --
│    └─Empty: 2-1508                     [128]                     --
│    └─Empty: 2-1509                     [128]                     --
│    └─BatchNorm2d: 2-1510               [16, 128, 32, 32]         --
│    └─Scaler: 2-1511                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1512                      [16, 128, 32, 32]         --
│    └─Empty: 2-1513                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1514                     [16, 128, 32, 32]         --
├─Dropout2d: 1-151                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-152        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1515                 [16, 128, 16, 16]         --
│    └─Empty: 2-1516                     [16, 128, 16, 16]         --
│    └─Empty: 2-1517                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1518        --                        --
│    └─One: 2-1519                       [1]                       --
│    └─OutputScale: 2-1520               --                        --
│    └─Empty: 2-1521                     [128, 128, 3, 3]          --
│    └─Empty: 2-1522                     [128, 128, 3, 3]          --
│    └─Empty: 2-1523                     [128]                     --
│    └─Empty: 2-1524                     [128]                     --
│    └─BatchNorm2d: 2-1525               [16, 128, 16, 16]         --
│    └─Scaler: 2-1526                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1527                      [16, 128, 16, 16]         --
│    └─Empty: 2-1528                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1529                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-153               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1530        --                        --
│    └─One: 2-1531                       [1]                       --
│    └─OutputScale: 2-1532               --                        --
│    └─Empty: 2-1533                     [128, 128, 1, 1]          --
│    └─Empty: 2-1534                     [128, 128, 1, 1]          --
│    └─Empty: 2-1535                     [128]                     --
│    └─Empty: 2-1536                     [128]                     --
│    └─BatchNorm2d: 2-1537               [16, 128, 16, 16]         --
│    └─Scaler: 2-1538                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1539                      [16, 128, 16, 16]         --
│    └─Empty: 2-1540                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1541                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-154        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1542                 [16, 128, 16, 16]         --
│    └─Empty: 2-1543                     [16, 128, 16, 16]         --
│    └─Empty: 2-1544                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1545        --                        --
│    └─One: 2-1546                       [1]                       --
│    └─OutputScale: 2-1547               --                        --
│    └─Empty: 2-1548                     [128, 128, 3, 3]          --
│    └─Empty: 2-1549                     [128, 128, 3, 3]          --
│    └─Empty: 2-1550                     [128]                     --
│    └─Empty: 2-1551                     [128]                     --
│    └─BatchNorm2d: 2-1552               [16, 128, 16, 16]         --
│    └─Scaler: 2-1553                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1554                      [16, 128, 16, 16]         --
│    └─Empty: 2-1555                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1556                     [16, 128, 16, 16]         --
├─Dropout2d: 1-155                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-156        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1557                 [16, 128, 8, 8]           --
│    └─Empty: 2-1558                     [16, 128, 8, 8]           --
│    └─Empty: 2-1559                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1560        --                        --
│    └─One: 2-1561                       [1]                       --
│    └─OutputScale: 2-1562               --                        --
│    └─Empty: 2-1563                     [128, 128, 3, 3]          --
│    └─Empty: 2-1564                     [128, 128, 3, 3]          --
│    └─Empty: 2-1565                     [128]                     --
│    └─Empty: 2-1566                     [128]                     --
│    └─BatchNorm2d: 2-1567               [16, 128, 8, 8]           --
│    └─Scaler: 2-1568                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1569                      [16, 128, 8, 8]           --
│    └─Empty: 2-1570                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1571                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-157               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1572        --                        --
│    └─One: 2-1573                       [1]                       --
│    └─OutputScale: 2-1574               --                        --
│    └─Empty: 2-1575                     [16, 128, 1, 1]           --
│    └─Empty: 2-1576                     [16, 128, 1, 1]           --
│    └─Empty: 2-1577                     [16]                      --
│    └─Empty: 2-1578                     [16]                      --
│    └─BatchNorm2d: 2-1579               [16, 16, 8, 8]            --
│    └─Scaler: 2-1580                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1581                      [16, 16, 8, 8]            --
│    └─Empty: 2-1582                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1583                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1584                 [16, 128, 8, 8]           --
│    └─Empty: 2-1585                     [16, 128, 8, 8]           --
│    └─Empty: 2-1586                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1587        --                        --
│    └─One: 2-1588                       [1]                       --
│    └─OutputScale: 2-1589               --                        --
│    └─Empty: 2-1590                     [16, 128, 3, 3]           --
│    └─Empty: 2-1591                     [16, 128, 3, 3]           --
│    └─Empty: 2-1592                     [16]                      --
│    └─Empty: 2-1593                     [16]                      --
│    └─BatchNorm2d: 2-1594               [16, 16, 8, 8]            --
│    └─Scaler: 2-1595                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1596                      [16, 16, 8, 8]            --
│    └─Empty: 2-1597                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1598                     [16, 16, 8, 8]            --
├─Dropout2d: 1-159                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-160               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1599        --                        --
│    └─One: 2-1600                       [1]                       --
│    └─OutputScale: 2-1601               --                        --
│    └─Empty: 2-1602                     [128, 48, 1, 1]           --
│    └─Empty: 2-1603                     [128, 48, 1, 1]           --
│    └─Empty: 2-1604                     [128]                     --
│    └─Empty: 2-1605                     [128]                     --
│    └─BatchNorm2d: 2-1606               [16, 128, 64, 64]         --
│    └─Scaler: 2-1607                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1608                      [16, 128, 64, 64]         --
│    └─Empty: 2-1609                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1610                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-161        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1611                 [16, 128, 32, 32]         --
│    └─Empty: 2-1612                     [16, 128, 32, 32]         --
│    └─Empty: 2-1613                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1614        --                        --
│    └─One: 2-1615                       [1]                       --
│    └─OutputScale: 2-1616               --                        --
│    └─Empty: 2-1617                     [128, 128, 3, 3]          --
│    └─Empty: 2-1618                     [128, 128, 3, 3]          --
│    └─Empty: 2-1619                     [128]                     --
│    └─Empty: 2-1620                     [128]                     --
│    └─BatchNorm2d: 2-1621               [16, 128, 32, 32]         --
│    └─Scaler: 2-1622                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1623                      [16, 128, 32, 32]         --
│    └─Empty: 2-1624                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1625                     [16, 128, 32, 32]         --
├─Dropout2d: 1-162                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-163        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1626                 [16, 128, 16, 16]         --
│    └─Empty: 2-1627                     [16, 128, 16, 16]         --
│    └─Empty: 2-1628                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [128, 128, 3, 3]          --
│    └─Empty: 2-1633                     [128, 128, 3, 3]          --
│    └─Empty: 2-1634                     [128]                     --
│    └─Empty: 2-1635                     [128]                     --
│    └─BatchNorm2d: 2-1636               [16, 128, 16, 16]         --
│    └─Scaler: 2-1637                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1638                      [16, 128, 16, 16]         --
│    └─Empty: 2-1639                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1640                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-164               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [128, 128, 1, 1]          --
│    └─Empty: 2-1645                     [128, 128, 1, 1]          --
│    └─Empty: 2-1646                     [128]                     --
│    └─Empty: 2-1647                     [128]                     --
│    └─BatchNorm2d: 2-1648               [16, 128, 16, 16]         --
│    └─Scaler: 2-1649                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1650                      [16, 128, 16, 16]         --
│    └─Empty: 2-1651                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1652                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1653                 [16, 128, 16, 16]         --
│    └─Empty: 2-1654                     [16, 128, 16, 16]         --
│    └─Empty: 2-1655                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [128, 128, 3, 3]          --
│    └─Empty: 2-1660                     [128, 128, 3, 3]          --
│    └─Empty: 2-1661                     [128]                     --
│    └─Empty: 2-1662                     [128]                     --
│    └─BatchNorm2d: 2-1663               [16, 128, 16, 16]         --
│    └─Scaler: 2-1664                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1665                      [16, 128, 16, 16]         --
│    └─Empty: 2-1666                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1667                     [16, 128, 16, 16]         --
├─Dropout2d: 1-166                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1668                 [16, 128, 8, 8]           --
│    └─Empty: 2-1669                     [16, 128, 8, 8]           --
│    └─Empty: 2-1670                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1671        --                        --
│    └─One: 2-1672                       [1]                       --
│    └─OutputScale: 2-1673               --                        --
│    └─Empty: 2-1674                     [128, 128, 3, 3]          --
│    └─Empty: 2-1675                     [128, 128, 3, 3]          --
│    └─Empty: 2-1676                     [128]                     --
│    └─Empty: 2-1677                     [128]                     --
│    └─BatchNorm2d: 2-1678               [16, 128, 8, 8]           --
│    └─Scaler: 2-1679                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1680                      [16, 128, 8, 8]           --
│    └─Empty: 2-1681                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1682                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-168               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [16, 128, 1, 1]           --
│    └─Empty: 2-1687                     [16, 128, 1, 1]           --
│    └─Empty: 2-1688                     [16]                      --
│    └─Empty: 2-1689                     [16]                      --
│    └─BatchNorm2d: 2-1690               [16, 16, 8, 8]            --
│    └─Scaler: 2-1691                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1692                      [16, 16, 8, 8]            --
│    └─Empty: 2-1693                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1694                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-169        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1695                 [16, 128, 8, 8]           --
│    └─Empty: 2-1696                     [16, 128, 8, 8]           --
│    └─Empty: 2-1697                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1698        --                        --
│    └─One: 2-1699                       [1]                       --
│    └─OutputScale: 2-1700               --                        --
│    └─Empty: 2-1701                     [16, 128, 3, 3]           --
│    └─Empty: 2-1702                     [16, 128, 3, 3]           --
│    └─Empty: 2-1703                     [16]                      --
│    └─Empty: 2-1704                     [16]                      --
│    └─BatchNorm2d: 2-1705               [16, 16, 8, 8]            --
│    └─Scaler: 2-1706                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1707                      [16, 16, 8, 8]            --
│    └─Empty: 2-1708                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1709                     [16, 16, 8, 8]            --
├─Dropout2d: 1-170                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-171               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [128, 48, 1, 1]           --
│    └─Empty: 2-1714                     [128, 48, 1, 1]           --
│    └─Empty: 2-1715                     [128]                     --
│    └─Empty: 2-1716                     [128]                     --
│    └─BatchNorm2d: 2-1717               [16, 128, 64, 64]         --
│    └─Scaler: 2-1718                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1719                      [16, 128, 64, 64]         --
│    └─Empty: 2-1720                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1721                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-172        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1722                 [16, 128, 32, 32]         --
│    └─Empty: 2-1723                     [16, 128, 32, 32]         --
│    └─Empty: 2-1724                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1725        --                        --
│    └─One: 2-1726                       [1]                       --
│    └─OutputScale: 2-1727               --                        --
│    └─Empty: 2-1728                     [128, 128, 3, 3]          --
│    └─Empty: 2-1729                     [128, 128, 3, 3]          --
│    └─Empty: 2-1730                     [128]                     --
│    └─Empty: 2-1731                     [128]                     --
│    └─BatchNorm2d: 2-1732               [16, 128, 32, 32]         --
│    └─Scaler: 2-1733                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1734                      [16, 128, 32, 32]         --
│    └─Empty: 2-1735                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1736                     [16, 128, 32, 32]         --
├─Dropout2d: 1-173                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1737                 [16, 128, 16, 16]         --
│    └─Empty: 2-1738                     [16, 128, 16, 16]         --
│    └─Empty: 2-1739                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1740        --                        --
│    └─One: 2-1741                       [1]                       --
│    └─OutputScale: 2-1742               --                        --
│    └─Empty: 2-1743                     [128, 128, 3, 3]          --
│    └─Empty: 2-1744                     [128, 128, 3, 3]          --
│    └─Empty: 2-1745                     [128]                     --
│    └─Empty: 2-1746                     [128]                     --
│    └─BatchNorm2d: 2-1747               [16, 128, 16, 16]         --
│    └─Scaler: 2-1748                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1749                      [16, 128, 16, 16]         --
│    └─Empty: 2-1750                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1751                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-175               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1752        --                        --
│    └─One: 2-1753                       [1]                       --
│    └─OutputScale: 2-1754               --                        --
│    └─Empty: 2-1755                     [128, 128, 1, 1]          --
│    └─Empty: 2-1756                     [128, 128, 1, 1]          --
│    └─Empty: 2-1757                     [128]                     --
│    └─Empty: 2-1758                     [128]                     --
│    └─BatchNorm2d: 2-1759               [16, 128, 16, 16]         --
│    └─Scaler: 2-1760                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1761                      [16, 128, 16, 16]         --
│    └─Empty: 2-1762                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1763                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1764                 [16, 128, 16, 16]         --
│    └─Empty: 2-1765                     [16, 128, 16, 16]         --
│    └─Empty: 2-1766                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1767        --                        --
│    └─One: 2-1768                       [1]                       --
│    └─OutputScale: 2-1769               --                        --
│    └─Empty: 2-1770                     [128, 128, 3, 3]          --
│    └─Empty: 2-1771                     [128, 128, 3, 3]          --
│    └─Empty: 2-1772                     [128]                     --
│    └─Empty: 2-1773                     [128]                     --
│    └─BatchNorm2d: 2-1774               [16, 128, 16, 16]         --
│    └─Scaler: 2-1775                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1776                      [16, 128, 16, 16]         --
│    └─Empty: 2-1777                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1778                     [16, 128, 16, 16]         --
├─Dropout2d: 1-177                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-178        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1779                 [16, 128, 8, 8]           --
│    └─Empty: 2-1780                     [16, 128, 8, 8]           --
│    └─Empty: 2-1781                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1782        --                        --
│    └─One: 2-1783                       [1]                       --
│    └─OutputScale: 2-1784               --                        --
│    └─Empty: 2-1785                     [128, 128, 3, 3]          --
│    └─Empty: 2-1786                     [128, 128, 3, 3]          --
│    └─Empty: 2-1787                     [128]                     --
│    └─Empty: 2-1788                     [128]                     --
│    └─BatchNorm2d: 2-1789               [16, 128, 8, 8]           --
│    └─Scaler: 2-1790                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1791                      [16, 128, 8, 8]           --
│    └─Empty: 2-1792                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1793                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-179               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1794        --                        --
│    └─One: 2-1795                       [1]                       --
│    └─OutputScale: 2-1796               --                        --
│    └─Empty: 2-1797                     [16, 128, 1, 1]           --
│    └─Empty: 2-1798                     [16, 128, 1, 1]           --
│    └─Empty: 2-1799                     [16]                      --
│    └─Empty: 2-1800                     [16]                      --
│    └─BatchNorm2d: 2-1801               [16, 16, 8, 8]            --
│    └─Scaler: 2-1802                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1803                      [16, 16, 8, 8]            --
│    └─Empty: 2-1804                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1805                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1806                 [16, 128, 8, 8]           --
│    └─Empty: 2-1807                     [16, 128, 8, 8]           --
│    └─Empty: 2-1808                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1809        --                        --
│    └─One: 2-1810                       [1]                       --
│    └─OutputScale: 2-1811               --                        --
│    └─Empty: 2-1812                     [16, 128, 3, 3]           --
│    └─Empty: 2-1813                     [16, 128, 3, 3]           --
│    └─Empty: 2-1814                     [16]                      --
│    └─Empty: 2-1815                     [16]                      --
│    └─BatchNorm2d: 2-1816               [16, 16, 8, 8]            --
│    └─Scaler: 2-1817                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1818                      [16, 16, 8, 8]            --
│    └─Empty: 2-1819                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1820                     [16, 16, 8, 8]            --
├─Dropout2d: 1-181                       [16, 16, 8, 8]            --
├─Conv1d: 1-182                          [16, 5, 16]               25,611
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [5, 1024, 5]              --
│    └─Empty: 2-1825                     [5, 1024, 5]              --
│    └─Empty: 2-1826                     [5]                       --
│    └─Empty: 2-1827                     [5]                       --
│    └─Scaler: 2-1828                    [16, 5, 16]               --
│    └─Empty: 2-1829                     [16, 5, 16]               --
│    └─Empty: 2-1830                     [16, 5, 16]               --
│    └─Clamp: 2-1831                     [16, 5, 16]               --
==========================================================================================
Total params: 659,291
Trainable params: 659,237
Non-trainable params: 54
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 2.53
Estimated Total Size (MB): 203.86
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.340 | Acc: 46.625% | Wgt Acc: 60.036%
	I - Batch: 100 | Loss: 1.200 | Acc: 53.062% | Wgt Acc: 68.629%
	I - Batch: 150 | Loss: 1.100 | Acc: 58.375% | Wgt Acc: 74.212%
	I - Batch: 200 | Loss: 1.036 | Acc: 61.312% | Wgt Acc: 77.513%
I - num batch: 222
I - Train -- Loss: 1.017 | Acc: 62.024% | Wgt Acc: 78.416% | LR: 1.000000e-04 | Dur: 133.21s
I - Confusion Matrix: [row->prediction - col->label]
[[632.   5.  18. 100. 254.]
 [ 26. 491.  34.  27. 213.]
 [ 18.  75. 665.  37. 421.]
 [ 21.   6.  17. 374.  74.]
 [  0.   1.   0.   0.  38.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.170 | Acc: 56.607% | Wgt Acc: 63.395% | Dur: 13.89s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  4.  4. 23. 24.]
 [ 0. 46.  8.  1. 16.]
 [ 5. 22. 54.  7. 68.]
 [ 6.  2.  6. 46.  3.]
 [ 5.  4.  3.  9. 69.]]

I - Local maximum validation set accuracy:  56.61

I - Validation set results: 
[14-1-2-0.50][50-3-4--0.11][124-2-2-0.41][127-0-0-0.99][443-2-2-0.82][567-0-0-0.87][573-1-1-0.88][615-0-0-0.69][695-1-2-0.71][722-3-0-0.94]
[826-0-0-0.88][878-0-0-0.95][1103-0-0-0.50][1212-3-3-0.03][1368-0-0-0.99][2181-2-3-0.19][2476-2-2-0.56][2721-2-2-0.94][2818-1-1-0.22][2886-2-2-0.49]
[3231-2-2-0.99][3333-2-2-0.44][3482-2-2-0.49][3536-3-0-0.29][3625-1-1-0.49][3909-0-0-0.58][4035-0-0-0.90][4140-0-0-0.93][4214-1-3-0.05][4346-1-0-0.14]
[4581-2-1-0.58][4708-3-2-0.42][4838-3-0--0.05][4845-1-2-0.16][4868-0-0-0.95][4939-0-4-0.35][4984-2-2-0.64][5078-1-2-0.19][5396-0-0-0.99][5479-1-1-0.90]
[5717-0-0-0.78][5843-1-2-0.14][5949-3-0-0.64][5987-2-4-0.38][6014-3-1-0.24][6033-3-0--0.06][6313-0-3-0.46][6421-3-3-0.69][6500-1-1-0.35][6583-3-3-0.33]
[6683-3-3-0.48][6825-2-1-0.72][6998-3-0-0.25][7049-3-3-0.39][7517-1-1-0.88][7521-1-1-0.70][7528-1-2-0.36][7949-1-2-0.96][8135-1-1--0.14][8185-3-0-0.95]
[8269-3-2-0.11][8273-3-3-0.95][8543-3-0-0.98][8666-1-1-0.85][8672-0-0-0.83][8903-1-2-0.41][9001-2-2-0.81][9036-2-2-0.98][9281-3-4--0.06][9300-2-2-0.99]
[9571-0-0-0.07][9617-1-4-0.16][9644-2-2-0.83][9705-2-4-0.02][9801-0-0-0.30][9803-3-3-0.08][9865-3-3-0.99][9896-2-2-0.80][10314-1-2-0.49][10337-3-3-0.70]
[10403-0-0--0.01][10653-2-1-0.15][10704-2-2-0.66][10719-1-1-0.97][10727-1-1-0.44][10836-0-0-0.99][10969-2-3-0.17][11042-0-0-0.91][11088-1-1-0.96][11322-0-0-0.96]
[11398-2-2-0.72][11499-0-0-0.76][11502-3-3-0.31][11512-3-3-0.24][11608-1-2-0.61][11610-0-0-0.45][11692-0-0-0.75][11905-0-0-0.97][11993-1-1-0.97][12002-2-0-0.56]
[12052-0-0-0.94][12201-0-0-0.85][12235-2-2-0.99][12320-1-0-0.39][12377-2-4-0.44][12398-2-3-0.16][12503-1-2-0.47][12617-0-2-0.06][12685-3-3--0.05][12738-2-2--0.01]
[12742-2-2-0.99][12823-0-0-0.80][13110-1-2-0.59][13240-3-0-0.61][13253-1-1-0.67][13273-0-0-0.99][13634-1-4-0.07][13763-2-2-0.81][13905-3-3--0.05][14060-2-2-0.30]
[14065-3-0-0.87][14147-3-3-0.35][14595-2-2-0.63][14687-2-2-0.99][14788-2-2-0.83][14869-1-1-0.88][14872-3-4-0.10][14877-1-1-0.85][14927-0-3-0.56][15066-0-0-0.98]
[15175-1-1-0.69][15178-2-3-0.01][15375-3-0-0.64][15389-3-3-0.89][15568-2-1-0.45][15675-3-3-0.97][15869-1-0--0.03][16207-3-0-0.44][16236-0-0-0.26][16302-3-3-0.46]
[16331-2-2-0.99][16381-0-0-0.23][16488-1-1-0.99][16495-0-0-0.98][16650-0-0-0.99][16719-1-2-0.41][16801-0-0-0.99][16828-0-0-0.87][17137-3-0-0.38][17245-1-2-0.29]
[17278-3-4-0.16][17282-0-2-0.14][17311-2-2-0.87][17336-2-1-0.92][17608-3-3-0.88][17627-0-0-0.86][17877-3-4-0.16][17924-1-2-0.37][17984-3-0-0.67][18211-0-0-0.62]
[18276-3-3-0.54][18287-1-1--0.12][18394-0-0-0.92][18428-0-0-0.98][18442-0-3-0.75][18478-3-3-0.51][18607-0-0-0.75][18616-0-0-0.51][18663-0-0-0.95][18718-0-0-0.99]
[18766-2-2-0.98][18824-2-2-0.75][18890-3-2-0.08][18930-3-4-0.25][18938-3-3-0.42][19817-1-1-0.63][19839-0-4--0.03][19930-3-3-0.92][19944-0-2-0.46][20036-2-2-0.99]
[20101-3-3--0.16][20474-1-2-0.34][20547-3-0-0.53][20929-2-2-0.97][21245-1-2-0.58][21257-3-2--0.05][21293-1-1-0.98][21316-1-1-0.98][21384-1-1-0.97][21448-1-1-0.89]
[21483-0-0-0.98][21487-2-2-0.96][21714-0-0-0.48][21943-3-4--0.05][21947-0-0-0.66][21948-0-0-0.99][21965-2-2-0.97][21998-1-1-0.81][22025-0-2-0.16][22228-3-3-0.89]
[22446-1-1-0.50][22494-3-0-0.69][22757-0-0-0.97][22811-3-3-0.98][22976-3-2-0.66][22985-3-3-0.71][23014-0-0-0.93][23112-1-1-0.96][23144-3-3-0.97][23168-2-3-0.05]
[23219-0-0-0.68][23363-3-3-0.66][23470-0-0--0.10][23486-2-2-0.46][23497-0-3-0.74][23516-0-0-0.99][23690-1-2-0.26][23921-2-2-0.56][23936-1-2-0.49][24040-3-2-0.04]
[24111-1-4-0.62][24182-0-0-0.97][24238-3-3-0.75][24290-2-0-0.77][24345-0-0-0.30][24364-1-1-0.14][24427-3-0-0.92][24477-2-2-0.95][24495-2-1-0.55][24893-2-2-0.64]
[25012-1-2-0.03][25121-2-2-0.98][25165-3-3-0.35][25183-0-0-0.93][25297-3-3-0.94][25398-0-0-0.82][25574-2-2-0.97][25644-1-1-0.92][25718-1-1--0.15][25774-2-2-0.33]
[26032-3-3-0.95][26051-3-3-0.96][26120-0-0-0.59][26321-1-1-0.43][26732-1-1-0.69][26784-3-3-0.99][26827-3-3-0.63][26833-0-3-0.93][26838-2-2-0.10][26860-1-2-0.54]
[26948-0-0-0.82][27049-3-0-0.98][27098-1-1-0.09][27526-0-0-0.95][27639-3-3-0.20][27698-3-0-0.44][27772-0-0-0.97][27890-1-1-0.67][28040-0-0-0.35][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.06][29777-0-0-0.99][29877-2-2-0.24][30035-1-1-0.96][30098-0-0-0.53][30326-1-1-0.99][30572-2-2-0.97][30716-0-4-0.28]
[30806-2-2-0.57][30906-1-1-0.99][31007-0-4-0.37][31181-3-0--0.18][31238-0-3-0.47][31347-0-0-0.95][31422-2-2-0.47][31429-3-3-0.24][31431-0-2--0.12][31432-1-1-0.85]
[31477-0-0-0.91][31524-1-1-0.36][31597-1-1-0.62][31619-1-0-0.02][31701-0-0-0.97][31755-0-0-0.97][31854-3-3-0.25][32074-1-1-0.51][32078-3-3-0.62][32111-1-1-0.91]
[32127-1-1-0.85][32140-3-3-0.75][32263-2-0-0.12][32365-0-0-0.92][32411-2-3-0.84][32429-3-3-0.59][32473-3-0-0.85][32574-3-3-0.45][32584-0-4-0.10][32622-0-0-0.03]
[32858-3-3-0.63][32969-3-0-0.88][33016-2-2-0.98][33031-1-3-0.71][33035-2-1-0.34][33133-2-2-0.78][33173-2-2-0.78][33175-3-4-0.21][33306-3-3-0.23][33309-2-2-0.32]
[33474-0-0-0.15][33478-2-0--0.04][33618-1-4-0.05][33712-0-0-0.62][33782-2-1-0.34][33914-3-3-0.91][34076-3-2-0.11][34112-2-2-0.69][34138-2-2-0.40][34239-1-1-0.30]
[34364-2-2-0.99][34617-1-2-0.36][34751-3-3-0.77][34783-2-2-0.40][35015-3-0-0.04][35018-1-1-0.55][35288-2-2-0.31][0-4-2-0.63][1-4-4-0.52][2-4-0-0.64]
[3-4-1-0.47][4-4-4-0.04][5-4-1-0.04][6-4-4-0.47][7-4-2-0.50][8-4-2-0.53][9-4-2-0.35][10-4-4-0.76][11-4-2-0.51][12-4-2-0.14]
[14-4-0--0.06][15-4-3-0.83][16-4-4-0.22][17-4-0--0.01][18-4-4-0.77][19-4-0-0.70][20-4-0-0.36][21-4-2-0.41][22-4-4-0.74][23-4-2-0.20]
[24-4-4-0.95][25-4-4--0.04][26-4-4--0.15][27-4-2-0.51][28-4-4-0.84][29-4-1-0.37][30-4-0-0.14][31-4-4-0.32][32-4-2-0.51][33-4-2-0.39]
[34-4-4--0.11][35-4-0-0.77][37-4-2-0.08][39-4-0-0.73][40-4-4-0.04][41-4-1-0.07][42-4-2-0.33][43-4-2-0.14][45-4-2-0.51][46-4-4-0.81]
[47-4-2-0.54][48-4-1-0.28][51-4-4-0.52][52-4-4-0.18][53-4-0-0.00][54-4-4-0.13][55-4-2-0.58][56-4-1-0.52][57-4-0-0.44][58-4-2-0.98]
[59-4-0-0.39][60-4-0-0.02][61-4-4-0.54][62-4-2-0.24][63-4-2-0.92][64-4-2-0.21][65-4-4-0.66][66-4-4-0.73][67-4-2-0.37][68-4-1--0.01]
[69-4-2--0.00][70-4-4-0.43][72-4-4-0.63][73-4-1-0.58][74-4-2-0.48][75-4-3-0.03][77-4-4-0.94][78-4-3--0.20][79-4-2-0.49][80-4-4-0.91]
[81-4-4-0.91][82-4-1-0.21][83-4-1-0.05][84-4-0-0.39][85-4-4-0.58][86-4-2-0.31][87-4-4-0.32][88-4-0-0.21][89-4-2-0.10][90-4-0-0.23]
[91-4-4-0.17][92-4-2-0.31][93-4-0--0.15][94-4-4-0.43][95-4-2-0.20][96-4-2-0.26][97-4-4-0.52][98-4-2-0.94][99-4-4-0.36][100-4-2-0.35]
[101-4-4-0.89][102-4-2-0.36][103-4-2-0.12][104-4-4-0.65][105-4-4-0.86][106-4-1-0.57][107-4-4-0.47][108-4-4-0.06][109-4-2-0.23][110-4-2-0.35]
[111-4-0-0.74][112-4-2-0.06][113-4-2-0.24][114-4-2-0.02][115-4-4-0.01][116-4-0-0.23][117-4-2-0.62][119-4-2-0.61][121-4-2-0.25][122-4-4-0.07]
[124-4-2--0.04][125-4-4-0.63][126-4-4-0.91][127-4-2-0.94][128-4-2--0.04][129-4-2-0.32][130-4-2-0.72][131-4-2-0.57][132-4-4-0.29][133-4-4-0.61]
[135-4-2-0.18][136-4-4--0.03][137-4-1-0.03][138-4-2-0.29][139-4-4-0.30][140-4-1-0.83][141-4-2-0.54][142-4-4-0.41][143-4-4-0.85][144-4-4-0.64]
[145-4-2-0.95][148-4-0-0.99][149-4-4-0.02][150-4-2-0.84][151-4-4-0.60][152-4-4-0.14][153-4-2-0.84][154-4-4-0.96][155-4-4-0.30][156-4-4--0.15]
[157-4-1-0.02][158-4-4-0.01][160-4-1-0.33][161-4-2-0.32][162-4-2--0.02][164-4-2-0.73][165-4-4-0.37][167-4-0-0.93][168-4-0-0.15][170-4-4-0.04]
[171-4-4-0.42][172-4-4-0.50][173-4-4-0.34][174-4-0-0.92][175-4-4-0.16][177-4-0-0.45][178-4-2-0.52][179-4-4-0.21][180-4-4-0.55][181-4-2-0.38]
[182-4-4-0.24][183-4-4-0.32][184-4-2-0.36][186-4-0-0.11][187-4-2-0.32][188-4-2-0.81][189-4-2-0.28][190-4-1--0.13][191-4-4-0.35][192-4-4-0.28]
[193-4-2-0.78][194-4-2-0.58][195-4-2-0.39][196-4-2-0.02][197-4-4-0.42][198-4-4-0.97][199-4-2-0.89]
---------------------------
I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 0.765 | Acc: 77.000% | Wgt Acc: 91.727%
	I - Batch: 100 | Loss: 0.751 | Acc: 77.938% | Wgt Acc: 91.916%
	I - Batch: 150 | Loss: 0.739 | Acc: 78.292% | Wgt Acc: 91.958%
	I - Batch: 200 | Loss: 0.725 | Acc: 79.969% | Wgt Acc: 92.660%
I - num batch: 222
I - Train -- Loss: 0.720 | Acc: 80.321% | Wgt Acc: 92.844% | LR: 1.000000e-04 | Dur: 133.86s
I - Confusion Matrix: [row->prediction - col->label]
[[676.   3.   2.  16. 204.]
 [  4. 568.   2.   4. 110.]
 [  6.   5. 729.   5. 235.]
 [ 10.   2.   1. 512.  87.]
 [  1.   0.   0.   1. 364.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.065 | Acc: 66.075% | Wgt Acc: 66.278% | Dur: 15.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   4.  12.  28.]
 [  0.  40.   3.   1.   4.]
 [  0.  11.  44.   1.  17.]
 [ 11.   9.  14.  63.  13.]
 [  7.  15.  10.   9. 118.]]

I - Local maximum validation set accuracy:  66.07

I - Validation set results: 
[14-1-2-0.38][50-3-3-0.10][124-2-2-0.25][127-0-0-0.99][443-2-2-0.94][567-0-0-0.93][573-1-1-0.86][615-0-3-0.67][695-1-2-0.85][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.94][1103-0-0-0.49][1212-3-3-0.19][1368-0-0-0.99][2181-2-3-0.67][2476-2-2-0.66][2721-2-2-0.52][2818-1-1-0.47][2886-2-4-0.54]
[3231-2-2-0.99][3333-2-3--0.05][3482-2-2-0.78][3536-3-3-0.02][3625-1-1-0.42][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.90][4214-1-3-0.37][4346-1-3-0.40]
[4581-2-1-0.33][4708-3-4-0.66][4838-3-3-0.01][4845-1-4--0.04][4868-0-0-0.99][4939-0-4-0.08][4984-2-2-0.72][5078-1-4-0.27][5396-0-0-0.99][5479-1-1-0.67]
[5717-0-0-0.96][5843-1-1-0.13][5949-3-3-0.53][5987-2-4-0.91][6014-3-3-0.95][6033-3-3-0.21][6313-0-3-0.72][6421-3-3-0.84][6500-1-1-0.62][6583-3-3-0.86]
[6683-3-3-0.82][6825-2-1-0.51][6998-3-3--0.08][7049-3-3-0.41][7517-1-1-0.15][7521-1-1--0.03][7528-1-3-0.09][7949-1-2-0.83][8135-1-3-0.45][8185-3-0-0.99]
[8269-3-1-0.23][8273-3-3-0.99][8543-3-0-0.98][8666-1-1-0.96][8672-0-0-0.75][8903-1-2-0.28][9001-2-2-0.40][9036-2-2-0.95][9281-3-3-0.31][9300-2-2-0.99]
[9571-0-3-0.51][9617-1-1-0.56][9644-2-2-0.81][9705-2-4-0.00][9801-0-3-0.92][9803-3-3-0.52][9865-3-3-0.99][9896-2-2-0.43][10314-1-4-0.34][10337-3-3-0.98]
[10403-0-0-0.37][10653-2-1-0.09][10704-2-2-0.19][10719-1-1-0.99][10727-1-4-0.52][10836-0-0-0.99][10969-2-3-0.98][11042-0-0-0.95][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.34][11499-0-0-0.99][11502-3-3-0.29][11512-3-3-0.85][11608-1-2-0.17][11610-0-0-0.91][11692-0-0-0.96][11905-0-0-0.96][11993-1-1-0.95][12002-2-3-0.16]
[12052-0-0-0.93][12201-0-0-0.88][12235-2-2-0.22][12320-1-0-0.67][12377-2-4-0.56][12398-2-3-0.71][12503-1-4-0.73][12617-0-3-0.20][12685-3-3-0.38][12738-2-0-0.67]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2--0.02][13240-3-0-0.97][13253-1-1-0.51][13273-0-0-0.99][13634-1-4--0.02][13763-2-3-0.56][13905-3-0--0.13][14060-2-2-0.13]
[14065-3-0-0.66][14147-3-3-0.75][14595-2-2-0.67][14687-2-2-0.99][14788-2-2-0.53][14869-1-1-0.90][14872-3-4-0.28][14877-1-1-0.97][14927-0-0-0.68][15066-0-0-0.97]
[15175-1-1-0.76][15178-2-3-0.36][15375-3-0-0.41][15389-3-3-0.96][15568-2-4-0.30][15675-3-3-0.99][15869-1-0-0.40][16207-3-0-0.26][16236-0-0-0.22][16302-3-3-0.96]
[16331-2-2-0.99][16381-0-3-0.64][16488-1-1-0.91][16495-0-0-0.99][16650-0-0-0.99][16719-1-4--0.01][16801-0-0-0.99][16828-0-0-0.89][17137-3-0-0.59][17245-1-2-0.13]
[17278-3-0--0.01][17282-0-0-0.66][17311-2-2-0.64][17336-2-3-0.06][17608-3-3-0.99][17627-0-0-0.79][17877-3-4-0.93][17924-1-2--0.06][17984-3-3-0.98][18211-0-3-0.70]
[18276-3-3-0.92][18287-1-1-0.65][18394-0-0-0.99][18428-0-0-0.99][18442-0-3-0.98][18478-3-3-0.84][18607-0-0-0.99][18616-0-0-0.93][18663-0-0-0.94][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.46][18890-3-3-0.76][18930-3-4-0.61][18938-3-3-0.49][19817-1-2-0.25][19839-0-0-0.61][19930-3-3-0.98][19944-0-0-0.63][20036-2-2-0.99]
[20101-3-3-0.92][20474-1-1-0.60][20547-3-3-0.47][20929-2-2-0.99][21245-1-2--0.04][21257-3-3-0.89][21293-1-1-0.50][21316-1-1-0.56][21384-1-1-0.64][21448-1-1-0.94]
[21483-0-0-0.99][21487-2-2-0.69][21714-0-0-0.43][21943-3-4-0.06][21947-0-0-0.77][21948-0-0-0.99][21965-2-2-0.94][21998-1-1-0.87][22025-0-4-0.87][22228-3-3-0.99]
[22446-1-1-0.95][22494-3-3-0.96][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.55][22985-3-3-0.97][23014-0-0-0.82][23112-1-1-0.92][23144-3-3-0.99][23168-2-3-0.38]
[23219-0-0-0.92][23363-3-3-0.99][23470-0-0-0.53][23486-2-2-0.03][23497-0-3-0.99][23516-0-0-0.97][23690-1-3-0.64][23921-2-2-0.15][23936-1-2-0.75][24040-3-0-0.70]
[24111-1-4-0.89][24182-0-0-0.99][24238-3-3-0.97][24290-2-0-0.69][24345-0-0-0.96][24364-1-3-0.24][24427-3-0-0.92][24477-2-2-0.74][24495-2-4-0.55][24893-2-4--0.04]
[25012-1-3--0.09][25121-2-2-0.94][25165-3-3-0.99][25183-0-0-0.98][25297-3-3-0.99][25398-0-0-0.75][25574-2-2-0.81][25644-1-1-0.82][25718-1-4--0.23][25774-2-2--0.17]
[26032-3-3-0.98][26051-3-3-0.99][26120-0-4-0.39][26321-1-1-0.61][26732-1-1-0.61][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.94][26838-2-3-0.09][26860-1-4-0.31]
[26948-0-0-0.95][27049-3-0-0.99][27098-1-0-0.65][27526-0-0-0.83][27639-3-3-0.79][27698-3-3-0.66][27772-0-0-0.99][27890-1-1-0.75][28040-0-4-0.85][28503-2-2-0.97]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.49][29777-0-0-0.99][29877-2-2-0.18][30035-1-1-0.99][30098-0-0-0.83][30326-1-1-0.98][30572-2-2-0.91][30716-0-4-0.73]
[30806-2-3-0.86][30906-1-1-0.99][31007-0-0-0.71][31181-3-3-0.48][31238-0-3-0.81][31347-0-0-0.99][31422-2-2-0.53][31429-3-3-0.33][31431-0-0-0.29][31432-1-1-0.96]
[31477-0-0-0.89][31524-1-3--0.26][31597-1-1-0.72][31619-1-4-0.37][31701-0-0-0.96][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.06][32078-3-3-0.99][32111-1-1-0.70]
[32127-1-4-0.64][32140-3-3-0.98][32263-2-0-0.10][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.94][32473-3-3-0.85][32574-3-3-0.62][32584-0-4-0.61][32622-0-4-0.39]
[32858-3-3-0.66][32969-3-3-0.88][33016-2-2-0.93][33031-1-3-0.97][33035-2-2-0.85][33133-2-2-0.45][33173-2-3--0.07][33175-3-4-0.61][33306-3-3-0.97][33309-2-2-0.30]
[33474-0-0-0.21][33478-2-0--0.22][33618-1-4-0.47][33712-0-0-0.77][33782-2-4-0.68][33914-3-3-0.99][34076-3-4-0.43][34112-2-2-0.86][34138-2-3-0.93][34239-1-1-0.24]
[34364-2-2-0.95][34617-1-4-0.73][34751-3-3-0.95][34783-2-2-0.42][35015-3-2-0.51][35018-1-4-0.44][35288-2-2-0.66][0-4-4-0.39][1-4-4-0.99][2-4-0-0.82]
[3-4-4-0.65][4-4-0-0.29][5-4-1-0.32][6-4-4-0.98][7-4-0-0.57][8-4-4-0.01][9-4-0-0.39][10-4-4-0.99][11-4-4-0.99][12-4-4-0.27]
[14-4-3-0.22][15-4-3-0.96][16-4-4-0.57][17-4-4-0.22][18-4-4-0.83][19-4-0-0.72][20-4-0-0.82][21-4-2-0.51][22-4-4-0.97][23-4-4-0.57]
[24-4-4-0.99][25-4-4-0.74][26-4-3-0.36][27-4-4-0.32][28-4-4-0.77][29-4-1-0.11][30-4-3-0.02][31-4-4-0.85][32-4-2-0.67][33-4-4-0.14]
[34-4-4-0.53][35-4-0-0.86][37-4-4-0.44][39-4-0-0.89][40-4-0-0.45][41-4-4--0.06][42-4-4-0.41][43-4-4-0.64][45-4-2-0.37][46-4-4-0.99]
[47-4-4-0.97][48-4-4-0.10][51-4-4-0.97][52-4-4-0.84][53-4-0-0.17][54-4-4-0.48][55-4-3-0.18][56-4-1-0.06][57-4-3-0.78][58-4-2-0.51]
[59-4-0-0.81][60-4-4-0.95][61-4-4-0.74][62-4-4-0.37][63-4-2-0.67][64-4-2-0.16][65-4-4-0.97][66-4-4-0.98][67-4-0-0.10][68-4-3-0.32]
[69-4-4-0.09][70-4-4-0.87][72-4-4-0.64][73-4-4-0.15][74-4-2-0.55][75-4-3-0.21][77-4-4-0.99][78-4-4-0.35][79-4-4-0.84][80-4-4-0.48]
[81-4-2-0.35][82-4-4-0.33][83-4-4-0.13][84-4-4-0.99][85-4-4-0.99][86-4-4-0.28][87-4-4-0.68][88-4-4-0.59][89-4-2-0.51][90-4-4-0.20]
[91-4-4-0.56][92-4-4-0.38][93-4-0-0.69][94-4-4-0.94][95-4-4-0.18][96-4-4-0.49][97-4-4-0.99][98-4-2-0.97][99-4-4-0.55][100-4-4-0.43]
[101-4-4-0.99][102-4-4-0.90][103-4-0-0.17][104-4-4-0.92][105-4-4-0.99][106-4-4-0.95][107-4-4-0.57][108-4-4-0.53][109-4-4-0.91][110-4-4-0.82]
[111-4-0-0.90][112-4-3-0.04][113-4-4-0.46][114-4-3--0.03][115-4-0-0.28][116-4-0-0.47][117-4-4-0.76][119-4-4-0.86][121-4-4-0.79][122-4-4-0.64]
[124-4-4-0.45][125-4-4-0.97][126-4-4-0.99][127-4-2-0.88][128-4-0-0.07][129-4-4-0.46][130-4-4-0.89][131-4-2-0.28][132-4-0-0.32][133-4-4-0.99]
[135-4-4-0.56][136-4-4-0.15][137-4-4-0.19][138-4-4-0.62][139-4-4-0.95][140-4-1-0.73][141-4-0-0.68][142-4-4-0.97][143-4-4-0.93][144-4-4-0.99]
[145-4-4-0.80][148-4-0-0.99][149-4-4-0.81][150-4-4-0.99][151-4-4-0.95][152-4-4-0.92][153-4-4-0.73][154-4-4-0.99][155-4-4-0.88][156-4-3-0.74]
[157-4-0--0.06][158-4-4-0.53][160-4-0-0.02][161-4-2-0.03][162-4-4-0.09][164-4-2-0.43][165-4-4-0.47][167-4-0-0.97][168-4-0-0.41][170-4-4-0.60]
[171-4-4-0.94][172-4-4-0.96][173-4-4-0.96][174-4-0-0.81][175-4-4-0.32][177-4-4-0.87][178-4-4-0.14][179-4-4-0.82][180-4-4-0.79][181-4-3-0.77]
[182-4-4-0.89][183-4-4-0.86][184-4-4-0.82][186-4-0-0.05][187-4-4-0.05][188-4-4-0.94][189-4-4-0.28][190-4-3--0.03][191-4-4-0.99][192-4-4-0.86]
[193-4-2-0.17][194-4-2-0.35][195-4-0-0.66][196-4-4-0.07][197-4-4-0.89][198-4-4-0.99][199-4-2-0.40]
---------------------------
I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.645 | Acc: 85.375% | Wgt Acc: 95.187%
	I - Batch: 100 | Loss: 0.653 | Acc: 85.562% | Wgt Acc: 95.106%
	I - Batch: 150 | Loss: 0.647 | Acc: 86.250% | Wgt Acc: 95.337%
	I - Batch: 200 | Loss: 0.643 | Acc: 86.438% | Wgt Acc: 95.223%
I - num batch: 222
I - Train -- Loss: 0.643 | Acc: 86.439% | Wgt Acc: 95.240% | LR: 1.000000e-04 | Dur: 134.16s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   1.   2.  11. 148.]
 [  2. 572.   1.   1.  71.]
 [  5.   4. 730.   1. 142.]
 [  5.   1.   0. 524.  83.]
 [  1.   0.   1.   1. 556.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.031 | Acc: 65.680% | Wgt Acc: 61.792% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   0.   1.   5.   7.]
 [  0.  39.   4.   2.   4.]
 [  3.  16.  48.   3.  28.]
 [ 14.   2.   7.  54.   5.]
 [ 15.  21.  15.  22. 136.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.612 | Acc: 88.375% | Wgt Acc: 96.329%
	I - Batch: 100 | Loss: 0.609 | Acc: 88.000% | Wgt Acc: 96.196%
	I - Batch: 150 | Loss: 0.610 | Acc: 88.208% | Wgt Acc: 96.317%
	I - Batch: 200 | Loss: 0.610 | Acc: 88.312% | Wgt Acc: 96.309%
I - num batch: 222
I - Train -- Loss: 0.609 | Acc: 88.497% | Wgt Acc: 96.379% | LR: 1.000000e-04 | Dur: 136.81s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   2.   5. 122.]
 [  0. 576.   0.   0.  77.]
 [  1.   0. 731.   0. 113.]
 [  1.   1.   0. 531.  79.]
 [  3.   1.   1.   2. 609.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.038 | Acc: 66.864% | Wgt Acc: 62.969% | Dur: 14.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   4.  18.  15.]
 [  2.  47.   9.   1.  12.]
 [  1.  11.  39.   1.  12.]
 [ 10.   3.   7.  50.   3.]
 [ 10.  15.  16.  16. 138.]]

I - Local maximum validation set accuracy:  66.86

I - Validation set results: 
[14-1-2-0.45][50-3-4-0.47][124-2-2--0.10][127-0-0-0.99][443-2-2-0.65][567-0-0-0.97][573-1-1-0.99][615-0-0-0.84][695-1-2-0.95][722-3-0-0.97]
[826-0-0-0.99][878-0-0-0.97][1103-0-0-0.85][1212-3-4-0.29][1368-0-0-0.99][2181-2-3--0.14][2476-2-2-0.35][2721-2-2-0.80][2818-1-1-0.73][2886-2-4-0.86]
[3231-2-2-0.99][3333-2-2-0.05][3482-2-2-0.71][3536-3-2-0.44][3625-1-1-0.65][3909-0-0-0.83][4035-0-0-0.95][4140-0-0-0.92][4214-1-4-0.24][4346-1-3-0.07]
[4581-2-1-0.98][4708-3-4-0.94][4838-3-3-0.13][4845-1-2-0.14][4868-0-0-0.99][4939-0-4-0.42][4984-2-3-0.39][5078-1-4-0.49][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.34][5843-1-1-0.60][5949-3-0-0.29][5987-2-4-0.94][6014-3-3-0.67][6033-3-3-0.16][6313-0-3-0.74][6421-3-3-0.64][6500-1-1-0.70][6583-3-3-0.35]
[6683-3-3-0.31][6825-2-0-0.38][6998-3-0-0.02][7049-3-3-0.72][7517-1-1-0.96][7521-1-1-0.99][7528-1-2--0.03][7949-1-2-0.97][8135-1-0--0.06][8185-3-0-0.99]
[8269-3-1-0.99][8273-3-3-0.87][8543-3-0-0.99][8666-1-1-0.98][8672-0-0-0.40][8903-1-1-0.71][9001-2-2-0.58][9036-2-2-0.99][9281-3-0-0.00][9300-2-2-0.99]
[9571-0-4-0.25][9617-1-4-0.82][9644-2-1-0.94][9705-2-1-0.34][9801-0-3-0.50][9803-3-3-0.28][9865-3-3-0.99][9896-2-4-0.67][10314-1-4-0.92][10337-3-3-0.99]
[10403-0-4-0.48][10653-2-4-0.59][10704-2-2-0.99][10719-1-1-0.93][10727-1-1-0.98][10836-0-0-0.99][10969-2-3-0.63][11042-0-0-0.96][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.13][11499-0-0-0.98][11502-3-3--0.22][11512-3-3-0.68][11608-1-1-0.80][11610-0-0-0.98][11692-0-0-0.98][11905-0-0-0.94][11993-1-1-0.93][12002-2-2--0.40]
[12052-0-0-0.92][12201-0-0-0.84][12235-2-4-0.71][12320-1-4-0.60][12377-2-4-0.97][12398-2-3-0.03][12503-1-4-0.43][12617-0-2--0.23][12685-3-4--0.04][12738-2-4--0.12]
[12742-2-2-0.99][12823-0-3-0.34][13110-1-2-0.43][13240-3-0-0.95][13253-1-1-0.82][13273-0-0-0.99][13634-1-4-0.12][13763-2-2-0.06][13905-3-3--0.28][14060-2-2-0.24]
[14065-3-0-0.64][14147-3-0-0.48][14595-2-2-0.68][14687-2-2-0.99][14788-2-2-0.80][14869-1-1-0.99][14872-3-4-0.87][14877-1-1-0.99][14927-0-3-0.57][15066-0-0-0.99]
[15175-1-1-0.91][15178-2-3-0.46][15375-3-0-0.34][15389-3-3-0.98][15568-2-1-0.77][15675-3-3-0.98][15869-1-0-0.08][16207-3-0-0.28][16236-0-0-0.35][16302-3-3-0.84]
[16331-2-2-0.99][16381-0-3-0.23][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.62][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.59][17245-1-4-0.90]
[17278-3-4-0.61][17282-0-0-0.48][17311-2-2-0.80][17336-2-1-0.54][17608-3-3-0.99][17627-0-0-0.63][17877-3-4-0.97][17924-1-2-0.52][17984-3-3-0.95][18211-0-3-0.49]
[18276-3-3-0.90][18287-1-1-0.81][18394-0-0-0.99][18428-0-1--0.41][18442-0-3-0.80][18478-3-3-0.47][18607-0-0-0.99][18616-0-0-0.88][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.80][18890-3-3-0.94][18930-3-4-0.67][18938-3-3-0.33][19817-1-1-0.90][19839-0-0-0.70][19930-3-3-0.77][19944-0-4-0.90][20036-2-2-0.99]
[20101-3-4-0.41][20474-1-1-0.88][20547-3-4-0.50][20929-2-2-0.99][21245-1-1-0.29][21257-3-3-0.11][21293-1-1-0.98][21316-1-1-0.99][21384-1-1-0.91][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.87][21714-0-0-0.66][21943-3-4-0.01][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.98][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.96][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.16][22985-3-0-0.81][23014-0-0-0.96][23112-1-1-0.99][23144-3-3-0.99][23168-2-0--0.12]
[23219-0-0-0.77][23363-3-3-0.99][23470-0-0-0.45][23486-2-4-0.24][23497-0-3-0.99][23516-0-0-0.99][23690-1-4-0.40][23921-2-1-0.21][23936-1-2-0.71][24040-3-0-0.52]
[24111-1-4-0.99][24182-0-0-0.96][24238-3-3-0.99][24290-2-0-0.98][24345-0-0-0.99][24364-1-2-0.17][24427-3-0-0.30][24477-2-2-0.79][24495-2-1-0.60][24893-2-2-0.22]
[25012-1-1--0.14][25121-2-2-0.99][25165-3-3-0.99][25183-0-0-0.89][25297-3-3-0.99][25398-0-0-0.88][25574-2-4-0.93][25644-1-1-0.84][25718-1-4-0.09][25774-2-2-0.39]
[26032-3-3-0.97][26051-3-3-0.99][26120-0-4-0.96][26321-1-1-0.92][26732-1-1-0.78][26784-3-3-0.99][26827-3-3-0.98][26833-0-3-0.97][26838-2-4-0.12][26860-1-4-0.51]
[26948-0-0-0.97][27049-3-0-0.98][27098-1-1-0.04][27526-0-0-0.89][27639-3-3-0.87][27698-3-0-0.55][27772-0-0-0.97][27890-1-1-0.99][28040-0-4-0.21][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.93][29777-0-0-0.99][29877-2-1--0.11][30035-1-1-0.99][30098-0-3-0.36][30326-1-1-0.99][30572-2-2-0.95][30716-0-4-0.98]
[30806-2-2-0.37][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.38][31238-0-0-0.37][31347-0-0-0.99][31422-2-2-0.51][31429-3-3-0.60][31431-0-0-0.90][31432-1-1-0.82]
[31477-0-0-0.76][31524-1-4-0.12][31597-1-1-0.74][31619-1-4-0.56][31701-0-4-0.30][31755-0-0-0.99][31854-3-3-0.66][32074-1-3-0.22][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-1-0.97][32140-3-3-0.96][32263-2-4-0.20][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.89][32473-3-0-0.65][32574-3-3-0.99][32584-0-4-0.85][32622-0-1-0.49]
[32858-3-0-0.59][32969-3-3-0.96][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.33][33133-2-2-0.85][33173-2-2-0.43][33175-3-4-0.98][33306-3-3-0.97][33309-2-2-0.47]
[33474-0-0--0.01][33478-2-0--0.03][33618-1-4-0.52][33712-0-0-0.76][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.72][34112-2-2-0.99][34138-2-3-0.28][34239-1-1-0.61]
[34364-2-2-0.99][34617-1-2-0.17][34751-3-3-0.88][34783-2-4-0.25][35015-3-4-0.37][35018-1-1-0.86][35288-2-1-0.19][0-4-4-0.91][1-4-4-0.99][2-4-4-0.86]
[3-4-4-0.91][4-4-0-0.39][5-4-1-0.90][6-4-4-0.99][7-4-0-0.85][8-4-4--0.08][9-4-0-0.54][10-4-4-0.99][11-4-4-0.99][12-4-4-0.47]
[14-4-4-0.53][15-4-3-0.37][16-4-4-0.56][17-4-4-0.44][18-4-4-0.98][19-4-0-0.78][20-4-4-0.43][21-4-4-0.91][22-4-4-0.99][23-4-4-0.60]
[24-4-4-0.99][25-4-4-0.91][26-4-4-0.04][27-4-4-0.97][28-4-4-0.99][29-4-1-0.47][30-4-4-0.46][31-4-4-0.79][32-4-4-0.94][33-4-4-0.68]
[34-4-4-0.85][35-4-4-0.89][37-4-4-0.92][39-4-0-0.98][40-4-4-0.35][41-4-1-0.13][42-4-4-0.01][43-4-4-0.98][45-4-1-0.40][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.45][51-4-4-0.99][52-4-4-0.50][53-4-0-0.16][54-4-4-0.92][55-4-4-0.97][56-4-1-0.95][57-4-3-0.54][58-4-2-0.80]
[59-4-0-0.96][60-4-4-0.34][61-4-4-0.99][62-4-4-0.92][63-4-2-0.95][64-4-4-0.56][65-4-4-0.99][66-4-4-0.73][67-4-4-0.33][68-4-4-0.31]
[69-4-4-0.09][70-4-4-0.88][72-4-1-0.97][73-4-1-0.95][74-4-2-0.66][75-4-2--0.17][77-4-4-0.99][78-4-4-0.19][79-4-4-0.99][80-4-4-0.93]
[81-4-4-0.98][82-4-1-0.48][83-4-4-0.56][84-4-4-0.99][85-4-4-0.98][86-4-4-0.14][87-4-4-0.98][88-4-4-0.97][89-4-2--0.11][90-4-4-0.40]
[91-4-4-0.83][92-4-4-0.41][93-4-4-0.53][94-4-4-0.99][95-4-4-0.59][96-4-4-0.95][97-4-4-0.95][98-4-2-0.36][99-4-4-0.62][100-4-1-0.72]
[101-4-4-0.99][102-4-4-0.95][103-4-4-0.24][104-4-4-0.99][105-4-4-0.30][106-4-4-0.99][107-4-4-0.95][108-4-1-0.82][109-4-4-0.74][110-4-4-0.97]
[111-4-0-0.97][112-4-2-0.38][113-4-4-0.11][114-4-4-0.42][115-4-4-0.55][116-4-4-0.80][117-4-4-0.99][119-4-4-0.96][121-4-4-0.95][122-4-4-0.96]
[124-4-4-0.47][125-4-4-0.99][126-4-4-0.99][127-4-2-0.83][128-4-0-0.52][129-4-4-0.90][130-4-4-0.15][131-4-4-0.82][132-4-4-0.30][133-4-4-0.99]
[135-4-4-0.76][136-4-1-0.50][137-4-4-0.46][138-4-4-0.88][139-4-4-0.96][140-4-1-0.73][141-4-0-0.61][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.76][150-4-4-0.99][151-4-4-0.99][152-4-4-0.95][153-4-4-0.86][154-4-4-0.99][155-4-4-0.99][156-4-4-0.41]
[157-4-0-0.58][158-4-4-0.94][160-4-4-0.69][161-4-2-0.11][162-4-4-0.28][164-4-4-0.96][165-4-4-0.96][167-4-0-0.95][168-4-4-0.88][170-4-4-0.95]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.97][175-4-4-0.98][177-4-4-0.99][178-4-4-0.45][179-4-4-0.83][180-4-4-0.99][181-4-4-0.83]
[182-4-4-0.97][183-4-4-0.99][184-4-4-0.92][186-4-4-0.15][187-4-2-0.11][188-4-4-0.99][189-4-4-0.40][190-4-4--0.00][191-4-4-0.96][192-4-4-0.95]
[193-4-2-0.95][194-4-3--0.01][195-4-0-0.88][196-4-4-0.54][197-4-4-0.90][198-4-4-0.99][199-4-2-0.91]
---------------------------
I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.580 | Acc: 90.625% | Wgt Acc: 97.177%
	I - Batch: 100 | Loss: 0.588 | Acc: 89.562% | Wgt Acc: 96.777%
	I - Batch: 150 | Loss: 0.589 | Acc: 89.083% | Wgt Acc: 96.577%
	I - Batch: 200 | Loss: 0.585 | Acc: 89.531% | Wgt Acc: 96.753%
I - num batch: 222
I - Train -- Loss: 0.584 | Acc: 89.569% | Wgt Acc: 96.805% | LR: 1.000000e-04 | Dur: 136.37s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   5. 139.]
 [  0. 578.   0.   1.  57.]
 [  0.   0. 734.   0.  98.]
 [  1.   0.   0. 529.  64.]
 [  2.   0.   0.   3. 642.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 66.667% | Wgt Acc: 60.189% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   3.  16.   7.]
 [  0.  37.   3.   0.   4.]
 [  1.  18.  42.   2.  16.]
 [  8.   3.   6.  45.   4.]
 [ 14.  17.  21.  23. 149.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.561 | Acc: 90.750% | Wgt Acc: 97.114%
	I - Batch: 100 | Loss: 0.561 | Acc: 90.625% | Wgt Acc: 97.112%
	I - Batch: 150 | Loss: 0.562 | Acc: 90.375% | Wgt Acc: 96.935%
	I - Batch: 200 | Loss: 0.565 | Acc: 90.281% | Wgt Acc: 96.868%
I - num batch: 222
I - Train -- Loss: 0.566 | Acc: 90.217% | Wgt Acc: 96.879% | LR: 1.000000e-04 | Dur: 135.11s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   1.   2.   4. 118.]
 [  0. 575.   0.   0.  59.]
 [  1.   1. 731.   1. 104.]
 [  2.   0.   0. 533.  50.]
 [  2.   1.   1.   0. 669.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.850% | Wgt Acc: 62.069% | Dur: 14.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   0.   9.   5.]
 [  0.  36.   2.   0.   3.]
 [  1.  12.  37.   0.  19.]
 [  9.   4.   8.  58.   4.]
 [ 14.  24.  28.  19. 149.]]

I - Local maximum validation set accuracy:  67.85

I - Validation set results: 
[14-1-2-0.19][50-3-4-0.88][124-2-2-0.63][127-0-0-0.99][443-2-2-0.80][567-0-0-0.61][573-1-1-0.65][615-0-0-0.65][695-1-2-0.98][722-3-3-0.87]
[826-0-0-0.91][878-0-0-0.99][1103-0-0-0.54][1212-3-3-0.66][1368-0-0-0.99][2181-2-3-0.16][2476-2-2-0.83][2721-2-2-0.99][2818-1-1-0.21][2886-2-4-0.97]
[3231-2-2-0.99][3333-2-4-0.38][3482-2-2-0.93][3536-3-4-0.33][3625-1-1-0.60][3909-0-0-0.88][4035-0-0-0.99][4140-0-0-0.67][4214-1-1-0.09][4346-1-0-0.15]
[4581-2-4-0.24][4708-3-4-0.98][4838-3-4-0.50][4845-1-4--0.07][4868-0-0-0.99][4939-0-4-0.49][4984-2-3-0.76][5078-1-4-0.49][5396-0-0-0.99][5479-1-1-0.97]
[5717-0-0-0.94][5843-1-1-0.37][5949-3-3-0.27][5987-2-4-0.97][6014-3-3-0.88][6033-3-3--0.10][6313-0-0-0.54][6421-3-3-0.72][6500-1-4--0.24][6583-3-3-0.92]
[6683-3-3-0.68][6825-2-1-0.94][6998-3-3--0.10][7049-3-3-0.93][7517-1-1-0.46][7521-1-1-0.98][7528-1-2-0.54][7949-1-2-0.99][8135-1-3-0.19][8185-3-0-0.96]
[8269-3-4-0.86][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.99][9001-2-4-0.70][9036-2-2-0.96][9281-3-3-0.42][9300-2-2-0.99]
[9571-0-4-0.66][9617-1-4-0.98][9644-2-2-0.99][9705-2-4-0.55][9801-0-3-0.68][9803-3-3-0.90][9865-3-3-0.99][9896-2-4-0.76][10314-1-4-0.82][10337-3-3-0.53]
[10403-0-4-0.79][10653-2-4-0.95][10704-2-2-0.97][10719-1-1-0.97][10727-1-4-0.97][10836-0-0-0.99][10969-2-3-0.50][11042-0-0-0.97][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.40][11499-0-0-0.92][11502-3-3--0.05][11512-3-3-0.78][11608-1-2-0.88][11610-0-0-0.95][11692-0-0-0.70][11905-0-0-0.77][11993-1-1-0.77][12002-2-2-0.09]
[12052-0-0-0.98][12201-0-3-0.59][12235-2-4-0.98][12320-1-0-0.96][12377-2-4-0.95][12398-2-3-0.41][12503-1-4-0.97][12617-0-3--0.40][12685-3-4-0.49][12738-2-4-0.38]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-4-0.30][13240-3-0-0.63][13253-1-4-0.68][13273-0-0-0.99][13634-1-4-0.61][13763-2-2-0.37][13905-3-3-0.17][14060-2-4-0.94]
[14065-3-0-0.54][14147-3-3-0.97][14595-2-2-0.99][14687-2-2-0.99][14788-2-2-0.92][14869-1-1-0.26][14872-3-4-0.92][14877-1-1-0.98][14927-0-3-0.55][15066-0-0-0.97]
[15175-1-4-0.97][15178-2-3-0.92][15375-3-3-0.49][15389-3-3-0.99][15568-2-4-0.78][15675-3-3-0.93][15869-1-4-0.13][16207-3-0-0.71][16236-0-0-0.97][16302-3-3-0.96]
[16331-2-2-0.99][16381-0-4-0.58][16488-1-1-0.98][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.60][16801-0-0-0.99][16828-0-0-0.98][17137-3-3-0.85][17245-1-4-0.76]
[17278-3-0--0.13][17282-0-0-0.82][17311-2-2-0.65][17336-2-1-0.44][17608-3-3-0.99][17627-0-4-0.26][17877-3-4-0.99][17924-1-2-0.83][17984-3-3-0.97][18211-0-3-0.46]
[18276-3-3-0.64][18287-1-4-0.24][18394-0-0-0.99][18428-0-0-0.98][18442-0-3-0.99][18478-3-3-0.64][18607-0-0-0.99][18616-0-0-0.79][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.96][18890-3-3-0.99][18930-3-4-0.88][18938-3-3-0.21][19817-1-2-0.45][19839-0-2-0.19][19930-3-3-0.86][19944-0-4-0.86][20036-2-2-0.99]
[20101-3-4-0.57][20474-1-1-0.34][20547-3-4-0.41][20929-2-2-0.99][21245-1-1--0.18][21257-3-3-0.91][21293-1-1-0.98][21316-1-1-0.99][21384-1-1-0.91][21448-1-1-0.96]
[21483-0-0-0.99][21487-2-2-0.65][21714-0-0-0.63][21943-3-4-0.52][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.43][21998-1-1-0.80][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.75][22985-3-3-0.52][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-3-0.09]
[23219-0-4-0.52][23363-3-3-0.84][23470-0-0-0.34][23486-2-4-0.52][23497-0-3-0.97][23516-0-0-0.99][23690-1-2-0.14][23921-2-4-0.68][23936-1-2-0.97][24040-3-4-0.19]
[24111-1-4-0.93][24182-0-0-0.93][24238-3-3-0.99][24290-2-4-0.93][24345-0-0-0.99][24364-1-3-0.07][24427-3-0-0.87][24477-2-2-0.97][24495-2-4-0.94][24893-2-4-0.40]
[25012-1-4--0.01][25121-2-2-0.98][25165-3-3-0.96][25183-0-0-0.37][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.98][25644-1-1-0.92][25718-1-4-0.39][25774-2-4-0.85]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.46][26321-1-1-0.99][26732-1-1-0.42][26784-3-3-0.99][26827-3-3-0.98][26833-0-3-0.99][26838-2-4-0.18][26860-1-2-0.81]
[26948-0-0-0.44][27049-3-0-0.99][27098-1-1--0.09][27526-0-0-0.66][27639-3-3-0.96][27698-3-0-0.87][27772-0-0-0.99][27890-1-1-0.59][28040-0-0-0.60][28503-2-2-0.99]
[28577-1-1-0.98][28959-0-0-0.99][29198-3-4-0.97][29777-0-0-0.99][29877-2-2-0.68][30035-1-1-0.99][30098-0-0-0.36][30326-1-1-0.99][30572-2-2-0.99][30716-0-4-0.99]
[30806-2-2-0.42][30906-1-1-0.99][31007-0-4-0.82][31181-3-4-0.45][31238-0-0-0.28][31347-0-0-0.94][31422-2-2-0.68][31429-3-3-0.37][31431-0-0-0.09][31432-1-1-0.54]
[31477-0-3-0.47][31524-1-4-0.42][31597-1-4-0.67][31619-1-4-0.66][31701-0-4-0.84][31755-0-0-0.99][31854-3-3-0.99][32074-1-3-0.12][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-4-0.62][32140-3-3-0.98][32263-2-4-0.14][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.76][32473-3-3-0.59][32574-3-3-0.86][32584-0-4-0.97][32622-0-4-0.92]
[32858-3-3-0.46][32969-3-3-0.97][33016-2-2-0.99][33031-1-3-0.97][33035-2-2-0.92][33133-2-2-0.99][33173-2-2-0.77][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.94]
[33474-0-0-0.50][33478-2-4-0.09][33618-1-4-0.92][33712-0-0-0.87][33782-2-4-0.97][33914-3-3-0.99][34076-3-4-0.98][34112-2-2-0.99][34138-2-2-0.27][34239-1-1-0.04]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-3-0.94][34783-2-4-0.94][35015-3-4-0.88][35018-1-4-0.53][35288-2-4--0.06][0-4-4-0.96][1-4-4-0.99][2-4-4-0.85]
[3-4-4-0.71][4-4-4-0.83][5-4-1-0.36][6-4-4-0.99][7-4-4-0.73][8-4-2-0.66][9-4-2-0.77][10-4-4-0.99][11-4-4-0.99][12-4-2-0.29]
[14-4-4-0.97][15-4-3-0.98][16-4-4-0.87][17-4-4-0.87][18-4-4-0.99][19-4-4-0.31][20-4-4-0.28][21-4-2-0.44][22-4-4-0.99][23-4-4-0.71]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.49][27-4-4-0.99][28-4-4-0.98][29-4-4-0.30][30-4-3-0.48][31-4-4-0.99][32-4-4-0.98][33-4-4-0.95]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.81][39-4-3-0.57][40-4-4-0.36][41-4-4-0.72][42-4-2-0.80][43-4-4-0.99][45-4-2-0.59][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.15][51-4-4-0.99][52-4-4-0.97][53-4-4-0.62][54-4-4-0.91][55-4-4-0.97][56-4-4-0.19][57-4-4-0.04][58-4-2-0.99]
[59-4-0-0.99][60-4-4-0.99][61-4-4-0.99][62-4-4-0.98][63-4-2-0.98][64-4-4-0.83][65-4-4-0.99][66-4-4-0.99][67-4-2-0.83][68-4-4-0.80]
[69-4-4-0.12][70-4-4-0.96][72-4-4-0.98][73-4-1-0.89][74-4-4-0.99][75-4-4--0.00][77-4-4-0.99][78-4-4-0.92][79-4-4-0.99][80-4-4-0.99]
[81-4-1-0.91][82-4-4-0.96][83-4-4-0.90][84-4-4-0.99][85-4-4-0.99][86-4-2-0.46][87-4-4-0.98][88-4-4-0.99][89-4-4-0.76][90-4-4-0.98]
[91-4-4-0.96][92-4-4-0.65][93-4-4-0.61][94-4-4-0.99][95-4-4-0.67][96-4-4-0.95][97-4-4-0.99][98-4-2-0.95][99-4-4-0.98][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.77][104-4-4-0.99][105-4-4-0.29][106-4-4-0.99][107-4-4-0.97][108-4-4-0.96][109-4-4-0.98][110-4-4-0.99]
[111-4-3-0.97][112-4-4-0.65][113-4-2-0.01][114-4-4-0.42][115-4-4-0.75][116-4-4-0.94][117-4-4-0.99][119-4-4-0.89][121-4-4-0.99][122-4-4-0.98]
[124-4-4-0.86][125-4-4-0.99][126-4-4-0.99][127-4-2-0.64][128-4-4-0.67][129-4-4-0.98][130-4-4-0.99][131-4-4-0.93][132-4-4-0.21][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.81][137-4-4-0.95][138-4-4-0.93][139-4-4-0.99][140-4-4-0.47][141-4-4-0.43][142-4-4-0.98][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.97][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.72][154-4-4-0.99][155-4-4-0.93][156-4-4-0.82]
[157-4-4-0.17][158-4-4-0.97][160-4-2-0.06][161-4-2-0.77][162-4-2-0.52][164-4-4-0.97][165-4-4-0.92][167-4-0-0.84][168-4-4-0.73][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.83][175-4-4-0.99][177-4-4-0.99][178-4-4-0.84][179-4-4-0.99][180-4-4-0.64][181-4-4-0.99]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.91][186-4-4-0.55][187-4-4-0.54][188-4-4-0.99][189-4-2-0.95][190-4-4-0.27][191-4-4-0.99][192-4-4-0.99]
[193-4-2-0.90][194-4-4-0.76][195-4-0-0.20][196-4-4-0.95][197-4-4-0.99][198-4-4-0.99][199-4-2-0.96]
---------------------------
I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.567 | Acc: 90.750% | Wgt Acc: 96.946%
	I - Batch: 100 | Loss: 0.564 | Acc: 90.625% | Wgt Acc: 97.057%
	I - Batch: 150 | Loss: 0.563 | Acc: 91.458% | Wgt Acc: 97.337%
	I - Batch: 200 | Loss: 0.563 | Acc: 91.031% | Wgt Acc: 97.204%
I - num batch: 222
I - Train -- Loss: 0.562 | Acc: 90.978% | Wgt Acc: 97.199% | LR: 1.000000e-04 | Dur: 137.78s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   4. 104.]
 [  0. 577.   0.   0.  37.]
 [  1.   0. 733.   0.  85.]
 [  2.   0.   0. 533.  82.]
 [  2.   1.   1.   1. 692.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 68.639% | Wgt Acc: 62.692% | Dur: 14.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   1.   2.  21.  14.]
 [  0.  42.   5.   0.   6.]
 [  0.   8.  37.   0.   9.]
 [  2.   3.   8.  45.   1.]
 [ 12.  24.  23.  20. 150.]]

I - Local maximum validation set accuracy:  68.64

I - Validation set results: 
[14-1-2-0.49][50-3-4-0.49][124-2-2-0.33][127-0-0-0.99][443-2-2-0.76][567-0-0-0.83][573-1-1-0.97][615-0-0-0.64][695-1-2-0.99][722-3-0-0.95]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.71][1212-3-4-0.47][1368-0-0-0.99][2181-2-3-0.19][2476-2-2-0.90][2721-2-2-0.97][2818-1-1-0.83][2886-2-1-0.70]
[3231-2-2-0.99][3333-2-4--0.09][3482-2-2-0.64][3536-3-4--0.41][3625-1-2-0.87][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.83][4346-1-4-0.20]
[4581-2-1-0.43][4708-3-4-0.99][4838-3-3-0.63][4845-1-4-0.60][4868-0-0-0.99][4939-0-4-0.11][4984-2-2-0.44][5078-1-4-0.79][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.96][5843-1-4-0.11][5949-3-3-0.13][5987-2-4-0.96][6014-3-3-0.91][6033-3-4-0.08][6313-0-0-0.98][6421-3-3-0.51][6500-1-1-0.31][6583-3-3-0.35]
[6683-3-3-0.34][6825-2-1-0.52][6998-3-0--0.20][7049-3-3-0.34][7517-1-1-0.99][7521-1-1-0.42][7528-1-2--0.26][7949-1-2-0.94][8135-1-3--0.27][8185-3-0-0.99]
[8269-3-4-0.44][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-1-0.86][9001-2-4-0.94][9036-2-2-0.96][9281-3-4-0.18][9300-2-2-0.99]
[9571-0-4-0.61][9617-1-4-0.64][9644-2-2-0.68][9705-2-1-0.55][9801-0-0-0.64][9803-3-3-0.16][9865-3-3-0.99][9896-2-4-0.96][10314-1-4-0.88][10337-3-3-0.81]
[10403-0-4-0.86][10653-2-4-0.97][10704-2-2-0.68][10719-1-1-0.99][10727-1-4-0.96][10836-0-0-0.99][10969-2-3-0.68][11042-0-0-0.87][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.66][11499-0-0-0.98][11502-3-0-0.20][11512-3-3-0.52][11608-1-1-0.52][11610-0-0-0.97][11692-0-0-0.98][11905-0-0-0.99][11993-1-1-0.98][12002-2-2--0.24]
[12052-0-0-0.99][12201-0-0-0.91][12235-2-2-0.61][12320-1-4-0.93][12377-2-4-0.99][12398-2-3-0.49][12503-1-4-0.96][12617-0-0--0.31][12685-3-3-0.20][12738-2-0-0.27]
[12742-2-2-0.99][12823-0-0-0.97][13110-1-2-0.62][13240-3-0-0.92][13253-1-1-0.55][13273-0-0-0.99][13634-1-4-0.30][13763-2-2-0.40][13905-3-0--0.13][14060-2-4-0.83]
[14065-3-0-0.79][14147-3-0-0.53][14595-2-2-0.99][14687-2-2-0.99][14788-2-2-0.73][14869-1-1-0.95][14872-3-4-0.52][14877-1-1-0.99][14927-0-0--0.08][15066-0-0-0.99]
[15175-1-4-0.91][15178-2-3-0.37][15375-3-0--0.03][15389-3-3-0.95][15568-2-4-0.75][15675-3-3-0.96][15869-1-4-0.15][16207-3-0-0.69][16236-0-0-0.99][16302-3-3-0.54]
[16331-2-2-0.99][16381-0-4-0.76][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.22][16801-0-0-0.99][16828-0-0-0.99][17137-3-0-0.45][17245-1-4-0.14]
[17278-3-0-0.01][17282-0-0-0.61][17311-2-2-0.94][17336-2-1-0.71][17608-3-3-0.99][17627-0-0-0.77][17877-3-4-0.99][17924-1-4-0.17][17984-3-3-0.95][18211-0-0-0.48]
[18276-3-3-0.49][18287-1-1-0.11][18394-0-0-0.99][18428-0-0-0.99][18442-0-3-0.27][18478-3-0-0.29][18607-0-0-0.99][18616-0-0-0.61][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.92][18890-3-3-0.93][18930-3-4-0.91][18938-3-3-0.81][19817-1-2-0.63][19839-0-0-0.61][19930-3-3-0.29][19944-0-4-0.96][20036-2-2-0.99]
[20101-3-3-0.33][20474-1-1-0.71][20547-3-4-0.76][20929-2-2-0.99][21245-1-4--0.16][21257-3-3-0.33][21293-1-1-0.99][21316-1-1--0.13][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.88][21714-0-0-0.79][21943-3-4-0.61][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.83][22494-3-0-0.62][22757-0-0-0.99][22811-3-3-0.32][22976-3-4--0.11][22985-3-3-0.87][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-3-0.11]
[23219-0-0-0.78][23363-3-3-0.77][23470-0-0-0.32][23486-2-4-0.46][23497-0-0-0.99][23516-0-0-0.99][23690-1-3-0.65][23921-2-4-0.93][23936-1-2-0.99][24040-3-4-0.59]
[24111-1-4-0.98][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.36][24364-1-1--0.11][24427-3-0-0.98][24477-2-2-0.72][24495-2-4-0.66][24893-2-2-0.07]
[25012-1-1-0.30][25121-2-2-0.97][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.96][25398-0-0-0.97][25574-2-4-0.90][25644-1-1-0.81][25718-1-4-0.92][25774-2-4-0.92]
[26032-3-3-0.75][26051-3-3-0.96][26120-0-4-0.94][26321-1-1-0.99][26732-1-1-0.78][26784-3-3-0.99][26827-3-3-0.59][26833-0-3-0.69][26838-2-4--0.07][26860-1-4-0.63]
[26948-0-0-0.99][27049-3-0-0.92][27098-1-0-0.86][27526-0-0-0.96][27639-3-3-0.74][27698-3-0-0.82][27772-0-0-0.99][27890-1-1-0.84][28040-0-4-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.98][29777-0-0-0.99][29877-2-2-0.06][30035-1-1-0.98][30098-0-0-0.71][30326-1-1-0.99][30572-2-2-0.97][30716-0-4-0.99]
[30806-2-2-0.41][30906-1-1-0.99][31007-0-0-0.96][31181-3-4-0.85][31238-0-0-0.63][31347-0-0-0.99][31422-2-4-0.41][31429-3-3--0.23][31431-0-0-0.97][31432-1-1-0.82]
[31477-0-0-0.94][31524-1-4-0.42][31597-1-1-0.80][31619-1-4-0.37][31701-0-0-0.98][31755-0-0-0.99][31854-3-3-0.86][32074-1-1-0.71][32078-3-3-0.96][32111-1-1-0.96]
[32127-1-1-0.66][32140-3-3-0.22][32263-2-4-0.33][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.15][32473-3-0-0.52][32574-3-3-0.90][32584-0-4-0.99][32622-0-4-0.43]
[32858-3-0-0.48][32969-3-0-0.83][33016-2-2-0.66][33031-1-3-0.99][33035-2-4-0.86][33133-2-2-0.95][33173-2-2-0.56][33175-3-4-0.99][33306-3-3-0.95][33309-2-3--0.21]
[33474-0-0-0.74][33478-2-4--0.26][33618-1-4-0.95][33712-0-0-0.88][33782-2-4-0.99][33914-3-4-0.23][34076-3-4-0.98][34112-2-2-0.88][34138-2-3-0.07][34239-1-1-0.37]
[34364-2-2-0.99][34617-1-4-0.24][34751-3-3-0.68][34783-2-4-0.94][35015-3-4-0.97][35018-1-1-0.70][35288-2-4-0.05][0-4-4-0.97][1-4-4-0.99][2-4-4-0.87]
[3-4-4-0.93][4-4-0-0.59][5-4-1-0.83][6-4-0-0.79][7-4-4-0.87][8-4-2-0.04][9-4-0-0.63][10-4-4-0.99][11-4-4-0.99][12-4-4-0.94]
[14-4-4-0.97][15-4-0-0.58][16-4-4-0.99][17-4-4-0.80][18-4-4-0.99][19-4-4-0.57][20-4-0-0.18][21-4-4-0.97][22-4-4-0.99][23-4-4-0.98]
[24-4-4-0.99][25-4-4-0.87][26-4-4-0.52][27-4-4-0.99][28-4-4-0.99][29-4-4-0.45][30-4-4-0.76][31-4-4-0.97][32-4-4-0.98][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.95][37-4-4-0.99][39-4-0-0.63][40-4-4-0.44][41-4-4-0.89][42-4-4-0.89][43-4-4-0.99][45-4-4-0.51][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.96][51-4-4-0.99][52-4-4-0.88][53-4-4-0.53][54-4-4-0.98][55-4-4-0.75][56-4-1-0.44][57-4-4-0.36][58-4-4-0.95]
[59-4-4-0.95][60-4-4-0.96][61-4-4-0.99][62-4-4-0.99][63-4-2-0.87][64-4-4-0.87][65-4-4-0.99][66-4-4-0.99][67-4-2-0.95][68-4-4-0.86]
[69-4-4-0.51][70-4-4-0.95][72-4-1-0.85][73-4-1-0.87][74-4-4-0.99][75-4-0--0.37][77-4-4-0.99][78-4-4-0.69][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.82][82-4-4-0.89][83-4-4-0.95][84-4-4-0.99][85-4-4-0.99][86-4-4-0.28][87-4-4-0.99][88-4-4-0.98][89-4-4-0.51][90-4-4-0.83]
[91-4-4-0.98][92-4-4-0.87][93-4-0-0.28][94-4-4-0.99][95-4-4-0.67][96-4-4-0.99][97-4-4-0.99][98-4-2-0.77][99-4-4-0.83][100-4-1-0.84]
[101-4-4-0.99][102-4-4-0.96][103-4-0-0.51][104-4-4-0.99][105-4-4-0.11][106-4-4-0.99][107-4-4-0.98][108-4-4-0.78][109-4-4-0.98][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.50][113-4-4-0.96][114-4-4-0.22][115-4-4-0.75][116-4-4-0.96][117-4-4-0.99][119-4-4-0.99][121-4-4-0.98][122-4-4-0.99]
[124-4-4-0.96][125-4-4-0.99][126-4-4-0.99][127-4-2-0.95][128-4-4-0.65][129-4-4-0.98][130-4-4-0.57][131-4-4-0.71][132-4-4-0.27][133-4-4-0.99]
[135-4-4-0.97][136-4-4-0.84][137-4-4-0.87][138-4-4-0.99][139-4-4-0.99][140-4-4-0.95][141-4-3--0.17][142-4-4-0.99][143-4-4-0.99][144-4-4-0.78]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.63][154-4-4-0.99][155-4-4-0.99][156-4-4-0.81]
[157-4-2--0.08][158-4-4-0.99][160-4-2-0.29][161-4-2-0.53][162-4-4-0.35][164-4-4-0.91][165-4-4-0.99][167-4-4-0.94][168-4-4-0.75][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.99][175-4-4-0.96][177-4-4-0.99][178-4-4-0.96][179-4-4-0.96][180-4-4-0.99][181-4-4-0.62]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.81][186-4-4-0.89][187-4-4-0.55][188-4-4-0.99][189-4-4-0.10][190-4-4-0.12][191-4-4-0.99][192-4-4-0.98]
[193-4-1-0.73][194-4-0--0.07][195-4-0-0.72][196-4-4-0.96][197-4-4-0.99][198-4-4-0.99][199-4-2-0.79]
---------------------------
I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.545 | Acc: 92.375% | Wgt Acc: 97.821%
	I - Batch: 100 | Loss: 0.550 | Acc: 91.500% | Wgt Acc: 97.397%
	I - Batch: 150 | Loss: 0.550 | Acc: 91.375% | Wgt Acc: 97.352%
	I - Batch: 200 | Loss: 0.553 | Acc: 91.594% | Wgt Acc: 97.336%
I - num batch: 222
I - Train -- Loss: 0.553 | Acc: 91.711% | Wgt Acc: 97.403% | LR: 1.000000e-04 | Dur: 137.43s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   2.  84.]
 [  0. 578.   0.   1.  45.]
 [  0.   0. 733.   0.  79.]
 [  4.   0.   1. 534.  74.]
 [  3.   0.   0.   1. 718.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.850% | Wgt Acc: 59.174% | Dur: 15.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   1.  13.  10.]
 [  0.  39.   2.   0.   4.]
 [  0.   8.  35.   0.   3.]
 [  8.   1.   8.  48.   1.]
 [ 20.  28.  29.  25. 162.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.542 | Acc: 91.000% | Wgt Acc: 97.215%
	I - Batch: 100 | Loss: 0.549 | Acc: 91.000% | Wgt Acc: 97.190%
	I - Batch: 150 | Loss: 0.546 | Acc: 91.833% | Wgt Acc: 97.505%
	I - Batch: 200 | Loss: 0.549 | Acc: 91.719% | Wgt Acc: 97.376%
I - num batch: 222
I - Train -- Loss: 0.548 | Acc: 91.880% | Wgt Acc: 97.425% | LR: 1.000000e-04 | Dur: 136.46s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   3.  96.]
 [  0. 578.   0.   0.  33.]
 [  1.   0. 733.   0.  87.]
 [  1.   0.   0. 535.  59.]
 [  7.   0.   1.   0. 725.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 68.245% | Wgt Acc: 61.977% | Dur: 14.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   2.   0.  15.  11.]
 [  0.  34.   1.   1.   3.]
 [  2.  17.  43.   1.  11.]
 [  5.   2.   8.  50.   4.]
 [ 13.  23.  23.  19. 151.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.548 | Acc: 91.500% | Wgt Acc: 97.462%
	I - Batch: 100 | Loss: 0.549 | Acc: 91.188% | Wgt Acc: 97.435%
	I - Batch: 150 | Loss: 0.549 | Acc: 91.542% | Wgt Acc: 97.486%
	I - Batch: 200 | Loss: 0.547 | Acc: 91.344% | Wgt Acc: 97.388%
I - num batch: 222
I - Train -- Loss: 0.547 | Acc: 91.401% | Wgt Acc: 97.426% | LR: 1.000000e-04 | Dur: 136.67s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   4. 115.]
 [  0. 578.   0.   0.  45.]
 [  0.   0. 733.   0.  74.]
 [  0.   0.   0. 533.  63.]
 [  2.   0.   1.   1. 703.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.014 | Acc: 69.034% | Wgt Acc: 65.079% | Dur: 14.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 78.   6.   4.  27.  17.]
 [  0.  49.   4.   2.   6.]
 [  0.   8.  41.   1.  13.]
 [  2.   3.   7.  41.   3.]
 [  8.  12.  19.  15. 141.]]

I - Local maximum validation set accuracy:  69.03

I - Validation set results: 
[14-1-2-0.19][50-3-4-0.77][124-2-2--0.20][127-0-0-0.99][443-2-2-0.97][567-0-0-0.99][573-1-1-0.25][615-0-0-0.95][695-1-2-0.99][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.72][1212-3-4-0.23][1368-0-0-0.99][2181-2-3-0.32][2476-2-2-0.68][2721-2-2-0.99][2818-1-1-0.94][2886-2-4-0.69]
[3231-2-2-0.99][3333-2-3--0.30][3482-2-2-0.30][3536-3-0-0.14][3625-1-1-0.77][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-1--0.26][4346-1-3-0.52]
[4581-2-4-0.52][4708-3-4-0.78][4838-3-4-0.13][4845-1-1-0.03][4868-0-0-0.99][4939-0-0--0.00][4984-2-3--0.17][5078-1-0-0.62][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.93][5843-1-1-0.48][5949-3-3-0.54][5987-2-4-0.99][6014-3-3-0.98][6033-3-0--0.02][6313-0-0-0.97][6421-3-3-0.35][6500-1-1-0.61][6583-3-3-0.65]
[6683-3-3-0.47][6825-2-1-0.98][6998-3-0-0.23][7049-3-3-0.01][7517-1-1-0.78][7521-1-1-0.98][7528-1-1--0.53][7949-1-2-0.96][8135-1-4--0.07][8185-3-0-0.99]
[8269-3-1-0.72][8273-3-3-0.94][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-1-0.98][9001-2-2-0.64][9036-2-2-0.93][9281-3-0-0.01][9300-2-2-0.99]
[9571-0-0-0.45][9617-1-1-0.91][9644-2-2-0.98][9705-2-4-0.47][9801-0-0-0.82][9803-3-0--0.24][9865-3-3-0.99][9896-2-2-0.91][10314-1-0-0.56][10337-3-3-0.57]
[10403-0-4-0.90][10653-2-4-0.89][10704-2-2-0.90][10719-1-1-0.90][10727-1-1-0.97][10836-0-0-0.99][10969-2-3-0.26][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.42][11499-0-0-0.99][11502-3-0-0.63][11512-3-3-0.83][11608-1-1-0.65][11610-0-0-0.88][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.98][12002-2-2--0.06]
[12052-0-0-0.94][12201-0-0-0.98][12235-2-2-0.88][12320-1-0-0.73][12377-2-4-0.99][12398-2-0--0.24][12503-1-4-0.92][12617-0-0--0.03][12685-3-4--0.22][12738-2-4-0.59]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.07][13240-3-0-0.99][13253-1-1-0.80][13273-0-0-0.99][13634-1-4-0.12][13763-2-2-0.50][13905-3-0-0.18][14060-2-4-0.94]
[14065-3-0-0.52][14147-3-3-0.71][14595-2-2-0.96][14687-2-2-0.99][14788-2-2-0.77][14869-1-1-0.95][14872-3-4-0.89][14877-1-1-0.99][14927-0-0-0.38][15066-0-0-0.99]
[15175-1-4-0.89][15178-2-3-0.17][15375-3-0-0.52][15389-3-3-0.95][15568-2-4-0.98][15675-3-3-0.99][15869-1-0-0.93][16207-3-0-0.95][16236-0-0-0.43][16302-3-3-0.45]
[16331-2-2-0.99][16381-0-0-0.04][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.87][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.55][17245-1-2-0.32]
[17278-3-1-0.05][17282-0-0-0.79][17311-2-2-0.73][17336-2-2--0.33][17608-3-3-0.82][17627-0-0-0.90][17877-3-0-0.72][17924-1-2-0.79][17984-3-0-0.93][18211-0-0-0.65]
[18276-3-0-0.87][18287-1-1-0.57][18394-0-0-0.99][18428-0-0-0.99][18442-0-3-0.76][18478-3-0-0.62][18607-0-0-0.99][18616-0-0-0.94][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.80][18890-3-3-0.89][18930-3-4-0.53][18938-3-3-0.74][19817-1-1-0.88][19839-0-0-0.76][19930-3-3-0.34][19944-0-4-0.97][20036-2-2-0.99]
[20101-3-4-0.37][20474-1-1-0.81][20547-3-4-0.49][20929-2-2-0.99][21245-1-1-0.33][21257-3-3-0.35][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-0-0.84][21943-3-4-0.06][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4--0.02][22985-3-0-0.83][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0-0.21]
[23219-0-0-0.99][23363-3-3-0.98][23470-0-0-0.51][23486-2-2-0.65][23497-0-3-0.99][23516-0-0-0.99][23690-1-4-0.33][23921-2-1-0.53][23936-1-0-0.62][24040-3-4--0.06]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.98][24290-2-0-0.99][24345-0-0-0.31][24364-1-1-0.52][24427-3-0-0.99][24477-2-2-0.98][24495-2-4-0.85][24893-2-2-0.68]
[25012-1-4--0.10][25121-2-2-0.99][25165-3-3-0.99][25183-0-4-0.82][25297-3-3-0.29][25398-0-0-0.99][25574-2-2-0.96][25644-1-1-0.90][25718-1-4-0.02][25774-2-4-0.85]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.98][26321-1-1-0.98][26732-1-1-0.89][26784-3-3-0.99][26827-3-0-0.98][26833-0-0-0.89][26838-2-4-0.14][26860-1-4-0.48]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.99][27526-0-0-0.56][27639-3-3-0.88][27698-3-0-0.98][27772-0-0-0.99][27890-1-1-0.96][28040-0-0--0.11][28503-2-2-0.97]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-1--0.06][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.87][30716-0-4-0.99]
[30806-2-2-0.21][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.30][31238-0-0-0.43][31347-0-0-0.99][31422-2-4-0.49][31429-3-3--0.10][31431-0-0--0.00][31432-1-1-0.87]
[31477-0-0-0.74][31524-1-1--0.22][31597-1-1-0.48][31619-1-2--0.15][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.98][32074-1-3-0.16][32078-3-3-0.99][32111-1-1-0.87]
[32127-1-1-0.99][32140-3-0-0.30][32263-2-4-0.49][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.97][32473-3-3-0.54][32574-3-3-0.39][32584-0-0-0.83][32622-0-4-0.81]
[32858-3-3-0.71][32969-3-0-0.96][33016-2-2-0.92][33031-1-3-0.96][33035-2-4-0.63][33133-2-2-0.75][33173-2-2-0.40][33175-3-4-0.99][33306-3-3-0.99][33309-2-2-0.77]
[33474-0-0-0.77][33478-2-0-0.58][33618-1-4-0.98][33712-0-0-0.96][33782-2-4-0.98][33914-3-3-0.94][34076-3-4--0.06][34112-2-3-0.49][34138-2-2-0.27][34239-1-1-0.42]
[34364-2-2-0.99][34617-1-2-0.57][34751-3-0-0.98][34783-2-4-0.92][35015-3-2-0.49][35018-1-4-0.72][35288-2-1-0.11][0-4-4-0.84][1-4-4-0.98][2-4-4-0.57]
[3-4-4-0.65][4-4-4-0.50][5-4-1-0.85][6-4-0-0.83][7-4-4-0.44][8-4-2-0.11][9-4-0-0.65][10-4-4-0.99][11-4-4-0.99][12-4-4-0.88]
[14-4-4-0.93][15-4-3-0.77][16-4-4-0.79][17-4-4-0.33][18-4-4-0.99][19-4-0-0.54][20-4-0-0.96][21-4-2-0.65][22-4-4-0.99][23-4-4-0.26]
[24-4-4-0.99][25-4-4-0.98][26-4-4-0.64][27-4-4-0.99][28-4-4-0.99][29-4-1-0.70][30-4-4-0.61][31-4-4-0.95][32-4-4-0.99][33-4-4-0.60]
[34-4-4-0.97][35-4-0-0.99][37-4-4-0.93][39-4-0-0.99][40-4-4-0.54][41-4-1-0.05][42-4-4-0.57][43-4-4-0.97][45-4-4-0.74][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.67][51-4-4-0.99][52-4-4-0.96][53-4-4-0.52][54-4-4-0.98][55-4-0--0.02][56-4-1-0.60][57-4-0--0.18][58-4-2-0.90]
[59-4-4-0.88][60-4-4-0.33][61-4-4-0.97][62-4-4-0.91][63-4-2-0.99][64-4-4-0.87][65-4-4-0.99][66-4-4-0.99][67-4-2-0.98][68-4-4-0.55]
[69-4-4--0.19][70-4-4-0.97][72-4-4-0.99][73-4-1-0.99][74-4-4-0.36][75-4-3-0.58][77-4-4-0.99][78-4-4-0.48][79-4-4-0.99][80-4-4-0.98]
[81-4-1-0.92][82-4-4-0.89][83-4-4-0.52][84-4-4-0.99][85-4-4-0.98][86-4-4-0.68][87-4-4-0.99][88-4-4-0.99][89-4-2-0.11][90-4-4-0.92]
[91-4-4-0.81][92-4-4-0.40][93-4-4-0.42][94-4-4-0.99][95-4-4-0.71][96-4-4-0.99][97-4-4-0.99][98-4-2-0.89][99-4-4-0.95][100-4-4-0.97]
[101-4-4-0.99][102-4-2-0.46][103-4-0-0.34][104-4-4-0.99][105-4-4-0.43][106-4-4-0.99][107-4-4-0.98][108-4-4-0.77][109-4-4-0.77][110-4-4-0.98]
[111-4-0-0.96][112-4-4-0.34][113-4-4--0.23][114-4-4--0.01][115-4-4-0.81][116-4-4-0.72][117-4-4-0.99][119-4-4-0.99][121-4-4-0.98][122-4-4-0.99]
[124-4-4-0.80][125-4-4-0.99][126-4-4-0.99][127-4-2-0.99][128-4-4-0.31][129-4-4-0.95][130-4-4-0.97][131-4-2-0.38][132-4-4-0.66][133-4-4-0.99]
[135-4-4-0.93][136-4-4-0.57][137-4-4-0.99][138-4-4-0.98][139-4-4-0.99][140-4-4-0.79][141-4-0-0.61][142-4-4-0.99][143-4-4-0.99][144-4-4-0.71]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.94][150-4-4-0.99][151-4-4-0.99][152-4-4-0.44][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.78]
[157-4-0-0.99][158-4-4-0.99][160-4-2-0.21][161-4-4-0.27][162-4-0--0.07][164-4-4-0.80][165-4-4-0.99][167-4-4-0.97][168-4-4-0.84][170-4-4-0.57]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.99][175-4-4-0.99][177-4-4-0.99][178-4-0-0.13][179-4-4-0.88][180-4-4-0.99][181-4-3-0.72]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.95][186-4-4-0.51][187-4-4-0.32][188-4-4-0.99][189-4-4-0.41][190-4-4--0.01][191-4-4-0.98][192-4-4-0.99]
[193-4-2-0.98][194-4-4-0.20][195-4-0-0.90][196-4-4-0.38][197-4-4-0.98][198-4-4-0.99][199-4-2-0.78]
---------------------------
I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.533 | Acc: 94.125% | Wgt Acc: 98.120%
	I - Batch: 100 | Loss: 0.531 | Acc: 93.375% | Wgt Acc: 98.063%
	I - Batch: 150 | Loss: 0.531 | Acc: 92.750% | Wgt Acc: 97.950%
	I - Batch: 200 | Loss: 0.531 | Acc: 92.625% | Wgt Acc: 97.903%
I - num batch: 222
I - Train -- Loss: 0.530 | Acc: 92.895% | Wgt Acc: 97.983% | LR: 5.000000e-05 | Dur: 135.07s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  84.]
 [  0. 578.   0.   0.  38.]
 [  0.   0. 734.   0.  73.]
 [  0.   0.   0. 537.  54.]
 [  2.   0.   0.   1. 751.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 68.836% | Wgt Acc: 62.196% | Dur: 14.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   3.  18.   8.]
 [  0.  42.   7.   1.   7.]
 [  1.  10.  36.   0.   8.]
 [  7.   2.  10.  48.   3.]
 [ 11.  21.  19.  19. 154.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.528 | Acc: 93.250% | Wgt Acc: 98.008%
	I - Batch: 100 | Loss: 0.527 | Acc: 93.250% | Wgt Acc: 97.910%
	I - Batch: 150 | Loss: 0.525 | Acc: 93.625% | Wgt Acc: 98.091%
	I - Batch: 200 | Loss: 0.526 | Acc: 93.719% | Wgt Acc: 98.164%
I - num batch: 222
I - Train -- Loss: 0.526 | Acc: 93.516% | Wgt Acc: 98.090% | LR: 5.000000e-05 | Dur: 134.18s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.  80.]
 [  0. 578.   0.   0.  33.]
 [  0.   0. 734.   0.  56.]
 [  0.   0.   0. 535.  56.]
 [  2.   0.   0.   2. 775.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 66.272% | Wgt Acc: 56.799% | Dur: 16.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   1.   0.  14.   6.]
 [  0.  37.   3.   0.   3.]
 [  0.   7.  27.   0.   4.]
 [  7.   3.  12.  47.   4.]
 [ 19.  30.  33.  25. 163.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.522 | Acc: 94.625% | Wgt Acc: 98.427%
	I - Batch: 100 | Loss: 0.527 | Acc: 93.562% | Wgt Acc: 98.192%
	I - Batch: 150 | Loss: 0.526 | Acc: 93.292% | Wgt Acc: 98.014%
	I - Batch: 200 | Loss: 0.526 | Acc: 93.344% | Wgt Acc: 98.058%
I - num batch: 222
I - Train -- Loss: 0.525 | Acc: 93.600% | Wgt Acc: 98.144% | LR: 5.000000e-05 | Dur: 133.99s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  87.]
 [  0. 578.   0.   0.  29.]
 [  0.   0. 733.   0.  66.]
 [  0.   0.   0. 536.  41.]
 [  1.   0.   1.   2. 777.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.987 | Acc: 69.625% | Wgt Acc: 62.934% | Dur: 14.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   5.   2.  18.  10.]
 [  0.  36.   2.   1.   4.]
 [  0.  12.  34.   0.   6.]
 [  5.   2.   8.  55.   4.]
 [ 11.  23.  29.  12. 156.]]

I - Local maximum validation set accuracy:  69.63

I - Validation set results: 
[14-1-4-0.21][50-3-4-0.93][124-2-4-0.68][127-0-0-0.99][443-2-2-0.81][567-0-0-0.99][573-1-1-0.87][615-0-0-0.67][695-1-2-0.99][722-3-3-0.98]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.86][1212-3-0-0.67][1368-0-0-0.99][2181-2-3-0.05][2476-2-2-0.82][2721-2-2-0.84][2818-1-1-0.43][2886-2-4-0.87]
[3231-2-2-0.99][3333-2-4--0.09][3482-2-2-0.62][3536-3-0--0.19][3625-1-2-0.64][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.90][4214-1-4-0.55][4346-1-0-0.44]
[4581-2-4-0.50][4708-3-4-0.90][4838-3-3-0.25][4845-1-4-0.29][4868-0-0-0.99][4939-0-4-0.68][4984-2-2-0.16][5078-1-4-0.70][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.05][5949-3-3-0.58][5987-2-4-0.99][6014-3-3-0.64][6033-3-3--0.19][6313-0-0-0.64][6421-3-3-0.97][6500-1-1-0.41][6583-3-3-0.99]
[6683-3-3-0.72][6825-2-1-0.88][6998-3-0--0.10][7049-3-3-0.72][7517-1-1-0.72][7521-1-1--0.13][7528-1-2--0.50][7949-1-2-0.99][8135-1-3--0.20][8185-3-0-0.99]
[8269-3-1-0.94][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.96][9001-2-4-0.80][9036-2-2-0.99][9281-3-3-0.08][9300-2-2-0.99]
[9571-0-4-0.07][9617-1-4-0.56][9644-2-2-0.99][9705-2-4-0.53][9801-0-0-0.68][9803-3-3-0.30][9865-3-3-0.99][9896-2-4-0.98][10314-1-4-0.96][10337-3-3-0.80]
[10403-0-4-0.84][10653-2-4-0.97][10704-2-2-0.54][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.91][11042-0-0-0.96][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.52][11499-0-0-0.99][11502-3-0--0.12][11512-3-3-0.99][11608-1-1-0.22][11610-0-0-0.95][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.96][12002-2-2--0.61]
[12052-0-0-0.91][12201-0-0-0.95][12235-2-2-0.94][12320-1-0-0.94][12377-2-4-0.94][12398-2-4--0.07][12503-1-4-0.30][12617-0-0-0.19][12685-3-3-0.23][12738-2-4-0.68]
[12742-2-2-0.99][12823-0-0-0.98][13110-1-2-0.76][13240-3-0-0.94][13253-1-0-0.89][13273-0-0-0.99][13634-1-4-0.45][13763-2-2-0.43][13905-3-3--0.27][14060-2-4-0.98]
[14065-3-0-0.75][14147-3-3-0.90][14595-2-4-0.75][14687-2-2-0.99][14788-2-4-0.80][14869-1-1-0.90][14872-3-4-0.83][14877-1-1-0.99][14927-0-3-0.33][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.64][15375-3-0-0.69][15389-3-3-0.97][15568-2-4-0.96][15675-3-3-0.99][15869-1-0-0.35][16207-3-0-0.80][16236-0-0-0.99][16302-3-3-0.99]
[16331-2-2-0.99][16381-0-3-0.62][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.80][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.93][17245-1-4--0.03]
[17278-3-0-0.10][17282-0-0-0.78][17311-2-2-0.84][17336-2-1-0.83][17608-3-3-0.99][17627-0-0-0.49][17877-3-4-0.99][17924-1-4-0.33][17984-3-3-0.95][18211-0-0-0.72]
[18276-3-3-0.94][18287-1-4-0.75][18394-0-0-0.99][18428-0-0-0.45][18442-0-3-0.61][18478-3-3-0.96][18607-0-0-0.99][18616-0-0-0.96][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.87][18930-3-4-0.84][18938-3-3-0.51][19817-1-1-0.45][19839-0-0-0.63][19930-3-3-0.70][19944-0-4-0.78][20036-2-2-0.99]
[20101-3-3-0.68][20474-1-2-0.38][20547-3-4-0.87][20929-2-2-0.99][21245-1-2-0.25][21257-3-3-0.85][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.98][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.89][21714-0-0-0.29][21943-3-4-0.67][21947-0-0-0.84][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.76][22494-3-3-0.96][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.16][22985-3-0-0.91][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-3--0.32]
[23219-0-0-0.84][23363-3-3-0.99][23470-0-0-0.91][23486-2-4-0.52][23497-0-0-0.94][23516-0-0-0.99][23690-1-4--0.04][23921-2-4-0.47][23936-1-2-0.77][24040-3-0-0.29]
[24111-1-4-0.96][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.97][24345-0-0-0.99][24364-1-2--0.11][24427-3-0-0.63][24477-2-4-0.97][24495-2-4-0.99][24893-2-2-0.76]
[25012-1-4-0.02][25121-2-2-0.97][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.98][25644-1-2-0.99][25718-1-1--0.14][25774-2-4-0.99]
[26032-3-3-0.95][26051-3-3-0.99][26120-0-4-0.97][26321-1-1-0.67][26732-1-1-0.37][26784-3-3-0.99][26827-3-3-0.83][26833-0-3-0.98][26838-2-4-0.26][26860-1-4-0.42]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.41][27526-0-0-0.83][27639-3-3-0.97][27698-3-0-0.65][27772-0-0-0.87][27890-1-1-0.88][28040-0-4--0.37][28503-2-2-0.95]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.96][29777-0-0-0.99][29877-2-3-0.09][30035-1-1-0.93][30098-0-0-0.32][30326-1-1-0.99][30572-2-2-0.99][30716-0-4-0.99]
[30806-2-2-0.80][30906-1-1-0.99][31007-0-0-0.99][31181-3-0--0.24][31238-0-0-0.60][31347-0-0-0.99][31422-2-4-0.84][31429-3-3-0.50][31431-0-0-0.63][31432-1-1-0.96]
[31477-0-0-0.81][31524-1-4-0.61][31597-1-1-0.74][31619-1-4-0.77][31701-0-0-0.98][31755-0-0-0.99][31854-3-3-0.96][32074-1-1-0.48][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-1-0.76][32140-3-3-0.76][32263-2-4-0.83][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.40][32473-3-3-0.85][32574-3-3-0.99][32584-0-4-0.95][32622-0-4-0.60]
[32858-3-3-0.59][32969-3-3-0.98][33016-2-2-0.92][33031-1-3-0.96][33035-2-4-0.92][33133-2-2-0.96][33173-2-2-0.97][33175-3-4-0.99][33306-3-3-0.98][33309-2-3-0.79]
[33474-0-3--0.12][33478-2-0-0.02][33618-1-4-0.98][33712-0-0-0.98][33782-2-4-0.98][33914-3-3-0.99][34076-3-4-0.85][34112-2-2-0.99][34138-2-3-0.27][34239-1-4-0.21]
[34364-2-2-0.98][34617-1-4-0.99][34751-3-0-0.99][34783-2-4-0.17][35015-3-4-0.93][35018-1-4-0.96][35288-2-2--0.03][0-4-4-0.96][1-4-4-0.99][2-4-4-0.98]
[3-4-4-0.92][4-4-4-0.95][5-4-2--0.21][6-4-4-0.43][7-4-4-0.93][8-4-4--0.02][9-4-0-0.96][10-4-4-0.99][11-4-4-0.99][12-4-4-0.95]
[14-4-4-0.98][15-4-3-0.88][16-4-4-0.95][17-4-4-0.97][18-4-4-0.94][19-4-0-0.58][20-4-0--0.06][21-4-4-0.62][22-4-4-0.99][23-4-4-0.84]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.94][27-4-4-0.99][28-4-4-0.98][29-4-4-0.66][30-4-4-0.73][31-4-4-0.99][32-4-4-0.99][33-4-4-0.98]
[34-4-4-0.99][35-4-4-0.95][37-4-4-0.82][39-4-0-0.62][40-4-4-0.66][41-4-4-0.37][42-4-4-0.76][43-4-4-0.99][45-4-4-0.62][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.98][51-4-4-0.99][52-4-4-0.99][53-4-4-0.85][54-4-4-0.99][55-4-4-0.71][56-4-1-0.32][57-4-3-0.92][58-4-4-0.96]
[59-4-4-0.93][60-4-4-0.97][61-4-4-0.99][62-4-4-0.98][63-4-2-0.82][64-4-4-0.93][65-4-4-0.99][66-4-4-0.99][67-4-4-0.14][68-4-4-0.74]
[69-4-4-0.43][70-4-4-0.99][72-4-4-0.98][73-4-1-0.91][74-4-4-0.99][75-4-3-0.13][77-4-4-0.99][78-4-4-0.89][79-4-4-0.99][80-4-4-0.99]
[81-4-1-0.87][82-4-4-0.99][83-4-4-0.93][84-4-4-0.99][85-4-4-0.99][86-4-4-0.90][87-4-4-0.99][88-4-4-0.99][89-4-4-0.66][90-4-4-0.97]
[91-4-4-0.94][92-4-4-0.18][93-4-4-0.76][94-4-4-0.99][95-4-4-0.73][96-4-4-0.99][97-4-4-0.99][98-4-2-0.97][99-4-4-0.91][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.67][103-4-0-0.39][104-4-4-0.99][105-4-4-0.14][106-4-4-0.99][107-4-4-0.99][108-4-4-0.94][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.63][113-4-4--0.06][114-4-4-0.67][115-4-4-0.93][116-4-4-0.87][117-4-4-0.99][119-4-4-0.99][121-4-4-0.98][122-4-4-0.97]
[124-4-4-0.92][125-4-4-0.99][126-4-4-0.99][127-4-2-0.35][128-4-4-0.68][129-4-4-0.94][130-4-4-0.91][131-4-4-0.98][132-4-4-0.51][133-4-4-0.99]
[135-4-4-0.98][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-4-0.91][141-4-3--0.05][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.98][148-4-0-0.99][149-4-4-0.91][150-4-4-0.99][151-4-4-0.99][152-4-4-0.96][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.48]
[157-4-4-0.52][158-4-4-0.95][160-4-4-0.56][161-4-4-0.45][162-4-4-0.64][164-4-4-0.99][165-4-4-0.99][167-4-0-0.99][168-4-4-0.97][170-4-4-0.95]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.79][175-4-4-0.99][177-4-4-0.97][178-4-4-0.99][179-4-4-0.99][180-4-4-0.99][181-4-4-0.97]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.87][186-4-4-0.89][187-4-4-0.60][188-4-4-0.99][189-4-1--0.09][190-4-4-0.18][191-4-4-0.99][192-4-4-0.99]
[193-4-2-0.98][194-4-4-0.06][195-4-0-0.70][196-4-4-0.91][197-4-4-0.99][198-4-4-0.99][199-4-2-0.62]
---------------------------
I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.521 | Acc: 92.625% | Wgt Acc: 97.896%
	I - Batch: 100 | Loss: 0.524 | Acc: 93.250% | Wgt Acc: 97.962%
	I - Batch: 150 | Loss: 0.523 | Acc: 93.458% | Wgt Acc: 98.046%
	I - Batch: 200 | Loss: 0.521 | Acc: 93.375% | Wgt Acc: 98.040%
I - num batch: 222
I - Train -- Loss: 0.521 | Acc: 93.403% | Wgt Acc: 98.032% | LR: 5.000000e-05 | Dur: 136.11s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   2.  85.]
 [  0. 578.   0.   0.  32.]
 [  0.   0. 734.   0.  53.]
 [  0.   0.   0. 535.  58.]
 [  3.   0.   0.   1. 772.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 68.639% | Wgt Acc: 63.026% | Dur: 15.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 75.   2.   5.  16.  12.]
 [  0.  39.   4.   1.   5.]
 [  0.  10.  33.   0.   6.]
 [  4.   7.  13.  52.   8.]
 [  9.  20.  20.  17. 149.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.518 | Acc: 93.375% | Wgt Acc: 97.964%
	I - Batch: 100 | Loss: 0.518 | Acc: 93.812% | Wgt Acc: 98.138%
	I - Batch: 150 | Loss: 0.522 | Acc: 93.250% | Wgt Acc: 97.870%
	I - Batch: 200 | Loss: 0.521 | Acc: 93.219% | Wgt Acc: 97.871%
I - num batch: 222
I - Train -- Loss: 0.519 | Acc: 93.487% | Wgt Acc: 97.970% | LR: 5.000000e-05 | Dur: 138.13s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   1.  83.]
 [  1. 577.   0.   0.  32.]
 [  0.   0. 733.   0.  59.]
 [  1.   0.   0. 535.  48.]
 [  2.   1.   1.   2. 778.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 67.653% | Wgt Acc: 59.912% | Dur: 14.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   1.   3.  16.  11.]
 [  0.  32.   4.   0.   2.]
 [  0.  18.  35.   0.   6.]
 [  2.   2.   6.  50.   4.]
 [ 17.  25.  27.  20. 157.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.520 | Acc: 93.250% | Wgt Acc: 98.173%
	I - Batch: 100 | Loss: 0.520 | Acc: 93.312% | Wgt Acc: 98.168%
	I - Batch: 150 | Loss: 0.521 | Acc: 93.375% | Wgt Acc: 98.143%
	I - Batch: 200 | Loss: 0.520 | Acc: 93.531% | Wgt Acc: 98.201%
I - num batch: 222
I - Train -- Loss: 0.519 | Acc: 93.657% | Wgt Acc: 98.187% | LR: 5.000000e-05 | Dur: 134.00s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  81.]
 [  0. 578.   0.   0.  30.]
 [  0.   0. 734.   0.  62.]
 [  1.   0.   0. 536.  49.]
 [  0.   0.   0.   2. 778.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 68.442% | Wgt Acc: 60.835% | Dur: 14.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   2.   2.  12.   9.]
 [  0.  36.   3.   1.   3.]
 [  0.  10.  34.   1.   7.]
 [  3.   2.   8.  51.   3.]
 [ 17.  28.  28.  21. 158.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.523 | Acc: 93.500% | Wgt Acc: 98.103%
	I - Batch: 100 | Loss: 0.517 | Acc: 94.188% | Wgt Acc: 98.348%
	I - Batch: 150 | Loss: 0.515 | Acc: 94.125% | Wgt Acc: 98.307%
	I - Batch: 200 | Loss: 0.512 | Acc: 94.344% | Wgt Acc: 98.363%
I - num batch: 222
I - Train -- Loss: 0.513 | Acc: 94.220% | Wgt Acc: 98.315% | LR: 5.000000e-05 | Dur: 136.52s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  77.]
 [  0. 578.   0.   0.  23.]
 [  0.   0. 734.   0.  58.]
 [  0.   0.   0. 537.  43.]
 [  3.   0.   0.   1. 799.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.992 | Acc: 68.639% | Wgt Acc: 60.270% | Dur: 17.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   2.   2.  12.   8.]
 [  0.  34.   2.   0.   1.]
 [  0.  13.  33.   1.   7.]
 [  7.   2.  11.  52.   2.]
 [ 14.  27.  27.  21. 162.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.509 | Acc: 95.000% | Wgt Acc: 98.509%
	I - Batch: 100 | Loss: 0.507 | Acc: 95.125% | Wgt Acc: 98.627%
	I - Batch: 150 | Loss: 0.511 | Acc: 94.583% | Wgt Acc: 98.410%
	I - Batch: 200 | Loss: 0.511 | Acc: 94.438% | Wgt Acc: 98.334%
I - num batch: 222
I - Train -- Loss: 0.512 | Acc: 94.164% | Wgt Acc: 98.271% | LR: 5.000000e-05 | Dur: 135.70s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  77.]
 [  0. 577.   0.   0.  26.]
 [  0.   0. 734.   0.  47.]
 [  0.   0.   0. 537.  52.]
 [  3.   1.   0.   1. 798.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.018 | Acc: 67.061% | Wgt Acc: 58.309% | Dur: 15.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  11.   5.]
 [  0.  36.   2.   0.   1.]
 [  0.  10.  34.   0.  12.]
 [  6.   4.   3.  49.   1.]
 [ 22.  26.  34.  26. 161.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.506 | Acc: 94.875% | Wgt Acc: 98.607%
	I - Batch: 100 | Loss: 0.505 | Acc: 94.812% | Wgt Acc: 98.595%
	I - Batch: 150 | Loss: 0.509 | Acc: 94.208% | Wgt Acc: 98.429%
	I - Batch: 200 | Loss: 0.512 | Acc: 94.312% | Wgt Acc: 98.390%
I - num batch: 222
I - Train -- Loss: 0.512 | Acc: 94.333% | Wgt Acc: 98.401% | LR: 5.000000e-05 | Dur: 136.90s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  66.]
 [  0. 578.   0.   0.  27.]
 [  0.   0. 734.   0.  54.]
 [  0.   0.   0. 537.  52.]
 [  1.   0.   0.   1. 801.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 66.469% | Wgt Acc: 57.271% | Dur: 14.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   2.  10.   6.]
 [  0.  33.   3.   1.   2.]
 [  0.  10.  31.   0.   6.]
 [  6.   2.   8.  49.   4.]
 [ 20.  31.  31.  26. 162.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.506 | Acc: 94.500% | Wgt Acc: 98.499%
	I - Batch: 100 | Loss: 0.509 | Acc: 94.125% | Wgt Acc: 98.329%
	I - Batch: 150 | Loss: 0.511 | Acc: 94.333% | Wgt Acc: 98.411%
	I - Batch: 200 | Loss: 0.509 | Acc: 94.156% | Wgt Acc: 98.389%
I - num batch: 222
I - Train -- Loss: 0.510 | Acc: 94.108% | Wgt Acc: 98.371% | LR: 5.000000e-05 | Dur: 133.75s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  65.]
 [  0. 578.   0.   0.  36.]
 [  0.   0. 733.   0.  60.]
 [  0.   0.   0. 538.  47.]
 [  0.   0.   1.   0. 792.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 67.258% | Wgt Acc: 58.217% | Dur: 14.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   1.   1.  10.   5.]
 [  0.  39.   3.   2.   3.]
 [  1.   9.  31.   0.   6.]
 [  9.   1.   4.  50.   3.]
 [ 20.  28.  36.  24. 163.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.507 | Acc: 94.250% | Wgt Acc: 98.313%
	I - Batch: 100 | Loss: 0.508 | Acc: 94.750% | Wgt Acc: 98.505%
	I - Batch: 150 | Loss: 0.506 | Acc: 95.208% | Wgt Acc: 98.656%
	I - Batch: 200 | Loss: 0.505 | Acc: 95.188% | Wgt Acc: 98.658%
I - num batch: 222
I - Train -- Loss: 0.505 | Acc: 95.123% | Wgt Acc: 98.619% | LR: 2.500000e-05 | Dur: 135.82s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  70.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  46.]
 [  0.   0.   0. 538.  34.]
 [  2.   0.   0.   0. 829.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 69.428% | Wgt Acc: 61.089% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   2.  15.   7.]
 [  0.  39.   4.   0.   3.]
 [  0.   6.  34.   0.   5.]
 [  5.   1.   7.  48.   2.]
 [ 15.  29.  28.  23. 163.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.501 | Acc: 95.000% | Wgt Acc: 98.601%
	I - Batch: 100 | Loss: 0.502 | Acc: 95.000% | Wgt Acc: 98.628%
	I - Batch: 150 | Loss: 0.503 | Acc: 94.875% | Wgt Acc: 98.609%
	I - Batch: 200 | Loss: 0.506 | Acc: 94.656% | Wgt Acc: 98.447%
I - num batch: 222
I - Train -- Loss: 0.505 | Acc: 94.784% | Wgt Acc: 98.462% | LR: 2.500000e-05 | Dur: 135.35s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  73.]
 [  0. 578.   0.   1.  21.]
 [  0.   0. 734.   0.  34.]
 [  0.   0.   0. 535.  53.]
 [  1.   0.   0.   2. 819.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.996 | Acc: 68.245% | Wgt Acc: 61.008% | Dur: 14.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   6.  16.  11.]
 [  0.  42.   6.   0.   4.]
 [  0.   8.  29.   0.   6.]
 [  7.   3.   8.  49.   3.]
 [ 11.  20.  26.  21. 156.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.505 | Acc: 95.375% | Wgt Acc: 98.632%
	I - Batch: 100 | Loss: 0.500 | Acc: 95.625% | Wgt Acc: 98.739%
	I - Batch: 150 | Loss: 0.499 | Acc: 95.458% | Wgt Acc: 98.726%
	I - Batch: 200 | Loss: 0.500 | Acc: 95.531% | Wgt Acc: 98.760%
I - num batch: 222
I - Train -- Loss: 0.502 | Acc: 95.320% | Wgt Acc: 98.645% | LR: 2.500000e-05 | Dur: 134.39s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  65.]
 [  0. 578.   0.   0.  22.]
 [  0.   0. 733.   0.  36.]
 [  0.   0.   0. 538.  40.]
 [  2.   0.   1.   0. 837.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.980 | Acc: 70.414% | Wgt Acc: 62.496% | Dur: 14.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   3.   1.  15.   8.]
 [  0.  36.   3.   1.   3.]
 [  0.   9.  32.   0.   4.]
 [  3.   5.   7.  53.   2.]
 [ 12.  25.  32.  17. 163.]]

I - Local maximum validation set accuracy:  70.41

I - Validation set results: 
[14-1-2--0.20][50-3-4-0.64][124-2-4-0.67][127-0-0-0.99][443-2-2-0.97][567-0-0-0.88][573-1-1-0.89][615-0-0-0.64][695-1-2-0.98][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.88][1212-3-4-0.61][1368-0-0-0.99][2181-2-3-0.45][2476-2-2-0.84][2721-2-2-0.88][2818-1-1-0.82][2886-2-4-0.46]
[3231-2-2-0.99][3333-2-4--0.21][3482-2-2-0.86][3536-3-3--0.21][3625-1-2-0.48][3909-0-0-0.98][4035-0-0-0.99][4140-0-0-0.98][4214-1-3-0.55][4346-1-3-0.13]
[4581-2-1-0.30][4708-3-4-0.98][4838-3-4-0.43][4845-1-4-0.59][4868-0-0-0.99][4939-0-4-0.28][4984-2-2-0.32][5078-1-0-0.56][5396-0-0-0.99][5479-1-1-0.94]
[5717-0-0-0.99][5843-1-3-0.45][5949-3-3-0.87][5987-2-4-0.99][6014-3-3-0.66][6033-3-3--0.14][6313-0-0-0.98][6421-3-3-0.98][6500-1-4-0.84][6583-3-3-0.99]
[6683-3-3-0.90][6825-2-1-0.71][6998-3-0-0.38][7049-3-3-0.84][7517-1-1-0.80][7521-1-1-0.20][7528-1-1--0.45][7949-1-2-0.86][8135-1-4-0.64][8185-3-0-0.99]
[8269-3-1-0.97][8273-3-3-0.99][8543-3-0-0.98][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.99][9001-2-4-0.81][9036-2-2-0.98][9281-3-4-0.18][9300-2-2-0.99]
[9571-0-4-0.02][9617-1-4-0.99][9644-2-2-0.79][9705-2-4-0.48][9801-0-0-0.78][9803-3-3-0.53][9865-3-3-0.99][9896-2-4-0.88][10314-1-4-0.94][10337-3-3-0.93]
[10403-0-4-0.87][10653-2-4-0.92][10704-2-2-0.95][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.94][11042-0-0-0.94][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.35][11499-0-0-0.99][11502-3-3--0.47][11512-3-3-0.99][11608-1-1-0.44][11610-0-0-0.98][11692-0-0-0.98][11905-0-0-0.97][11993-1-1-0.93][12002-2-0--0.09]
[12052-0-0-0.98][12201-0-0-0.75][12235-2-4-0.71][12320-1-4-0.93][12377-2-4-0.99][12398-2-4-0.26][12503-1-4-0.71][12617-0-0-0.25][12685-3-4-0.97][12738-2-4-0.49]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.35][13240-3-0-0.72][13253-1-1-0.46][13273-0-0-0.99][13634-1-4-0.64][13763-2-2-0.23][13905-3-0-0.08][14060-2-4-0.99]
[14065-3-0-0.21][14147-3-3-0.99][14595-2-2-0.61][14687-2-2-0.99][14788-2-2-0.80][14869-1-1-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-3-0.59][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.76][15375-3-3-0.37][15389-3-3-0.98][15568-2-4-0.97][15675-3-3-0.99][15869-1-0-0.78][16207-3-0-0.61][16236-0-0-0.21][16302-3-3-0.62]
[16331-2-2-0.99][16381-0-4-0.37][16488-1-1-0.96][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.97][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.75][17245-1-4-0.59]
[17278-3-0-0.17][17282-0-0-0.79][17311-2-2-0.83][17336-2-1-0.01][17608-3-3-0.99][17627-0-0-0.64][17877-3-4-0.99][17924-1-4-0.53][17984-3-3-0.99][18211-0-3-0.84]
[18276-3-3-0.48][18287-1-1-0.29][18394-0-0-0.99][18428-0-0-0.35][18442-0-3-0.82][18478-3-3-0.98][18607-0-0-0.99][18616-0-0-0.97][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.97][18890-3-3-0.91][18930-3-4-0.90][18938-3-3-0.75][19817-1-1-0.37][19839-0-0-0.75][19930-3-3-0.89][19944-0-4-0.90][20036-2-2-0.99]
[20101-3-3-0.79][20474-1-1-0.74][20547-3-4-0.99][20929-2-2-0.99][21245-1-4-0.41][21257-3-3-0.84][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.98][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.92][21714-0-0-0.70][21943-3-4-0.98][21947-0-0-0.82][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.95][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.47][22494-3-3-0.87][22757-0-0-0.99][22811-3-3-0.99][22976-3-4--0.03][22985-3-0-0.70][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.13]
[23219-0-0-0.68][23363-3-3-0.99][23470-0-0-0.55][23486-2-4-0.69][23497-0-0-0.90][23516-0-0-0.99][23690-1-4--0.08][23921-2-4-0.94][23936-1-2-0.82][24040-3-0-0.38]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-4-0.97][24345-0-0-0.99][24364-1-2--0.04][24427-3-0-0.73][24477-2-4-0.96][24495-2-4-0.86][24893-2-4-0.87]
[25012-1-4-0.56][25121-2-4-0.75][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.98][25644-1-2-0.85][25718-1-4-0.93][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.95][26321-1-1-0.70][26732-1-1-0.62][26784-3-3-0.99][26827-3-3-0.81][26833-0-0-0.96][26838-2-4-0.42][26860-1-4-0.14]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.41][27526-0-0-0.99][27639-3-3-0.98][27698-3-0-0.95][27772-0-0-0.99][27890-1-1-0.96][28040-0-4-0.39][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-3-0.61][30035-1-1-0.99][30098-0-0-0.96][30326-1-1-0.99][30572-2-2-0.98][30716-0-4-0.99]
[30806-2-2-0.55][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.07][31238-0-0-0.52][31347-0-0-0.99][31422-2-4-0.98][31429-3-3-0.60][31431-0-0-0.86][31432-1-1-0.59]
[31477-0-0-0.56][31524-1-4-0.70][31597-1-4-0.90][31619-1-4-0.59][31701-0-0-0.87][31755-0-0-0.99][31854-3-3-0.99][32074-1-3-0.91][32078-3-3-0.99][32111-1-1-0.84]
[32127-1-1-0.97][32140-3-3-0.49][32263-2-4-0.79][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.66][32473-3-3-0.94][32574-3-3-0.90][32584-0-4-0.97][32622-0-4-0.98]
[32858-3-3-0.56][32969-3-3-0.71][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.89][33133-2-2-0.97][33173-2-2-0.88][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.58]
[33474-0-0-0.90][33478-2-2--0.41][33618-1-4-0.99][33712-0-0-0.95][33782-2-4-0.99][33914-3-4-0.85][34076-3-4-0.98][34112-2-2-0.99][34138-2-3-0.92][34239-1-4-0.19]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-0-0.99][34783-2-4-0.81][35015-3-4-0.98][35018-1-1-0.78][35288-2-4-0.47][0-4-4-0.95][1-4-4-0.90][2-4-4-0.98]
[3-4-4-0.94][4-4-4-0.59][5-4-1--0.30][6-4-4-0.99][7-4-4-0.87][8-4-4-0.40][9-4-4-0.95][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-4-0.98][17-4-4-0.95][18-4-4-0.99][19-4-4-0.69][20-4-0-0.94][21-4-4-0.89][22-4-4-0.99][23-4-4-0.81]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.99][27-4-4-0.99][28-4-4-0.99][29-4-4-0.67][30-4-4-0.98][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.94][39-4-0-0.99][40-4-4-0.94][41-4-4-0.63][42-4-4-0.86][43-4-4-0.99][45-4-4-0.87][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.76][51-4-4-0.99][52-4-4-0.99][53-4-4-0.95][54-4-4-0.99][55-4-4-0.78][56-4-1-0.47][57-4-3-0.55][58-4-4-0.99]
[59-4-4-0.99][60-4-4-0.75][61-4-4-0.99][62-4-4-0.99][63-4-4-0.98][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.24][68-4-4-0.97]
[69-4-4-0.45][70-4-4-0.98][72-4-4-0.89][73-4-1-0.50][74-4-4-0.99][75-4-0-0.09][77-4-4-0.99][78-4-4-0.68][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.92][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.92][87-4-4-0.99][88-4-4-0.99][89-4-0-0.39][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.51][93-4-4-0.66][94-4-4-0.99][95-4-4-0.95][96-4-4-0.99][97-4-4-0.99][98-4-2-0.61][99-4-4-0.95][100-4-4-0.97]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.88][104-4-4-0.99][105-4-4-0.99][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.76][113-4-4-0.43][114-4-4-0.99][115-4-4-0.97][116-4-4-0.90][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.98][128-4-4-0.95][129-4-4-0.99][130-4-4-0.98][131-4-4-0.88][132-4-4-0.58][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.98][138-4-4-0.99][139-4-4-0.99][140-4-4-0.98][141-4-4-0.78][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.76]
[157-4-4-0.69][158-4-4-0.99][160-4-2--0.10][161-4-4-0.85][162-4-4-0.35][164-4-4-0.99][165-4-4-0.99][167-4-4-0.91][168-4-4-0.95][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.58][175-4-4-0.99][177-4-4-0.99][178-4-4-0.78][179-4-4-0.99][180-4-4-0.99][181-4-4-0.98]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.95][186-4-4-0.85][187-4-4-0.97][188-4-4-0.99][189-4-4--0.17][190-4-4-0.38][191-4-4-0.99][192-4-4-0.99]
[193-4-2-0.24][194-4-4-0.92][195-4-0-0.31][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-4-0.70]
---------------------------
I - Global maximum validation set accuracy:  70.41
I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.506 | Acc: 94.375% | Wgt Acc: 98.232%
	I - Batch: 100 | Loss: 0.505 | Acc: 94.688% | Wgt Acc: 98.427%
	I - Batch: 150 | Loss: 0.505 | Acc: 94.750% | Wgt Acc: 98.477%
	I - Batch: 200 | Loss: 0.504 | Acc: 94.688% | Wgt Acc: 98.424%
I - num batch: 222
I - Train -- Loss: 0.504 | Acc: 94.672% | Wgt Acc: 98.435% | LR: 2.500000e-05 | Dur: 133.35s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.  71.]
 [  0. 578.   0.   0.  26.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 536.  51.]
 [  2.   0.   0.   1. 815.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 69.428% | Wgt Acc: 60.743% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   1.   1.  13.   7.]
 [  0.  37.   3.   1.   3.]
 [  0.   8.  33.   0.   3.]
 [  6.   1.   6.  52.   2.]
 [ 17.  31.  32.  20. 165.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.503 | Acc: 95.500% | Wgt Acc: 98.760%
	I - Batch: 100 | Loss: 0.501 | Acc: 95.188% | Wgt Acc: 98.630%
	I - Batch: 150 | Loss: 0.501 | Acc: 95.042% | Wgt Acc: 98.615%
	I - Batch: 200 | Loss: 0.503 | Acc: 95.031% | Wgt Acc: 98.620%
I - num batch: 222
I - Train -- Loss: 0.503 | Acc: 94.869% | Wgt Acc: 98.574% | LR: 2.500000e-05 | Dur: 132.01s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  71.]
 [  0. 578.   0.   0.  28.]
 [  0.   0. 734.   0.  43.]
 [  0.   0.   0. 537.  39.]
 [  0.   0.   0.   1. 819.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 68.442% | Wgt Acc: 61.008% | Dur: 14.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 75.   4.   4.  16.  10.]
 [  0.  37.   3.   1.   3.]
 [  0.   6.  29.   0.   4.]
 [  2.   1.  10.  49.   6.]
 [ 11.  30.  29.  20. 157.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.499 | Acc: 95.125% | Wgt Acc: 98.547%
	I - Batch: 100 | Loss: 0.503 | Acc: 95.062% | Wgt Acc: 98.445%
	I - Batch: 150 | Loss: 0.501 | Acc: 95.208% | Wgt Acc: 98.526%
	I - Batch: 200 | Loss: 0.501 | Acc: 95.156% | Wgt Acc: 98.554%
I - num batch: 222
I - Train -- Loss: 0.502 | Acc: 95.123% | Wgt Acc: 98.531% | LR: 1.250000e-05 | Dur: 133.77s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  62.]
 [  0. 577.   0.   0.  15.]
 [  0.   0. 734.   0.  47.]
 [  0.   0.   0. 537.  44.]
 [  3.   1.   0.   1. 832.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 68.639% | Wgt Acc: 59.751% | Dur: 18.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   2.  15.   6.]
 [  0.  37.   2.   0.   2.]
 [  0.   7.  31.   0.   6.]
 [  2.   1.   6.  46.   2.]
 [ 16.  28.  34.  25. 164.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.500% | Wgt Acc: 99.105%
	I - Batch: 100 | Loss: 0.490 | Acc: 96.188% | Wgt Acc: 99.015%
	I - Batch: 150 | Loss: 0.492 | Acc: 96.167% | Wgt Acc: 99.003%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.906% | Wgt Acc: 98.938%
I - num batch: 208
I - Train -- Loss: 0.494 | Acc: 95.823% | Wgt Acc: 98.916% | LR: 1.250000e-05 | Dur: 125.80s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  35.]
 [  0.   0.   0. 538.  35.]
 [  0.   0.   0.   0. 642.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 68.047% | Wgt Acc: 59.866% | Dur: 14.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   3.   3.  16.   9.]
 [  0.  34.   3.   1.   2.]
 [  0.  11.  28.   0.   5.]
 [  4.   1.   8.  51.   4.]
 [ 12.  29.  33.  18. 160.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.500 | Acc: 95.500% | Wgt Acc: 98.628%
	I - Batch: 100 | Loss: 0.499 | Acc: 95.438% | Wgt Acc: 98.620%
	I - Batch: 150 | Loss: 0.498 | Acc: 95.833% | Wgt Acc: 98.775%
	I - Batch: 200 | Loss: 0.497 | Acc: 96.000% | Wgt Acc: 98.815%
I - num batch: 222
I - Train -- Loss: 0.497 | Acc: 95.715% | Wgt Acc: 98.720% | LR: 1.250000e-05 | Dur: 134.70s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  59.]
 [  0. 577.   0.   0.  18.]
 [  0.   0. 734.   0.  38.]
 [  0.   1.   0. 537.  33.]
 [  2.   0.   0.   1. 852.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 69.034% | Wgt Acc: 60.627% | Dur: 15.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   3.  15.   7.]
 [  0.  37.   2.   0.   2.]
 [  0.   9.  31.   0.   5.]
 [  5.   2.   8.  52.   3.]
 [ 16.  26.  31.  19. 163.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 96.125% | Wgt Acc: 98.959%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.500% | Wgt Acc: 98.987%
	I - Batch: 150 | Loss: 0.494 | Acc: 96.333% | Wgt Acc: 98.963%
	I - Batch: 200 | Loss: 0.495 | Acc: 96.062% | Wgt Acc: 98.865%
I - num batch: 222
I - Train -- Loss: 0.496 | Acc: 95.997% | Wgt Acc: 98.853% | LR: 1.250000e-05 | Dur: 133.36s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.  53.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  40.]
 [  0.   0.   0. 537.  26.]
 [  1.   0.   0.   0. 860.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.014 | Acc: 67.850% | Wgt Acc: 59.416% | Dur: 14.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   1.  14.   7.]
 [  0.  36.   5.   0.   3.]
 [  0.  11.  26.   0.   5.]
 [  4.   2.   8.  51.   4.]
 [ 14.  25.  35.  21. 161.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.502 | Acc: 95.500% | Wgt Acc: 98.789%
	I - Batch: 100 | Loss: 0.498 | Acc: 95.438% | Wgt Acc: 98.709%
	I - Batch: 150 | Loss: 0.498 | Acc: 95.292% | Wgt Acc: 98.682%
	I - Batch: 200 | Loss: 0.498 | Acc: 95.594% | Wgt Acc: 98.734%
I - num batch: 222
I - Train -- Loss: 0.498 | Acc: 95.405% | Wgt Acc: 98.665% | LR: 1.250000e-05 | Dur: 137.69s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  60.]
 [  1. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  41.]
 [  0.   0.   0. 537.  44.]
 [  1.   0.   0.   1. 840.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 69.034% | Wgt Acc: 60.339% | Dur: 16.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   0.  12.   5.]
 [  0.  36.   2.   1.   2.]
 [  0.   8.  32.   0.   7.]
 [  4.   2.   9.  49.   2.]
 [ 15.  29.  32.  24. 164.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.503 | Acc: 95.500% | Wgt Acc: 98.679%
	I - Batch: 100 | Loss: 0.500 | Acc: 95.500% | Wgt Acc: 98.668%
	I - Batch: 150 | Loss: 0.500 | Acc: 95.375% | Wgt Acc: 98.620%
	I - Batch: 200 | Loss: 0.499 | Acc: 95.781% | Wgt Acc: 98.760%
I - num batch: 222
I - Train -- Loss: 0.499 | Acc: 95.771% | Wgt Acc: 98.764% | LR: 1.250000e-05 | Dur: 134.86s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  52.]
 [  0. 578.   0.   0.  23.]
 [  0.   0. 734.   0.  45.]
 [  0.   0.   0. 537.  27.]
 [  2.   0.   0.   1. 853.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 67.653% | Wgt Acc: 58.309% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   1.   8.   4.]
 [  0.  37.   3.   0.   1.]
 [  0.  11.  31.   0.   8.]
 [  4.   3.   8.  50.   2.]
 [ 24.  26.  32.  28. 165.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 96.125% | Wgt Acc: 98.965%
	I - Batch: 100 | Loss: 0.495 | Acc: 95.438% | Wgt Acc: 98.780%
	I - Batch: 150 | Loss: 0.498 | Acc: 95.083% | Wgt Acc: 98.630%
	I - Batch: 200 | Loss: 0.499 | Acc: 95.125% | Wgt Acc: 98.651%
I - num batch: 222
I - Train -- Loss: 0.499 | Acc: 95.179% | Wgt Acc: 98.659% | LR: 1.250000e-05 | Dur: 135.78s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  56.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  52.]
 [  0.   0.   0. 537.  41.]
 [  0.   0.   0.   1. 830.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 67.456% | Wgt Acc: 57.225% | Dur: 15.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   1.   2.  11.   4.]
 [  0.  36.   2.   0.   3.]
 [  0.  10.  24.   0.   1.]
 [  8.   2.   8.  51.   3.]
 [ 18.  29.  39.  24. 169.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.494 | Acc: 96.125% | Wgt Acc: 98.831%
	I - Batch: 100 | Loss: 0.497 | Acc: 96.000% | Wgt Acc: 98.728%
	I - Batch: 150 | Loss: 0.497 | Acc: 95.875% | Wgt Acc: 98.657%
	I - Batch: 200 | Loss: 0.497 | Acc: 95.938% | Wgt Acc: 98.671%
I - num batch: 222
I - Train -- Loss: 0.496 | Acc: 95.827% | Wgt Acc: 98.669% | LR: 1.250000e-05 | Dur: 134.49s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  59.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 731.   0.  36.]
 [  1.   0.   0. 537.  30.]
 [  2.   0.   3.   1. 859.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.980 | Acc: 71.203% | Wgt Acc: 62.588% | Dur: 14.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   3.   9.   3.]
 [  0.  42.   4.   0.   3.]
 [  0.  10.  34.   1.   4.]
 [  6.   1.   7.  53.   2.]
 [ 18.  23.  27.  23. 168.]]

I - Local maximum validation set accuracy:  71.20

I - Validation set results: 
[14-1-2-0.35][50-3-4-0.84][124-2-4-0.77][127-0-0-0.99][443-2-2-0.91][567-0-0-0.47][573-1-1-0.99][615-0-0-0.66][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.98][1103-0-4-0.87][1212-3-4-0.76][1368-0-0-0.99][2181-2-3-0.23][2476-2-2-0.98][2721-2-2-0.98][2818-1-1-0.99][2886-2-4-0.50]
[3231-2-2-0.99][3333-2-2-0.22][3482-2-2-0.64][3536-3-4-0.11][3625-1-1-0.47][3909-0-0-0.98][4035-0-0-0.99][4140-0-0-0.88][4214-1-1-0.11][4346-1-4-0.62]
[4581-2-4-0.50][4708-3-4-0.99][4838-3-4-0.46][4845-1-4-0.82][4868-0-0-0.88][4939-0-4-0.33][4984-2-2--0.15][5078-1-2-0.58][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.87][5843-1-1-0.19][5949-3-3-0.50][5987-2-4-0.99][6014-3-3-0.93][6033-3-3--0.53][6313-0-0-0.39][6421-3-3--0.12][6500-1-1-0.51][6583-3-3-0.97]
[6683-3-3-0.91][6825-2-1-0.97][6998-3-0--0.50][7049-3-3-0.94][7517-1-1-0.81][7521-1-1-0.66][7528-1-1--0.62][7949-1-2-0.98][8135-1-4-0.31][8185-3-0-0.99]
[8269-3-4-0.60][8273-3-3-0.99][8543-3-0-0.98][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.95][9001-2-4-0.61][9036-2-2-0.99][9281-3-4-0.45][9300-2-2-0.99]
[9571-0-4-0.87][9617-1-1-0.80][9644-2-2-0.71][9705-2-4-0.91][9801-0-0-0.37][9803-3-3-0.56][9865-3-3-0.99][9896-2-4-0.99][10314-1-4-0.98][10337-3-3-0.78]
[10403-0-4-0.99][10653-2-4-0.96][10704-2-2-0.79][10719-1-1-0.99][10727-1-4-0.98][10836-0-0-0.99][10969-2-3-0.32][11042-0-0-0.59][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0-0.96][11502-3-2--0.07][11512-3-3-0.53][11608-1-2-0.63][11610-0-0-0.44][11692-0-0-0.88][11905-0-0-0.88][11993-1-1-0.97][12002-2-0-0.70]
[12052-0-0-0.99][12201-0-0-0.55][12235-2-4-0.59][12320-1-4-0.99][12377-2-4-0.99][12398-2-4-0.66][12503-1-4-0.99][12617-0-0--0.24][12685-3-4-0.81][12738-2-0-0.66]
[12742-2-2-0.99][12823-0-0-0.67][13110-1-4-0.77][13240-3-4-0.94][13253-1-0-0.55][13273-0-0-0.99][13634-1-4-0.78][13763-2-2-0.47][13905-3-4--0.29][14060-2-4-0.98]
[14065-3-0-0.23][14147-3-3-0.92][14595-2-2-0.97][14687-2-2-0.99][14788-2-2-0.77][14869-1-1-0.86][14872-3-4-0.98][14877-1-1-0.99][14927-0-3-0.31][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.49][15375-3-3-0.28][15389-3-3-0.99][15568-2-4-0.95][15675-3-3-0.99][15869-1-4--0.00][16207-3-0-0.27][16236-0-0-0.99][16302-3-3-0.99]
[16331-2-2-0.99][16381-0-4-0.43][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.75][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.62][17245-1-4-0.99]
[17278-3-4--0.29][17282-0-0-0.89][17311-2-2-0.81][17336-2-1-0.92][17608-3-3-0.99][17627-0-0-0.99][17877-3-4-0.99][17924-1-2-0.38][17984-3-3-0.99][18211-0-0-0.30]
[18276-3-3-0.78][18287-1-1-0.64][18394-0-0-0.99][18428-0-0--0.35][18442-0-3-0.44][18478-3-3-0.95][18607-0-0-0.99][18616-0-0-0.95][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.98][18890-3-3-0.79][18930-3-4-0.86][18938-3-3-0.75][19817-1-1-0.51][19839-0-0-0.60][19930-3-3-0.76][19944-0-4-0.98][20036-2-2-0.99]
[20101-3-3-0.81][20474-1-1-0.80][20547-3-4-0.97][20929-2-2-0.99][21245-1-1-0.09][21257-3-3-0.58][21293-1-1-0.99][21316-1-1--0.08][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.10][21714-0-4-0.47][21943-3-4-0.86][21947-0-0-0.96][21948-0-0-0.99][21965-2-2-0.92][21998-1-1-0.97][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-4-0.59][22494-3-3-0.18][22757-0-0-0.99][22811-3-3-0.99][22976-3-4--0.23][22985-3-0-0.35][23014-0-0-0.89][23112-1-1-0.99][23144-3-3-0.99][23168-2-3-0.38]
[23219-0-0-0.91][23363-3-3-0.72][23470-0-0-0.58][23486-2-4-0.50][23497-0-3-0.80][23516-0-0-0.99][23690-1-4-0.94][23921-2-1-0.61][23936-1-2-0.80][24040-3-4-0.77]
[24111-1-4-0.99][24182-0-0-0.97][24238-3-3-0.99][24290-2-0-0.98][24345-0-4-0.58][24364-1-2-0.12][24427-3-4-0.97][24477-2-4-0.85][24495-2-4-0.87][24893-2-2-0.69]
[25012-1-4-0.65][25121-2-2-0.80][25165-3-3-0.99][25183-0-4-0.96][25297-3-3-0.99][25398-0-0-0.83][25574-2-4-0.96][25644-1-1-0.99][25718-1-4-0.91][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.98][26120-0-4-0.99][26321-1-1-0.48][26732-1-1-0.43][26784-3-3-0.99][26827-3-3-0.83][26833-0-3-0.94][26838-2-4-0.33][26860-1-4-0.94]
[26948-0-0-0.98][27049-3-0-0.97][27098-1-0-0.34][27526-0-0-0.76][27639-3-3-0.98][27698-3-0-0.76][27772-0-0-0.99][27890-1-1-0.95][28040-0-4-0.68][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-1--0.10][30035-1-1-0.99][30098-0-4-0.16][30326-1-1-0.99][30572-2-2-0.99][30716-0-4-0.99]
[30806-2-2-0.56][30906-1-1-0.99][31007-0-4-0.83][31181-3-3-0.21][31238-0-3-0.60][31347-0-0-0.98][31422-2-4-0.94][31429-3-3-0.27][31431-0-0-0.60][31432-1-1-0.77]
[31477-0-3-0.59][31524-1-4-0.79][31597-1-1-0.93][31619-1-4-0.70][31701-0-0-0.96][31755-0-0-0.99][31854-3-3-0.91][32074-1-1-0.46][32078-3-3-0.99][32111-1-1-0.90]
[32127-1-1-0.99][32140-3-3-0.64][32263-2-4-0.84][32365-0-0-0.99][32411-2-3-0.98][32429-3-3-0.96][32473-3-3-0.87][32574-3-3-0.99][32584-0-4-0.99][32622-0-4-0.70]
[32858-3-3-0.59][32969-3-3-0.89][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.74][33133-2-2-0.99][33173-2-2-0.64][33175-3-4-0.99][33306-3-3-0.98][33309-2-3-0.96]
[33474-0-4-0.73][33478-2-4-0.43][33618-1-4-0.99][33712-0-0-0.86][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.85][34112-2-2-0.97][34138-2-3-0.33][34239-1-1-0.24]
[34364-2-2-0.99][34617-1-4-0.86][34751-3-0-0.96][34783-2-4-0.99][35015-3-4-0.99][35018-1-4-0.69][35288-2-4-0.50][0-4-4-0.99][1-4-4-0.99][2-4-4-0.98]
[3-4-4-0.85][4-4-4-0.97][5-4-1--0.17][6-4-4-0.99][7-4-4-0.91][8-4-4-0.56][9-4-4-0.75][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.94][16-4-4-0.94][17-4-4-0.83][18-4-4-0.99][19-4-4-0.96][20-4-4-0.64][21-4-4-0.86][22-4-4-0.99][23-4-4-0.94]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.85][27-4-4-0.99][28-4-4-0.99][29-4-4-0.46][30-4-4-0.96][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.98][39-4-0-0.98][40-4-4-0.96][41-4-4-0.90][42-4-4-0.72][43-4-4-0.99][45-4-4-0.95][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.88][51-4-4-0.99][52-4-4-0.95][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-4-0.64][57-4-4-0.59][58-4-4-0.86]
[59-4-4-0.99][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.86][64-4-4-0.99][65-4-4-0.99][66-4-4-0.64][67-4-2-0.90][68-4-4-0.94]
[69-4-4-0.42][70-4-4-0.99][72-4-4-0.98][73-4-1-0.87][74-4-4-0.99][75-4-3-0.38][77-4-4-0.99][78-4-4-0.95][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.74][82-4-4-0.95][83-4-4-0.90][84-4-4-0.99][85-4-4-0.99][86-4-4-0.87][87-4-4-0.99][88-4-4-0.99][89-4-4-0.95][90-4-4-0.97]
[91-4-4-0.99][92-4-4-0.67][93-4-4-0.80][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-2-0.96][99-4-4-0.98][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.94][103-4-4-0.36][104-4-4-0.99][105-4-4-0.69][106-4-4-0.99][107-4-4-0.99][108-4-4-0.53][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.72][113-4-4-0.19][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.95][128-4-4-0.98][129-4-4-0.98][130-4-4-0.98][131-4-4-0.58][132-4-4-0.79][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.94][137-4-4-0.98][138-4-4-0.99][139-4-4-0.99][140-4-4-0.97][141-4-4-0.76][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.98][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.87]
[157-4-4-0.58][158-4-4-0.99][160-4-4-0.89][161-4-4-0.98][162-4-4--0.49][164-4-4-0.99][165-4-4-0.99][167-4-4-0.99][168-4-4-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-4-0.76][175-4-4-0.83][177-4-4-0.98][178-4-4-0.99][179-4-4-0.97][180-4-4-0.99][181-4-4-0.99]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.98][186-4-4-0.81][187-4-4-0.54][188-4-4-0.99][189-4-4-0.10][190-4-4-0.96][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.52][194-4-4-0.68][195-4-4-0.73][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-2-0.09]
---------------------------
I - Global maximum validation set accuracy:  71.20
I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.503 | Acc: 94.500% | Wgt Acc: 98.122%
	I - Batch: 100 | Loss: 0.497 | Acc: 95.500% | Wgt Acc: 98.591%
	I - Batch: 150 | Loss: 0.496 | Acc: 95.625% | Wgt Acc: 98.639%
	I - Batch: 200 | Loss: 0.496 | Acc: 95.531% | Wgt Acc: 98.631%
I - num batch: 222
I - Train -- Loss: 0.497 | Acc: 95.405% | Wgt Acc: 98.604% | LR: 1.250000e-05 | Dur: 136.23s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  60.]
 [  0. 578.   0.   0.  25.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 535.  36.]
 [  2.   0.   0.   3. 842.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 68.047% | Wgt Acc: 58.701% | Dur: 15.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.   9.   5.]
 [  0.  37.   3.   1.   3.]
 [  0.   8.  24.   0.   4.]
 [  5.   1.   8.  53.   2.]
 [ 18.  29.  39.  23. 166.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.498 | Acc: 95.250% | Wgt Acc: 98.679%
	I - Batch: 100 | Loss: 0.494 | Acc: 95.750% | Wgt Acc: 98.831%
	I - Batch: 150 | Loss: 0.495 | Acc: 96.000% | Wgt Acc: 98.864%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.906% | Wgt Acc: 98.849%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 95.968% | Wgt Acc: 98.873% | LR: 1.250000e-05 | Dur: 134.90s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.  52.]
 [  0. 578.   0.   0.  24.]
 [  0.   0. 734.   0.  32.]
 [  0.   0.   0. 537.  34.]
 [  0.   0.   0.   0. 858.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 68.245% | Wgt Acc: 59.958% | Dur: 14.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   5.   2.  12.   7.]
 [  0.  37.   2.   1.   3.]
 [  0.   9.  30.   0.   6.]
 [  5.   2.   7.  51.   3.]
 [ 16.  25.  34.  22. 161.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.495 | Acc: 95.125% | Wgt Acc: 98.546%
	I - Batch: 100 | Loss: 0.494 | Acc: 95.875% | Wgt Acc: 98.825%
	I - Batch: 150 | Loss: 0.494 | Acc: 96.000% | Wgt Acc: 98.882%
	I - Batch: 200 | Loss: 0.497 | Acc: 95.875% | Wgt Acc: 98.790%
I - num batch: 222
I - Train -- Loss: 0.496 | Acc: 95.940% | Wgt Acc: 98.814% | LR: 1.250000e-05 | Dur: 134.98s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  50.]
 [  0. 578.   0.   0.  25.]
 [  0.   0. 733.   0.  26.]
 [  0.   0.   0. 538.  40.]
 [  2.   0.   1.   0. 859.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 69.034% | Wgt Acc: 60.316% | Dur: 14.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   2.   1.  17.   7.]
 [  0.  38.   3.   1.   2.]
 [  0.  10.  29.   0.   5.]
 [  3.   2.   7.  47.   2.]
 [ 13.  26.  35.  21. 164.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 95.875% | Wgt Acc: 98.865%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.375% | Wgt Acc: 99.009%
	I - Batch: 150 | Loss: 0.493 | Acc: 96.250% | Wgt Acc: 98.931%
	I - Batch: 200 | Loss: 0.494 | Acc: 96.094% | Wgt Acc: 98.873%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 96.109% | Wgt Acc: 98.884% | LR: 1.250000e-05 | Dur: 133.48s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  56.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  31.]
 [  0.   0.   0. 537.  31.]
 [  1.   0.   0.   1. 864.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 68.047% | Wgt Acc: 59.001% | Dur: 14.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   1.  14.   8.]
 [  0.  37.   5.   0.   3.]
 [  0.   9.  27.   0.   4.]
 [  3.   1.   6.  48.   1.]
 [ 16.  26.  36.  24. 164.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.500 | Acc: 95.000% | Wgt Acc: 98.501%
	I - Batch: 100 | Loss: 0.494 | Acc: 96.000% | Wgt Acc: 98.803%
	I - Batch: 150 | Loss: 0.494 | Acc: 96.042% | Wgt Acc: 98.801%
	I - Batch: 200 | Loss: 0.494 | Acc: 96.250% | Wgt Acc: 98.882%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 96.250% | Wgt Acc: 98.864% | LR: 1.250000e-05 | Dur: 133.08s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.  57.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  27.]
 [  1.   0.   0. 536.  29.]
 [  1.   0.   0.   1. 871.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 68.245% | Wgt Acc: 58.113% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   3.   2.  18.   6.]
 [  0.  33.   2.   1.   0.]
 [  0.   6.  27.   0.   3.]
 [  3.   1.   5.  45.   2.]
 [ 13.  35.  39.  22. 169.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 96.750% | Wgt Acc: 99.100%
	I - Batch: 100 | Loss: 0.491 | Acc: 96.812% | Wgt Acc: 99.134%
	I - Batch: 150 | Loss: 0.494 | Acc: 96.542% | Wgt Acc: 99.020%
	I - Batch: 200 | Loss: 0.495 | Acc: 96.375% | Wgt Acc: 98.984%
I - num batch: 222
I - Train -- Loss: 0.495 | Acc: 96.279% | Wgt Acc: 98.961% | LR: 1.250000e-05 | Dur: 134.72s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  22.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 538.  33.]
 [  1.   0.   0.   0. 869.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.456% | Wgt Acc: 57.502% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   1.  17.   7.]
 [  0.  36.   2.   1.   1.]
 [  0.   8.  25.   0.   3.]
 [  5.   2.   8.  45.   2.]
 [ 14.  27.  39.  23. 167.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 97.125% | Wgt Acc: 99.213%
	I - Batch: 100 | Loss: 0.494 | Acc: 96.562% | Wgt Acc: 99.057%
	I - Batch: 150 | Loss: 0.495 | Acc: 96.333% | Wgt Acc: 98.996%
	I - Batch: 200 | Loss: 0.493 | Acc: 96.500% | Wgt Acc: 99.050%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 96.250% | Wgt Acc: 98.981% | LR: 1.250000e-05 | Dur: 134.95s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  53.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  33.]
 [  0.   0.   0. 538.  26.]
 [  0.   0.   0.   0. 867.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.997 | Acc: 68.639% | Wgt Acc: 59.232% | Dur: 14.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   1.  15.   7.]
 [  0.  36.   2.   0.   3.]
 [  0.   7.  24.   0.   1.]
 [  7.   2.   7.  51.   2.]
 [ 11.  29.  41.  20. 167.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.500 | Acc: 95.375% | Wgt Acc: 98.579%
	I - Batch: 100 | Loss: 0.494 | Acc: 96.250% | Wgt Acc: 98.916%
	I - Batch: 150 | Loss: 0.497 | Acc: 95.625% | Wgt Acc: 98.720%
	I - Batch: 200 | Loss: 0.496 | Acc: 96.094% | Wgt Acc: 98.871%
I - num batch: 222
I - Train -- Loss: 0.496 | Acc: 95.884% | Wgt Acc: 98.792% | LR: 1.250000e-05 | Dur: 134.51s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  50.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 536.  37.]
 [  1.   0.   0.   2. 857.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 70.414% | Wgt Acc: 61.827% | Dur: 14.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   3.   1.  13.   6.]
 [  0.  40.   2.   0.   2.]
 [  0.   7.  30.   0.   3.]
 [  2.   1.   8.  49.   3.]
 [ 14.  27.  34.  24. 166.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.501 | Acc: 94.625% | Wgt Acc: 98.249%
	I - Batch: 100 | Loss: 0.495 | Acc: 95.625% | Wgt Acc: 98.674%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.958% | Wgt Acc: 98.810%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.812% | Wgt Acc: 98.802%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 95.827% | Wgt Acc: 98.807% | LR: 1.250000e-05 | Dur: 135.82s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  54.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  40.]
 [  0.   0.   0. 537.  31.]
 [  1.   0.   0.   1. 854.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 67.061% | Wgt Acc: 57.663% | Dur: 14.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   0.   1.  14.   8.]
 [  0.  38.   3.   1.   2.]
 [  0.   4.  24.   0.   4.]
 [  6.   1.   8.  47.   2.]
 [ 15.  35.  39.  24. 164.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.494 | Acc: 95.750% | Wgt Acc: 98.850%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.938% | Wgt Acc: 98.891%
	I - Batch: 150 | Loss: 0.494 | Acc: 95.500% | Wgt Acc: 98.783%
	I - Batch: 200 | Loss: 0.495 | Acc: 95.719% | Wgt Acc: 98.836%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 95.771% | Wgt Acc: 98.850% | LR: 1.250000e-05 | Dur: 135.33s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  69.]
 [  0. 578.   0.   0.  20.]
 [  0.   0. 734.   0.  31.]
 [  0.   0.   0. 538.  30.]
 [  0.   0.   0.   0. 850.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 67.850% | Wgt Acc: 59.440% | Dur: 14.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   1.   2.  15.   6.]
 [  0.  38.   3.   1.   3.]
 [  0.   9.  26.   0.   8.]
 [  7.   1.  11.  51.   2.]
 [ 13.  29.  33.  19. 161.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.495 | Acc: 95.500% | Wgt Acc: 98.783%
	I - Batch: 100 | Loss: 0.497 | Acc: 95.500% | Wgt Acc: 98.711%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.708% | Wgt Acc: 98.799%
	I - Batch: 200 | Loss: 0.493 | Acc: 96.031% | Wgt Acc: 98.895%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 96.166% | Wgt Acc: 98.930% | LR: 1.250000e-05 | Dur: 136.10s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  50.]
 [  0. 578.   0.   0.  23.]
 [  0.   0. 734.   0.  41.]
 [  0.   0.   0. 538.  21.]
 [  1.   0.   0.   0. 865.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 67.258% | Wgt Acc: 58.355% | Dur: 14.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   2.  14.   9.]
 [  0.  31.   2.   0.   2.]
 [  0.   9.  28.   0.   6.]
 [  5.   5.   9.  51.   1.]
 [ 14.  29.  34.  21. 162.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.498 | Acc: 95.750% | Wgt Acc: 98.475%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.812% | Wgt Acc: 98.699%
	I - Batch: 150 | Loss: 0.496 | Acc: 95.292% | Wgt Acc: 98.597%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.781% | Wgt Acc: 98.760%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 95.771% | Wgt Acc: 98.761% | LR: 1.250000e-05 | Dur: 135.74s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.  62.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  35.]
 [  0.   0.   0. 536.  34.]
 [  1.   0.   0.   1. 853.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 67.061% | Wgt Acc: 57.329% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   3.  16.   5.]
 [  0.  35.   3.   1.   2.]
 [  0.   9.  29.   0.   5.]
 [  4.   2.   8.  43.   3.]
 [ 16.  28.  32.  26. 165.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 96.375% | Wgt Acc: 98.870%
	I - Batch: 100 | Loss: 0.494 | Acc: 95.812% | Wgt Acc: 98.729%
	I - Batch: 150 | Loss: 0.493 | Acc: 96.042% | Wgt Acc: 98.828%
	I - Batch: 200 | Loss: 0.491 | Acc: 96.281% | Wgt Acc: 98.924%
I - num batch: 222
I - Train -- Loss: 0.492 | Acc: 96.138% | Wgt Acc: 98.864% | LR: 1.250000e-05 | Dur: 135.69s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  38.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   1.  38.]
 [  0.   0.   0. 537.  41.]
 [  2.   0.   0.   0. 866.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 67.258% | Wgt Acc: 58.759% | Dur: 14.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  14.   8.]
 [  0.  32.   3.   0.   2.]
 [  0.   9.  31.   0.   7.]
 [  5.   2.   9.  50.   3.]
 [ 15.  32.  31.  22. 160.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 95.625% | Wgt Acc: 98.816%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.375% | Wgt Acc: 99.017%
	I - Batch: 150 | Loss: 0.495 | Acc: 96.167% | Wgt Acc: 98.867%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.875% | Wgt Acc: 98.782%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 95.940% | Wgt Acc: 98.812% | LR: 1.250000e-05 | Dur: 136.00s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  59.]
 [  0. 577.   0.   0.  22.]
 [  0.   0. 734.   0.  28.]
 [  0.   0.   0. 538.  32.]
 [  2.   1.   0.   0. 859.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 67.456% | Wgt Acc: 57.710% | Dur: 15.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   0.  13.   6.]
 [  0.  34.   3.   1.   1.]
 [  0.   5.  28.   0.   4.]
 [  5.   1.   8.  46.   3.]
 [ 15.  34.  36.  26. 166.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 99.049%
	I - Batch: 100 | Loss: 0.492 | Acc: 95.750% | Wgt Acc: 98.658%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.125% | Wgt Acc: 98.789%
	I - Batch: 200 | Loss: 0.492 | Acc: 96.000% | Wgt Acc: 98.790%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.109% | Wgt Acc: 98.829% | LR: 1.250000e-05 | Dur: 135.37s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  40.]
 [  0.   0.   0. 537.  32.]
 [  3.   0.   0.   1. 866.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 69.625% | Wgt Acc: 61.031% | Dur: 19.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  10.   5.]
 [  0.  39.   3.   0.   3.]
 [  0.  10.  27.   0.   4.]
 [  7.   1.   9.  52.   3.]
 [ 11.  25.  35.  24. 165.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.501 | Acc: 95.500% | Wgt Acc: 98.610%
	I - Batch: 100 | Loss: 0.496 | Acc: 96.125% | Wgt Acc: 98.881%
	I - Batch: 150 | Loss: 0.495 | Acc: 96.125% | Wgt Acc: 98.898%
	I - Batch: 200 | Loss: 0.494 | Acc: 96.125% | Wgt Acc: 98.887%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 95.997% | Wgt Acc: 98.856% | LR: 1.250000e-05 | Dur: 135.70s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  63.]
 [  0. 578.   0.   0.  23.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  31.]
 [  2.   0.   0.   0. 860.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.011 | Acc: 67.850% | Wgt Acc: 58.321% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   2.  11.   4.]
 [  0.  33.   3.   2.   3.]
 [  0.   9.  31.   0.   4.]
 [  5.   1.   7.  50.   3.]
 [ 19.  33.  32.  23. 166.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.494 | Acc: 96.500% | Wgt Acc: 99.031%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.750% | Wgt Acc: 99.040%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.500% | Wgt Acc: 98.961%
	I - Batch: 200 | Loss: 0.491 | Acc: 96.406% | Wgt Acc: 98.927%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.391% | Wgt Acc: 98.902% | LR: 1.250000e-05 | Dur: 135.45s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  22.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 536.  32.]
 [  2.   0.   0.   2. 876.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.653% | Wgt Acc: 58.033% | Dur: 16.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   1.  12.   6.]
 [  0.  37.   4.   0.   1.]
 [  0.  10.  32.   0.   5.]
 [  5.   1.   4.  47.   2.]
 [ 22.  28.  34.  27. 166.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.498 | Acc: 94.125% | Wgt Acc: 98.394%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.312% | Wgt Acc: 98.726%
	I - Batch: 150 | Loss: 0.494 | Acc: 95.542% | Wgt Acc: 98.739%
	I - Batch: 200 | Loss: 0.493 | Acc: 95.500% | Wgt Acc: 98.715%
I - num batch: 222
I - Train -- Loss: 0.494 | Acc: 95.235% | Wgt Acc: 98.648% | LR: 1.250000e-05 | Dur: 137.33s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  67.]
 [  0. 577.   0.   0.  24.]
 [  0.   0. 734.   0.  39.]
 [  0.   0.   0. 538.  37.]
 [  1.   1.   0.   0. 833.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 66.667% | Wgt Acc: 56.533% | Dur: 14.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   3.   1.  11.   4.]
 [  0.  38.   3.   0.   2.]
 [  0.   6.  22.   0.   3.]
 [  4.   2.   7.  48.   4.]
 [ 21.  29.  42.  27. 167.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.498 | Acc: 95.750% | Wgt Acc: 98.707%
	I - Batch: 100 | Loss: 0.495 | Acc: 96.250% | Wgt Acc: 98.907%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.875% | Wgt Acc: 98.827%
	I - Batch: 200 | Loss: 0.494 | Acc: 95.688% | Wgt Acc: 98.762%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 95.912% | Wgt Acc: 98.803% | LR: 1.250000e-05 | Dur: 134.25s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  57.]
 [  0. 578.   0.   0.  25.]
 [  0.   0. 734.   0.  32.]
 [  0.   0.   0. 537.  28.]
 [  2.   0.   0.   1. 858.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 69.231% | Wgt Acc: 61.469% | Dur: 16.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   5.   2.  15.   7.]
 [  0.  39.   3.   0.   5.]
 [  0.   9.  32.   0.   5.]
 [  5.   1.   9.  49.   3.]
 [ 12.  24.  29.  22. 160.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 94.875% | Wgt Acc: 98.624%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.375% | Wgt Acc: 98.677%
	I - Batch: 150 | Loss: 0.492 | Acc: 95.833% | Wgt Acc: 98.828%
	I - Batch: 200 | Loss: 0.492 | Acc: 96.031% | Wgt Acc: 98.887%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.081% | Wgt Acc: 98.907% | LR: 1.250000e-05 | Dur: 134.97s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 734.   0.  40.]
 [  0.   0.   0. 538.  31.]
 [  1.   0.   0.   0. 862.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.030 | Acc: 67.258% | Wgt Acc: 57.410% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   5.   2.  15.   6.]
 [  0.  31.   2.   0.   2.]
 [  0.   5.  25.   0.   3.]
 [  2.   2.   7.  46.   3.]
 [ 13.  35.  39.  25. 166.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.000% | Wgt Acc: 98.969%
	I - Batch: 100 | Loss: 0.487 | Acc: 96.125% | Wgt Acc: 98.998%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.417% | Wgt Acc: 99.065%
	I - Batch: 200 | Loss: 0.487 | Acc: 96.281% | Wgt Acc: 99.003%
I - num batch: 208
I - Train -- Loss: 0.487 | Acc: 96.274% | Wgt Acc: 99.004% | LR: 1.250000e-05 | Dur: 127.17s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  46.]
 [  0. 577.   0.   0.  16.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  37.]
 [  0.   1.   0.   0. 658.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.258% | Wgt Acc: 57.525% | Dur: 14.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   1.  18.   5.]
 [  0.  31.   2.   0.   1.]
 [  0.   6.  32.   0.   5.]
 [  1.   2.   6.  42.   4.]
 [ 16.  35.  34.  26. 165.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 95.500% | Wgt Acc: 98.766%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.375% | Wgt Acc: 98.683%
	I - Batch: 150 | Loss: 0.491 | Acc: 95.917% | Wgt Acc: 98.853%
	I - Batch: 200 | Loss: 0.490 | Acc: 96.250% | Wgt Acc: 98.953%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.222% | Wgt Acc: 98.915% | LR: 1.250000e-05 | Dur: 135.17s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  53.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  30.]
 [  0.   0.   0. 537.  32.]
 [  1.   0.   0.   1. 868.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 67.061% | Wgt Acc: 55.887% | Dur: 15.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   1.   0.  12.   2.]
 [  0.  34.   2.   0.   2.]
 [  0.   4.  27.   0.   1.]
 [  4.   2.   8.  44.   3.]
 [ 21.  37.  38.  30. 172.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 96.500% | Wgt Acc: 98.790%
	I - Batch: 100 | Loss: 0.493 | Acc: 96.188% | Wgt Acc: 98.627%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.167% | Wgt Acc: 98.741%
	I - Batch: 200 | Loss: 0.490 | Acc: 96.281% | Wgt Acc: 98.832%
I - num batch: 222
I - Train -- Loss: 0.490 | Acc: 96.194% | Wgt Acc: 98.821% | LR: 1.250000e-05 | Dur: 134.89s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 536.  32.]
 [  3.   0.   0.   2. 870.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.982 | Acc: 69.822% | Wgt Acc: 61.331% | Dur: 17.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   0.   8.   8.]
 [  0.  36.   2.   0.   2.]
 [  0.   8.  31.   0.   4.]
 [  5.   2.   9.  55.   1.]
 [ 16.  28.  33.  23. 165.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.490 | Acc: 96.250% | Wgt Acc: 98.968%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.188% | Wgt Acc: 98.893%
	I - Batch: 150 | Loss: 0.492 | Acc: 96.125% | Wgt Acc: 98.859%
	I - Batch: 200 | Loss: 0.492 | Acc: 96.000% | Wgt Acc: 98.844%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 95.968% | Wgt Acc: 98.817% | LR: 1.250000e-05 | Dur: 135.02s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  63.]
 [  0. 577.   0.   0.  10.]
 [  0.   0. 734.   0.  32.]
 [  0.   0.   0. 537.  35.]
 [  1.   1.   0.   1. 860.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 69.231% | Wgt Acc: 60.374% | Dur: 14.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   2.   0.  12.   3.]
 [  0.  34.   3.   0.   2.]
 [  0.  10.  31.   0.   5.]
 [  3.   2.   7.  49.   5.]
 [ 13.  30.  34.  25. 165.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 95.750% | Wgt Acc: 98.849%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.250% | Wgt Acc: 98.978%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.125% | Wgt Acc: 98.944%
	I - Batch: 200 | Loss: 0.489 | Acc: 96.406% | Wgt Acc: 99.025%
I - num batch: 222
I - Train -- Loss: 0.490 | Acc: 96.391% | Wgt Acc: 99.019% | LR: 1.250000e-05 | Dur: 134.70s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  47.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  45.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 872.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 68.442% | Wgt Acc: 58.551% | Dur: 15.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   1.  15.   5.]
 [  0.  34.   3.   0.   1.]
 [  0.   6.  26.   0.   3.]
 [  5.   2.   8.  52.   2.]
 [ 17.  33.  37.  19. 169.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.750% | Wgt Acc: 99.014%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.438% | Wgt Acc: 98.981%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.500% | Wgt Acc: 99.017%
	I - Batch: 200 | Loss: 0.492 | Acc: 96.312% | Wgt Acc: 98.968%
I - num batch: 222
I - Train -- Loss: 0.493 | Acc: 96.138% | Wgt Acc: 98.895% | LR: 1.250000e-05 | Dur: 135.67s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  55.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  29.]
 [  1.   0.   0. 538.  30.]
 [  1.   0.   0.   0. 865.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 67.653% | Wgt Acc: 58.413% | Dur: 14.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  14.   7.]
 [  0.  38.   3.   1.   2.]
 [  0.   8.  28.   0.   5.]
 [  2.   1.   7.  45.   2.]
 [ 18.  28.  36.  26. 164.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 95.875% | Wgt Acc: 98.874%
	I - Batch: 100 | Loss: 0.490 | Acc: 96.250% | Wgt Acc: 98.854%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.292% | Wgt Acc: 98.865%
	I - Batch: 200 | Loss: 0.490 | Acc: 96.375% | Wgt Acc: 98.923%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.391% | Wgt Acc: 98.935% | LR: 1.250000e-05 | Dur: 137.37s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  47.]
 [  0. 577.   0.   0.  18.]
 [  0.   0. 733.   0.  32.]
 [  0.   0.   0. 538.  28.]
 [  1.   1.   1.   0. 875.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 67.456% | Wgt Acc: 58.021% | Dur: 15.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   1.   9.   6.]
 [  0.  37.   3.   0.   3.]
 [  0.   8.  29.   0.   4.]
 [  8.   1.   7.  49.   2.]
 [ 18.  29.  35.  28. 165.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 96.250% | Wgt Acc: 98.977%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.188% | Wgt Acc: 98.962%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.042% | Wgt Acc: 98.882%
	I - Batch: 200 | Loss: 0.491 | Acc: 95.906% | Wgt Acc: 98.823%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 95.799% | Wgt Acc: 98.771% | LR: 1.250000e-05 | Dur: 135.13s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  56.]
 [  0. 577.   0.   0.  17.]
 [  0.   0. 734.   0.  36.]
 [  0.   0.   0. 537.  37.]
 [  1.   1.   0.   1. 854.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.987 | Acc: 70.020% | Wgt Acc: 61.273% | Dur: 15.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   2.  16.   4.]
 [  0.  38.   2.   0.   3.]
 [  0.   5.  30.   1.   3.]
 [  3.   2.   8.  49.   4.]
 [ 13.  29.  33.  20. 166.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 99.072%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.875% | Wgt Acc: 99.155%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.875% | Wgt Acc: 99.151%
	I - Batch: 200 | Loss: 0.487 | Acc: 96.812% | Wgt Acc: 99.134%
I - num batch: 222
I - Train -- Loss: 0.488 | Acc: 96.673% | Wgt Acc: 99.096% | LR: 1.250000e-05 | Dur: 134.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  37.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 882.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 69.034% | Wgt Acc: 59.659% | Dur: 14.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   0.  15.   5.]
 [  0.  37.   4.   1.   1.]
 [  0.   7.  32.   0.   4.]
 [  4.   1.   6.  46.   3.]
 [ 16.  30.  33.  24. 167.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 97.375% | Wgt Acc: 99.164%
	I - Batch: 100 | Loss: 0.483 | Acc: 96.625% | Wgt Acc: 98.904%
	I - Batch: 150 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 98.883%
	I - Batch: 200 | Loss: 0.488 | Acc: 96.500% | Wgt Acc: 98.889%
I - num batch: 222
I - Train -- Loss: 0.488 | Acc: 96.560% | Wgt Acc: 98.922% | LR: 1.250000e-05 | Dur: 135.86s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  44.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 734.   0.  31.]
 [  1.   0.   0. 537.  30.]
 [  2.   1.   0.   1. 883.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 67.456% | Wgt Acc: 57.110% | Dur: 14.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   1.  13.   4.]
 [  0.  36.   3.   0.   2.]
 [  0.  10.  28.   0.   3.]
 [  6.   1.   9.  46.   2.]
 [ 19.  29.  34.  27. 169.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 97.000% | Wgt Acc: 99.179%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.562% | Wgt Acc: 98.988%
	I - Batch: 150 | Loss: 0.488 | Acc: 96.542% | Wgt Acc: 99.011%
	I - Batch: 200 | Loss: 0.488 | Acc: 96.625% | Wgt Acc: 99.016%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.701% | Wgt Acc: 99.045% | LR: 1.250000e-05 | Dur: 136.29s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.  44.]
 [  0. 578.   0.   0.  20.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 537.  29.]
 [  1.   0.   0.   0. 885.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.985 | Acc: 68.245% | Wgt Acc: 59.059% | Dur: 16.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   0.  10.   4.]
 [  0.  35.   3.   0.   2.]
 [  0.   8.  31.   0.   6.]
 [  3.   1.   4.  49.   3.]
 [ 19.  29.  37.  27. 165.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 95.375% | Wgt Acc: 98.494%
	I - Batch: 100 | Loss: 0.490 | Acc: 95.938% | Wgt Acc: 98.707%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.208% | Wgt Acc: 98.805%
	I - Batch: 200 | Loss: 0.489 | Acc: 96.344% | Wgt Acc: 98.881%
I - num batch: 222
I - Train -- Loss: 0.488 | Acc: 96.589% | Wgt Acc: 98.962% | LR: 1.250000e-05 | Dur: 135.80s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  49.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 733.   0.  22.]
 [  0.   0.   0. 538.  30.]
 [  3.   0.   1.   0. 883.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.988 | Acc: 68.047% | Wgt Acc: 58.171% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   1.  13.   4.]
 [  0.  37.   3.   0.   1.]
 [  0.   6.  31.   0.   5.]
 [  5.   1.   6.  48.   2.]
 [ 22.  32.  34.  25. 168.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.125% | Wgt Acc: 98.954%
	I - Batch: 100 | Loss: 0.488 | Acc: 96.250% | Wgt Acc: 98.976%
	I - Batch: 150 | Loss: 0.489 | Acc: 96.375% | Wgt Acc: 98.966%
	I - Batch: 200 | Loss: 0.488 | Acc: 96.344% | Wgt Acc: 98.971%
I - num batch: 222
I - Train -- Loss: 0.490 | Acc: 96.279% | Wgt Acc: 98.958% | LR: 1.250000e-05 | Dur: 134.21s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  52.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  30.]
 [  0.   0.   0. 537.  33.]
 [  0.   0.   0.   1. 869.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.986 | Acc: 69.034% | Wgt Acc: 61.031% | Dur: 17.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.  11.   7.]
 [  0.  34.   3.   0.   2.]
 [  1.   9.  35.   0.   6.]
 [  6.   1.   7.  53.   4.]
 [ 14.  33.  29.  22. 161.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.250% | Wgt Acc: 98.977%
	I - Batch: 100 | Loss: 0.489 | Acc: 97.000% | Wgt Acc: 99.182%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.917% | Wgt Acc: 99.163%
	I - Batch: 200 | Loss: 0.491 | Acc: 96.625% | Wgt Acc: 99.081%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.645% | Wgt Acc: 99.088% | LR: 1.250000e-05 | Dur: 131.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  58.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 881.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 68.836% | Wgt Acc: 59.416% | Dur: 13.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   2.  14.   5.]
 [  0.  33.   2.   1.   3.]
 [  0.  11.  33.   0.   4.]
 [  7.   2.   7.  49.   1.]
 [ 14.  28.  31.  22. 167.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 95.750% | Wgt Acc: 98.711%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.125% | Wgt Acc: 98.882%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.000% | Wgt Acc: 98.793%
	I - Batch: 200 | Loss: 0.490 | Acc: 95.938% | Wgt Acc: 98.804%
I - num batch: 222
I - Train -- Loss: 0.490 | Acc: 96.109% | Wgt Acc: 98.832% | LR: 1.250000e-05 | Dur: 135.21s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  46.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  31.]
 [  0.   0.   0. 538.  43.]
 [  4.   0.   0.   0. 866.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.974 | Acc: 69.822% | Wgt Acc: 61.735% | Dur: 15.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   0.  13.   6.]
 [  0.  39.   4.   1.   2.]
 [  0.   8.  33.   0.   4.]
 [  7.   2.  10.  53.   5.]
 [ 15.  26.  28.  19. 163.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 95.875% | Wgt Acc: 98.639%
	I - Batch: 100 | Loss: 0.490 | Acc: 96.000% | Wgt Acc: 98.794%
	I - Batch: 150 | Loss: 0.489 | Acc: 96.250% | Wgt Acc: 98.898%
	I - Batch: 200 | Loss: 0.491 | Acc: 96.094% | Wgt Acc: 98.846%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.166% | Wgt Acc: 98.873% | LR: 1.250000e-05 | Dur: 134.35s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  54.]
 [  0. 577.   0.   0.  17.]
 [  0.   0. 734.   0.  38.]
 [  0.   0.   0. 538.  24.]
 [  2.   1.   0.   0. 867.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.012 | Acc: 67.258% | Wgt Acc: 57.675% | Dur: 14.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  16.   6.]
 [  0.  34.   2.   1.   2.]
 [  0.   7.  26.   0.   4.]
 [  2.   3.   7.  47.   3.]
 [ 17.  30.  39.  22. 165.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 97.125% | Wgt Acc: 99.220%
	I - Batch: 100 | Loss: 0.488 | Acc: 96.438% | Wgt Acc: 99.039%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.333% | Wgt Acc: 98.959%
	I - Batch: 200 | Loss: 0.491 | Acc: 96.219% | Wgt Acc: 98.907%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 96.250% | Wgt Acc: 98.895% | LR: 1.250000e-05 | Dur: 133.76s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  53.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  34.]
 [  0.   0.   0. 537.  27.]
 [  2.   0.   0.   1. 870.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.011 | Acc: 66.469% | Wgt Acc: 55.784% | Dur: 13.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   2.  11.   4.]
 [  0.  36.   3.   1.   2.]
 [  0.   6.  24.   0.   4.]
 [  6.   2.   8.  46.   1.]
 [ 20.  32.  38.  28. 169.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.500% | Wgt Acc: 98.911%
	I - Batch: 100 | Loss: 0.488 | Acc: 96.688% | Wgt Acc: 98.897%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.792% | Wgt Acc: 98.990%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.844% | Wgt Acc: 99.041%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.927% | Wgt Acc: 99.077% | LR: 1.250000e-05 | Dur: 132.81s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  40.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 734.   0.  31.]
 [  1.   0.   0. 537.  22.]
 [  0.   1.   0.   1. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 68.245% | Wgt Acc: 59.267% | Dur: 17.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   2.  15.   7.]
 [  0.  41.   4.   0.   1.]
 [  0.   7.  27.   0.   5.]
 [  5.   1.   8.  46.   3.]
 [ 15.  24.  34.  25. 164.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.750% | Wgt Acc: 98.836%
	I - Batch: 100 | Loss: 0.485 | Acc: 97.250% | Wgt Acc: 99.134%
	I - Batch: 150 | Loss: 0.485 | Acc: 97.000% | Wgt Acc: 99.109%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.719% | Wgt Acc: 99.049%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.645% | Wgt Acc: 99.004% | LR: 1.250000e-05 | Dur: 133.01s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  51.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  28.]
 [  2.   1.   0.   0. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 68.442% | Wgt Acc: 58.921% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   2.  15.   4.]
 [  0.  34.   2.   0.   2.]
 [  0.   9.  24.   0.   4.]
 [  4.   4.  11.  50.   3.]
 [ 12.  27.  36.  21. 167.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 96.250% | Wgt Acc: 98.957%
	I - Batch: 100 | Loss: 0.487 | Acc: 96.562% | Wgt Acc: 99.054%
	I - Batch: 150 | Loss: 0.488 | Acc: 96.375% | Wgt Acc: 99.011%
	I - Batch: 200 | Loss: 0.487 | Acc: 96.594% | Wgt Acc: 99.073%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.560% | Wgt Acc: 99.065% | LR: 1.250000e-05 | Dur: 133.23s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  36.]
 [  0.   0.   0.   0. 878.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.980 | Acc: 71.203% | Wgt Acc: 62.576% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.  10.   3.]
 [  0.  39.   2.   1.   2.]
 [  0.   9.  33.   0.   4.]
 [  6.   2.   6.  54.   3.]
 [ 15.  27.  33.  21. 168.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 96.000% | Wgt Acc: 98.929%
	I - Batch: 100 | Loss: 0.487 | Acc: 96.500% | Wgt Acc: 99.045%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.417% | Wgt Acc: 99.036%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.375% | Wgt Acc: 98.986%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.420% | Wgt Acc: 98.999% | LR: 1.250000e-05 | Dur: 135.02s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  50.]
 [  0. 578.   0.   0.  21.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  29.]
 [  1.   0.   0.   0. 874.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 68.836% | Wgt Acc: 58.759% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  12.   4.]
 [  0.  34.   3.   1.   1.]
 [  0.   6.  28.   0.   3.]
 [  2.   1.   8.  47.   2.]
 [ 16.  34.  35.  26. 170.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 97.375% | Wgt Acc: 99.286%
	I - Batch: 100 | Loss: 0.486 | Acc: 97.312% | Wgt Acc: 99.207%
	I - Batch: 150 | Loss: 0.488 | Acc: 97.167% | Wgt Acc: 99.141%
	I - Batch: 200 | Loss: 0.488 | Acc: 96.844% | Wgt Acc: 99.077%
I - num batch: 222
I - Train -- Loss: 0.489 | Acc: 96.673% | Wgt Acc: 99.037% | LR: 1.250000e-05 | Dur: 136.60s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 537.  29.]
 [  1.   0.   0.   1. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.019 | Acc: 67.061% | Wgt Acc: 57.341% | Dur: 15.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   2.   0.  15.   6.]
 [  0.  34.   3.   1.   2.]
 [  0.   7.  27.   0.   5.]
 [  1.   1.   6.  44.   2.]
 [ 17.  34.  39.  26. 165.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.500% | Wgt Acc: 98.690%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.438% | Wgt Acc: 98.787%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.375% | Wgt Acc: 98.813%
	I - Batch: 200 | Loss: 0.487 | Acc: 96.312% | Wgt Acc: 98.813%
I - num batch: 222
I - Train -- Loss: 0.488 | Acc: 96.081% | Wgt Acc: 98.737% | LR: 1.250000e-05 | Dur: 135.87s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  65.]
 [  0. 577.   0.   0.  18.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 537.  27.]
 [  5.   1.   0.   1. 868.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 67.653% | Wgt Acc: 57.825% | Dur: 16.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   2.  11.   4.]
 [  0.  35.   2.   0.   2.]
 [  0.   8.  28.   0.   5.]
 [  4.   1.   8.  48.   2.]
 [ 19.  32.  35.  27. 167.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.125% | Wgt Acc: 98.815%
	I - Batch: 100 | Loss: 0.486 | Acc: 95.875% | Wgt Acc: 98.818%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.000% | Wgt Acc: 98.788%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.219% | Wgt Acc: 98.846%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.250% | Wgt Acc: 98.867% | LR: 1.250000e-05 | Dur: 134.11s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  50.]
 [  0. 578.   0.   0.  20.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 537.  33.]
 [  3.   0.   0.   1. 871.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.996 | Acc: 70.414% | Wgt Acc: 62.034% | Dur: 13.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   3.   1.  17.   5.]
 [  0.  42.   3.   1.   5.]
 [  1.   7.  28.   1.   3.]
 [  2.   1.   7.  48.   2.]
 [ 11.  25.  36.  19. 165.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 96.125% | Wgt Acc: 98.953%
	I - Batch: 100 | Loss: 0.492 | Acc: 95.188% | Wgt Acc: 98.679%
	I - Batch: 150 | Loss: 0.489 | Acc: 95.583% | Wgt Acc: 98.761%
	I - Batch: 200 | Loss: 0.488 | Acc: 95.750% | Wgt Acc: 98.781%
I - num batch: 222
I - Train -- Loss: 0.488 | Acc: 95.912% | Wgt Acc: 98.830% | LR: 1.250000e-05 | Dur: 134.38s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  59.]
 [  0. 578.   0.   0.  25.]
 [  0.   0. 734.   0.  28.]
 [  0.   0.   0. 537.  31.]
 [  1.   0.   0.   1. 857.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 68.047% | Wgt Acc: 57.871% | Dur: 16.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   3.  13.   5.]
 [  0.  39.   3.   0.   2.]
 [  0.   6.  26.   0.   2.]
 [  4.   1.   4.  43.   2.]
 [ 16.  29.  39.  30. 169.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.625% | Wgt Acc: 99.078%
	I - Batch: 100 | Loss: 0.488 | Acc: 96.438% | Wgt Acc: 99.028%
	I - Batch: 150 | Loss: 0.490 | Acc: 96.542% | Wgt Acc: 99.052%
	I - Batch: 200 | Loss: 0.489 | Acc: 96.562% | Wgt Acc: 99.033%
I - num batch: 222
I - Train -- Loss: 0.489 | Acc: 96.504% | Wgt Acc: 99.022% | LR: 1.250000e-05 | Dur: 133.53s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  22.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  27.]
 [  1.   0.   0.   0. 877.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.984 | Acc: 68.836% | Wgt Acc: 59.693% | Dur: 14.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   0.  15.   6.]
 [  0.  37.   4.   0.   3.]
 [  0.   9.  29.   0.   3.]
 [  6.   1.   8.  50.   2.]
 [ 15.  27.  34.  21. 166.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 96.500% | Wgt Acc: 99.040%
	I - Batch: 100 | Loss: 0.492 | Acc: 96.438% | Wgt Acc: 98.945%
	I - Batch: 150 | Loss: 0.491 | Acc: 96.417% | Wgt Acc: 98.884%
	I - Batch: 200 | Loss: 0.489 | Acc: 96.375% | Wgt Acc: 98.881%
I - num batch: 222
I - Train -- Loss: 0.489 | Acc: 96.279% | Wgt Acc: 98.869% | LR: 1.250000e-05 | Dur: 136.15s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.  40.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  38.]
 [  0.   0.   0. 535.  33.]
 [  1.   0.   0.   2. 872.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 68.836% | Wgt Acc: 59.197% | Dur: 15.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   3.  18.   5.]
 [  0.  38.   2.   1.   3.]
 [  0.   4.  28.   0.   2.]
 [  3.   1.   7.  46.   2.]
 [ 16.  32.  35.  21. 168.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 99.134%
	I - Batch: 100 | Loss: 0.481 | Acc: 96.812% | Wgt Acc: 99.177%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.917% | Wgt Acc: 99.199%
	I - Batch: 200 | Loss: 0.481 | Acc: 96.719% | Wgt Acc: 99.148%
I - num batch: 208
I - Train -- Loss: 0.482 | Acc: 96.695% | Wgt Acc: 99.143% | LR: 1.250000e-05 | Dur: 124.24s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  31.]
 [  0. 578.   0.   0.  20.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  30.]
 [  0.   0.   0.   0. 671.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.258% | Wgt Acc: 57.490% | Dur: 14.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   1.   1.  14.   5.]
 [  0.  34.   3.   1.   2.]
 [  0.  12.  27.   0.   5.]
 [  4.   2.   7.  48.   2.]
 [ 18.  29.  37.  23. 166.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.490 | Acc: 96.250% | Wgt Acc: 98.981%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.250% | Wgt Acc: 98.859%
	I - Batch: 150 | Loss: 0.489 | Acc: 96.500% | Wgt Acc: 98.959%
	I - Batch: 200 | Loss: 0.490 | Acc: 96.469% | Wgt Acc: 98.978%
I - num batch: 222
I - Train -- Loss: 0.490 | Acc: 96.532% | Wgt Acc: 98.971% | LR: 1.250000e-05 | Dur: 133.42s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  56.]
 [  0. 576.   0.   0.  11.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  26.]
 [  1.   2.   0.   0. 880.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 68.442% | Wgt Acc: 59.151% | Dur: 14.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   1.  13.   6.]
 [  0.  36.   3.   0.   2.]
 [  0.   9.  28.   0.   4.]
 [  6.   2.   9.  50.   2.]
 [ 15.  27.  34.  23. 166.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 98.000% | Wgt Acc: 99.328%
	I - Batch: 100 | Loss: 0.484 | Acc: 97.000% | Wgt Acc: 99.063%
	I - Batch: 150 | Loss: 0.483 | Acc: 97.208% | Wgt Acc: 99.157%
	I - Batch: 200 | Loss: 0.484 | Acc: 97.188% | Wgt Acc: 99.170%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 97.124% | Wgt Acc: 99.158% | LR: 1.250000e-05 | Dur: 135.35s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  36.]
 [  0. 577.   0.   0.  18.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 537.  26.]
 [  0.   1.   0.   1. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 68.047% | Wgt Acc: 58.033% | Dur: 14.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   6.   1.  20.   6.]
 [  0.  35.   3.   1.   1.]
 [  0.   5.  29.   0.   3.]
 [  1.   1.   6.  43.   2.]
 [ 17.  31.  36.  22. 168.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 97.250% | Wgt Acc: 99.275%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 99.056%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.375% | Wgt Acc: 99.016%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.375% | Wgt Acc: 99.014%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.476% | Wgt Acc: 99.014% | LR: 1.250000e-05 | Dur: 135.03s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  58.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  37.]
 [  1.   0.   0.   0. 876.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 69.034% | Wgt Acc: 59.935% | Dur: 15.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   3.  14.   4.]
 [  0.  37.   2.   0.   3.]
 [  0.   6.  29.   0.   6.]
 [  2.   1.   8.  49.   1.]
 [ 17.  29.  33.  23. 166.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 95.875% | Wgt Acc: 98.895%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.375% | Wgt Acc: 98.958%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.417% | Wgt Acc: 98.943%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.688% | Wgt Acc: 99.007%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.701% | Wgt Acc: 99.017% | LR: 1.250000e-05 | Dur: 134.63s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  49.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  35.]
 [  0.   0.   0. 537.  22.]
 [  2.   0.   0.   1. 886.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.987 | Acc: 69.231% | Wgt Acc: 60.662% | Dur: 14.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   4.   1.  12.   5.]
 [  0.  37.   3.   0.   3.]
 [  0.   6.  26.   0.   6.]
 [  2.   1.   6.  51.   2.]
 [ 13.  30.  39.  23. 164.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 97.625% | Wgt Acc: 99.352%
	I - Batch: 100 | Loss: 0.484 | Acc: 97.062% | Wgt Acc: 99.208%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.500% | Wgt Acc: 99.006%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.656% | Wgt Acc: 99.028%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.476% | Wgt Acc: 98.956% | LR: 1.250000e-05 | Dur: 136.25s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 733.   0.  28.]
 [  0.   0.   0. 537.  32.]
 [  1.   0.   1.   1. 878.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 69.231% | Wgt Acc: 59.163% | Dur: 15.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.  11.   4.]
 [  0.  35.   3.   0.   2.]
 [  0.   4.  28.   0.   1.]
 [  6.   2.   9.  50.   2.]
 [ 15.  36.  34.  25. 171.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.875% | Wgt Acc: 99.025%
	I - Batch: 100 | Loss: 0.489 | Acc: 96.062% | Wgt Acc: 98.679%
	I - Batch: 150 | Loss: 0.489 | Acc: 96.167% | Wgt Acc: 98.794%
	I - Batch: 200 | Loss: 0.488 | Acc: 96.312% | Wgt Acc: 98.874%
I - num batch: 222
I - Train -- Loss: 0.487 | Acc: 96.448% | Wgt Acc: 98.924% | LR: 1.250000e-05 | Dur: 134.95s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  50.]
 [  1. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  27.]
 [  3.   0.   0.   0. 878.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.988 | Acc: 69.231% | Wgt Acc: 60.005% | Dur: 14.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   1.  12.   2.]
 [  0.  36.   3.   0.   1.]
 [  0.  11.  30.   0.   7.]
 [  6.   2.   6.  50.   3.]
 [ 14.  25.  35.  24. 167.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 96.250% | Wgt Acc: 98.991%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.438% | Wgt Acc: 99.030%
	I - Batch: 150 | Loss: 0.484 | Acc: 96.500% | Wgt Acc: 99.054%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.531% | Wgt Acc: 99.057%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.448% | Wgt Acc: 99.004% | LR: 1.250000e-05 | Dur: 136.78s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  51.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  28.]
 [  0.   0.   0. 537.  33.]
 [  0.   0.   0.   1. 875.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 67.653% | Wgt Acc: 57.133% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   3.  16.   5.]
 [  0.  37.   2.   0.   0.]
 [  0.   5.  23.   0.   2.]
 [  2.   1.   7.  44.   3.]
 [ 17.  32.  40.  26. 170.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.750% | Wgt Acc: 98.996%
	I - Batch: 100 | Loss: 0.487 | Acc: 96.188% | Wgt Acc: 98.895%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.542% | Wgt Acc: 98.977%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.625% | Wgt Acc: 98.929%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.701% | Wgt Acc: 98.959% | LR: 1.250000e-05 | Dur: 134.11s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  34.]
 [  0. 578.   0.   0.  20.]
 [  0.   0. 734.   0.  35.]
 [  0.   0.   0. 536.  23.]
 [  3.   0.   0.   2. 888.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 67.061% | Wgt Acc: 57.179% | Dur: 14.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   1.  12.   7.]
 [  0.  34.   2.   1.   3.]
 [  0.   7.  25.   0.   3.]
 [  4.   2.   6.  46.   1.]
 [ 15.  30.  41.  27. 166.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.625% | Wgt Acc: 99.085%
	I - Batch: 100 | Loss: 0.484 | Acc: 96.875% | Wgt Acc: 99.094%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.917% | Wgt Acc: 99.036%
	I - Batch: 200 | Loss: 0.487 | Acc: 96.750% | Wgt Acc: 99.019%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.955% | Wgt Acc: 99.086% | LR: 1.250000e-05 | Dur: 133.32s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  36.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 733.   0.  31.]
 [  0.   0.   0. 537.  29.]
 [  1.   0.   1.   1. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 68.836% | Wgt Acc: 60.120% | Dur: 14.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   2.  15.   6.]
 [  0.  36.   2.   0.   3.]
 [  0.   9.  27.   0.   4.]
 [  4.   2.   7.  51.   3.]
 [ 13.  27.  37.  20. 164.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 95.125% | Wgt Acc: 98.519%
	I - Batch: 100 | Loss: 0.488 | Acc: 95.562% | Wgt Acc: 98.710%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.042% | Wgt Acc: 98.881%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.250% | Wgt Acc: 98.949%
I - num batch: 222
I - Train -- Loss: 0.486 | Acc: 96.391% | Wgt Acc: 98.962% | LR: 1.250000e-05 | Dur: 133.27s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  46.]
 [  0. 577.   0.   0.  18.]
 [  0.   0. 734.   0.  35.]
 [  0.   0.   0. 538.  27.]
 [  1.   1.   0.   0. 874.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 67.850% | Wgt Acc: 57.906% | Dur: 14.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   2.  15.   4.]
 [  0.  35.   2.   0.   1.]
 [  0.   4.  25.   0.   4.]
 [  3.   2.   7.  49.   3.]
 [ 18.  34.  39.  22. 168.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 97.375% | Wgt Acc: 99.166%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.188% | Wgt Acc: 99.116%
	I - Batch: 150 | Loss: 0.483 | Acc: 96.917% | Wgt Acc: 99.073%
	I - Batch: 200 | Loss: 0.482 | Acc: 97.031% | Wgt Acc: 99.129%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 97.068% | Wgt Acc: 99.146% | LR: 1.250000e-05 | Dur: 138.14s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  44.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  26.]
 [  1.   1.   0.   0. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 67.653% | Wgt Acc: 58.690% | Dur: 15.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   1.  15.   7.]
 [  0.  38.   3.   0.   2.]
 [  0.  12.  26.   0.   6.]
 [  4.   1.   7.  48.   2.]
 [ 16.  23.  38.  23. 163.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.242%
	I - Batch: 100 | Loss: 0.484 | Acc: 96.875% | Wgt Acc: 99.153%
	I - Batch: 150 | Loss: 0.485 | Acc: 96.708% | Wgt Acc: 99.067%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.656% | Wgt Acc: 99.033%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.645% | Wgt Acc: 99.005% | LR: 1.250000e-05 | Dur: 135.70s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  49.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  29.]
 [  3.   0.   0.   0. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 66.864% | Wgt Acc: 56.879% | Dur: 14.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   1.   1.  14.   5.]
 [  0.  33.   2.   0.   2.]
 [  0.   6.  24.   0.   5.]
 [  2.   2.   5.  45.   2.]
 [ 15.  36.  43.  27. 166.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 97.500% | Wgt Acc: 99.321%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.125% | Wgt Acc: 99.221%
	I - Batch: 150 | Loss: 0.483 | Acc: 97.083% | Wgt Acc: 99.171%
	I - Batch: 200 | Loss: 0.484 | Acc: 96.688% | Wgt Acc: 99.040%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.560% | Wgt Acc: 99.010% | LR: 1.250000e-05 | Dur: 134.59s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  54.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  18.]
 [  2.   0.   0.   0. 880.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 68.639% | Wgt Acc: 59.855% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  14.   6.]
 [  0.  36.   3.   0.   2.]
 [  0.   7.  28.   0.   6.]
 [  5.   1.   8.  51.   2.]
 [ 14.  31.  35.  21. 164.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 96.500% | Wgt Acc: 99.060%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.000% | Wgt Acc: 98.906%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.000% | Wgt Acc: 98.897%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.250% | Wgt Acc: 98.980%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.109% | Wgt Acc: 98.942% | LR: 1.250000e-05 | Dur: 135.21s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  55.]
 [  0. 578.   0.   0.  22.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  32.]
 [  0.   0.   0.   0. 862.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 69.034% | Wgt Acc: 60.270% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   2.  13.   6.]
 [  0.  40.   2.   0.   3.]
 [  0.   5.  24.   0.   3.]
 [  6.   1.   9.  53.   3.]
 [ 14.  28.  38.  20. 165.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.875% | Wgt Acc: 99.026%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.812% | Wgt Acc: 99.073%
	I - Batch: 150 | Loss: 0.485 | Acc: 97.042% | Wgt Acc: 99.157%
	I - Batch: 200 | Loss: 0.484 | Acc: 97.219% | Wgt Acc: 99.213%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 97.153% | Wgt Acc: 99.171% | LR: 1.250000e-05 | Dur: 134.35s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  38.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 733.   0.  25.]
 [  1.   0.   0. 538.  18.]
 [  0.   0.   1.   0. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 69.625% | Wgt Acc: 60.304% | Dur: 14.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   2.   1.  14.   5.]
 [  0.  36.   2.   0.   1.]
 [  0.   6.  27.   0.   4.]
 [  1.   2.   8.  49.   2.]
 [ 14.  32.  37.  23. 168.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.500% | Wgt Acc: 99.062%
	I - Batch: 100 | Loss: 0.484 | Acc: 96.688% | Wgt Acc: 98.976%
	I - Batch: 150 | Loss: 0.485 | Acc: 96.750% | Wgt Acc: 99.034%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.688% | Wgt Acc: 99.005%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 96.871% | Wgt Acc: 99.063% | LR: 1.250000e-05 | Dur: 134.83s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  38.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 537.  26.]
 [  2.   0.   0.   1. 892.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 68.442% | Wgt Acc: 58.240% | Dur: 14.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  14.   4.]
 [  0.  37.   4.   0.   2.]
 [  0.   8.  28.   0.   3.]
 [  6.   2.   8.  46.   1.]
 [ 16.  29.  34.  26. 170.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.025%
	I - Batch: 100 | Loss: 0.483 | Acc: 96.438% | Wgt Acc: 98.972%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.458% | Wgt Acc: 99.003%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.656% | Wgt Acc: 99.062%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.645% | Wgt Acc: 99.060% | LR: 1.250000e-05 | Dur: 135.19s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  34.]
 [  0.   0.   0. 538.  30.]
 [  1.   0.   0.   0. 882.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 68.245% | Wgt Acc: 58.771% | Dur: 15.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   0.   1.  11.   5.]
 [  0.  36.   2.   1.   2.]
 [  0.  14.  31.   0.   5.]
 [  3.   1.   6.  45.   2.]
 [ 17.  27.  35.  29. 166.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 96.375% | Wgt Acc: 99.006%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 99.071%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 99.077%
	I - Batch: 200 | Loss: 0.483 | Acc: 96.594% | Wgt Acc: 99.073%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.504% | Wgt Acc: 99.050% | LR: 1.250000e-05 | Dur: 132.65s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  51.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  34.]
 [  0.   0.   0.   0. 876.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.988 | Acc: 69.822% | Wgt Acc: 61.066% | Dur: 13.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  11.   4.]
 [  0.  37.   3.   0.   3.]
 [  0.   9.  30.   0.   5.]
 [  2.   2.   5.  52.   2.]
 [ 17.  26.  36.  23. 166.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.491 | Acc: 96.375% | Wgt Acc: 98.865%
	I - Batch: 100 | Loss: 0.487 | Acc: 96.562% | Wgt Acc: 98.925%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.458% | Wgt Acc: 98.869%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.594% | Wgt Acc: 98.876%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.589% | Wgt Acc: 98.896% | LR: 1.250000e-05 | Dur: 133.83s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  35.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 734.   0.  32.]
 [  0.   0.   0. 535.  35.]
 [  2.   1.   0.   3. 885.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.006 | Acc: 68.442% | Wgt Acc: 58.229% | Dur: 14.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   1.   0.  11.   4.]
 [  0.  36.   3.   0.   1.]
 [  0.   8.  26.   0.   3.]
 [  2.   2.   7.  46.   2.]
 [ 17.  31.  39.  29. 170.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 95.875% | Wgt Acc: 98.885%
	I - Batch: 100 | Loss: 0.484 | Acc: 95.750% | Wgt Acc: 98.841%
	I - Batch: 150 | Loss: 0.483 | Acc: 95.792% | Wgt Acc: 98.771%
	I - Batch: 200 | Loss: 0.483 | Acc: 96.219% | Wgt Acc: 98.909%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.166% | Wgt Acc: 98.899% | LR: 1.250000e-05 | Dur: 135.45s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  60.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 537.  33.]
 [  1.   0.   0.   1. 866.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.997 | Acc: 69.034% | Wgt Acc: 59.739% | Dur: 18.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  12.   5.]
 [  0.  40.   3.   1.   5.]
 [  0.   5.  27.   0.   2.]
 [  5.   1.   7.  48.   1.]
 [ 15.  29.  37.  25. 167.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.875% | Wgt Acc: 99.151%
	I - Batch: 100 | Loss: 0.485 | Acc: 97.000% | Wgt Acc: 99.184%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.833% | Wgt Acc: 99.048%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.969% | Wgt Acc: 99.077%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 97.012% | Wgt Acc: 99.099% | LR: 1.250000e-05 | Dur: 135.97s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 536.  17.]
 [  1.   0.   0.   2. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 67.258% | Wgt Acc: 57.537% | Dur: 14.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   0.  10.   6.]
 [  0.  34.   2.   0.   3.]
 [  0.   7.  24.   0.   4.]
 [  6.   2.   9.  50.   1.]
 [ 15.  31.  40.  26. 166.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 99.099%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.812% | Wgt Acc: 98.946%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.667% | Wgt Acc: 98.971%
	I - Batch: 200 | Loss: 0.483 | Acc: 96.469% | Wgt Acc: 98.945%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.701% | Wgt Acc: 99.019% | LR: 1.250000e-05 | Dur: 138.08s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  49.]
 [  0. 577.   0.   0.  10.]
 [  0.   0. 733.   0.  17.]
 [  0.   0.   0. 538.  38.]
 [  1.   1.   1.   0. 886.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.034 | Acc: 66.075% | Wgt Acc: 55.518% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   1.   0.   8.   3.]
 [  0.  37.   2.   0.   2.]
 [  0.   9.  25.   0.   4.]
 [  6.   1.   6.  48.   3.]
 [ 25.  30.  42.  30. 168.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 96.875% | Wgt Acc: 99.156%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.000% | Wgt Acc: 99.189%
	I - Batch: 150 | Loss: 0.483 | Acc: 96.958% | Wgt Acc: 99.090%
	I - Batch: 200 | Loss: 0.484 | Acc: 96.688% | Wgt Acc: 99.005%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 96.673% | Wgt Acc: 99.013% | LR: 1.250000e-05 | Dur: 137.07s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  47.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  31.]
 [  3.   0.   0.   0. 885.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 69.428% | Wgt Acc: 60.697% | Dur: 14.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   5.   3.  16.   7.]
 [  0.  41.   2.   1.   2.]
 [  0.   5.  26.   0.   3.]
 [  4.   1.   9.  48.   3.]
 [ 12.  26.  35.  21. 165.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.375% | Wgt Acc: 99.001%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.312% | Wgt Acc: 98.993%
	I - Batch: 150 | Loss: 0.484 | Acc: 96.500% | Wgt Acc: 99.042%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.406% | Wgt Acc: 98.988%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.307% | Wgt Acc: 98.965% | LR: 1.250000e-05 | Dur: 135.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  58.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 537.  24.]
 [  0.   0.   0.   1. 870.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 66.864% | Wgt Acc: 56.695% | Dur: 16.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   0.  14.   4.]
 [  0.  33.   2.   1.   1.]
 [  1.   7.  28.   0.   5.]
 [  4.   1.   7.  46.   3.]
 [ 18.  33.  38.  25. 167.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 96.625% | Wgt Acc: 98.846%
	I - Batch: 100 | Loss: 0.484 | Acc: 96.438% | Wgt Acc: 98.928%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.167% | Wgt Acc: 98.794%
	I - Batch: 200 | Loss: 0.485 | Acc: 96.375% | Wgt Acc: 98.889%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.391% | Wgt Acc: 98.905% | LR: 1.250000e-05 | Dur: 134.30s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  54.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 537.  31.]
 [  3.   0.   0.   1. 876.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 69.428% | Wgt Acc: 60.904% | Dur: 14.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   3.   3.  15.   5.]
 [  0.  37.   3.   0.   2.]
 [  0.   7.  30.   1.   5.]
 [  5.   3.   8.  50.   4.]
 [ 12.  28.  31.  20. 164.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.484 | Acc: 96.500% | Wgt Acc: 98.922%
	I - Batch: 100 | Loss: 0.483 | Acc: 96.438% | Wgt Acc: 98.909%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.750% | Wgt Acc: 99.038%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.562% | Wgt Acc: 99.005%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.532% | Wgt Acc: 99.002% | LR: 1.250000e-05 | Dur: 135.08s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  46.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  32.]
 [  0.   0.   0. 538.  29.]
 [  2.   0.   0.   0. 879.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.996 | Acc: 68.245% | Wgt Acc: 59.117% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   3.  14.   5.]
 [  0.  40.   2.   0.   3.]
 [  0.   5.  26.   0.   5.]
 [  8.   1.  11.  49.   2.]
 [ 14.  27.  33.  23. 165.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.000% | Wgt Acc: 99.238%
	I - Batch: 100 | Loss: 0.478 | Acc: 96.562% | Wgt Acc: 99.061%
	I - Batch: 150 | Loss: 0.477 | Acc: 96.792% | Wgt Acc: 99.132%
	I - Batch: 200 | Loss: 0.478 | Acc: 96.844% | Wgt Acc: 99.150%
I - num batch: 208
I - Train -- Loss: 0.479 | Acc: 96.785% | Wgt Acc: 99.138% | LR: 1.250000e-05 | Dur: 124.30s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  29.]
 [  0. 578.   0.   0.  24.]
 [  0.   0. 734.   0.  25.]
 [  1.   0.   0. 538.  28.]
 [  0.   0.   0.   0. 675.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 69.428% | Wgt Acc: 61.562% | Dur: 13.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   5.   1.  14.   9.]
 [  0.  34.   3.   1.   2.]
 [  1.   6.  31.   0.   7.]
 [  3.   2.   8.  53.   1.]
 [ 11.  31.  32.  18. 161.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 97.125% | Wgt Acc: 99.210%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.938% | Wgt Acc: 99.157%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.833% | Wgt Acc: 99.096%
	I - Batch: 200 | Loss: 0.481 | Acc: 96.750% | Wgt Acc: 99.084%
I - num batch: 222
I - Train -- Loss: 0.481 | Acc: 96.673% | Wgt Acc: 99.040% | LR: 1.250000e-05 | Dur: 137.16s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  30.]
 [  2.   0.   0.   0. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.040 | Acc: 66.469% | Wgt Acc: 55.830% | Dur: 14.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   1.  21.   5.]
 [  0.  36.   4.   0.   2.]
 [  0.   5.  25.   0.   3.]
 [  1.   1.   4.  39.   2.]
 [ 18.  31.  41.  26. 168.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 97.000% | Wgt Acc: 99.185%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.375% | Wgt Acc: 99.226%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.875% | Wgt Acc: 99.066%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.844% | Wgt Acc: 99.076%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.786% | Wgt Acc: 99.065% | LR: 1.250000e-05 | Dur: 134.41s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  31.]
 [  0. 578.   0.   0.  23.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 536.  34.]
 [  0.   0.   0.   2. 888.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 66.272% | Wgt Acc: 55.438% | Dur: 14.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   1.  14.   3.]
 [  0.  31.   2.   0.   2.]
 [  0.   5.  26.   0.   4.]
 [  5.   2.   5.  45.   2.]
 [ 18.  38.  41.  27. 169.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 97.375% | Wgt Acc: 99.156%
	I - Batch: 100 | Loss: 0.484 | Acc: 97.500% | Wgt Acc: 99.252%
	I - Batch: 150 | Loss: 0.485 | Acc: 97.042% | Wgt Acc: 99.108%
	I - Batch: 200 | Loss: 0.483 | Acc: 97.250% | Wgt Acc: 99.189%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 97.181% | Wgt Acc: 99.178% | LR: 1.250000e-05 | Dur: 134.48s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  22.]
 [  2.   0.   0.   0. 902.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.988 | Acc: 69.428% | Wgt Acc: 60.581% | Dur: 16.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   0.   9.   4.]
 [  0.  45.   2.   1.   3.]
 [  0.   5.  26.   0.   5.]
 [  7.   1.   7.  50.   2.]
 [ 16.  24.  40.  26. 166.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.000% | Wgt Acc: 99.190%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.375% | Wgt Acc: 99.284%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.167% | Wgt Acc: 99.233%
	I - Batch: 200 | Loss: 0.482 | Acc: 97.156% | Wgt Acc: 99.227%
I - num batch: 222
I - Train -- Loss: 0.481 | Acc: 97.096% | Wgt Acc: 99.211% | LR: 1.250000e-05 | Dur: 133.84s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  23.]
 [  0.   0.   0.   0. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 68.245% | Wgt Acc: 58.033% | Dur: 14.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.   9.   4.]
 [  0.  32.   2.   1.   0.]
 [  0.   6.  26.   0.   4.]
 [  4.   2.   7.  51.   2.]
 [ 17.  37.  39.  25. 170.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 99.268%
	I - Batch: 100 | Loss: 0.480 | Acc: 96.188% | Wgt Acc: 98.955%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.375% | Wgt Acc: 99.011%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.438% | Wgt Acc: 99.032%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.448% | Wgt Acc: 99.034% | LR: 1.250000e-05 | Dur: 133.72s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  60.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  24.]
 [  0.   0.   0.   0. 874.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 68.639% | Wgt Acc: 58.367% | Dur: 14.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   3.  11.   4.]
 [  0.  33.   2.   1.   0.]
 [  0.  10.  26.   0.   3.]
 [  5.   3.   7.  51.   2.]
 [ 16.  29.  37.  23. 171.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 97.250% | Wgt Acc: 99.271%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.188% | Wgt Acc: 99.240%
	I - Batch: 150 | Loss: 0.482 | Acc: 97.125% | Wgt Acc: 99.218%
	I - Batch: 200 | Loss: 0.481 | Acc: 97.188% | Wgt Acc: 99.235%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 97.153% | Wgt Acc: 99.226% | LR: 1.250000e-05 | Dur: 132.46s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  41.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  20.]
 [  0.   0.   0.   0. 899.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.990 | Acc: 70.020% | Wgt Acc: 60.535% | Dur: 14.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   3.   9.   4.]
 [  0.  38.   2.   0.   2.]
 [  0.   6.  27.   0.   2.]
 [  6.   1.   9.  53.   2.]
 [ 15.  30.  34.  24. 170.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 95.875% | Wgt Acc: 98.621%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 98.920%
	I - Batch: 150 | Loss: 0.484 | Acc: 96.875% | Wgt Acc: 99.066%
	I - Batch: 200 | Loss: 0.484 | Acc: 96.875% | Wgt Acc: 99.086%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.983% | Wgt Acc: 99.122% | LR: 1.250000e-05 | Dur: 134.21s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 537.  29.]
 [  1.   0.   0.   1. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 69.034% | Wgt Acc: 59.313% | Dur: 18.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   1.  10.   3.]
 [  0.  37.   3.   0.   3.]
 [  0.   8.  28.   0.   2.]
 [  5.   1.   7.  49.   3.]
 [ 16.  29.  36.  27. 169.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 97.375% | Wgt Acc: 99.279%
	I - Batch: 100 | Loss: 0.480 | Acc: 98.000% | Wgt Acc: 99.456%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.958% | Wgt Acc: 99.444%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.938% | Wgt Acc: 99.438%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.886% | Wgt Acc: 99.425% | LR: 1.250000e-05 | Dur: 134.49s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  25.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  13.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 69.428% | Wgt Acc: 62.184% | Dur: 14.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   5.   3.  16.  10.]
 [  0.  40.   3.   0.   2.]
 [  0.   8.  31.   0.   7.]
 [  6.   2.   8.  50.   3.]
 [  9.  23.  30.  20. 158.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 97.125% | Wgt Acc: 99.224%
	I - Batch: 100 | Loss: 0.482 | Acc: 97.125% | Wgt Acc: 99.156%
	I - Batch: 150 | Loss: 0.482 | Acc: 97.292% | Wgt Acc: 99.218%
	I - Batch: 200 | Loss: 0.481 | Acc: 97.281% | Wgt Acc: 99.231%
I - num batch: 222
I - Train -- Loss: 0.481 | Acc: 97.237% | Wgt Acc: 99.194% | LR: 1.250000e-05 | Dur: 136.05s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  32.]
 [  1. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  30.]
 [  0.   0.   0. 538.  25.]
 [  1.   0.   0.   0. 904.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 68.639% | Wgt Acc: 58.759% | Dur: 15.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   1.  13.   3.]
 [  0.  35.   2.   0.   3.]
 [  1.   8.  29.   0.   3.]
 [  6.   2.   6.  49.   2.]
 [ 15.  28.  37.  24. 169.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 96.375% | Wgt Acc: 98.754%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 98.793%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.583% | Wgt Acc: 98.857%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.656% | Wgt Acc: 98.928%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.871% | Wgt Acc: 99.005% | LR: 1.250000e-05 | Dur: 136.82s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 536.  25.]
 [  3.   0.   0.   2. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.019 | Acc: 67.456% | Wgt Acc: 57.283% | Dur: 14.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   2.  13.   6.]
 [  0.  35.   2.   0.   1.]
 [  0.   3.  28.   0.   3.]
 [  6.   3.   7.  45.   2.]
 [ 16.  33.  36.  28. 168.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.484 | Acc: 97.375% | Wgt Acc: 99.291%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.312% | Wgt Acc: 99.262%
	I - Batch: 150 | Loss: 0.481 | Acc: 97.125% | Wgt Acc: 99.172%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.219% | Wgt Acc: 99.211%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.322% | Wgt Acc: 99.243% | LR: 1.250000e-05 | Dur: 137.21s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 577.   0.   0.  10.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  15.]
 [  0.   1.   0.   0. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 67.653% | Wgt Acc: 58.471% | Dur: 15.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   0.  15.   6.]
 [  0.  37.   2.   0.   3.]
 [  0.   5.  26.   0.   5.]
 [  3.   2.   7.  48.   2.]
 [ 17.  29.  40.  23. 164.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.490 | Acc: 96.500% | Wgt Acc: 99.034%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.875% | Wgt Acc: 99.080%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.625% | Wgt Acc: 98.952%
	I - Batch: 200 | Loss: 0.484 | Acc: 97.094% | Wgt Acc: 99.113%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 97.124% | Wgt Acc: 99.132% | LR: 1.250000e-05 | Dur: 137.13s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 537.  20.]
 [  2.   0.   0.   1. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 69.034% | Wgt Acc: 59.751% | Dur: 14.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   5.   2.  13.   6.]
 [  0.  37.   2.   1.   2.]
 [  0.   4.  25.   0.   2.]
 [  2.   3.   9.  50.   3.]
 [ 15.  29.  37.  22. 167.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 96.250% | Wgt Acc: 98.988%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.875% | Wgt Acc: 99.090%
	I - Batch: 150 | Loss: 0.483 | Acc: 97.042% | Wgt Acc: 99.067%
	I - Batch: 200 | Loss: 0.483 | Acc: 96.969% | Wgt Acc: 99.075%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 97.040% | Wgt Acc: 99.082% | LR: 1.250000e-05 | Dur: 134.32s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 733.   0.  23.]
 [  0.   0.   0. 537.  16.]
 [  2.   0.   1.   1. 899.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 68.047% | Wgt Acc: 58.701% | Dur: 14.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   0.   7.   2.]
 [  0.  33.   3.   1.   2.]
 [  0.   8.  29.   0.   6.]
 [  6.   2.   6.  55.   4.]
 [ 20.  33.  37.  23. 166.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 95.750% | Wgt Acc: 98.842%
	I - Batch: 100 | Loss: 0.486 | Acc: 95.750% | Wgt Acc: 98.733%
	I - Batch: 150 | Loss: 0.485 | Acc: 96.167% | Wgt Acc: 98.836%
	I - Batch: 200 | Loss: 0.486 | Acc: 96.188% | Wgt Acc: 98.870%
I - num batch: 222
I - Train -- Loss: 0.485 | Acc: 96.307% | Wgt Acc: 98.910% | LR: 1.250000e-05 | Dur: 133.03s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 537.  35.]
 [  2.   0.   0.   1. 872.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 68.047% | Wgt Acc: 59.197% | Dur: 13.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   2.  16.   6.]
 [  0.  38.   7.   0.   4.]
 [  1.   7.  27.   0.   5.]
 [  5.   2.   7.  47.   2.]
 [ 12.  27.  32.  23. 163.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.875% | Wgt Acc: 99.424%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.125% | Wgt Acc: 99.223%
	I - Batch: 150 | Loss: 0.480 | Acc: 97.250% | Wgt Acc: 99.256%
	I - Batch: 200 | Loss: 0.481 | Acc: 97.125% | Wgt Acc: 99.223%
I - num batch: 222
I - Train -- Loss: 0.481 | Acc: 97.040% | Wgt Acc: 99.195% | LR: 1.250000e-05 | Dur: 134.58s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  37.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 69.428% | Wgt Acc: 59.474% | Dur: 16.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   1.   1.  13.   2.]
 [  0.  39.   3.   1.   1.]
 [  0.   3.  22.   0.   4.]
 [  6.   1.   8.  50.   2.]
 [ 12.  34.  41.  22. 171.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.875% | Wgt Acc: 99.008%
	I - Batch: 100 | Loss: 0.482 | Acc: 97.000% | Wgt Acc: 99.114%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.875% | Wgt Acc: 99.103%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.906% | Wgt Acc: 99.123%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.955% | Wgt Acc: 99.114% | LR: 1.250000e-05 | Dur: 134.48s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  41.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 733.   0.  26.]
 [  0.   0.   0. 537.  23.]
 [  0.   0.   1.   1. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 68.047% | Wgt Acc: 57.502% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   1.  14.   3.]
 [  0.  37.   2.   1.   2.]
 [  0.   4.  24.   0.   2.]
 [  4.   2.   7.  46.   2.]
 [ 17.  32.  41.  25. 171.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.324%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.327%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.125% | Wgt Acc: 99.219%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.188% | Wgt Acc: 99.238%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.096% | Wgt Acc: 99.211% | LR: 1.250000e-05 | Dur: 134.76s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  26.]
 [  0.   0.   0.   0. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.032 | Acc: 67.456% | Wgt Acc: 56.822% | Dur: 14.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   2.  17.   5.]
 [  0.  31.   2.   1.   1.]
 [  0.   5.  24.   0.   2.]
 [  1.   2.   7.  45.   2.]
 [ 15.  36.  40.  23. 170.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 97.000% | Wgt Acc: 99.178%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.000% | Wgt Acc: 99.126%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.875% | Wgt Acc: 99.109%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 99.050%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.589% | Wgt Acc: 99.045% | LR: 1.250000e-05 | Dur: 134.15s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  48.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 538.  36.]
 [  1.   0.   0.   0. 880.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 69.034% | Wgt Acc: 59.474% | Dur: 16.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   5.   3.  16.   5.]
 [  0.  39.   2.   0.   4.]
 [  0.   6.  24.   0.   1.]
 [  1.   2.   7.  46.   2.]
 [ 14.  26.  39.  24. 168.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.625% | Wgt Acc: 99.367%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.438% | Wgt Acc: 99.314%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.125% | Wgt Acc: 99.224%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.250% | Wgt Acc: 99.255%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.237% | Wgt Acc: 99.249% | LR: 1.250000e-05 | Dur: 136.27s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  32.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 538.  27.]
 [  0.   0.   0.   0. 902.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 69.428% | Wgt Acc: 59.555% | Dur: 14.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   1.  13.   4.]
 [  0.  36.   2.   0.   2.]
 [  0.   7.  30.   1.   2.]
 [  5.   2.   5.  46.   2.]
 [ 13.  29.  37.  26. 170.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 97.500% | Wgt Acc: 99.321%
	I - Batch: 100 | Loss: 0.480 | Acc: 97.312% | Wgt Acc: 99.272%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.542% | Wgt Acc: 99.335%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.188% | Wgt Acc: 99.237%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.153% | Wgt Acc: 99.198% | LR: 1.250000e-05 | Dur: 134.69s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  25.]
 [  1.   0.   0.   0. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.038 | Acc: 66.864% | Wgt Acc: 55.553% | Dur: 14.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   2.   2.  18.   6.]
 [  0.  34.   2.   1.   0.]
 [  0.   4.  23.   0.   1.]
 [  2.   2.   7.  41.   1.]
 [ 17.  36.  41.  26. 172.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.625% | Wgt Acc: 99.356%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.500% | Wgt Acc: 99.319%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.458% | Wgt Acc: 99.314%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.344% | Wgt Acc: 99.280%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.265% | Wgt Acc: 99.229% | LR: 1.250000e-05 | Dur: 138.66s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  37.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  21.]
 [  1.   0.   0.   0. 904.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 66.469% | Wgt Acc: 55.980% | Dur: 15.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   1.  12.   3.]
 [  0.  33.   2.   0.   3.]
 [  0.   6.  24.   0.   3.]
 [  4.   1.   7.  47.   3.]
 [ 19.  36.  41.  27. 168.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 95.625% | Wgt Acc: 98.578%
	I - Batch: 100 | Loss: 0.481 | Acc: 96.125% | Wgt Acc: 98.826%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.625% | Wgt Acc: 99.004%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.719% | Wgt Acc: 99.044%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.786% | Wgt Acc: 99.040% | LR: 1.250000e-05 | Dur: 137.41s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  51.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 537.  24.]
 [  2.   0.   0.   1. 889.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 67.653% | Wgt Acc: 58.528% | Dur: 14.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   1.  13.   4.]
 [  0.  34.   2.   0.   1.]
 [  0.   8.  26.   0.   7.]
 [  4.   3.   7.  52.   4.]
 [ 17.  30.  39.  21. 164.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 97.125% | Wgt Acc: 99.229%
	I - Batch: 100 | Loss: 0.480 | Acc: 97.188% | Wgt Acc: 99.113%
	I - Batch: 150 | Loss: 0.481 | Acc: 97.167% | Wgt Acc: 99.065%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.250% | Wgt Acc: 99.131%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.265% | Wgt Acc: 99.143% | LR: 1.250000e-05 | Dur: 131.82s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  32.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 537.  28.]
 [  3.   0.   0.   1. 907.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 68.639% | Wgt Acc: 59.243% | Dur: 14.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   1.   2.  12.   3.]
 [  0.  37.   3.   1.   2.]
 [  0.   7.  25.   0.   5.]
 [  5.   2.   6.  51.   3.]
 [ 15.  31.  39.  22. 167.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.229%
	I - Batch: 100 | Loss: 0.481 | Acc: 96.688% | Wgt Acc: 99.100%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.667% | Wgt Acc: 99.096%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.844% | Wgt Acc: 99.110%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.871% | Wgt Acc: 99.120% | LR: 1.250000e-05 | Dur: 133.99s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  50.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  20.]
 [  0.   1.   0.   0. 890.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.258% | Wgt Acc: 56.752% | Dur: 13.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   2.   2.  18.   2.]
 [  0.  38.   2.   0.   3.]
 [  0.   6.  26.   0.   3.]
 [  3.   1.   5.  41.   3.]
 [ 18.  31.  40.  27. 169.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.750% | Wgt Acc: 99.133%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.125% | Wgt Acc: 99.157%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.833% | Wgt Acc: 99.094%
	I - Batch: 200 | Loss: 0.481 | Acc: 96.938% | Wgt Acc: 99.105%
I - num batch: 222
I - Train -- Loss: 0.481 | Acc: 97.068% | Wgt Acc: 99.148% | LR: 1.250000e-05 | Dur: 133.20s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  47.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  26.]
 [  2.   0.   0.   0. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 68.836% | Wgt Acc: 60.316% | Dur: 24.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  12.   4.]
 [  0.  39.   5.   1.   3.]
 [  0.  10.  30.   0.   5.]
 [  6.   1.   7.  49.   5.]
 [ 14.  25.  32.  24. 163.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 95.625% | Wgt Acc: 98.672%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.562% | Wgt Acc: 98.935%
	I - Batch: 150 | Loss: 0.483 | Acc: 97.042% | Wgt Acc: 99.107%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.969% | Wgt Acc: 99.077%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.983% | Wgt Acc: 99.097% | LR: 1.250000e-05 | Dur: 133.25s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 538.  27.]
 [  3.   0.   0.   0. 896.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 68.442% | Wgt Acc: 57.963% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   0.   1.  16.   4.]
 [  0.  37.   3.   1.   0.]
 [  0.   5.  28.   0.   3.]
 [  3.   1.   4.  43.   2.]
 [ 17.  35.  39.  26. 171.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.375% | Wgt Acc: 98.901%
	I - Batch: 100 | Loss: 0.479 | Acc: 96.500% | Wgt Acc: 98.944%
	I - Batch: 150 | Loss: 0.478 | Acc: 96.667% | Wgt Acc: 99.045%
	I - Batch: 200 | Loss: 0.477 | Acc: 96.719% | Wgt Acc: 99.085%
I - num batch: 208
I - Train -- Loss: 0.477 | Acc: 96.755% | Wgt Acc: 99.097% | LR: 1.250000e-05 | Dur: 125.99s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  33.]
 [  0. 577.   0.   0.  19.]
 [  0.   0. 734.   0.  28.]
 [  0.   0.   0. 537.  26.]
 [  0.   1.   0.   1. 675.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 68.639% | Wgt Acc: 58.517% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   1.  13.   3.]
 [  0.  36.   3.   1.   0.]
 [  0.   7.  32.   0.   5.]
 [  7.   1.   6.  47.   2.]
 [ 18.  32.  33.  25. 170.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.750% | Wgt Acc: 99.125%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.438% | Wgt Acc: 99.246%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.179%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.000% | Wgt Acc: 99.151%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.040% | Wgt Acc: 99.165% | LR: 1.250000e-05 | Dur: 138.31s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 537.  27.]
 [  0.   0.   0.   1. 896.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 67.258% | Wgt Acc: 56.822% | Dur: 15.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   2.  15.   5.]
 [  0.  36.   2.   0.   2.]
 [  1.   4.  20.   0.   2.]
 [  3.   2.   6.  45.   2.]
 [ 13.  32.  45.  26. 169.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.250% | Wgt Acc: 99.239%
	I - Batch: 100 | Loss: 0.480 | Acc: 96.938% | Wgt Acc: 99.100%
	I - Batch: 150 | Loss: 0.479 | Acc: 96.917% | Wgt Acc: 99.113%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.183%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 96.983% | Wgt Acc: 99.125% | LR: 1.250000e-05 | Dur: 134.76s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  29.]
 [  2.   0.   0.   0. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 68.639% | Wgt Acc: 61.216% | Dur: 16.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   3.  13.   7.]
 [  0.  40.   4.   0.   3.]
 [  0.   9.  28.   0.  10.]
 [  7.   2.   6.  54.   2.]
 [ 13.  23.  34.  19. 158.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.500% | Wgt Acc: 98.913%
	I - Batch: 100 | Loss: 0.481 | Acc: 96.688% | Wgt Acc: 99.025%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.875% | Wgt Acc: 99.056%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.062% | Wgt Acc: 99.132%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.040% | Wgt Acc: 99.109% | LR: 1.250000e-05 | Dur: 132.83s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  40.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 537.  24.]
 [  2.   0.   0.   1. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.442% | Wgt Acc: 59.301% | Dur: 13.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   2.  14.   6.]
 [  0.  31.   2.   0.   1.]
 [  1.   8.  31.   0.   5.]
 [  3.   2.   7.  50.   3.]
 [ 14.  34.  33.  22. 165.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.150%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.438% | Wgt Acc: 99.298%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.667% | Wgt Acc: 99.365%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.438% | Wgt Acc: 99.304%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.491% | Wgt Acc: 99.318% | LR: 1.250000e-05 | Dur: 134.33s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  14.]
 [  0.   0.   0.   0. 911.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 67.258% | Wgt Acc: 58.355% | Dur: 18.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  11.   6.]
 [  0.  37.   3.   0.   2.]
 [  1.   7.  28.   0.   8.]
 [  5.   1.   5.  48.   2.]
 [ 16.  29.  38.  27. 162.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.375% | Wgt Acc: 99.293%
	I - Batch: 100 | Loss: 0.480 | Acc: 97.125% | Wgt Acc: 99.142%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.250% | Wgt Acc: 99.210%
	I - Batch: 200 | Loss: 0.481 | Acc: 97.062% | Wgt Acc: 99.137%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.040% | Wgt Acc: 99.137% | LR: 1.250000e-05 | Dur: 132.86s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  40.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 537.  30.]
 [  1.   0.   0.   1. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.850% | Wgt Acc: 57.813% | Dur: 14.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   1.  16.   4.]
 [  0.  37.   6.   1.   3.]
 [  0.   5.  28.   1.   3.]
 [  6.   2.   5.  44.   2.]
 [ 15.  31.  35.  24. 168.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.750% | Wgt Acc: 98.980%
	I - Batch: 100 | Loss: 0.481 | Acc: 97.062% | Wgt Acc: 99.131%
	I - Batch: 150 | Loss: 0.480 | Acc: 97.000% | Wgt Acc: 99.141%
	I - Batch: 200 | Loss: 0.479 | Acc: 96.938% | Wgt Acc: 99.138%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.096% | Wgt Acc: 99.183% | LR: 1.250000e-05 | Dur: 137.84s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  38.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  24.]
 [  1.   0.   0.   0. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 67.456% | Wgt Acc: 58.136% | Dur: 19.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   3.   1.  16.   6.]
 [  0.  33.   2.   0.   2.]
 [  0.   8.  25.   0.   5.]
 [  1.   1.   7.  47.   3.]
 [ 14.  33.  40.  23. 164.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 97.250% | Wgt Acc: 99.256%
	I - Batch: 100 | Loss: 0.480 | Acc: 97.125% | Wgt Acc: 99.216%
	I - Batch: 150 | Loss: 0.480 | Acc: 97.042% | Wgt Acc: 99.196%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.000% | Wgt Acc: 99.154%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.068% | Wgt Acc: 99.175% | LR: 1.250000e-05 | Dur: 133.95s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  41.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  25.]
 [  1.   0.   0.   0. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 67.061% | Wgt Acc: 57.421% | Dur: 14.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   3.  15.   3.]
 [  0.  33.   4.   0.   3.]
 [  0.   9.  29.   0.   5.]
 [  6.   2.   7.  48.   4.]
 [ 17.  30.  32.  23. 165.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.750% | Wgt Acc: 99.277%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.562% | Wgt Acc: 99.289%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.333% | Wgt Acc: 99.200%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.406% | Wgt Acc: 99.235%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.491% | Wgt Acc: 99.263% | LR: 1.250000e-05 | Dur: 141.22s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  26.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 538.  18.]
 [  2.   0.   0.   0. 913.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.987 | Acc: 69.034% | Wgt Acc: 59.001% | Dur: 19.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   5.   4.  17.   3.]
 [  0.  38.   3.   0.   3.]
 [  0.   6.  24.   0.   2.]
 [  2.   1.   7.  44.   2.]
 [ 12.  28.  37.  25. 170.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 98.000% | Wgt Acc: 99.464%
	I - Batch: 100 | Loss: 0.479 | Acc: 97.812% | Wgt Acc: 99.343%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.750% | Wgt Acc: 99.346%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.562% | Wgt Acc: 99.305%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.547% | Wgt Acc: 99.306% | LR: 1.250000e-05 | Dur: 136.91s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  38.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  21.]
 [  1.   0.   0.   0. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 67.456% | Wgt Acc: 57.594% | Dur: 14.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   2.  13.   4.]
 [  0.  36.   3.   1.   3.]
 [  0.   9.  26.   0.   4.]
 [  5.   1.   5.  49.   2.]
 [ 19.  30.  39.  23. 167.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.625% | Wgt Acc: 98.953%
	I - Batch: 100 | Loss: 0.483 | Acc: 96.812% | Wgt Acc: 99.061%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.958% | Wgt Acc: 99.091%
	I - Batch: 200 | Loss: 0.481 | Acc: 96.969% | Wgt Acc: 99.050%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 97.068% | Wgt Acc: 99.089% | LR: 1.250000e-05 | Dur: 133.31s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 537.  21.]
 [  3.   0.   0.   1. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.006 | Acc: 67.653% | Wgt Acc: 57.836% | Dur: 14.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   2.  14.   4.]
 [  0.  34.   3.   0.   1.]
 [  0.   7.  24.   0.   5.]
 [  3.   5.   7.  49.   3.]
 [ 16.  28.  39.  23. 167.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.220%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.312% | Wgt Acc: 99.214%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.500% | Wgt Acc: 99.238%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.312% | Wgt Acc: 99.207%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.322% | Wgt Acc: 99.215% | LR: 1.250000e-05 | Dur: 140.46s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  38.]
 [  0. 577.   0.   0.  16.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  20.]
 [  1.   1.   0.   0. 907.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.836% | Wgt Acc: 60.316% | Dur: 14.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   3.  14.   6.]
 [  0.  41.   3.   1.   2.]
 [  0.   4.  26.   0.   7.]
 [  3.   1.   6.  48.   2.]
 [ 14.  28.  37.  23. 163.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.125% | Wgt Acc: 98.803%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.562% | Wgt Acc: 98.994%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.542% | Wgt Acc: 99.011%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.084%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.124% | Wgt Acc: 99.163% | LR: 1.250000e-05 | Dur: 136.01s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 733.   0.  22.]
 [  0.   0.   0. 538.  28.]
 [  1.   0.   1.   0. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 66.864% | Wgt Acc: 58.194% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   2.  15.   6.]
 [  0.  37.   4.   0.   5.]
 [  0.   9.  28.   0.   6.]
 [  3.   2.   8.  46.   3.]
 [ 17.  26.  33.  25. 160.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.750% | Wgt Acc: 99.127%
	I - Batch: 100 | Loss: 0.480 | Acc: 96.812% | Wgt Acc: 99.066%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.917% | Wgt Acc: 99.029%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.938% | Wgt Acc: 99.065%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.983% | Wgt Acc: 99.091% | LR: 1.250000e-05 | Dur: 132.59s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 536.  22.]
 [  1.   0.   0.   2. 896.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.991 | Acc: 68.836% | Wgt Acc: 60.039% | Dur: 13.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   2.   2.  18.   6.]
 [  0.  39.   3.   1.   5.]
 [  0.   3.  27.   0.   2.]
 [  1.   1.   7.  46.   3.]
 [ 14.  33.  36.  21. 164.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.326%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.438% | Wgt Acc: 99.305%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.042% | Wgt Acc: 99.201%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.000% | Wgt Acc: 99.186%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.068% | Wgt Acc: 99.203% | LR: 1.250000e-05 | Dur: 138.52s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  27.]
 [  0.   0.   0.   0. 896.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.035 | Acc: 64.694% | Wgt Acc: 53.108% | Dur: 15.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   4.   2.  12.   5.]
 [  0.  31.   2.   0.   0.]
 [  0.   5.  20.   0.   3.]
 [  4.   1.   6.  45.   2.]
 [ 22.  37.  45.  29. 170.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.000% | Wgt Acc: 99.180%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.750% | Wgt Acc: 99.392%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.792% | Wgt Acc: 99.405%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.625% | Wgt Acc: 99.352%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.575% | Wgt Acc: 99.341% | LR: 1.250000e-05 | Dur: 134.62s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  41.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  11.]
 [  0.   0.   0.   0. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 67.850% | Wgt Acc: 58.551% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   1.   1.  13.   4.]
 [  0.  43.   2.   0.   4.]
 [  0.   6.  24.   0.   3.]
 [  7.   2.   5.  46.   4.]
 [ 15.  26.  43.  27. 165.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.875% | Wgt Acc: 99.435%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.500% | Wgt Acc: 99.333%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.333% | Wgt Acc: 99.203%
	I - Batch: 200 | Loss: 0.479 | Acc: 97.500% | Wgt Acc: 99.229%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.434% | Wgt Acc: 99.220% | LR: 1.250000e-05 | Dur: 140.33s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  34.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  20.]
 [  3.   0.   0.   0. 912.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 65.680% | Wgt Acc: 55.288% | Dur: 14.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  15.   6.]
 [  0.  33.   2.   1.   1.]
 [  0.   6.  23.   0.   6.]
 [  4.   2.   8.  45.   1.]
 [ 18.  33.  41.  25. 166.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.625% | Wgt Acc: 99.343%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.938% | Wgt Acc: 99.435%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.708% | Wgt Acc: 99.374%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.750% | Wgt Acc: 99.388%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.773% | Wgt Acc: 99.394% | LR: 1.250000e-05 | Dur: 134.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  20.]
 [  0.   0.   0.   0. 921.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.992 | Acc: 68.639% | Wgt Acc: 59.174% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   6.   3.  18.   5.]
 [  0.  37.   3.   0.   2.]
 [  0.   5.  25.   0.   4.]
 [  4.   2.   6.  48.   2.]
 [ 13.  28.  38.  20. 167.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.375% | Wgt Acc: 99.289%
	I - Batch: 100 | Loss: 0.480 | Acc: 97.062% | Wgt Acc: 99.201%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.750% | Wgt Acc: 99.120%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.062% | Wgt Acc: 99.204%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.927% | Wgt Acc: 99.165% | LR: 1.250000e-05 | Dur: 133.94s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  50.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  30.]
 [  0.   0.   0.   0. 891.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.030 | Acc: 65.286% | Wgt Acc: 54.111% | Dur: 14.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   1.  13.   5.]
 [  0.  33.   1.   0.   0.]
 [  0.   7.  26.   0.   4.]
 [  5.   2.   3.  44.   2.]
 [ 24.  33.  44.  29. 169.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 96.750% | Wgt Acc: 99.088%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.250% | Wgt Acc: 99.185%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.292% | Wgt Acc: 99.219%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.250% | Wgt Acc: 99.185%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.322% | Wgt Acc: 99.214% | LR: 1.250000e-05 | Dur: 135.75s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 537.  28.]
 [  1.   0.   0.   1. 907.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 66.272% | Wgt Acc: 55.841% | Dur: 14.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  11.   5.]
 [  0.  36.   5.   0.   2.]
 [  0.   7.  25.   0.   4.]
 [  2.   1.   3.  42.   2.]
 [ 20.  32.  41.  33. 167.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.500% | Wgt Acc: 99.324%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.062% | Wgt Acc: 99.139%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.250% | Wgt Acc: 99.212%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.156% | Wgt Acc: 99.194%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 96.983% | Wgt Acc: 99.122% | LR: 1.250000e-05 | Dur: 135.16s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  43.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  29.]
 [  0.   0.   0. 537.  19.]
 [  1.   0.   0.   1. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 68.639% | Wgt Acc: 59.982% | Dur: 14.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   5.   2.  17.   8.]
 [  0.  35.   4.   0.   5.]
 [  0.   5.  28.   0.   2.]
 [  4.   2.   7.  48.   2.]
 [ 10.  31.  34.  21. 163.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.500% | Wgt Acc: 98.824%
	I - Batch: 100 | Loss: 0.478 | Acc: 96.875% | Wgt Acc: 99.040%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.625% | Wgt Acc: 99.001%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.088%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.068% | Wgt Acc: 99.145% | LR: 1.250000e-05 | Dur: 135.97s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  32.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  33.]
 [  0.   0.   0. 537.  26.]
 [  1.   0.   0.   1. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 66.469% | Wgt Acc: 55.922% | Dur: 17.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   0.  11.   4.]
 [  0.  34.   2.   0.   1.]
 [  0.   2.  24.   0.   5.]
 [  3.   1.   6.  44.   2.]
 [ 18.  38.  43.  31. 168.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 97.125% | Wgt Acc: 99.220%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.438% | Wgt Acc: 99.028%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.750% | Wgt Acc: 99.040%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.090%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 96.955% | Wgt Acc: 99.116% | LR: 1.250000e-05 | Dur: 135.70s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  45.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  33.]
 [  1.   1.   0.   0. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 65.680% | Wgt Acc: 54.665% | Dur: 14.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   3.   1.  15.   4.]
 [  0.  35.   2.   0.   2.]
 [  0.   7.  21.   0.   3.]
 [  3.   1.   3.  44.   2.]
 [ 21.  32.  48.  27. 169.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.875% | Wgt Acc: 99.308%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.750% | Wgt Acc: 99.332%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.667% | Wgt Acc: 99.330%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.656% | Wgt Acc: 99.333%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.688% | Wgt Acc: 99.344% | LR: 1.250000e-05 | Dur: 137.68s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  14.]
 [  0.   0.   0. 538.  24.]
 [  1.   0.   0.   0. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.012 | Acc: 67.258% | Wgt Acc: 56.303% | Dur: 17.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  23.   4.]
 [  0.  37.   2.   1.   2.]
 [  0.   4.  24.   0.   2.]
 [  2.   1.   5.  40.   1.]
 [ 17.  32.  43.  22. 171.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.250% | Wgt Acc: 99.255%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.438% | Wgt Acc: 99.302%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.167% | Wgt Acc: 99.231%
	I - Batch: 200 | Loss: 0.480 | Acc: 97.031% | Wgt Acc: 99.190%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.983% | Wgt Acc: 99.180% | LR: 1.250000e-05 | Dur: 136.17s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  23.]
 [  0.   0.   0.   0. 893.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.019 | Acc: 66.864% | Wgt Acc: 57.998% | Dur: 15.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   1.  11.   4.]
 [  0.  36.   3.   2.   3.]
 [  0.   8.  30.   0.   8.]
 [  5.   2.   5.  47.   4.]
 [ 18.  30.  36.  26. 161.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.375% | Wgt Acc: 99.276%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.250% | Wgt Acc: 99.248%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.167% | Wgt Acc: 99.227%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.216%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.124% | Wgt Acc: 99.218% | LR: 1.250000e-05 | Dur: 137.30s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  24.]
 [  0.   0.   0.   0. 898.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 69.231% | Wgt Acc: 59.774% | Dur: 17.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   2.   1.  13.   3.]
 [  0.  38.   2.   0.   2.]
 [  0.   4.  30.   0.   5.]
 [  4.   1.   5.  48.   2.]
 [ 17.  33.  37.  25. 168.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.375% | Wgt Acc: 99.274%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.125% | Wgt Acc: 99.210%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.083% | Wgt Acc: 99.157%
	I - Batch: 200 | Loss: 0.479 | Acc: 96.875% | Wgt Acc: 99.114%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.871% | Wgt Acc: 99.091% | LR: 1.250000e-05 | Dur: 132.46s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  25.]
 [  0.   0.   0. 537.  27.]
 [  1.   0.   0.   1. 891.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 67.653% | Wgt Acc: 58.944% | Dur: 14.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.  13.   5.]
 [  0.  38.   3.   1.   3.]
 [  1.   6.  28.   0.   7.]
 [  6.   2.   9.  50.   3.]
 [ 16.  29.  34.  22. 162.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.750% | Wgt Acc: 99.401%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.438% | Wgt Acc: 99.332%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.349%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.312% | Wgt Acc: 99.302%
I - num batch: 208
I - Train -- Loss: 0.474 | Acc: 97.386% | Wgt Acc: 99.322% | LR: 1.250000e-05 | Dur: 127.56s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 694.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 68.442% | Wgt Acc: 59.336% | Dur: 14.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   2.   1.  14.   6.]
 [  0.  38.   4.   0.   2.]
 [  1.   7.  25.   0.   6.]
 [  4.   1.   6.  48.   1.]
 [ 12.  30.  39.  24. 165.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.156%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.188% | Wgt Acc: 99.166%
	I - Batch: 150 | Loss: 0.479 | Acc: 96.917% | Wgt Acc: 99.117%
	I - Batch: 200 | Loss: 0.479 | Acc: 96.969% | Wgt Acc: 99.142%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.068% | Wgt Acc: 99.172% | LR: 1.250000e-05 | Dur: 136.11s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 537.  31.]
 [  0.   0.   0.   1. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 66.272% | Wgt Acc: 55.841% | Dur: 20.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   2.   2.  17.   2.]
 [  0.  32.   2.   1.   2.]
 [  0.   9.  25.   0.   5.]
 [  4.   1.   7.  44.   4.]
 [ 16.  34.  39.  24. 167.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.750% | Wgt Acc: 99.125%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.062% | Wgt Acc: 99.140%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.292% | Wgt Acc: 99.226%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.125% | Wgt Acc: 99.158%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.265% | Wgt Acc: 99.172% | LR: 1.250000e-05 | Dur: 133.97s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  34.]
 [  0. 577.   0.   0.   9.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  28.]
 [  2.   1.   0.   0. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 67.850% | Wgt Acc: 58.482% | Dur: 14.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   3.   4.  17.   7.]
 [  0.  35.   3.   0.   2.]
 [  0.   7.  24.   0.   5.]
 [  2.   1.   8.  47.   1.]
 [ 13.  32.  36.  22. 165.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 97.250% | Wgt Acc: 99.103%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.188% | Wgt Acc: 99.112%
	I - Batch: 150 | Loss: 0.479 | Acc: 97.208% | Wgt Acc: 99.161%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.094% | Wgt Acc: 99.152%
I - num batch: 222
I - Train -- Loss: 0.479 | Acc: 97.040% | Wgt Acc: 99.137% | LR: 1.250000e-05 | Dur: 136.37s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  49.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 537.  29.]
 [  1.   0.   0.   1. 897.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 69.034% | Wgt Acc: 59.682% | Dur: 19.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   2.  20.   5.]
 [  0.  39.   3.   1.   3.]
 [  0.   5.  28.   0.   3.]
 [  4.   2.   8.  46.   2.]
 [ 14.  27.  34.  19. 167.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.296%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.000% | Wgt Acc: 99.193%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.417% | Wgt Acc: 99.299%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.357%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.745% | Wgt Acc: 99.387% | LR: 1.250000e-05 | Dur: 136.52s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  36.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  19.]
 [  0.   0.   0.   0. 920.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 66.864% | Wgt Acc: 56.360% | Dur: 14.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   0.   9.   5.]
 [  0.  34.   3.   0.   1.]
 [  0.   8.  23.   0.   4.]
 [  6.   1.   8.  49.   1.]
 [ 18.  33.  41.  28. 169.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.500% | Wgt Acc: 99.052%
	I - Batch: 100 | Loss: 0.477 | Acc: 96.688% | Wgt Acc: 98.982%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.042% | Wgt Acc: 99.115%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.031% | Wgt Acc: 99.135%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.096% | Wgt Acc: 99.128% | LR: 1.250000e-05 | Dur: 136.08s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  22.]
 [  3.   0.   0.   0. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 68.442% | Wgt Acc: 58.840% | Dur: 14.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   5.   0.  20.   5.]
 [  0.  37.   4.   0.   2.]
 [  1.   6.  27.   0.   3.]
 [  2.   1.   7.  45.   3.]
 [ 14.  29.  37.  21. 167.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.750% | Wgt Acc: 99.389%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.356%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.458% | Wgt Acc: 99.267%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.469% | Wgt Acc: 99.249%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.604% | Wgt Acc: 99.292% | LR: 1.250000e-05 | Dur: 135.69s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  40.]
 [  0. 577.   0.   0.   9.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  17.]
 [  1.   1.   0.   0. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.024 | Acc: 67.061% | Wgt Acc: 56.256% | Dur: 14.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   3.   1.  17.   7.]
 [  0.  36.   2.   1.   1.]
 [  0.   6.  22.   1.   1.]
 [  3.   2.   6.  41.   1.]
 [ 14.  31.  44.  26. 170.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.625% | Wgt Acc: 99.080%
	I - Batch: 100 | Loss: 0.477 | Acc: 96.750% | Wgt Acc: 99.118%
	I - Batch: 150 | Loss: 0.476 | Acc: 96.750% | Wgt Acc: 99.117%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.031% | Wgt Acc: 99.195%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 96.955% | Wgt Acc: 99.172% | LR: 1.250000e-05 | Dur: 136.01s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  45.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  24.]
 [  0.   0.   0.   0. 892.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 68.639% | Wgt Acc: 59.255% | Dur: 15.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   1.  10.   3.]
 [  0.  38.   3.   0.   1.]
 [  0.   7.  26.   0.   5.]
 [  6.   2.  10.  51.   4.]
 [ 16.  28.  35.  25. 167.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 98.125% | Wgt Acc: 99.495%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.875% | Wgt Acc: 99.426%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.792% | Wgt Acc: 99.400%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.812% | Wgt Acc: 99.406%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.660% | Wgt Acc: 99.364% | LR: 1.250000e-05 | Dur: 133.49s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  22.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  23.]
 [  0.   0.   0.   0. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.993 | Acc: 69.625% | Wgt Acc: 60.155% | Dur: 14.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   1.  12.   2.]
 [  0.  39.   2.   1.   1.]
 [  0.   4.  29.   0.   5.]
 [  4.   1.   5.  50.   3.]
 [ 18.  31.  38.  23. 169.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.750% | Wgt Acc: 99.397%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.688% | Wgt Acc: 99.254%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.333% | Wgt Acc: 99.159%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.531% | Wgt Acc: 99.241%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.434% | Wgt Acc: 99.220% | LR: 1.250000e-05 | Dur: 133.56s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  25.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  30.]
 [  3.   0.   0.   0. 912.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.245% | Wgt Acc: 57.986% | Dur: 14.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  14.   3.]
 [  0.  32.   2.   0.   1.]
 [  1.   7.  27.   0.   2.]
 [  5.   1.   7.  49.   4.]
 [ 14.  35.  38.  23. 170.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.418%
	I - Batch: 100 | Loss: 0.472 | Acc: 98.000% | Wgt Acc: 99.452%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.958% | Wgt Acc: 99.438%
	I - Batch: 200 | Loss: 0.474 | Acc: 98.000% | Wgt Acc: 99.454%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 98.055% | Wgt Acc: 99.471% | LR: 1.250000e-05 | Dur: 132.38s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  34.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  11.]
 [  0.   0.   0. 538.  16.]
 [  0.   0.   0.   0. 931.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.996 | Acc: 68.836% | Wgt Acc: 60.547% | Dur: 17.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   1.  15.   5.]
 [  0.  35.   2.   0.   3.]
 [  0.  13.  32.   0.   6.]
 [  6.   2.   9.  52.   4.]
 [ 14.  24.  31.  19. 162.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 98.000% | Wgt Acc: 99.457%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.427%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.917% | Wgt Acc: 99.395%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.321%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.604% | Wgt Acc: 99.319% | LR: 1.250000e-05 | Dur: 134.32s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  34.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 734.   0.  13.]
 [  0.   0.   0. 538.  26.]
 [  0.   1.   0.   0. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.990 | Acc: 70.020% | Wgt Acc: 60.374% | Dur: 17.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 75.   1.   1.  16.   4.]
 [  0.  36.   2.   0.   1.]
 [  1.  10.  27.   0.   3.]
 [  1.   2.   6.  47.   2.]
 [ 11.  29.  39.  23. 170.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 98.250% | Wgt Acc: 99.526%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.375% | Wgt Acc: 99.217%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.458% | Wgt Acc: 99.258%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.375% | Wgt Acc: 99.219%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.124% | Wgt Acc: 99.160% | LR: 1.250000e-05 | Dur: 135.01s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 537.  23.]
 [  1.   0.   0.   1. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 66.864% | Wgt Acc: 57.421% | Dur: 14.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   2.  15.   4.]
 [  0.  36.   3.   0.   2.]
 [  0.   5.  25.   0.   7.]
 [  4.   1.   6.  49.   3.]
 [ 19.  33.  39.  22. 164.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.320%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.500% | Wgt Acc: 99.315%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.542% | Wgt Acc: 99.336%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.406% | Wgt Acc: 99.298%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.547% | Wgt Acc: 99.333% | LR: 1.250000e-05 | Dur: 135.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  14.]
 [  0.   0.   0. 538.  18.]
 [  0.   0.   0.   0. 913.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.012 | Acc: 67.061% | Wgt Acc: 56.326% | Dur: 14.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  13.   3.]
 [  0.  36.   2.   1.   2.]
 [  0.   7.  21.   1.   2.]
 [  1.   1.   3.  44.   3.]
 [ 18.  31.  48.  27. 170.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.750% | Wgt Acc: 99.253%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.299%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.210%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.219% | Wgt Acc: 99.148%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.350% | Wgt Acc: 99.163% | LR: 1.250000e-05 | Dur: 135.64s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   1.  21.]
 [  0.   0.   0. 536.  26.]
 [  2.   0.   0.   1. 910.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.992 | Acc: 68.639% | Wgt Acc: 60.535% | Dur: 14.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.  16.   3.]
 [  0.  39.   3.   1.   5.]
 [  0.   7.  29.   0.   6.]
 [  4.   2.   8.  52.   5.]
 [ 17.  29.  34.  17. 161.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 96.750% | Wgt Acc: 99.146%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.312% | Wgt Acc: 99.279%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.583% | Wgt Acc: 99.349%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.312% | Wgt Acc: 99.269%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.293% | Wgt Acc: 99.237% | LR: 1.250000e-05 | Dur: 134.79s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  20.]
 [  1.   0.   0.   0. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.245% | Wgt Acc: 60.178% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   2.  13.   7.]
 [  0.  38.   3.   1.   2.]
 [  0.   8.  27.   0.   8.]
 [  4.   2.   6.  51.   3.]
 [ 14.  27.  37.  21. 160.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.375% | Wgt Acc: 99.289%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.250% | Wgt Acc: 99.258%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.458% | Wgt Acc: 99.308%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.438% | Wgt Acc: 99.305%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.237% | Wgt Acc: 99.249% | LR: 1.250000e-05 | Dur: 137.66s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  27.]
 [  0.   0.   0. 538.  20.]
 [  0.   0.   0.   0. 902.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 68.047% | Wgt Acc: 57.963% | Dur: 14.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   2.  11.   4.]
 [  0.  41.   2.   1.   1.]
 [  0.   2.  20.   0.   3.]
 [  3.   1.   3.  46.   3.]
 [ 16.  31.  48.  28. 169.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.875% | Wgt Acc: 99.419%
	I - Batch: 100 | Loss: 0.473 | Acc: 98.125% | Wgt Acc: 99.428%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.917% | Wgt Acc: 99.394%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.750% | Wgt Acc: 99.359%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.632% | Wgt Acc: 99.329% | LR: 1.250000e-05 | Dur: 134.99s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  28.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  25.]
 [  1.   0.   0.   0. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.018 | Acc: 67.258% | Wgt Acc: 56.280% | Dur: 14.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   1.   0.  10.   2.]
 [  0.  31.   2.   0.   0.]
 [  0.   8.  24.   0.   4.]
 [  7.   1.   5.  51.   2.]
 [ 18.  37.  44.  25. 172.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.875% | Wgt Acc: 99.419%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.375% | Wgt Acc: 99.284%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.292% | Wgt Acc: 99.264%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.321%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.265% | Wgt Acc: 99.257% | LR: 1.250000e-05 | Dur: 139.09s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  15.]
 [  0.   0.   0. 538.  27.]
 [  0.   0.   0.   0. 903.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 65.680% | Wgt Acc: 56.130% | Dur: 16.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  14.   6.]
 [  0.  34.   3.   1.   2.]
 [  0.   8.  26.   0.   8.]
 [  2.   1.   5.  45.   2.]
 [ 20.  31.  40.  26. 162.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 98.000% | Wgt Acc: 99.446%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.625% | Wgt Acc: 99.343%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.275%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.531% | Wgt Acc: 99.298%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.575% | Wgt Acc: 99.313% | LR: 1.250000e-05 | Dur: 136.15s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  29.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  26.]
 [  1.   0.   0.   0. 915.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.011 | Acc: 67.850% | Wgt Acc: 57.802% | Dur: 14.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   2.  19.   6.]
 [  0.  36.   4.   0.   3.]
 [  1.   7.  24.   0.   2.]
 [  4.   2.   6.  44.   1.]
 [ 11.  29.  39.  23. 168.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 97.250% | Wgt Acc: 99.115%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.250% | Wgt Acc: 99.129%
	I - Batch: 150 | Loss: 0.478 | Acc: 97.333% | Wgt Acc: 99.192%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.281% | Wgt Acc: 99.196%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 97.237% | Wgt Acc: 99.191% | LR: 1.250000e-05 | Dur: 137.68s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 537.  22.]
 [  1.   0.   0.   1. 904.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.002 | Acc: 68.836% | Wgt Acc: 59.001% | Dur: 15.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   2.   0.  13.   6.]
 [  0.  35.   2.   1.   1.]
 [  0.   6.  28.   0.   3.]
 [  6.   2.   7.  48.   1.]
 [ 13.  33.  38.  24. 169.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.750% | Wgt Acc: 98.960%
	I - Batch: 100 | Loss: 0.478 | Acc: 96.875% | Wgt Acc: 99.022%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.042% | Wgt Acc: 99.110%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.125% | Wgt Acc: 99.156%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.209% | Wgt Acc: 99.186% | LR: 1.250000e-05 | Dur: 132.75s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  25.]
 [  2.   0.   0.   0. 903.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.034 | Acc: 65.878% | Wgt Acc: 55.149% | Dur: 17.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   0.  12.   4.]
 [  0.  34.   3.   1.   1.]
 [  0.   7.  22.   0.   4.]
 [  5.   1.   4.  45.   3.]
 [ 18.  33.  46.  28. 168.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.159%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.312% | Wgt Acc: 99.206%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.333% | Wgt Acc: 99.234%
	I - Batch: 200 | Loss: 0.478 | Acc: 97.312% | Wgt Acc: 99.209%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.293% | Wgt Acc: 99.209% | LR: 1.250000e-05 | Dur: 133.48s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  43.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  25.]
 [  2.   0.   0.   0. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 69.822% | Wgt Acc: 60.420% | Dur: 13.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  14.   6.]
 [  0.  41.   3.   1.   1.]
 [  0.   4.  26.   0.   3.]
 [  4.   1.   7.  49.   1.]
 [ 15.  29.  38.  22. 169.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.875% | Wgt Acc: 99.435%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.562% | Wgt Acc: 99.340%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.286%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.531% | Wgt Acc: 99.300%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.575% | Wgt Acc: 99.313% | LR: 1.250000e-05 | Dur: 132.13s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  28.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  27.]
 [  1.   0.   0.   0. 915.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 66.864% | Wgt Acc: 57.075% | Dur: 13.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   3.  16.   5.]
 [  0.  36.   2.   1.   2.]
 [  1.   5.  27.   0.   5.]
 [  3.   1.   6.  43.   3.]
 [ 16.  33.  37.  26. 165.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.230%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.750% | Wgt Acc: 99.325%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.542% | Wgt Acc: 99.289%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.290%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.519% | Wgt Acc: 99.267% | LR: 1.250000e-05 | Dur: 132.25s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  14.]
 [  0.   0.   0. 537.  23.]
 [  1.   0.   0.   1. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 66.469% | Wgt Acc: 55.657% | Dur: 14.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  15.   4.]
 [  0.  33.   5.   1.   1.]
 [  1.   9.  28.   0.   4.]
 [  5.   1.   6.  42.   2.]
 [ 17.  31.  34.  28. 169.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 98.000% | Wgt Acc: 99.461%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.938% | Wgt Acc: 99.380%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.625% | Wgt Acc: 99.308%
	I - Batch: 200 | Loss: 0.477 | Acc: 97.531% | Wgt Acc: 99.296%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 97.406% | Wgt Acc: 99.240% | LR: 1.250000e-05 | Dur: 132.62s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  19.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  15.]
 [  2.   0.   0.   0. 910.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 66.469% | Wgt Acc: 56.003% | Dur: 14.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   1.  18.   4.]
 [  0.  39.   3.   0.   2.]
 [  1.   6.  28.   0.   5.]
 [  2.   1.   4.  36.   2.]
 [ 18.  29.  39.  32. 167.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.000% | Wgt Acc: 99.175%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.312% | Wgt Acc: 99.267%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.292% | Wgt Acc: 99.266%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.062% | Wgt Acc: 99.175%
I - num batch: 222
I - Train -- Loss: 0.477 | Acc: 96.871% | Wgt Acc: 99.122% | LR: 1.250000e-05 | Dur: 134.39s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  41.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  30.]
 [  0.   0.   0. 538.  28.]
 [  1.   0.   0.   0. 890.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.975 | Acc: 69.231% | Wgt Acc: 60.512% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   1.   1.  10.   5.]
 [  0.  38.   4.   0.   3.]
 [  0.   9.  31.   1.   5.]
 [  8.   1.   6.  53.   2.]
 [ 16.  29.  33.  22. 165.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.750% | Wgt Acc: 99.421%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.314%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.167% | Wgt Acc: 99.262%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.188% | Wgt Acc: 99.269%
I - num batch: 208
I - Train -- Loss: 0.472 | Acc: 97.266% | Wgt Acc: 99.291% | LR: 1.250000e-05 | Dur: 125.51s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  31.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  30.]
 [  0.   0.   0.   0. 690.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.995 | Acc: 67.850% | Wgt Acc: 58.286% | Dur: 14.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   2.  15.   6.]
 [  0.  36.   2.   0.   1.]
 [  0.   5.  26.   0.   5.]
 [  5.   2.   7.  47.   2.]
 [ 14.  30.  38.  24. 166.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 99.273%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.375% | Wgt Acc: 99.285%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.350%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.656% | Wgt Acc: 99.329%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.660% | Wgt Acc: 99.336% | LR: 1.250000e-05 | Dur: 137.60s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  31.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  21.]
 [  1.   0.   0.   0. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.992 | Acc: 69.822% | Wgt Acc: 61.527% | Dur: 15.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   1.   1.  11.   6.]
 [  0.  39.   3.   0.   2.]
 [  0.   8.  30.   0.   6.]
 [  6.   1.   8.  53.   2.]
 [ 14.  29.  33.  22. 164.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 98.250% | Wgt Acc: 99.280%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.298%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.625% | Wgt Acc: 99.272%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.531% | Wgt Acc: 99.266%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.604% | Wgt Acc: 99.290% | LR: 1.250000e-05 | Dur: 134.91s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  36.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  15.]
 [  0.   0.   0. 537.  25.]
 [  1.   0.   0.   1. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.039 | Acc: 64.892% | Wgt Acc: 53.143% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   1.   2.  14.   4.]
 [  0.  31.   2.   1.   0.]
 [  0.   5.  20.   0.   3.]
 [  3.   1.   4.  44.   2.]
 [ 22.  40.  47.  27. 171.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.625% | Wgt Acc: 99.352%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.625% | Wgt Acc: 99.354%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.625% | Wgt Acc: 99.357%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.531% | Wgt Acc: 99.332%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.688% | Wgt Acc: 99.372% | LR: 1.250000e-05 | Dur: 133.39s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  35.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  22.]
 [  0.   0.   0.   0. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.030 | Acc: 65.286% | Wgt Acc: 53.615% | Dur: 14.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   1.  15.   4.]
 [  0.  34.   2.   0.   1.]
 [  1.   4.  22.   0.   2.]
 [  4.   1.   4.  40.   2.]
 [ 19.  35.  46.  31. 171.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 97.000% | Wgt Acc: 99.199%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.625% | Wgt Acc: 99.354%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.667% | Wgt Acc: 99.365%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.388%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.688% | Wgt Acc: 99.372% | LR: 1.250000e-05 | Dur: 133.08s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  17.]
 [  0.   0.   0.   0. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.994 | Acc: 69.231% | Wgt Acc: 60.166% | Dur: 14.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   1.   1.  14.   5.]
 [  0.  38.   2.   0.   2.]
 [  1.   8.  28.   0.   5.]
 [  3.   1.   5.  47.   2.]
 [ 12.  30.  39.  25. 166.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 96.875% | Wgt Acc: 99.130%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.438% | Wgt Acc: 99.298%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.000% | Wgt Acc: 99.179%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.156% | Wgt Acc: 99.226%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.012% | Wgt Acc: 99.188% | LR: 1.250000e-05 | Dur: 133.87s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  44.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  31.]
 [  0.   0.   0. 538.  20.]
 [  0.   0.   0.   0. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 65.286% | Wgt Acc: 54.146% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   1.   1.  12.   2.]
 [  0.  32.   2.   1.   2.]
 [  0.   8.  27.   0.   4.]
 [  5.   1.   4.  46.   3.]
 [ 26.  36.  41.  27. 169.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.875% | Wgt Acc: 99.147%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.250% | Wgt Acc: 99.254%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.375% | Wgt Acc: 99.284%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.285%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.434% | Wgt Acc: 99.303% | LR: 1.250000e-05 | Dur: 133.70s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  19.]
 [  0.   0.   0.   0. 909.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.002 | Acc: 67.653% | Wgt Acc: 58.009% | Dur: 18.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.  17.   5.]
 [  0.  37.   4.   0.   2.]
 [  0.   9.  29.   0.   6.]
 [  5.   2.   5.  46.   1.]
 [ 18.  27.  36.  23. 166.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.387%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.291%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.283%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.286%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.293% | Wgt Acc: 99.264% | LR: 1.250000e-05 | Dur: 135.63s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  32.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  29.]
 [  0.   0.   0.   0. 904.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 66.864% | Wgt Acc: 56.695% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  18.   5.]
 [  0.  39.   3.   1.   5.]
 [  1.   6.  21.   0.   2.]
 [  2.   2.   6.  43.   1.]
 [ 16.  28.  44.  24. 167.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.314%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.386%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.792% | Wgt Acc: 99.399%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.875% | Wgt Acc: 99.388%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.942% | Wgt Acc: 99.382% | LR: 1.250000e-05 | Dur: 135.78s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  23.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 537.  12.]
 [  1.   0.   0.   1. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.028 | Acc: 67.061% | Wgt Acc: 56.925% | Dur: 14.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   2.  16.   4.]
 [  0.  32.   2.   0.   3.]
 [  0.   7.  27.   0.   4.]
 [  3.   3.   5.  45.   2.]
 [ 16.  32.  39.  25. 167.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 98.125% | Wgt Acc: 99.482%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.938% | Wgt Acc: 99.436%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.379%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.906% | Wgt Acc: 99.397%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.914% | Wgt Acc: 99.404% | LR: 1.250000e-05 | Dur: 135.73s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  31.]
 [  0. 577.   0.   0.   8.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  18.]
 [  0.   1.   0.   0. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 68.639% | Wgt Acc: 58.563% | Dur: 14.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  11.   3.]
 [  0.  36.   3.   0.   2.]
 [  0.   6.  27.   0.   3.]
 [  7.   2.   6.  49.   2.]
 [ 15.  30.  38.  26. 170.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 98.250% | Wgt Acc: 99.529%
	I - Batch: 100 | Loss: 0.471 | Acc: 98.125% | Wgt Acc: 99.499%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.917% | Wgt Acc: 99.439%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.969% | Wgt Acc: 99.448%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.998% | Wgt Acc: 99.456% | LR: 1.250000e-05 | Dur: 140.39s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  30.]
 [  0. 578.   0.   0.   6.]
 [  0.   0. 734.   0.  13.]
 [  0.   0.   0. 538.  22.]
 [  0.   0.   0.   0. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 67.258% | Wgt Acc: 56.891% | Dur: 17.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   0.  14.   2.]
 [  0.  34.   2.   1.   3.]
 [  1.   6.  26.   0.   3.]
 [  6.   1.   7.  49.   3.]
 [ 18.  35.  40.  22. 169.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 98.000% | Wgt Acc: 99.464%
	I - Batch: 100 | Loss: 0.472 | Acc: 98.062% | Wgt Acc: 99.477%
	I - Batch: 150 | Loss: 0.471 | Acc: 98.125% | Wgt Acc: 99.493%
	I - Batch: 200 | Loss: 0.471 | Acc: 98.094% | Wgt Acc: 99.484%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 98.111% | Wgt Acc: 99.486% | LR: 1.250000e-05 | Dur: 133.68s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  34.]
 [  0. 578.   0.   0.   3.]
 [  0.   0. 734.   0.  13.]
 [  0.   0.   0. 538.  17.]
 [  0.   0.   0.   0. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.997 | Acc: 68.442% | Wgt Acc: 58.229% | Dur: 14.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  11.   4.]
 [  0.  34.   2.   1.   2.]
 [  1.   2.  26.   0.   2.]
 [  5.   2.   6.  47.   2.]
 [ 12.  37.  40.  27. 170.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 200
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 98.000% | Wgt Acc: 99.461%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 99.186%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.333% | Wgt Acc: 99.192%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.312% | Wgt Acc: 99.209%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.293% | Wgt Acc: 99.209% | LR: 1.250000e-05 | Dur: 136.79s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  22.]
 [  2.   0.   0.   0. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 67.456% | Wgt Acc: 57.571% | Dur: 16.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   2.  11.   4.]
 [  0.  34.   2.   0.   3.]
 [  0.   5.  24.   0.   4.]
 [  6.   3.   5.  49.   2.]
 [ 14.  32.  42.  26. 167.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 201
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.750% | Wgt Acc: 99.258%
	I - Batch: 100 | Loss: 0.471 | Acc: 98.125% | Wgt Acc: 99.423%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.875% | Wgt Acc: 99.334%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.781% | Wgt Acc: 99.304%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.745% | Wgt Acc: 99.304% | LR: 1.250000e-05 | Dur: 134.69s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  14.]
 [  3.   0.   0.   0. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.006 | Acc: 68.047% | Wgt Acc: 59.912% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   3.  13.   7.]
 [  0.  36.   2.   1.   4.]
 [  0.   8.  29.   0.   6.]
 [  7.   4.   6.  52.   3.]
 [ 13.  27.  35.  20. 160.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 202
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.500% | Wgt Acc: 99.314%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.438% | Wgt Acc: 99.305%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.167% | Wgt Acc: 99.226%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.281% | Wgt Acc: 99.260%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.209% | Wgt Acc: 99.241% | LR: 1.250000e-05 | Dur: 133.56s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  37.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  27.]
 [  0.   0.   0.   0. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 68.245% | Wgt Acc: 58.206% | Dur: 14.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   3.  13.   4.]
 [  0.  35.   2.   0.   2.]
 [  1.   1.  24.   0.   2.]
 [  4.   2.   5.  48.   3.]
 [ 13.  35.  41.  25. 169.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 203
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.349%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.938% | Wgt Acc: 99.431%
	I - Batch: 150 | Loss: 0.477 | Acc: 97.792% | Wgt Acc: 99.354%
	I - Batch: 200 | Loss: 0.476 | Acc: 97.625% | Wgt Acc: 99.321%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.660% | Wgt Acc: 99.336% | LR: 1.250000e-05 | Dur: 135.09s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 578.   0.   0.   6.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  20.]
 [  1.   0.   0.   0. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.047% | Wgt Acc: 58.402% | Dur: 14.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   5.   0.  13.   3.]
 [  0.  39.   3.   0.   4.]
 [  0.   6.  24.   0.   3.]
 [  6.   1.   6.  48.   3.]
 [ 15.  27.  42.  25. 167.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 204
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 98.125% | Wgt Acc: 99.495%
	I - Batch: 100 | Loss: 0.472 | Acc: 98.062% | Wgt Acc: 99.413%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.708% | Wgt Acc: 99.293%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.625% | Wgt Acc: 99.255%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.604% | Wgt Acc: 99.261% | LR: 1.250000e-05 | Dur: 136.60s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  32.]
 [  0. 577.   0.   0.   7.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 537.  17.]
 [  1.   1.   0.   1. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 65.878% | Wgt Acc: 54.884% | Dur: 16.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   2.   2.  15.   3.]
 [  0.  33.   2.   1.   3.]
 [  0.   6.  22.   0.   2.]
 [  5.   1.   5.  43.   3.]
 [ 16.  36.  44.  27. 169.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 205
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.750% | Wgt Acc: 99.390%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.625% | Wgt Acc: 99.294%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.625% | Wgt Acc: 99.272%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.688% | Wgt Acc: 99.310%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.660% | Wgt Acc: 99.307% | LR: 1.250000e-05 | Dur: 136.58s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 577.   0.   0.   5.]
 [  0.   0. 734.   0.  15.]
 [  0.   0.   0. 538.  26.]
 [  1.   1.   0.   0. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 66.469% | Wgt Acc: 56.037% | Dur: 14.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  20.   3.]
 [  0.  34.   2.   0.   2.]
 [  0.   6.  26.   0.   5.]
 [  3.   1.   5.  40.   3.]
 [ 15.  34.  41.  26. 167.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 206
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.072%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.126%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.792% | Wgt Acc: 99.270%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.190%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.434% | Wgt Acc: 99.220% | LR: 1.250000e-05 | Dur: 136.21s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  36.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  26.]
 [  3.   0.   0.   0. 912.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.999 | Acc: 67.258% | Wgt Acc: 57.502% | Dur: 16.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   2.  12.   6.]
 [  1.  37.   3.   1.   3.]
 [  0.   8.  25.   0.   4.]
 [  6.   2.   7.  47.   1.]
 [ 15.  26.  38.  26. 166.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 207
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 98.000% | Wgt Acc: 99.350%
	I - Batch: 100 | Loss: 0.472 | Acc: 98.062% | Wgt Acc: 99.413%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.958% | Wgt Acc: 99.403%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.688% | Wgt Acc: 99.311%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.716% | Wgt Acc: 99.324% | LR: 1.250000e-05 | Dur: 134.26s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  27.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  25.]
 [  2.   0.   0.   0. 921.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 66.075% | Wgt Acc: 55.195% | Dur: 14.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  14.   2.]
 [  0.  35.   2.   1.   2.]
 [  0.   3.  18.   0.   3.]
 [  3.   1.   6.  44.   4.]
 [ 16.  36.  48.  27. 169.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 208
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 98.000% | Wgt Acc: 99.464%
	I - Batch: 100 | Loss: 0.470 | Acc: 98.188% | Wgt Acc: 99.510%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.833% | Wgt Acc: 99.374%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.750% | Wgt Acc: 99.358%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.575% | Wgt Acc: 99.283% | LR: 1.250000e-05 | Dur: 135.35s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  35.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 537.  15.]
 [  1.   0.   0.   1. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 66.469% | Wgt Acc: 55.345% | Dur: 19.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   1.  12.   3.]
 [  0.  32.   2.   0.   1.]
 [  1.   6.  20.   0.   3.]
 [  3.   2.   6.  47.   2.]
 [ 17.  37.  46.  27. 171.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 209
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 98.375% | Wgt Acc: 99.559%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.500% | Wgt Acc: 99.266%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.542% | Wgt Acc: 99.294%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.295%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.575% | Wgt Acc: 99.286% | LR: 1.250000e-05 | Dur: 132.90s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  31.]
 [  0. 578.   0.   0.  17.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  18.]
 [  2.   0.   0.   0. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 69.034% | Wgt Acc: 59.416% | Dur: 13.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   2.   0.  14.   5.]
 [  0.  38.   3.   1.   2.]
 [  0.   5.  32.   0.   3.]
 [  4.   1.   5.  44.   2.]
 [ 16.  32.  35.  27. 168.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 210
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.875% | Wgt Acc: 99.421%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.438% | Wgt Acc: 99.298%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 99.251%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.125% | Wgt Acc: 99.220%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.040% | Wgt Acc: 99.195% | LR: 1.250000e-05 | Dur: 134.65s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  49.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  26.]
 [  0.   0.   0.   0. 895.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.057 | Acc: 63.905% | Wgt Acc: 52.012% | Dur: 16.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   4.   1.  12.   4.]
 [  0.  30.   1.   0.   2.]
 [  0.   4.  18.   0.   3.]
 [  6.   2.   3.  44.   1.]
 [ 20.  38.  52.  30. 170.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 211
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 98.500% | Wgt Acc: 99.580%
	I - Batch: 100 | Loss: 0.473 | Acc: 98.375% | Wgt Acc: 99.554%
	I - Batch: 150 | Loss: 0.471 | Acc: 98.125% | Wgt Acc: 99.451%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.938% | Wgt Acc: 99.407%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.857% | Wgt Acc: 99.388% | LR: 1.250000e-05 | Dur: 137.96s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  26.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  18.]
 [  0.   1.   0.   0. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.001 | Acc: 68.442% | Wgt Acc: 58.471% | Dur: 15.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   3.  16.   6.]
 [  0.  37.   4.   0.   0.]
 [  0.   7.  25.   1.   4.]
 [  5.   3.   7.  47.   1.]
 [ 14.  27.  36.  22. 169.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 212
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.260%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.625% | Wgt Acc: 99.284%
	I - Batch: 150 | Loss: 0.476 | Acc: 97.583% | Wgt Acc: 99.298%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.406% | Wgt Acc: 99.263%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.181% | Wgt Acc: 99.206% | LR: 1.250000e-05 | Dur: 133.63s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  40.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  23.]
 [  1.   0.   0.   0. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.442% | Wgt Acc: 58.263% | Dur: 14.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.  13.   4.]
 [  0.  43.   3.   0.   1.]
 [  0.   7.  25.   0.   3.]
 [  4.   1.   7.  44.   2.]
 [ 19.  24.  39.  29. 170.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 213
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.875% | Wgt Acc: 99.129%
	I - Batch: 100 | Loss: 0.477 | Acc: 97.062% | Wgt Acc: 99.193%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.292% | Wgt Acc: 99.262%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.438% | Wgt Acc: 99.273%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 97.322% | Wgt Acc: 99.244% | LR: 1.250000e-05 | Dur: 134.94s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  42.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  15.]
 [  0.   0.   0. 538.  25.]
 [  1.   0.   0.   0. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 68.442% | Wgt Acc: 58.044% | Dur: 14.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   1.  17.   4.]
 [  0.  38.   2.   0.   0.]
 [  0.   5.  25.   0.   4.]
 [  6.   3.   3.  46.   1.]
 [ 15.  28.  44.  23. 171.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 214
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.625% | Wgt Acc: 99.354%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.875% | Wgt Acc: 99.356%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.667% | Wgt Acc: 99.322%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.356%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.857% | Wgt Acc: 99.387% | LR: 1.250000e-05 | Dur: 133.35s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  29.]
 [  0. 578.   0.   0.   6.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 537.  20.]
 [  0.   0.   0.   1. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 69.625% | Wgt Acc: 60.374% | Dur: 14.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   2.   3.  14.   5.]
 [  0.  40.   2.   1.   1.]
 [  1.   3.  22.   0.   3.]
 [  3.   1.   7.  50.   3.]
 [ 11.  32.  41.  21. 168.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 215
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 98.250% | Wgt Acc: 99.542%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 99.417%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.708% | Wgt Acc: 99.368%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.719% | Wgt Acc: 99.380%
I - num batch: 208
I - Train -- Loss: 0.470 | Acc: 97.716% | Wgt Acc: 99.379% | LR: 1.250000e-05 | Dur: 124.91s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  28.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  20.]
 [  1.   0.   0.   0. 706.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 0.998 | Acc: 69.231% | Wgt Acc: 59.970% | Dur: 13.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   4.  16.   7.]
 [  0.  35.   4.   0.   1.]
 [  1.   7.  28.   0.   4.]
 [  4.   2.   7.  49.   1.]
 [ 11.  30.  32.  21. 167.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 216
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 99.280%
	I - Batch: 100 | Loss: 0.474 | Acc: 96.812% | Wgt Acc: 99.071%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.125% | Wgt Acc: 99.173%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 99.189%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.265% | Wgt Acc: 99.201% | LR: 1.250000e-05 | Dur: 132.44s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  47.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  12.]
 [  0.   0.   0. 538.  24.]
 [  2.   0.   0.   0. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 67.850% | Wgt Acc: 57.640% | Dur: 15.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  14.   4.]
 [  0.  36.   2.   0.   1.]
 [  1.   3.  24.   0.   4.]
 [  4.   1.   8.  46.   2.]
 [ 14.  34.  40.  26. 169.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 217
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.125% | Wgt Acc: 99.201%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.312% | Wgt Acc: 99.260%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.458% | Wgt Acc: 99.302%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.469% | Wgt Acc: 99.310%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.547% | Wgt Acc: 99.333% | LR: 1.250000e-05 | Dur: 133.94s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  27.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  22.]
 [  0.   0.   0. 538.  25.]
 [  0.   0.   0.   0. 913.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 68.047% | Wgt Acc: 57.098% | Dur: 14.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   3.   2.  18.   5.]
 [  0.  34.   2.   1.   1.]
 [  0.   6.  29.   0.   0.]
 [  0.   1.   4.  39.   2.]
 [ 17.  34.  38.  28. 172.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 218
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.750% | Wgt Acc: 99.388%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.438% | Wgt Acc: 99.173%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.208% | Wgt Acc: 99.156%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.281% | Wgt Acc: 99.167%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.237% | Wgt Acc: 99.166% | LR: 1.250000e-05 | Dur: 134.82s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  12.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  25.]
 [  3.   0.   0.   0. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 65.878% | Wgt Acc: 55.311% | Dur: 16.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   1.  16.   4.]
 [  0.  34.   2.   0.   4.]
 [  0.   9.  26.   0.   4.]
 [  4.   4.   4.  43.   1.]
 [ 20.  29.  42.  27. 167.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 219
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 99.334%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.427%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.625% | Wgt Acc: 99.358%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.500% | Wgt Acc: 99.324%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.463% | Wgt Acc: 99.310% | LR: 1.250000e-05 | Dur: 135.86s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  18.]
 [  0.   0.   0.   0. 910.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.033 | Acc: 66.864% | Wgt Acc: 55.415% | Dur: 14.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   1.  13.   3.]
 [  0.  32.   2.   0.   1.]
 [  0.   4.  19.   0.   1.]
 [  2.   1.   4.  45.   2.]
 [ 16.  37.  49.  28. 173.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 220
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.250% | Wgt Acc: 99.236%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.688% | Wgt Acc: 99.364%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.625% | Wgt Acc: 99.354%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.594% | Wgt Acc: 99.345%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.604% | Wgt Acc: 99.349% | LR: 1.250000e-05 | Dur: 135.23s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  13.]
 [  0.   0.   0. 538.  26.]
 [  0.   0.   0.   0. 915.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.014 | Acc: 66.469% | Wgt Acc: 55.657% | Dur: 18.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   3.   2.  16.   3.]
 [  0.  37.   2.   0.   2.]
 [  0.   8.  20.   0.   4.]
 [  1.   2.   5.  40.   2.]
 [ 16.  28.  46.  30. 169.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 221
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 99.159%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.562% | Wgt Acc: 99.275%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.278%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.375% | Wgt Acc: 99.257%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.463% | Wgt Acc: 99.283% | LR: 1.250000e-05 | Dur: 135.13s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  39.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  21.]
 [  1.   0.   0.   0. 911.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.019 | Acc: 68.639% | Wgt Acc: 57.687% | Dur: 14.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  13.   3.]
 [  0.  36.   2.   1.   0.]
 [  0.   6.  21.   0.   1.]
 [  6.   1.   5.  47.   2.]
 [ 12.  32.  46.  25. 174.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 222
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.750% | Wgt Acc: 99.393%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.414%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.833% | Wgt Acc: 99.406%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.844% | Wgt Acc: 99.414%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.660% | Wgt Acc: 99.364% | LR: 1.250000e-05 | Dur: 136.19s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  24.]
 [  0.   0.   0.   0. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 68.047% | Wgt Acc: 58.390% | Dur: 14.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   1.   1.  10.   4.]
 [  0.  36.   2.   0.   0.]
 [  2.   6.  27.   1.   4.]
 [  3.   1.   5.  49.   5.]
 [ 17.  34.  40.  26. 167.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 223
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.500% | Wgt Acc: 99.315%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.812% | Wgt Acc: 99.405%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.917% | Wgt Acc: 99.432%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.938% | Wgt Acc: 99.440%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.914% | Wgt Acc: 99.433% | LR: 1.250000e-05 | Dur: 134.77s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  23.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  16.]
 [  0.   0.   0.   0. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.028 | Acc: 67.061% | Wgt Acc: 55.968% | Dur: 14.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   3.   2.  13.   4.]
 [  0.  31.   2.   0.   1.]
 [  1.   6.  17.   0.   1.]
 [  2.   2.   5.  49.   2.]
 [ 14.  36.  49.  24. 172.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 224
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 98.000% | Wgt Acc: 99.464%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.812% | Wgt Acc: 99.405%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.708% | Wgt Acc: 99.375%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.750% | Wgt Acc: 99.354%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.829% | Wgt Acc: 99.379% | LR: 1.250000e-05 | Dur: 135.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  29.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 734.   1.  18.]
 [  0.   0.   0. 537.  21.]
 [  0.   0.   0.   0. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 65.089% | Wgt Acc: 53.454% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   1.   1.  14.   2.]
 [  0.  37.   1.   0.   2.]
 [  1.   6.  21.   0.   3.]
 [  4.   0.   6.  43.   2.]
 [ 25.  34.  46.  29. 171.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 225
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 99.353%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.875% | Wgt Acc: 99.429%
	I - Batch: 150 | Loss: 0.470 | Acc: 98.000% | Wgt Acc: 99.458%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.969% | Wgt Acc: 99.448%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.942% | Wgt Acc: 99.413% | LR: 1.250000e-05 | Dur: 134.38s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  11.]
 [  0.   0.   0. 538.  18.]
 [  1.   0.   0.   0. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.061% | Wgt Acc: 56.453% | Dur: 14.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   3.  24.   3.]
 [  0.  39.   2.   0.   1.]
 [  1.   3.  24.   0.   4.]
 [  4.   2.   5.  39.   3.]
 [ 14.  30.  41.  23. 169.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 226
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 98.500% | Wgt Acc: 99.595%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.938% | Wgt Acc: 99.445%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.625% | Wgt Acc: 99.310%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.625% | Wgt Acc: 99.323%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.801% | Wgt Acc: 99.373% | LR: 1.250000e-05 | Dur: 134.55s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  32.]
 [  0. 577.   0.   0.   9.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  18.]
 [  0.   1.   0.   0. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.003 | Acc: 69.034% | Wgt Acc: 58.897% | Dur: 16.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   2.  12.   3.]
 [  0.  39.   2.   1.   1.]
 [  1.   5.  27.   0.   3.]
 [  5.   1.   4.  48.   2.]
 [ 17.  31.  40.  25. 171.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 227
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 98.500% | Wgt Acc: 99.469%
	I - Batch: 100 | Loss: 0.469 | Acc: 98.062% | Wgt Acc: 99.412%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.377%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.388%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.914% | Wgt Acc: 99.372% | LR: 1.250000e-05 | Dur: 132.73s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  32.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  11.]
 [  0.   0.   0. 536.  20.]
 [  0.   0.   0.   2. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.019 | Acc: 67.653% | Wgt Acc: 57.629% | Dur: 15.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  11.   6.]
 [  0.  38.   2.   0.   3.]
 [  0.   5.  25.   0.   1.]
 [  7.   1.   6.  47.   2.]
 [ 16.  30.  40.  28. 168.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 228
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 96.625% | Wgt Acc: 99.081%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.062% | Wgt Acc: 99.203%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 99.255%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 99.254%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.322% | Wgt Acc: 99.272% | LR: 1.250000e-05 | Dur: 135.70s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  22.]
 [  0.   0.   0.   0. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.043 | Acc: 65.483% | Wgt Acc: 54.077% | Dur: 21.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   1.   2.   9.   4.]
 [  0.  33.   2.   0.   2.]
 [  1.   4.  22.   0.   1.]
 [  6.   2.   6.  49.   2.]
 [ 24.  38.  43.  28. 171.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 229
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.250% | Wgt Acc: 99.265%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.812% | Wgt Acc: 99.402%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.708% | Wgt Acc: 99.375%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.594% | Wgt Acc: 99.344%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.632% | Wgt Acc: 99.356% | LR: 1.250000e-05 | Dur: 135.75s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  24.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  24.]
 [  0.   0.   0. 538.  27.]
 [  0.   0.   0.   0. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.024 | Acc: 66.075% | Wgt Acc: 55.934% | Dur: 14.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   1.  15.   7.]
 [  0.  35.   2.   1.   2.]
 [  1.   6.  24.   0.   4.]
 [  2.   1.   4.  40.   2.]
 [ 14.  32.  44.  30. 165.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 230
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 98.000% | Wgt Acc: 99.451%
	I - Batch: 100 | Loss: 0.469 | Acc: 98.062% | Wgt Acc: 99.473%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.917% | Wgt Acc: 99.435%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.426%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.632% | Wgt Acc: 99.356% | LR: 1.250000e-05 | Dur: 137.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 538.  20.]
 [  0.   0.   0.   0. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.036 | Acc: 64.892% | Wgt Acc: 53.915% | Dur: 18.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  16.   6.]
 [  0.  34.   3.   1.   2.]
 [  1.   7.  23.   0.   3.]
 [  3.   1.   5.  40.   2.]
 [ 19.  32.  42.  29. 167.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 231
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 98.625% | Wgt Acc: 99.629%
	I - Batch: 100 | Loss: 0.471 | Acc: 98.312% | Wgt Acc: 99.544%
	I - Batch: 150 | Loss: 0.472 | Acc: 98.125% | Wgt Acc: 99.450%
	I - Batch: 200 | Loss: 0.471 | Acc: 98.219% | Wgt Acc: 99.486%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 98.083% | Wgt Acc: 99.451% | LR: 1.250000e-05 | Dur: 134.38s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  33.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  14.]
 [  0.   0.   0. 538.  13.]
 [  1.   0.   0.   0. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.028 | Acc: 67.456% | Wgt Acc: 56.441% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  12.   2.]
 [  0.  34.   2.   0.   0.]
 [  0.   3.  23.   0.   3.]
 [  4.   1.   5.  45.   3.]
 [ 16.  37.  44.  29. 172.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 232
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 98.125% | Wgt Acc: 99.482%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.938% | Wgt Acc: 99.433%
	I - Batch: 150 | Loss: 0.469 | Acc: 98.167% | Wgt Acc: 99.498%
	I - Batch: 200 | Loss: 0.470 | Acc: 98.031% | Wgt Acc: 99.462%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.998% | Wgt Acc: 99.456% | LR: 1.250000e-05 | Dur: 133.91s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  28.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  18.]
 [  0.   0.   0.   0. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.653% | Wgt Acc: 57.041% | Dur: 16.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   0.   1.  10.   4.]
 [  0.  35.   2.   0.   0.]
 [  0.   5.  24.   0.   3.]
 [  7.   1.   5.  50.   2.]
 [ 18.  37.  43.  26. 171.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 233
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 99.128%
	I - Batch: 100 | Loss: 0.476 | Acc: 96.938% | Wgt Acc: 98.986%
	I - Batch: 150 | Loss: 0.476 | Acc: 96.917% | Wgt Acc: 99.044%
	I - Batch: 200 | Loss: 0.475 | Acc: 97.156% | Wgt Acc: 99.131%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.124% | Wgt Acc: 99.134% | LR: 1.250000e-05 | Dur: 133.19s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  43.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  24.]
 [  2.   1.   0.   0. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 67.850% | Wgt Acc: 58.517% | Dur: 14.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   0.  12.   5.]
 [  0.  38.   3.   0.   1.]
 [  0.   7.  28.   0.   7.]
 [  5.   1.   5.  47.   2.]
 [ 17.  30.  39.  27. 165.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 234
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 99.381%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.750% | Wgt Acc: 99.389%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.917% | Wgt Acc: 99.394%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.906% | Wgt Acc: 99.369%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.886% | Wgt Acc: 99.370% | LR: 1.250000e-05 | Dur: 136.58s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  22.]
 [  0. 578.   0.   0.   5.]
 [  0.   0. 734.   0.  19.]
 [  0.   0.   0. 538.  27.]
 [  2.   0.   0.   0. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.061% | Wgt Acc: 56.349% | Dur: 17.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   2.  14.   2.]
 [  0.  36.   3.   0.   2.]
 [  0.   4.  22.   0.   2.]
 [  4.   2.   6.  45.   4.]
 [ 17.  32.  42.  27. 170.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 235
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 98.125% | Wgt Acc: 99.500%
	I - Batch: 100 | Loss: 0.466 | Acc: 98.375% | Wgt Acc: 99.561%
	I - Batch: 150 | Loss: 0.468 | Acc: 98.292% | Wgt Acc: 99.535%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.969% | Wgt Acc: 99.416%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.857% | Wgt Acc: 99.390% | LR: 1.250000e-05 | Dur: 135.14s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  14.]
 [  1.   0.   0.   0. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.653% | Wgt Acc: 56.937% | Dur: 14.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   1.  13.   5.]
 [  0.  32.   1.   1.   1.]
 [  0.   6.  25.   0.   1.]
 [  3.   3.   6.  47.   2.]
 [ 17.  34.  42.  25. 171.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 236
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.250% | Wgt Acc: 99.254%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.188% | Wgt Acc: 99.235%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.500% | Wgt Acc: 99.321%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.625% | Wgt Acc: 99.356%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.322% | Wgt Acc: 99.272% | LR: 1.250000e-05 | Dur: 142.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  38.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  26.]
 [  0.   0.   0. 538.  22.]
 [  0.   0.   0.   0. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.032 | Acc: 65.089% | Wgt Acc: 53.500% | Dur: 19.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   0.   1.   7.   3.]
 [  0.  33.   2.   0.   1.]
 [  0.   6.  20.   0.   2.]
 [  6.   1.   5.  47.   3.]
 [ 23.  38.  47.  32. 171.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 237
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 96.750% | Wgt Acc: 99.093%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.312% | Wgt Acc: 99.195%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.750% | Wgt Acc: 99.342%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.656% | Wgt Acc: 99.327%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.716% | Wgt Acc: 99.349% | LR: 1.250000e-05 | Dur: 135.14s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  37.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.   9.]
 [  0.   0.   0. 537.  23.]
 [  0.   0.   0.   1. 920.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.000 | Acc: 67.653% | Wgt Acc: 58.840% | Dur: 14.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   2.   3.  17.   7.]
 [  0.  37.   2.   0.   4.]
 [  0.   7.  29.   0.   5.]
 [  6.   2.   7.  46.   2.]
 [ 13.  30.  34.  23. 162.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 238
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.625% | Wgt Acc: 99.366%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 99.291%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.292% | Wgt Acc: 99.270%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 99.304%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.463% | Wgt Acc: 99.310% | LR: 1.250000e-05 | Dur: 133.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  33.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 734.   0.  21.]
 [  0.   0.   0. 538.  21.]
 [  0.   0.   0.   0. 910.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.037 | Acc: 66.667% | Wgt Acc: 55.911% | Dur: 14.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  15.   6.]
 [  0.  34.   3.   0.   1.]
 [  0.   3.  24.   0.   3.]
 [  4.   1.   6.  41.   1.]
 [ 14.  37.  41.  30. 169.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 239
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.875% | Wgt Acc: 99.282%
	I - Batch: 100 | Loss: 0.472 | Acc: 98.000% | Wgt Acc: 99.390%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.750% | Wgt Acc: 99.344%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.750% | Wgt Acc: 99.357%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.801% | Wgt Acc: 99.375% | LR: 1.250000e-05 | Dur: 134.41s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  39.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  12.]
 [  0.   0.   0. 538.  15.]
 [  1.   0.   0.   0. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 67.850% | Wgt Acc: 57.802% | Dur: 16.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   4.   2.  15.   5.]
 [  0.  34.   3.   1.   1.]
 [  0.   5.  25.   0.   4.]
 [  2.   3.   6.  45.   2.]
 [ 14.  32.  39.  25. 168.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 240
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.000% | Wgt Acc: 99.459%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.875% | Wgt Acc: 99.363%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.542% | Wgt Acc: 99.245%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.438% | Wgt Acc: 99.237%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.406% | Wgt Acc: 99.206% | LR: 1.250000e-05 | Dur: 135.27s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  36.]
 [  0. 578.   0.   0.  16.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 536.  21.]
 [  1.   0.   0.   2. 911.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.009 | Acc: 67.456% | Wgt Acc: 57.560% | Dur: 14.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  16.   5.]
 [  0.  37.   2.   1.   1.]
 [  1.   6.  22.   0.   4.]
 [  3.   2.   6.  47.   3.]
 [ 15.  29.  44.  22. 167.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 241
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.250% | Wgt Acc: 99.545%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 99.298%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.583% | Wgt Acc: 99.351%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.344% | Wgt Acc: 99.212%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.491% | Wgt Acc: 99.258% | LR: 1.250000e-05 | Dur: 139.19s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  37.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 537.  19.]
 [  0.   1.   0.   1. 913.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.061% | Wgt Acc: 55.530% | Dur: 15.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   0.   9.   1.]
 [  0.  33.   3.   1.   0.]
 [  0.   8.  27.   0.   3.]
 [  5.   1.   5.  47.   2.]
 [ 24.  33.  40.  29. 174.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 242
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.875% | Wgt Acc: 99.436%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.938% | Wgt Acc: 99.465%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 99.384%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.719% | Wgt Acc: 99.409%
I - num batch: 208
I - Train -- Loss: 0.469 | Acc: 97.746% | Wgt Acc: 99.415% | LR: 1.250000e-05 | Dur: 127.26s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  25.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 734.   0.  17.]
 [  0.   0.   0. 538.  22.]
 [  0.   0.   0.   0. 706.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 67.850% | Wgt Acc: 58.286% | Dur: 14.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   0.  12.   5.]
 [  0.  36.   3.   0.   4.]
 [  1.   5.  27.   0.   3.]
 [  5.   1.   7.  47.   2.]
 [ 14.  33.  38.  27. 166.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 243
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.375% | Wgt Acc: 99.155%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 99.253%
	I - Batch: 150 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 99.197%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.500% | Wgt Acc: 99.260%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.547% | Wgt Acc: 99.250% | LR: 1.250000e-05 | Dur: 135.25s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  42.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  23.]
 [  0.   0.   0. 538.  12.]
 [  3.   0.   0.   0. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 65.483% | Wgt Acc: 54.238% | Dur: 16.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  15.   3.]
 [  0.  31.   2.   1.   1.]
 [  1.   6.  27.   0.   5.]
 [  3.   2.   4.  39.   2.]
 [ 18.  37.  41.  31. 169.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 244
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 98.875% | Wgt Acc: 99.700%
	I - Batch: 100 | Loss: 0.468 | Acc: 98.250% | Wgt Acc: 99.471%
	I - Batch: 150 | Loss: 0.469 | Acc: 98.042% | Wgt Acc: 99.432%
	I - Batch: 200 | Loss: 0.470 | Acc: 98.000% | Wgt Acc: 99.427%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.970% | Wgt Acc: 99.421% | LR: 1.250000e-05 | Dur: 136.72s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  27.]
 [  0. 578.   0.   0.   9.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  19.]
 [  1.   0.   0.   0. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.014 | Acc: 66.864% | Wgt Acc: 56.487% | Dur: 15.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  13.   4.]
 [  0.  35.   2.   0.   2.]
 [  1.   7.  25.   0.   4.]
 [  4.   1.   3.  45.   2.]
 [ 17.  33.  44.  28. 168.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 245
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 97.125% | Wgt Acc: 99.214%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.312% | Wgt Acc: 99.271%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.292% | Wgt Acc: 99.260%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.438% | Wgt Acc: 99.269%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.491% | Wgt Acc: 99.287% | LR: 1.250000e-05 | Dur: 135.93s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  38.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   1.  17.]
 [  0.   0.   0. 537.  26.]
 [  0.   0.   0.   0. 912.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.015 | Acc: 68.442% | Wgt Acc: 57.929% | Dur: 17.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   3.   1.  18.   4.]
 [  0.  40.   2.   0.   1.]
 [  0.   3.  24.   0.   2.]
 [  1.   2.   5.  40.   2.]
 [ 15.  30.  43.  28. 171.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 246
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 98.250% | Wgt Acc: 99.536%
	I - Batch: 100 | Loss: 0.470 | Acc: 98.125% | Wgt Acc: 99.494%
	I - Batch: 150 | Loss: 0.471 | Acc: 98.208% | Wgt Acc: 99.475%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.906% | Wgt Acc: 99.401%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.970% | Wgt Acc: 99.421% | LR: 1.250000e-05 | Dur: 137.04s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.  33.]
 [  0. 578.   0.   0.   7.]
 [  0.   0. 734.   0.  16.]
 [  0.   0.   0. 538.  15.]
 [  1.   0.   0.   0. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.012 | Acc: 67.653% | Wgt Acc: 58.275% | Dur: 14.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   1.  13.   5.]
 [  0.  38.   2.   0.   3.]
 [  0.   6.  23.   0.   5.]
 [  4.   2.   5.  48.   2.]
 [ 15.  29.  44.  25. 165.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 247
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.125% | Wgt Acc: 99.215%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.812% | Wgt Acc: 99.408%
	I - Batch: 150 | Loss: 0.471 | Acc: 98.042% | Wgt Acc: 99.467%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.938% | Wgt Acc: 99.440%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.942% | Wgt Acc: 99.440% | LR: 1.250000e-05 | Dur: 138.64s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  42.]
 [  0. 578.   0.   0.   6.]
 [  0.   0. 734.   0.  11.]
 [  0.   0.   0. 538.  14.]
 [  0.   0.   0.   0. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.245% | Wgt Acc: 57.848% | Dur: 14.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   1.  10.   4.]
 [  0.  40.   2.   1.   1.]
 [  0.   7.  27.   0.   3.]
 [  6.   1.   4.  48.   1.]
 [ 22.  29.  41.  27. 171.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 248
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.875% | Wgt Acc: 99.408%
	I - Batch: 100 | Loss: 0.471 | Acc: 98.062% | Wgt Acc: 99.400%
	I - Batch: 150 | Loss: 0.470 | Acc: 98.042% | Wgt Acc: 99.419%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.719% | Wgt Acc: 99.344%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.716% | Wgt Acc: 99.350% | LR: 1.250000e-05 | Dur: 134.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  34.]
 [  0. 577.   0.   0.  16.]
 [  0.   0. 734.   0.  20.]
 [  0.   0.   0. 538.  10.]
 [  0.   1.   0.   0. 920.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.037 | Acc: 66.667% | Wgt Acc: 56.568% | Dur: 16.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   4.   0.  15.   7.]
 [  0.  31.   2.   0.   1.]
 [  1.   8.  26.   0.   4.]
 [  3.   2.   7.  44.   2.]
 [ 13.  33.  40.  27. 166.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 249
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 99.101%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.500% | Wgt Acc: 99.257%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.542% | Wgt Acc: 99.289%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.438% | Wgt Acc: 99.237%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.575% | Wgt Acc: 99.281% | LR: 1.250000e-05 | Dur: 134.14s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.  28.]
 [  0. 577.   0.   0.  10.]
 [  0.   0. 734.   0.  18.]
 [  0.   0.   0. 537.  28.]
 [  0.   1.   0.   1. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 68.639% | Wgt Acc: 58.286% | Dur: 14.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   4.   1.  14.   3.]
 [  0.  36.   2.   1.   1.]
 [  1.  12.  26.   0.   3.]
 [  4.   1.   7.  46.   2.]
 [ 14.  25.  39.  25. 171.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Maximum validation set accuracy in current training:  71.20
