Mon Sep 26 15:25:27 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.21, 0.26, 0.24, 0.21, 0.08], 'classWeightsFlag': True, 'dataConfig': {'augmentData': True, 'bulkPickles': True, 'dataCount': 5, 'loadData2memory': True}, 'dataPath': '/data/processed/Kinetics/', 'epochNo': 200, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 2, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 18, 'validationAccThr': 60, 'weightDecay': 0.001}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  14004
I - Label distribution: [1886.  927. 1335. 1926. 7930.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Test set length:  3086
I - Label distribution: [ 535.  370.  392.  574. 1215.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([ 2848,  3718,  2822,  4350,  7912, 11701,  4979,  3939,  1560,    96,
         4978, 12275, 13371,  4675,  1026,  7211])
I - Initializing model TCNv2
I - Number of Model Parameters: 910464
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv2                                    [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-61                        [16, 64, 32, 32]          --
│    └─Empty: 2-62                       [16, 64, 32, 32]          --
│    └─Clamp: 2-63                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-64          --                        --
│    └─One: 2-65                         [1]                       --
│    └─OutputScale: 2-66                 --                        --
│    └─Empty: 2-67                       [64, 64, 3, 3]            --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64]                      --
│    └─Empty: 2-70                       [64]                      --
│    └─BatchNorm2d: 2-71                 [16, 64, 32, 32]          --
│    └─Scaler: 2-72                      [16, 64, 32, 32]          --
│    └─ReLU: 2-73                        [16, 64, 32, 32]          --
│    └─Empty: 2-74                       [16, 64, 32, 32]          --
│    └─Clamp: 2-75                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-76                   [16, 64, 16, 16]          --
│    └─Empty: 2-77                       [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-79          --                        --
│    └─One: 2-80                         [1]                       --
│    └─OutputScale: 2-81                 --                        --
│    └─Empty: 2-82                       [64, 64, 3, 3]            --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64]                      --
│    └─Empty: 2-85                       [64]                      --
│    └─BatchNorm2d: 2-86                 [16, 64, 16, 16]          --
│    └─Scaler: 2-87                      [16, 64, 16, 16]          --
│    └─ReLU: 2-88                        [16, 64, 16, 16]          --
│    └─Empty: 2-89                       [16, 64, 16, 16]          --
│    └─Clamp: 2-90                       [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-91          --                        --
│    └─One: 2-92                         [1]                       --
│    └─OutputScale: 2-93                 --                        --
│    └─Empty: 2-94                       [64, 64, 3, 3]            --
│    └─Empty: 2-95                       [64, 64, 3, 3]            --
│    └─Empty: 2-96                       [64]                      --
│    └─Empty: 2-97                       [64]                      --
│    └─BatchNorm2d: 2-98                 [16, 64, 16, 16]          --
│    └─Scaler: 2-99                      [16, 64, 16, 16]          --
│    └─ReLU: 2-100                       [16, 64, 16, 16]          --
│    └─Empty: 2-101                      [16, 64, 16, 16]          --
│    └─Clamp: 2-102                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-103                  [16, 64, 8, 8]            --
│    └─Empty: 2-104                      [16, 64, 8, 8]            --
│    └─Empty: 2-105                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-106         --                        --
│    └─One: 2-107                        [1]                       --
│    └─OutputScale: 2-108                --                        --
│    └─Empty: 2-109                      [64, 64, 3, 3]            --
│    └─Empty: 2-110                      [64, 64, 3, 3]            --
│    └─Empty: 2-111                      [64]                      --
│    └─Empty: 2-112                      [64]                      --
│    └─BatchNorm2d: 2-113                [16, 64, 8, 8]            --
│    └─Scaler: 2-114                     [16, 64, 8, 8]            --
│    └─ReLU: 2-115                       [16, 64, 8, 8]            --
│    └─Empty: 2-116                      [16, 64, 8, 8]            --
│    └─Clamp: 2-117                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-118         --                        --
│    └─One: 2-119                        [1]                       --
│    └─OutputScale: 2-120                --                        --
│    └─Empty: 2-121                      [64, 64, 1, 1]            --
│    └─Empty: 2-122                      [64, 64, 1, 1]            --
│    └─Empty: 2-123                      [64]                      --
│    └─Empty: 2-124                      [64]                      --
│    └─BatchNorm2d: 2-125                [16, 64, 8, 8]            --
│    └─Scaler: 2-126                     [16, 64, 8, 8]            --
│    └─ReLU: 2-127                       [16, 64, 8, 8]            --
│    └─Empty: 2-128                      [16, 64, 8, 8]            --
│    └─Clamp: 2-129                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-130                  [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Empty: 2-132                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-133         --                        --
│    └─One: 2-134                        [1]                       --
│    └─OutputScale: 2-135                --                        --
│    └─Empty: 2-136                      [64, 64, 3, 3]            --
│    └─Empty: 2-137                      [64, 64, 3, 3]            --
│    └─Empty: 2-138                      [64]                      --
│    └─Empty: 2-139                      [64]                      --
│    └─BatchNorm2d: 2-140                [16, 64, 8, 8]            --
│    └─Scaler: 2-141                     [16, 64, 8, 8]            --
│    └─ReLU: 2-142                       [16, 64, 8, 8]            --
│    └─Empty: 2-143                      [16, 64, 8, 8]            --
│    └─Clamp: 2-144                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-145                  [16, 64, 4, 4]            --
│    └─Empty: 2-146                      [16, 64, 4, 4]            --
│    └─Empty: 2-147                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-148         --                        --
│    └─One: 2-149                        [1]                       --
│    └─OutputScale: 2-150                --                        --
│    └─Empty: 2-151                      [64, 64, 3, 3]            --
│    └─Empty: 2-152                      [64, 64, 3, 3]            --
│    └─Empty: 2-153                      [64]                      --
│    └─Empty: 2-154                      [64]                      --
│    └─BatchNorm2d: 2-155                [16, 64, 4, 4]            --
│    └─Scaler: 2-156                     [16, 64, 4, 4]            --
│    └─ReLU: 2-157                       [16, 64, 4, 4]            --
│    └─Empty: 2-158                      [16, 64, 4, 4]            --
│    └─Clamp: 2-159                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-160         --                        --
│    └─One: 2-161                        [1]                       --
│    └─OutputScale: 2-162                --                        --
│    └─Empty: 2-163                      [64, 64, 1, 1]            --
│    └─Empty: 2-164                      [64, 64, 1, 1]            --
│    └─Empty: 2-165                      [64]                      --
│    └─Empty: 2-166                      [64]                      --
│    └─BatchNorm2d: 2-167                [16, 64, 4, 4]            --
│    └─Scaler: 2-168                     [16, 64, 4, 4]            --
│    └─ReLU: 2-169                       [16, 64, 4, 4]            --
│    └─Empty: 2-170                      [16, 64, 4, 4]            --
│    └─Clamp: 2-171                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-172                  [16, 64, 4, 4]            --
│    └─Empty: 2-173                      [16, 64, 4, 4]            --
│    └─Empty: 2-174                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-175         --                        --
│    └─One: 2-176                        [1]                       --
│    └─OutputScale: 2-177                --                        --
│    └─Empty: 2-178                      [64, 64, 3, 3]            --
│    └─Empty: 2-179                      [64, 64, 3, 3]            --
│    └─Empty: 2-180                      [64]                      --
│    └─Empty: 2-181                      [64]                      --
│    └─BatchNorm2d: 2-182                [16, 64, 4, 4]            --
│    └─Scaler: 2-183                     [16, 64, 4, 4]            --
│    └─ReLU: 2-184                       [16, 64, 4, 4]            --
│    └─Empty: 2-185                      [16, 64, 4, 4]            --
│    └─Clamp: 2-186                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-187                  [16, 64, 2, 2]            --
│    └─Empty: 2-188                      [16, 64, 2, 2]            --
│    └─Empty: 2-189                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-190         --                        --
│    └─One: 2-191                        [1]                       --
│    └─OutputScale: 2-192                --                        --
│    └─Empty: 2-193                      [64, 64, 1, 1]            --
│    └─Empty: 2-194                      [64, 64, 1, 1]            --
│    └─Empty: 2-195                      [64]                      --
│    └─Empty: 2-196                      [64]                      --
│    └─BatchNorm2d: 2-197                [16, 64, 2, 2]            --
│    └─Scaler: 2-198                     [16, 64, 2, 2]            --
│    └─ReLU: 2-199                       [16, 64, 2, 2]            --
│    └─Empty: 2-200                      [16, 64, 2, 2]            --
│    └─Clamp: 2-201                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-202         --                        --
│    └─One: 2-203                        [1]                       --
│    └─OutputScale: 2-204                --                        --
│    └─Empty: 2-205                      [64, 64, 1, 1]            --
│    └─Empty: 2-206                      [64, 64, 1, 1]            --
│    └─Empty: 2-207                      [64]                      --
│    └─Empty: 2-208                      [64]                      --
│    └─BatchNorm2d: 2-209                [16, 64, 2, 2]            --
│    └─Scaler: 2-210                     [16, 64, 2, 2]            --
│    └─ReLU: 2-211                       [16, 64, 2, 2]            --
│    └─Empty: 2-212                      [16, 64, 2, 2]            --
│    └─Clamp: 2-213                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-214                  [16, 64, 2, 2]            --
│    └─Empty: 2-215                      [16, 64, 2, 2]            --
│    └─Empty: 2-216                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-217         --                        --
│    └─One: 2-218                        [1]                       --
│    └─OutputScale: 2-219                --                        --
│    └─Empty: 2-220                      [64, 64, 3, 3]            --
│    └─Empty: 2-221                      [64, 64, 3, 3]            --
│    └─Empty: 2-222                      [64]                      --
│    └─Empty: 2-223                      [64]                      --
│    └─BatchNorm2d: 2-224                [16, 64, 2, 2]            --
│    └─Scaler: 2-225                     [16, 64, 2, 2]            --
│    └─ReLU: 2-226                       [16, 64, 2, 2]            --
│    └─Empty: 2-227                      [16, 64, 2, 2]            --
│    └─Clamp: 2-228                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-229         --                        --
│    └─One: 2-230                        [1]                       --
│    └─OutputScale: 2-231                --                        --
│    └─Empty: 2-232                      [64, 48, 1, 1]            --
│    └─Empty: 2-233                      [64, 48, 1, 1]            --
│    └─Empty: 2-234                      [64]                      --
│    └─Empty: 2-235                      [64]                      --
│    └─BatchNorm2d: 2-236                [16, 64, 64, 64]          --
│    └─Scaler: 2-237                     [16, 64, 64, 64]          --
│    └─ReLU: 2-238                       [16, 64, 64, 64]          --
│    └─Empty: 2-239                      [16, 64, 64, 64]          --
│    └─Clamp: 2-240                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-241         --                        --
│    └─One: 2-242                        [1]                       --
│    └─OutputScale: 2-243                --                        --
│    └─Empty: 2-244                      [64, 64, 3, 3]            --
│    └─Empty: 2-245                      [64, 64, 3, 3]            --
│    └─Empty: 2-246                      [64]                      --
│    └─Empty: 2-247                      [64]                      --
│    └─BatchNorm2d: 2-248                [16, 64, 64, 64]          --
│    └─Scaler: 2-249                     [16, 64, 64, 64]          --
│    └─ReLU: 2-250                       [16, 64, 64, 64]          --
│    └─Empty: 2-251                      [16, 64, 64, 64]          --
│    └─Clamp: 2-252                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-253         --                        --
│    └─One: 2-254                        [1]                       --
│    └─OutputScale: 2-255                --                        --
│    └─Empty: 2-256                      [64, 64, 1, 1]            --
│    └─Empty: 2-257                      [64, 64, 1, 1]            --
│    └─Empty: 2-258                      [64]                      --
│    └─Empty: 2-259                      [64]                      --
│    └─BatchNorm2d: 2-260                [16, 64, 64, 64]          --
│    └─Scaler: 2-261                     [16, 64, 64, 64]          --
│    └─ReLU: 2-262                       [16, 64, 64, 64]          --
│    └─Empty: 2-263                      [16, 64, 64, 64]          --
│    └─Clamp: 2-264                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-265         --                        --
│    └─One: 2-266                        [1]                       --
│    └─OutputScale: 2-267                --                        --
│    └─Empty: 2-268                      [64, 64, 3, 3]            --
│    └─Empty: 2-269                      [64, 64, 3, 3]            --
│    └─Empty: 2-270                      [64]                      --
│    └─Empty: 2-271                      [64]                      --
│    └─BatchNorm2d: 2-272                [16, 64, 64, 64]          --
│    └─Scaler: 2-273                     [16, 64, 64, 64]          --
│    └─ReLU: 2-274                       [16, 64, 64, 64]          --
│    └─Empty: 2-275                      [16, 64, 64, 64]          --
│    └─Clamp: 2-276                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-277                  [16, 64, 32, 32]          --
│    └─Empty: 2-278                      [16, 64, 32, 32]          --
│    └─Empty: 2-279                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-280         --                        --
│    └─One: 2-281                        [1]                       --
│    └─OutputScale: 2-282                --                        --
│    └─Empty: 2-283                      [64, 64, 3, 3]            --
│    └─Empty: 2-284                      [64, 64, 3, 3]            --
│    └─Empty: 2-285                      [64]                      --
│    └─Empty: 2-286                      [64]                      --
│    └─BatchNorm2d: 2-287                [16, 64, 32, 32]          --
│    └─Scaler: 2-288                     [16, 64, 32, 32]          --
│    └─ReLU: 2-289                       [16, 64, 32, 32]          --
│    └─Empty: 2-290                      [16, 64, 32, 32]          --
│    └─Clamp: 2-291                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-292         --                        --
│    └─One: 2-293                        [1]                       --
│    └─OutputScale: 2-294                --                        --
│    └─Empty: 2-295                      [64, 64, 3, 3]            --
│    └─Empty: 2-296                      [64, 64, 3, 3]            --
│    └─Empty: 2-297                      [64]                      --
│    └─Empty: 2-298                      [64]                      --
│    └─BatchNorm2d: 2-299                [16, 64, 32, 32]          --
│    └─Scaler: 2-300                     [16, 64, 32, 32]          --
│    └─ReLU: 2-301                       [16, 64, 32, 32]          --
│    └─Empty: 2-302                      [16, 64, 32, 32]          --
│    └─Clamp: 2-303                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-304                  [16, 64, 16, 16]          --
│    └─Empty: 2-305                      [16, 64, 16, 16]          --
│    └─Empty: 2-306                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-307         --                        --
│    └─One: 2-308                        [1]                       --
│    └─OutputScale: 2-309                --                        --
│    └─Empty: 2-310                      [64, 64, 3, 3]            --
│    └─Empty: 2-311                      [64, 64, 3, 3]            --
│    └─Empty: 2-312                      [64]                      --
│    └─Empty: 2-313                      [64]                      --
│    └─BatchNorm2d: 2-314                [16, 64, 16, 16]          --
│    └─Scaler: 2-315                     [16, 64, 16, 16]          --
│    └─ReLU: 2-316                       [16, 64, 16, 16]          --
│    └─Empty: 2-317                      [16, 64, 16, 16]          --
│    └─Clamp: 2-318                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-319         --                        --
│    └─One: 2-320                        [1]                       --
│    └─OutputScale: 2-321                --                        --
│    └─Empty: 2-322                      [64, 64, 3, 3]            --
│    └─Empty: 2-323                      [64, 64, 3, 3]            --
│    └─Empty: 2-324                      [64]                      --
│    └─Empty: 2-325                      [64]                      --
│    └─BatchNorm2d: 2-326                [16, 64, 16, 16]          --
│    └─Scaler: 2-327                     [16, 64, 16, 16]          --
│    └─ReLU: 2-328                       [16, 64, 16, 16]          --
│    └─Empty: 2-329                      [16, 64, 16, 16]          --
│    └─Clamp: 2-330                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-331                  [16, 64, 8, 8]            --
│    └─Empty: 2-332                      [16, 64, 8, 8]            --
│    └─Empty: 2-333                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-334         --                        --
│    └─One: 2-335                        [1]                       --
│    └─OutputScale: 2-336                --                        --
│    └─Empty: 2-337                      [64, 64, 3, 3]            --
│    └─Empty: 2-338                      [64, 64, 3, 3]            --
│    └─Empty: 2-339                      [64]                      --
│    └─Empty: 2-340                      [64]                      --
│    └─BatchNorm2d: 2-341                [16, 64, 8, 8]            --
│    └─Scaler: 2-342                     [16, 64, 8, 8]            --
│    └─ReLU: 2-343                       [16, 64, 8, 8]            --
│    └─Empty: 2-344                      [16, 64, 8, 8]            --
│    └─Clamp: 2-345                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-346         --                        --
│    └─One: 2-347                        [1]                       --
│    └─OutputScale: 2-348                --                        --
│    └─Empty: 2-349                      [64, 64, 1, 1]            --
│    └─Empty: 2-350                      [64, 64, 1, 1]            --
│    └─Empty: 2-351                      [64]                      --
│    └─Empty: 2-352                      [64]                      --
│    └─BatchNorm2d: 2-353                [16, 64, 8, 8]            --
│    └─Scaler: 2-354                     [16, 64, 8, 8]            --
│    └─ReLU: 2-355                       [16, 64, 8, 8]            --
│    └─Empty: 2-356                      [16, 64, 8, 8]            --
│    └─Clamp: 2-357                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-358                  [16, 64, 8, 8]            --
│    └─Empty: 2-359                      [16, 64, 8, 8]            --
│    └─Empty: 2-360                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-361         --                        --
│    └─One: 2-362                        [1]                       --
│    └─OutputScale: 2-363                --                        --
│    └─Empty: 2-364                      [64, 64, 3, 3]            --
│    └─Empty: 2-365                      [64, 64, 3, 3]            --
│    └─Empty: 2-366                      [64]                      --
│    └─Empty: 2-367                      [64]                      --
│    └─BatchNorm2d: 2-368                [16, 64, 8, 8]            --
│    └─Scaler: 2-369                     [16, 64, 8, 8]            --
│    └─ReLU: 2-370                       [16, 64, 8, 8]            --
│    └─Empty: 2-371                      [16, 64, 8, 8]            --
│    └─Clamp: 2-372                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-373                  [16, 64, 4, 4]            --
│    └─Empty: 2-374                      [16, 64, 4, 4]            --
│    └─Empty: 2-375                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-376         --                        --
│    └─One: 2-377                        [1]                       --
│    └─OutputScale: 2-378                --                        --
│    └─Empty: 2-379                      [64, 64, 3, 3]            --
│    └─Empty: 2-380                      [64, 64, 3, 3]            --
│    └─Empty: 2-381                      [64]                      --
│    └─Empty: 2-382                      [64]                      --
│    └─BatchNorm2d: 2-383                [16, 64, 4, 4]            --
│    └─Scaler: 2-384                     [16, 64, 4, 4]            --
│    └─ReLU: 2-385                       [16, 64, 4, 4]            --
│    └─Empty: 2-386                      [16, 64, 4, 4]            --
│    └─Clamp: 2-387                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-388         --                        --
│    └─One: 2-389                        [1]                       --
│    └─OutputScale: 2-390                --                        --
│    └─Empty: 2-391                      [64, 64, 1, 1]            --
│    └─Empty: 2-392                      [64, 64, 1, 1]            --
│    └─Empty: 2-393                      [64]                      --
│    └─Empty: 2-394                      [64]                      --
│    └─BatchNorm2d: 2-395                [16, 64, 4, 4]            --
│    └─Scaler: 2-396                     [16, 64, 4, 4]            --
│    └─ReLU: 2-397                       [16, 64, 4, 4]            --
│    └─Empty: 2-398                      [16, 64, 4, 4]            --
│    └─Clamp: 2-399                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-400                  [16, 64, 4, 4]            --
│    └─Empty: 2-401                      [16, 64, 4, 4]            --
│    └─Empty: 2-402                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-403         --                        --
│    └─One: 2-404                        [1]                       --
│    └─OutputScale: 2-405                --                        --
│    └─Empty: 2-406                      [64, 64, 3, 3]            --
│    └─Empty: 2-407                      [64, 64, 3, 3]            --
│    └─Empty: 2-408                      [64]                      --
│    └─Empty: 2-409                      [64]                      --
│    └─BatchNorm2d: 2-410                [16, 64, 4, 4]            --
│    └─Scaler: 2-411                     [16, 64, 4, 4]            --
│    └─ReLU: 2-412                       [16, 64, 4, 4]            --
│    └─Empty: 2-413                      [16, 64, 4, 4]            --
│    └─Clamp: 2-414                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-415                  [16, 64, 2, 2]            --
│    └─Empty: 2-416                      [16, 64, 2, 2]            --
│    └─Empty: 2-417                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-418         --                        --
│    └─One: 2-419                        [1]                       --
│    └─OutputScale: 2-420                --                        --
│    └─Empty: 2-421                      [64, 64, 1, 1]            --
│    └─Empty: 2-422                      [64, 64, 1, 1]            --
│    └─Empty: 2-423                      [64]                      --
│    └─Empty: 2-424                      [64]                      --
│    └─BatchNorm2d: 2-425                [16, 64, 2, 2]            --
│    └─Scaler: 2-426                     [16, 64, 2, 2]            --
│    └─ReLU: 2-427                       [16, 64, 2, 2]            --
│    └─Empty: 2-428                      [16, 64, 2, 2]            --
│    └─Clamp: 2-429                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-430         --                        --
│    └─One: 2-431                        [1]                       --
│    └─OutputScale: 2-432                --                        --
│    └─Empty: 2-433                      [64, 64, 1, 1]            --
│    └─Empty: 2-434                      [64, 64, 1, 1]            --
│    └─Empty: 2-435                      [64]                      --
│    └─Empty: 2-436                      [64]                      --
│    └─BatchNorm2d: 2-437                [16, 64, 2, 2]            --
│    └─Scaler: 2-438                     [16, 64, 2, 2]            --
│    └─ReLU: 2-439                       [16, 64, 2, 2]            --
│    └─Empty: 2-440                      [16, 64, 2, 2]            --
│    └─Clamp: 2-441                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-442                  [16, 64, 2, 2]            --
│    └─Empty: 2-443                      [16, 64, 2, 2]            --
│    └─Empty: 2-444                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-445         --                        --
│    └─One: 2-446                        [1]                       --
│    └─OutputScale: 2-447                --                        --
│    └─Empty: 2-448                      [64, 64, 3, 3]            --
│    └─Empty: 2-449                      [64, 64, 3, 3]            --
│    └─Empty: 2-450                      [64]                      --
│    └─Empty: 2-451                      [64]                      --
│    └─BatchNorm2d: 2-452                [16, 64, 2, 2]            --
│    └─Scaler: 2-453                     [16, 64, 2, 2]            --
│    └─ReLU: 2-454                       [16, 64, 2, 2]            --
│    └─Empty: 2-455                      [16, 64, 2, 2]            --
│    └─Clamp: 2-456                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-457         --                        --
│    └─One: 2-458                        [1]                       --
│    └─OutputScale: 2-459                --                        --
│    └─Empty: 2-460                      [64, 48, 1, 1]            --
│    └─Empty: 2-461                      [64, 48, 1, 1]            --
│    └─Empty: 2-462                      [64]                      --
│    └─Empty: 2-463                      [64]                      --
│    └─BatchNorm2d: 2-464                [16, 64, 64, 64]          --
│    └─Scaler: 2-465                     [16, 64, 64, 64]          --
│    └─ReLU: 2-466                       [16, 64, 64, 64]          --
│    └─Empty: 2-467                      [16, 64, 64, 64]          --
│    └─Clamp: 2-468                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-469         --                        --
│    └─One: 2-470                        [1]                       --
│    └─OutputScale: 2-471                --                        --
│    └─Empty: 2-472                      [64, 64, 3, 3]            --
│    └─Empty: 2-473                      [64, 64, 3, 3]            --
│    └─Empty: 2-474                      [64]                      --
│    └─Empty: 2-475                      [64]                      --
│    └─BatchNorm2d: 2-476                [16, 64, 64, 64]          --
│    └─Scaler: 2-477                     [16, 64, 64, 64]          --
│    └─ReLU: 2-478                       [16, 64, 64, 64]          --
│    └─Empty: 2-479                      [16, 64, 64, 64]          --
│    └─Clamp: 2-480                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-481         --                        --
│    └─One: 2-482                        [1]                       --
│    └─OutputScale: 2-483                --                        --
│    └─Empty: 2-484                      [64, 64, 1, 1]            --
│    └─Empty: 2-485                      [64, 64, 1, 1]            --
│    └─Empty: 2-486                      [64]                      --
│    └─Empty: 2-487                      [64]                      --
│    └─BatchNorm2d: 2-488                [16, 64, 64, 64]          --
│    └─Scaler: 2-489                     [16, 64, 64, 64]          --
│    └─ReLU: 2-490                       [16, 64, 64, 64]          --
│    └─Empty: 2-491                      [16, 64, 64, 64]          --
│    └─Clamp: 2-492                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-493         --                        --
│    └─One: 2-494                        [1]                       --
│    └─OutputScale: 2-495                --                        --
│    └─Empty: 2-496                      [64, 64, 3, 3]            --
│    └─Empty: 2-497                      [64, 64, 3, 3]            --
│    └─Empty: 2-498                      [64]                      --
│    └─Empty: 2-499                      [64]                      --
│    └─BatchNorm2d: 2-500                [16, 64, 64, 64]          --
│    └─Scaler: 2-501                     [16, 64, 64, 64]          --
│    └─ReLU: 2-502                       [16, 64, 64, 64]          --
│    └─Empty: 2-503                      [16, 64, 64, 64]          --
│    └─Clamp: 2-504                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-505                  [16, 64, 32, 32]          --
│    └─Empty: 2-506                      [16, 64, 32, 32]          --
│    └─Empty: 2-507                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-508         --                        --
│    └─One: 2-509                        [1]                       --
│    └─OutputScale: 2-510                --                        --
│    └─Empty: 2-511                      [64, 64, 3, 3]            --
│    └─Empty: 2-512                      [64, 64, 3, 3]            --
│    └─Empty: 2-513                      [64]                      --
│    └─Empty: 2-514                      [64]                      --
│    └─BatchNorm2d: 2-515                [16, 64, 32, 32]          --
│    └─Scaler: 2-516                     [16, 64, 32, 32]          --
│    └─ReLU: 2-517                       [16, 64, 32, 32]          --
│    └─Empty: 2-518                      [16, 64, 32, 32]          --
│    └─Clamp: 2-519                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-520         --                        --
│    └─One: 2-521                        [1]                       --
│    └─OutputScale: 2-522                --                        --
│    └─Empty: 2-523                      [64, 64, 3, 3]            --
│    └─Empty: 2-524                      [64, 64, 3, 3]            --
│    └─Empty: 2-525                      [64]                      --
│    └─Empty: 2-526                      [64]                      --
│    └─BatchNorm2d: 2-527                [16, 64, 32, 32]          --
│    └─Scaler: 2-528                     [16, 64, 32, 32]          --
│    └─ReLU: 2-529                       [16, 64, 32, 32]          --
│    └─Empty: 2-530                      [16, 64, 32, 32]          --
│    └─Clamp: 2-531                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-532                  [16, 64, 16, 16]          --
│    └─Empty: 2-533                      [16, 64, 16, 16]          --
│    └─Empty: 2-534                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-535         --                        --
│    └─One: 2-536                        [1]                       --
│    └─OutputScale: 2-537                --                        --
│    └─Empty: 2-538                      [64, 64, 3, 3]            --
│    └─Empty: 2-539                      [64, 64, 3, 3]            --
│    └─Empty: 2-540                      [64]                      --
│    └─Empty: 2-541                      [64]                      --
│    └─BatchNorm2d: 2-542                [16, 64, 16, 16]          --
│    └─Scaler: 2-543                     [16, 64, 16, 16]          --
│    └─ReLU: 2-544                       [16, 64, 16, 16]          --
│    └─Empty: 2-545                      [16, 64, 16, 16]          --
│    └─Clamp: 2-546                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-547         --                        --
│    └─One: 2-548                        [1]                       --
│    └─OutputScale: 2-549                --                        --
│    └─Empty: 2-550                      [64, 64, 3, 3]            --
│    └─Empty: 2-551                      [64, 64, 3, 3]            --
│    └─Empty: 2-552                      [64]                      --
│    └─Empty: 2-553                      [64]                      --
│    └─BatchNorm2d: 2-554                [16, 64, 16, 16]          --
│    └─Scaler: 2-555                     [16, 64, 16, 16]          --
│    └─ReLU: 2-556                       [16, 64, 16, 16]          --
│    └─Empty: 2-557                      [16, 64, 16, 16]          --
│    └─Clamp: 2-558                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-559                  [16, 64, 8, 8]            --
│    └─Empty: 2-560                      [16, 64, 8, 8]            --
│    └─Empty: 2-561                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-562         --                        --
│    └─One: 2-563                        [1]                       --
│    └─OutputScale: 2-564                --                        --
│    └─Empty: 2-565                      [64, 64, 3, 3]            --
│    └─Empty: 2-566                      [64, 64, 3, 3]            --
│    └─Empty: 2-567                      [64]                      --
│    └─Empty: 2-568                      [64]                      --
│    └─BatchNorm2d: 2-569                [16, 64, 8, 8]            --
│    └─Scaler: 2-570                     [16, 64, 8, 8]            --
│    └─ReLU: 2-571                       [16, 64, 8, 8]            --
│    └─Empty: 2-572                      [16, 64, 8, 8]            --
│    └─Clamp: 2-573                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-574         --                        --
│    └─One: 2-575                        [1]                       --
│    └─OutputScale: 2-576                --                        --
│    └─Empty: 2-577                      [64, 64, 1, 1]            --
│    └─Empty: 2-578                      [64, 64, 1, 1]            --
│    └─Empty: 2-579                      [64]                      --
│    └─Empty: 2-580                      [64]                      --
│    └─BatchNorm2d: 2-581                [16, 64, 8, 8]            --
│    └─Scaler: 2-582                     [16, 64, 8, 8]            --
│    └─ReLU: 2-583                       [16, 64, 8, 8]            --
│    └─Empty: 2-584                      [16, 64, 8, 8]            --
│    └─Clamp: 2-585                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-586                  [16, 64, 8, 8]            --
│    └─Empty: 2-587                      [16, 64, 8, 8]            --
│    └─Empty: 2-588                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-589         --                        --
│    └─One: 2-590                        [1]                       --
│    └─OutputScale: 2-591                --                        --
│    └─Empty: 2-592                      [64, 64, 3, 3]            --
│    └─Empty: 2-593                      [64, 64, 3, 3]            --
│    └─Empty: 2-594                      [64]                      --
│    └─Empty: 2-595                      [64]                      --
│    └─BatchNorm2d: 2-596                [16, 64, 8, 8]            --
│    └─Scaler: 2-597                     [16, 64, 8, 8]            --
│    └─ReLU: 2-598                       [16, 64, 8, 8]            --
│    └─Empty: 2-599                      [16, 64, 8, 8]            --
│    └─Clamp: 2-600                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-601                  [16, 64, 4, 4]            --
│    └─Empty: 2-602                      [16, 64, 4, 4]            --
│    └─Empty: 2-603                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-604         --                        --
│    └─One: 2-605                        [1]                       --
│    └─OutputScale: 2-606                --                        --
│    └─Empty: 2-607                      [64, 64, 3, 3]            --
│    └─Empty: 2-608                      [64, 64, 3, 3]            --
│    └─Empty: 2-609                      [64]                      --
│    └─Empty: 2-610                      [64]                      --
│    └─BatchNorm2d: 2-611                [16, 64, 4, 4]            --
│    └─Scaler: 2-612                     [16, 64, 4, 4]            --
│    └─ReLU: 2-613                       [16, 64, 4, 4]            --
│    └─Empty: 2-614                      [16, 64, 4, 4]            --
│    └─Clamp: 2-615                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-616         --                        --
│    └─One: 2-617                        [1]                       --
│    └─OutputScale: 2-618                --                        --
│    └─Empty: 2-619                      [64, 64, 1, 1]            --
│    └─Empty: 2-620                      [64, 64, 1, 1]            --
│    └─Empty: 2-621                      [64]                      --
│    └─Empty: 2-622                      [64]                      --
│    └─BatchNorm2d: 2-623                [16, 64, 4, 4]            --
│    └─Scaler: 2-624                     [16, 64, 4, 4]            --
│    └─ReLU: 2-625                       [16, 64, 4, 4]            --
│    └─Empty: 2-626                      [16, 64, 4, 4]            --
│    └─Clamp: 2-627                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-628                  [16, 64, 4, 4]            --
│    └─Empty: 2-629                      [16, 64, 4, 4]            --
│    └─Empty: 2-630                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-631         --                        --
│    └─One: 2-632                        [1]                       --
│    └─OutputScale: 2-633                --                        --
│    └─Empty: 2-634                      [64, 64, 3, 3]            --
│    └─Empty: 2-635                      [64, 64, 3, 3]            --
│    └─Empty: 2-636                      [64]                      --
│    └─Empty: 2-637                      [64]                      --
│    └─BatchNorm2d: 2-638                [16, 64, 4, 4]            --
│    └─Scaler: 2-639                     [16, 64, 4, 4]            --
│    └─ReLU: 2-640                       [16, 64, 4, 4]            --
│    └─Empty: 2-641                      [16, 64, 4, 4]            --
│    └─Clamp: 2-642                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-643                  [16, 64, 2, 2]            --
│    └─Empty: 2-644                      [16, 64, 2, 2]            --
│    └─Empty: 2-645                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-646         --                        --
│    └─One: 2-647                        [1]                       --
│    └─OutputScale: 2-648                --                        --
│    └─Empty: 2-649                      [64, 64, 1, 1]            --
│    └─Empty: 2-650                      [64, 64, 1, 1]            --
│    └─Empty: 2-651                      [64]                      --
│    └─Empty: 2-652                      [64]                      --
│    └─BatchNorm2d: 2-653                [16, 64, 2, 2]            --
│    └─Scaler: 2-654                     [16, 64, 2, 2]            --
│    └─ReLU: 2-655                       [16, 64, 2, 2]            --
│    └─Empty: 2-656                      [16, 64, 2, 2]            --
│    └─Clamp: 2-657                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-658         --                        --
│    └─One: 2-659                        [1]                       --
│    └─OutputScale: 2-660                --                        --
│    └─Empty: 2-661                      [64, 64, 1, 1]            --
│    └─Empty: 2-662                      [64, 64, 1, 1]            --
│    └─Empty: 2-663                      [64]                      --
│    └─Empty: 2-664                      [64]                      --
│    └─BatchNorm2d: 2-665                [16, 64, 2, 2]            --
│    └─Scaler: 2-666                     [16, 64, 2, 2]            --
│    └─ReLU: 2-667                       [16, 64, 2, 2]            --
│    └─Empty: 2-668                      [16, 64, 2, 2]            --
│    └─Clamp: 2-669                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-670                  [16, 64, 2, 2]            --
│    └─Empty: 2-671                      [16, 64, 2, 2]            --
│    └─Empty: 2-672                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-673         --                        --
│    └─One: 2-674                        [1]                       --
│    └─OutputScale: 2-675                --                        --
│    └─Empty: 2-676                      [64, 64, 3, 3]            --
│    └─Empty: 2-677                      [64, 64, 3, 3]            --
│    └─Empty: 2-678                      [64]                      --
│    └─Empty: 2-679                      [64]                      --
│    └─BatchNorm2d: 2-680                [16, 64, 2, 2]            --
│    └─Scaler: 2-681                     [16, 64, 2, 2]            --
│    └─ReLU: 2-682                       [16, 64, 2, 2]            --
│    └─Empty: 2-683                      [16, 64, 2, 2]            --
│    └─Clamp: 2-684                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-685         --                        --
│    └─One: 2-686                        [1]                       --
│    └─OutputScale: 2-687                --                        --
│    └─Empty: 2-688                      [64, 48, 1, 1]            --
│    └─Empty: 2-689                      [64, 48, 1, 1]            --
│    └─Empty: 2-690                      [64]                      --
│    └─Empty: 2-691                      [64]                      --
│    └─BatchNorm2d: 2-692                [16, 64, 64, 64]          --
│    └─Scaler: 2-693                     [16, 64, 64, 64]          --
│    └─ReLU: 2-694                       [16, 64, 64, 64]          --
│    └─Empty: 2-695                      [16, 64, 64, 64]          --
│    └─Clamp: 2-696                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-697         --                        --
│    └─One: 2-698                        [1]                       --
│    └─OutputScale: 2-699                --                        --
│    └─Empty: 2-700                      [64, 64, 3, 3]            --
│    └─Empty: 2-701                      [64, 64, 3, 3]            --
│    └─Empty: 2-702                      [64]                      --
│    └─Empty: 2-703                      [64]                      --
│    └─BatchNorm2d: 2-704                [16, 64, 64, 64]          --
│    └─Scaler: 2-705                     [16, 64, 64, 64]          --
│    └─ReLU: 2-706                       [16, 64, 64, 64]          --
│    └─Empty: 2-707                      [16, 64, 64, 64]          --
│    └─Clamp: 2-708                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-709         --                        --
│    └─One: 2-710                        [1]                       --
│    └─OutputScale: 2-711                --                        --
│    └─Empty: 2-712                      [64, 64, 1, 1]            --
│    └─Empty: 2-713                      [64, 64, 1, 1]            --
│    └─Empty: 2-714                      [64]                      --
│    └─Empty: 2-715                      [64]                      --
│    └─BatchNorm2d: 2-716                [16, 64, 64, 64]          --
│    └─Scaler: 2-717                     [16, 64, 64, 64]          --
│    └─ReLU: 2-718                       [16, 64, 64, 64]          --
│    └─Empty: 2-719                      [16, 64, 64, 64]          --
│    └─Clamp: 2-720                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-721         --                        --
│    └─One: 2-722                        [1]                       --
│    └─OutputScale: 2-723                --                        --
│    └─Empty: 2-724                      [64, 64, 3, 3]            --
│    └─Empty: 2-725                      [64, 64, 3, 3]            --
│    └─Empty: 2-726                      [64]                      --
│    └─Empty: 2-727                      [64]                      --
│    └─BatchNorm2d: 2-728                [16, 64, 64, 64]          --
│    └─Scaler: 2-729                     [16, 64, 64, 64]          --
│    └─ReLU: 2-730                       [16, 64, 64, 64]          --
│    └─Empty: 2-731                      [16, 64, 64, 64]          --
│    └─Clamp: 2-732                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-733                  [16, 64, 32, 32]          --
│    └─Empty: 2-734                      [16, 64, 32, 32]          --
│    └─Empty: 2-735                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-736         --                        --
│    └─One: 2-737                        [1]                       --
│    └─OutputScale: 2-738                --                        --
│    └─Empty: 2-739                      [64, 64, 3, 3]            --
│    └─Empty: 2-740                      [64, 64, 3, 3]            --
│    └─Empty: 2-741                      [64]                      --
│    └─Empty: 2-742                      [64]                      --
│    └─BatchNorm2d: 2-743                [16, 64, 32, 32]          --
│    └─Scaler: 2-744                     [16, 64, 32, 32]          --
│    └─ReLU: 2-745                       [16, 64, 32, 32]          --
│    └─Empty: 2-746                      [16, 64, 32, 32]          --
│    └─Clamp: 2-747                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-748         --                        --
│    └─One: 2-749                        [1]                       --
│    └─OutputScale: 2-750                --                        --
│    └─Empty: 2-751                      [64, 64, 3, 3]            --
│    └─Empty: 2-752                      [64, 64, 3, 3]            --
│    └─Empty: 2-753                      [64]                      --
│    └─Empty: 2-754                      [64]                      --
│    └─BatchNorm2d: 2-755                [16, 64, 32, 32]          --
│    └─Scaler: 2-756                     [16, 64, 32, 32]          --
│    └─ReLU: 2-757                       [16, 64, 32, 32]          --
│    └─Empty: 2-758                      [16, 64, 32, 32]          --
│    └─Clamp: 2-759                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-760                  [16, 64, 16, 16]          --
│    └─Empty: 2-761                      [16, 64, 16, 16]          --
│    └─Empty: 2-762                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-763         --                        --
│    └─One: 2-764                        [1]                       --
│    └─OutputScale: 2-765                --                        --
│    └─Empty: 2-766                      [64, 64, 3, 3]            --
│    └─Empty: 2-767                      [64, 64, 3, 3]            --
│    └─Empty: 2-768                      [64]                      --
│    └─Empty: 2-769                      [64]                      --
│    └─BatchNorm2d: 2-770                [16, 64, 16, 16]          --
│    └─Scaler: 2-771                     [16, 64, 16, 16]          --
│    └─ReLU: 2-772                       [16, 64, 16, 16]          --
│    └─Empty: 2-773                      [16, 64, 16, 16]          --
│    └─Clamp: 2-774                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-775         --                        --
│    └─One: 2-776                        [1]                       --
│    └─OutputScale: 2-777                --                        --
│    └─Empty: 2-778                      [64, 64, 3, 3]            --
│    └─Empty: 2-779                      [64, 64, 3, 3]            --
│    └─Empty: 2-780                      [64]                      --
│    └─Empty: 2-781                      [64]                      --
│    └─BatchNorm2d: 2-782                [16, 64, 16, 16]          --
│    └─Scaler: 2-783                     [16, 64, 16, 16]          --
│    └─ReLU: 2-784                       [16, 64, 16, 16]          --
│    └─Empty: 2-785                      [16, 64, 16, 16]          --
│    └─Clamp: 2-786                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-787                  [16, 64, 8, 8]            --
│    └─Empty: 2-788                      [16, 64, 8, 8]            --
│    └─Empty: 2-789                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-790         --                        --
│    └─One: 2-791                        [1]                       --
│    └─OutputScale: 2-792                --                        --
│    └─Empty: 2-793                      [64, 64, 3, 3]            --
│    └─Empty: 2-794                      [64, 64, 3, 3]            --
│    └─Empty: 2-795                      [64]                      --
│    └─Empty: 2-796                      [64]                      --
│    └─BatchNorm2d: 2-797                [16, 64, 8, 8]            --
│    └─Scaler: 2-798                     [16, 64, 8, 8]            --
│    └─ReLU: 2-799                       [16, 64, 8, 8]            --
│    └─Empty: 2-800                      [16, 64, 8, 8]            --
│    └─Clamp: 2-801                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-802         --                        --
│    └─One: 2-803                        [1]                       --
│    └─OutputScale: 2-804                --                        --
│    └─Empty: 2-805                      [64, 64, 1, 1]            --
│    └─Empty: 2-806                      [64, 64, 1, 1]            --
│    └─Empty: 2-807                      [64]                      --
│    └─Empty: 2-808                      [64]                      --
│    └─BatchNorm2d: 2-809                [16, 64, 8, 8]            --
│    └─Scaler: 2-810                     [16, 64, 8, 8]            --
│    └─ReLU: 2-811                       [16, 64, 8, 8]            --
│    └─Empty: 2-812                      [16, 64, 8, 8]            --
│    └─Clamp: 2-813                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-814                  [16, 64, 8, 8]            --
│    └─Empty: 2-815                      [16, 64, 8, 8]            --
│    └─Empty: 2-816                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-817         --                        --
│    └─One: 2-818                        [1]                       --
│    └─OutputScale: 2-819                --                        --
│    └─Empty: 2-820                      [64, 64, 3, 3]            --
│    └─Empty: 2-821                      [64, 64, 3, 3]            --
│    └─Empty: 2-822                      [64]                      --
│    └─Empty: 2-823                      [64]                      --
│    └─BatchNorm2d: 2-824                [16, 64, 8, 8]            --
│    └─Scaler: 2-825                     [16, 64, 8, 8]            --
│    └─ReLU: 2-826                       [16, 64, 8, 8]            --
│    └─Empty: 2-827                      [16, 64, 8, 8]            --
│    └─Clamp: 2-828                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-829                  [16, 64, 4, 4]            --
│    └─Empty: 2-830                      [16, 64, 4, 4]            --
│    └─Empty: 2-831                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-832         --                        --
│    └─One: 2-833                        [1]                       --
│    └─OutputScale: 2-834                --                        --
│    └─Empty: 2-835                      [64, 64, 3, 3]            --
│    └─Empty: 2-836                      [64, 64, 3, 3]            --
│    └─Empty: 2-837                      [64]                      --
│    └─Empty: 2-838                      [64]                      --
│    └─BatchNorm2d: 2-839                [16, 64, 4, 4]            --
│    └─Scaler: 2-840                     [16, 64, 4, 4]            --
│    └─ReLU: 2-841                       [16, 64, 4, 4]            --
│    └─Empty: 2-842                      [16, 64, 4, 4]            --
│    └─Clamp: 2-843                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-844         --                        --
│    └─One: 2-845                        [1]                       --
│    └─OutputScale: 2-846                --                        --
│    └─Empty: 2-847                      [64, 64, 1, 1]            --
│    └─Empty: 2-848                      [64, 64, 1, 1]            --
│    └─Empty: 2-849                      [64]                      --
│    └─Empty: 2-850                      [64]                      --
│    └─BatchNorm2d: 2-851                [16, 64, 4, 4]            --
│    └─Scaler: 2-852                     [16, 64, 4, 4]            --
│    └─ReLU: 2-853                       [16, 64, 4, 4]            --
│    └─Empty: 2-854                      [16, 64, 4, 4]            --
│    └─Clamp: 2-855                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-856                  [16, 64, 4, 4]            --
│    └─Empty: 2-857                      [16, 64, 4, 4]            --
│    └─Empty: 2-858                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-859         --                        --
│    └─One: 2-860                        [1]                       --
│    └─OutputScale: 2-861                --                        --
│    └─Empty: 2-862                      [64, 64, 3, 3]            --
│    └─Empty: 2-863                      [64, 64, 3, 3]            --
│    └─Empty: 2-864                      [64]                      --
│    └─Empty: 2-865                      [64]                      --
│    └─BatchNorm2d: 2-866                [16, 64, 4, 4]            --
│    └─Scaler: 2-867                     [16, 64, 4, 4]            --
│    └─ReLU: 2-868                       [16, 64, 4, 4]            --
│    └─Empty: 2-869                      [16, 64, 4, 4]            --
│    └─Clamp: 2-870                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-871                  [16, 64, 2, 2]            --
│    └─Empty: 2-872                      [16, 64, 2, 2]            --
│    └─Empty: 2-873                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-874         --                        --
│    └─One: 2-875                        [1]                       --
│    └─OutputScale: 2-876                --                        --
│    └─Empty: 2-877                      [64, 64, 1, 1]            --
│    └─Empty: 2-878                      [64, 64, 1, 1]            --
│    └─Empty: 2-879                      [64]                      --
│    └─Empty: 2-880                      [64]                      --
│    └─BatchNorm2d: 2-881                [16, 64, 2, 2]            --
│    └─Scaler: 2-882                     [16, 64, 2, 2]            --
│    └─ReLU: 2-883                       [16, 64, 2, 2]            --
│    └─Empty: 2-884                      [16, 64, 2, 2]            --
│    └─Clamp: 2-885                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-886         --                        --
│    └─One: 2-887                        [1]                       --
│    └─OutputScale: 2-888                --                        --
│    └─Empty: 2-889                      [64, 64, 1, 1]            --
│    └─Empty: 2-890                      [64, 64, 1, 1]            --
│    └─Empty: 2-891                      [64]                      --
│    └─Empty: 2-892                      [64]                      --
│    └─BatchNorm2d: 2-893                [16, 64, 2, 2]            --
│    └─Scaler: 2-894                     [16, 64, 2, 2]            --
│    └─ReLU: 2-895                       [16, 64, 2, 2]            --
│    └─Empty: 2-896                      [16, 64, 2, 2]            --
│    └─Clamp: 2-897                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-898                  [16, 64, 2, 2]            --
│    └─Empty: 2-899                      [16, 64, 2, 2]            --
│    └─Empty: 2-900                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-901         --                        --
│    └─One: 2-902                        [1]                       --
│    └─OutputScale: 2-903                --                        --
│    └─Empty: 2-904                      [64, 64, 3, 3]            --
│    └─Empty: 2-905                      [64, 64, 3, 3]            --
│    └─Empty: 2-906                      [64]                      --
│    └─Empty: 2-907                      [64]                      --
│    └─BatchNorm2d: 2-908                [16, 64, 2, 2]            --
│    └─Scaler: 2-909                     [16, 64, 2, 2]            --
│    └─ReLU: 2-910                       [16, 64, 2, 2]            --
│    └─Empty: 2-911                      [16, 64, 2, 2]            --
│    └─Clamp: 2-912                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-913         --                        --
│    └─One: 2-914                        [1]                       --
│    └─OutputScale: 2-915                --                        --
│    └─Empty: 2-916                      [64, 48, 1, 1]            --
│    └─Empty: 2-917                      [64, 48, 1, 1]            --
│    └─Empty: 2-918                      [64]                      --
│    └─Empty: 2-919                      [64]                      --
│    └─BatchNorm2d: 2-920                [16, 64, 64, 64]          --
│    └─Scaler: 2-921                     [16, 64, 64, 64]          --
│    └─ReLU: 2-922                       [16, 64, 64, 64]          --
│    └─Empty: 2-923                      [16, 64, 64, 64]          --
│    └─Clamp: 2-924                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-925         --                        --
│    └─One: 2-926                        [1]                       --
│    └─OutputScale: 2-927                --                        --
│    └─Empty: 2-928                      [64, 64, 3, 3]            --
│    └─Empty: 2-929                      [64, 64, 3, 3]            --
│    └─Empty: 2-930                      [64]                      --
│    └─Empty: 2-931                      [64]                      --
│    └─BatchNorm2d: 2-932                [16, 64, 64, 64]          --
│    └─Scaler: 2-933                     [16, 64, 64, 64]          --
│    └─ReLU: 2-934                       [16, 64, 64, 64]          --
│    └─Empty: 2-935                      [16, 64, 64, 64]          --
│    └─Clamp: 2-936                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-937         --                        --
│    └─One: 2-938                        [1]                       --
│    └─OutputScale: 2-939                --                        --
│    └─Empty: 2-940                      [64, 64, 1, 1]            --
│    └─Empty: 2-941                      [64, 64, 1, 1]            --
│    └─Empty: 2-942                      [64]                      --
│    └─Empty: 2-943                      [64]                      --
│    └─BatchNorm2d: 2-944                [16, 64, 64, 64]          --
│    └─Scaler: 2-945                     [16, 64, 64, 64]          --
│    └─ReLU: 2-946                       [16, 64, 64, 64]          --
│    └─Empty: 2-947                      [16, 64, 64, 64]          --
│    └─Clamp: 2-948                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-949         --                        --
│    └─One: 2-950                        [1]                       --
│    └─OutputScale: 2-951                --                        --
│    └─Empty: 2-952                      [64, 64, 3, 3]            --
│    └─Empty: 2-953                      [64, 64, 3, 3]            --
│    └─Empty: 2-954                      [64]                      --
│    └─Empty: 2-955                      [64]                      --
│    └─BatchNorm2d: 2-956                [16, 64, 64, 64]          --
│    └─Scaler: 2-957                     [16, 64, 64, 64]          --
│    └─ReLU: 2-958                       [16, 64, 64, 64]          --
│    └─Empty: 2-959                      [16, 64, 64, 64]          --
│    └─Clamp: 2-960                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-961                  [16, 64, 32, 32]          --
│    └─Empty: 2-962                      [16, 64, 32, 32]          --
│    └─Empty: 2-963                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-964         --                        --
│    └─One: 2-965                        [1]                       --
│    └─OutputScale: 2-966                --                        --
│    └─Empty: 2-967                      [64, 64, 3, 3]            --
│    └─Empty: 2-968                      [64, 64, 3, 3]            --
│    └─Empty: 2-969                      [64]                      --
│    └─Empty: 2-970                      [64]                      --
│    └─BatchNorm2d: 2-971                [16, 64, 32, 32]          --
│    └─Scaler: 2-972                     [16, 64, 32, 32]          --
│    └─ReLU: 2-973                       [16, 64, 32, 32]          --
│    └─Empty: 2-974                      [16, 64, 32, 32]          --
│    └─Clamp: 2-975                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-976         --                        --
│    └─One: 2-977                        [1]                       --
│    └─OutputScale: 2-978                --                        --
│    └─Empty: 2-979                      [64, 64, 3, 3]            --
│    └─Empty: 2-980                      [64, 64, 3, 3]            --
│    └─Empty: 2-981                      [64]                      --
│    └─Empty: 2-982                      [64]                      --
│    └─BatchNorm2d: 2-983                [16, 64, 32, 32]          --
│    └─Scaler: 2-984                     [16, 64, 32, 32]          --
│    └─ReLU: 2-985                       [16, 64, 32, 32]          --
│    └─Empty: 2-986                      [16, 64, 32, 32]          --
│    └─Clamp: 2-987                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-988                  [16, 64, 16, 16]          --
│    └─Empty: 2-989                      [16, 64, 16, 16]          --
│    └─Empty: 2-990                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-991         --                        --
│    └─One: 2-992                        [1]                       --
│    └─OutputScale: 2-993                --                        --
│    └─Empty: 2-994                      [64, 64, 3, 3]            --
│    └─Empty: 2-995                      [64, 64, 3, 3]            --
│    └─Empty: 2-996                      [64]                      --
│    └─Empty: 2-997                      [64]                      --
│    └─BatchNorm2d: 2-998                [16, 64, 16, 16]          --
│    └─Scaler: 2-999                     [16, 64, 16, 16]          --
│    └─ReLU: 2-1000                      [16, 64, 16, 16]          --
│    └─Empty: 2-1001                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1002                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1003        --                        --
│    └─One: 2-1004                       [1]                       --
│    └─OutputScale: 2-1005               --                        --
│    └─Empty: 2-1006                     [64, 64, 3, 3]            --
│    └─Empty: 2-1007                     [64, 64, 3, 3]            --
│    └─Empty: 2-1008                     [64]                      --
│    └─Empty: 2-1009                     [64]                      --
│    └─BatchNorm2d: 2-1010               [16, 64, 16, 16]          --
│    └─Scaler: 2-1011                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1012                      [16, 64, 16, 16]          --
│    └─Empty: 2-1013                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1014                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1015                 [16, 64, 8, 8]            --
│    └─Empty: 2-1016                     [16, 64, 8, 8]            --
│    └─Empty: 2-1017                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1018        --                        --
│    └─One: 2-1019                       [1]                       --
│    └─OutputScale: 2-1020               --                        --
│    └─Empty: 2-1021                     [64, 64, 3, 3]            --
│    └─Empty: 2-1022                     [64, 64, 3, 3]            --
│    └─Empty: 2-1023                     [64]                      --
│    └─Empty: 2-1024                     [64]                      --
│    └─BatchNorm2d: 2-1025               [16, 64, 8, 8]            --
│    └─Scaler: 2-1026                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1027                      [16, 64, 8, 8]            --
│    └─Empty: 2-1028                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1029                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1030        --                        --
│    └─One: 2-1031                       [1]                       --
│    └─OutputScale: 2-1032               --                        --
│    └─Empty: 2-1033                     [64, 64, 1, 1]            --
│    └─Empty: 2-1034                     [64, 64, 1, 1]            --
│    └─Empty: 2-1035                     [64]                      --
│    └─Empty: 2-1036                     [64]                      --
│    └─BatchNorm2d: 2-1037               [16, 64, 8, 8]            --
│    └─Scaler: 2-1038                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1039                      [16, 64, 8, 8]            --
│    └─Empty: 2-1040                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1041                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1042                 [16, 64, 8, 8]            --
│    └─Empty: 2-1043                     [16, 64, 8, 8]            --
│    └─Empty: 2-1044                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1045        --                        --
│    └─One: 2-1046                       [1]                       --
│    └─OutputScale: 2-1047               --                        --
│    └─Empty: 2-1048                     [64, 64, 3, 3]            --
│    └─Empty: 2-1049                     [64, 64, 3, 3]            --
│    └─Empty: 2-1050                     [64]                      --
│    └─Empty: 2-1051                     [64]                      --
│    └─BatchNorm2d: 2-1052               [16, 64, 8, 8]            --
│    └─Scaler: 2-1053                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1054                      [16, 64, 8, 8]            --
│    └─Empty: 2-1055                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1056                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1057                 [16, 64, 4, 4]            --
│    └─Empty: 2-1058                     [16, 64, 4, 4]            --
│    └─Empty: 2-1059                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1060        --                        --
│    └─One: 2-1061                       [1]                       --
│    └─OutputScale: 2-1062               --                        --
│    └─Empty: 2-1063                     [64, 64, 3, 3]            --
│    └─Empty: 2-1064                     [64, 64, 3, 3]            --
│    └─Empty: 2-1065                     [64]                      --
│    └─Empty: 2-1066                     [64]                      --
│    └─BatchNorm2d: 2-1067               [16, 64, 4, 4]            --
│    └─Scaler: 2-1068                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1069                      [16, 64, 4, 4]            --
│    └─Empty: 2-1070                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1071                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1072        --                        --
│    └─One: 2-1073                       [1]                       --
│    └─OutputScale: 2-1074               --                        --
│    └─Empty: 2-1075                     [64, 64, 1, 1]            --
│    └─Empty: 2-1076                     [64, 64, 1, 1]            --
│    └─Empty: 2-1077                     [64]                      --
│    └─Empty: 2-1078                     [64]                      --
│    └─BatchNorm2d: 2-1079               [16, 64, 4, 4]            --
│    └─Scaler: 2-1080                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1081                      [16, 64, 4, 4]            --
│    └─Empty: 2-1082                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1083                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1084                 [16, 64, 4, 4]            --
│    └─Empty: 2-1085                     [16, 64, 4, 4]            --
│    └─Empty: 2-1086                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1087        --                        --
│    └─One: 2-1088                       [1]                       --
│    └─OutputScale: 2-1089               --                        --
│    └─Empty: 2-1090                     [64, 64, 3, 3]            --
│    └─Empty: 2-1091                     [64, 64, 3, 3]            --
│    └─Empty: 2-1092                     [64]                      --
│    └─Empty: 2-1093                     [64]                      --
│    └─BatchNorm2d: 2-1094               [16, 64, 4, 4]            --
│    └─Scaler: 2-1095                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1096                      [16, 64, 4, 4]            --
│    └─Empty: 2-1097                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1098                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1099                 [16, 64, 2, 2]            --
│    └─Empty: 2-1100                     [16, 64, 2, 2]            --
│    └─Empty: 2-1101                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1102        --                        --
│    └─One: 2-1103                       [1]                       --
│    └─OutputScale: 2-1104               --                        --
│    └─Empty: 2-1105                     [64, 64, 1, 1]            --
│    └─Empty: 2-1106                     [64, 64, 1, 1]            --
│    └─Empty: 2-1107                     [64]                      --
│    └─Empty: 2-1108                     [64]                      --
│    └─BatchNorm2d: 2-1109               [16, 64, 2, 2]            --
│    └─Scaler: 2-1110                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1111                      [16, 64, 2, 2]            --
│    └─Empty: 2-1112                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1113                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1114        --                        --
│    └─One: 2-1115                       [1]                       --
│    └─OutputScale: 2-1116               --                        --
│    └─Empty: 2-1117                     [64, 64, 1, 1]            --
│    └─Empty: 2-1118                     [64, 64, 1, 1]            --
│    └─Empty: 2-1119                     [64]                      --
│    └─Empty: 2-1120                     [64]                      --
│    └─BatchNorm2d: 2-1121               [16, 64, 2, 2]            --
│    └─Scaler: 2-1122                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1123                      [16, 64, 2, 2]            --
│    └─Empty: 2-1124                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1125                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1126                 [16, 64, 2, 2]            --
│    └─Empty: 2-1127                     [16, 64, 2, 2]            --
│    └─Empty: 2-1128                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1129        --                        --
│    └─One: 2-1130                       [1]                       --
│    └─OutputScale: 2-1131               --                        --
│    └─Empty: 2-1132                     [64, 64, 3, 3]            --
│    └─Empty: 2-1133                     [64, 64, 3, 3]            --
│    └─Empty: 2-1134                     [64]                      --
│    └─Empty: 2-1135                     [64]                      --
│    └─BatchNorm2d: 2-1136               [16, 64, 2, 2]            --
│    └─Scaler: 2-1137                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1138                      [16, 64, 2, 2]            --
│    └─Empty: 2-1139                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1140                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1141        --                        --
│    └─One: 2-1142                       [1]                       --
│    └─OutputScale: 2-1143               --                        --
│    └─Empty: 2-1144                     [64, 48, 1, 1]            --
│    └─Empty: 2-1145                     [64, 48, 1, 1]            --
│    └─Empty: 2-1146                     [64]                      --
│    └─Empty: 2-1147                     [64]                      --
│    └─BatchNorm2d: 2-1148               [16, 64, 64, 64]          --
│    └─Scaler: 2-1149                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1150                      [16, 64, 64, 64]          --
│    └─Empty: 2-1151                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1152                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1153        --                        --
│    └─One: 2-1154                       [1]                       --
│    └─OutputScale: 2-1155               --                        --
│    └─Empty: 2-1156                     [64, 64, 3, 3]            --
│    └─Empty: 2-1157                     [64, 64, 3, 3]            --
│    └─Empty: 2-1158                     [64]                      --
│    └─Empty: 2-1159                     [64]                      --
│    └─BatchNorm2d: 2-1160               [16, 64, 64, 64]          --
│    └─Scaler: 2-1161                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1162                      [16, 64, 64, 64]          --
│    └─Empty: 2-1163                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1164                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1165        --                        --
│    └─One: 2-1166                       [1]                       --
│    └─OutputScale: 2-1167               --                        --
│    └─Empty: 2-1168                     [64, 64, 1, 1]            --
│    └─Empty: 2-1169                     [64, 64, 1, 1]            --
│    └─Empty: 2-1170                     [64]                      --
│    └─Empty: 2-1171                     [64]                      --
│    └─BatchNorm2d: 2-1172               [16, 64, 64, 64]          --
│    └─Scaler: 2-1173                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1174                      [16, 64, 64, 64]          --
│    └─Empty: 2-1175                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1176                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1177        --                        --
│    └─One: 2-1178                       [1]                       --
│    └─OutputScale: 2-1179               --                        --
│    └─Empty: 2-1180                     [64, 64, 3, 3]            --
│    └─Empty: 2-1181                     [64, 64, 3, 3]            --
│    └─Empty: 2-1182                     [64]                      --
│    └─Empty: 2-1183                     [64]                      --
│    └─BatchNorm2d: 2-1184               [16, 64, 64, 64]          --
│    └─Scaler: 2-1185                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1186                      [16, 64, 64, 64]          --
│    └─Empty: 2-1187                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1188                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1189                 [16, 64, 32, 32]          --
│    └─Empty: 2-1190                     [16, 64, 32, 32]          --
│    └─Empty: 2-1191                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1192        --                        --
│    └─One: 2-1193                       [1]                       --
│    └─OutputScale: 2-1194               --                        --
│    └─Empty: 2-1195                     [64, 64, 3, 3]            --
│    └─Empty: 2-1196                     [64, 64, 3, 3]            --
│    └─Empty: 2-1197                     [64]                      --
│    └─Empty: 2-1198                     [64]                      --
│    └─BatchNorm2d: 2-1199               [16, 64, 32, 32]          --
│    └─Scaler: 2-1200                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1201                      [16, 64, 32, 32]          --
│    └─Empty: 2-1202                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1203                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1204        --                        --
│    └─One: 2-1205                       [1]                       --
│    └─OutputScale: 2-1206               --                        --
│    └─Empty: 2-1207                     [64, 64, 3, 3]            --
│    └─Empty: 2-1208                     [64, 64, 3, 3]            --
│    └─Empty: 2-1209                     [64]                      --
│    └─Empty: 2-1210                     [64]                      --
│    └─BatchNorm2d: 2-1211               [16, 64, 32, 32]          --
│    └─Scaler: 2-1212                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1213                      [16, 64, 32, 32]          --
│    └─Empty: 2-1214                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1215                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1216                 [16, 64, 16, 16]          --
│    └─Empty: 2-1217                     [16, 64, 16, 16]          --
│    └─Empty: 2-1218                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1219        --                        --
│    └─One: 2-1220                       [1]                       --
│    └─OutputScale: 2-1221               --                        --
│    └─Empty: 2-1222                     [64, 64, 3, 3]            --
│    └─Empty: 2-1223                     [64, 64, 3, 3]            --
│    └─Empty: 2-1224                     [64]                      --
│    └─Empty: 2-1225                     [64]                      --
│    └─BatchNorm2d: 2-1226               [16, 64, 16, 16]          --
│    └─Scaler: 2-1227                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1228                      [16, 64, 16, 16]          --
│    └─Empty: 2-1229                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1230                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1231        --                        --
│    └─One: 2-1232                       [1]                       --
│    └─OutputScale: 2-1233               --                        --
│    └─Empty: 2-1234                     [64, 64, 3, 3]            --
│    └─Empty: 2-1235                     [64, 64, 3, 3]            --
│    └─Empty: 2-1236                     [64]                      --
│    └─Empty: 2-1237                     [64]                      --
│    └─BatchNorm2d: 2-1238               [16, 64, 16, 16]          --
│    └─Scaler: 2-1239                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1240                      [16, 64, 16, 16]          --
│    └─Empty: 2-1241                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1242                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1243                 [16, 64, 8, 8]            --
│    └─Empty: 2-1244                     [16, 64, 8, 8]            --
│    └─Empty: 2-1245                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1246        --                        --
│    └─One: 2-1247                       [1]                       --
│    └─OutputScale: 2-1248               --                        --
│    └─Empty: 2-1249                     [64, 64, 3, 3]            --
│    └─Empty: 2-1250                     [64, 64, 3, 3]            --
│    └─Empty: 2-1251                     [64]                      --
│    └─Empty: 2-1252                     [64]                      --
│    └─BatchNorm2d: 2-1253               [16, 64, 8, 8]            --
│    └─Scaler: 2-1254                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1255                      [16, 64, 8, 8]            --
│    └─Empty: 2-1256                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1257                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1258        --                        --
│    └─One: 2-1259                       [1]                       --
│    └─OutputScale: 2-1260               --                        --
│    └─Empty: 2-1261                     [64, 64, 1, 1]            --
│    └─Empty: 2-1262                     [64, 64, 1, 1]            --
│    └─Empty: 2-1263                     [64]                      --
│    └─Empty: 2-1264                     [64]                      --
│    └─BatchNorm2d: 2-1265               [16, 64, 8, 8]            --
│    └─Scaler: 2-1266                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1267                      [16, 64, 8, 8]            --
│    └─Empty: 2-1268                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1269                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1270                 [16, 64, 8, 8]            --
│    └─Empty: 2-1271                     [16, 64, 8, 8]            --
│    └─Empty: 2-1272                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1273        --                        --
│    └─One: 2-1274                       [1]                       --
│    └─OutputScale: 2-1275               --                        --
│    └─Empty: 2-1276                     [64, 64, 3, 3]            --
│    └─Empty: 2-1277                     [64, 64, 3, 3]            --
│    └─Empty: 2-1278                     [64]                      --
│    └─Empty: 2-1279                     [64]                      --
│    └─BatchNorm2d: 2-1280               [16, 64, 8, 8]            --
│    └─Scaler: 2-1281                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1282                      [16, 64, 8, 8]            --
│    └─Empty: 2-1283                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1284                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1285                 [16, 64, 4, 4]            --
│    └─Empty: 2-1286                     [16, 64, 4, 4]            --
│    └─Empty: 2-1287                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1288        --                        --
│    └─One: 2-1289                       [1]                       --
│    └─OutputScale: 2-1290               --                        --
│    └─Empty: 2-1291                     [64, 64, 3, 3]            --
│    └─Empty: 2-1292                     [64, 64, 3, 3]            --
│    └─Empty: 2-1293                     [64]                      --
│    └─Empty: 2-1294                     [64]                      --
│    └─BatchNorm2d: 2-1295               [16, 64, 4, 4]            --
│    └─Scaler: 2-1296                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1297                      [16, 64, 4, 4]            --
│    └─Empty: 2-1298                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1299                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1300        --                        --
│    └─One: 2-1301                       [1]                       --
│    └─OutputScale: 2-1302               --                        --
│    └─Empty: 2-1303                     [64, 64, 1, 1]            --
│    └─Empty: 2-1304                     [64, 64, 1, 1]            --
│    └─Empty: 2-1305                     [64]                      --
│    └─Empty: 2-1306                     [64]                      --
│    └─BatchNorm2d: 2-1307               [16, 64, 4, 4]            --
│    └─Scaler: 2-1308                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1309                      [16, 64, 4, 4]            --
│    └─Empty: 2-1310                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1311                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1312                 [16, 64, 4, 4]            --
│    └─Empty: 2-1313                     [16, 64, 4, 4]            --
│    └─Empty: 2-1314                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1315        --                        --
│    └─One: 2-1316                       [1]                       --
│    └─OutputScale: 2-1317               --                        --
│    └─Empty: 2-1318                     [64, 64, 3, 3]            --
│    └─Empty: 2-1319                     [64, 64, 3, 3]            --
│    └─Empty: 2-1320                     [64]                      --
│    └─Empty: 2-1321                     [64]                      --
│    └─BatchNorm2d: 2-1322               [16, 64, 4, 4]            --
│    └─Scaler: 2-1323                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1324                      [16, 64, 4, 4]            --
│    └─Empty: 2-1325                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1326                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1327                 [16, 64, 2, 2]            --
│    └─Empty: 2-1328                     [16, 64, 2, 2]            --
│    └─Empty: 2-1329                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1330        --                        --
│    └─One: 2-1331                       [1]                       --
│    └─OutputScale: 2-1332               --                        --
│    └─Empty: 2-1333                     [64, 64, 1, 1]            --
│    └─Empty: 2-1334                     [64, 64, 1, 1]            --
│    └─Empty: 2-1335                     [64]                      --
│    └─Empty: 2-1336                     [64]                      --
│    └─BatchNorm2d: 2-1337               [16, 64, 2, 2]            --
│    └─Scaler: 2-1338                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1339                      [16, 64, 2, 2]            --
│    └─Empty: 2-1340                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1341                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1342        --                        --
│    └─One: 2-1343                       [1]                       --
│    └─OutputScale: 2-1344               --                        --
│    └─Empty: 2-1345                     [64, 64, 1, 1]            --
│    └─Empty: 2-1346                     [64, 64, 1, 1]            --
│    └─Empty: 2-1347                     [64]                      --
│    └─Empty: 2-1348                     [64]                      --
│    └─BatchNorm2d: 2-1349               [16, 64, 2, 2]            --
│    └─Scaler: 2-1350                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1351                      [16, 64, 2, 2]            --
│    └─Empty: 2-1352                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1353                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1354                 [16, 64, 2, 2]            --
│    └─Empty: 2-1355                     [16, 64, 2, 2]            --
│    └─Empty: 2-1356                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1357        --                        --
│    └─One: 2-1358                       [1]                       --
│    └─OutputScale: 2-1359               --                        --
│    └─Empty: 2-1360                     [64, 64, 3, 3]            --
│    └─Empty: 2-1361                     [64, 64, 3, 3]            --
│    └─Empty: 2-1362                     [64]                      --
│    └─Empty: 2-1363                     [64]                      --
│    └─BatchNorm2d: 2-1364               [16, 64, 2, 2]            --
│    └─Scaler: 2-1365                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1366                      [16, 64, 2, 2]            --
│    └─Empty: 2-1367                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1368                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1369        --                        --
│    └─One: 2-1370                       [1]                       --
│    └─OutputScale: 2-1371               --                        --
│    └─Empty: 2-1372                     [64, 48, 1, 1]            --
│    └─Empty: 2-1373                     [64, 48, 1, 1]            --
│    └─Empty: 2-1374                     [64]                      --
│    └─Empty: 2-1375                     [64]                      --
│    └─BatchNorm2d: 2-1376               [16, 64, 64, 64]          --
│    └─Scaler: 2-1377                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1378                      [16, 64, 64, 64]          --
│    └─Empty: 2-1379                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1380                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1381        --                        --
│    └─One: 2-1382                       [1]                       --
│    └─OutputScale: 2-1383               --                        --
│    └─Empty: 2-1384                     [64, 64, 3, 3]            --
│    └─Empty: 2-1385                     [64, 64, 3, 3]            --
│    └─Empty: 2-1386                     [64]                      --
│    └─Empty: 2-1387                     [64]                      --
│    └─BatchNorm2d: 2-1388               [16, 64, 64, 64]          --
│    └─Scaler: 2-1389                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1390                      [16, 64, 64, 64]          --
│    └─Empty: 2-1391                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1392                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1393        --                        --
│    └─One: 2-1394                       [1]                       --
│    └─OutputScale: 2-1395               --                        --
│    └─Empty: 2-1396                     [64, 64, 1, 1]            --
│    └─Empty: 2-1397                     [64, 64, 1, 1]            --
│    └─Empty: 2-1398                     [64]                      --
│    └─Empty: 2-1399                     [64]                      --
│    └─BatchNorm2d: 2-1400               [16, 64, 64, 64]          --
│    └─Scaler: 2-1401                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1402                      [16, 64, 64, 64]          --
│    └─Empty: 2-1403                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1404                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1405        --                        --
│    └─One: 2-1406                       [1]                       --
│    └─OutputScale: 2-1407               --                        --
│    └─Empty: 2-1408                     [64, 64, 3, 3]            --
│    └─Empty: 2-1409                     [64, 64, 3, 3]            --
│    └─Empty: 2-1410                     [64]                      --
│    └─Empty: 2-1411                     [64]                      --
│    └─BatchNorm2d: 2-1412               [16, 64, 64, 64]          --
│    └─Scaler: 2-1413                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1414                      [16, 64, 64, 64]          --
│    └─Empty: 2-1415                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1416                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1417                 [16, 64, 32, 32]          --
│    └─Empty: 2-1418                     [16, 64, 32, 32]          --
│    └─Empty: 2-1419                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1420        --                        --
│    └─One: 2-1421                       [1]                       --
│    └─OutputScale: 2-1422               --                        --
│    └─Empty: 2-1423                     [64, 64, 3, 3]            --
│    └─Empty: 2-1424                     [64, 64, 3, 3]            --
│    └─Empty: 2-1425                     [64]                      --
│    └─Empty: 2-1426                     [64]                      --
│    └─BatchNorm2d: 2-1427               [16, 64, 32, 32]          --
│    └─Scaler: 2-1428                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1429                      [16, 64, 32, 32]          --
│    └─Empty: 2-1430                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1431                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1432        --                        --
│    └─One: 2-1433                       [1]                       --
│    └─OutputScale: 2-1434               --                        --
│    └─Empty: 2-1435                     [64, 64, 3, 3]            --
│    └─Empty: 2-1436                     [64, 64, 3, 3]            --
│    └─Empty: 2-1437                     [64]                      --
│    └─Empty: 2-1438                     [64]                      --
│    └─BatchNorm2d: 2-1439               [16, 64, 32, 32]          --
│    └─Scaler: 2-1440                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1441                      [16, 64, 32, 32]          --
│    └─Empty: 2-1442                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1443                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1444                 [16, 64, 16, 16]          --
│    └─Empty: 2-1445                     [16, 64, 16, 16]          --
│    └─Empty: 2-1446                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1447        --                        --
│    └─One: 2-1448                       [1]                       --
│    └─OutputScale: 2-1449               --                        --
│    └─Empty: 2-1450                     [64, 64, 3, 3]            --
│    └─Empty: 2-1451                     [64, 64, 3, 3]            --
│    └─Empty: 2-1452                     [64]                      --
│    └─Empty: 2-1453                     [64]                      --
│    └─BatchNorm2d: 2-1454               [16, 64, 16, 16]          --
│    └─Scaler: 2-1455                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1456                      [16, 64, 16, 16]          --
│    └─Empty: 2-1457                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1458                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1459        --                        --
│    └─One: 2-1460                       [1]                       --
│    └─OutputScale: 2-1461               --                        --
│    └─Empty: 2-1462                     [64, 64, 3, 3]            --
│    └─Empty: 2-1463                     [64, 64, 3, 3]            --
│    └─Empty: 2-1464                     [64]                      --
│    └─Empty: 2-1465                     [64]                      --
│    └─BatchNorm2d: 2-1466               [16, 64, 16, 16]          --
│    └─Scaler: 2-1467                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1468                      [16, 64, 16, 16]          --
│    └─Empty: 2-1469                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1470                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1471                 [16, 64, 8, 8]            --
│    └─Empty: 2-1472                     [16, 64, 8, 8]            --
│    └─Empty: 2-1473                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1474        --                        --
│    └─One: 2-1475                       [1]                       --
│    └─OutputScale: 2-1476               --                        --
│    └─Empty: 2-1477                     [64, 64, 3, 3]            --
│    └─Empty: 2-1478                     [64, 64, 3, 3]            --
│    └─Empty: 2-1479                     [64]                      --
│    └─Empty: 2-1480                     [64]                      --
│    └─BatchNorm2d: 2-1481               [16, 64, 8, 8]            --
│    └─Scaler: 2-1482                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1483                      [16, 64, 8, 8]            --
│    └─Empty: 2-1484                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1485                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1486        --                        --
│    └─One: 2-1487                       [1]                       --
│    └─OutputScale: 2-1488               --                        --
│    └─Empty: 2-1489                     [64, 64, 1, 1]            --
│    └─Empty: 2-1490                     [64, 64, 1, 1]            --
│    └─Empty: 2-1491                     [64]                      --
│    └─Empty: 2-1492                     [64]                      --
│    └─BatchNorm2d: 2-1493               [16, 64, 8, 8]            --
│    └─Scaler: 2-1494                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1495                      [16, 64, 8, 8]            --
│    └─Empty: 2-1496                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1497                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1498                 [16, 64, 8, 8]            --
│    └─Empty: 2-1499                     [16, 64, 8, 8]            --
│    └─Empty: 2-1500                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1501        --                        --
│    └─One: 2-1502                       [1]                       --
│    └─OutputScale: 2-1503               --                        --
│    └─Empty: 2-1504                     [64, 64, 3, 3]            --
│    └─Empty: 2-1505                     [64, 64, 3, 3]            --
│    └─Empty: 2-1506                     [64]                      --
│    └─Empty: 2-1507                     [64]                      --
│    └─BatchNorm2d: 2-1508               [16, 64, 8, 8]            --
│    └─Scaler: 2-1509                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1510                      [16, 64, 8, 8]            --
│    └─Empty: 2-1511                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1512                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1513                 [16, 64, 4, 4]            --
│    └─Empty: 2-1514                     [16, 64, 4, 4]            --
│    └─Empty: 2-1515                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1516        --                        --
│    └─One: 2-1517                       [1]                       --
│    └─OutputScale: 2-1518               --                        --
│    └─Empty: 2-1519                     [64, 64, 3, 3]            --
│    └─Empty: 2-1520                     [64, 64, 3, 3]            --
│    └─Empty: 2-1521                     [64]                      --
│    └─Empty: 2-1522                     [64]                      --
│    └─BatchNorm2d: 2-1523               [16, 64, 4, 4]            --
│    └─Scaler: 2-1524                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1525                      [16, 64, 4, 4]            --
│    └─Empty: 2-1526                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1527                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1528        --                        --
│    └─One: 2-1529                       [1]                       --
│    └─OutputScale: 2-1530               --                        --
│    └─Empty: 2-1531                     [64, 64, 1, 1]            --
│    └─Empty: 2-1532                     [64, 64, 1, 1]            --
│    └─Empty: 2-1533                     [64]                      --
│    └─Empty: 2-1534                     [64]                      --
│    └─BatchNorm2d: 2-1535               [16, 64, 4, 4]            --
│    └─Scaler: 2-1536                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1537                      [16, 64, 4, 4]            --
│    └─Empty: 2-1538                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1539                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1540                 [16, 64, 4, 4]            --
│    └─Empty: 2-1541                     [16, 64, 4, 4]            --
│    └─Empty: 2-1542                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1543        --                        --
│    └─One: 2-1544                       [1]                       --
│    └─OutputScale: 2-1545               --                        --
│    └─Empty: 2-1546                     [64, 64, 3, 3]            --
│    └─Empty: 2-1547                     [64, 64, 3, 3]            --
│    └─Empty: 2-1548                     [64]                      --
│    └─Empty: 2-1549                     [64]                      --
│    └─BatchNorm2d: 2-1550               [16, 64, 4, 4]            --
│    └─Scaler: 2-1551                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1552                      [16, 64, 4, 4]            --
│    └─Empty: 2-1553                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1554                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1555                 [16, 64, 2, 2]            --
│    └─Empty: 2-1556                     [16, 64, 2, 2]            --
│    └─Empty: 2-1557                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1558        --                        --
│    └─One: 2-1559                       [1]                       --
│    └─OutputScale: 2-1560               --                        --
│    └─Empty: 2-1561                     [64, 64, 1, 1]            --
│    └─Empty: 2-1562                     [64, 64, 1, 1]            --
│    └─Empty: 2-1563                     [64]                      --
│    └─Empty: 2-1564                     [64]                      --
│    └─BatchNorm2d: 2-1565               [16, 64, 2, 2]            --
│    └─Scaler: 2-1566                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1567                      [16, 64, 2, 2]            --
│    └─Empty: 2-1568                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1569                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1570        --                        --
│    └─One: 2-1571                       [1]                       --
│    └─OutputScale: 2-1572               --                        --
│    └─Empty: 2-1573                     [64, 64, 1, 1]            --
│    └─Empty: 2-1574                     [64, 64, 1, 1]            --
│    └─Empty: 2-1575                     [64]                      --
│    └─Empty: 2-1576                     [64]                      --
│    └─BatchNorm2d: 2-1577               [16, 64, 2, 2]            --
│    └─Scaler: 2-1578                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1579                      [16, 64, 2, 2]            --
│    └─Empty: 2-1580                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1581                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1582                 [16, 64, 2, 2]            --
│    └─Empty: 2-1583                     [16, 64, 2, 2]            --
│    └─Empty: 2-1584                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1585        --                        --
│    └─One: 2-1586                       [1]                       --
│    └─OutputScale: 2-1587               --                        --
│    └─Empty: 2-1588                     [64, 64, 3, 3]            --
│    └─Empty: 2-1589                     [64, 64, 3, 3]            --
│    └─Empty: 2-1590                     [64]                      --
│    └─Empty: 2-1591                     [64]                      --
│    └─BatchNorm2d: 2-1592               [16, 64, 2, 2]            --
│    └─Scaler: 2-1593                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1594                      [16, 64, 2, 2]            --
│    └─Empty: 2-1595                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1596                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1597        --                        --
│    └─One: 2-1598                       [1]                       --
│    └─OutputScale: 2-1599               --                        --
│    └─Empty: 2-1600                     [64, 48, 1, 1]            --
│    └─Empty: 2-1601                     [64, 48, 1, 1]            --
│    └─Empty: 2-1602                     [64]                      --
│    └─Empty: 2-1603                     [64]                      --
│    └─BatchNorm2d: 2-1604               [16, 64, 64, 64]          --
│    └─Scaler: 2-1605                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1606                      [16, 64, 64, 64]          --
│    └─Empty: 2-1607                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1608                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1609        --                        --
│    └─One: 2-1610                       [1]                       --
│    └─OutputScale: 2-1611               --                        --
│    └─Empty: 2-1612                     [64, 64, 3, 3]            --
│    └─Empty: 2-1613                     [64, 64, 3, 3]            --
│    └─Empty: 2-1614                     [64]                      --
│    └─Empty: 2-1615                     [64]                      --
│    └─BatchNorm2d: 2-1616               [16, 64, 64, 64]          --
│    └─Scaler: 2-1617                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1618                      [16, 64, 64, 64]          --
│    └─Empty: 2-1619                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1620                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1621        --                        --
│    └─One: 2-1622                       [1]                       --
│    └─OutputScale: 2-1623               --                        --
│    └─Empty: 2-1624                     [64, 64, 1, 1]            --
│    └─Empty: 2-1625                     [64, 64, 1, 1]            --
│    └─Empty: 2-1626                     [64]                      --
│    └─Empty: 2-1627                     [64]                      --
│    └─BatchNorm2d: 2-1628               [16, 64, 64, 64]          --
│    └─Scaler: 2-1629                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1630                      [16, 64, 64, 64]          --
│    └─Empty: 2-1631                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1632                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1633        --                        --
│    └─One: 2-1634                       [1]                       --
│    └─OutputScale: 2-1635               --                        --
│    └─Empty: 2-1636                     [64, 64, 3, 3]            --
│    └─Empty: 2-1637                     [64, 64, 3, 3]            --
│    └─Empty: 2-1638                     [64]                      --
│    └─Empty: 2-1639                     [64]                      --
│    └─BatchNorm2d: 2-1640               [16, 64, 64, 64]          --
│    └─Scaler: 2-1641                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1642                      [16, 64, 64, 64]          --
│    └─Empty: 2-1643                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1644                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1645                 [16, 64, 32, 32]          --
│    └─Empty: 2-1646                     [16, 64, 32, 32]          --
│    └─Empty: 2-1647                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1648        --                        --
│    └─One: 2-1649                       [1]                       --
│    └─OutputScale: 2-1650               --                        --
│    └─Empty: 2-1651                     [64, 64, 3, 3]            --
│    └─Empty: 2-1652                     [64, 64, 3, 3]            --
│    └─Empty: 2-1653                     [64]                      --
│    └─Empty: 2-1654                     [64]                      --
│    └─BatchNorm2d: 2-1655               [16, 64, 32, 32]          --
│    └─Scaler: 2-1656                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1657                      [16, 64, 32, 32]          --
│    └─Empty: 2-1658                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1659                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1660        --                        --
│    └─One: 2-1661                       [1]                       --
│    └─OutputScale: 2-1662               --                        --
│    └─Empty: 2-1663                     [64, 64, 3, 3]            --
│    └─Empty: 2-1664                     [64, 64, 3, 3]            --
│    └─Empty: 2-1665                     [64]                      --
│    └─Empty: 2-1666                     [64]                      --
│    └─BatchNorm2d: 2-1667               [16, 64, 32, 32]          --
│    └─Scaler: 2-1668                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1669                      [16, 64, 32, 32]          --
│    └─Empty: 2-1670                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1671                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1672                 [16, 64, 16, 16]          --
│    └─Empty: 2-1673                     [16, 64, 16, 16]          --
│    └─Empty: 2-1674                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1675        --                        --
│    └─One: 2-1676                       [1]                       --
│    └─OutputScale: 2-1677               --                        --
│    └─Empty: 2-1678                     [64, 64, 3, 3]            --
│    └─Empty: 2-1679                     [64, 64, 3, 3]            --
│    └─Empty: 2-1680                     [64]                      --
│    └─Empty: 2-1681                     [64]                      --
│    └─BatchNorm2d: 2-1682               [16, 64, 16, 16]          --
│    └─Scaler: 2-1683                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1684                      [16, 64, 16, 16]          --
│    └─Empty: 2-1685                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1686                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1687        --                        --
│    └─One: 2-1688                       [1]                       --
│    └─OutputScale: 2-1689               --                        --
│    └─Empty: 2-1690                     [64, 64, 3, 3]            --
│    └─Empty: 2-1691                     [64, 64, 3, 3]            --
│    └─Empty: 2-1692                     [64]                      --
│    └─Empty: 2-1693                     [64]                      --
│    └─BatchNorm2d: 2-1694               [16, 64, 16, 16]          --
│    └─Scaler: 2-1695                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1696                      [16, 64, 16, 16]          --
│    └─Empty: 2-1697                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1698                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1699                 [16, 64, 8, 8]            --
│    └─Empty: 2-1700                     [16, 64, 8, 8]            --
│    └─Empty: 2-1701                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1702        --                        --
│    └─One: 2-1703                       [1]                       --
│    └─OutputScale: 2-1704               --                        --
│    └─Empty: 2-1705                     [64, 64, 3, 3]            --
│    └─Empty: 2-1706                     [64, 64, 3, 3]            --
│    └─Empty: 2-1707                     [64]                      --
│    └─Empty: 2-1708                     [64]                      --
│    └─BatchNorm2d: 2-1709               [16, 64, 8, 8]            --
│    └─Scaler: 2-1710                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1711                      [16, 64, 8, 8]            --
│    └─Empty: 2-1712                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1713                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1714        --                        --
│    └─One: 2-1715                       [1]                       --
│    └─OutputScale: 2-1716               --                        --
│    └─Empty: 2-1717                     [64, 64, 1, 1]            --
│    └─Empty: 2-1718                     [64, 64, 1, 1]            --
│    └─Empty: 2-1719                     [64]                      --
│    └─Empty: 2-1720                     [64]                      --
│    └─BatchNorm2d: 2-1721               [16, 64, 8, 8]            --
│    └─Scaler: 2-1722                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1723                      [16, 64, 8, 8]            --
│    └─Empty: 2-1724                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1725                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1726                 [16, 64, 8, 8]            --
│    └─Empty: 2-1727                     [16, 64, 8, 8]            --
│    └─Empty: 2-1728                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1729        --                        --
│    └─One: 2-1730                       [1]                       --
│    └─OutputScale: 2-1731               --                        --
│    └─Empty: 2-1732                     [64, 64, 3, 3]            --
│    └─Empty: 2-1733                     [64, 64, 3, 3]            --
│    └─Empty: 2-1734                     [64]                      --
│    └─Empty: 2-1735                     [64]                      --
│    └─BatchNorm2d: 2-1736               [16, 64, 8, 8]            --
│    └─Scaler: 2-1737                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1738                      [16, 64, 8, 8]            --
│    └─Empty: 2-1739                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1740                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1741                 [16, 64, 4, 4]            --
│    └─Empty: 2-1742                     [16, 64, 4, 4]            --
│    └─Empty: 2-1743                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1744        --                        --
│    └─One: 2-1745                       [1]                       --
│    └─OutputScale: 2-1746               --                        --
│    └─Empty: 2-1747                     [64, 64, 3, 3]            --
│    └─Empty: 2-1748                     [64, 64, 3, 3]            --
│    └─Empty: 2-1749                     [64]                      --
│    └─Empty: 2-1750                     [64]                      --
│    └─BatchNorm2d: 2-1751               [16, 64, 4, 4]            --
│    └─Scaler: 2-1752                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1753                      [16, 64, 4, 4]            --
│    └─Empty: 2-1754                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1755                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1756        --                        --
│    └─One: 2-1757                       [1]                       --
│    └─OutputScale: 2-1758               --                        --
│    └─Empty: 2-1759                     [64, 64, 1, 1]            --
│    └─Empty: 2-1760                     [64, 64, 1, 1]            --
│    └─Empty: 2-1761                     [64]                      --
│    └─Empty: 2-1762                     [64]                      --
│    └─BatchNorm2d: 2-1763               [16, 64, 4, 4]            --
│    └─Scaler: 2-1764                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1765                      [16, 64, 4, 4]            --
│    └─Empty: 2-1766                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1767                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1768                 [16, 64, 4, 4]            --
│    └─Empty: 2-1769                     [16, 64, 4, 4]            --
│    └─Empty: 2-1770                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1771        --                        --
│    └─One: 2-1772                       [1]                       --
│    └─OutputScale: 2-1773               --                        --
│    └─Empty: 2-1774                     [64, 64, 3, 3]            --
│    └─Empty: 2-1775                     [64, 64, 3, 3]            --
│    └─Empty: 2-1776                     [64]                      --
│    └─Empty: 2-1777                     [64]                      --
│    └─BatchNorm2d: 2-1778               [16, 64, 4, 4]            --
│    └─Scaler: 2-1779                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1780                      [16, 64, 4, 4]            --
│    └─Empty: 2-1781                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1782                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1783                 [16, 64, 2, 2]            --
│    └─Empty: 2-1784                     [16, 64, 2, 2]            --
│    └─Empty: 2-1785                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1786        --                        --
│    └─One: 2-1787                       [1]                       --
│    └─OutputScale: 2-1788               --                        --
│    └─Empty: 2-1789                     [64, 64, 1, 1]            --
│    └─Empty: 2-1790                     [64, 64, 1, 1]            --
│    └─Empty: 2-1791                     [64]                      --
│    └─Empty: 2-1792                     [64]                      --
│    └─BatchNorm2d: 2-1793               [16, 64, 2, 2]            --
│    └─Scaler: 2-1794                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1795                      [16, 64, 2, 2]            --
│    └─Empty: 2-1796                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1797                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1798        --                        --
│    └─One: 2-1799                       [1]                       --
│    └─OutputScale: 2-1800               --                        --
│    └─Empty: 2-1801                     [64, 64, 1, 1]            --
│    └─Empty: 2-1802                     [64, 64, 1, 1]            --
│    └─Empty: 2-1803                     [64]                      --
│    └─Empty: 2-1804                     [64]                      --
│    └─BatchNorm2d: 2-1805               [16, 64, 2, 2]            --
│    └─Scaler: 2-1806                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1807                      [16, 64, 2, 2]            --
│    └─Empty: 2-1808                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1809                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1810                 [16, 64, 2, 2]            --
│    └─Empty: 2-1811                     [16, 64, 2, 2]            --
│    └─Empty: 2-1812                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1813        --                        --
│    └─One: 2-1814                       [1]                       --
│    └─OutputScale: 2-1815               --                        --
│    └─Empty: 2-1816                     [64, 64, 3, 3]            --
│    └─Empty: 2-1817                     [64, 64, 3, 3]            --
│    └─Empty: 2-1818                     [64]                      --
│    └─Empty: 2-1819                     [64]                      --
│    └─BatchNorm2d: 2-1820               [16, 64, 2, 2]            --
│    └─Scaler: 2-1821                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1822                      [16, 64, 2, 2]            --
│    └─Empty: 2-1823                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1824                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1825        --                        --
│    └─One: 2-1826                       [1]                       --
│    └─OutputScale: 2-1827               --                        --
│    └─Empty: 2-1828                     [64, 48, 1, 1]            --
│    └─Empty: 2-1829                     [64, 48, 1, 1]            --
│    └─Empty: 2-1830                     [64]                      --
│    └─Empty: 2-1831                     [64]                      --
│    └─BatchNorm2d: 2-1832               [16, 64, 64, 64]          --
│    └─Scaler: 2-1833                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1834                      [16, 64, 64, 64]          --
│    └─Empty: 2-1835                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1836                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1837        --                        --
│    └─One: 2-1838                       [1]                       --
│    └─OutputScale: 2-1839               --                        --
│    └─Empty: 2-1840                     [64, 64, 3, 3]            --
│    └─Empty: 2-1841                     [64, 64, 3, 3]            --
│    └─Empty: 2-1842                     [64]                      --
│    └─Empty: 2-1843                     [64]                      --
│    └─BatchNorm2d: 2-1844               [16, 64, 64, 64]          --
│    └─Scaler: 2-1845                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1846                      [16, 64, 64, 64]          --
│    └─Empty: 2-1847                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1848                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1849        --                        --
│    └─One: 2-1850                       [1]                       --
│    └─OutputScale: 2-1851               --                        --
│    └─Empty: 2-1852                     [64, 64, 1, 1]            --
│    └─Empty: 2-1853                     [64, 64, 1, 1]            --
│    └─Empty: 2-1854                     [64]                      --
│    └─Empty: 2-1855                     [64]                      --
│    └─BatchNorm2d: 2-1856               [16, 64, 64, 64]          --
│    └─Scaler: 2-1857                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1858                      [16, 64, 64, 64]          --
│    └─Empty: 2-1859                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1860                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1861        --                        --
│    └─One: 2-1862                       [1]                       --
│    └─OutputScale: 2-1863               --                        --
│    └─Empty: 2-1864                     [64, 64, 3, 3]            --
│    └─Empty: 2-1865                     [64, 64, 3, 3]            --
│    └─Empty: 2-1866                     [64]                      --
│    └─Empty: 2-1867                     [64]                      --
│    └─BatchNorm2d: 2-1868               [16, 64, 64, 64]          --
│    └─Scaler: 2-1869                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1870                      [16, 64, 64, 64]          --
│    └─Empty: 2-1871                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1872                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1873                 [16, 64, 32, 32]          --
│    └─Empty: 2-1874                     [16, 64, 32, 32]          --
│    └─Empty: 2-1875                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1876        --                        --
│    └─One: 2-1877                       [1]                       --
│    └─OutputScale: 2-1878               --                        --
│    └─Empty: 2-1879                     [64, 64, 3, 3]            --
│    └─Empty: 2-1880                     [64, 64, 3, 3]            --
│    └─Empty: 2-1881                     [64]                      --
│    └─Empty: 2-1882                     [64]                      --
│    └─BatchNorm2d: 2-1883               [16, 64, 32, 32]          --
│    └─Scaler: 2-1884                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1885                      [16, 64, 32, 32]          --
│    └─Empty: 2-1886                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1887                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1888        --                        --
│    └─One: 2-1889                       [1]                       --
│    └─OutputScale: 2-1890               --                        --
│    └─Empty: 2-1891                     [64, 64, 3, 3]            --
│    └─Empty: 2-1892                     [64, 64, 3, 3]            --
│    └─Empty: 2-1893                     [64]                      --
│    └─Empty: 2-1894                     [64]                      --
│    └─BatchNorm2d: 2-1895               [16, 64, 32, 32]          --
│    └─Scaler: 2-1896                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1897                      [16, 64, 32, 32]          --
│    └─Empty: 2-1898                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1899                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1900                 [16, 64, 16, 16]          --
│    └─Empty: 2-1901                     [16, 64, 16, 16]          --
│    └─Empty: 2-1902                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1903        --                        --
│    └─One: 2-1904                       [1]                       --
│    └─OutputScale: 2-1905               --                        --
│    └─Empty: 2-1906                     [64, 64, 3, 3]            --
│    └─Empty: 2-1907                     [64, 64, 3, 3]            --
│    └─Empty: 2-1908                     [64]                      --
│    └─Empty: 2-1909                     [64]                      --
│    └─BatchNorm2d: 2-1910               [16, 64, 16, 16]          --
│    └─Scaler: 2-1911                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1912                      [16, 64, 16, 16]          --
│    └─Empty: 2-1913                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1914                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1915        --                        --
│    └─One: 2-1916                       [1]                       --
│    └─OutputScale: 2-1917               --                        --
│    └─Empty: 2-1918                     [64, 64, 3, 3]            --
│    └─Empty: 2-1919                     [64, 64, 3, 3]            --
│    └─Empty: 2-1920                     [64]                      --
│    └─Empty: 2-1921                     [64]                      --
│    └─BatchNorm2d: 2-1922               [16, 64, 16, 16]          --
│    └─Scaler: 2-1923                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1924                      [16, 64, 16, 16]          --
│    └─Empty: 2-1925                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1926                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1927                 [16, 64, 8, 8]            --
│    └─Empty: 2-1928                     [16, 64, 8, 8]            --
│    └─Empty: 2-1929                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1930        --                        --
│    └─One: 2-1931                       [1]                       --
│    └─OutputScale: 2-1932               --                        --
│    └─Empty: 2-1933                     [64, 64, 3, 3]            --
│    └─Empty: 2-1934                     [64, 64, 3, 3]            --
│    └─Empty: 2-1935                     [64]                      --
│    └─Empty: 2-1936                     [64]                      --
│    └─BatchNorm2d: 2-1937               [16, 64, 8, 8]            --
│    └─Scaler: 2-1938                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1939                      [16, 64, 8, 8]            --
│    └─Empty: 2-1940                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1941                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1942        --                        --
│    └─One: 2-1943                       [1]                       --
│    └─OutputScale: 2-1944               --                        --
│    └─Empty: 2-1945                     [64, 64, 1, 1]            --
│    └─Empty: 2-1946                     [64, 64, 1, 1]            --
│    └─Empty: 2-1947                     [64]                      --
│    └─Empty: 2-1948                     [64]                      --
│    └─BatchNorm2d: 2-1949               [16, 64, 8, 8]            --
│    └─Scaler: 2-1950                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1951                      [16, 64, 8, 8]            --
│    └─Empty: 2-1952                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1953                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1954                 [16, 64, 8, 8]            --
│    └─Empty: 2-1955                     [16, 64, 8, 8]            --
│    └─Empty: 2-1956                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1957        --                        --
│    └─One: 2-1958                       [1]                       --
│    └─OutputScale: 2-1959               --                        --
│    └─Empty: 2-1960                     [64, 64, 3, 3]            --
│    └─Empty: 2-1961                     [64, 64, 3, 3]            --
│    └─Empty: 2-1962                     [64]                      --
│    └─Empty: 2-1963                     [64]                      --
│    └─BatchNorm2d: 2-1964               [16, 64, 8, 8]            --
│    └─Scaler: 2-1965                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1966                      [16, 64, 8, 8]            --
│    └─Empty: 2-1967                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1968                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1969                 [16, 64, 4, 4]            --
│    └─Empty: 2-1970                     [16, 64, 4, 4]            --
│    └─Empty: 2-1971                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1972        --                        --
│    └─One: 2-1973                       [1]                       --
│    └─OutputScale: 2-1974               --                        --
│    └─Empty: 2-1975                     [64, 64, 3, 3]            --
│    └─Empty: 2-1976                     [64, 64, 3, 3]            --
│    └─Empty: 2-1977                     [64]                      --
│    └─Empty: 2-1978                     [64]                      --
│    └─BatchNorm2d: 2-1979               [16, 64, 4, 4]            --
│    └─Scaler: 2-1980                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1981                      [16, 64, 4, 4]            --
│    └─Empty: 2-1982                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1983                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1984        --                        --
│    └─One: 2-1985                       [1]                       --
│    └─OutputScale: 2-1986               --                        --
│    └─Empty: 2-1987                     [64, 64, 1, 1]            --
│    └─Empty: 2-1988                     [64, 64, 1, 1]            --
│    └─Empty: 2-1989                     [64]                      --
│    └─Empty: 2-1990                     [64]                      --
│    └─BatchNorm2d: 2-1991               [16, 64, 4, 4]            --
│    └─Scaler: 2-1992                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1993                      [16, 64, 4, 4]            --
│    └─Empty: 2-1994                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1995                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1996                 [16, 64, 4, 4]            --
│    └─Empty: 2-1997                     [16, 64, 4, 4]            --
│    └─Empty: 2-1998                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1999        --                        --
│    └─One: 2-2000                       [1]                       --
│    └─OutputScale: 2-2001               --                        --
│    └─Empty: 2-2002                     [64, 64, 3, 3]            --
│    └─Empty: 2-2003                     [64, 64, 3, 3]            --
│    └─Empty: 2-2004                     [64]                      --
│    └─Empty: 2-2005                     [64]                      --
│    └─BatchNorm2d: 2-2006               [16, 64, 4, 4]            --
│    └─Scaler: 2-2007                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2008                      [16, 64, 4, 4]            --
│    └─Empty: 2-2009                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2010                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2011                 [16, 64, 2, 2]            --
│    └─Empty: 2-2012                     [16, 64, 2, 2]            --
│    └─Empty: 2-2013                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2014        --                        --
│    └─One: 2-2015                       [1]                       --
│    └─OutputScale: 2-2016               --                        --
│    └─Empty: 2-2017                     [64, 64, 1, 1]            --
│    └─Empty: 2-2018                     [64, 64, 1, 1]            --
│    └─Empty: 2-2019                     [64]                      --
│    └─Empty: 2-2020                     [64]                      --
│    └─BatchNorm2d: 2-2021               [16, 64, 2, 2]            --
│    └─Scaler: 2-2022                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2023                      [16, 64, 2, 2]            --
│    └─Empty: 2-2024                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2025                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2026        --                        --
│    └─One: 2-2027                       [1]                       --
│    └─OutputScale: 2-2028               --                        --
│    └─Empty: 2-2029                     [64, 64, 1, 1]            --
│    └─Empty: 2-2030                     [64, 64, 1, 1]            --
│    └─Empty: 2-2031                     [64]                      --
│    └─Empty: 2-2032                     [64]                      --
│    └─BatchNorm2d: 2-2033               [16, 64, 2, 2]            --
│    └─Scaler: 2-2034                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2035                      [16, 64, 2, 2]            --
│    └─Empty: 2-2036                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2037                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2038                 [16, 64, 2, 2]            --
│    └─Empty: 2-2039                     [16, 64, 2, 2]            --
│    └─Empty: 2-2040                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2041        --                        --
│    └─One: 2-2042                       [1]                       --
│    └─OutputScale: 2-2043               --                        --
│    └─Empty: 2-2044                     [64, 64, 3, 3]            --
│    └─Empty: 2-2045                     [64, 64, 3, 3]            --
│    └─Empty: 2-2046                     [64]                      --
│    └─Empty: 2-2047                     [64]                      --
│    └─BatchNorm2d: 2-2048               [16, 64, 2, 2]            --
│    └─Scaler: 2-2049                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2050                      [16, 64, 2, 2]            --
│    └─Empty: 2-2051                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2052                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2053        --                        --
│    └─One: 2-2054                       [1]                       --
│    └─OutputScale: 2-2055               --                        --
│    └─Empty: 2-2056                     [64, 48, 1, 1]            --
│    └─Empty: 2-2057                     [64, 48, 1, 1]            --
│    └─Empty: 2-2058                     [64]                      --
│    └─Empty: 2-2059                     [64]                      --
│    └─BatchNorm2d: 2-2060               [16, 64, 64, 64]          --
│    └─Scaler: 2-2061                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2062                      [16, 64, 64, 64]          --
│    └─Empty: 2-2063                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2064                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2065        --                        --
│    └─One: 2-2066                       [1]                       --
│    └─OutputScale: 2-2067               --                        --
│    └─Empty: 2-2068                     [64, 64, 3, 3]            --
│    └─Empty: 2-2069                     [64, 64, 3, 3]            --
│    └─Empty: 2-2070                     [64]                      --
│    └─Empty: 2-2071                     [64]                      --
│    └─BatchNorm2d: 2-2072               [16, 64, 64, 64]          --
│    └─Scaler: 2-2073                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2074                      [16, 64, 64, 64]          --
│    └─Empty: 2-2075                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2076                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2077        --                        --
│    └─One: 2-2078                       [1]                       --
│    └─OutputScale: 2-2079               --                        --
│    └─Empty: 2-2080                     [64, 64, 1, 1]            --
│    └─Empty: 2-2081                     [64, 64, 1, 1]            --
│    └─Empty: 2-2082                     [64]                      --
│    └─Empty: 2-2083                     [64]                      --
│    └─BatchNorm2d: 2-2084               [16, 64, 64, 64]          --
│    └─Scaler: 2-2085                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2086                      [16, 64, 64, 64]          --
│    └─Empty: 2-2087                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2088                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2089        --                        --
│    └─One: 2-2090                       [1]                       --
│    └─OutputScale: 2-2091               --                        --
│    └─Empty: 2-2092                     [64, 64, 3, 3]            --
│    └─Empty: 2-2093                     [64, 64, 3, 3]            --
│    └─Empty: 2-2094                     [64]                      --
│    └─Empty: 2-2095                     [64]                      --
│    └─BatchNorm2d: 2-2096               [16, 64, 64, 64]          --
│    └─Scaler: 2-2097                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2098                      [16, 64, 64, 64]          --
│    └─Empty: 2-2099                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2100                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2101                 [16, 64, 32, 32]          --
│    └─Empty: 2-2102                     [16, 64, 32, 32]          --
│    └─Empty: 2-2103                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2104        --                        --
│    └─One: 2-2105                       [1]                       --
│    └─OutputScale: 2-2106               --                        --
│    └─Empty: 2-2107                     [64, 64, 3, 3]            --
│    └─Empty: 2-2108                     [64, 64, 3, 3]            --
│    └─Empty: 2-2109                     [64]                      --
│    └─Empty: 2-2110                     [64]                      --
│    └─BatchNorm2d: 2-2111               [16, 64, 32, 32]          --
│    └─Scaler: 2-2112                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2113                      [16, 64, 32, 32]          --
│    └─Empty: 2-2114                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2115                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2116        --                        --
│    └─One: 2-2117                       [1]                       --
│    └─OutputScale: 2-2118               --                        --
│    └─Empty: 2-2119                     [64, 64, 3, 3]            --
│    └─Empty: 2-2120                     [64, 64, 3, 3]            --
│    └─Empty: 2-2121                     [64]                      --
│    └─Empty: 2-2122                     [64]                      --
│    └─BatchNorm2d: 2-2123               [16, 64, 32, 32]          --
│    └─Scaler: 2-2124                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2125                      [16, 64, 32, 32]          --
│    └─Empty: 2-2126                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2127                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2128                 [16, 64, 16, 16]          --
│    └─Empty: 2-2129                     [16, 64, 16, 16]          --
│    └─Empty: 2-2130                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2131        --                        --
│    └─One: 2-2132                       [1]                       --
│    └─OutputScale: 2-2133               --                        --
│    └─Empty: 2-2134                     [64, 64, 3, 3]            --
│    └─Empty: 2-2135                     [64, 64, 3, 3]            --
│    └─Empty: 2-2136                     [64]                      --
│    └─Empty: 2-2137                     [64]                      --
│    └─BatchNorm2d: 2-2138               [16, 64, 16, 16]          --
│    └─Scaler: 2-2139                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2140                      [16, 64, 16, 16]          --
│    └─Empty: 2-2141                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2142                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2143        --                        --
│    └─One: 2-2144                       [1]                       --
│    └─OutputScale: 2-2145               --                        --
│    └─Empty: 2-2146                     [64, 64, 3, 3]            --
│    └─Empty: 2-2147                     [64, 64, 3, 3]            --
│    └─Empty: 2-2148                     [64]                      --
│    └─Empty: 2-2149                     [64]                      --
│    └─BatchNorm2d: 2-2150               [16, 64, 16, 16]          --
│    └─Scaler: 2-2151                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2152                      [16, 64, 16, 16]          --
│    └─Empty: 2-2153                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2154                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2155                 [16, 64, 8, 8]            --
│    └─Empty: 2-2156                     [16, 64, 8, 8]            --
│    └─Empty: 2-2157                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2158        --                        --
│    └─One: 2-2159                       [1]                       --
│    └─OutputScale: 2-2160               --                        --
│    └─Empty: 2-2161                     [64, 64, 3, 3]            --
│    └─Empty: 2-2162                     [64, 64, 3, 3]            --
│    └─Empty: 2-2163                     [64]                      --
│    └─Empty: 2-2164                     [64]                      --
│    └─BatchNorm2d: 2-2165               [16, 64, 8, 8]            --
│    └─Scaler: 2-2166                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2167                      [16, 64, 8, 8]            --
│    └─Empty: 2-2168                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2169                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2170        --                        --
│    └─One: 2-2171                       [1]                       --
│    └─OutputScale: 2-2172               --                        --
│    └─Empty: 2-2173                     [64, 64, 1, 1]            --
│    └─Empty: 2-2174                     [64, 64, 1, 1]            --
│    └─Empty: 2-2175                     [64]                      --
│    └─Empty: 2-2176                     [64]                      --
│    └─BatchNorm2d: 2-2177               [16, 64, 8, 8]            --
│    └─Scaler: 2-2178                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2179                      [16, 64, 8, 8]            --
│    └─Empty: 2-2180                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2181                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2182                 [16, 64, 8, 8]            --
│    └─Empty: 2-2183                     [16, 64, 8, 8]            --
│    └─Empty: 2-2184                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2185        --                        --
│    └─One: 2-2186                       [1]                       --
│    └─OutputScale: 2-2187               --                        --
│    └─Empty: 2-2188                     [64, 64, 3, 3]            --
│    └─Empty: 2-2189                     [64, 64, 3, 3]            --
│    └─Empty: 2-2190                     [64]                      --
│    └─Empty: 2-2191                     [64]                      --
│    └─BatchNorm2d: 2-2192               [16, 64, 8, 8]            --
│    └─Scaler: 2-2193                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2194                      [16, 64, 8, 8]            --
│    └─Empty: 2-2195                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2196                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2197                 [16, 64, 4, 4]            --
│    └─Empty: 2-2198                     [16, 64, 4, 4]            --
│    └─Empty: 2-2199                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2200        --                        --
│    └─One: 2-2201                       [1]                       --
│    └─OutputScale: 2-2202               --                        --
│    └─Empty: 2-2203                     [64, 64, 3, 3]            --
│    └─Empty: 2-2204                     [64, 64, 3, 3]            --
│    └─Empty: 2-2205                     [64]                      --
│    └─Empty: 2-2206                     [64]                      --
│    └─BatchNorm2d: 2-2207               [16, 64, 4, 4]            --
│    └─Scaler: 2-2208                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2209                      [16, 64, 4, 4]            --
│    └─Empty: 2-2210                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2211                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2212        --                        --
│    └─One: 2-2213                       [1]                       --
│    └─OutputScale: 2-2214               --                        --
│    └─Empty: 2-2215                     [64, 64, 1, 1]            --
│    └─Empty: 2-2216                     [64, 64, 1, 1]            --
│    └─Empty: 2-2217                     [64]                      --
│    └─Empty: 2-2218                     [64]                      --
│    └─BatchNorm2d: 2-2219               [16, 64, 4, 4]            --
│    └─Scaler: 2-2220                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2221                      [16, 64, 4, 4]            --
│    └─Empty: 2-2222                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2223                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2224                 [16, 64, 4, 4]            --
│    └─Empty: 2-2225                     [16, 64, 4, 4]            --
│    └─Empty: 2-2226                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2227        --                        --
│    └─One: 2-2228                       [1]                       --
│    └─OutputScale: 2-2229               --                        --
│    └─Empty: 2-2230                     [64, 64, 3, 3]            --
│    └─Empty: 2-2231                     [64, 64, 3, 3]            --
│    └─Empty: 2-2232                     [64]                      --
│    └─Empty: 2-2233                     [64]                      --
│    └─BatchNorm2d: 2-2234               [16, 64, 4, 4]            --
│    └─Scaler: 2-2235                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2236                      [16, 64, 4, 4]            --
│    └─Empty: 2-2237                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2238                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2239                 [16, 64, 2, 2]            --
│    └─Empty: 2-2240                     [16, 64, 2, 2]            --
│    └─Empty: 2-2241                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2242        --                        --
│    └─One: 2-2243                       [1]                       --
│    └─OutputScale: 2-2244               --                        --
│    └─Empty: 2-2245                     [64, 64, 1, 1]            --
│    └─Empty: 2-2246                     [64, 64, 1, 1]            --
│    └─Empty: 2-2247                     [64]                      --
│    └─Empty: 2-2248                     [64]                      --
│    └─BatchNorm2d: 2-2249               [16, 64, 2, 2]            --
│    └─Scaler: 2-2250                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2251                      [16, 64, 2, 2]            --
│    └─Empty: 2-2252                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2253                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2254        --                        --
│    └─One: 2-2255                       [1]                       --
│    └─OutputScale: 2-2256               --                        --
│    └─Empty: 2-2257                     [64, 64, 1, 1]            --
│    └─Empty: 2-2258                     [64, 64, 1, 1]            --
│    └─Empty: 2-2259                     [64]                      --
│    └─Empty: 2-2260                     [64]                      --
│    └─BatchNorm2d: 2-2261               [16, 64, 2, 2]            --
│    └─Scaler: 2-2262                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2263                      [16, 64, 2, 2]            --
│    └─Empty: 2-2264                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2265                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2266                 [16, 64, 2, 2]            --
│    └─Empty: 2-2267                     [16, 64, 2, 2]            --
│    └─Empty: 2-2268                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2269        --                        --
│    └─One: 2-2270                       [1]                       --
│    └─OutputScale: 2-2271               --                        --
│    └─Empty: 2-2272                     [64, 64, 3, 3]            --
│    └─Empty: 2-2273                     [64, 64, 3, 3]            --
│    └─Empty: 2-2274                     [64]                      --
│    └─Empty: 2-2275                     [64]                      --
│    └─BatchNorm2d: 2-2276               [16, 64, 2, 2]            --
│    └─Scaler: 2-2277                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2278                      [16, 64, 2, 2]            --
│    └─Empty: 2-2279                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2280                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2281        --                        --
│    └─One: 2-2282                       [1]                       --
│    └─OutputScale: 2-2283               --                        --
│    └─Empty: 2-2284                     [64, 48, 1, 1]            --
│    └─Empty: 2-2285                     [64, 48, 1, 1]            --
│    └─Empty: 2-2286                     [64]                      --
│    └─Empty: 2-2287                     [64]                      --
│    └─BatchNorm2d: 2-2288               [16, 64, 64, 64]          --
│    └─Scaler: 2-2289                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2290                      [16, 64, 64, 64]          --
│    └─Empty: 2-2291                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2292                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2293        --                        --
│    └─One: 2-2294                       [1]                       --
│    └─OutputScale: 2-2295               --                        --
│    └─Empty: 2-2296                     [64, 64, 3, 3]            --
│    └─Empty: 2-2297                     [64, 64, 3, 3]            --
│    └─Empty: 2-2298                     [64]                      --
│    └─Empty: 2-2299                     [64]                      --
│    └─BatchNorm2d: 2-2300               [16, 64, 64, 64]          --
│    └─Scaler: 2-2301                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2302                      [16, 64, 64, 64]          --
│    └─Empty: 2-2303                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2304                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2305        --                        --
│    └─One: 2-2306                       [1]                       --
│    └─OutputScale: 2-2307               --                        --
│    └─Empty: 2-2308                     [64, 64, 1, 1]            --
│    └─Empty: 2-2309                     [64, 64, 1, 1]            --
│    └─Empty: 2-2310                     [64]                      --
│    └─Empty: 2-2311                     [64]                      --
│    └─BatchNorm2d: 2-2312               [16, 64, 64, 64]          --
│    └─Scaler: 2-2313                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2314                      [16, 64, 64, 64]          --
│    └─Empty: 2-2315                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2316                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2317        --                        --
│    └─One: 2-2318                       [1]                       --
│    └─OutputScale: 2-2319               --                        --
│    └─Empty: 2-2320                     [64, 64, 3, 3]            --
│    └─Empty: 2-2321                     [64, 64, 3, 3]            --
│    └─Empty: 2-2322                     [64]                      --
│    └─Empty: 2-2323                     [64]                      --
│    └─BatchNorm2d: 2-2324               [16, 64, 64, 64]          --
│    └─Scaler: 2-2325                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2326                      [16, 64, 64, 64]          --
│    └─Empty: 2-2327                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2328                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2329                 [16, 64, 32, 32]          --
│    └─Empty: 2-2330                     [16, 64, 32, 32]          --
│    └─Empty: 2-2331                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2332        --                        --
│    └─One: 2-2333                       [1]                       --
│    └─OutputScale: 2-2334               --                        --
│    └─Empty: 2-2335                     [64, 64, 3, 3]            --
│    └─Empty: 2-2336                     [64, 64, 3, 3]            --
│    └─Empty: 2-2337                     [64]                      --
│    └─Empty: 2-2338                     [64]                      --
│    └─BatchNorm2d: 2-2339               [16, 64, 32, 32]          --
│    └─Scaler: 2-2340                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2341                      [16, 64, 32, 32]          --
│    └─Empty: 2-2342                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2343                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2344        --                        --
│    └─One: 2-2345                       [1]                       --
│    └─OutputScale: 2-2346               --                        --
│    └─Empty: 2-2347                     [64, 64, 3, 3]            --
│    └─Empty: 2-2348                     [64, 64, 3, 3]            --
│    └─Empty: 2-2349                     [64]                      --
│    └─Empty: 2-2350                     [64]                      --
│    └─BatchNorm2d: 2-2351               [16, 64, 32, 32]          --
│    └─Scaler: 2-2352                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2353                      [16, 64, 32, 32]          --
│    └─Empty: 2-2354                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2355                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2356                 [16, 64, 16, 16]          --
│    └─Empty: 2-2357                     [16, 64, 16, 16]          --
│    └─Empty: 2-2358                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2359        --                        --
│    └─One: 2-2360                       [1]                       --
│    └─OutputScale: 2-2361               --                        --
│    └─Empty: 2-2362                     [64, 64, 3, 3]            --
│    └─Empty: 2-2363                     [64, 64, 3, 3]            --
│    └─Empty: 2-2364                     [64]                      --
│    └─Empty: 2-2365                     [64]                      --
│    └─BatchNorm2d: 2-2366               [16, 64, 16, 16]          --
│    └─Scaler: 2-2367                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2368                      [16, 64, 16, 16]          --
│    └─Empty: 2-2369                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2370                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2371        --                        --
│    └─One: 2-2372                       [1]                       --
│    └─OutputScale: 2-2373               --                        --
│    └─Empty: 2-2374                     [64, 64, 3, 3]            --
│    └─Empty: 2-2375                     [64, 64, 3, 3]            --
│    └─Empty: 2-2376                     [64]                      --
│    └─Empty: 2-2377                     [64]                      --
│    └─BatchNorm2d: 2-2378               [16, 64, 16, 16]          --
│    └─Scaler: 2-2379                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2380                      [16, 64, 16, 16]          --
│    └─Empty: 2-2381                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2382                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2383                 [16, 64, 8, 8]            --
│    └─Empty: 2-2384                     [16, 64, 8, 8]            --
│    └─Empty: 2-2385                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2386        --                        --
│    └─One: 2-2387                       [1]                       --
│    └─OutputScale: 2-2388               --                        --
│    └─Empty: 2-2389                     [64, 64, 3, 3]            --
│    └─Empty: 2-2390                     [64, 64, 3, 3]            --
│    └─Empty: 2-2391                     [64]                      --
│    └─Empty: 2-2392                     [64]                      --
│    └─BatchNorm2d: 2-2393               [16, 64, 8, 8]            --
│    └─Scaler: 2-2394                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2395                      [16, 64, 8, 8]            --
│    └─Empty: 2-2396                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2397                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2398        --                        --
│    └─One: 2-2399                       [1]                       --
│    └─OutputScale: 2-2400               --                        --
│    └─Empty: 2-2401                     [64, 64, 1, 1]            --
│    └─Empty: 2-2402                     [64, 64, 1, 1]            --
│    └─Empty: 2-2403                     [64]                      --
│    └─Empty: 2-2404                     [64]                      --
│    └─BatchNorm2d: 2-2405               [16, 64, 8, 8]            --
│    └─Scaler: 2-2406                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2407                      [16, 64, 8, 8]            --
│    └─Empty: 2-2408                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2409                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2410                 [16, 64, 8, 8]            --
│    └─Empty: 2-2411                     [16, 64, 8, 8]            --
│    └─Empty: 2-2412                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2413        --                        --
│    └─One: 2-2414                       [1]                       --
│    └─OutputScale: 2-2415               --                        --
│    └─Empty: 2-2416                     [64, 64, 3, 3]            --
│    └─Empty: 2-2417                     [64, 64, 3, 3]            --
│    └─Empty: 2-2418                     [64]                      --
│    └─Empty: 2-2419                     [64]                      --
│    └─BatchNorm2d: 2-2420               [16, 64, 8, 8]            --
│    └─Scaler: 2-2421                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2422                      [16, 64, 8, 8]            --
│    └─Empty: 2-2423                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2424                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2425                 [16, 64, 4, 4]            --
│    └─Empty: 2-2426                     [16, 64, 4, 4]            --
│    └─Empty: 2-2427                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2428        --                        --
│    └─One: 2-2429                       [1]                       --
│    └─OutputScale: 2-2430               --                        --
│    └─Empty: 2-2431                     [64, 64, 3, 3]            --
│    └─Empty: 2-2432                     [64, 64, 3, 3]            --
│    └─Empty: 2-2433                     [64]                      --
│    └─Empty: 2-2434                     [64]                      --
│    └─BatchNorm2d: 2-2435               [16, 64, 4, 4]            --
│    └─Scaler: 2-2436                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2437                      [16, 64, 4, 4]            --
│    └─Empty: 2-2438                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2439                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2440        --                        --
│    └─One: 2-2441                       [1]                       --
│    └─OutputScale: 2-2442               --                        --
│    └─Empty: 2-2443                     [64, 64, 1, 1]            --
│    └─Empty: 2-2444                     [64, 64, 1, 1]            --
│    └─Empty: 2-2445                     [64]                      --
│    └─Empty: 2-2446                     [64]                      --
│    └─BatchNorm2d: 2-2447               [16, 64, 4, 4]            --
│    └─Scaler: 2-2448                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2449                      [16, 64, 4, 4]            --
│    └─Empty: 2-2450                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2451                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2452                 [16, 64, 4, 4]            --
│    └─Empty: 2-2453                     [16, 64, 4, 4]            --
│    └─Empty: 2-2454                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2455        --                        --
│    └─One: 2-2456                       [1]                       --
│    └─OutputScale: 2-2457               --                        --
│    └─Empty: 2-2458                     [64, 64, 3, 3]            --
│    └─Empty: 2-2459                     [64, 64, 3, 3]            --
│    └─Empty: 2-2460                     [64]                      --
│    └─Empty: 2-2461                     [64]                      --
│    └─BatchNorm2d: 2-2462               [16, 64, 4, 4]            --
│    └─Scaler: 2-2463                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2464                      [16, 64, 4, 4]            --
│    └─Empty: 2-2465                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2466                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2467                 [16, 64, 2, 2]            --
│    └─Empty: 2-2468                     [16, 64, 2, 2]            --
│    └─Empty: 2-2469                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2470        --                        --
│    └─One: 2-2471                       [1]                       --
│    └─OutputScale: 2-2472               --                        --
│    └─Empty: 2-2473                     [64, 64, 1, 1]            --
│    └─Empty: 2-2474                     [64, 64, 1, 1]            --
│    └─Empty: 2-2475                     [64]                      --
│    └─Empty: 2-2476                     [64]                      --
│    └─BatchNorm2d: 2-2477               [16, 64, 2, 2]            --
│    └─Scaler: 2-2478                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2479                      [16, 64, 2, 2]            --
│    └─Empty: 2-2480                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2481                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2482        --                        --
│    └─One: 2-2483                       [1]                       --
│    └─OutputScale: 2-2484               --                        --
│    └─Empty: 2-2485                     [64, 64, 1, 1]            --
│    └─Empty: 2-2486                     [64, 64, 1, 1]            --
│    └─Empty: 2-2487                     [64]                      --
│    └─Empty: 2-2488                     [64]                      --
│    └─BatchNorm2d: 2-2489               [16, 64, 2, 2]            --
│    └─Scaler: 2-2490                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2491                      [16, 64, 2, 2]            --
│    └─Empty: 2-2492                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2493                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2494                 [16, 64, 2, 2]            --
│    └─Empty: 2-2495                     [16, 64, 2, 2]            --
│    └─Empty: 2-2496                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2497        --                        --
│    └─One: 2-2498                       [1]                       --
│    └─OutputScale: 2-2499               --                        --
│    └─Empty: 2-2500                     [64, 64, 3, 3]            --
│    └─Empty: 2-2501                     [64, 64, 3, 3]            --
│    └─Empty: 2-2502                     [64]                      --
│    └─Empty: 2-2503                     [64]                      --
│    └─BatchNorm2d: 2-2504               [16, 64, 2, 2]            --
│    └─Scaler: 2-2505                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2506                      [16, 64, 2, 2]            --
│    └─Empty: 2-2507                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2508                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2509        --                        --
│    └─One: 2-2510                       [1]                       --
│    └─OutputScale: 2-2511               --                        --
│    └─Empty: 2-2512                     [64, 48, 1, 1]            --
│    └─Empty: 2-2513                     [64, 48, 1, 1]            --
│    └─Empty: 2-2514                     [64]                      --
│    └─Empty: 2-2515                     [64]                      --
│    └─BatchNorm2d: 2-2516               [16, 64, 64, 64]          --
│    └─Scaler: 2-2517                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2518                      [16, 64, 64, 64]          --
│    └─Empty: 2-2519                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2520                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2521        --                        --
│    └─One: 2-2522                       [1]                       --
│    └─OutputScale: 2-2523               --                        --
│    └─Empty: 2-2524                     [64, 64, 3, 3]            --
│    └─Empty: 2-2525                     [64, 64, 3, 3]            --
│    └─Empty: 2-2526                     [64]                      --
│    └─Empty: 2-2527                     [64]                      --
│    └─BatchNorm2d: 2-2528               [16, 64, 64, 64]          --
│    └─Scaler: 2-2529                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2530                      [16, 64, 64, 64]          --
│    └─Empty: 2-2531                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2532                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2533        --                        --
│    └─One: 2-2534                       [1]                       --
│    └─OutputScale: 2-2535               --                        --
│    └─Empty: 2-2536                     [64, 64, 1, 1]            --
│    └─Empty: 2-2537                     [64, 64, 1, 1]            --
│    └─Empty: 2-2538                     [64]                      --
│    └─Empty: 2-2539                     [64]                      --
│    └─BatchNorm2d: 2-2540               [16, 64, 64, 64]          --
│    └─Scaler: 2-2541                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2542                      [16, 64, 64, 64]          --
│    └─Empty: 2-2543                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2544                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2545        --                        --
│    └─One: 2-2546                       [1]                       --
│    └─OutputScale: 2-2547               --                        --
│    └─Empty: 2-2548                     [64, 64, 3, 3]            --
│    └─Empty: 2-2549                     [64, 64, 3, 3]            --
│    └─Empty: 2-2550                     [64]                      --
│    └─Empty: 2-2551                     [64]                      --
│    └─BatchNorm2d: 2-2552               [16, 64, 64, 64]          --
│    └─Scaler: 2-2553                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2554                      [16, 64, 64, 64]          --
│    └─Empty: 2-2555                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2556                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2557                 [16, 64, 32, 32]          --
│    └─Empty: 2-2558                     [16, 64, 32, 32]          --
│    └─Empty: 2-2559                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2560        --                        --
│    └─One: 2-2561                       [1]                       --
│    └─OutputScale: 2-2562               --                        --
│    └─Empty: 2-2563                     [64, 64, 3, 3]            --
│    └─Empty: 2-2564                     [64, 64, 3, 3]            --
│    └─Empty: 2-2565                     [64]                      --
│    └─Empty: 2-2566                     [64]                      --
│    └─BatchNorm2d: 2-2567               [16, 64, 32, 32]          --
│    └─Scaler: 2-2568                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2569                      [16, 64, 32, 32]          --
│    └─Empty: 2-2570                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2571                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2572        --                        --
│    └─One: 2-2573                       [1]                       --
│    └─OutputScale: 2-2574               --                        --
│    └─Empty: 2-2575                     [64, 64, 3, 3]            --
│    └─Empty: 2-2576                     [64, 64, 3, 3]            --
│    └─Empty: 2-2577                     [64]                      --
│    └─Empty: 2-2578                     [64]                      --
│    └─BatchNorm2d: 2-2579               [16, 64, 32, 32]          --
│    └─Scaler: 2-2580                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2581                      [16, 64, 32, 32]          --
│    └─Empty: 2-2582                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2583                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2584                 [16, 64, 16, 16]          --
│    └─Empty: 2-2585                     [16, 64, 16, 16]          --
│    └─Empty: 2-2586                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2587        --                        --
│    └─One: 2-2588                       [1]                       --
│    └─OutputScale: 2-2589               --                        --
│    └─Empty: 2-2590                     [64, 64, 3, 3]            --
│    └─Empty: 2-2591                     [64, 64, 3, 3]            --
│    └─Empty: 2-2592                     [64]                      --
│    └─Empty: 2-2593                     [64]                      --
│    └─BatchNorm2d: 2-2594               [16, 64, 16, 16]          --
│    └─Scaler: 2-2595                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2596                      [16, 64, 16, 16]          --
│    └─Empty: 2-2597                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2598                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2599        --                        --
│    └─One: 2-2600                       [1]                       --
│    └─OutputScale: 2-2601               --                        --
│    └─Empty: 2-2602                     [64, 64, 3, 3]            --
│    └─Empty: 2-2603                     [64, 64, 3, 3]            --
│    └─Empty: 2-2604                     [64]                      --
│    └─Empty: 2-2605                     [64]                      --
│    └─BatchNorm2d: 2-2606               [16, 64, 16, 16]          --
│    └─Scaler: 2-2607                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2608                      [16, 64, 16, 16]          --
│    └─Empty: 2-2609                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2610                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2611                 [16, 64, 8, 8]            --
│    └─Empty: 2-2612                     [16, 64, 8, 8]            --
│    └─Empty: 2-2613                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2614        --                        --
│    └─One: 2-2615                       [1]                       --
│    └─OutputScale: 2-2616               --                        --
│    └─Empty: 2-2617                     [64, 64, 3, 3]            --
│    └─Empty: 2-2618                     [64, 64, 3, 3]            --
│    └─Empty: 2-2619                     [64]                      --
│    └─Empty: 2-2620                     [64]                      --
│    └─BatchNorm2d: 2-2621               [16, 64, 8, 8]            --
│    └─Scaler: 2-2622                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2623                      [16, 64, 8, 8]            --
│    └─Empty: 2-2624                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2625                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2626        --                        --
│    └─One: 2-2627                       [1]                       --
│    └─OutputScale: 2-2628               --                        --
│    └─Empty: 2-2629                     [64, 64, 1, 1]            --
│    └─Empty: 2-2630                     [64, 64, 1, 1]            --
│    └─Empty: 2-2631                     [64]                      --
│    └─Empty: 2-2632                     [64]                      --
│    └─BatchNorm2d: 2-2633               [16, 64, 8, 8]            --
│    └─Scaler: 2-2634                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2635                      [16, 64, 8, 8]            --
│    └─Empty: 2-2636                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2637                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2638                 [16, 64, 8, 8]            --
│    └─Empty: 2-2639                     [16, 64, 8, 8]            --
│    └─Empty: 2-2640                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2641        --                        --
│    └─One: 2-2642                       [1]                       --
│    └─OutputScale: 2-2643               --                        --
│    └─Empty: 2-2644                     [64, 64, 3, 3]            --
│    └─Empty: 2-2645                     [64, 64, 3, 3]            --
│    └─Empty: 2-2646                     [64]                      --
│    └─Empty: 2-2647                     [64]                      --
│    └─BatchNorm2d: 2-2648               [16, 64, 8, 8]            --
│    └─Scaler: 2-2649                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2650                      [16, 64, 8, 8]            --
│    └─Empty: 2-2651                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2652                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2653                 [16, 64, 4, 4]            --
│    └─Empty: 2-2654                     [16, 64, 4, 4]            --
│    └─Empty: 2-2655                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2656        --                        --
│    └─One: 2-2657                       [1]                       --
│    └─OutputScale: 2-2658               --                        --
│    └─Empty: 2-2659                     [64, 64, 3, 3]            --
│    └─Empty: 2-2660                     [64, 64, 3, 3]            --
│    └─Empty: 2-2661                     [64]                      --
│    └─Empty: 2-2662                     [64]                      --
│    └─BatchNorm2d: 2-2663               [16, 64, 4, 4]            --
│    └─Scaler: 2-2664                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2665                      [16, 64, 4, 4]            --
│    └─Empty: 2-2666                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2667                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2668        --                        --
│    └─One: 2-2669                       [1]                       --
│    └─OutputScale: 2-2670               --                        --
│    └─Empty: 2-2671                     [64, 64, 1, 1]            --
│    └─Empty: 2-2672                     [64, 64, 1, 1]            --
│    └─Empty: 2-2673                     [64]                      --
│    └─Empty: 2-2674                     [64]                      --
│    └─BatchNorm2d: 2-2675               [16, 64, 4, 4]            --
│    └─Scaler: 2-2676                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2677                      [16, 64, 4, 4]            --
│    └─Empty: 2-2678                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2679                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2680                 [16, 64, 4, 4]            --
│    └─Empty: 2-2681                     [16, 64, 4, 4]            --
│    └─Empty: 2-2682                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2683        --                        --
│    └─One: 2-2684                       [1]                       --
│    └─OutputScale: 2-2685               --                        --
│    └─Empty: 2-2686                     [64, 64, 3, 3]            --
│    └─Empty: 2-2687                     [64, 64, 3, 3]            --
│    └─Empty: 2-2688                     [64]                      --
│    └─Empty: 2-2689                     [64]                      --
│    └─BatchNorm2d: 2-2690               [16, 64, 4, 4]            --
│    └─Scaler: 2-2691                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2692                      [16, 64, 4, 4]            --
│    └─Empty: 2-2693                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2694                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2695                 [16, 64, 2, 2]            --
│    └─Empty: 2-2696                     [16, 64, 2, 2]            --
│    └─Empty: 2-2697                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2698        --                        --
│    └─One: 2-2699                       [1]                       --
│    └─OutputScale: 2-2700               --                        --
│    └─Empty: 2-2701                     [64, 64, 1, 1]            --
│    └─Empty: 2-2702                     [64, 64, 1, 1]            --
│    └─Empty: 2-2703                     [64]                      --
│    └─Empty: 2-2704                     [64]                      --
│    └─BatchNorm2d: 2-2705               [16, 64, 2, 2]            --
│    └─Scaler: 2-2706                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2707                      [16, 64, 2, 2]            --
│    └─Empty: 2-2708                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2709                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2710        --                        --
│    └─One: 2-2711                       [1]                       --
│    └─OutputScale: 2-2712               --                        --
│    └─Empty: 2-2713                     [64, 64, 1, 1]            --
│    └─Empty: 2-2714                     [64, 64, 1, 1]            --
│    └─Empty: 2-2715                     [64]                      --
│    └─Empty: 2-2716                     [64]                      --
│    └─BatchNorm2d: 2-2717               [16, 64, 2, 2]            --
│    └─Scaler: 2-2718                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2719                      [16, 64, 2, 2]            --
│    └─Empty: 2-2720                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2721                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2722                 [16, 64, 2, 2]            --
│    └─Empty: 2-2723                     [16, 64, 2, 2]            --
│    └─Empty: 2-2724                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2725        --                        --
│    └─One: 2-2726                       [1]                       --
│    └─OutputScale: 2-2727               --                        --
│    └─Empty: 2-2728                     [64, 64, 3, 3]            --
│    └─Empty: 2-2729                     [64, 64, 3, 3]            --
│    └─Empty: 2-2730                     [64]                      --
│    └─Empty: 2-2731                     [64]                      --
│    └─BatchNorm2d: 2-2732               [16, 64, 2, 2]            --
│    └─Scaler: 2-2733                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2734                      [16, 64, 2, 2]            --
│    └─Empty: 2-2735                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2736                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2737        --                        --
│    └─One: 2-2738                       [1]                       --
│    └─OutputScale: 2-2739               --                        --
│    └─Empty: 2-2740                     [64, 48, 1, 1]            --
│    └─Empty: 2-2741                     [64, 48, 1, 1]            --
│    └─Empty: 2-2742                     [64]                      --
│    └─Empty: 2-2743                     [64]                      --
│    └─BatchNorm2d: 2-2744               [16, 64, 64, 64]          --
│    └─Scaler: 2-2745                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2746                      [16, 64, 64, 64]          --
│    └─Empty: 2-2747                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2748                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2749        --                        --
│    └─One: 2-2750                       [1]                       --
│    └─OutputScale: 2-2751               --                        --
│    └─Empty: 2-2752                     [64, 64, 3, 3]            --
│    └─Empty: 2-2753                     [64, 64, 3, 3]            --
│    └─Empty: 2-2754                     [64]                      --
│    └─Empty: 2-2755                     [64]                      --
│    └─BatchNorm2d: 2-2756               [16, 64, 64, 64]          --
│    └─Scaler: 2-2757                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2758                      [16, 64, 64, 64]          --
│    └─Empty: 2-2759                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2760                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2761        --                        --
│    └─One: 2-2762                       [1]                       --
│    └─OutputScale: 2-2763               --                        --
│    └─Empty: 2-2764                     [64, 64, 1, 1]            --
│    └─Empty: 2-2765                     [64, 64, 1, 1]            --
│    └─Empty: 2-2766                     [64]                      --
│    └─Empty: 2-2767                     [64]                      --
│    └─BatchNorm2d: 2-2768               [16, 64, 64, 64]          --
│    └─Scaler: 2-2769                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2770                      [16, 64, 64, 64]          --
│    └─Empty: 2-2771                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2772                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2773        --                        --
│    └─One: 2-2774                       [1]                       --
│    └─OutputScale: 2-2775               --                        --
│    └─Empty: 2-2776                     [64, 64, 3, 3]            --
│    └─Empty: 2-2777                     [64, 64, 3, 3]            --
│    └─Empty: 2-2778                     [64]                      --
│    └─Empty: 2-2779                     [64]                      --
│    └─BatchNorm2d: 2-2780               [16, 64, 64, 64]          --
│    └─Scaler: 2-2781                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2782                      [16, 64, 64, 64]          --
│    └─Empty: 2-2783                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2784                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2785                 [16, 64, 32, 32]          --
│    └─Empty: 2-2786                     [16, 64, 32, 32]          --
│    └─Empty: 2-2787                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2788        --                        --
│    └─One: 2-2789                       [1]                       --
│    └─OutputScale: 2-2790               --                        --
│    └─Empty: 2-2791                     [64, 64, 3, 3]            --
│    └─Empty: 2-2792                     [64, 64, 3, 3]            --
│    └─Empty: 2-2793                     [64]                      --
│    └─Empty: 2-2794                     [64]                      --
│    └─BatchNorm2d: 2-2795               [16, 64, 32, 32]          --
│    └─Scaler: 2-2796                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2797                      [16, 64, 32, 32]          --
│    └─Empty: 2-2798                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2799                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2800        --                        --
│    └─One: 2-2801                       [1]                       --
│    └─OutputScale: 2-2802               --                        --
│    └─Empty: 2-2803                     [64, 64, 3, 3]            --
│    └─Empty: 2-2804                     [64, 64, 3, 3]            --
│    └─Empty: 2-2805                     [64]                      --
│    └─Empty: 2-2806                     [64]                      --
│    └─BatchNorm2d: 2-2807               [16, 64, 32, 32]          --
│    └─Scaler: 2-2808                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2809                      [16, 64, 32, 32]          --
│    └─Empty: 2-2810                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2811                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2812                 [16, 64, 16, 16]          --
│    └─Empty: 2-2813                     [16, 64, 16, 16]          --
│    └─Empty: 2-2814                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2815        --                        --
│    └─One: 2-2816                       [1]                       --
│    └─OutputScale: 2-2817               --                        --
│    └─Empty: 2-2818                     [64, 64, 3, 3]            --
│    └─Empty: 2-2819                     [64, 64, 3, 3]            --
│    └─Empty: 2-2820                     [64]                      --
│    └─Empty: 2-2821                     [64]                      --
│    └─BatchNorm2d: 2-2822               [16, 64, 16, 16]          --
│    └─Scaler: 2-2823                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2824                      [16, 64, 16, 16]          --
│    └─Empty: 2-2825                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2826                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2827        --                        --
│    └─One: 2-2828                       [1]                       --
│    └─OutputScale: 2-2829               --                        --
│    └─Empty: 2-2830                     [64, 64, 3, 3]            --
│    └─Empty: 2-2831                     [64, 64, 3, 3]            --
│    └─Empty: 2-2832                     [64]                      --
│    └─Empty: 2-2833                     [64]                      --
│    └─BatchNorm2d: 2-2834               [16, 64, 16, 16]          --
│    └─Scaler: 2-2835                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2836                      [16, 64, 16, 16]          --
│    └─Empty: 2-2837                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2838                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2839                 [16, 64, 8, 8]            --
│    └─Empty: 2-2840                     [16, 64, 8, 8]            --
│    └─Empty: 2-2841                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2842        --                        --
│    └─One: 2-2843                       [1]                       --
│    └─OutputScale: 2-2844               --                        --
│    └─Empty: 2-2845                     [64, 64, 3, 3]            --
│    └─Empty: 2-2846                     [64, 64, 3, 3]            --
│    └─Empty: 2-2847                     [64]                      --
│    └─Empty: 2-2848                     [64]                      --
│    └─BatchNorm2d: 2-2849               [16, 64, 8, 8]            --
│    └─Scaler: 2-2850                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2851                      [16, 64, 8, 8]            --
│    └─Empty: 2-2852                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2853                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2854        --                        --
│    └─One: 2-2855                       [1]                       --
│    └─OutputScale: 2-2856               --                        --
│    └─Empty: 2-2857                     [64, 64, 1, 1]            --
│    └─Empty: 2-2858                     [64, 64, 1, 1]            --
│    └─Empty: 2-2859                     [64]                      --
│    └─Empty: 2-2860                     [64]                      --
│    └─BatchNorm2d: 2-2861               [16, 64, 8, 8]            --
│    └─Scaler: 2-2862                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2863                      [16, 64, 8, 8]            --
│    └─Empty: 2-2864                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2865                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2866                 [16, 64, 8, 8]            --
│    └─Empty: 2-2867                     [16, 64, 8, 8]            --
│    └─Empty: 2-2868                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2869        --                        --
│    └─One: 2-2870                       [1]                       --
│    └─OutputScale: 2-2871               --                        --
│    └─Empty: 2-2872                     [64, 64, 3, 3]            --
│    └─Empty: 2-2873                     [64, 64, 3, 3]            --
│    └─Empty: 2-2874                     [64]                      --
│    └─Empty: 2-2875                     [64]                      --
│    └─BatchNorm2d: 2-2876               [16, 64, 8, 8]            --
│    └─Scaler: 2-2877                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2878                      [16, 64, 8, 8]            --
│    └─Empty: 2-2879                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2880                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2881                 [16, 64, 4, 4]            --
│    └─Empty: 2-2882                     [16, 64, 4, 4]            --
│    └─Empty: 2-2883                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2884        --                        --
│    └─One: 2-2885                       [1]                       --
│    └─OutputScale: 2-2886               --                        --
│    └─Empty: 2-2887                     [64, 64, 3, 3]            --
│    └─Empty: 2-2888                     [64, 64, 3, 3]            --
│    └─Empty: 2-2889                     [64]                      --
│    └─Empty: 2-2890                     [64]                      --
│    └─BatchNorm2d: 2-2891               [16, 64, 4, 4]            --
│    └─Scaler: 2-2892                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2893                      [16, 64, 4, 4]            --
│    └─Empty: 2-2894                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2895                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2896        --                        --
│    └─One: 2-2897                       [1]                       --
│    └─OutputScale: 2-2898               --                        --
│    └─Empty: 2-2899                     [64, 64, 1, 1]            --
│    └─Empty: 2-2900                     [64, 64, 1, 1]            --
│    └─Empty: 2-2901                     [64]                      --
│    └─Empty: 2-2902                     [64]                      --
│    └─BatchNorm2d: 2-2903               [16, 64, 4, 4]            --
│    └─Scaler: 2-2904                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2905                      [16, 64, 4, 4]            --
│    └─Empty: 2-2906                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2907                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2908                 [16, 64, 4, 4]            --
│    └─Empty: 2-2909                     [16, 64, 4, 4]            --
│    └─Empty: 2-2910                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2911        --                        --
│    └─One: 2-2912                       [1]                       --
│    └─OutputScale: 2-2913               --                        --
│    └─Empty: 2-2914                     [64, 64, 3, 3]            --
│    └─Empty: 2-2915                     [64, 64, 3, 3]            --
│    └─Empty: 2-2916                     [64]                      --
│    └─Empty: 2-2917                     [64]                      --
│    └─BatchNorm2d: 2-2918               [16, 64, 4, 4]            --
│    └─Scaler: 2-2919                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2920                      [16, 64, 4, 4]            --
│    └─Empty: 2-2921                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2922                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2923                 [16, 64, 2, 2]            --
│    └─Empty: 2-2924                     [16, 64, 2, 2]            --
│    └─Empty: 2-2925                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2926        --                        --
│    └─One: 2-2927                       [1]                       --
│    └─OutputScale: 2-2928               --                        --
│    └─Empty: 2-2929                     [64, 64, 1, 1]            --
│    └─Empty: 2-2930                     [64, 64, 1, 1]            --
│    └─Empty: 2-2931                     [64]                      --
│    └─Empty: 2-2932                     [64]                      --
│    └─BatchNorm2d: 2-2933               [16, 64, 2, 2]            --
│    └─Scaler: 2-2934                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2935                      [16, 64, 2, 2]            --
│    └─Empty: 2-2936                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2937                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2938        --                        --
│    └─One: 2-2939                       [1]                       --
│    └─OutputScale: 2-2940               --                        --
│    └─Empty: 2-2941                     [64, 64, 1, 1]            --
│    └─Empty: 2-2942                     [64, 64, 1, 1]            --
│    └─Empty: 2-2943                     [64]                      --
│    └─Empty: 2-2944                     [64]                      --
│    └─BatchNorm2d: 2-2945               [16, 64, 2, 2]            --
│    └─Scaler: 2-2946                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2947                      [16, 64, 2, 2]            --
│    └─Empty: 2-2948                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2949                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2950                 [16, 64, 2, 2]            --
│    └─Empty: 2-2951                     [16, 64, 2, 2]            --
│    └─Empty: 2-2952                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2953        --                        --
│    └─One: 2-2954                       [1]                       --
│    └─OutputScale: 2-2955               --                        --
│    └─Empty: 2-2956                     [64, 64, 3, 3]            --
│    └─Empty: 2-2957                     [64, 64, 3, 3]            --
│    └─Empty: 2-2958                     [64]                      --
│    └─Empty: 2-2959                     [64]                      --
│    └─BatchNorm2d: 2-2960               [16, 64, 2, 2]            --
│    └─Scaler: 2-2961                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2962                      [16, 64, 2, 2]            --
│    └─Empty: 2-2963                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2964                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2965        --                        --
│    └─One: 2-2966                       [1]                       --
│    └─OutputScale: 2-2967               --                        --
│    └─Empty: 2-2968                     [64, 48, 1, 1]            --
│    └─Empty: 2-2969                     [64, 48, 1, 1]            --
│    └─Empty: 2-2970                     [64]                      --
│    └─Empty: 2-2971                     [64]                      --
│    └─BatchNorm2d: 2-2972               [16, 64, 64, 64]          --
│    └─Scaler: 2-2973                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2974                      [16, 64, 64, 64]          --
│    └─Empty: 2-2975                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2976                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2977        --                        --
│    └─One: 2-2978                       [1]                       --
│    └─OutputScale: 2-2979               --                        --
│    └─Empty: 2-2980                     [64, 64, 3, 3]            --
│    └─Empty: 2-2981                     [64, 64, 3, 3]            --
│    └─Empty: 2-2982                     [64]                      --
│    └─Empty: 2-2983                     [64]                      --
│    └─BatchNorm2d: 2-2984               [16, 64, 64, 64]          --
│    └─Scaler: 2-2985                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2986                      [16, 64, 64, 64]          --
│    └─Empty: 2-2987                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2988                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2989        --                        --
│    └─One: 2-2990                       [1]                       --
│    └─OutputScale: 2-2991               --                        --
│    └─Empty: 2-2992                     [64, 64, 1, 1]            --
│    └─Empty: 2-2993                     [64, 64, 1, 1]            --
│    └─Empty: 2-2994                     [64]                      --
│    └─Empty: 2-2995                     [64]                      --
│    └─BatchNorm2d: 2-2996               [16, 64, 64, 64]          --
│    └─Scaler: 2-2997                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2998                      [16, 64, 64, 64]          --
│    └─Empty: 2-2999                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3000                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3001        --                        --
│    └─One: 2-3002                       [1]                       --
│    └─OutputScale: 2-3003               --                        --
│    └─Empty: 2-3004                     [64, 64, 3, 3]            --
│    └─Empty: 2-3005                     [64, 64, 3, 3]            --
│    └─Empty: 2-3006                     [64]                      --
│    └─Empty: 2-3007                     [64]                      --
│    └─BatchNorm2d: 2-3008               [16, 64, 64, 64]          --
│    └─Scaler: 2-3009                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3010                      [16, 64, 64, 64]          --
│    └─Empty: 2-3011                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3012                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3013                 [16, 64, 32, 32]          --
│    └─Empty: 2-3014                     [16, 64, 32, 32]          --
│    └─Empty: 2-3015                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3016        --                        --
│    └─One: 2-3017                       [1]                       --
│    └─OutputScale: 2-3018               --                        --
│    └─Empty: 2-3019                     [64, 64, 3, 3]            --
│    └─Empty: 2-3020                     [64, 64, 3, 3]            --
│    └─Empty: 2-3021                     [64]                      --
│    └─Empty: 2-3022                     [64]                      --
│    └─BatchNorm2d: 2-3023               [16, 64, 32, 32]          --
│    └─Scaler: 2-3024                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3025                      [16, 64, 32, 32]          --
│    └─Empty: 2-3026                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3027                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3028        --                        --
│    └─One: 2-3029                       [1]                       --
│    └─OutputScale: 2-3030               --                        --
│    └─Empty: 2-3031                     [64, 64, 3, 3]            --
│    └─Empty: 2-3032                     [64, 64, 3, 3]            --
│    └─Empty: 2-3033                     [64]                      --
│    └─Empty: 2-3034                     [64]                      --
│    └─BatchNorm2d: 2-3035               [16, 64, 32, 32]          --
│    └─Scaler: 2-3036                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3037                      [16, 64, 32, 32]          --
│    └─Empty: 2-3038                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3039                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3040                 [16, 64, 16, 16]          --
│    └─Empty: 2-3041                     [16, 64, 16, 16]          --
│    └─Empty: 2-3042                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3043        --                        --
│    └─One: 2-3044                       [1]                       --
│    └─OutputScale: 2-3045               --                        --
│    └─Empty: 2-3046                     [64, 64, 3, 3]            --
│    └─Empty: 2-3047                     [64, 64, 3, 3]            --
│    └─Empty: 2-3048                     [64]                      --
│    └─Empty: 2-3049                     [64]                      --
│    └─BatchNorm2d: 2-3050               [16, 64, 16, 16]          --
│    └─Scaler: 2-3051                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3052                      [16, 64, 16, 16]          --
│    └─Empty: 2-3053                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3054                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3055        --                        --
│    └─One: 2-3056                       [1]                       --
│    └─OutputScale: 2-3057               --                        --
│    └─Empty: 2-3058                     [64, 64, 3, 3]            --
│    └─Empty: 2-3059                     [64, 64, 3, 3]            --
│    └─Empty: 2-3060                     [64]                      --
│    └─Empty: 2-3061                     [64]                      --
│    └─BatchNorm2d: 2-3062               [16, 64, 16, 16]          --
│    └─Scaler: 2-3063                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3064                      [16, 64, 16, 16]          --
│    └─Empty: 2-3065                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3066                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3067                 [16, 64, 8, 8]            --
│    └─Empty: 2-3068                     [16, 64, 8, 8]            --
│    └─Empty: 2-3069                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3070        --                        --
│    └─One: 2-3071                       [1]                       --
│    └─OutputScale: 2-3072               --                        --
│    └─Empty: 2-3073                     [64, 64, 3, 3]            --
│    └─Empty: 2-3074                     [64, 64, 3, 3]            --
│    └─Empty: 2-3075                     [64]                      --
│    └─Empty: 2-3076                     [64]                      --
│    └─BatchNorm2d: 2-3077               [16, 64, 8, 8]            --
│    └─Scaler: 2-3078                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3079                      [16, 64, 8, 8]            --
│    └─Empty: 2-3080                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3081                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3082        --                        --
│    └─One: 2-3083                       [1]                       --
│    └─OutputScale: 2-3084               --                        --
│    └─Empty: 2-3085                     [64, 64, 1, 1]            --
│    └─Empty: 2-3086                     [64, 64, 1, 1]            --
│    └─Empty: 2-3087                     [64]                      --
│    └─Empty: 2-3088                     [64]                      --
│    └─BatchNorm2d: 2-3089               [16, 64, 8, 8]            --
│    └─Scaler: 2-3090                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3091                      [16, 64, 8, 8]            --
│    └─Empty: 2-3092                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3093                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3094                 [16, 64, 8, 8]            --
│    └─Empty: 2-3095                     [16, 64, 8, 8]            --
│    └─Empty: 2-3096                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3097        --                        --
│    └─One: 2-3098                       [1]                       --
│    └─OutputScale: 2-3099               --                        --
│    └─Empty: 2-3100                     [64, 64, 3, 3]            --
│    └─Empty: 2-3101                     [64, 64, 3, 3]            --
│    └─Empty: 2-3102                     [64]                      --
│    └─Empty: 2-3103                     [64]                      --
│    └─BatchNorm2d: 2-3104               [16, 64, 8, 8]            --
│    └─Scaler: 2-3105                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3106                      [16, 64, 8, 8]            --
│    └─Empty: 2-3107                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3108                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3109                 [16, 64, 4, 4]            --
│    └─Empty: 2-3110                     [16, 64, 4, 4]            --
│    └─Empty: 2-3111                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3112        --                        --
│    └─One: 2-3113                       [1]                       --
│    └─OutputScale: 2-3114               --                        --
│    └─Empty: 2-3115                     [64, 64, 3, 3]            --
│    └─Empty: 2-3116                     [64, 64, 3, 3]            --
│    └─Empty: 2-3117                     [64]                      --
│    └─Empty: 2-3118                     [64]                      --
│    └─BatchNorm2d: 2-3119               [16, 64, 4, 4]            --
│    └─Scaler: 2-3120                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3121                      [16, 64, 4, 4]            --
│    └─Empty: 2-3122                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3123                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3124        --                        --
│    └─One: 2-3125                       [1]                       --
│    └─OutputScale: 2-3126               --                        --
│    └─Empty: 2-3127                     [64, 64, 1, 1]            --
│    └─Empty: 2-3128                     [64, 64, 1, 1]            --
│    └─Empty: 2-3129                     [64]                      --
│    └─Empty: 2-3130                     [64]                      --
│    └─BatchNorm2d: 2-3131               [16, 64, 4, 4]            --
│    └─Scaler: 2-3132                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3133                      [16, 64, 4, 4]            --
│    └─Empty: 2-3134                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3135                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3136                 [16, 64, 4, 4]            --
│    └─Empty: 2-3137                     [16, 64, 4, 4]            --
│    └─Empty: 2-3138                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3139        --                        --
│    └─One: 2-3140                       [1]                       --
│    └─OutputScale: 2-3141               --                        --
│    └─Empty: 2-3142                     [64, 64, 3, 3]            --
│    └─Empty: 2-3143                     [64, 64, 3, 3]            --
│    └─Empty: 2-3144                     [64]                      --
│    └─Empty: 2-3145                     [64]                      --
│    └─BatchNorm2d: 2-3146               [16, 64, 4, 4]            --
│    └─Scaler: 2-3147                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3148                      [16, 64, 4, 4]            --
│    └─Empty: 2-3149                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3150                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3151                 [16, 64, 2, 2]            --
│    └─Empty: 2-3152                     [16, 64, 2, 2]            --
│    └─Empty: 2-3153                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3154        --                        --
│    └─One: 2-3155                       [1]                       --
│    └─OutputScale: 2-3156               --                        --
│    └─Empty: 2-3157                     [64, 64, 1, 1]            --
│    └─Empty: 2-3158                     [64, 64, 1, 1]            --
│    └─Empty: 2-3159                     [64]                      --
│    └─Empty: 2-3160                     [64]                      --
│    └─BatchNorm2d: 2-3161               [16, 64, 2, 2]            --
│    └─Scaler: 2-3162                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3163                      [16, 64, 2, 2]            --
│    └─Empty: 2-3164                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3165                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3166        --                        --
│    └─One: 2-3167                       [1]                       --
│    └─OutputScale: 2-3168               --                        --
│    └─Empty: 2-3169                     [64, 64, 1, 1]            --
│    └─Empty: 2-3170                     [64, 64, 1, 1]            --
│    └─Empty: 2-3171                     [64]                      --
│    └─Empty: 2-3172                     [64]                      --
│    └─BatchNorm2d: 2-3173               [16, 64, 2, 2]            --
│    └─Scaler: 2-3174                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3175                      [16, 64, 2, 2]            --
│    └─Empty: 2-3176                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3177                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3178                 [16, 64, 2, 2]            --
│    └─Empty: 2-3179                     [16, 64, 2, 2]            --
│    └─Empty: 2-3180                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3181        --                        --
│    └─One: 2-3182                       [1]                       --
│    └─OutputScale: 2-3183               --                        --
│    └─Empty: 2-3184                     [64, 64, 3, 3]            --
│    └─Empty: 2-3185                     [64, 64, 3, 3]            --
│    └─Empty: 2-3186                     [64]                      --
│    └─Empty: 2-3187                     [64]                      --
│    └─BatchNorm2d: 2-3188               [16, 64, 2, 2]            --
│    └─Scaler: 2-3189                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3190                      [16, 64, 2, 2]            --
│    └─Empty: 2-3191                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3192                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3193        --                        --
│    └─One: 2-3194                       [1]                       --
│    └─OutputScale: 2-3195               --                        --
│    └─Empty: 2-3196                     [64, 48, 1, 1]            --
│    └─Empty: 2-3197                     [64, 48, 1, 1]            --
│    └─Empty: 2-3198                     [64]                      --
│    └─Empty: 2-3199                     [64]                      --
│    └─BatchNorm2d: 2-3200               [16, 64, 64, 64]          --
│    └─Scaler: 2-3201                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3202                      [16, 64, 64, 64]          --
│    └─Empty: 2-3203                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3204                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3205        --                        --
│    └─One: 2-3206                       [1]                       --
│    └─OutputScale: 2-3207               --                        --
│    └─Empty: 2-3208                     [64, 64, 3, 3]            --
│    └─Empty: 2-3209                     [64, 64, 3, 3]            --
│    └─Empty: 2-3210                     [64]                      --
│    └─Empty: 2-3211                     [64]                      --
│    └─BatchNorm2d: 2-3212               [16, 64, 64, 64]          --
│    └─Scaler: 2-3213                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3214                      [16, 64, 64, 64]          --
│    └─Empty: 2-3215                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3216                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3217        --                        --
│    └─One: 2-3218                       [1]                       --
│    └─OutputScale: 2-3219               --                        --
│    └─Empty: 2-3220                     [64, 64, 1, 1]            --
│    └─Empty: 2-3221                     [64, 64, 1, 1]            --
│    └─Empty: 2-3222                     [64]                      --
│    └─Empty: 2-3223                     [64]                      --
│    └─BatchNorm2d: 2-3224               [16, 64, 64, 64]          --
│    └─Scaler: 2-3225                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3226                      [16, 64, 64, 64]          --
│    └─Empty: 2-3227                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3228                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3229        --                        --
│    └─One: 2-3230                       [1]                       --
│    └─OutputScale: 2-3231               --                        --
│    └─Empty: 2-3232                     [64, 64, 3, 3]            --
│    └─Empty: 2-3233                     [64, 64, 3, 3]            --
│    └─Empty: 2-3234                     [64]                      --
│    └─Empty: 2-3235                     [64]                      --
│    └─BatchNorm2d: 2-3236               [16, 64, 64, 64]          --
│    └─Scaler: 2-3237                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3238                      [16, 64, 64, 64]          --
│    └─Empty: 2-3239                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3240                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3241                 [16, 64, 32, 32]          --
│    └─Empty: 2-3242                     [16, 64, 32, 32]          --
│    └─Empty: 2-3243                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3244        --                        --
│    └─One: 2-3245                       [1]                       --
│    └─OutputScale: 2-3246               --                        --
│    └─Empty: 2-3247                     [64, 64, 3, 3]            --
│    └─Empty: 2-3248                     [64, 64, 3, 3]            --
│    └─Empty: 2-3249                     [64]                      --
│    └─Empty: 2-3250                     [64]                      --
│    └─BatchNorm2d: 2-3251               [16, 64, 32, 32]          --
│    └─Scaler: 2-3252                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3253                      [16, 64, 32, 32]          --
│    └─Empty: 2-3254                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3255                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3256        --                        --
│    └─One: 2-3257                       [1]                       --
│    └─OutputScale: 2-3258               --                        --
│    └─Empty: 2-3259                     [64, 64, 3, 3]            --
│    └─Empty: 2-3260                     [64, 64, 3, 3]            --
│    └─Empty: 2-3261                     [64]                      --
│    └─Empty: 2-3262                     [64]                      --
│    └─BatchNorm2d: 2-3263               [16, 64, 32, 32]          --
│    └─Scaler: 2-3264                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3265                      [16, 64, 32, 32]          --
│    └─Empty: 2-3266                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3267                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3268                 [16, 64, 16, 16]          --
│    └─Empty: 2-3269                     [16, 64, 16, 16]          --
│    └─Empty: 2-3270                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3271        --                        --
│    └─One: 2-3272                       [1]                       --
│    └─OutputScale: 2-3273               --                        --
│    └─Empty: 2-3274                     [64, 64, 3, 3]            --
│    └─Empty: 2-3275                     [64, 64, 3, 3]            --
│    └─Empty: 2-3276                     [64]                      --
│    └─Empty: 2-3277                     [64]                      --
│    └─BatchNorm2d: 2-3278               [16, 64, 16, 16]          --
│    └─Scaler: 2-3279                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3280                      [16, 64, 16, 16]          --
│    └─Empty: 2-3281                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3282                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3283        --                        --
│    └─One: 2-3284                       [1]                       --
│    └─OutputScale: 2-3285               --                        --
│    └─Empty: 2-3286                     [64, 64, 3, 3]            --
│    └─Empty: 2-3287                     [64, 64, 3, 3]            --
│    └─Empty: 2-3288                     [64]                      --
│    └─Empty: 2-3289                     [64]                      --
│    └─BatchNorm2d: 2-3290               [16, 64, 16, 16]          --
│    └─Scaler: 2-3291                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3292                      [16, 64, 16, 16]          --
│    └─Empty: 2-3293                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3294                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3295                 [16, 64, 8, 8]            --
│    └─Empty: 2-3296                     [16, 64, 8, 8]            --
│    └─Empty: 2-3297                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3298        --                        --
│    └─One: 2-3299                       [1]                       --
│    └─OutputScale: 2-3300               --                        --
│    └─Empty: 2-3301                     [64, 64, 3, 3]            --
│    └─Empty: 2-3302                     [64, 64, 3, 3]            --
│    └─Empty: 2-3303                     [64]                      --
│    └─Empty: 2-3304                     [64]                      --
│    └─BatchNorm2d: 2-3305               [16, 64, 8, 8]            --
│    └─Scaler: 2-3306                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3307                      [16, 64, 8, 8]            --
│    └─Empty: 2-3308                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3309                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3310        --                        --
│    └─One: 2-3311                       [1]                       --
│    └─OutputScale: 2-3312               --                        --
│    └─Empty: 2-3313                     [64, 64, 1, 1]            --
│    └─Empty: 2-3314                     [64, 64, 1, 1]            --
│    └─Empty: 2-3315                     [64]                      --
│    └─Empty: 2-3316                     [64]                      --
│    └─BatchNorm2d: 2-3317               [16, 64, 8, 8]            --
│    └─Scaler: 2-3318                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3319                      [16, 64, 8, 8]            --
│    └─Empty: 2-3320                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3321                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3322                 [16, 64, 8, 8]            --
│    └─Empty: 2-3323                     [16, 64, 8, 8]            --
│    └─Empty: 2-3324                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3325        --                        --
│    └─One: 2-3326                       [1]                       --
│    └─OutputScale: 2-3327               --                        --
│    └─Empty: 2-3328                     [64, 64, 3, 3]            --
│    └─Empty: 2-3329                     [64, 64, 3, 3]            --
│    └─Empty: 2-3330                     [64]                      --
│    └─Empty: 2-3331                     [64]                      --
│    └─BatchNorm2d: 2-3332               [16, 64, 8, 8]            --
│    └─Scaler: 2-3333                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3334                      [16, 64, 8, 8]            --
│    └─Empty: 2-3335                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3336                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3337                 [16, 64, 4, 4]            --
│    └─Empty: 2-3338                     [16, 64, 4, 4]            --
│    └─Empty: 2-3339                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3340        --                        --
│    └─One: 2-3341                       [1]                       --
│    └─OutputScale: 2-3342               --                        --
│    └─Empty: 2-3343                     [64, 64, 3, 3]            --
│    └─Empty: 2-3344                     [64, 64, 3, 3]            --
│    └─Empty: 2-3345                     [64]                      --
│    └─Empty: 2-3346                     [64]                      --
│    └─BatchNorm2d: 2-3347               [16, 64, 4, 4]            --
│    └─Scaler: 2-3348                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3349                      [16, 64, 4, 4]            --
│    └─Empty: 2-3350                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3351                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3352        --                        --
│    └─One: 2-3353                       [1]                       --
│    └─OutputScale: 2-3354               --                        --
│    └─Empty: 2-3355                     [64, 64, 1, 1]            --
│    └─Empty: 2-3356                     [64, 64, 1, 1]            --
│    └─Empty: 2-3357                     [64]                      --
│    └─Empty: 2-3358                     [64]                      --
│    └─BatchNorm2d: 2-3359               [16, 64, 4, 4]            --
│    └─Scaler: 2-3360                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3361                      [16, 64, 4, 4]            --
│    └─Empty: 2-3362                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3363                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3364                 [16, 64, 4, 4]            --
│    └─Empty: 2-3365                     [16, 64, 4, 4]            --
│    └─Empty: 2-3366                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3367        --                        --
│    └─One: 2-3368                       [1]                       --
│    └─OutputScale: 2-3369               --                        --
│    └─Empty: 2-3370                     [64, 64, 3, 3]            --
│    └─Empty: 2-3371                     [64, 64, 3, 3]            --
│    └─Empty: 2-3372                     [64]                      --
│    └─Empty: 2-3373                     [64]                      --
│    └─BatchNorm2d: 2-3374               [16, 64, 4, 4]            --
│    └─Scaler: 2-3375                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3376                      [16, 64, 4, 4]            --
│    └─Empty: 2-3377                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3378                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3379                 [16, 64, 2, 2]            --
│    └─Empty: 2-3380                     [16, 64, 2, 2]            --
│    └─Empty: 2-3381                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3382        --                        --
│    └─One: 2-3383                       [1]                       --
│    └─OutputScale: 2-3384               --                        --
│    └─Empty: 2-3385                     [64, 64, 1, 1]            --
│    └─Empty: 2-3386                     [64, 64, 1, 1]            --
│    └─Empty: 2-3387                     [64]                      --
│    └─Empty: 2-3388                     [64]                      --
│    └─BatchNorm2d: 2-3389               [16, 64, 2, 2]            --
│    └─Scaler: 2-3390                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3391                      [16, 64, 2, 2]            --
│    └─Empty: 2-3392                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3393                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3394        --                        --
│    └─One: 2-3395                       [1]                       --
│    └─OutputScale: 2-3396               --                        --
│    └─Empty: 2-3397                     [64, 64, 1, 1]            --
│    └─Empty: 2-3398                     [64, 64, 1, 1]            --
│    └─Empty: 2-3399                     [64]                      --
│    └─Empty: 2-3400                     [64]                      --
│    └─BatchNorm2d: 2-3401               [16, 64, 2, 2]            --
│    └─Scaler: 2-3402                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3403                      [16, 64, 2, 2]            --
│    └─Empty: 2-3404                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3405                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3406                 [16, 64, 2, 2]            --
│    └─Empty: 2-3407                     [16, 64, 2, 2]            --
│    └─Empty: 2-3408                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3409        --                        --
│    └─One: 2-3410                       [1]                       --
│    └─OutputScale: 2-3411               --                        --
│    └─Empty: 2-3412                     [64, 64, 3, 3]            --
│    └─Empty: 2-3413                     [64, 64, 3, 3]            --
│    └─Empty: 2-3414                     [64]                      --
│    └─Empty: 2-3415                     [64]                      --
│    └─BatchNorm2d: 2-3416               [16, 64, 2, 2]            --
│    └─Scaler: 2-3417                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3418                      [16, 64, 2, 2]            --
│    └─Empty: 2-3419                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3420                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3421        --                        --
│    └─One: 2-3422                       [1]                       --
│    └─OutputScale: 2-3423               --                        --
│    └─Empty: 2-3424                     [64, 48, 1, 1]            --
│    └─Empty: 2-3425                     [64, 48, 1, 1]            --
│    └─Empty: 2-3426                     [64]                      --
│    └─Empty: 2-3427                     [64]                      --
│    └─BatchNorm2d: 2-3428               [16, 64, 64, 64]          --
│    └─Scaler: 2-3429                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3430                      [16, 64, 64, 64]          --
│    └─Empty: 2-3431                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3432                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3433        --                        --
│    └─One: 2-3434                       [1]                       --
│    └─OutputScale: 2-3435               --                        --
│    └─Empty: 2-3436                     [64, 64, 3, 3]            --
│    └─Empty: 2-3437                     [64, 64, 3, 3]            --
│    └─Empty: 2-3438                     [64]                      --
│    └─Empty: 2-3439                     [64]                      --
│    └─BatchNorm2d: 2-3440               [16, 64, 64, 64]          --
│    └─Scaler: 2-3441                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3442                      [16, 64, 64, 64]          --
│    └─Empty: 2-3443                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3444                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3445        --                        --
│    └─One: 2-3446                       [1]                       --
│    └─OutputScale: 2-3447               --                        --
│    └─Empty: 2-3448                     [64, 64, 1, 1]            --
│    └─Empty: 2-3449                     [64, 64, 1, 1]            --
│    └─Empty: 2-3450                     [64]                      --
│    └─Empty: 2-3451                     [64]                      --
│    └─BatchNorm2d: 2-3452               [16, 64, 64, 64]          --
│    └─Scaler: 2-3453                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3454                      [16, 64, 64, 64]          --
│    └─Empty: 2-3455                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3456                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3457        --                        --
│    └─One: 2-3458                       [1]                       --
│    └─OutputScale: 2-3459               --                        --
│    └─Empty: 2-3460                     [64, 64, 3, 3]            --
│    └─Empty: 2-3461                     [64, 64, 3, 3]            --
│    └─Empty: 2-3462                     [64]                      --
│    └─Empty: 2-3463                     [64]                      --
│    └─BatchNorm2d: 2-3464               [16, 64, 64, 64]          --
│    └─Scaler: 2-3465                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3466                      [16, 64, 64, 64]          --
│    └─Empty: 2-3467                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3468                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3469                 [16, 64, 32, 32]          --
│    └─Empty: 2-3470                     [16, 64, 32, 32]          --
│    └─Empty: 2-3471                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3472        --                        --
│    └─One: 2-3473                       [1]                       --
│    └─OutputScale: 2-3474               --                        --
│    └─Empty: 2-3475                     [64, 64, 3, 3]            --
│    └─Empty: 2-3476                     [64, 64, 3, 3]            --
│    └─Empty: 2-3477                     [64]                      --
│    └─Empty: 2-3478                     [64]                      --
│    └─BatchNorm2d: 2-3479               [16, 64, 32, 32]          --
│    └─Scaler: 2-3480                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3481                      [16, 64, 32, 32]          --
│    └─Empty: 2-3482                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3483                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3484        --                        --
│    └─One: 2-3485                       [1]                       --
│    └─OutputScale: 2-3486               --                        --
│    └─Empty: 2-3487                     [64, 64, 3, 3]            --
│    └─Empty: 2-3488                     [64, 64, 3, 3]            --
│    └─Empty: 2-3489                     [64]                      --
│    └─Empty: 2-3490                     [64]                      --
│    └─BatchNorm2d: 2-3491               [16, 64, 32, 32]          --
│    └─Scaler: 2-3492                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3493                      [16, 64, 32, 32]          --
│    └─Empty: 2-3494                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3495                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3496                 [16, 64, 16, 16]          --
│    └─Empty: 2-3497                     [16, 64, 16, 16]          --
│    └─Empty: 2-3498                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3499        --                        --
│    └─One: 2-3500                       [1]                       --
│    └─OutputScale: 2-3501               --                        --
│    └─Empty: 2-3502                     [64, 64, 3, 3]            --
│    └─Empty: 2-3503                     [64, 64, 3, 3]            --
│    └─Empty: 2-3504                     [64]                      --
│    └─Empty: 2-3505                     [64]                      --
│    └─BatchNorm2d: 2-3506               [16, 64, 16, 16]          --
│    └─Scaler: 2-3507                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3508                      [16, 64, 16, 16]          --
│    └─Empty: 2-3509                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3510                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3511        --                        --
│    └─One: 2-3512                       [1]                       --
│    └─OutputScale: 2-3513               --                        --
│    └─Empty: 2-3514                     [64, 64, 3, 3]            --
│    └─Empty: 2-3515                     [64, 64, 3, 3]            --
│    └─Empty: 2-3516                     [64]                      --
│    └─Empty: 2-3517                     [64]                      --
│    └─BatchNorm2d: 2-3518               [16, 64, 16, 16]          --
│    └─Scaler: 2-3519                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3520                      [16, 64, 16, 16]          --
│    └─Empty: 2-3521                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3522                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3523                 [16, 64, 8, 8]            --
│    └─Empty: 2-3524                     [16, 64, 8, 8]            --
│    └─Empty: 2-3525                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3526        --                        --
│    └─One: 2-3527                       [1]                       --
│    └─OutputScale: 2-3528               --                        --
│    └─Empty: 2-3529                     [64, 64, 3, 3]            --
│    └─Empty: 2-3530                     [64, 64, 3, 3]            --
│    └─Empty: 2-3531                     [64]                      --
│    └─Empty: 2-3532                     [64]                      --
│    └─BatchNorm2d: 2-3533               [16, 64, 8, 8]            --
│    └─Scaler: 2-3534                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3535                      [16, 64, 8, 8]            --
│    └─Empty: 2-3536                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3537                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3538        --                        --
│    └─One: 2-3539                       [1]                       --
│    └─OutputScale: 2-3540               --                        --
│    └─Empty: 2-3541                     [64, 64, 1, 1]            --
│    └─Empty: 2-3542                     [64, 64, 1, 1]            --
│    └─Empty: 2-3543                     [64]                      --
│    └─Empty: 2-3544                     [64]                      --
│    └─BatchNorm2d: 2-3545               [16, 64, 8, 8]            --
│    └─Scaler: 2-3546                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3547                      [16, 64, 8, 8]            --
│    └─Empty: 2-3548                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3549                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3550                 [16, 64, 8, 8]            --
│    └─Empty: 2-3551                     [16, 64, 8, 8]            --
│    └─Empty: 2-3552                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3553        --                        --
│    └─One: 2-3554                       [1]                       --
│    └─OutputScale: 2-3555               --                        --
│    └─Empty: 2-3556                     [64, 64, 3, 3]            --
│    └─Empty: 2-3557                     [64, 64, 3, 3]            --
│    └─Empty: 2-3558                     [64]                      --
│    └─Empty: 2-3559                     [64]                      --
│    └─BatchNorm2d: 2-3560               [16, 64, 8, 8]            --
│    └─Scaler: 2-3561                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3562                      [16, 64, 8, 8]            --
│    └─Empty: 2-3563                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3564                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3565                 [16, 64, 4, 4]            --
│    └─Empty: 2-3566                     [16, 64, 4, 4]            --
│    └─Empty: 2-3567                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3568        --                        --
│    └─One: 2-3569                       [1]                       --
│    └─OutputScale: 2-3570               --                        --
│    └─Empty: 2-3571                     [64, 64, 3, 3]            --
│    └─Empty: 2-3572                     [64, 64, 3, 3]            --
│    └─Empty: 2-3573                     [64]                      --
│    └─Empty: 2-3574                     [64]                      --
│    └─BatchNorm2d: 2-3575               [16, 64, 4, 4]            --
│    └─Scaler: 2-3576                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3577                      [16, 64, 4, 4]            --
│    └─Empty: 2-3578                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3579                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3580        --                        --
│    └─One: 2-3581                       [1]                       --
│    └─OutputScale: 2-3582               --                        --
│    └─Empty: 2-3583                     [64, 64, 1, 1]            --
│    └─Empty: 2-3584                     [64, 64, 1, 1]            --
│    └─Empty: 2-3585                     [64]                      --
│    └─Empty: 2-3586                     [64]                      --
│    └─BatchNorm2d: 2-3587               [16, 64, 4, 4]            --
│    └─Scaler: 2-3588                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3589                      [16, 64, 4, 4]            --
│    └─Empty: 2-3590                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3591                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3592                 [16, 64, 4, 4]            --
│    └─Empty: 2-3593                     [16, 64, 4, 4]            --
│    └─Empty: 2-3594                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3595        --                        --
│    └─One: 2-3596                       [1]                       --
│    └─OutputScale: 2-3597               --                        --
│    └─Empty: 2-3598                     [64, 64, 3, 3]            --
│    └─Empty: 2-3599                     [64, 64, 3, 3]            --
│    └─Empty: 2-3600                     [64]                      --
│    └─Empty: 2-3601                     [64]                      --
│    └─BatchNorm2d: 2-3602               [16, 64, 4, 4]            --
│    └─Scaler: 2-3603                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3604                      [16, 64, 4, 4]            --
│    └─Empty: 2-3605                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3606                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3607                 [16, 64, 2, 2]            --
│    └─Empty: 2-3608                     [16, 64, 2, 2]            --
│    └─Empty: 2-3609                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3610        --                        --
│    └─One: 2-3611                       [1]                       --
│    └─OutputScale: 2-3612               --                        --
│    └─Empty: 2-3613                     [64, 64, 1, 1]            --
│    └─Empty: 2-3614                     [64, 64, 1, 1]            --
│    └─Empty: 2-3615                     [64]                      --
│    └─Empty: 2-3616                     [64]                      --
│    └─BatchNorm2d: 2-3617               [16, 64, 2, 2]            --
│    └─Scaler: 2-3618                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3619                      [16, 64, 2, 2]            --
│    └─Empty: 2-3620                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3621                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3622        --                        --
│    └─One: 2-3623                       [1]                       --
│    └─OutputScale: 2-3624               --                        --
│    └─Empty: 2-3625                     [64, 64, 1, 1]            --
│    └─Empty: 2-3626                     [64, 64, 1, 1]            --
│    └─Empty: 2-3627                     [64]                      --
│    └─Empty: 2-3628                     [64]                      --
│    └─BatchNorm2d: 2-3629               [16, 64, 2, 2]            --
│    └─Scaler: 2-3630                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3631                      [16, 64, 2, 2]            --
│    └─Empty: 2-3632                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3633                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3634                 [16, 64, 2, 2]            --
│    └─Empty: 2-3635                     [16, 64, 2, 2]            --
│    └─Empty: 2-3636                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3637        --                        --
│    └─One: 2-3638                       [1]                       --
│    └─OutputScale: 2-3639               --                        --
│    └─Empty: 2-3640                     [64, 64, 3, 3]            --
│    └─Empty: 2-3641                     [64, 64, 3, 3]            --
│    └─Empty: 2-3642                     [64]                      --
│    └─Empty: 2-3643                     [64]                      --
│    └─BatchNorm2d: 2-3644               [16, 64, 2, 2]            --
│    └─Scaler: 2-3645                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3646                      [16, 64, 2, 2]            --
│    └─Empty: 2-3647                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3648                     [16, 64, 2, 2]            --
├─FusedConv1dBNReLU: 1-273               [16, 64, 12]              81,990
│    └─OutputShiftSqueeze: 2-3649        --                        --
│    └─One: 2-3650                       [1]                       --
│    └─OutputScale: 2-3651               --                        --
│    └─Empty: 2-3652                     [64, 256, 5]              --
│    └─Empty: 2-3653                     [64, 256, 5]              --
│    └─Empty: 2-3654                     [64]                      --
│    └─Empty: 2-3655                     [64]                      --
│    └─BatchNorm1d: 2-3656               [16, 64, 12]              --
│    └─Scaler: 2-3657                    [16, 64, 12]              --
│    └─ReLU: 2-3658                      [16, 64, 12]              --
│    └─Empty: 2-3659                     [16, 64, 12]              --
│    └─Clamp: 2-3660                     [16, 64, 12]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 8]               20,550
│    └─OutputShiftSqueeze: 2-3661        --                        --
│    └─One: 2-3662                       [1]                       --
│    └─OutputScale: 2-3663               --                        --
│    └─Empty: 2-3664                     [64, 64, 5]               --
│    └─Empty: 2-3665                     [64, 64, 5]               --
│    └─Empty: 2-3666                     [64]                      --
│    └─Empty: 2-3667                     [64]                      --
│    └─BatchNorm1d: 2-3668               [16, 64, 8]               --
│    └─Scaler: 2-3669                    [16, 64, 8]               --
│    └─ReLU: 2-3670                      [16, 64, 8]               --
│    └─Empty: 2-3671                     [16, 64, 8]               --
│    └─Clamp: 2-3672                     [16, 64, 8]               --
├─FusedConv1dBNReLU: 1-275               [16, 64, 4]               20,550
│    └─OutputShiftSqueeze: 2-3673        --                        --
│    └─One: 2-3674                       [1]                       --
│    └─OutputScale: 2-3675               --                        --
│    └─Empty: 2-3676                     [64, 64, 5]               --
│    └─Empty: 2-3677                     [64, 64, 5]               --
│    └─Empty: 2-3678                     [64]                      --
│    └─Empty: 2-3679                     [64]                      --
│    └─BatchNorm1d: 2-3680               [16, 64, 4]               --
│    └─Scaler: 2-3681                    [16, 64, 4]               --
│    └─ReLU: 2-3682                      [16, 64, 4]               --
│    └─Empty: 2-3683                     [16, 64, 4]               --
│    └─Clamp: 2-3684                     [16, 64, 4]               --
├─FusedConv1dBNReLU: 1-276               [16, 64, 2]               12,358
│    └─OutputShiftSqueeze: 2-3685        --                        --
│    └─One: 2-3686                       [1]                       --
│    └─OutputScale: 2-3687               --                        --
│    └─Empty: 2-3688                     [64, 64, 3]               --
│    └─Empty: 2-3689                     [64, 64, 3]               --
│    └─Empty: 2-3690                     [64]                      --
│    └─Empty: 2-3691                     [64]                      --
│    └─BatchNorm1d: 2-3692               [16, 64, 2]               --
│    └─Scaler: 2-3693                    [16, 64, 2]               --
│    └─ReLU: 2-3694                      [16, 64, 2]               --
│    └─Empty: 2-3695                     [16, 64, 2]               --
│    └─Clamp: 2-3696                     [16, 64, 2]               --
├─FusedConv1dBNReLU: 1-277               [16, 64, 12]              49,222
│    └─OutputShiftSqueeze: 2-3697        --                        --
│    └─One: 2-3698                       [1]                       --
│    └─OutputScale: 2-3699               --                        --
│    └─Empty: 2-3700                     [64, 256, 3]              --
│    └─Empty: 2-3701                     [64, 256, 3]              --
│    └─Empty: 2-3702                     [64]                      --
│    └─Empty: 2-3703                     [64]                      --
│    └─BatchNorm1d: 2-3704               [16, 64, 12]              --
│    └─Scaler: 2-3705                    [16, 64, 12]              --
│    └─ReLU: 2-3706                      [16, 64, 12]              --
│    └─Empty: 2-3707                     [16, 64, 12]              --
│    └─Clamp: 2-3708                     [16, 64, 12]              --
├─FusedConv1dBNReLU: 1-278               [16, 64, 8]               12,358
│    └─OutputShiftSqueeze: 2-3709        --                        --
│    └─One: 2-3710                       [1]                       --
│    └─OutputScale: 2-3711               --                        --
│    └─Empty: 2-3712                     [64, 64, 3]               --
│    └─Empty: 2-3713                     [64, 64, 3]               --
│    └─Empty: 2-3714                     [64]                      --
│    └─Empty: 2-3715                     [64]                      --
│    └─BatchNorm1d: 2-3716               [16, 64, 8]               --
│    └─Scaler: 2-3717                    [16, 64, 8]               --
│    └─ReLU: 2-3718                      [16, 64, 8]               --
│    └─Empty: 2-3719                     [16, 64, 8]               --
│    └─Clamp: 2-3720                     [16, 64, 8]               --
├─FusedConv1dBNReLU: 1-279               [16, 64, 4]               12,358
│    └─OutputShiftSqueeze: 2-3721        --                        --
│    └─One: 2-3722                       [1]                       --
│    └─OutputScale: 2-3723               --                        --
│    └─Empty: 2-3724                     [64, 64, 3]               --
│    └─Empty: 2-3725                     [64, 64, 3]               --
│    └─Empty: 2-3726                     [64]                      --
│    └─Empty: 2-3727                     [64]                      --
│    └─BatchNorm1d: 2-3728               [16, 64, 4]               --
│    └─Scaler: 2-3729                    [16, 64, 4]               --
│    └─ReLU: 2-3730                      [16, 64, 4]               --
│    └─Empty: 2-3731                     [16, 64, 4]               --
│    └─Clamp: 2-3732                     [16, 64, 4]               --
├─FusedConv1dBNReLU: 1-280               [16, 64, 2]               12,358
│    └─OutputShiftSqueeze: 2-3733        --                        --
│    └─One: 2-3734                       [1]                       --
│    └─OutputScale: 2-3735               --                        --
│    └─Empty: 2-3736                     [64, 64, 3]               --
│    └─Empty: 2-3737                     [64, 64, 3]               --
│    └─Empty: 2-3738                     [64]                      --
│    └─Empty: 2-3739                     [64]                      --
│    └─BatchNorm1d: 2-3740               [16, 64, 2]               --
│    └─Scaler: 2-3741                    [16, 64, 2]               --
│    └─ReLU: 2-3742                      [16, 64, 2]               --
│    └─Empty: 2-3743                     [16, 64, 2]               --
│    └─Clamp: 2-3744                     [16, 64, 2]               --
├─FusedConv1dBNReLU: 1-281               [16, 64, 14]              49,222
│    └─OutputShiftSqueeze: 2-3745        --                        --
│    └─One: 2-3746                       [1]                       --
│    └─OutputScale: 2-3747               --                        --
│    └─Empty: 2-3748                     [64, 256, 3]              --
│    └─Empty: 2-3749                     [64, 256, 3]              --
│    └─Empty: 2-3750                     [64]                      --
│    └─Empty: 2-3751                     [64]                      --
│    └─BatchNorm1d: 2-3752               [16, 64, 14]              --
│    └─Scaler: 2-3753                    [16, 64, 14]              --
│    └─ReLU: 2-3754                      [16, 64, 14]              --
│    └─Empty: 2-3755                     [16, 64, 14]              --
│    └─Clamp: 2-3756                     [16, 64, 14]              --
├─FusedConv1dBNReLU: 1-282               [16, 64, 10]              12,358
│    └─OutputShiftSqueeze: 2-3757        --                        --
│    └─One: 2-3758                       [1]                       --
│    └─OutputScale: 2-3759               --                        --
│    └─Empty: 2-3760                     [64, 64, 3]               --
│    └─Empty: 2-3761                     [64, 64, 3]               --
│    └─Empty: 2-3762                     [64]                      --
│    └─Empty: 2-3763                     [64]                      --
│    └─BatchNorm1d: 2-3764               [16, 64, 10]              --
│    └─Scaler: 2-3765                    [16, 64, 10]              --
│    └─ReLU: 2-3766                      [16, 64, 10]              --
│    └─Empty: 2-3767                     [16, 64, 10]              --
│    └─Clamp: 2-3768                     [16, 64, 10]              --
├─FusedConv1dBNReLU: 1-283               [16, 64, 2]               12,358
│    └─OutputShiftSqueeze: 2-3769        --                        --
│    └─One: 2-3770                       [1]                       --
│    └─OutputScale: 2-3771               --                        --
│    └─Empty: 2-3772                     [64, 64, 3]               --
│    └─Empty: 2-3773                     [64, 64, 3]               --
│    └─Empty: 2-3774                     [64]                      --
│    └─Empty: 2-3775                     [64]                      --
│    └─BatchNorm1d: 2-3776               [16, 64, 2]               --
│    └─Scaler: 2-3777                    [16, 64, 2]               --
│    └─ReLU: 2-3778                      [16, 64, 2]               --
│    └─Empty: 2-3779                     [16, 64, 2]               --
│    └─Clamp: 2-3780                     [16, 64, 2]               --
├─FusedConv1dBNReLU: 1-284               [16, 64, 8]               147,526
│    └─OutputShiftSqueeze: 2-3781        --                        --
│    └─One: 2-3782                       [1]                       --
│    └─OutputScale: 2-3783               --                        --
│    └─Empty: 2-3784                     [64, 256, 9]              --
│    └─Empty: 2-3785                     [64, 256, 9]              --
│    └─Empty: 2-3786                     [64]                      --
│    └─Empty: 2-3787                     [64]                      --
│    └─BatchNorm1d: 2-3788               [16, 64, 8]               --
│    └─Scaler: 2-3789                    [16, 64, 8]               --
│    └─ReLU: 2-3790                      [16, 64, 8]               --
│    └─Empty: 2-3791                     [16, 64, 8]               --
│    └─Clamp: 2-3792                     [16, 64, 8]               --
├─FusedConv1dBNReLU: 1-285               [16, 64, 4]               20,550
│    └─OutputShiftSqueeze: 2-3793        --                        --
│    └─One: 2-3794                       [1]                       --
│    └─OutputScale: 2-3795               --                        --
│    └─Empty: 2-3796                     [64, 64, 5]               --
│    └─Empty: 2-3797                     [64, 64, 5]               --
│    └─Empty: 2-3798                     [64]                      --
│    └─Empty: 2-3799                     [64]                      --
│    └─BatchNorm1d: 2-3800               [16, 64, 4]               --
│    └─Scaler: 2-3801                    [16, 64, 4]               --
│    └─ReLU: 2-3802                      [16, 64, 4]               --
│    └─Empty: 2-3803                     [16, 64, 4]               --
│    └─Clamp: 2-3804                     [16, 64, 4]               --
├─FusedConv1dBNReLU: 1-286               [16, 64, 2]               12,358
│    └─OutputShiftSqueeze: 2-3805        --                        --
│    └─One: 2-3806                       [1]                       --
│    └─OutputScale: 2-3807               --                        --
│    └─Empty: 2-3808                     [64, 64, 3]               --
│    └─Empty: 2-3809                     [64, 64, 3]               --
│    └─Empty: 2-3810                     [64]                      --
│    └─Empty: 2-3811                     [64]                      --
│    └─BatchNorm1d: 2-3812               [16, 64, 2]               --
│    └─Scaler: 2-3813                    [16, 64, 2]               --
│    └─ReLU: 2-3814                      [16, 64, 2]               --
│    └─Empty: 2-3815                     [16, 64, 2]               --
│    └─Clamp: 2-3816                     [16, 64, 2]               --
├─FusedLinearReLU: 1-287                 [16, 32]                  4,134
│    └─OutputShiftSqueeze: 2-3817        --                        --
│    └─One: 2-3818                       [1]                       --
│    └─OutputScale: 2-3819               --                        --
│    └─Empty: 2-3820                     [32, 128]                 --
│    └─Empty: 2-3821                     [32, 128]                 --
│    └─Empty: 2-3822                     [32]                      --
│    └─Empty: 2-3823                     [32]                      --
│    └─Scaler: 2-3824                    [16, 32]                  --
│    └─ReLU: 2-3825                      [16, 32]                  --
│    └─Empty: 2-3826                     [16, 32]                  --
│    └─Clamp: 2-3827                     [16, 32]                  --
├─Linear: 1-288                          [16, 5]                   166
│    └─OutputShiftSqueeze: 2-3828        --                        --
│    └─One: 2-3829                       [1]                       --
│    └─OutputScale: 2-3830               --                        --
│    └─Empty: 2-3831                     [5, 32]                   --
│    └─Empty: 2-3832                     [5, 32]                   --
│    └─Empty: 2-3833                     [16, 5]                   --
│    └─Empty: 2-3834                     [16, 5]                   --
│    └─Clamp: 2-3835                     [16, 5]                   --
==========================================================================================
Total params: 910,662
Trainable params: 910,464
Non-trainable params: 198
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.560 | Acc: 55.875% | Wgt Acc: 30.974%
	I - Batch: 100 | Loss: 1.542 | Acc: 55.500% | Wgt Acc: 31.559%
	I - Batch: 150 | Loss: 1.535 | Acc: 53.292% | Wgt Acc: 32.038%
	I - Batch: 200 | Loss: 1.523 | Acc: 54.031% | Wgt Acc: 33.308%
	I - Batch: 250 | Loss: 1.513 | Acc: 53.900% | Wgt Acc: 33.708%
	I - Batch: 300 | Loss: 1.500 | Acc: 53.729% | Wgt Acc: 34.444%
	I - Batch: 350 | Loss: 1.488 | Acc: 53.518% | Wgt Acc: 34.963%
	I - Batch: 400 | Loss: 1.481 | Acc: 53.609% | Wgt Acc: 35.216%
	I - Batch: 450 | Loss: 1.467 | Acc: 54.097% | Wgt Acc: 35.976%
	I - Batch: 500 | Loss: 1.453 | Acc: 54.587% | Wgt Acc: 36.507%
	I - Batch: 550 | Loss: 1.450 | Acc: 54.511% | Wgt Acc: 36.642%
	I - Batch: 600 | Loss: 1.439 | Acc: 55.031% | Wgt Acc: 37.304%
	I - Batch: 650 | Loss: 1.434 | Acc: 55.173% | Wgt Acc: 37.660%
	I - Batch: 700 | Loss: 1.428 | Acc: 55.438% | Wgt Acc: 37.916%
	I - Batch: 750 | Loss: 1.424 | Acc: 55.642% | Wgt Acc: 38.090%
	I - Batch: 800 | Loss: 1.419 | Acc: 55.875% | Wgt Acc: 38.302%
	I - Batch: 850 | Loss: 1.416 | Acc: 55.926% | Wgt Acc: 38.450%
I - num batch: 876
I - Train -- Loss: 1.415 | Acc: 55.855% | Wgt Acc: 38.438% | LR: 1.000000e-03 | Dur: 549.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 565.   57.   79.  473.  486.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    1.    0.    0.]
 [ 510.   88.  122.  523.  711.]
 [ 811.  782. 1133.  930. 6733.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.625 | Acc: 24.250% | Wgt Acc: 22.276%
	I - Batch: 100 | Loss: 1.508 | Acc: 36.000% | Wgt Acc: 27.493%
	I - Batch: 150 | Loss: 1.431 | Acc: 41.667% | Wgt Acc: 31.046%
I - num batch: 193
I - Val -- Loss: 1.418 | Acc: 42.612% | Wgt Acc: 31.533% | Dur: 92.51s
I - Confusion Matrix: [row->prediction - col->label]
[[439.  68.  55. 448. 315.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 14.  25.  24.  14.  38.]
 [ 82. 277. 313. 112. 862.]]

I - Local maximum validation set accuracy:  42.61

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.326 | Acc: 55.500% | Wgt Acc: 39.290%
	I - Batch: 100 | Loss: 1.338 | Acc: 54.938% | Wgt Acc: 39.101%
	I - Batch: 150 | Loss: 1.342 | Acc: 55.583% | Wgt Acc: 38.869%
	I - Batch: 200 | Loss: 1.329 | Acc: 56.375% | Wgt Acc: 39.467%
	I - Batch: 250 | Loss: 1.328 | Acc: 57.300% | Wgt Acc: 40.270%
	I - Batch: 300 | Loss: 1.319 | Acc: 58.062% | Wgt Acc: 40.992%
	I - Batch: 350 | Loss: 1.319 | Acc: 58.250% | Wgt Acc: 41.441%
	I - Batch: 400 | Loss: 1.317 | Acc: 58.672% | Wgt Acc: 41.868%
	I - Batch: 450 | Loss: 1.315 | Acc: 58.833% | Wgt Acc: 42.288%
	I - Batch: 500 | Loss: 1.311 | Acc: 58.975% | Wgt Acc: 42.497%
	I - Batch: 550 | Loss: 1.313 | Acc: 58.625% | Wgt Acc: 42.434%
	I - Batch: 600 | Loss: 1.316 | Acc: 58.406% | Wgt Acc: 42.366%
	I - Batch: 650 | Loss: 1.315 | Acc: 58.337% | Wgt Acc: 42.378%
	I - Batch: 700 | Loss: 1.309 | Acc: 58.616% | Wgt Acc: 42.886%
	I - Batch: 750 | Loss: 1.309 | Acc: 58.450% | Wgt Acc: 42.959%
	I - Batch: 800 | Loss: 1.310 | Acc: 58.281% | Wgt Acc: 43.025%
	I - Batch: 850 | Loss: 1.309 | Acc: 58.331% | Wgt Acc: 43.142%
I - num batch: 876
I - Train -- Loss: 1.310 | Acc: 58.126% | Wgt Acc: 43.062% | LR: 1.000000e-03 | Dur: 547.25s
I - Confusion Matrix: [row->prediction - col->label]
[[1056.   47.   77.  790.  714.]
 [   0.    0.    0.    0.    0.]
 [  14.   75.  102.   32.  190.]
 [ 289.   58.  105.  422.  466.]
 [ 527.  747. 1051.  682. 6560.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.322 | Acc: 41.750% | Wgt Acc: 39.871%
	I - Batch: 100 | Loss: 1.326 | Acc: 44.188% | Wgt Acc: 42.102%
	I - Batch: 150 | Loss: 1.304 | Acc: 44.833% | Wgt Acc: 43.464%
I - num batch: 193
I - Val -- Loss: 1.302 | Acc: 45.139% | Wgt Acc: 44.090% | Dur: 92.83s
I - Confusion Matrix: [row->prediction - col->label]
[[367.  12.  30. 220. 184.]
 [  0.   6.   3.   5.  13.]
 [ 23. 203. 231.  46. 311.]
 [ 98.  60.  56. 248. 166.]
 [ 47.  89.  72.  55. 541.]]

I - Local maximum validation set accuracy:  45.14

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 1.306 | Acc: 55.750% | Wgt Acc: 44.420%
	I - Batch: 100 | Loss: 1.293 | Acc: 54.188% | Wgt Acc: 44.334%
	I - Batch: 150 | Loss: 1.294 | Acc: 54.458% | Wgt Acc: 43.771%
	I - Batch: 200 | Loss: 1.282 | Acc: 55.719% | Wgt Acc: 44.709%
	I - Batch: 250 | Loss: 1.276 | Acc: 56.725% | Wgt Acc: 45.309%
	I - Batch: 300 | Loss: 1.268 | Acc: 56.875% | Wgt Acc: 45.517%
	I - Batch: 350 | Loss: 1.272 | Acc: 56.625% | Wgt Acc: 45.189%
	I - Batch: 400 | Loss: 1.273 | Acc: 56.500% | Wgt Acc: 45.197%
	I - Batch: 450 | Loss: 1.278 | Acc: 56.264% | Wgt Acc: 45.015%
	I - Batch: 500 | Loss: 1.279 | Acc: 56.075% | Wgt Acc: 44.839%
	I - Batch: 550 | Loss: 1.279 | Acc: 56.227% | Wgt Acc: 45.114%
	I - Batch: 600 | Loss: 1.279 | Acc: 56.250% | Wgt Acc: 45.138%
	I - Batch: 650 | Loss: 1.278 | Acc: 56.163% | Wgt Acc: 45.099%
	I - Batch: 700 | Loss: 1.277 | Acc: 56.321% | Wgt Acc: 45.287%
	I - Batch: 750 | Loss: 1.278 | Acc: 56.358% | Wgt Acc: 45.397%
	I - Batch: 800 | Loss: 1.278 | Acc: 56.336% | Wgt Acc: 45.412%
	I - Batch: 850 | Loss: 1.278 | Acc: 56.272% | Wgt Acc: 45.318%
I - num batch: 876
I - Train -- Loss: 1.280 | Acc: 56.198% | Wgt Acc: 45.210% | LR: 1.000000e-03 | Dur: 539.42s
I - Confusion Matrix: [row->prediction - col->label]
[[1010.   33.   59.  739.  715.]
 [   1.    1.    3.    3.    7.]
 [  46.  376.  512.  164.  930.]
 [ 325.   58.   91.  458.  389.]
 [ 504.  459.  670.  562. 5889.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.465 | Acc: 28.375% | Wgt Acc: 26.967%
	I - Batch: 100 | Loss: 1.384 | Acc: 40.938% | Wgt Acc: 33.392%
	I - Batch: 150 | Loss: 1.323 | Acc: 46.458% | Wgt Acc: 37.092%
I - num batch: 193
I - Val -- Loss: 1.326 | Acc: 47.699% | Wgt Acc: 38.182% | Dur: 94.00s
I - Confusion Matrix: [row->prediction - col->label]
[[276.  11.  21. 201.  96.]
 [  2.   0.   0.   1.   1.]
 [ 23. 169. 141.  76. 180.]
 [ 83.  13.  19. 173.  56.]
 [151. 177. 211. 123. 882.]]

I - Local maximum validation set accuracy:  47.70

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 1.292 | Acc: 54.375% | Wgt Acc: 44.880%
	I - Batch: 100 | Loss: 1.285 | Acc: 56.375% | Wgt Acc: 45.629%
	I - Batch: 150 | Loss: 1.284 | Acc: 56.667% | Wgt Acc: 45.591%
	I - Batch: 200 | Loss: 1.276 | Acc: 57.469% | Wgt Acc: 46.306%
	I - Batch: 250 | Loss: 1.273 | Acc: 57.350% | Wgt Acc: 46.403%
	I - Batch: 300 | Loss: 1.269 | Acc: 57.458% | Wgt Acc: 46.504%
	I - Batch: 350 | Loss: 1.269 | Acc: 57.500% | Wgt Acc: 46.274%
	I - Batch: 400 | Loss: 1.270 | Acc: 57.203% | Wgt Acc: 45.919%
	I - Batch: 450 | Loss: 1.272 | Acc: 56.792% | Wgt Acc: 45.604%
	I - Batch: 500 | Loss: 1.271 | Acc: 56.975% | Wgt Acc: 45.706%
	I - Batch: 550 | Loss: 1.266 | Acc: 57.011% | Wgt Acc: 46.004%
	I - Batch: 600 | Loss: 1.268 | Acc: 56.646% | Wgt Acc: 45.980%
	I - Batch: 650 | Loss: 1.270 | Acc: 56.596% | Wgt Acc: 45.829%
	I - Batch: 700 | Loss: 1.272 | Acc: 56.473% | Wgt Acc: 45.702%
	I - Batch: 750 | Loss: 1.270 | Acc: 56.583% | Wgt Acc: 45.926%
	I - Batch: 800 | Loss: 1.269 | Acc: 56.672% | Wgt Acc: 45.992%
	I - Batch: 850 | Loss: 1.267 | Acc: 56.706% | Wgt Acc: 46.070%
I - num batch: 876
I - Train -- Loss: 1.267 | Acc: 56.798% | Wgt Acc: 46.181% | LR: 1.000000e-03 | Dur: 541.85s
I - Confusion Matrix: [row->prediction - col->label]
[[1040.   26.   48.  694.  686.]
 [   1.    0.    0.    1.    0.]
 [  50.  376.  481.  169.  853.]
 [ 315.  115.  142.  565.  523.]
 [ 480.  410.  664.  497. 5868.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.543 | Acc: 29.500% | Wgt Acc: 27.853%
	I - Batch: 100 | Loss: 1.407 | Acc: 42.625% | Wgt Acc: 34.083%
	I - Batch: 150 | Loss: 1.322 | Acc: 48.083% | Wgt Acc: 37.916%
I - num batch: 193
I - Val -- Loss: 1.308 | Acc: 49.320% | Wgt Acc: 38.884% | Dur: 91.00s
I - Confusion Matrix: [row->prediction - col->label]
[[375.  12.  27. 328. 133.]
 [  0.   0.   0.   0.   0.]
 [ 13. 117. 125.  35.  90.]
 [ 18.  39.  34.  91.  61.]
 [129. 202. 206. 120. 931.]]

I - Local maximum validation set accuracy:  49.32

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 1.300 | Acc: 57.125% | Wgt Acc: 46.092%
	I - Batch: 100 | Loss: 1.232 | Acc: 59.375% | Wgt Acc: 49.249%
	I - Batch: 150 | Loss: 1.222 | Acc: 59.417% | Wgt Acc: 49.206%
	I - Batch: 200 | Loss: 1.214 | Acc: 59.312% | Wgt Acc: 49.746%
	I - Batch: 250 | Loss: 1.224 | Acc: 58.850% | Wgt Acc: 49.060%
	I - Batch: 300 | Loss: 1.231 | Acc: 58.479% | Wgt Acc: 48.767%
	I - Batch: 350 | Loss: 1.230 | Acc: 58.518% | Wgt Acc: 48.746%
	I - Batch: 400 | Loss: 1.240 | Acc: 57.906% | Wgt Acc: 48.020%
	I - Batch: 450 | Loss: 1.243 | Acc: 57.653% | Wgt Acc: 48.146%
	I - Batch: 500 | Loss: 1.246 | Acc: 57.587% | Wgt Acc: 47.984%
	I - Batch: 550 | Loss: 1.244 | Acc: 57.739% | Wgt Acc: 48.160%
	I - Batch: 600 | Loss: 1.244 | Acc: 57.833% | Wgt Acc: 48.260%
	I - Batch: 650 | Loss: 1.247 | Acc: 57.327% | Wgt Acc: 47.870%
	I - Batch: 700 | Loss: 1.244 | Acc: 57.304% | Wgt Acc: 47.980%
	I - Batch: 750 | Loss: 1.247 | Acc: 57.042% | Wgt Acc: 47.878%
	I - Batch: 800 | Loss: 1.246 | Acc: 57.219% | Wgt Acc: 47.969%
	I - Batch: 850 | Loss: 1.249 | Acc: 56.993% | Wgt Acc: 47.808%
I - num batch: 876
I - Train -- Loss: 1.251 | Acc: 56.898% | Wgt Acc: 47.767% | LR: 1.000000e-03 | Dur: 538.50s
I - Confusion Matrix: [row->prediction - col->label]
[[1061.   32.   49.  619.  713.]
 [   0.    0.    2.    1.    4.]
 [  51.  454.  589.  199.  972.]
 [ 355.   99.  136.  646.  569.]
 [ 419.  342.  559.  461. 5672.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.627 | Acc: 30.500% | Wgt Acc: 28.148%
	I - Batch: 100 | Loss: 1.502 | Acc: 39.438% | Wgt Acc: 33.153%
	I - Batch: 150 | Loss: 1.418 | Acc: 43.458% | Wgt Acc: 35.870%
I - num batch: 193
I - Val -- Loss: 1.406 | Acc: 44.038% | Wgt Acc: 36.743% | Dur: 91.10s
I - Confusion Matrix: [row->prediction - col->label]
[[458.  45.  53. 371. 307.]
 [  0.   0.   0.   0.   0.]
 [  3.  31.  28.   2.  15.]
 [ 30.  99.  84. 142. 162.]
 [ 44. 195. 227.  59. 731.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 1.295 | Acc: 53.375% | Wgt Acc: 45.654%
	I - Batch: 100 | Loss: 1.262 | Acc: 55.688% | Wgt Acc: 47.050%
	I - Batch: 150 | Loss: 1.242 | Acc: 56.250% | Wgt Acc: 47.964%
	I - Batch: 200 | Loss: 1.239 | Acc: 56.938% | Wgt Acc: 48.156%
	I - Batch: 250 | Loss: 1.248 | Acc: 56.375% | Wgt Acc: 47.467%
	I - Batch: 300 | Loss: 1.261 | Acc: 55.896% | Wgt Acc: 46.929%
	I - Batch: 350 | Loss: 1.262 | Acc: 55.982% | Wgt Acc: 46.846%
	I - Batch: 400 | Loss: 1.258 | Acc: 56.031% | Wgt Acc: 46.922%
	I - Batch: 450 | Loss: 1.252 | Acc: 56.042% | Wgt Acc: 47.138%
	I - Batch: 500 | Loss: 1.253 | Acc: 56.225% | Wgt Acc: 47.078%
	I - Batch: 550 | Loss: 1.248 | Acc: 56.614% | Wgt Acc: 47.348%
	I - Batch: 600 | Loss: 1.244 | Acc: 56.771% | Wgt Acc: 47.493%
	I - Batch: 650 | Loss: 1.243 | Acc: 56.654% | Wgt Acc: 47.486%
	I - Batch: 700 | Loss: 1.240 | Acc: 56.750% | Wgt Acc: 47.649%
	I - Batch: 750 | Loss: 1.241 | Acc: 56.692% | Wgt Acc: 47.671%
	I - Batch: 800 | Loss: 1.238 | Acc: 57.008% | Wgt Acc: 48.042%
	I - Batch: 850 | Loss: 1.238 | Acc: 57.103% | Wgt Acc: 48.066%
I - num batch: 876
I - Train -- Loss: 1.238 | Acc: 57.212% | Wgt Acc: 48.145% | LR: 1.000000e-03 | Dur: 536.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 976.   20.   34.  532.  658.]
 [   1.    1.    1.    2.    2.]
 [  47.  412.  557.  179.  911.]
 [ 454.  154.  166.  800.  681.]
 [ 408.  340.  577.  413. 5678.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.415 | Acc: 33.000% | Wgt Acc: 30.969%
	I - Batch: 100 | Loss: 1.326 | Acc: 45.500% | Wgt Acc: 37.195%
	I - Batch: 150 | Loss: 1.255 | Acc: 51.208% | Wgt Acc: 41.339%
I - num batch: 193
I - Val -- Loss: 1.257 | Acc: 52.171% | Wgt Acc: 42.055% | Dur: 91.64s
I - Confusion Matrix: [row->prediction - col->label]
[[355.   8.  14. 180.  96.]
 [  0.   0.   0.   0.   0.]
 [  2. 132. 111.  29.  90.]
 [ 59.  33.  53. 201.  86.]
 [119. 197. 214. 164. 943.]]

I - Local maximum validation set accuracy:  52.17

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 1.231 | Acc: 58.875% | Wgt Acc: 48.938%
	I - Batch: 100 | Loss: 1.249 | Acc: 58.000% | Wgt Acc: 48.257%
	I - Batch: 150 | Loss: 1.244 | Acc: 58.500% | Wgt Acc: 48.208%
	I - Batch: 200 | Loss: 1.237 | Acc: 59.312% | Wgt Acc: 48.821%
	I - Batch: 250 | Loss: 1.235 | Acc: 59.075% | Wgt Acc: 48.983%
	I - Batch: 300 | Loss: 1.241 | Acc: 58.854% | Wgt Acc: 48.753%
	I - Batch: 350 | Loss: 1.231 | Acc: 58.857% | Wgt Acc: 49.371%
	I - Batch: 400 | Loss: 1.230 | Acc: 58.906% | Wgt Acc: 49.331%
	I - Batch: 450 | Loss: 1.231 | Acc: 58.833% | Wgt Acc: 49.330%
	I - Batch: 500 | Loss: 1.228 | Acc: 58.888% | Wgt Acc: 49.515%
	I - Batch: 550 | Loss: 1.228 | Acc: 58.739% | Wgt Acc: 49.378%
	I - Batch: 600 | Loss: 1.225 | Acc: 58.833% | Wgt Acc: 49.640%
	I - Batch: 650 | Loss: 1.219 | Acc: 59.038% | Wgt Acc: 49.893%
	I - Batch: 700 | Loss: 1.218 | Acc: 59.312% | Wgt Acc: 49.912%
	I - Batch: 750 | Loss: 1.219 | Acc: 59.267% | Wgt Acc: 49.940%
	I - Batch: 800 | Loss: 1.220 | Acc: 59.227% | Wgt Acc: 49.732%
	I - Batch: 850 | Loss: 1.223 | Acc: 59.022% | Wgt Acc: 49.629%
I - num batch: 876
I - Train -- Loss: 1.222 | Acc: 59.033% | Wgt Acc: 49.628% | LR: 1.000000e-03 | Dur: 542.07s
I - Confusion Matrix: [row->prediction - col->label]
[[1050.   22.   27.  532.  608.]
 [   4.   23.   19.   13.   29.]
 [  37.  389.  537.  118.  804.]
 [ 370.  130.  156.  791.  623.]
 [ 425.  363.  596.  472. 5866.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.431 | Acc: 32.875% | Wgt Acc: 31.019%
	I - Batch: 100 | Loss: 1.322 | Acc: 44.438% | Wgt Acc: 37.567%
	I - Batch: 150 | Loss: 1.252 | Acc: 49.667% | Wgt Acc: 41.401%
I - num batch: 193
I - Val -- Loss: 1.248 | Acc: 50.745% | Wgt Acc: 42.068% | Dur: 93.18s
I - Confusion Matrix: [row->prediction - col->label]
[[413.  21.  29. 296. 193.]
 [  0.   0.   0.   0.   0.]
 [  5. 151. 144.  29.  81.]
 [ 48.  37.  39. 130.  62.]
 [ 69. 161. 180. 119. 879.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 1.160 | Acc: 62.250% | Wgt Acc: 53.891%
	I - Batch: 100 | Loss: 1.196 | Acc: 60.125% | Wgt Acc: 50.506%
	I - Batch: 150 | Loss: 1.209 | Acc: 59.208% | Wgt Acc: 49.657%
	I - Batch: 200 | Loss: 1.200 | Acc: 59.406% | Wgt Acc: 49.587%
	I - Batch: 250 | Loss: 1.218 | Acc: 58.775% | Wgt Acc: 48.727%
	I - Batch: 300 | Loss: 1.227 | Acc: 58.875% | Wgt Acc: 48.529%
	I - Batch: 350 | Loss: 1.218 | Acc: 59.411% | Wgt Acc: 49.241%
	I - Batch: 400 | Loss: 1.218 | Acc: 59.031% | Wgt Acc: 48.984%
	I - Batch: 450 | Loss: 1.214 | Acc: 59.208% | Wgt Acc: 49.173%
	I - Batch: 500 | Loss: 1.212 | Acc: 59.300% | Wgt Acc: 49.276%
	I - Batch: 550 | Loss: 1.204 | Acc: 59.682% | Wgt Acc: 49.783%
	I - Batch: 600 | Loss: 1.204 | Acc: 59.635% | Wgt Acc: 49.827%
	I - Batch: 650 | Loss: 1.201 | Acc: 59.827% | Wgt Acc: 49.983%
	I - Batch: 700 | Loss: 1.199 | Acc: 59.839% | Wgt Acc: 50.024%
	I - Batch: 750 | Loss: 1.201 | Acc: 59.875% | Wgt Acc: 50.084%
	I - Batch: 800 | Loss: 1.206 | Acc: 59.484% | Wgt Acc: 49.844%
	I - Batch: 850 | Loss: 1.205 | Acc: 59.596% | Wgt Acc: 49.886%
I - num batch: 876
I - Train -- Loss: 1.205 | Acc: 59.597% | Wgt Acc: 49.902% | LR: 1.000000e-03 | Dur: 548.59s
I - Confusion Matrix: [row->prediction - col->label]
[[1031.   19.   26.  517.  570.]
 [   2.   27.   32.    7.   31.]
 [  33.  430.  528.  141.  709.]
 [ 403.  117.  187.  809.  669.]
 [ 417.  334.  562.  452. 5951.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.569 | Acc: 33.375% | Wgt Acc: 31.248%
	I - Batch: 100 | Loss: 1.472 | Acc: 40.938% | Wgt Acc: 35.328%
	I - Batch: 150 | Loss: 1.391 | Acc: 45.375% | Wgt Acc: 38.687%
I - num batch: 193
I - Val -- Loss: 1.372 | Acc: 46.111% | Wgt Acc: 39.514% | Dur: 93.08s
I - Confusion Matrix: [row->prediction - col->label]
[[438.  22.  38. 363. 237.]
 [  0.   0.   0.   0.   0.]
 [  0.  78. 104.   9.  43.]
 [ 61. 103.  85. 140. 194.]
 [ 36. 167. 165.  62. 741.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 1.197 | Acc: 58.250% | Wgt Acc: 49.534%
	I - Batch: 100 | Loss: 1.167 | Acc: 59.812% | Wgt Acc: 52.550%
	I - Batch: 150 | Loss: 1.191 | Acc: 58.708% | Wgt Acc: 50.858%
	I - Batch: 200 | Loss: 1.195 | Acc: 59.562% | Wgt Acc: 51.322%
	I - Batch: 250 | Loss: 1.199 | Acc: 59.475% | Wgt Acc: 50.904%
	I - Batch: 300 | Loss: 1.209 | Acc: 59.396% | Wgt Acc: 50.435%
	I - Batch: 350 | Loss: 1.210 | Acc: 59.661% | Wgt Acc: 50.446%
	I - Batch: 400 | Loss: 1.210 | Acc: 59.812% | Wgt Acc: 50.637%
	I - Batch: 450 | Loss: 1.212 | Acc: 59.972% | Wgt Acc: 50.636%
	I - Batch: 500 | Loss: 1.209 | Acc: 59.850% | Wgt Acc: 50.480%
	I - Batch: 550 | Loss: 1.204 | Acc: 60.034% | Wgt Acc: 50.667%
	I - Batch: 600 | Loss: 1.202 | Acc: 59.906% | Wgt Acc: 50.562%
	I - Batch: 650 | Loss: 1.200 | Acc: 60.038% | Wgt Acc: 50.797%
	I - Batch: 700 | Loss: 1.203 | Acc: 59.955% | Wgt Acc: 50.714%
	I - Batch: 750 | Loss: 1.203 | Acc: 59.783% | Wgt Acc: 50.641%
	I - Batch: 800 | Loss: 1.201 | Acc: 59.992% | Wgt Acc: 50.749%
	I - Batch: 850 | Loss: 1.205 | Acc: 59.618% | Wgt Acc: 50.334%
I - num batch: 876
I - Train -- Loss: 1.204 | Acc: 59.554% | Wgt Acc: 50.304% | LR: 1.000000e-03 | Dur: 536.30s
I - Confusion Matrix: [row->prediction - col->label]
[[1025.   18.   36.  499.  599.]
 [   0.    0.    1.    0.    1.]
 [  36.  441.  579.  146.  783.]
 [ 410.  140.  151.  855.  666.]
 [ 415.  328.  568.  426. 5881.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.583 | Acc: 34.375% | Wgt Acc: 33.742%
	I - Batch: 100 | Loss: 1.520 | Acc: 39.438% | Wgt Acc: 35.864%
	I - Batch: 150 | Loss: 1.475 | Acc: 42.083% | Wgt Acc: 37.978%
I - num batch: 193
I - Val -- Loss: 1.507 | Acc: 41.251% | Wgt Acc: 37.187% | Dur: 90.35s
I - Confusion Matrix: [row->prediction - col->label]
[[179.   1.   4.  45.  22.]
 [ 11.   1.   3.  17.   4.]
 [107. 318. 311. 271. 514.]
 [ 94.   8.   7. 142.  35.]
 [144.  42.  67.  99. 640.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 1.362 | Acc: 52.375% | Wgt Acc: 41.088%
	I - Batch: 100 | Loss: 1.305 | Acc: 56.250% | Wgt Acc: 45.095%
	I - Batch: 150 | Loss: 1.265 | Acc: 58.208% | Wgt Acc: 47.565%
	I - Batch: 200 | Loss: 1.241 | Acc: 59.562% | Wgt Acc: 48.599%
	I - Batch: 250 | Loss: 1.239 | Acc: 59.650% | Wgt Acc: 48.386%
	I - Batch: 300 | Loss: 1.225 | Acc: 60.021% | Wgt Acc: 49.052%
	I - Batch: 350 | Loss: 1.217 | Acc: 60.250% | Wgt Acc: 49.555%
	I - Batch: 400 | Loss: 1.210 | Acc: 60.172% | Wgt Acc: 49.871%
	I - Batch: 450 | Loss: 1.213 | Acc: 59.861% | Wgt Acc: 49.758%
	I - Batch: 500 | Loss: 1.208 | Acc: 59.700% | Wgt Acc: 49.816%
	I - Batch: 550 | Loss: 1.208 | Acc: 59.455% | Wgt Acc: 49.847%
	I - Batch: 600 | Loss: 1.207 | Acc: 59.354% | Wgt Acc: 49.789%
	I - Batch: 650 | Loss: 1.210 | Acc: 59.163% | Wgt Acc: 49.586%
	I - Batch: 700 | Loss: 1.212 | Acc: 59.170% | Wgt Acc: 49.652%
	I - Batch: 750 | Loss: 1.212 | Acc: 59.142% | Wgt Acc: 49.567%
	I - Batch: 800 | Loss: 1.210 | Acc: 59.297% | Wgt Acc: 49.757%
	I - Batch: 850 | Loss: 1.209 | Acc: 59.412% | Wgt Acc: 49.861%
I - num batch: 876
I - Train -- Loss: 1.208 | Acc: 59.483% | Wgt Acc: 49.902% | LR: 1.000000e-03 | Dur: 535.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 975.   19.   23.  471.  587.]
 [  15.   53.   61.   36.   44.]
 [  31.  405.  540.  131.  717.]
 [ 429.  128.  152.  824.  644.]
 [ 436.  322.  559.  464. 5938.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.543 | Acc: 36.375% | Wgt Acc: 34.584%
	I - Batch: 100 | Loss: 1.514 | Acc: 39.750% | Wgt Acc: 37.008%
	I - Batch: 150 | Loss: 1.459 | Acc: 41.708% | Wgt Acc: 38.756%
I - num batch: 193
I - Val -- Loss: 1.462 | Acc: 40.927% | Wgt Acc: 38.263% | Dur: 89.84s
I - Confusion Matrix: [row->prediction - col->label]
[[500.  66. 106. 459. 488.]
 [  2.  26.  20.   1.  11.]
 [  2. 120. 110.   8.  41.]
 [ 19.  74.  49.  83. 131.]
 [ 12.  84. 107.  23. 544.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 1.175 | Acc: 60.750% | Wgt Acc: 49.529%
	I - Batch: 100 | Loss: 1.155 | Acc: 61.688% | Wgt Acc: 51.974%
	I - Batch: 150 | Loss: 1.173 | Acc: 60.708% | Wgt Acc: 51.008%
	I - Batch: 200 | Loss: 1.158 | Acc: 61.344% | Wgt Acc: 52.075%
	I - Batch: 250 | Loss: 1.146 | Acc: 62.100% | Wgt Acc: 53.041%
	I - Batch: 300 | Loss: 1.133 | Acc: 62.729% | Wgt Acc: 53.762%
	I - Batch: 350 | Loss: 1.126 | Acc: 62.911% | Wgt Acc: 54.062%
	I - Batch: 400 | Loss: 1.127 | Acc: 62.641% | Wgt Acc: 53.636%
	I - Batch: 450 | Loss: 1.126 | Acc: 62.847% | Wgt Acc: 53.939%
	I - Batch: 500 | Loss: 1.128 | Acc: 62.737% | Wgt Acc: 53.828%
	I - Batch: 550 | Loss: 1.127 | Acc: 62.875% | Wgt Acc: 53.987%
	I - Batch: 600 | Loss: 1.127 | Acc: 62.865% | Wgt Acc: 53.972%
	I - Batch: 650 | Loss: 1.126 | Acc: 62.894% | Wgt Acc: 53.835%
	I - Batch: 700 | Loss: 1.123 | Acc: 62.830% | Wgt Acc: 53.832%
	I - Batch: 750 | Loss: 1.126 | Acc: 62.708% | Wgt Acc: 53.627%
	I - Batch: 800 | Loss: 1.128 | Acc: 62.477% | Wgt Acc: 53.430%
	I - Batch: 850 | Loss: 1.128 | Acc: 62.456% | Wgt Acc: 53.369%
I - num batch: 876
I - Train -- Loss: 1.128 | Acc: 62.511% | Wgt Acc: 53.434% | LR: 5.000000e-04 | Dur: 535.39s
I - Confusion Matrix: [row->prediction - col->label]
[[1065.   16.   22.  403.  528.]
 [   7.   58.   68.   49.   66.]
 [  27.  476.  564.  115.  618.]
 [ 370.  109.  128.  979.  630.]
 [ 417.  268.  553.  380. 6088.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.527 | Acc: 34.750% | Wgt Acc: 32.834%
	I - Batch: 100 | Loss: 1.346 | Acc: 49.438% | Wgt Acc: 40.410%
	I - Batch: 150 | Loss: 1.252 | Acc: 55.208% | Wgt Acc: 44.889%
I - num batch: 193
I - Val -- Loss: 1.235 | Acc: 56.610% | Wgt Acc: 45.767% | Dur: 91.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 323.    4.    2.  141.   53.]
 [   1.    9.    5.    5.    0.]
 [   1.  114.  132.   13.   44.]
 [  71.   50.   42.  259.   94.]
 [ 139.  193.  211.  156. 1024.]]

I - Local maximum validation set accuracy:  56.61

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 1.216 | Acc: 59.625% | Wgt Acc: 50.139%
	I - Batch: 100 | Loss: 1.210 | Acc: 60.125% | Wgt Acc: 50.910%
	I - Batch: 150 | Loss: 1.193 | Acc: 60.667% | Wgt Acc: 51.030%
	I - Batch: 200 | Loss: 1.177 | Acc: 60.938% | Wgt Acc: 51.329%
	I - Batch: 250 | Loss: 1.173 | Acc: 61.800% | Wgt Acc: 52.301%
	I - Batch: 300 | Loss: 1.166 | Acc: 61.646% | Wgt Acc: 52.052%
	I - Batch: 350 | Loss: 1.154 | Acc: 61.750% | Wgt Acc: 52.663%
	I - Batch: 400 | Loss: 1.153 | Acc: 61.797% | Wgt Acc: 52.762%
	I - Batch: 450 | Loss: 1.150 | Acc: 61.764% | Wgt Acc: 52.679%
	I - Batch: 500 | Loss: 1.138 | Acc: 62.250% | Wgt Acc: 53.272%
	I - Batch: 550 | Loss: 1.133 | Acc: 62.420% | Wgt Acc: 53.296%
	I - Batch: 600 | Loss: 1.131 | Acc: 62.365% | Wgt Acc: 53.153%
	I - Batch: 650 | Loss: 1.125 | Acc: 62.510% | Wgt Acc: 53.517%
	I - Batch: 700 | Loss: 1.123 | Acc: 62.562% | Wgt Acc: 53.505%
	I - Batch: 750 | Loss: 1.119 | Acc: 62.683% | Wgt Acc: 53.600%
	I - Batch: 800 | Loss: 1.119 | Acc: 62.766% | Wgt Acc: 53.722%
	I - Batch: 850 | Loss: 1.117 | Acc: 62.831% | Wgt Acc: 53.779%
I - num batch: 876
I - Train -- Loss: 1.113 | Acc: 62.975% | Wgt Acc: 54.020% | LR: 5.000000e-04 | Dur: 541.93s
I - Confusion Matrix: [row->prediction - col->label]
[[1042.    9.   25.  384.  488.]
 [   3.   42.   50.   40.   54.]
 [  23.  493.  578.   80.  634.]
 [ 422.  127.  167. 1057.  654.]
 [ 396.  256.  515.  365. 6100.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.523 | Acc: 37.875% | Wgt Acc: 35.770%
	I - Batch: 100 | Loss: 1.369 | Acc: 49.000% | Wgt Acc: 41.146%
	I - Batch: 150 | Loss: 1.286 | Acc: 54.500% | Wgt Acc: 44.961%
I - num batch: 193
I - Val -- Loss: 1.268 | Acc: 56.254% | Wgt Acc: 46.119% | Dur: 91.88s
I - Confusion Matrix: [row->prediction - col->label]
[[362.  12.  15. 158. 106.]
 [  0.  19.   9.   0.   1.]
 [  0.  86. 106.  10.  27.]
 [ 84.  77.  57. 259.  91.]
 [ 89. 176. 205. 147. 990.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 1.057 | Acc: 66.500% | Wgt Acc: 58.303%
	I - Batch: 100 | Loss: 1.086 | Acc: 65.188% | Wgt Acc: 57.147%
	I - Batch: 150 | Loss: 1.075 | Acc: 65.292% | Wgt Acc: 57.139%
	I - Batch: 200 | Loss: 1.068 | Acc: 64.812% | Wgt Acc: 56.947%
	I - Batch: 250 | Loss: 1.070 | Acc: 64.800% | Wgt Acc: 56.817%
	I - Batch: 300 | Loss: 1.077 | Acc: 64.750% | Wgt Acc: 56.415%
	I - Batch: 350 | Loss: 1.070 | Acc: 64.804% | Wgt Acc: 56.526%
	I - Batch: 400 | Loss: 1.069 | Acc: 65.031% | Wgt Acc: 56.818%
	I - Batch: 450 | Loss: 1.070 | Acc: 65.153% | Wgt Acc: 56.936%
	I - Batch: 500 | Loss: 1.069 | Acc: 65.037% | Wgt Acc: 56.771%
	I - Batch: 550 | Loss: 1.070 | Acc: 64.977% | Wgt Acc: 56.770%
	I - Batch: 600 | Loss: 1.072 | Acc: 64.896% | Wgt Acc: 56.655%
	I - Batch: 650 | Loss: 1.072 | Acc: 64.750% | Wgt Acc: 56.498%
	I - Batch: 700 | Loss: 1.074 | Acc: 64.750% | Wgt Acc: 56.498%
	I - Batch: 750 | Loss: 1.075 | Acc: 64.558% | Wgt Acc: 56.346%
	I - Batch: 800 | Loss: 1.071 | Acc: 64.461% | Wgt Acc: 56.309%
	I - Batch: 850 | Loss: 1.072 | Acc: 64.471% | Wgt Acc: 56.364%
I - num batch: 876
I - Train -- Loss: 1.072 | Acc: 64.424% | Wgt Acc: 56.355% | LR: 5.000000e-04 | Dur: 543.31s
I - Confusion Matrix: [row->prediction - col->label]
[[1126.   17.   24.  379.  557.]
 [   5.   37.   37.   29.   32.]
 [  17.  523.  658.   96.  624.]
 [ 377.  129.  146. 1115.  631.]
 [ 361.  221.  470.  307. 6086.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.419 | Acc: 39.375% | Wgt Acc: 37.427%
	I - Batch: 100 | Loss: 1.268 | Acc: 50.562% | Wgt Acc: 44.081%
	I - Batch: 150 | Loss: 1.196 | Acc: 54.833% | Wgt Acc: 47.030%
I - num batch: 193
I - Val -- Loss: 1.185 | Acc: 56.157% | Wgt Acc: 47.958% | Dur: 91.20s
I - Confusion Matrix: [row->prediction - col->label]
[[402.  14.  21. 234. 135.]
 [  0.  32.   5.   8.   5.]
 [  4. 140. 160.  17.  62.]
 [ 44.  38.  38. 210.  84.]
 [ 85. 146. 168. 105. 929.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 1.030 | Acc: 63.875% | Wgt Acc: 55.739%
	I - Batch: 100 | Loss: 1.010 | Acc: 65.562% | Wgt Acc: 57.916%
	I - Batch: 150 | Loss: 1.011 | Acc: 66.000% | Wgt Acc: 58.467%
	I - Batch: 200 | Loss: 1.020 | Acc: 65.594% | Wgt Acc: 57.893%
	I - Batch: 250 | Loss: 1.030 | Acc: 65.575% | Wgt Acc: 57.847%
	I - Batch: 300 | Loss: 1.033 | Acc: 65.354% | Wgt Acc: 57.515%
	I - Batch: 350 | Loss: 1.031 | Acc: 65.571% | Wgt Acc: 57.529%
	I - Batch: 400 | Loss: 1.035 | Acc: 65.516% | Wgt Acc: 57.122%
	I - Batch: 450 | Loss: 1.036 | Acc: 65.528% | Wgt Acc: 57.119%
	I - Batch: 500 | Loss: 1.041 | Acc: 65.175% | Wgt Acc: 56.848%
	I - Batch: 550 | Loss: 1.045 | Acc: 65.182% | Wgt Acc: 56.743%
	I - Batch: 600 | Loss: 1.047 | Acc: 65.177% | Wgt Acc: 56.824%
	I - Batch: 650 | Loss: 1.045 | Acc: 65.413% | Wgt Acc: 57.183%
	I - Batch: 700 | Loss: 1.042 | Acc: 65.527% | Wgt Acc: 57.279%
	I - Batch: 750 | Loss: 1.045 | Acc: 65.583% | Wgt Acc: 57.245%
	I - Batch: 800 | Loss: 1.048 | Acc: 65.469% | Wgt Acc: 57.131%
	I - Batch: 850 | Loss: 1.048 | Acc: 65.441% | Wgt Acc: 57.134%
I - num batch: 876
I - Train -- Loss: 1.050 | Acc: 65.388% | Wgt Acc: 57.086% | LR: 5.000000e-04 | Dur: 539.67s
I - Confusion Matrix: [row->prediction - col->label]
[[1125.   14.   19.  348.  498.]
 [   5.   68.   69.   32.   39.]
 [  18.  507.  625.   68.  589.]
 [ 356.  116.  136. 1143.  608.]
 [ 382.  222.  486.  335. 6196.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.509 | Acc: 36.000% | Wgt Acc: 33.867%
	I - Batch: 100 | Loss: 1.315 | Acc: 48.812% | Wgt Acc: 40.097%
	I - Batch: 150 | Loss: 1.227 | Acc: 54.833% | Wgt Acc: 44.338%
I - num batch: 193
I - Val -- Loss: 1.216 | Acc: 56.837% | Wgt Acc: 45.808% | Dur: 91.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 268.    2.    9.   92.   31.]
 [   0.    6.    2.    5.    5.]
 [   2.  130.  134.   10.   45.]
 [ 102.   26.   34.  313.  101.]
 [ 163.  206.  213.  154. 1033.]]

I - Local maximum validation set accuracy:  56.84

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 1.082 | Acc: 64.000% | Wgt Acc: 56.882%
	I - Batch: 100 | Loss: 1.051 | Acc: 64.500% | Wgt Acc: 57.849%
	I - Batch: 150 | Loss: 1.032 | Acc: 65.417% | Wgt Acc: 59.209%
	I - Batch: 200 | Loss: 1.019 | Acc: 65.594% | Wgt Acc: 59.313%
	I - Batch: 250 | Loss: 1.026 | Acc: 65.275% | Wgt Acc: 58.770%
	I - Batch: 300 | Loss: 1.031 | Acc: 65.583% | Wgt Acc: 58.794%
	I - Batch: 350 | Loss: 1.037 | Acc: 65.625% | Wgt Acc: 58.800%
	I - Batch: 400 | Loss: 1.034 | Acc: 65.781% | Wgt Acc: 59.102%
	I - Batch: 450 | Loss: 1.030 | Acc: 65.806% | Wgt Acc: 58.916%
	I - Batch: 500 | Loss: 1.033 | Acc: 65.775% | Wgt Acc: 58.854%
	I - Batch: 550 | Loss: 1.032 | Acc: 65.693% | Wgt Acc: 58.694%
	I - Batch: 600 | Loss: 1.033 | Acc: 65.667% | Wgt Acc: 58.501%
	I - Batch: 650 | Loss: 1.031 | Acc: 65.490% | Wgt Acc: 58.286%
	I - Batch: 700 | Loss: 1.031 | Acc: 65.554% | Wgt Acc: 58.238%
	I - Batch: 750 | Loss: 1.031 | Acc: 65.550% | Wgt Acc: 58.293%
	I - Batch: 800 | Loss: 1.026 | Acc: 65.680% | Wgt Acc: 58.399%
	I - Batch: 850 | Loss: 1.025 | Acc: 65.846% | Wgt Acc: 58.446%
I - num batch: 876
I - Train -- Loss: 1.025 | Acc: 65.981% | Wgt Acc: 58.537% | LR: 5.000000e-04 | Dur: 539.27s
I - Confusion Matrix: [row->prediction - col->label]
[[1154.   12.   14.  292.  523.]
 [   3.  145.  137.   32.   73.]
 [  16.  452.  582.   61.  588.]
 [ 360.   99.  118. 1232.  619.]
 [ 353.  219.  484.  309. 6127.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.534 | Acc: 37.375% | Wgt Acc: 35.344%
	I - Batch: 100 | Loss: 1.362 | Acc: 48.312% | Wgt Acc: 40.140%
	I - Batch: 150 | Loss: 1.272 | Acc: 53.542% | Wgt Acc: 43.714%
I - num batch: 193
I - Val -- Loss: 1.261 | Acc: 54.893% | Wgt Acc: 44.645% | Dur: 91.24s
I - Confusion Matrix: [row->prediction - col->label]
[[408.  12.  26. 271. 119.]
 [  0.  20.   2.   3.   6.]
 [  1.  93. 108.   5.  26.]
 [ 30.  58.  49. 176.  82.]
 [ 96. 187. 207. 119. 982.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.966 | Acc: 68.750% | Wgt Acc: 60.021%
	I - Batch: 100 | Loss: 0.960 | Acc: 69.125% | Wgt Acc: 61.267%
	I - Batch: 150 | Loss: 0.966 | Acc: 68.458% | Wgt Acc: 60.729%
	I - Batch: 200 | Loss: 0.956 | Acc: 68.812% | Wgt Acc: 61.146%
	I - Batch: 250 | Loss: 0.964 | Acc: 68.275% | Wgt Acc: 60.958%
	I - Batch: 300 | Loss: 0.977 | Acc: 68.167% | Wgt Acc: 60.812%
	I - Batch: 350 | Loss: 0.984 | Acc: 67.696% | Wgt Acc: 60.257%
	I - Batch: 400 | Loss: 0.986 | Acc: 67.672% | Wgt Acc: 60.239%
	I - Batch: 450 | Loss: 0.989 | Acc: 67.514% | Wgt Acc: 60.127%
	I - Batch: 500 | Loss: 0.994 | Acc: 67.213% | Wgt Acc: 59.851%
	I - Batch: 550 | Loss: 0.999 | Acc: 67.023% | Wgt Acc: 59.562%
	I - Batch: 600 | Loss: 0.992 | Acc: 67.281% | Wgt Acc: 59.952%
	I - Batch: 650 | Loss: 0.992 | Acc: 67.365% | Wgt Acc: 59.996%
	I - Batch: 700 | Loss: 0.994 | Acc: 67.277% | Wgt Acc: 59.854%
	I - Batch: 750 | Loss: 0.992 | Acc: 67.367% | Wgt Acc: 60.028%
	I - Batch: 800 | Loss: 0.994 | Acc: 67.359% | Wgt Acc: 59.983%
	I - Batch: 850 | Loss: 0.994 | Acc: 67.324% | Wgt Acc: 59.991%
I - num batch: 876
I - Train -- Loss: 0.993 | Acc: 67.424% | Wgt Acc: 60.094% | LR: 5.000000e-04 | Dur: 539.54s
I - Confusion Matrix: [row->prediction - col->label]
[[1212.   13.   12.  266.  513.]
 [   9.  170.  166.   38.   79.]
 [  14.  458.  557.   56.  525.]
 [ 316.   97.  140. 1285.  595.]
 [ 335.  189.  460.  281. 6218.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.676 | Acc: 39.875% | Wgt Acc: 37.389%
	I - Batch: 100 | Loss: 1.470 | Acc: 45.875% | Wgt Acc: 41.379%
	I - Batch: 150 | Loss: 1.364 | Acc: 49.750% | Wgt Acc: 44.841%
I - num batch: 193
I - Val -- Loss: 1.354 | Acc: 50.356% | Wgt Acc: 45.573% | Dur: 90.91s
I - Confusion Matrix: [row->prediction - col->label]
[[383.  44.  38. 177. 265.]
 [  0.  26.  16.   8.   7.]
 [  1.  70.  82.   2.  23.]
 [123.  75.  79. 348. 205.]
 [ 28. 155. 177.  39. 715.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.952 | Acc: 70.000% | Wgt Acc: 61.825%
	I - Batch: 100 | Loss: 0.936 | Acc: 70.125% | Wgt Acc: 61.988%
	I - Batch: 150 | Loss: 0.960 | Acc: 68.542% | Wgt Acc: 61.439%
	I - Batch: 200 | Loss: 0.954 | Acc: 68.969% | Wgt Acc: 61.882%
	I - Batch: 250 | Loss: 0.972 | Acc: 68.375% | Wgt Acc: 61.224%
	I - Batch: 300 | Loss: 0.972 | Acc: 68.167% | Wgt Acc: 60.839%
	I - Batch: 350 | Loss: 0.974 | Acc: 68.143% | Wgt Acc: 60.871%
	I - Batch: 400 | Loss: 0.971 | Acc: 68.125% | Wgt Acc: 61.020%
	I - Batch: 450 | Loss: 0.975 | Acc: 68.097% | Wgt Acc: 60.861%
	I - Batch: 500 | Loss: 0.973 | Acc: 67.938% | Wgt Acc: 60.884%
	I - Batch: 550 | Loss: 0.971 | Acc: 68.011% | Wgt Acc: 60.988%
	I - Batch: 600 | Loss: 0.968 | Acc: 67.948% | Wgt Acc: 60.969%
	I - Batch: 650 | Loss: 0.970 | Acc: 67.654% | Wgt Acc: 60.692%
	I - Batch: 700 | Loss: 0.966 | Acc: 67.884% | Wgt Acc: 60.945%
	I - Batch: 750 | Loss: 0.966 | Acc: 67.667% | Wgt Acc: 60.748%
	I - Batch: 800 | Loss: 0.964 | Acc: 67.703% | Wgt Acc: 60.817%
	I - Batch: 850 | Loss: 0.965 | Acc: 67.787% | Wgt Acc: 60.906%
I - num batch: 876
I - Train -- Loss: 0.966 | Acc: 67.752% | Wgt Acc: 60.865% | LR: 5.000000e-04 | Dur: 540.06s
I - Confusion Matrix: [row->prediction - col->label]
[[1229.    9.   14.  254.  531.]
 [  11.  231.  212.   32.  104.]
 [  16.  412.  516.   47.  552.]
 [ 302.   86.  109. 1324.  555.]
 [ 328.  189.  484.  269. 6188.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.499 | Acc: 36.000% | Wgt Acc: 33.807%
	I - Batch: 100 | Loss: 1.342 | Acc: 48.312% | Wgt Acc: 39.989%
	I - Batch: 150 | Loss: 1.265 | Acc: 54.167% | Wgt Acc: 43.975%
I - num batch: 193
I - Val -- Loss: 1.252 | Acc: 55.671% | Wgt Acc: 44.784% | Dur: 92.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 413.   13.   25.  242.  122.]
 [   0.    4.    3.    9.    0.]
 [  10.  156.  125.   13.   46.]
 [  37.   11.   15.  163.   34.]
 [  75.  186.  224.  147. 1013.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.986 | Acc: 67.750% | Wgt Acc: 61.352%
	I - Batch: 100 | Loss: 0.968 | Acc: 67.250% | Wgt Acc: 60.600%
	I - Batch: 150 | Loss: 0.956 | Acc: 68.875% | Wgt Acc: 62.408%
	I - Batch: 200 | Loss: 0.953 | Acc: 68.688% | Wgt Acc: 62.281%
	I - Batch: 250 | Loss: 0.951 | Acc: 68.500% | Wgt Acc: 62.319%
	I - Batch: 300 | Loss: 0.950 | Acc: 68.229% | Wgt Acc: 62.246%
	I - Batch: 350 | Loss: 0.949 | Acc: 68.500% | Wgt Acc: 62.312%
	I - Batch: 400 | Loss: 0.942 | Acc: 68.516% | Wgt Acc: 62.397%
	I - Batch: 450 | Loss: 0.942 | Acc: 68.514% | Wgt Acc: 62.390%
	I - Batch: 500 | Loss: 0.942 | Acc: 68.675% | Wgt Acc: 62.550%
	I - Batch: 550 | Loss: 0.947 | Acc: 68.318% | Wgt Acc: 62.233%
	I - Batch: 600 | Loss: 0.946 | Acc: 68.271% | Wgt Acc: 62.235%
	I - Batch: 650 | Loss: 0.945 | Acc: 68.250% | Wgt Acc: 62.169%
	I - Batch: 700 | Loss: 0.940 | Acc: 68.527% | Wgt Acc: 62.404%
	I - Batch: 750 | Loss: 0.941 | Acc: 68.517% | Wgt Acc: 62.249%
	I - Batch: 800 | Loss: 0.939 | Acc: 68.648% | Wgt Acc: 62.336%
	I - Batch: 850 | Loss: 0.936 | Acc: 68.735% | Wgt Acc: 62.337%
I - num batch: 876
I - Train -- Loss: 0.935 | Acc: 68.816% | Wgt Acc: 62.460% | LR: 5.000000e-04 | Dur: 542.00s
I - Confusion Matrix: [row->prediction - col->label]
[[1268.   10.   15.  224.  511.]
 [   8.  304.  289.   35.  121.]
 [  15.  360.  478.   43.  534.]
 [ 275.   80.   93. 1384.  561.]
 [ 320.  173.  460.  240. 6203.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.189 | Acc: 46.375% | Wgt Acc: 45.339%
	I - Batch: 100 | Loss: 1.177 | Acc: 51.250% | Wgt Acc: 48.817%
	I - Batch: 150 | Loss: 1.151 | Acc: 52.792% | Wgt Acc: 50.131%
I - num batch: 193
I - Val -- Loss: 1.165 | Acc: 52.625% | Wgt Acc: 50.030% | Dur: 91.64s
I - Confusion Matrix: [row->prediction - col->label]
[[271.   2.  10.  66.  46.]
 [  6. 129. 113.  42.  62.]
 [ 17. 162. 163.  51. 266.]
 [174.  25.  41. 353. 133.]
 [ 67.  52.  65.  62. 708.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.906 | Acc: 70.000% | Wgt Acc: 63.052%
	I - Batch: 100 | Loss: 0.923 | Acc: 69.375% | Wgt Acc: 62.766%
	I - Batch: 150 | Loss: 0.905 | Acc: 69.917% | Wgt Acc: 63.824%
	I - Batch: 200 | Loss: 0.894 | Acc: 69.969% | Wgt Acc: 64.190%
	I - Batch: 250 | Loss: 0.892 | Acc: 69.950% | Wgt Acc: 64.434%
	I - Batch: 300 | Loss: 0.907 | Acc: 69.083% | Wgt Acc: 63.673%
	I - Batch: 350 | Loss: 0.906 | Acc: 69.018% | Wgt Acc: 63.557%
	I - Batch: 400 | Loss: 0.907 | Acc: 69.141% | Wgt Acc: 63.640%
	I - Batch: 450 | Loss: 0.904 | Acc: 69.292% | Wgt Acc: 63.713%
	I - Batch: 500 | Loss: 0.902 | Acc: 69.525% | Wgt Acc: 63.946%
	I - Batch: 550 | Loss: 0.906 | Acc: 69.398% | Wgt Acc: 63.633%
	I - Batch: 600 | Loss: 0.911 | Acc: 69.125% | Wgt Acc: 63.378%
	I - Batch: 650 | Loss: 0.911 | Acc: 69.356% | Wgt Acc: 63.566%
	I - Batch: 700 | Loss: 0.911 | Acc: 69.339% | Wgt Acc: 63.474%
	I - Batch: 750 | Loss: 0.910 | Acc: 69.500% | Wgt Acc: 63.508%
	I - Batch: 800 | Loss: 0.911 | Acc: 69.648% | Wgt Acc: 63.673%
	I - Batch: 850 | Loss: 0.912 | Acc: 69.647% | Wgt Acc: 63.671%
I - num batch: 876
I - Train -- Loss: 0.911 | Acc: 69.737% | Wgt Acc: 63.787% | LR: 5.000000e-04 | Dur: 535.54s
I - Confusion Matrix: [row->prediction - col->label]
[[1285.    7.    9.  196.  503.]
 [   9.  335.  285.   39.  128.]
 [  13.  342.  519.   46.  540.]
 [ 251.   80.   95. 1398.  530.]
 [ 328.  163.  427.  247. 6229.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.432 | Acc: 41.250% | Wgt Acc: 40.232%
	I - Batch: 100 | Loss: 1.266 | Acc: 52.500% | Wgt Acc: 46.759%
	I - Batch: 150 | Loss: 1.234 | Acc: 54.292% | Wgt Acc: 47.298%
I - num batch: 193
I - Val -- Loss: 1.236 | Acc: 54.796% | Wgt Acc: 47.568% | Dur: 90.82s
I - Confusion Matrix: [row->prediction - col->label]
[[224.   4.   2.  47.  23.]
 [  8.  98.  72.  33.  32.]
 [ 14. 136. 168.  39. 191.]
 [114.  24.  28. 297.  65.]
 [175. 108. 122. 158. 904.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.842 | Acc: 74.000% | Wgt Acc: 68.636%
	I - Batch: 100 | Loss: 0.853 | Acc: 73.000% | Wgt Acc: 67.356%
	I - Batch: 150 | Loss: 0.856 | Acc: 71.958% | Wgt Acc: 65.617%
	I - Batch: 200 | Loss: 0.862 | Acc: 71.281% | Wgt Acc: 64.754%
	I - Batch: 250 | Loss: 0.862 | Acc: 71.275% | Wgt Acc: 65.036%
	I - Batch: 300 | Loss: 0.863 | Acc: 71.042% | Wgt Acc: 64.945%
	I - Batch: 350 | Loss: 0.862 | Acc: 70.875% | Wgt Acc: 65.148%
	I - Batch: 400 | Loss: 0.865 | Acc: 70.688% | Wgt Acc: 64.938%
	I - Batch: 450 | Loss: 0.867 | Acc: 70.542% | Wgt Acc: 64.645%
	I - Batch: 500 | Loss: 0.865 | Acc: 70.800% | Wgt Acc: 64.933%
	I - Batch: 550 | Loss: 0.867 | Acc: 71.023% | Wgt Acc: 65.169%
	I - Batch: 600 | Loss: 0.873 | Acc: 70.625% | Wgt Acc: 64.815%
	I - Batch: 650 | Loss: 0.871 | Acc: 70.606% | Wgt Acc: 64.775%
	I - Batch: 700 | Loss: 0.871 | Acc: 70.545% | Wgt Acc: 64.790%
	I - Batch: 750 | Loss: 0.871 | Acc: 70.633% | Wgt Acc: 64.751%
	I - Batch: 800 | Loss: 0.873 | Acc: 70.719% | Wgt Acc: 64.812%
	I - Batch: 850 | Loss: 0.876 | Acc: 70.669% | Wgt Acc: 64.740%
I - num batch: 876
I - Train -- Loss: 0.875 | Acc: 70.701% | Wgt Acc: 64.724% | LR: 5.000000e-04 | Dur: 537.98s
I - Confusion Matrix: [row->prediction - col->label]
[[1306.    5.   12.  176.  500.]
 [  10.  355.  310.   37.  119.]
 [   7.  357.  502.   36.  525.]
 [ 239.   65.   78. 1431.  479.]
 [ 324.  145.  433.  246. 6307.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.488 | Acc: 42.750% | Wgt Acc: 41.369%
	I - Batch: 100 | Loss: 1.283 | Acc: 53.750% | Wgt Acc: 47.006%
	I - Batch: 150 | Loss: 1.203 | Acc: 58.042% | Wgt Acc: 49.955%
I - num batch: 193
I - Val -- Loss: 1.204 | Acc: 58.976% | Wgt Acc: 50.556% | Dur: 90.64s
I - Confusion Matrix: [row->prediction - col->label]
[[331.   8.  20. 117.  65.]
 [  1. 122.  96.  22.  33.]
 [  1.  54.  90.   6.  52.]
 [ 77.  39.  39. 293.  81.]
 [125. 147. 147. 136. 984.]]

I - Local maximum validation set accuracy:  58.98

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.838 | Acc: 72.125% | Wgt Acc: 66.184%
	I - Batch: 100 | Loss: 0.807 | Acc: 73.000% | Wgt Acc: 67.472%
	I - Batch: 150 | Loss: 0.780 | Acc: 74.208% | Wgt Acc: 69.198%
	I - Batch: 200 | Loss: 0.776 | Acc: 74.000% | Wgt Acc: 68.836%
	I - Batch: 250 | Loss: 0.774 | Acc: 74.400% | Wgt Acc: 69.271%
	I - Batch: 300 | Loss: 0.774 | Acc: 74.188% | Wgt Acc: 68.917%
	I - Batch: 350 | Loss: 0.761 | Acc: 74.536% | Wgt Acc: 69.493%
	I - Batch: 400 | Loss: 0.766 | Acc: 74.141% | Wgt Acc: 69.113%
	I - Batch: 450 | Loss: 0.768 | Acc: 74.319% | Wgt Acc: 69.293%
	I - Batch: 500 | Loss: 0.767 | Acc: 74.525% | Wgt Acc: 69.531%
	I - Batch: 550 | Loss: 0.765 | Acc: 74.648% | Wgt Acc: 69.702%
	I - Batch: 600 | Loss: 0.767 | Acc: 74.542% | Wgt Acc: 69.574%
	I - Batch: 650 | Loss: 0.767 | Acc: 74.500% | Wgt Acc: 69.602%
	I - Batch: 700 | Loss: 0.769 | Acc: 74.607% | Wgt Acc: 69.696%
	I - Batch: 750 | Loss: 0.766 | Acc: 74.783% | Wgt Acc: 70.025%
	I - Batch: 800 | Loss: 0.765 | Acc: 74.766% | Wgt Acc: 70.087%
	I - Batch: 850 | Loss: 0.761 | Acc: 74.978% | Wgt Acc: 70.351%
I - num batch: 876
I - Train -- Loss: 0.758 | Acc: 75.057% | Wgt Acc: 70.425% | LR: 2.500000e-04 | Dur: 532.57s
I - Confusion Matrix: [row->prediction - col->label]
[[1439.    8.   11.  140.  479.]
 [   4.  511.  371.   28.  103.]
 [  10.  259.  533.   16.  453.]
 [ 154.   35.   56. 1544.  411.]
 [ 279.  114.  364.  198. 6484.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.374 | Acc: 48.500% | Wgt Acc: 47.591%
	I - Batch: 100 | Loss: 1.221 | Acc: 57.125% | Wgt Acc: 52.370%
	I - Batch: 150 | Loss: 1.159 | Acc: 59.500% | Wgt Acc: 53.731%
I - num batch: 193
I - Val -- Loss: 1.177 | Acc: 59.819% | Wgt Acc: 53.844% | Dur: 89.62s
I - Confusion Matrix: [row->prediction - col->label]
[[350.   4.  21. 107.  52.]
 [  5. 151. 110.  34.  40.]
 [  7.  97. 144.  17. 140.]
 [ 64.  22.  23. 283.  65.]
 [109.  96.  94. 133. 918.]]

I - Local maximum validation set accuracy:  59.82

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.665 | Acc: 78.500% | Wgt Acc: 74.542%
	I - Batch: 100 | Loss: 0.672 | Acc: 77.312% | Wgt Acc: 73.422%
	I - Batch: 150 | Loss: 0.657 | Acc: 78.125% | Wgt Acc: 74.490%
	I - Batch: 200 | Loss: 0.670 | Acc: 77.531% | Wgt Acc: 73.365%
	I - Batch: 250 | Loss: 0.680 | Acc: 76.925% | Wgt Acc: 72.623%
	I - Batch: 300 | Loss: 0.679 | Acc: 76.896% | Wgt Acc: 72.706%
	I - Batch: 350 | Loss: 0.682 | Acc: 77.036% | Wgt Acc: 72.936%
	I - Batch: 400 | Loss: 0.682 | Acc: 77.172% | Wgt Acc: 73.248%
	I - Batch: 450 | Loss: 0.686 | Acc: 77.014% | Wgt Acc: 73.149%
	I - Batch: 500 | Loss: 0.690 | Acc: 76.987% | Wgt Acc: 73.102%
	I - Batch: 550 | Loss: 0.692 | Acc: 76.977% | Wgt Acc: 73.117%
	I - Batch: 600 | Loss: 0.694 | Acc: 77.146% | Wgt Acc: 73.333%
	I - Batch: 650 | Loss: 0.690 | Acc: 77.375% | Wgt Acc: 73.511%
	I - Batch: 700 | Loss: 0.694 | Acc: 77.045% | Wgt Acc: 73.126%
	I - Batch: 750 | Loss: 0.693 | Acc: 77.150% | Wgt Acc: 73.234%
	I - Batch: 800 | Loss: 0.693 | Acc: 77.195% | Wgt Acc: 73.291%
	I - Batch: 850 | Loss: 0.691 | Acc: 77.243% | Wgt Acc: 73.307%
I - num batch: 876
I - Train -- Loss: 0.695 | Acc: 77.157% | Wgt Acc: 73.176% | LR: 2.500000e-04 | Dur: 543.17s
I - Confusion Matrix: [row->prediction - col->label]
[[1510.    4.    7.  111.  434.]
 [   4.  508.  351.   24.   70.]
 [   6.  289.  618.   22.  481.]
 [ 122.   32.   44. 1614.  390.]
 [ 244.   94.  315.  155. 6555.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.844 | Acc: 37.000% | Wgt Acc: 35.366%
	I - Batch: 100 | Loss: 1.541 | Acc: 51.375% | Wgt Acc: 42.227%
	I - Batch: 150 | Loss: 1.433 | Acc: 56.750% | Wgt Acc: 45.543%
I - num batch: 193
I - Val -- Loss: 1.428 | Acc: 58.458% | Wgt Acc: 46.450% | Dur: 92.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 282.    4.   10.   68.   27.]
 [   1.   59.   28.   11.   13.]
 [   3.   96.  106.   14.   41.]
 [  81.   22.   15.  255.   32.]
 [ 168.  189.  233.  226. 1102.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.697 | Acc: 76.750% | Wgt Acc: 72.846%
	I - Batch: 100 | Loss: 0.696 | Acc: 76.812% | Wgt Acc: 73.328%
	I - Batch: 150 | Loss: 0.684 | Acc: 77.125% | Wgt Acc: 73.675%
	I - Batch: 200 | Loss: 0.675 | Acc: 77.625% | Wgt Acc: 73.993%
	I - Batch: 250 | Loss: 0.672 | Acc: 78.000% | Wgt Acc: 74.419%
	I - Batch: 300 | Loss: 0.672 | Acc: 77.979% | Wgt Acc: 74.641%
	I - Batch: 350 | Loss: 0.660 | Acc: 78.607% | Wgt Acc: 75.208%
	I - Batch: 400 | Loss: 0.656 | Acc: 78.781% | Wgt Acc: 75.349%
	I - Batch: 450 | Loss: 0.654 | Acc: 78.806% | Wgt Acc: 75.478%
	I - Batch: 500 | Loss: 0.656 | Acc: 78.925% | Wgt Acc: 75.627%
	I - Batch: 550 | Loss: 0.658 | Acc: 79.045% | Wgt Acc: 75.726%
	I - Batch: 600 | Loss: 0.654 | Acc: 79.240% | Wgt Acc: 75.886%
	I - Batch: 650 | Loss: 0.660 | Acc: 79.048% | Wgt Acc: 75.612%
	I - Batch: 700 | Loss: 0.662 | Acc: 78.777% | Wgt Acc: 75.385%
	I - Batch: 750 | Loss: 0.660 | Acc: 78.775% | Wgt Acc: 75.362%
	I - Batch: 800 | Loss: 0.658 | Acc: 78.602% | Wgt Acc: 75.278%
	I - Batch: 850 | Loss: 0.657 | Acc: 78.706% | Wgt Acc: 75.409%
I - num batch: 876
I - Train -- Loss: 0.657 | Acc: 78.656% | Wgt Acc: 75.359% | LR: 2.500000e-04 | Dur: 539.18s
I - Confusion Matrix: [row->prediction - col->label]
[[1534.    1.    9.   89.  444.]
 [   1.  550.  301.   18.   89.]
 [   2.  266.  687.   16.  481.]
 [ 121.   35.   29. 1653.  325.]
 [ 228.   75.  309.  150. 6591.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.883 | Acc: 39.750% | Wgt Acc: 37.979%
	I - Batch: 100 | Loss: 1.572 | Acc: 52.625% | Wgt Acc: 44.735%
	I - Batch: 150 | Loss: 1.436 | Acc: 57.583% | Wgt Acc: 48.372%
I - num batch: 193
I - Val -- Loss: 1.435 | Acc: 58.458% | Wgt Acc: 48.736% | Dur: 91.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 378.   13.   38.  169.   95.]
 [   0.   65.   15.    6.    9.]
 [   3.   78.   94.   12.   42.]
 [  69.   35.   28.  257.   59.]
 [  85.  179.  217.  130. 1010.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.627 | Acc: 79.750% | Wgt Acc: 76.460%
	I - Batch: 100 | Loss: 0.629 | Acc: 79.750% | Wgt Acc: 76.120%
	I - Batch: 150 | Loss: 0.608 | Acc: 80.292% | Wgt Acc: 76.530%
	I - Batch: 200 | Loss: 0.614 | Acc: 79.781% | Wgt Acc: 75.624%
	I - Batch: 250 | Loss: 0.614 | Acc: 79.750% | Wgt Acc: 75.761%
	I - Batch: 300 | Loss: 0.609 | Acc: 80.250% | Wgt Acc: 76.431%
	I - Batch: 350 | Loss: 0.609 | Acc: 80.321% | Wgt Acc: 76.454%
	I - Batch: 400 | Loss: 0.610 | Acc: 80.656% | Wgt Acc: 76.900%
	I - Batch: 450 | Loss: 0.610 | Acc: 80.583% | Wgt Acc: 76.987%
	I - Batch: 500 | Loss: 0.618 | Acc: 80.200% | Wgt Acc: 76.664%
	I - Batch: 550 | Loss: 0.615 | Acc: 80.182% | Wgt Acc: 76.778%
	I - Batch: 600 | Loss: 0.610 | Acc: 80.281% | Wgt Acc: 76.974%
	I - Batch: 650 | Loss: 0.608 | Acc: 80.442% | Wgt Acc: 77.176%
	I - Batch: 700 | Loss: 0.606 | Acc: 80.562% | Wgt Acc: 77.359%
	I - Batch: 750 | Loss: 0.612 | Acc: 80.267% | Wgt Acc: 76.974%
	I - Batch: 800 | Loss: 0.609 | Acc: 80.359% | Wgt Acc: 77.119%
	I - Batch: 850 | Loss: 0.613 | Acc: 80.221% | Wgt Acc: 76.964%
I - num batch: 876
I - Train -- Loss: 0.615 | Acc: 80.249% | Wgt Acc: 76.932% | LR: 2.500000e-04 | Dur: 540.99s
I - Confusion Matrix: [row->prediction - col->label]
[[1568.    0.    4.   80.  400.]
 [   3.  546.  302.   18.   63.]
 [   3.  287.  734.   12.  452.]
 [ 109.   24.   25. 1671.  296.]
 [ 203.   70.  270.  145. 6719.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.877 | Acc: 38.000% | Wgt Acc: 36.645%
	I - Batch: 100 | Loss: 1.594 | Acc: 52.500% | Wgt Acc: 44.301%
	I - Batch: 150 | Loss: 1.472 | Acc: 57.167% | Wgt Acc: 47.419%
I - num batch: 193
I - Val -- Loss: 1.478 | Acc: 58.522% | Wgt Acc: 48.045% | Dur: 92.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 379.   15.   30.  187.   72.]
 [   2.   71.   12.    6.    2.]
 [   5.  107.  145.   14.   65.]
 [  32.    8.    8.  156.   21.]
 [ 117.  169.  197.  211. 1055.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.563 | Acc: 80.875% | Wgt Acc: 78.076%
	I - Batch: 100 | Loss: 0.613 | Acc: 78.562% | Wgt Acc: 76.573%
	I - Batch: 150 | Loss: 0.602 | Acc: 79.625% | Wgt Acc: 77.385%
	I - Batch: 200 | Loss: 0.592 | Acc: 80.031% | Wgt Acc: 77.746%
	I - Batch: 250 | Loss: 0.582 | Acc: 80.675% | Wgt Acc: 78.422%
	I - Batch: 300 | Loss: 0.584 | Acc: 80.604% | Wgt Acc: 78.414%
	I - Batch: 350 | Loss: 0.581 | Acc: 80.732% | Wgt Acc: 78.532%
	I - Batch: 400 | Loss: 0.580 | Acc: 80.812% | Wgt Acc: 78.633%
	I - Batch: 450 | Loss: 0.581 | Acc: 80.903% | Wgt Acc: 78.671%
	I - Batch: 500 | Loss: 0.581 | Acc: 81.013% | Wgt Acc: 78.741%
	I - Batch: 550 | Loss: 0.583 | Acc: 81.057% | Wgt Acc: 78.765%
	I - Batch: 600 | Loss: 0.579 | Acc: 81.104% | Wgt Acc: 78.783%
	I - Batch: 650 | Loss: 0.582 | Acc: 81.029% | Wgt Acc: 78.816%
	I - Batch: 700 | Loss: 0.580 | Acc: 81.116% | Wgt Acc: 78.897%
	I - Batch: 750 | Loss: 0.582 | Acc: 81.133% | Wgt Acc: 78.934%
	I - Batch: 800 | Loss: 0.582 | Acc: 81.117% | Wgt Acc: 78.828%
	I - Batch: 850 | Loss: 0.580 | Acc: 81.265% | Wgt Acc: 78.971%
I - num batch: 876
I - Train -- Loss: 0.582 | Acc: 81.191% | Wgt Acc: 78.815% | LR: 2.500000e-04 | Dur: 547.64s
I - Confusion Matrix: [row->prediction - col->label]
[[1587.    1.    8.   64.  389.]
 [   4.  597.  261.   16.   60.]
 [   5.  252.  800.   12.  489.]
 [  97.   25.   21. 1708.  314.]
 [ 193.   52.  245.  126. 6678.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.656 | Acc: 45.625% | Wgt Acc: 44.147%
	I - Batch: 100 | Loss: 1.420 | Acc: 55.062% | Wgt Acc: 50.171%
	I - Batch: 150 | Loss: 1.345 | Acc: 57.292% | Wgt Acc: 51.392%
I - num batch: 193
I - Val -- Loss: 1.357 | Acc: 58.425% | Wgt Acc: 52.172% | Dur: 92.66s
I - Confusion Matrix: [row->prediction - col->label]
[[431.  22.  40. 235. 141.]
 [  3. 118.  48.  11.  28.]
 [  5.  80. 132.  13.  72.]
 [ 45.  44.  35. 222.  74.]
 [ 51. 106. 137.  93. 900.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.526 | Acc: 84.125% | Wgt Acc: 82.091%
	I - Batch: 100 | Loss: 0.501 | Acc: 84.938% | Wgt Acc: 82.288%
	I - Batch: 150 | Loss: 0.500 | Acc: 84.833% | Wgt Acc: 82.506%
	I - Batch: 200 | Loss: 0.496 | Acc: 84.875% | Wgt Acc: 82.695%
	I - Batch: 250 | Loss: 0.503 | Acc: 84.650% | Wgt Acc: 82.339%
	I - Batch: 300 | Loss: 0.496 | Acc: 84.896% | Wgt Acc: 82.572%
	I - Batch: 350 | Loss: 0.491 | Acc: 85.018% | Wgt Acc: 82.896%
	I - Batch: 400 | Loss: 0.486 | Acc: 85.312% | Wgt Acc: 83.120%
	I - Batch: 450 | Loss: 0.481 | Acc: 85.611% | Wgt Acc: 83.353%
	I - Batch: 500 | Loss: 0.480 | Acc: 85.588% | Wgt Acc: 83.309%
	I - Batch: 550 | Loss: 0.478 | Acc: 85.659% | Wgt Acc: 83.408%
	I - Batch: 600 | Loss: 0.481 | Acc: 85.469% | Wgt Acc: 83.160%
	I - Batch: 650 | Loss: 0.482 | Acc: 85.365% | Wgt Acc: 83.114%
	I - Batch: 700 | Loss: 0.478 | Acc: 85.545% | Wgt Acc: 83.302%
	I - Batch: 750 | Loss: 0.479 | Acc: 85.525% | Wgt Acc: 83.200%
	I - Batch: 800 | Loss: 0.478 | Acc: 85.555% | Wgt Acc: 83.292%
	I - Batch: 850 | Loss: 0.474 | Acc: 85.772% | Wgt Acc: 83.491%
I - num batch: 876
I - Train -- Loss: 0.472 | Acc: 85.868% | Wgt Acc: 83.650% | LR: 1.250000e-04 | Dur: 546.48s
I - Confusion Matrix: [row->prediction - col->label]
[[1686.    1.    5.   42.  315.]
 [   1.  653.  237.   14.   39.]
 [   2.  222.  882.    3.  355.]
 [  59.   17.   10. 1770.  187.]
 [ 138.   34.  201.   97. 7034.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.744 | Acc: 46.500% | Wgt Acc: 45.016%
	I - Batch: 100 | Loss: 1.463 | Acc: 56.375% | Wgt Acc: 50.007%
	I - Batch: 150 | Loss: 1.370 | Acc: 60.083% | Wgt Acc: 52.612%
I - num batch: 193
I - Val -- Loss: 1.378 | Acc: 61.017% | Wgt Acc: 52.968% | Dur: 92.72s
I - Confusion Matrix: [row->prediction - col->label]
[[373.  10.  29. 116.  73.]
 [  4. 105.  33.  11.  21.]
 [  2.  83. 126.  14.  64.]
 [ 67.  37.  34. 288.  66.]
 [ 89. 135. 170. 145. 991.]]

I - Local maximum validation set accuracy:  61.02

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.428 | Acc: 87.500% | Wgt Acc: 85.187%
	I - Batch: 100 | Loss: 0.427 | Acc: 86.812% | Wgt Acc: 85.021%
	I - Batch: 150 | Loss: 0.410 | Acc: 87.917% | Wgt Acc: 86.076%
	I - Batch: 200 | Loss: 0.397 | Acc: 88.250% | Wgt Acc: 86.478%
	I - Batch: 250 | Loss: 0.407 | Acc: 87.975% | Wgt Acc: 86.171%
	I - Batch: 300 | Loss: 0.404 | Acc: 88.333% | Wgt Acc: 86.506%
	I - Batch: 350 | Loss: 0.413 | Acc: 87.929% | Wgt Acc: 86.140%
	I - Batch: 400 | Loss: 0.413 | Acc: 88.031% | Wgt Acc: 86.283%
	I - Batch: 450 | Loss: 0.420 | Acc: 87.764% | Wgt Acc: 85.954%
	I - Batch: 500 | Loss: 0.424 | Acc: 87.775% | Wgt Acc: 86.035%
	I - Batch: 550 | Loss: 0.421 | Acc: 87.886% | Wgt Acc: 86.194%
	I - Batch: 600 | Loss: 0.420 | Acc: 87.865% | Wgt Acc: 86.120%
	I - Batch: 650 | Loss: 0.417 | Acc: 87.971% | Wgt Acc: 86.256%
	I - Batch: 700 | Loss: 0.417 | Acc: 88.036% | Wgt Acc: 86.262%
	I - Batch: 750 | Loss: 0.417 | Acc: 88.067% | Wgt Acc: 86.401%
	I - Batch: 800 | Loss: 0.418 | Acc: 87.969% | Wgt Acc: 86.284%
	I - Batch: 850 | Loss: 0.418 | Acc: 87.963% | Wgt Acc: 86.330%
I - num batch: 876
I - Train -- Loss: 0.419 | Acc: 87.918% | Wgt Acc: 86.284% | LR: 1.250000e-04 | Dur: 546.79s
I - Confusion Matrix: [row->prediction - col->label]
[[1727.    4.    3.   24.  259.]
 [   1.  683.  201.   12.   38.]
 [   2.  193.  953.    1.  344.]
 [  35.   10.    8. 1828.  168.]
 [ 121.   37.  170.   61. 7121.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.834 | Acc: 42.625% | Wgt Acc: 41.637%
	I - Batch: 100 | Loss: 1.526 | Acc: 54.250% | Wgt Acc: 47.581%
	I - Batch: 150 | Loss: 1.440 | Acc: 58.083% | Wgt Acc: 50.234%
I - num batch: 193
I - Val -- Loss: 1.455 | Acc: 59.170% | Wgt Acc: 50.570% | Dur: 92.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 346.    9.   30.  129.   63.]
 [   6.  102.   13.   13.   17.]
 [   7.  113.  166.   25.   90.]
 [  51.   15.   17.  209.   42.]
 [ 125.  131.  166.  198. 1003.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.401 | Acc: 88.125% | Wgt Acc: 86.561%
	I - Batch: 100 | Loss: 0.404 | Acc: 87.938% | Wgt Acc: 86.333%
	I - Batch: 150 | Loss: 0.397 | Acc: 88.542% | Wgt Acc: 86.878%
	I - Batch: 200 | Loss: 0.399 | Acc: 88.438% | Wgt Acc: 86.912%
	I - Batch: 250 | Loss: 0.392 | Acc: 88.775% | Wgt Acc: 87.134%
	I - Batch: 300 | Loss: 0.395 | Acc: 88.708% | Wgt Acc: 87.259%
	I - Batch: 350 | Loss: 0.392 | Acc: 88.821% | Wgt Acc: 87.518%
	I - Batch: 400 | Loss: 0.396 | Acc: 88.766% | Wgt Acc: 87.500%
	I - Batch: 450 | Loss: 0.398 | Acc: 88.764% | Wgt Acc: 87.384%
	I - Batch: 500 | Loss: 0.399 | Acc: 88.750% | Wgt Acc: 87.342%
	I - Batch: 550 | Loss: 0.399 | Acc: 88.727% | Wgt Acc: 87.363%
	I - Batch: 600 | Loss: 0.399 | Acc: 88.667% | Wgt Acc: 87.319%
	I - Batch: 650 | Loss: 0.400 | Acc: 88.654% | Wgt Acc: 87.255%
	I - Batch: 700 | Loss: 0.400 | Acc: 88.607% | Wgt Acc: 87.206%
	I - Batch: 750 | Loss: 0.399 | Acc: 88.617% | Wgt Acc: 87.217%
	I - Batch: 800 | Loss: 0.397 | Acc: 88.555% | Wgt Acc: 87.289%
	I - Batch: 850 | Loss: 0.397 | Acc: 88.625% | Wgt Acc: 87.285%
I - num batch: 876
I - Train -- Loss: 0.398 | Acc: 88.575% | Wgt Acc: 87.264% | LR: 1.250000e-04 | Dur: 546.38s
I - Confusion Matrix: [row->prediction - col->label]
[[1728.    1.    2.   20.  256.]
 [   0.  701.  162.    5.   34.]
 [   1.  197. 1000.    1.  346.]
 [  40.    8.    6. 1838.  157.]
 [ 117.   20.  165.   62. 7137.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.788 | Acc: 49.000% | Wgt Acc: 47.591%
	I - Batch: 100 | Loss: 1.498 | Acc: 57.000% | Wgt Acc: 51.229%
	I - Batch: 150 | Loss: 1.417 | Acc: 60.375% | Wgt Acc: 53.411%
I - num batch: 193
I - Val -- Loss: 1.418 | Acc: 61.147% | Wgt Acc: 53.741% | Dur: 92.60s
I - Confusion Matrix: [row->prediction - col->label]
[[350.   9.  29. 115.  62.]
 [ 12. 123.  44.  19.  26.]
 [  3.  52. 124.  10.  58.]
 [ 80.  64.  36. 317.  96.]
 [ 90. 122. 159. 113. 973.]]

I - Local maximum validation set accuracy:  61.15

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.362 | Acc: 89.625% | Wgt Acc: 88.392%
	I - Batch: 100 | Loss: 0.345 | Acc: 90.188% | Wgt Acc: 89.511%
	I - Batch: 150 | Loss: 0.353 | Acc: 90.417% | Wgt Acc: 89.559%
	I - Batch: 200 | Loss: 0.346 | Acc: 90.656% | Wgt Acc: 89.634%
	I - Batch: 250 | Loss: 0.362 | Acc: 89.850% | Wgt Acc: 88.653%
	I - Batch: 300 | Loss: 0.367 | Acc: 89.625% | Wgt Acc: 88.357%
	I - Batch: 350 | Loss: 0.362 | Acc: 89.964% | Wgt Acc: 88.762%
	I - Batch: 400 | Loss: 0.367 | Acc: 89.766% | Wgt Acc: 88.495%
	I - Batch: 450 | Loss: 0.366 | Acc: 89.694% | Wgt Acc: 88.452%
	I - Batch: 500 | Loss: 0.364 | Acc: 89.713% | Wgt Acc: 88.571%
	I - Batch: 550 | Loss: 0.362 | Acc: 89.784% | Wgt Acc: 88.756%
	I - Batch: 600 | Loss: 0.367 | Acc: 89.667% | Wgt Acc: 88.535%
	I - Batch: 650 | Loss: 0.369 | Acc: 89.596% | Wgt Acc: 88.427%
	I - Batch: 700 | Loss: 0.367 | Acc: 89.652% | Wgt Acc: 88.448%
	I - Batch: 750 | Loss: 0.366 | Acc: 89.575% | Wgt Acc: 88.429%
	I - Batch: 800 | Loss: 0.367 | Acc: 89.625% | Wgt Acc: 88.485%
	I - Batch: 850 | Loss: 0.368 | Acc: 89.618% | Wgt Acc: 88.452%
I - num batch: 876
I - Train -- Loss: 0.369 | Acc: 89.560% | Wgt Acc: 88.385% | LR: 1.250000e-04 | Dur: 541.08s
I - Confusion Matrix: [row->prediction - col->label]
[[1753.    1.    0.   24.  238.]
 [   1.  747.  170.    6.   25.]
 [   4.  152. 1007.    3.  302.]
 [  34.    5.    9. 1828.  158.]
 [  94.   22.  149.   65. 7207.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.708 | Acc: 48.750% | Wgt Acc: 47.991%
	I - Batch: 100 | Loss: 1.474 | Acc: 56.875% | Wgt Acc: 52.087%
	I - Batch: 150 | Loss: 1.422 | Acc: 58.667% | Wgt Acc: 53.142%
I - num batch: 193
I - Val -- Loss: 1.445 | Acc: 58.782% | Wgt Acc: 52.807% | Dur: 91.37s
I - Confusion Matrix: [row->prediction - col->label]
[[327.  13.  33. 119.  65.]
 [ 10. 153.  57.  33.  43.]
 [  9.  80. 150.  17. 105.]
 [ 79.  32.  29. 274.  92.]
 [110.  92. 123. 131. 910.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.358 | Acc: 89.625% | Wgt Acc: 88.843%
	I - Batch: 100 | Loss: 0.348 | Acc: 89.750% | Wgt Acc: 88.914%
	I - Batch: 150 | Loss: 0.339 | Acc: 90.375% | Wgt Acc: 89.066%
	I - Batch: 200 | Loss: 0.327 | Acc: 90.875% | Wgt Acc: 89.548%
	I - Batch: 250 | Loss: 0.334 | Acc: 90.375% | Wgt Acc: 89.341%
	I - Batch: 300 | Loss: 0.333 | Acc: 90.625% | Wgt Acc: 89.587%
	I - Batch: 350 | Loss: 0.335 | Acc: 90.696% | Wgt Acc: 89.639%
	I - Batch: 400 | Loss: 0.335 | Acc: 90.781% | Wgt Acc: 89.636%
	I - Batch: 450 | Loss: 0.331 | Acc: 90.778% | Wgt Acc: 89.664%
	I - Batch: 500 | Loss: 0.335 | Acc: 90.662% | Wgt Acc: 89.504%
	I - Batch: 550 | Loss: 0.340 | Acc: 90.466% | Wgt Acc: 89.316%
	I - Batch: 600 | Loss: 0.337 | Acc: 90.458% | Wgt Acc: 89.351%
	I - Batch: 650 | Loss: 0.339 | Acc: 90.337% | Wgt Acc: 89.241%
	I - Batch: 700 | Loss: 0.336 | Acc: 90.438% | Wgt Acc: 89.439%
	I - Batch: 750 | Loss: 0.336 | Acc: 90.533% | Wgt Acc: 89.503%
	I - Batch: 800 | Loss: 0.336 | Acc: 90.570% | Wgt Acc: 89.544%
	I - Batch: 850 | Loss: 0.337 | Acc: 90.529% | Wgt Acc: 89.536%
I - num batch: 876
I - Train -- Loss: 0.339 | Acc: 90.510% | Wgt Acc: 89.492% | LR: 1.250000e-04 | Dur: 545.08s
I - Confusion Matrix: [row->prediction - col->label]
[[1749.    1.    2.   21.  206.]
 [   1.  741.  126.    6.   27.]
 [   2.  158. 1074.    1.  292.]
 [  32.    9.    2. 1846.  140.]
 [ 102.   18.  131.   52. 7265.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.818 | Acc: 47.750% | Wgt Acc: 46.957%
	I - Batch: 100 | Loss: 1.516 | Acc: 57.062% | Wgt Acc: 51.768%
	I - Batch: 150 | Loss: 1.453 | Acc: 59.375% | Wgt Acc: 53.111%
I - num batch: 193
I - Val -- Loss: 1.462 | Acc: 60.045% | Wgt Acc: 53.329% | Dur: 92.16s
I - Confusion Matrix: [row->prediction - col->label]
[[349.  16.  31. 147.  79.]
 [  4. 143.  39.  14.  25.]
 [  4.  79. 162.  18. 102.]
 [ 67.  35.  26. 248.  58.]
 [111.  97. 134. 147. 951.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.306 | Acc: 92.375% | Wgt Acc: 91.684%
	I - Batch: 100 | Loss: 0.301 | Acc: 92.062% | Wgt Acc: 91.295%
	I - Batch: 150 | Loss: 0.312 | Acc: 91.792% | Wgt Acc: 90.585%
	I - Batch: 200 | Loss: 0.308 | Acc: 91.812% | Wgt Acc: 90.627%
	I - Batch: 250 | Loss: 0.308 | Acc: 91.575% | Wgt Acc: 90.486%
	I - Batch: 300 | Loss: 0.311 | Acc: 91.375% | Wgt Acc: 90.367%
	I - Batch: 350 | Loss: 0.317 | Acc: 91.321% | Wgt Acc: 90.285%
	I - Batch: 400 | Loss: 0.320 | Acc: 91.297% | Wgt Acc: 90.290%
	I - Batch: 450 | Loss: 0.317 | Acc: 91.361% | Wgt Acc: 90.456%
	I - Batch: 500 | Loss: 0.317 | Acc: 91.300% | Wgt Acc: 90.505%
	I - Batch: 550 | Loss: 0.320 | Acc: 91.148% | Wgt Acc: 90.348%
	I - Batch: 600 | Loss: 0.318 | Acc: 91.167% | Wgt Acc: 90.451%
	I - Batch: 650 | Loss: 0.316 | Acc: 91.240% | Wgt Acc: 90.539%
	I - Batch: 700 | Loss: 0.318 | Acc: 91.286% | Wgt Acc: 90.521%
	I - Batch: 750 | Loss: 0.321 | Acc: 91.075% | Wgt Acc: 90.336%
	I - Batch: 800 | Loss: 0.322 | Acc: 91.023% | Wgt Acc: 90.273%
	I - Batch: 850 | Loss: 0.320 | Acc: 91.051% | Wgt Acc: 90.347%
I - num batch: 876
I - Train -- Loss: 0.319 | Acc: 91.088% | Wgt Acc: 90.361% | LR: 1.250000e-04 | Dur: 539.01s
I - Confusion Matrix: [row->prediction - col->label]
[[1765.    1.    1.   19.  195.]
 [   1.  768.  119.    3.   31.]
 [   1.  132. 1092.    2.  279.]
 [  30.    9.    4. 1854.  148.]
 [  89.   17.  119.   48. 7277.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.852 | Acc: 46.000% | Wgt Acc: 45.907%
	I - Batch: 100 | Loss: 1.558 | Acc: 57.062% | Wgt Acc: 51.430%
	I - Batch: 150 | Loss: 1.513 | Acc: 59.167% | Wgt Acc: 52.351%
I - num batch: 193
I - Val -- Loss: 1.537 | Acc: 59.689% | Wgt Acc: 52.165% | Dur: 91.10s
I - Confusion Matrix: [row->prediction - col->label]
[[298.   8.  23. 100.  41.]
 [  8. 188.  78.  37.  42.]
 [  7.  52. 131.  13.  92.]
 [ 78.  19.  22. 235.  50.]
 [144. 103. 138. 189. 990.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.300 | Acc: 91.000% | Wgt Acc: 90.056%
	I - Batch: 100 | Loss: 0.321 | Acc: 90.062% | Wgt Acc: 89.424%
	I - Batch: 150 | Loss: 0.316 | Acc: 91.125% | Wgt Acc: 90.211%
	I - Batch: 200 | Loss: 0.316 | Acc: 90.656% | Wgt Acc: 89.696%
	I - Batch: 250 | Loss: 0.318 | Acc: 90.825% | Wgt Acc: 90.005%
	I - Batch: 300 | Loss: 0.313 | Acc: 91.062% | Wgt Acc: 90.343%
	I - Batch: 350 | Loss: 0.312 | Acc: 91.125% | Wgt Acc: 90.544%
	I - Batch: 400 | Loss: 0.309 | Acc: 91.312% | Wgt Acc: 90.774%
	I - Batch: 450 | Loss: 0.304 | Acc: 91.556% | Wgt Acc: 91.012%
	I - Batch: 500 | Loss: 0.305 | Acc: 91.500% | Wgt Acc: 90.953%
	I - Batch: 550 | Loss: 0.308 | Acc: 91.432% | Wgt Acc: 90.896%
	I - Batch: 600 | Loss: 0.311 | Acc: 91.312% | Wgt Acc: 90.750%
	I - Batch: 650 | Loss: 0.309 | Acc: 91.317% | Wgt Acc: 90.800%
	I - Batch: 700 | Loss: 0.306 | Acc: 91.411% | Wgt Acc: 90.909%
	I - Batch: 750 | Loss: 0.305 | Acc: 91.442% | Wgt Acc: 90.916%
	I - Batch: 800 | Loss: 0.304 | Acc: 91.539% | Wgt Acc: 91.031%
	I - Batch: 850 | Loss: 0.304 | Acc: 91.485% | Wgt Acc: 90.965%
I - num batch: 876
I - Train -- Loss: 0.305 | Acc: 91.495% | Wgt Acc: 90.988% | LR: 1.250000e-04 | Dur: 537.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1768.    1.    2.   26.  198.]
 [   0.  790.  100.    5.   22.]
 [   0.  103. 1117.    0.  293.]
 [  27.   17.    4. 1851.  130.]
 [  91.   16.  112.   44. 7287.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.215 | Acc: 39.375% | Wgt Acc: 38.444%
	I - Batch: 100 | Loss: 1.817 | Acc: 53.938% | Wgt Acc: 46.385%
	I - Batch: 150 | Loss: 1.682 | Acc: 57.875% | Wgt Acc: 49.081%
I - num batch: 193
I - Val -- Loss: 1.685 | Acc: 59.008% | Wgt Acc: 49.569% | Dur: 90.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 286.    6.   13.  101.   32.]
 [   4.   96.   21.   17.   11.]
 [  10.   96.  163.   20.   96.]
 [  71.   13.   19.  244.   44.]
 [ 164.  159.  176.  192. 1032.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.276 | Acc: 92.250% | Wgt Acc: 91.426%
	I - Batch: 100 | Loss: 0.275 | Acc: 92.875% | Wgt Acc: 92.025%
	I - Batch: 150 | Loss: 0.272 | Acc: 92.917% | Wgt Acc: 92.298%
	I - Batch: 200 | Loss: 0.275 | Acc: 92.656% | Wgt Acc: 91.983%
	I - Batch: 250 | Loss: 0.275 | Acc: 92.700% | Wgt Acc: 92.142%
	I - Batch: 300 | Loss: 0.275 | Acc: 92.604% | Wgt Acc: 91.939%
	I - Batch: 350 | Loss: 0.275 | Acc: 92.821% | Wgt Acc: 92.126%
	I - Batch: 400 | Loss: 0.270 | Acc: 92.797% | Wgt Acc: 92.121%
	I - Batch: 450 | Loss: 0.266 | Acc: 92.972% | Wgt Acc: 92.353%
	I - Batch: 500 | Loss: 0.267 | Acc: 92.888% | Wgt Acc: 92.336%
	I - Batch: 550 | Loss: 0.269 | Acc: 92.818% | Wgt Acc: 92.252%
	I - Batch: 600 | Loss: 0.269 | Acc: 92.792% | Wgt Acc: 92.247%
	I - Batch: 650 | Loss: 0.269 | Acc: 92.788% | Wgt Acc: 92.288%
	I - Batch: 700 | Loss: 0.269 | Acc: 92.723% | Wgt Acc: 92.236%
	I - Batch: 750 | Loss: 0.272 | Acc: 92.700% | Wgt Acc: 92.187%
	I - Batch: 800 | Loss: 0.272 | Acc: 92.711% | Wgt Acc: 92.212%
	I - Batch: 850 | Loss: 0.278 | Acc: 92.588% | Wgt Acc: 92.052%
I - num batch: 876
I - Train -- Loss: 0.277 | Acc: 92.581% | Wgt Acc: 92.079% | LR: 1.250000e-04 | Dur: 537.76s
I - Confusion Matrix: [row->prediction - col->label]
[[1780.    0.    1.   19.  187.]
 [   1.  803.   98.    1.   26.]
 [   0.  102. 1143.    1.  223.]
 [  28.    8.    3. 1863.  118.]
 [  77.   14.   90.   42. 7376.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.807 | Acc: 47.250% | Wgt Acc: 46.919%
	I - Batch: 100 | Loss: 1.539 | Acc: 56.188% | Wgt Acc: 52.021%
	I - Batch: 150 | Loss: 1.488 | Acc: 58.042% | Wgt Acc: 53.056%
I - num batch: 193
I - Val -- Loss: 1.511 | Acc: 58.555% | Wgt Acc: 53.331% | Dur: 91.03s
I - Confusion Matrix: [row->prediction - col->label]
[[296.   7.  18.  76.  53.]
 [  9. 160.  54.  49.  49.]
 [ 13.  84. 183.  27. 155.]
 [ 90.  25.  22. 280.  70.]
 [127.  94. 115. 142. 888.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.246 | Acc: 93.750% | Wgt Acc: 92.951%
	I - Batch: 100 | Loss: 0.253 | Acc: 93.562% | Wgt Acc: 93.310%
	I - Batch: 150 | Loss: 0.248 | Acc: 93.625% | Wgt Acc: 93.269%
	I - Batch: 200 | Loss: 0.252 | Acc: 93.562% | Wgt Acc: 93.037%
	I - Batch: 250 | Loss: 0.256 | Acc: 93.300% | Wgt Acc: 92.694%
	I - Batch: 300 | Loss: 0.258 | Acc: 93.271% | Wgt Acc: 92.635%
	I - Batch: 350 | Loss: 0.254 | Acc: 93.304% | Wgt Acc: 92.722%
	I - Batch: 400 | Loss: 0.250 | Acc: 93.312% | Wgt Acc: 92.731%
	I - Batch: 450 | Loss: 0.251 | Acc: 93.417% | Wgt Acc: 92.806%
	I - Batch: 500 | Loss: 0.249 | Acc: 93.475% | Wgt Acc: 92.918%
	I - Batch: 550 | Loss: 0.247 | Acc: 93.557% | Wgt Acc: 93.012%
	I - Batch: 600 | Loss: 0.247 | Acc: 93.531% | Wgt Acc: 92.998%
	I - Batch: 650 | Loss: 0.252 | Acc: 93.327% | Wgt Acc: 92.807%
	I - Batch: 700 | Loss: 0.253 | Acc: 93.223% | Wgt Acc: 92.668%
	I - Batch: 750 | Loss: 0.253 | Acc: 93.142% | Wgt Acc: 92.615%
	I - Batch: 800 | Loss: 0.256 | Acc: 92.977% | Wgt Acc: 92.455%
	I - Batch: 850 | Loss: 0.259 | Acc: 92.919% | Wgt Acc: 92.359%
I - num batch: 876
I - Train -- Loss: 0.260 | Acc: 92.873% | Wgt Acc: 92.312% | LR: 1.250000e-04 | Dur: 537.02s
I - Confusion Matrix: [row->prediction - col->label]
[[1803.    1.    0.   13.  168.]
 [   1.  815.  107.    4.   18.]
 [   0.   91. 1121.    2.  215.]
 [  17.    7.    3. 1861.  123.]
 [  65.   13.  104.   46. 7406.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.884 | Acc: 47.250% | Wgt Acc: 46.602%
	I - Batch: 100 | Loss: 1.640 | Acc: 56.500% | Wgt Acc: 51.509%
	I - Batch: 150 | Loss: 1.591 | Acc: 57.625% | Wgt Acc: 51.972%
I - num batch: 193
I - Val -- Loss: 1.609 | Acc: 57.907% | Wgt Acc: 51.903% | Dur: 90.61s
I - Confusion Matrix: [row->prediction - col->label]
[[303.  10.  16.  91.  50.]
 [  5. 119.  27.  35.  27.]
 [ 18. 129. 213.  31. 193.]
 [ 79.  16.  20. 248.  41.]
 [130.  96. 116. 169. 904.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.248 | Acc: 93.000% | Wgt Acc: 92.152%
	I - Batch: 100 | Loss: 0.232 | Acc: 93.562% | Wgt Acc: 92.877%
	I - Batch: 150 | Loss: 0.232 | Acc: 93.833% | Wgt Acc: 93.134%
	I - Batch: 200 | Loss: 0.230 | Acc: 94.125% | Wgt Acc: 93.560%
	I - Batch: 250 | Loss: 0.230 | Acc: 94.050% | Wgt Acc: 93.603%
	I - Batch: 300 | Loss: 0.234 | Acc: 94.000% | Wgt Acc: 93.492%
	I - Batch: 350 | Loss: 0.240 | Acc: 93.857% | Wgt Acc: 93.328%
	I - Batch: 400 | Loss: 0.242 | Acc: 93.922% | Wgt Acc: 93.445%
	I - Batch: 450 | Loss: 0.244 | Acc: 93.819% | Wgt Acc: 93.275%
	I - Batch: 500 | Loss: 0.246 | Acc: 93.650% | Wgt Acc: 93.068%
	I - Batch: 550 | Loss: 0.248 | Acc: 93.602% | Wgt Acc: 92.959%
	I - Batch: 600 | Loss: 0.249 | Acc: 93.469% | Wgt Acc: 92.850%
	I - Batch: 650 | Loss: 0.248 | Acc: 93.404% | Wgt Acc: 92.816%
	I - Batch: 700 | Loss: 0.247 | Acc: 93.482% | Wgt Acc: 92.933%
	I - Batch: 750 | Loss: 0.250 | Acc: 93.400% | Wgt Acc: 92.832%
	I - Batch: 800 | Loss: 0.251 | Acc: 93.375% | Wgt Acc: 92.792%
	I - Batch: 850 | Loss: 0.252 | Acc: 93.331% | Wgt Acc: 92.749%
I - num batch: 876
I - Train -- Loss: 0.253 | Acc: 93.316% | Wgt Acc: 92.762% | LR: 1.250000e-04 | Dur: 536.72s
I - Confusion Matrix: [row->prediction - col->label]
[[1797.    0.    1.   14.  170.]
 [   1.  799.   84.    4.   22.]
 [   0.  111. 1165.    1.  185.]
 [  15.    7.    5. 1866.  112.]
 [  73.   10.   80.   41. 7441.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.823 | Acc: 51.750% | Wgt Acc: 50.440%
	I - Batch: 100 | Loss: 1.611 | Acc: 56.375% | Wgt Acc: 53.257%
	I - Batch: 150 | Loss: 1.537 | Acc: 58.458% | Wgt Acc: 54.703%
I - num batch: 193
I - Val -- Loss: 1.553 | Acc: 58.425% | Wgt Acc: 54.415% | Dur: 90.75s
I - Confusion Matrix: [row->prediction - col->label]
[[426.  29.  45. 175. 170.]
 [  5. 161.  66.  19.  49.]
 [  1.  27.  94.   2.  33.]
 [ 54.  82.  57. 304. 145.]
 [ 49.  71. 130.  74. 818.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.232 | Acc: 95.125% | Wgt Acc: 94.366%
	I - Batch: 100 | Loss: 0.237 | Acc: 94.375% | Wgt Acc: 93.634%
	I - Batch: 150 | Loss: 0.231 | Acc: 94.375% | Wgt Acc: 93.708%
	I - Batch: 200 | Loss: 0.239 | Acc: 94.062% | Wgt Acc: 93.346%
	I - Batch: 250 | Loss: 0.242 | Acc: 93.825% | Wgt Acc: 93.137%
	I - Batch: 300 | Loss: 0.240 | Acc: 93.896% | Wgt Acc: 93.209%
	I - Batch: 350 | Loss: 0.233 | Acc: 94.179% | Wgt Acc: 93.602%
	I - Batch: 400 | Loss: 0.231 | Acc: 94.172% | Wgt Acc: 93.697%
	I - Batch: 450 | Loss: 0.227 | Acc: 94.278% | Wgt Acc: 93.808%
	I - Batch: 500 | Loss: 0.228 | Acc: 94.150% | Wgt Acc: 93.573%
	I - Batch: 550 | Loss: 0.227 | Acc: 94.102% | Wgt Acc: 93.580%
	I - Batch: 600 | Loss: 0.226 | Acc: 94.021% | Wgt Acc: 93.647%
	I - Batch: 650 | Loss: 0.227 | Acc: 93.962% | Wgt Acc: 93.629%
	I - Batch: 700 | Loss: 0.227 | Acc: 93.964% | Wgt Acc: 93.620%
	I - Batch: 750 | Loss: 0.228 | Acc: 93.917% | Wgt Acc: 93.574%
	I - Batch: 800 | Loss: 0.229 | Acc: 93.875% | Wgt Acc: 93.566%
	I - Batch: 850 | Loss: 0.229 | Acc: 93.853% | Wgt Acc: 93.523%
I - num batch: 876
I - Train -- Loss: 0.228 | Acc: 93.923% | Wgt Acc: 93.597% | LR: 1.250000e-04 | Dur: 547.05s
I - Confusion Matrix: [row->prediction - col->label]
[[1805.    1.    1.   12.  152.]
 [   0.  837.   78.    5.   23.]
 [   0.   74. 1175.    0.  190.]
 [  16.    3.    2. 1869.   98.]
 [  65.   12.   79.   40. 7467.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.790 | Acc: 50.625% | Wgt Acc: 49.773%
	I - Batch: 100 | Loss: 1.630 | Acc: 55.438% | Wgt Acc: 52.389%
	I - Batch: 150 | Loss: 1.579 | Acc: 56.458% | Wgt Acc: 53.051%
I - num batch: 193
I - Val -- Loss: 1.601 | Acc: 56.643% | Wgt Acc: 52.864% | Dur: 92.99s
I - Confusion Matrix: [row->prediction - col->label]
[[327.  17.  33.  95. 110.]
 [  7. 162.  58.  34.  54.]
 [  8.  64. 139.  16. 108.]
 [104.  53.  38. 318. 141.]
 [ 89.  74. 124. 111. 802.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.185 | Acc: 96.000% | Wgt Acc: 95.772%
	I - Batch: 100 | Loss: 0.209 | Acc: 94.875% | Wgt Acc: 94.608%
	I - Batch: 150 | Loss: 0.214 | Acc: 94.667% | Wgt Acc: 94.594%
	I - Batch: 200 | Loss: 0.204 | Acc: 94.938% | Wgt Acc: 94.842%
	I - Batch: 250 | Loss: 0.214 | Acc: 94.425% | Wgt Acc: 94.264%
	I - Batch: 300 | Loss: 0.219 | Acc: 94.250% | Wgt Acc: 93.906%
	I - Batch: 350 | Loss: 0.225 | Acc: 94.089% | Wgt Acc: 93.778%
	I - Batch: 400 | Loss: 0.227 | Acc: 93.844% | Wgt Acc: 93.524%
	I - Batch: 450 | Loss: 0.226 | Acc: 93.903% | Wgt Acc: 93.643%
	I - Batch: 500 | Loss: 0.224 | Acc: 93.912% | Wgt Acc: 93.694%
	I - Batch: 550 | Loss: 0.223 | Acc: 93.977% | Wgt Acc: 93.760%
	I - Batch: 600 | Loss: 0.222 | Acc: 93.979% | Wgt Acc: 93.781%
	I - Batch: 650 | Loss: 0.221 | Acc: 93.981% | Wgt Acc: 93.830%
	I - Batch: 700 | Loss: 0.222 | Acc: 93.946% | Wgt Acc: 93.775%
	I - Batch: 750 | Loss: 0.221 | Acc: 93.992% | Wgt Acc: 93.753%
	I - Batch: 800 | Loss: 0.224 | Acc: 93.906% | Wgt Acc: 93.601%
	I - Batch: 850 | Loss: 0.224 | Acc: 93.912% | Wgt Acc: 93.612%
I - num batch: 876
I - Train -- Loss: 0.224 | Acc: 93.916% | Wgt Acc: 93.616% | LR: 1.250000e-04 | Dur: 546.39s
I - Confusion Matrix: [row->prediction - col->label]
[[1809.    1.    2.   12.  141.]
 [   2.  836.   66.    6.   22.]
 [   0.   75. 1183.    2.  195.]
 [  14.    5.    2. 1860.  108.]
 [  61.   10.   82.   46. 7464.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.048 | Acc: 46.000% | Wgt Acc: 44.601%
	I - Batch: 100 | Loss: 1.736 | Acc: 55.312% | Wgt Acc: 49.809%
	I - Batch: 150 | Loss: 1.669 | Acc: 56.958% | Wgt Acc: 50.957%
I - num batch: 193
I - Val -- Loss: 1.676 | Acc: 57.842% | Wgt Acc: 51.258% | Dur: 91.79s
I - Confusion Matrix: [row->prediction - col->label]
[[341.  11.  30. 112.  80.]
 [  2.  83.  15.  17.  10.]
 [  8. 134. 188.  24. 152.]
 [ 78.  33.  26. 266.  66.]
 [106. 109. 133. 155. 907.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.216 | Acc: 94.000% | Wgt Acc: 93.992%
	I - Batch: 100 | Loss: 0.208 | Acc: 94.250% | Wgt Acc: 94.223%
	I - Batch: 150 | Loss: 0.200 | Acc: 94.583% | Wgt Acc: 94.480%
	I - Batch: 200 | Loss: 0.206 | Acc: 94.750% | Wgt Acc: 94.528%
	I - Batch: 250 | Loss: 0.208 | Acc: 94.775% | Wgt Acc: 94.382%
	I - Batch: 300 | Loss: 0.209 | Acc: 94.646% | Wgt Acc: 94.226%
	I - Batch: 350 | Loss: 0.206 | Acc: 94.696% | Wgt Acc: 94.344%
	I - Batch: 400 | Loss: 0.204 | Acc: 94.781% | Wgt Acc: 94.438%
	I - Batch: 450 | Loss: 0.203 | Acc: 94.764% | Wgt Acc: 94.481%
	I - Batch: 500 | Loss: 0.201 | Acc: 94.737% | Wgt Acc: 94.452%
	I - Batch: 550 | Loss: 0.200 | Acc: 94.750% | Wgt Acc: 94.491%
	I - Batch: 600 | Loss: 0.197 | Acc: 94.833% | Wgt Acc: 94.629%
	I - Batch: 650 | Loss: 0.197 | Acc: 94.808% | Wgt Acc: 94.616%
	I - Batch: 700 | Loss: 0.197 | Acc: 94.830% | Wgt Acc: 94.648%
	I - Batch: 750 | Loss: 0.198 | Acc: 94.808% | Wgt Acc: 94.650%
	I - Batch: 800 | Loss: 0.199 | Acc: 94.828% | Wgt Acc: 94.687%
	I - Batch: 850 | Loss: 0.201 | Acc: 94.816% | Wgt Acc: 94.628%
I - num batch: 876
I - Train -- Loss: 0.202 | Acc: 94.773% | Wgt Acc: 94.582% | LR: 1.250000e-04 | Dur: 544.07s
I - Confusion Matrix: [row->prediction - col->label]
[[1818.    1.    1.    7.  132.]
 [   0.  859.   65.    4.   21.]
 [   0.   49. 1186.    1.  173.]
 [  10.    9.    2. 1890.   85.]
 [  58.    9.   81.   24. 7519.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.508 | Acc: 37.875% | Wgt Acc: 37.394%
	I - Batch: 100 | Loss: 2.082 | Acc: 52.062% | Wgt Acc: 44.423%
	I - Batch: 150 | Loss: 1.945 | Acc: 56.417% | Wgt Acc: 47.221%
I - num batch: 193
I - Val -- Loss: 1.936 | Acc: 58.263% | Wgt Acc: 48.289% | Dur: 92.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 250.    2.   11.   72.   16.]
 [   0.  121.   23.   20.   15.]
 [  10.   78.  147.   17.   90.]
 [  50.   26.   19.  228.   42.]
 [ 225.  143.  192.  237. 1052.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.153 | Acc: 96.375% | Wgt Acc: 96.581%
	I - Batch: 100 | Loss: 0.180 | Acc: 95.875% | Wgt Acc: 95.644%
	I - Batch: 150 | Loss: 0.185 | Acc: 95.542% | Wgt Acc: 95.248%
	I - Batch: 200 | Loss: 0.180 | Acc: 95.562% | Wgt Acc: 95.361%
	I - Batch: 250 | Loss: 0.183 | Acc: 95.250% | Wgt Acc: 95.051%
	I - Batch: 300 | Loss: 0.182 | Acc: 95.354% | Wgt Acc: 95.245%
	I - Batch: 350 | Loss: 0.190 | Acc: 95.125% | Wgt Acc: 94.830%
	I - Batch: 400 | Loss: 0.187 | Acc: 95.172% | Wgt Acc: 94.968%
	I - Batch: 450 | Loss: 0.188 | Acc: 95.222% | Wgt Acc: 95.042%
	I - Batch: 500 | Loss: 0.189 | Acc: 95.250% | Wgt Acc: 95.039%
	I - Batch: 550 | Loss: 0.190 | Acc: 95.216% | Wgt Acc: 94.941%
	I - Batch: 600 | Loss: 0.189 | Acc: 95.240% | Wgt Acc: 94.999%
	I - Batch: 650 | Loss: 0.191 | Acc: 95.240% | Wgt Acc: 94.958%
	I - Batch: 700 | Loss: 0.191 | Acc: 95.143% | Wgt Acc: 94.899%
	I - Batch: 750 | Loss: 0.190 | Acc: 95.167% | Wgt Acc: 94.952%
	I - Batch: 800 | Loss: 0.190 | Acc: 95.148% | Wgt Acc: 94.948%
	I - Batch: 850 | Loss: 0.189 | Acc: 95.169% | Wgt Acc: 94.973%
I - num batch: 876
I - Train -- Loss: 0.188 | Acc: 95.173% | Wgt Acc: 94.974% | LR: 1.250000e-04 | Dur: 541.93s
I - Confusion Matrix: [row->prediction - col->label]
[[1822.    1.    0.   13.  113.]
 [   1.  858.   61.    2.   22.]
 [   0.   57. 1208.    0.  169.]
 [  10.    6.    2. 1886.   72.]
 [  53.    5.   64.   25. 7554.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.414 | Acc: 42.875% | Wgt Acc: 41.725%
	I - Batch: 100 | Loss: 2.003 | Acc: 55.000% | Wgt Acc: 47.887%
	I - Batch: 150 | Loss: 1.906 | Acc: 58.333% | Wgt Acc: 49.716%
I - num batch: 193
I - Val -- Loss: 1.910 | Acc: 59.268% | Wgt Acc: 49.907% | Dur: 91.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 325.   20.   32.  124.   81.]
 [   1.  110.   28.   13.   18.]
 [   7.   53.  125.   19.   45.]
 [  62.   29.   22.  241.   43.]
 [ 140.  158.  185.  177. 1028.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.189 | Acc: 95.625% | Wgt Acc: 95.503%
	I - Batch: 100 | Loss: 0.173 | Acc: 95.688% | Wgt Acc: 95.530%
	I - Batch: 150 | Loss: 0.175 | Acc: 95.833% | Wgt Acc: 95.660%
	I - Batch: 200 | Loss: 0.173 | Acc: 95.844% | Wgt Acc: 95.672%
	I - Batch: 250 | Loss: 0.179 | Acc: 95.575% | Wgt Acc: 95.360%
	I - Batch: 300 | Loss: 0.190 | Acc: 95.125% | Wgt Acc: 94.892%
	I - Batch: 350 | Loss: 0.196 | Acc: 94.750% | Wgt Acc: 94.635%
	I - Batch: 400 | Loss: 0.199 | Acc: 94.609% | Wgt Acc: 94.515%
	I - Batch: 450 | Loss: 0.199 | Acc: 94.681% | Wgt Acc: 94.567%
	I - Batch: 500 | Loss: 0.195 | Acc: 94.850% | Wgt Acc: 94.736%
	I - Batch: 550 | Loss: 0.195 | Acc: 94.830% | Wgt Acc: 94.707%
	I - Batch: 600 | Loss: 0.194 | Acc: 94.844% | Wgt Acc: 94.724%
	I - Batch: 650 | Loss: 0.192 | Acc: 94.962% | Wgt Acc: 94.837%
	I - Batch: 700 | Loss: 0.191 | Acc: 94.991% | Wgt Acc: 94.870%
	I - Batch: 750 | Loss: 0.190 | Acc: 95.050% | Wgt Acc: 94.912%
	I - Batch: 800 | Loss: 0.189 | Acc: 95.062% | Wgt Acc: 94.942%
	I - Batch: 850 | Loss: 0.187 | Acc: 95.132% | Wgt Acc: 94.986%
I - num batch: 876
I - Train -- Loss: 0.188 | Acc: 95.101% | Wgt Acc: 94.958% | LR: 1.250000e-04 | Dur: 539.72s
I - Confusion Matrix: [row->prediction - col->label]
[[1819.    0.    1.   15.  123.]
 [   0.  863.   52.    5.   22.]
 [   0.   52. 1220.    2.  144.]
 [  14.    7.    1. 1871.   96.]
 [  53.    5.   61.   33. 7545.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.943 | Acc: 50.250% | Wgt Acc: 50.139%
	I - Batch: 100 | Loss: 1.724 | Acc: 57.875% | Wgt Acc: 54.033%
	I - Batch: 150 | Loss: 1.671 | Acc: 58.958% | Wgt Acc: 54.187%
I - num batch: 193
I - Val -- Loss: 1.682 | Acc: 59.624% | Wgt Acc: 54.444% | Dur: 91.44s
I - Confusion Matrix: [row->prediction - col->label]
[[317.  10.  30.  86.  42.]
 [ 11. 219.  78.  67. 104.]
 [  6.  46. 142.  10. 105.]
 [ 74.  19.  16. 252.  54.]
 [127.  76. 126. 159. 910.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.214 | Acc: 94.250% | Wgt Acc: 93.723%
	I - Batch: 100 | Loss: 0.196 | Acc: 94.812% | Wgt Acc: 94.412%
	I - Batch: 150 | Loss: 0.203 | Acc: 94.667% | Wgt Acc: 94.260%
	I - Batch: 200 | Loss: 0.197 | Acc: 94.656% | Wgt Acc: 94.360%
	I - Batch: 250 | Loss: 0.196 | Acc: 94.775% | Wgt Acc: 94.502%
	I - Batch: 300 | Loss: 0.190 | Acc: 94.833% | Wgt Acc: 94.693%
	I - Batch: 350 | Loss: 0.189 | Acc: 94.911% | Wgt Acc: 94.654%
	I - Batch: 400 | Loss: 0.185 | Acc: 94.906% | Wgt Acc: 94.721%
	I - Batch: 450 | Loss: 0.186 | Acc: 94.903% | Wgt Acc: 94.724%
	I - Batch: 500 | Loss: 0.185 | Acc: 94.950% | Wgt Acc: 94.749%
	I - Batch: 550 | Loss: 0.183 | Acc: 94.966% | Wgt Acc: 94.805%
	I - Batch: 600 | Loss: 0.182 | Acc: 95.021% | Wgt Acc: 94.858%
	I - Batch: 650 | Loss: 0.179 | Acc: 95.144% | Wgt Acc: 94.994%
	I - Batch: 700 | Loss: 0.183 | Acc: 95.009% | Wgt Acc: 94.878%
	I - Batch: 750 | Loss: 0.183 | Acc: 94.992% | Wgt Acc: 94.833%
	I - Batch: 800 | Loss: 0.184 | Acc: 94.906% | Wgt Acc: 94.771%
	I - Batch: 850 | Loss: 0.184 | Acc: 94.897% | Wgt Acc: 94.771%
I - num batch: 876
I - Train -- Loss: 0.184 | Acc: 94.951% | Wgt Acc: 94.822% | LR: 1.250000e-04 | Dur: 540.40s
I - Confusion Matrix: [row->prediction - col->label]
[[1822.    0.    0.    9.  124.]
 [   0.  858.   55.    3.   16.]
 [   0.   50. 1207.    0.  179.]
 [   9.    9.    1. 1883.   84.]
 [  55.   10.   72.   31. 7527.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.361 | Acc: 42.625% | Wgt Acc: 40.965%
	I - Batch: 100 | Loss: 1.962 | Acc: 53.750% | Wgt Acc: 46.582%
	I - Batch: 150 | Loss: 1.824 | Acc: 57.417% | Wgt Acc: 48.902%
I - num batch: 193
I - Val -- Loss: 1.818 | Acc: 59.170% | Wgt Acc: 49.964% | Dur: 91.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 368.   14.   26.  136.   84.]
 [   2.   82.   20.    9.   15.]
 [   3.   65.  103.    8.   49.]
 [  62.   48.   25.  268.   62.]
 [ 100.  161.  218.  153. 1005.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.136 | Acc: 96.625% | Wgt Acc: 96.499%
	I - Batch: 100 | Loss: 0.149 | Acc: 96.375% | Wgt Acc: 96.206%
	I - Batch: 150 | Loss: 0.153 | Acc: 96.042% | Wgt Acc: 96.026%
	I - Batch: 200 | Loss: 0.158 | Acc: 96.031% | Wgt Acc: 95.906%
	I - Batch: 250 | Loss: 0.158 | Acc: 96.000% | Wgt Acc: 95.943%
	I - Batch: 300 | Loss: 0.158 | Acc: 96.021% | Wgt Acc: 95.856%
	I - Batch: 350 | Loss: 0.159 | Acc: 95.964% | Wgt Acc: 95.767%
	I - Batch: 400 | Loss: 0.159 | Acc: 96.031% | Wgt Acc: 95.873%
	I - Batch: 450 | Loss: 0.160 | Acc: 96.042% | Wgt Acc: 95.827%
	I - Batch: 500 | Loss: 0.161 | Acc: 96.025% | Wgt Acc: 95.797%
	I - Batch: 550 | Loss: 0.160 | Acc: 95.966% | Wgt Acc: 95.750%
	I - Batch: 600 | Loss: 0.160 | Acc: 96.021% | Wgt Acc: 95.840%
	I - Batch: 650 | Loss: 0.161 | Acc: 95.981% | Wgt Acc: 95.798%
	I - Batch: 700 | Loss: 0.160 | Acc: 95.929% | Wgt Acc: 95.772%
	I - Batch: 750 | Loss: 0.159 | Acc: 95.958% | Wgt Acc: 95.766%
	I - Batch: 800 | Loss: 0.161 | Acc: 95.898% | Wgt Acc: 95.699%
	I - Batch: 850 | Loss: 0.164 | Acc: 95.824% | Wgt Acc: 95.608%
I - num batch: 876
I - Train -- Loss: 0.164 | Acc: 95.815% | Wgt Acc: 95.617% | LR: 1.250000e-04 | Dur: 543.87s
I - Confusion Matrix: [row->prediction - col->label]
[[1828.    1.    0.    7.  107.]
 [   0.  866.   45.    5.   18.]
 [   0.   44. 1231.    0.  120.]
 [  16.    8.    1. 1884.   76.]
 [  42.    8.   58.   30. 7609.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.375 | Acc: 43.625% | Wgt Acc: 42.375%
	I - Batch: 100 | Loss: 1.963 | Acc: 54.250% | Wgt Acc: 48.189%
	I - Batch: 150 | Loss: 1.840 | Acc: 57.375% | Wgt Acc: 50.263%
I - num batch: 193
I - Val -- Loss: 1.858 | Acc: 58.069% | Wgt Acc: 50.230% | Dur: 92.99s
I - Confusion Matrix: [row->prediction - col->label]
[[349.  18.  31. 131.  80.]
 [  2. 112.  30.  11.  20.]
 [  6.  69. 129.   9.  81.]
 [ 58.  28.  32. 245.  77.]
 [120. 143. 170. 178. 957.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 96.750% | Wgt Acc: 96.631%
	I - Batch: 100 | Loss: 0.150 | Acc: 96.312% | Wgt Acc: 95.897%
	I - Batch: 150 | Loss: 0.152 | Acc: 96.000% | Wgt Acc: 95.784%
	I - Batch: 200 | Loss: 0.159 | Acc: 95.719% | Wgt Acc: 95.737%
	I - Batch: 250 | Loss: 0.156 | Acc: 95.875% | Wgt Acc: 95.967%
	I - Batch: 300 | Loss: 0.153 | Acc: 95.958% | Wgt Acc: 95.967%
	I - Batch: 350 | Loss: 0.150 | Acc: 96.107% | Wgt Acc: 96.141%
	I - Batch: 400 | Loss: 0.154 | Acc: 95.984% | Wgt Acc: 95.970%
	I - Batch: 450 | Loss: 0.150 | Acc: 96.194% | Wgt Acc: 96.166%
	I - Batch: 500 | Loss: 0.152 | Acc: 96.150% | Wgt Acc: 96.076%
	I - Batch: 550 | Loss: 0.158 | Acc: 95.977% | Wgt Acc: 95.874%
	I - Batch: 600 | Loss: 0.160 | Acc: 95.833% | Wgt Acc: 95.769%
	I - Batch: 650 | Loss: 0.160 | Acc: 95.769% | Wgt Acc: 95.682%
	I - Batch: 700 | Loss: 0.161 | Acc: 95.679% | Wgt Acc: 95.613%
	I - Batch: 750 | Loss: 0.163 | Acc: 95.567% | Wgt Acc: 95.463%
	I - Batch: 800 | Loss: 0.165 | Acc: 95.461% | Wgt Acc: 95.373%
	I - Batch: 850 | Loss: 0.164 | Acc: 95.515% | Wgt Acc: 95.431%
I - num batch: 876
I - Train -- Loss: 0.164 | Acc: 95.523% | Wgt Acc: 95.428% | LR: 1.250000e-04 | Dur: 544.02s
I - Confusion Matrix: [row->prediction - col->label]
[[1827.    1.    1.    3.  128.]
 [   0.  867.   46.    6.   15.]
 [   1.   44. 1226.    0.  136.]
 [  10.    7.    0. 1886.   80.]
 [  48.    8.   62.   31. 7571.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.854 | Acc: 33.125% | Wgt Acc: 32.189%
	I - Batch: 100 | Loss: 2.266 | Acc: 49.938% | Wgt Acc: 41.165%
	I - Batch: 150 | Loss: 2.086 | Acc: 55.500% | Wgt Acc: 44.755%
I - num batch: 193
I - Val -- Loss: 2.091 | Acc: 57.323% | Wgt Acc: 45.717% | Dur: 91.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 257.    9.   17.   82.   29.]
 [   4.   79.   15.    8.   12.]
 [   5.   72.  130.   12.   46.]
 [  69.   21.   15.  215.   40.]
 [ 200.  189.  215.  257. 1088.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.150 | Acc: 95.875% | Wgt Acc: 94.990%
	I - Batch: 100 | Loss: 0.143 | Acc: 96.188% | Wgt Acc: 95.614%
	I - Batch: 150 | Loss: 0.149 | Acc: 96.417% | Wgt Acc: 95.966%
	I - Batch: 200 | Loss: 0.155 | Acc: 96.375% | Wgt Acc: 95.946%
	I - Batch: 250 | Loss: 0.156 | Acc: 96.200% | Wgt Acc: 95.809%
	I - Batch: 300 | Loss: 0.156 | Acc: 96.125% | Wgt Acc: 95.864%
	I - Batch: 350 | Loss: 0.156 | Acc: 96.107% | Wgt Acc: 95.870%
	I - Batch: 400 | Loss: 0.154 | Acc: 96.219% | Wgt Acc: 96.034%
	I - Batch: 450 | Loss: 0.152 | Acc: 96.333% | Wgt Acc: 96.142%
	I - Batch: 500 | Loss: 0.152 | Acc: 96.338% | Wgt Acc: 96.105%
	I - Batch: 550 | Loss: 0.153 | Acc: 96.284% | Wgt Acc: 96.022%
	I - Batch: 600 | Loss: 0.156 | Acc: 96.156% | Wgt Acc: 95.878%
	I - Batch: 650 | Loss: 0.158 | Acc: 96.077% | Wgt Acc: 95.819%
	I - Batch: 700 | Loss: 0.158 | Acc: 96.036% | Wgt Acc: 95.777%
	I - Batch: 750 | Loss: 0.159 | Acc: 95.967% | Wgt Acc: 95.725%
	I - Batch: 800 | Loss: 0.160 | Acc: 95.914% | Wgt Acc: 95.666%
	I - Batch: 850 | Loss: 0.161 | Acc: 95.824% | Wgt Acc: 95.634%
I - num batch: 876
I - Train -- Loss: 0.161 | Acc: 95.844% | Wgt Acc: 95.658% | LR: 1.250000e-04 | Dur: 539.81s
I - Confusion Matrix: [row->prediction - col->label]
[[1834.    2.    0.    5.  103.]
 [   0.  863.   49.    4.   17.]
 [   0.   49. 1231.    0.  122.]
 [  12.    5.    3. 1886.   80.]
 [  40.    8.   52.   31. 7608.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.225 | Acc: 46.250% | Wgt Acc: 45.410%
	I - Batch: 100 | Loss: 1.861 | Acc: 57.312% | Wgt Acc: 51.413%
	I - Batch: 150 | Loss: 1.759 | Acc: 60.333% | Wgt Acc: 53.325%
I - num batch: 193
I - Val -- Loss: 1.773 | Acc: 60.726% | Wgt Acc: 53.045% | Dur: 91.23s
I - Confusion Matrix: [row->prediction - col->label]
[[344.  15.  30. 121.  83.]
 [  9. 160.  42.  28.  44.]
 [  5.  38. 115.   8.  43.]
 [ 64.  37.  27. 263.  53.]
 [113. 120. 178. 154. 992.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.119 | Acc: 96.875% | Wgt Acc: 97.041%
	I - Batch: 100 | Loss: 0.138 | Acc: 96.375% | Wgt Acc: 96.143%
	I - Batch: 150 | Loss: 0.136 | Acc: 96.417% | Wgt Acc: 96.375%
	I - Batch: 200 | Loss: 0.127 | Acc: 96.500% | Wgt Acc: 96.624%
	I - Batch: 250 | Loss: 0.134 | Acc: 96.475% | Wgt Acc: 96.583%
	I - Batch: 300 | Loss: 0.133 | Acc: 96.708% | Wgt Acc: 96.698%
	I - Batch: 350 | Loss: 0.133 | Acc: 96.679% | Wgt Acc: 96.646%
	I - Batch: 400 | Loss: 0.137 | Acc: 96.531% | Wgt Acc: 96.504%
	I - Batch: 450 | Loss: 0.138 | Acc: 96.486% | Wgt Acc: 96.491%
	I - Batch: 500 | Loss: 0.135 | Acc: 96.562% | Wgt Acc: 96.561%
	I - Batch: 550 | Loss: 0.139 | Acc: 96.443% | Wgt Acc: 96.436%
	I - Batch: 600 | Loss: 0.141 | Acc: 96.375% | Wgt Acc: 96.342%
	I - Batch: 650 | Loss: 0.141 | Acc: 96.375% | Wgt Acc: 96.325%
	I - Batch: 700 | Loss: 0.145 | Acc: 96.268% | Wgt Acc: 96.237%
	I - Batch: 750 | Loss: 0.145 | Acc: 96.233% | Wgt Acc: 96.212%
	I - Batch: 800 | Loss: 0.145 | Acc: 96.250% | Wgt Acc: 96.219%
	I - Batch: 850 | Loss: 0.145 | Acc: 96.162% | Wgt Acc: 96.169%
I - num batch: 876
I - Train -- Loss: 0.146 | Acc: 96.201% | Wgt Acc: 96.201% | LR: 1.250000e-04 | Dur: 540.68s
I - Confusion Matrix: [row->prediction - col->label]
[[1842.    1.    1.   11.   94.]
 [   1.  887.   41.    4.   15.]
 [   0.   28. 1237.    0.  129.]
 [   9.    5.    1. 1890.   76.]
 [  34.    6.   55.   21. 7616.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.973 | Acc: 48.750% | Wgt Acc: 48.018%
	I - Batch: 100 | Loss: 1.700 | Acc: 55.625% | Wgt Acc: 52.143%
	I - Batch: 150 | Loss: 1.639 | Acc: 57.792% | Wgt Acc: 53.681%
I - num batch: 193
I - Val -- Loss: 1.666 | Acc: 57.745% | Wgt Acc: 53.514% | Dur: 92.59s
I - Confusion Matrix: [row->prediction - col->label]
[[343.  19.  27. 124.  96.]
 [  5. 190.  88.  39.  57.]
 [  0.  26. 110.   2.  78.]
 [107.  45.  43. 304. 149.]
 [ 80.  90. 124. 105. 835.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.163 | Acc: 96.250% | Wgt Acc: 95.751%
	I - Batch: 100 | Loss: 0.191 | Acc: 94.875% | Wgt Acc: 94.733%
	I - Batch: 150 | Loss: 0.175 | Acc: 95.583% | Wgt Acc: 95.358%
	I - Batch: 200 | Loss: 0.165 | Acc: 95.844% | Wgt Acc: 95.689%
	I - Batch: 250 | Loss: 0.155 | Acc: 96.025% | Wgt Acc: 96.056%
	I - Batch: 300 | Loss: 0.151 | Acc: 96.229% | Wgt Acc: 96.294%
	I - Batch: 350 | Loss: 0.148 | Acc: 96.286% | Wgt Acc: 96.385%
	I - Batch: 400 | Loss: 0.149 | Acc: 96.297% | Wgt Acc: 96.330%
	I - Batch: 450 | Loss: 0.144 | Acc: 96.431% | Wgt Acc: 96.476%
	I - Batch: 500 | Loss: 0.139 | Acc: 96.600% | Wgt Acc: 96.643%
	I - Batch: 550 | Loss: 0.138 | Acc: 96.716% | Wgt Acc: 96.739%
	I - Batch: 600 | Loss: 0.141 | Acc: 96.615% | Wgt Acc: 96.605%
	I - Batch: 650 | Loss: 0.141 | Acc: 96.548% | Wgt Acc: 96.549%
	I - Batch: 700 | Loss: 0.142 | Acc: 96.562% | Wgt Acc: 96.538%
	I - Batch: 750 | Loss: 0.142 | Acc: 96.492% | Wgt Acc: 96.445%
	I - Batch: 800 | Loss: 0.143 | Acc: 96.398% | Wgt Acc: 96.376%
	I - Batch: 850 | Loss: 0.144 | Acc: 96.346% | Wgt Acc: 96.312%
I - num batch: 876
I - Train -- Loss: 0.145 | Acc: 96.308% | Wgt Acc: 96.274% | LR: 1.250000e-04 | Dur: 547.73s
I - Confusion Matrix: [row->prediction - col->label]
[[1836.    1.    1.    7.   99.]
 [   0.  884.   35.    6.   14.]
 [   0.   32. 1246.    1.  116.]
 [  11.    5.    0. 1891.   71.]
 [  39.    5.   53.   21. 7630.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.553 | Acc: 41.500% | Wgt Acc: 39.855%
	I - Batch: 100 | Loss: 2.139 | Acc: 53.125% | Wgt Acc: 45.852%
	I - Batch: 150 | Loss: 1.987 | Acc: 57.083% | Wgt Acc: 48.558%
I - num batch: 193
I - Val -- Loss: 1.996 | Acc: 57.485% | Wgt Acc: 48.202% | Dur: 93.41s
I - Confusion Matrix: [row->prediction - col->label]
[[357.  17.  31. 158.  78.]
 [  2.  77.  19.  15.  23.]
 [  8.  64. 122.  15.  56.]
 [ 58.  36.  23. 224.  64.]
 [110. 176. 197. 162. 994.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.138 | Acc: 96.250% | Wgt Acc: 96.552%
	I - Batch: 100 | Loss: 0.134 | Acc: 96.500% | Wgt Acc: 96.744%
	I - Batch: 150 | Loss: 0.127 | Acc: 96.917% | Wgt Acc: 97.029%
	I - Batch: 200 | Loss: 0.134 | Acc: 96.656% | Wgt Acc: 96.742%
	I - Batch: 250 | Loss: 0.131 | Acc: 96.750% | Wgt Acc: 96.806%
	I - Batch: 300 | Loss: 0.126 | Acc: 96.938% | Wgt Acc: 96.995%
	I - Batch: 350 | Loss: 0.123 | Acc: 97.089% | Wgt Acc: 97.138%
	I - Batch: 400 | Loss: 0.120 | Acc: 97.203% | Wgt Acc: 97.263%
	I - Batch: 450 | Loss: 0.120 | Acc: 97.167% | Wgt Acc: 97.195%
	I - Batch: 500 | Loss: 0.119 | Acc: 97.162% | Wgt Acc: 97.166%
	I - Batch: 550 | Loss: 0.121 | Acc: 97.114% | Wgt Acc: 97.114%
	I - Batch: 600 | Loss: 0.120 | Acc: 97.104% | Wgt Acc: 97.100%
	I - Batch: 650 | Loss: 0.120 | Acc: 97.077% | Wgt Acc: 97.079%
	I - Batch: 700 | Loss: 0.119 | Acc: 97.161% | Wgt Acc: 97.138%
	I - Batch: 750 | Loss: 0.125 | Acc: 97.042% | Wgt Acc: 96.977%
	I - Batch: 800 | Loss: 0.127 | Acc: 96.977% | Wgt Acc: 96.892%
	I - Batch: 850 | Loss: 0.127 | Acc: 96.949% | Wgt Acc: 96.899%
I - num batch: 876
I - Train -- Loss: 0.127 | Acc: 96.951% | Wgt Acc: 96.902% | LR: 1.250000e-04 | Dur: 547.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1854.    0.    1.   11.   77.]
 [   0.  890.   35.    0.   11.]
 [   0.   29. 1258.    1.   99.]
 [  10.    3.    0. 1891.   59.]
 [  22.    5.   41.   23. 7684.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.054 | Acc: 47.375% | Wgt Acc: 46.640%
	I - Batch: 100 | Loss: 1.801 | Acc: 55.062% | Wgt Acc: 51.150%
	I - Batch: 150 | Loss: 1.698 | Acc: 58.000% | Wgt Acc: 53.428%
I - num batch: 193
I - Val -- Loss: 1.707 | Acc: 58.393% | Wgt Acc: 53.447% | Dur: 91.94s
I - Confusion Matrix: [row->prediction - col->label]
[[390.  23.  40. 170. 138.]
 [  7. 168.  70.  34.  67.]
 [  1.  43. 125.   7.  48.]
 [ 65.  41.  32. 254.  97.]
 [ 72.  95. 125. 109. 865.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.125 | Acc: 96.500% | Wgt Acc: 96.846%
	I - Batch: 100 | Loss: 0.120 | Acc: 97.125% | Wgt Acc: 97.316%
	I - Batch: 150 | Loss: 0.122 | Acc: 97.250% | Wgt Acc: 97.462%
	I - Batch: 200 | Loss: 0.124 | Acc: 97.062% | Wgt Acc: 97.195%
	I - Batch: 250 | Loss: 0.130 | Acc: 96.850% | Wgt Acc: 96.881%
	I - Batch: 300 | Loss: 0.130 | Acc: 96.750% | Wgt Acc: 96.747%
	I - Batch: 350 | Loss: 0.128 | Acc: 96.857% | Wgt Acc: 96.774%
	I - Batch: 400 | Loss: 0.128 | Acc: 96.797% | Wgt Acc: 96.786%
	I - Batch: 450 | Loss: 0.127 | Acc: 96.764% | Wgt Acc: 96.771%
	I - Batch: 500 | Loss: 0.126 | Acc: 96.875% | Wgt Acc: 96.864%
	I - Batch: 550 | Loss: 0.127 | Acc: 96.909% | Wgt Acc: 96.885%
	I - Batch: 600 | Loss: 0.127 | Acc: 96.896% | Wgt Acc: 96.849%
	I - Batch: 650 | Loss: 0.130 | Acc: 96.760% | Wgt Acc: 96.676%
	I - Batch: 700 | Loss: 0.134 | Acc: 96.643% | Wgt Acc: 96.524%
	I - Batch: 750 | Loss: 0.135 | Acc: 96.625% | Wgt Acc: 96.547%
	I - Batch: 800 | Loss: 0.136 | Acc: 96.594% | Wgt Acc: 96.517%
	I - Batch: 850 | Loss: 0.136 | Acc: 96.603% | Wgt Acc: 96.514%
I - num batch: 876
I - Train -- Loss: 0.136 | Acc: 96.587% | Wgt Acc: 96.491% | LR: 1.250000e-04 | Dur: 542.53s
I - Confusion Matrix: [row->prediction - col->label]
[[1835.    0.    0.   20.   94.]
 [   0.  898.   32.    3.   17.]
 [   0.   18. 1250.    0.   92.]
 [  11.    4.    2. 1877.   61.]
 [  40.    7.   51.   26. 7666.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.629 | Acc: 37.500% | Wgt Acc: 36.722%
	I - Batch: 100 | Loss: 2.154 | Acc: 52.875% | Wgt Acc: 44.771%
	I - Batch: 150 | Loss: 2.018 | Acc: 57.125% | Wgt Acc: 47.594%
I - num batch: 193
I - Val -- Loss: 2.010 | Acc: 58.652% | Wgt Acc: 48.310% | Dur: 91.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 294.    9.   20.  100.   35.]
 [   2.   85.   12.   12.   13.]
 [   9.   99.  170.   26.   78.]
 [  54.   16.   12.  199.   27.]
 [ 176.  161.  178.  237. 1062.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.111 | Acc: 97.625% | Wgt Acc: 97.575%
	I - Batch: 100 | Loss: 0.100 | Acc: 98.000% | Wgt Acc: 98.018%
	I - Batch: 150 | Loss: 0.102 | Acc: 97.917% | Wgt Acc: 98.007%
	I - Batch: 200 | Loss: 0.107 | Acc: 97.656% | Wgt Acc: 97.607%
	I - Batch: 250 | Loss: 0.116 | Acc: 97.325% | Wgt Acc: 97.153%
	I - Batch: 300 | Loss: 0.116 | Acc: 97.229% | Wgt Acc: 97.084%
	I - Batch: 350 | Loss: 0.118 | Acc: 97.125% | Wgt Acc: 97.018%
	I - Batch: 400 | Loss: 0.127 | Acc: 96.734% | Wgt Acc: 96.546%
	I - Batch: 450 | Loss: 0.131 | Acc: 96.514% | Wgt Acc: 96.320%
	I - Batch: 500 | Loss: 0.130 | Acc: 96.550% | Wgt Acc: 96.380%
	I - Batch: 550 | Loss: 0.130 | Acc: 96.545% | Wgt Acc: 96.373%
	I - Batch: 600 | Loss: 0.128 | Acc: 96.604% | Wgt Acc: 96.447%
	I - Batch: 650 | Loss: 0.126 | Acc: 96.663% | Wgt Acc: 96.534%
	I - Batch: 700 | Loss: 0.124 | Acc: 96.750% | Wgt Acc: 96.643%
	I - Batch: 750 | Loss: 0.123 | Acc: 96.808% | Wgt Acc: 96.746%
	I - Batch: 800 | Loss: 0.123 | Acc: 96.773% | Wgt Acc: 96.729%
	I - Batch: 850 | Loss: 0.123 | Acc: 96.787% | Wgt Acc: 96.761%
I - num batch: 876
I - Train -- Loss: 0.124 | Acc: 96.758% | Wgt Acc: 96.707% | LR: 1.250000e-04 | Dur: 541.20s
I - Confusion Matrix: [row->prediction - col->label]
[[1843.    0.    1.    3.   91.]
 [   0.  883.   28.    3.   10.]
 [   0.   31. 1260.    0.   99.]
 [   5.    6.    1. 1896.   62.]
 [  38.    7.   45.   24. 7668.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.515 | Acc: 40.625% | Wgt Acc: 39.466%
	I - Batch: 100 | Loss: 2.063 | Acc: 55.000% | Wgt Acc: 47.390%
	I - Batch: 150 | Loss: 1.942 | Acc: 59.292% | Wgt Acc: 50.423%
I - num batch: 193
I - Val -- Loss: 1.946 | Acc: 60.175% | Wgt Acc: 50.693% | Dur: 91.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 312.    8.   22.   98.   38.]
 [   2.  105.   22.    9.   14.]
 [   5.   64.  130.   14.   60.]
 [  80.   46.   29.  269.   62.]
 [ 136.  147.  189.  184. 1041.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.122 | Acc: 95.875% | Wgt Acc: 96.140%
	I - Batch: 100 | Loss: 0.108 | Acc: 96.750% | Wgt Acc: 97.064%
	I - Batch: 150 | Loss: 0.106 | Acc: 97.125% | Wgt Acc: 97.273%
	I - Batch: 200 | Loss: 0.101 | Acc: 97.375% | Wgt Acc: 97.533%
	I - Batch: 250 | Loss: 0.104 | Acc: 97.325% | Wgt Acc: 97.401%
	I - Batch: 300 | Loss: 0.104 | Acc: 97.354% | Wgt Acc: 97.450%
	I - Batch: 350 | Loss: 0.102 | Acc: 97.536% | Wgt Acc: 97.592%
	I - Batch: 400 | Loss: 0.099 | Acc: 97.594% | Wgt Acc: 97.636%
	I - Batch: 450 | Loss: 0.100 | Acc: 97.583% | Wgt Acc: 97.573%
	I - Batch: 500 | Loss: 0.100 | Acc: 97.600% | Wgt Acc: 97.612%
	I - Batch: 550 | Loss: 0.100 | Acc: 97.591% | Wgt Acc: 97.663%
	I - Batch: 600 | Loss: 0.101 | Acc: 97.594% | Wgt Acc: 97.639%
	I - Batch: 650 | Loss: 0.101 | Acc: 97.577% | Wgt Acc: 97.627%
	I - Batch: 700 | Loss: 0.102 | Acc: 97.589% | Wgt Acc: 97.604%
	I - Batch: 750 | Loss: 0.105 | Acc: 97.558% | Wgt Acc: 97.540%
	I - Batch: 800 | Loss: 0.105 | Acc: 97.547% | Wgt Acc: 97.493%
	I - Batch: 850 | Loss: 0.104 | Acc: 97.574% | Wgt Acc: 97.519%
I - num batch: 876
I - Train -- Loss: 0.105 | Acc: 97.586% | Wgt Acc: 97.526% | LR: 1.250000e-04 | Dur: 541.10s
I - Confusion Matrix: [row->prediction - col->label]
[[1853.    2.    0.    3.   69.]
 [   1.  891.   20.    5.   15.]
 [   1.   27. 1287.    0.   58.]
 [   5.    6.    1. 1896.   49.]
 [  26.    1.   27.   22. 7739.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.503 | Acc: 43.000% | Wgt Acc: 41.943%
	I - Batch: 100 | Loss: 2.088 | Acc: 55.250% | Wgt Acc: 48.886%
	I - Batch: 150 | Loss: 1.983 | Acc: 58.167% | Wgt Acc: 50.439%
I - num batch: 193
I - Val -- Loss: 1.985 | Acc: 59.170% | Wgt Acc: 50.645% | Dur: 91.44s
I - Confusion Matrix: [row->prediction - col->label]
[[338.  16.  30. 121.  67.]
 [  5. 109.  20.  15.  23.]
 [  8.  69. 150.  14.  63.]
 [ 56.  31.  23. 230.  63.]
 [128. 145. 169. 194. 999.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.152 | Acc: 94.375% | Wgt Acc: 94.774%
	I - Batch: 100 | Loss: 0.140 | Acc: 95.312% | Wgt Acc: 95.569%
	I - Batch: 150 | Loss: 0.139 | Acc: 95.708% | Wgt Acc: 95.728%
	I - Batch: 200 | Loss: 0.148 | Acc: 95.656% | Wgt Acc: 95.738%
	I - Batch: 250 | Loss: 0.146 | Acc: 95.550% | Wgt Acc: 95.743%
	I - Batch: 300 | Loss: 0.142 | Acc: 95.729% | Wgt Acc: 95.773%
	I - Batch: 350 | Loss: 0.136 | Acc: 96.000% | Wgt Acc: 96.051%
	I - Batch: 400 | Loss: 0.133 | Acc: 96.188% | Wgt Acc: 96.214%
	I - Batch: 450 | Loss: 0.135 | Acc: 96.125% | Wgt Acc: 96.079%
	I - Batch: 500 | Loss: 0.135 | Acc: 96.175% | Wgt Acc: 96.136%
	I - Batch: 550 | Loss: 0.134 | Acc: 96.239% | Wgt Acc: 96.179%
	I - Batch: 600 | Loss: 0.131 | Acc: 96.312% | Wgt Acc: 96.307%
	I - Batch: 650 | Loss: 0.128 | Acc: 96.471% | Wgt Acc: 96.442%
	I - Batch: 700 | Loss: 0.126 | Acc: 96.509% | Wgt Acc: 96.513%
	I - Batch: 750 | Loss: 0.124 | Acc: 96.558% | Wgt Acc: 96.578%
	I - Batch: 800 | Loss: 0.122 | Acc: 96.602% | Wgt Acc: 96.633%
	I - Batch: 850 | Loss: 0.120 | Acc: 96.728% | Wgt Acc: 96.766%
I - num batch: 876
I - Train -- Loss: 0.121 | Acc: 96.680% | Wgt Acc: 96.714% | LR: 1.250000e-04 | Dur: 539.50s
I - Confusion Matrix: [row->prediction - col->label]
[[1852.    1.    1.    5.   87.]
 [   1.  890.   41.    4.   12.]
 [   0.   27. 1252.    0.  123.]
 [   5.    5.    0. 1895.   58.]
 [  28.    4.   41.   22. 7650.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.658 | Acc: 39.000% | Wgt Acc: 38.362%
	I - Batch: 100 | Loss: 2.215 | Acc: 53.312% | Wgt Acc: 45.547%
	I - Batch: 150 | Loss: 2.088 | Acc: 57.750% | Wgt Acc: 48.190%
I - num batch: 193
I - Val -- Loss: 2.084 | Acc: 59.073% | Wgt Acc: 48.917% | Dur: 91.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 250.    5.   18.   71.   33.]
 [   5.  117.   18.   23.   18.]
 [   6.   62.  144.   15.   57.]
 [  80.   22.   16.  247.   42.]
 [ 194.  164.  196.  218. 1065.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.098 | Acc: 97.875% | Wgt Acc: 97.522%
	I - Batch: 100 | Loss: 0.092 | Acc: 98.000% | Wgt Acc: 97.829%
	I - Batch: 150 | Loss: 0.088 | Acc: 98.125% | Wgt Acc: 98.100%
	I - Batch: 200 | Loss: 0.102 | Acc: 97.844% | Wgt Acc: 97.712%
	I - Batch: 250 | Loss: 0.103 | Acc: 97.625% | Wgt Acc: 97.570%
	I - Batch: 300 | Loss: 0.103 | Acc: 97.521% | Wgt Acc: 97.455%
	I - Batch: 350 | Loss: 0.102 | Acc: 97.554% | Wgt Acc: 97.495%
	I - Batch: 400 | Loss: 0.099 | Acc: 97.688% | Wgt Acc: 97.633%
	I - Batch: 450 | Loss: 0.099 | Acc: 97.611% | Wgt Acc: 97.610%
	I - Batch: 500 | Loss: 0.101 | Acc: 97.625% | Wgt Acc: 97.588%
	I - Batch: 550 | Loss: 0.104 | Acc: 97.511% | Wgt Acc: 97.446%
	I - Batch: 600 | Loss: 0.102 | Acc: 97.542% | Wgt Acc: 97.505%
	I - Batch: 650 | Loss: 0.106 | Acc: 97.452% | Wgt Acc: 97.421%
	I - Batch: 700 | Loss: 0.105 | Acc: 97.446% | Wgt Acc: 97.413%
	I - Batch: 750 | Loss: 0.105 | Acc: 97.425% | Wgt Acc: 97.411%
	I - Batch: 800 | Loss: 0.104 | Acc: 97.438% | Wgt Acc: 97.419%
	I - Batch: 850 | Loss: 0.106 | Acc: 97.368% | Wgt Acc: 97.355%
I - num batch: 876
I - Train -- Loss: 0.106 | Acc: 97.322% | Wgt Acc: 97.332% | LR: 1.250000e-04 | Dur: 538.61s
I - Confusion Matrix: [row->prediction - col->label]
[[1843.    1.    1.   10.   62.]
 [   1.  902.   19.    3.   13.]
 [   0.   20. 1277.    1.   87.]
 [   8.    1.    0. 1896.   57.]
 [  34.    3.   38.   16. 7711.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.569 | Acc: 40.875% | Wgt Acc: 39.745%
	I - Batch: 100 | Loss: 2.128 | Acc: 53.562% | Wgt Acc: 46.135%
	I - Batch: 150 | Loss: 1.977 | Acc: 57.875% | Wgt Acc: 49.296%
I - num batch: 193
I - Val -- Loss: 1.958 | Acc: 59.494% | Wgt Acc: 50.207% | Dur: 90.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 298.    9.   26.   88.   68.]
 [   2.  101.   17.   14.   13.]
 [   2.   62.  117.    9.   45.]
 [ 110.   42.   27.  298.   67.]
 [ 123.  156.  205.  165. 1022.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.160 | Acc: 94.750% | Wgt Acc: 95.049%
	I - Batch: 100 | Loss: 0.136 | Acc: 95.875% | Wgt Acc: 96.065%
	I - Batch: 150 | Loss: 0.123 | Acc: 96.292% | Wgt Acc: 96.569%
	I - Batch: 200 | Loss: 0.111 | Acc: 96.875% | Wgt Acc: 97.089%
	I - Batch: 250 | Loss: 0.108 | Acc: 97.100% | Wgt Acc: 97.223%
	I - Batch: 300 | Loss: 0.116 | Acc: 96.792% | Wgt Acc: 96.905%
	I - Batch: 350 | Loss: 0.116 | Acc: 96.804% | Wgt Acc: 96.811%
	I - Batch: 400 | Loss: 0.116 | Acc: 96.812% | Wgt Acc: 96.845%
	I - Batch: 450 | Loss: 0.116 | Acc: 96.750% | Wgt Acc: 96.818%
	I - Batch: 500 | Loss: 0.120 | Acc: 96.737% | Wgt Acc: 96.795%
	I - Batch: 550 | Loss: 0.119 | Acc: 96.807% | Wgt Acc: 96.846%
	I - Batch: 600 | Loss: 0.118 | Acc: 96.833% | Wgt Acc: 96.853%
	I - Batch: 650 | Loss: 0.116 | Acc: 96.923% | Wgt Acc: 96.937%
	I - Batch: 700 | Loss: 0.118 | Acc: 96.830% | Wgt Acc: 96.835%
	I - Batch: 750 | Loss: 0.117 | Acc: 96.900% | Wgt Acc: 96.889%
	I - Batch: 800 | Loss: 0.117 | Acc: 96.930% | Wgt Acc: 96.899%
	I - Batch: 850 | Loss: 0.120 | Acc: 96.838% | Wgt Acc: 96.806%
I - num batch: 876
I - Train -- Loss: 0.120 | Acc: 96.801% | Wgt Acc: 96.776% | LR: 1.250000e-04 | Dur: 540.47s
I - Confusion Matrix: [row->prediction - col->label]
[[1841.    0.    0.    7.  100.]
 [   1.  893.   35.    7.   10.]
 [   0.   22. 1264.    0.   77.]
 [   6.    6.    1. 1886.   71.]
 [  38.    6.   35.   26. 7672.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.474 | Acc: 42.375% | Wgt Acc: 41.861%
	I - Batch: 100 | Loss: 2.085 | Acc: 54.188% | Wgt Acc: 47.630%
	I - Batch: 150 | Loss: 1.991 | Acc: 57.500% | Wgt Acc: 49.647%
I - num batch: 193
I - Val -- Loss: 1.985 | Acc: 58.879% | Wgt Acc: 50.387% | Dur: 92.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 317.   11.   33.  109.   81.]
 [   5.  165.   66.   31.   50.]
 [   5.   25.   88.    6.   32.]
 [  57.   42.   26.  245.   50.]
 [ 151.  127.  179.  183. 1002.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.137 | Acc: 96.125% | Wgt Acc: 95.966%
	I - Batch: 100 | Loss: 0.139 | Acc: 96.062% | Wgt Acc: 95.902%
	I - Batch: 150 | Loss: 0.136 | Acc: 96.167% | Wgt Acc: 95.996%
	I - Batch: 200 | Loss: 0.131 | Acc: 96.281% | Wgt Acc: 96.209%
	I - Batch: 250 | Loss: 0.128 | Acc: 96.450% | Wgt Acc: 96.364%
	I - Batch: 300 | Loss: 0.132 | Acc: 96.417% | Wgt Acc: 96.364%
	I - Batch: 350 | Loss: 0.129 | Acc: 96.554% | Wgt Acc: 96.574%
	I - Batch: 400 | Loss: 0.126 | Acc: 96.719% | Wgt Acc: 96.736%
	I - Batch: 450 | Loss: 0.122 | Acc: 96.778% | Wgt Acc: 96.823%
	I - Batch: 500 | Loss: 0.122 | Acc: 96.825% | Wgt Acc: 96.858%
	I - Batch: 550 | Loss: 0.120 | Acc: 96.875% | Wgt Acc: 96.881%
	I - Batch: 600 | Loss: 0.119 | Acc: 96.875% | Wgt Acc: 96.849%
	I - Batch: 650 | Loss: 0.121 | Acc: 96.808% | Wgt Acc: 96.795%
	I - Batch: 700 | Loss: 0.122 | Acc: 96.750% | Wgt Acc: 96.720%
	I - Batch: 750 | Loss: 0.124 | Acc: 96.650% | Wgt Acc: 96.628%
	I - Batch: 800 | Loss: 0.125 | Acc: 96.586% | Wgt Acc: 96.541%
	I - Batch: 850 | Loss: 0.127 | Acc: 96.485% | Wgt Acc: 96.496%
I - num batch: 876
I - Train -- Loss: 0.127 | Acc: 96.494% | Wgt Acc: 96.496% | LR: 1.250000e-04 | Dur: 549.76s
I - Confusion Matrix: [row->prediction - col->label]
[[1837.    2.    2.   15.   96.]
 [   0.  888.   31.    5.   18.]
 [   0.   25. 1266.    0.   96.]
 [  18.    4.    0. 1878.   76.]
 [  31.    8.   36.   28. 7644.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.275 | Acc: 44.375% | Wgt Acc: 44.201%
	I - Batch: 100 | Loss: 1.918 | Acc: 55.562% | Wgt Acc: 49.872%
	I - Batch: 150 | Loss: 1.875 | Acc: 57.250% | Wgt Acc: 50.532%
I - num batch: 193
I - Val -- Loss: 1.874 | Acc: 58.425% | Wgt Acc: 51.060% | Dur: 93.55s
I - Confusion Matrix: [row->prediction - col->label]
[[285.   6.  22.  79.  39.]
 [  7. 174.  65.  31.  54.]
 [  4.  55. 136.  17.  94.]
 [ 71.  22.  27. 241.  61.]
 [168. 113. 142. 206. 967.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.127 | Acc: 97.000% | Wgt Acc: 96.697%
	I - Batch: 100 | Loss: 0.116 | Acc: 97.188% | Wgt Acc: 96.933%
	I - Batch: 150 | Loss: 0.104 | Acc: 97.583% | Wgt Acc: 97.560%
	I - Batch: 200 | Loss: 0.100 | Acc: 97.656% | Wgt Acc: 97.721%
	I - Batch: 250 | Loss: 0.099 | Acc: 97.525% | Wgt Acc: 97.637%
	I - Batch: 300 | Loss: 0.094 | Acc: 97.708% | Wgt Acc: 97.782%
	I - Batch: 350 | Loss: 0.090 | Acc: 97.946% | Wgt Acc: 98.029%
	I - Batch: 400 | Loss: 0.089 | Acc: 97.938% | Wgt Acc: 98.039%
	I - Batch: 450 | Loss: 0.088 | Acc: 97.889% | Wgt Acc: 98.003%
	I - Batch: 500 | Loss: 0.087 | Acc: 97.925% | Wgt Acc: 98.062%
	I - Batch: 550 | Loss: 0.088 | Acc: 97.943% | Wgt Acc: 98.024%
	I - Batch: 600 | Loss: 0.088 | Acc: 97.875% | Wgt Acc: 97.955%
	I - Batch: 650 | Loss: 0.090 | Acc: 97.788% | Wgt Acc: 97.846%
	I - Batch: 700 | Loss: 0.093 | Acc: 97.679% | Wgt Acc: 97.734%
	I - Batch: 750 | Loss: 0.094 | Acc: 97.625% | Wgt Acc: 97.704%
	I - Batch: 800 | Loss: 0.095 | Acc: 97.641% | Wgt Acc: 97.707%
	I - Batch: 850 | Loss: 0.093 | Acc: 97.684% | Wgt Acc: 97.753%
I - num batch: 876
I - Train -- Loss: 0.094 | Acc: 97.672% | Wgt Acc: 97.750% | LR: 1.250000e-04 | Dur: 545.96s
I - Confusion Matrix: [row->prediction - col->label]
[[1855.    1.    1.    9.   74.]
 [   0.  907.   17.    7.   11.]
 [   0.   13. 1291.    0.   70.]
 [   4.    5.    0. 1894.   44.]
 [  27.    1.   26.   16. 7731.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.455 | Acc: 43.500% | Wgt Acc: 42.485%
	I - Batch: 100 | Loss: 2.070 | Acc: 53.812% | Wgt Acc: 48.113%
	I - Batch: 150 | Loss: 1.974 | Acc: 57.333% | Wgt Acc: 50.499%
I - num batch: 193
I - Val -- Loss: 1.960 | Acc: 58.522% | Wgt Acc: 50.994% | Dur: 91.76s
I - Confusion Matrix: [row->prediction - col->label]
[[353.  14.  33. 152.  93.]
 [  9. 130.  36.  37.  37.]
 [ 10.  69. 138.  14.  74.]
 [ 62.  25.  19. 227.  53.]
 [101. 132. 166. 144. 958.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.080 | Acc: 98.750% | Wgt Acc: 98.395%
	I - Batch: 100 | Loss: 0.075 | Acc: 98.875% | Wgt Acc: 98.671%
	I - Batch: 150 | Loss: 0.092 | Acc: 98.125% | Wgt Acc: 97.999%
	I - Batch: 200 | Loss: 0.088 | Acc: 98.156% | Wgt Acc: 98.058%
	I - Batch: 250 | Loss: 0.081 | Acc: 98.275% | Wgt Acc: 98.255%
	I - Batch: 300 | Loss: 0.079 | Acc: 98.396% | Wgt Acc: 98.386%
	I - Batch: 350 | Loss: 0.079 | Acc: 98.429% | Wgt Acc: 98.350%
	I - Batch: 400 | Loss: 0.080 | Acc: 98.359% | Wgt Acc: 98.304%
	I - Batch: 450 | Loss: 0.083 | Acc: 98.181% | Wgt Acc: 98.165%
	I - Batch: 500 | Loss: 0.082 | Acc: 98.188% | Wgt Acc: 98.190%
	I - Batch: 550 | Loss: 0.084 | Acc: 98.148% | Wgt Acc: 98.102%
	I - Batch: 600 | Loss: 0.085 | Acc: 98.104% | Wgt Acc: 98.091%
	I - Batch: 650 | Loss: 0.086 | Acc: 98.087% | Wgt Acc: 98.075%
	I - Batch: 700 | Loss: 0.084 | Acc: 98.134% | Wgt Acc: 98.130%
	I - Batch: 750 | Loss: 0.084 | Acc: 98.125% | Wgt Acc: 98.145%
	I - Batch: 800 | Loss: 0.084 | Acc: 98.141% | Wgt Acc: 98.145%
	I - Batch: 850 | Loss: 0.084 | Acc: 98.140% | Wgt Acc: 98.160%
I - num batch: 876
I - Train -- Loss: 0.083 | Acc: 98.115% | Wgt Acc: 98.152% | LR: 1.250000e-04 | Dur: 547.51s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    1.    5.   53.]
 [   1.  907.   17.    1.   10.]
 [   0.   15. 1293.    0.   59.]
 [   3.    2.    0. 1903.   38.]
 [  15.    3.   24.   17. 7770.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.749 | Acc: 40.500% | Wgt Acc: 39.324%
	I - Batch: 100 | Loss: 2.272 | Acc: 53.375% | Wgt Acc: 45.708%
	I - Batch: 150 | Loss: 2.151 | Acc: 57.250% | Wgt Acc: 48.116%
I - num batch: 193
I - Val -- Loss: 2.143 | Acc: 58.522% | Wgt Acc: 48.808% | Dur: 93.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 308.    9.   23.   97.   33.]
 [   1.   81.   15.   17.   11.]
 [   7.   89.  161.   19.   79.]
 [  62.   39.   19.  224.   60.]
 [ 157.  152.  174.  217. 1032.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.081 | Acc: 97.500% | Wgt Acc: 97.544%
	I - Batch: 100 | Loss: 0.079 | Acc: 98.062% | Wgt Acc: 97.977%
	I - Batch: 150 | Loss: 0.083 | Acc: 97.917% | Wgt Acc: 97.838%
	I - Batch: 200 | Loss: 0.086 | Acc: 97.812% | Wgt Acc: 97.820%
	I - Batch: 250 | Loss: 0.084 | Acc: 97.875% | Wgt Acc: 97.858%
	I - Batch: 300 | Loss: 0.084 | Acc: 97.875% | Wgt Acc: 97.876%
	I - Batch: 350 | Loss: 0.092 | Acc: 97.768% | Wgt Acc: 97.701%
	I - Batch: 400 | Loss: 0.091 | Acc: 97.828% | Wgt Acc: 97.745%
	I - Batch: 450 | Loss: 0.092 | Acc: 97.806% | Wgt Acc: 97.706%
	I - Batch: 500 | Loss: 0.091 | Acc: 97.838% | Wgt Acc: 97.775%
	I - Batch: 550 | Loss: 0.089 | Acc: 97.909% | Wgt Acc: 97.842%
	I - Batch: 600 | Loss: 0.087 | Acc: 97.958% | Wgt Acc: 97.934%
	I - Batch: 650 | Loss: 0.090 | Acc: 97.837% | Wgt Acc: 97.762%
	I - Batch: 700 | Loss: 0.092 | Acc: 97.768% | Wgt Acc: 97.694%
	I - Batch: 750 | Loss: 0.093 | Acc: 97.708% | Wgt Acc: 97.670%
	I - Batch: 800 | Loss: 0.094 | Acc: 97.672% | Wgt Acc: 97.637%
	I - Batch: 850 | Loss: 0.094 | Acc: 97.691% | Wgt Acc: 97.642%
I - num batch: 876
I - Train -- Loss: 0.093 | Acc: 97.679% | Wgt Acc: 97.641% | LR: 1.250000e-04 | Dur: 551.35s
I - Confusion Matrix: [row->prediction - col->label]
[[1858.    2.    0.    5.   50.]
 [   0.  893.   21.    1.   16.]
 [   0.   26. 1282.    0.   88.]
 [   8.    1.    2. 1904.   34.]
 [  20.    5.   30.   16. 7742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.386 | Acc: 44.750% | Wgt Acc: 44.130%
	I - Batch: 100 | Loss: 2.009 | Acc: 55.375% | Wgt Acc: 49.855%
	I - Batch: 150 | Loss: 1.914 | Acc: 58.417% | Wgt Acc: 51.903%
I - num batch: 193
I - Val -- Loss: 1.935 | Acc: 59.138% | Wgt Acc: 52.230% | Dur: 93.80s
I - Confusion Matrix: [row->prediction - col->label]
[[278.   7.  22.  65.  41.]
 [  8. 159.  48.  38.  59.]
 [  7.  40. 132.  10.  69.]
 [ 91.  33.  33. 307.  97.]
 [151. 131. 157. 154. 949.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.058 | Acc: 99.125% | Wgt Acc: 99.118%
	I - Batch: 100 | Loss: 0.089 | Acc: 98.250% | Wgt Acc: 98.046%
	I - Batch: 150 | Loss: 0.108 | Acc: 97.250% | Wgt Acc: 97.125%
	I - Batch: 200 | Loss: 0.109 | Acc: 97.125% | Wgt Acc: 97.126%
	I - Batch: 250 | Loss: 0.104 | Acc: 97.275% | Wgt Acc: 97.384%
	I - Batch: 300 | Loss: 0.104 | Acc: 97.292% | Wgt Acc: 97.333%
	I - Batch: 350 | Loss: 0.101 | Acc: 97.446% | Wgt Acc: 97.486%
	I - Batch: 400 | Loss: 0.097 | Acc: 97.484% | Wgt Acc: 97.501%
	I - Batch: 450 | Loss: 0.095 | Acc: 97.542% | Wgt Acc: 97.601%
	I - Batch: 500 | Loss: 0.091 | Acc: 97.662% | Wgt Acc: 97.728%
	I - Batch: 550 | Loss: 0.091 | Acc: 97.648% | Wgt Acc: 97.716%
	I - Batch: 600 | Loss: 0.092 | Acc: 97.677% | Wgt Acc: 97.725%
	I - Batch: 650 | Loss: 0.092 | Acc: 97.683% | Wgt Acc: 97.714%
	I - Batch: 700 | Loss: 0.092 | Acc: 97.688% | Wgt Acc: 97.685%
	I - Batch: 750 | Loss: 0.092 | Acc: 97.675% | Wgt Acc: 97.693%
	I - Batch: 800 | Loss: 0.092 | Acc: 97.688% | Wgt Acc: 97.705%
	I - Batch: 850 | Loss: 0.094 | Acc: 97.603% | Wgt Acc: 97.607%
I - num batch: 876
I - Train -- Loss: 0.095 | Acc: 97.622% | Wgt Acc: 97.632% | LR: 1.250000e-04 | Dur: 550.85s
I - Confusion Matrix: [row->prediction - col->label]
[[1852.    0.    1.    7.   60.]
 [   2.  902.   23.    4.    9.]
 [   0.   16. 1287.    0.   73.]
 [  10.    4.    0. 1895.   53.]
 [  22.    5.   24.   20. 7735.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.220 | Acc: 49.125% | Wgt Acc: 47.739%
	I - Batch: 100 | Loss: 1.902 | Acc: 55.750% | Wgt Acc: 52.409%
	I - Batch: 150 | Loss: 1.859 | Acc: 57.083% | Wgt Acc: 53.273%
I - num batch: 193
I - Val -- Loss: 1.876 | Acc: 56.999% | Wgt Acc: 53.012% | Dur: 93.70s
I - Confusion Matrix: [row->prediction - col->label]
[[386.  32.  38. 173. 154.]
 [  5. 114.  24.  12.  45.]
 [  4. 116. 172.  25. 112.]
 [ 73.  33.  32. 284. 101.]
 [ 67.  75. 126.  80. 803.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.121 | Acc: 97.000% | Wgt Acc: 96.510%
	I - Batch: 100 | Loss: 0.105 | Acc: 97.750% | Wgt Acc: 97.486%
	I - Batch: 150 | Loss: 0.095 | Acc: 97.625% | Wgt Acc: 97.460%
	I - Batch: 200 | Loss: 0.092 | Acc: 97.719% | Wgt Acc: 97.540%
	I - Batch: 250 | Loss: 0.092 | Acc: 97.725% | Wgt Acc: 97.531%
	I - Batch: 300 | Loss: 0.094 | Acc: 97.562% | Wgt Acc: 97.469%
	I - Batch: 350 | Loss: 0.093 | Acc: 97.554% | Wgt Acc: 97.501%
	I - Batch: 400 | Loss: 0.092 | Acc: 97.594% | Wgt Acc: 97.539%
	I - Batch: 450 | Loss: 0.090 | Acc: 97.667% | Wgt Acc: 97.636%
	I - Batch: 500 | Loss: 0.090 | Acc: 97.650% | Wgt Acc: 97.617%
	I - Batch: 550 | Loss: 0.090 | Acc: 97.693% | Wgt Acc: 97.639%
	I - Batch: 600 | Loss: 0.089 | Acc: 97.740% | Wgt Acc: 97.658%
	I - Batch: 650 | Loss: 0.088 | Acc: 97.760% | Wgt Acc: 97.691%
	I - Batch: 700 | Loss: 0.087 | Acc: 97.795% | Wgt Acc: 97.731%
	I - Batch: 750 | Loss: 0.085 | Acc: 97.850% | Wgt Acc: 97.816%
	I - Batch: 800 | Loss: 0.083 | Acc: 97.883% | Wgt Acc: 97.854%
	I - Batch: 850 | Loss: 0.084 | Acc: 97.868% | Wgt Acc: 97.855%
I - num batch: 876
I - Train -- Loss: 0.083 | Acc: 97.893% | Wgt Acc: 97.873% | LR: 1.250000e-04 | Dur: 551.16s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    1.    0.    5.   51.]
 [   0.  903.   21.    0.    9.]
 [   0.   19. 1279.    0.   70.]
 [   2.    0.    1. 1903.   42.]
 [  18.    4.   34.   18. 7758.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.530 | Acc: 42.375% | Wgt Acc: 41.938%
	I - Batch: 100 | Loss: 2.074 | Acc: 55.875% | Wgt Acc: 49.468%
	I - Batch: 150 | Loss: 1.959 | Acc: 59.292% | Wgt Acc: 51.671%
I - num batch: 193
I - Val -- Loss: 1.992 | Acc: 59.559% | Wgt Acc: 51.337% | Dur: 92.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 287.    9.   21.   74.   32.]
 [   0.  140.   22.   25.   33.]
 [   9.   70.  169.   14.   86.]
 [  81.   16.   21.  235.   57.]
 [ 158.  135.  159.  226. 1007.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.066 | Acc: 97.875% | Wgt Acc: 97.873%
	I - Batch: 100 | Loss: 0.057 | Acc: 98.438% | Wgt Acc: 98.601%
	I - Batch: 150 | Loss: 0.060 | Acc: 98.583% | Wgt Acc: 98.621%
	I - Batch: 200 | Loss: 0.059 | Acc: 98.594% | Wgt Acc: 98.716%
	I - Batch: 250 | Loss: 0.058 | Acc: 98.650% | Wgt Acc: 98.735%
	I - Batch: 300 | Loss: 0.062 | Acc: 98.542% | Wgt Acc: 98.641%
	I - Batch: 350 | Loss: 0.063 | Acc: 98.536% | Wgt Acc: 98.617%
	I - Batch: 400 | Loss: 0.076 | Acc: 98.188% | Wgt Acc: 98.212%
	I - Batch: 450 | Loss: 0.076 | Acc: 98.194% | Wgt Acc: 98.200%
	I - Batch: 500 | Loss: 0.080 | Acc: 97.975% | Wgt Acc: 97.996%
	I - Batch: 550 | Loss: 0.087 | Acc: 97.818% | Wgt Acc: 97.814%
	I - Batch: 600 | Loss: 0.089 | Acc: 97.698% | Wgt Acc: 97.666%
	I - Batch: 650 | Loss: 0.094 | Acc: 97.500% | Wgt Acc: 97.461%
	I - Batch: 700 | Loss: 0.097 | Acc: 97.384% | Wgt Acc: 97.318%
	I - Batch: 750 | Loss: 0.097 | Acc: 97.400% | Wgt Acc: 97.323%
	I - Batch: 800 | Loss: 0.096 | Acc: 97.430% | Wgt Acc: 97.355%
	I - Batch: 850 | Loss: 0.096 | Acc: 97.412% | Wgt Acc: 97.365%
I - num batch: 876
I - Train -- Loss: 0.096 | Acc: 97.422% | Wgt Acc: 97.372% | LR: 1.250000e-04 | Dur: 543.80s
I - Confusion Matrix: [row->prediction - col->label]
[[1852.    1.    0.    6.   66.]
 [   0.  903.   29.    5.   16.]
 [   0.   17. 1265.    0.   78.]
 [  10.    6.    1. 1898.   45.]
 [  24.    0.   40.   17. 7725.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.689 | Acc: 40.250% | Wgt Acc: 39.297%
	I - Batch: 100 | Loss: 2.244 | Acc: 53.375% | Wgt Acc: 46.168%
	I - Batch: 150 | Loss: 2.100 | Acc: 57.083% | Wgt Acc: 48.436%
I - num batch: 193
I - Val -- Loss: 2.088 | Acc: 58.328% | Wgt Acc: 49.034% | Dur: 91.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 303.    9.   28.   94.   50.]
 [   1.  106.   18.   19.   19.]
 [   4.   76.  140.   10.   77.]
 [  73.   28.   18.  233.   51.]
 [ 154.  151.  188.  218. 1018.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.091 | Acc: 97.250% | Wgt Acc: 97.449%
	I - Batch: 100 | Loss: 0.103 | Acc: 96.875% | Wgt Acc: 97.037%
	I - Batch: 150 | Loss: 0.095 | Acc: 97.208% | Wgt Acc: 97.428%
	I - Batch: 200 | Loss: 0.090 | Acc: 97.531% | Wgt Acc: 97.706%
	I - Batch: 250 | Loss: 0.090 | Acc: 97.550% | Wgt Acc: 97.710%
	I - Batch: 300 | Loss: 0.084 | Acc: 97.792% | Wgt Acc: 97.959%
	I - Batch: 350 | Loss: 0.080 | Acc: 97.946% | Wgt Acc: 98.079%
	I - Batch: 400 | Loss: 0.079 | Acc: 98.016% | Wgt Acc: 98.158%
	I - Batch: 450 | Loss: 0.076 | Acc: 98.069% | Wgt Acc: 98.178%
	I - Batch: 500 | Loss: 0.075 | Acc: 98.112% | Wgt Acc: 98.236%
	I - Batch: 550 | Loss: 0.073 | Acc: 98.114% | Wgt Acc: 98.241%
	I - Batch: 600 | Loss: 0.073 | Acc: 98.177% | Wgt Acc: 98.270%
	I - Batch: 650 | Loss: 0.071 | Acc: 98.231% | Wgt Acc: 98.330%
	I - Batch: 700 | Loss: 0.071 | Acc: 98.250% | Wgt Acc: 98.322%
	I - Batch: 750 | Loss: 0.073 | Acc: 98.200% | Wgt Acc: 98.244%
	I - Batch: 800 | Loss: 0.076 | Acc: 98.117% | Wgt Acc: 98.153%
	I - Batch: 850 | Loss: 0.077 | Acc: 98.081% | Wgt Acc: 98.121%
I - num batch: 876
I - Train -- Loss: 0.079 | Acc: 98.093% | Wgt Acc: 98.128% | LR: 1.250000e-04 | Dur: 538.49s
I - Confusion Matrix: [row->prediction - col->label]
[[1858.    3.    0.    5.   56.]
 [   1.  906.   11.    1.    6.]
 [   0.   11. 1300.    0.   53.]
 [   4.    4.    1. 1903.   45.]
 [  23.    3.   23.   17. 7770.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.438 | Acc: 46.500% | Wgt Acc: 45.579%
	I - Batch: 100 | Loss: 2.047 | Acc: 55.688% | Wgt Acc: 50.598%
	I - Batch: 150 | Loss: 1.934 | Acc: 58.792% | Wgt Acc: 52.447%
I - num batch: 193
I - Val -- Loss: 1.935 | Acc: 59.786% | Wgt Acc: 52.870% | Dur: 91.40s
I - Confusion Matrix: [row->prediction - col->label]
[[347.  14.  27. 129. 103.]
 [  3. 151.  48.  16.  34.]
 [  2.  34. 112.   7.  48.]
 [ 80.  29.  40. 287.  82.]
 [103. 142. 165. 135. 948.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 96.250% | Wgt Acc: 96.287%
	I - Batch: 100 | Loss: 0.116 | Acc: 96.812% | Wgt Acc: 96.786%
	I - Batch: 150 | Loss: 0.127 | Acc: 96.208% | Wgt Acc: 96.356%
	I - Batch: 200 | Loss: 0.122 | Acc: 96.312% | Wgt Acc: 96.521%
	I - Batch: 250 | Loss: 0.118 | Acc: 96.500% | Wgt Acc: 96.693%
	I - Batch: 300 | Loss: 0.111 | Acc: 96.646% | Wgt Acc: 96.899%
	I - Batch: 350 | Loss: 0.107 | Acc: 96.821% | Wgt Acc: 96.963%
	I - Batch: 400 | Loss: 0.109 | Acc: 96.766% | Wgt Acc: 96.899%
	I - Batch: 450 | Loss: 0.113 | Acc: 96.681% | Wgt Acc: 96.792%
	I - Batch: 500 | Loss: 0.111 | Acc: 96.787% | Wgt Acc: 96.851%
	I - Batch: 550 | Loss: 0.109 | Acc: 96.864% | Wgt Acc: 96.915%
	I - Batch: 600 | Loss: 0.107 | Acc: 96.896% | Wgt Acc: 96.940%
	I - Batch: 650 | Loss: 0.106 | Acc: 96.913% | Wgt Acc: 96.969%
	I - Batch: 700 | Loss: 0.105 | Acc: 96.973% | Wgt Acc: 97.019%
	I - Batch: 750 | Loss: 0.105 | Acc: 96.975% | Wgt Acc: 97.011%
	I - Batch: 800 | Loss: 0.105 | Acc: 96.977% | Wgt Acc: 96.988%
	I - Batch: 850 | Loss: 0.104 | Acc: 97.022% | Wgt Acc: 97.040%
I - num batch: 876
I - Train -- Loss: 0.103 | Acc: 97.051% | Wgt Acc: 97.063% | LR: 1.250000e-04 | Dur: 540.46s
I - Confusion Matrix: [row->prediction - col->label]
[[1840.    3.    1.   10.   70.]
 [   0.  896.   19.    6.   16.]
 [   0.   15. 1279.    0.   91.]
 [  13.    6.    0. 1887.   64.]
 [  33.    7.   36.   23. 7689.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.758 | Acc: 38.125% | Wgt Acc: 37.416%
	I - Batch: 100 | Loss: 2.271 | Acc: 52.250% | Wgt Acc: 44.925%
	I - Batch: 150 | Loss: 2.174 | Acc: 56.250% | Wgt Acc: 47.365%
I - num batch: 193
I - Val -- Loss: 2.153 | Acc: 58.134% | Wgt Acc: 48.558% | Dur: 92.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 235.    7.   21.   55.   25.]
 [   2.  113.   17.   16.   19.]
 [   6.   66.  144.    5.   74.]
 [  90.   36.   25.  271.   66.]
 [ 202.  148.  185.  227. 1031.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 97.750% | Wgt Acc: 97.482%
	I - Batch: 100 | Loss: 0.084 | Acc: 97.562% | Wgt Acc: 97.538%
	I - Batch: 150 | Loss: 0.087 | Acc: 97.333% | Wgt Acc: 97.310%
	I - Batch: 200 | Loss: 0.084 | Acc: 97.594% | Wgt Acc: 97.628%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.475% | Wgt Acc: 97.461%
	I - Batch: 300 | Loss: 0.083 | Acc: 97.708% | Wgt Acc: 97.683%
	I - Batch: 350 | Loss: 0.084 | Acc: 97.804% | Wgt Acc: 97.820%
	I - Batch: 400 | Loss: 0.084 | Acc: 97.844% | Wgt Acc: 97.833%
	I - Batch: 450 | Loss: 0.085 | Acc: 97.833% | Wgt Acc: 97.792%
	I - Batch: 500 | Loss: 0.085 | Acc: 97.850% | Wgt Acc: 97.814%
	I - Batch: 550 | Loss: 0.088 | Acc: 97.716% | Wgt Acc: 97.679%
	I - Batch: 600 | Loss: 0.092 | Acc: 97.615% | Wgt Acc: 97.573%
	I - Batch: 650 | Loss: 0.095 | Acc: 97.519% | Wgt Acc: 97.417%
	I - Batch: 700 | Loss: 0.095 | Acc: 97.464% | Wgt Acc: 97.327%
	I - Batch: 750 | Loss: 0.097 | Acc: 97.400% | Wgt Acc: 97.251%
	I - Batch: 800 | Loss: 0.095 | Acc: 97.422% | Wgt Acc: 97.302%
	I - Batch: 850 | Loss: 0.093 | Acc: 97.478% | Wgt Acc: 97.389%
I - num batch: 876
I - Train -- Loss: 0.094 | Acc: 97.458% | Wgt Acc: 97.370% | LR: 1.250000e-04 | Dur: 545.50s
I - Confusion Matrix: [row->prediction - col->label]
[[1852.    0.    0.    7.   62.]
 [   0.  898.   28.    4.   12.]
 [   0.   23. 1276.    0.   59.]
 [   8.    3.    1. 1888.   63.]
 [  26.    3.   30.   27. 7734.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.041 | Acc: 34.625% | Wgt Acc: 33.610%
	I - Batch: 100 | Loss: 2.518 | Acc: 49.625% | Wgt Acc: 40.916%
	I - Batch: 150 | Loss: 2.341 | Acc: 54.958% | Wgt Acc: 44.345%
I - num batch: 193
I - Val -- Loss: 2.334 | Acc: 56.416% | Wgt Acc: 45.162% | Dur: 91.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 272.    8.   19.  108.   42.]
 [   0.   72.    8.    8.   10.]
 [   8.   79.  146.   15.   51.]
 [  53.   24.   13.  185.   46.]
 [ 202.  187.  206.  258. 1066.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 99.000% | Wgt Acc: 99.062%
	I - Batch: 100 | Loss: 0.071 | Acc: 98.562% | Wgt Acc: 98.686%
	I - Batch: 150 | Loss: 0.070 | Acc: 98.667% | Wgt Acc: 98.699%
	I - Batch: 200 | Loss: 0.077 | Acc: 98.375% | Wgt Acc: 98.431%
	I - Batch: 250 | Loss: 0.073 | Acc: 98.525% | Wgt Acc: 98.530%
	I - Batch: 300 | Loss: 0.075 | Acc: 98.438% | Wgt Acc: 98.423%
	I - Batch: 350 | Loss: 0.075 | Acc: 98.411% | Wgt Acc: 98.412%
	I - Batch: 400 | Loss: 0.079 | Acc: 98.312% | Wgt Acc: 98.279%
	I - Batch: 450 | Loss: 0.080 | Acc: 98.222% | Wgt Acc: 98.216%
	I - Batch: 500 | Loss: 0.084 | Acc: 97.987% | Wgt Acc: 97.984%
	I - Batch: 550 | Loss: 0.083 | Acc: 98.000% | Wgt Acc: 97.962%
	I - Batch: 600 | Loss: 0.083 | Acc: 97.958% | Wgt Acc: 97.940%
	I - Batch: 650 | Loss: 0.084 | Acc: 97.923% | Wgt Acc: 97.909%
	I - Batch: 700 | Loss: 0.084 | Acc: 97.920% | Wgt Acc: 97.887%
	I - Batch: 750 | Loss: 0.086 | Acc: 97.808% | Wgt Acc: 97.767%
	I - Batch: 800 | Loss: 0.087 | Acc: 97.773% | Wgt Acc: 97.737%
	I - Batch: 850 | Loss: 0.085 | Acc: 97.824% | Wgt Acc: 97.795%
I - num batch: 876
I - Train -- Loss: 0.085 | Acc: 97.836% | Wgt Acc: 97.813% | LR: 1.250000e-04 | Dur: 543.31s
I - Confusion Matrix: [row->prediction - col->label]
[[1855.    2.    1.    8.   61.]
 [   1.  903.   23.    2.   10.]
 [   0.   16. 1287.    2.   59.]
 [   9.    4.    0. 1900.   44.]
 [  21.    2.   24.   14. 7756.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.600 | Acc: 40.875% | Wgt Acc: 40.554%
	I - Batch: 100 | Loss: 2.250 | Acc: 52.562% | Wgt Acc: 45.967%
	I - Batch: 150 | Loss: 2.144 | Acc: 55.833% | Wgt Acc: 47.835%
I - num batch: 193
I - Val -- Loss: 2.149 | Acc: 57.129% | Wgt Acc: 48.733% | Dur: 92.17s
I - Confusion Matrix: [row->prediction - col->label]
[[227.   7.  18.  55.  24.]
 [  6. 149.  45.  34.  51.]
 [ 10.  47. 132.  15.  74.]
 [ 96.  26.  25. 270.  81.]
 [196. 141. 172. 200. 985.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.142 | Acc: 95.000% | Wgt Acc: 94.612%
	I - Batch: 100 | Loss: 0.113 | Acc: 96.312% | Wgt Acc: 96.187%
	I - Batch: 150 | Loss: 0.102 | Acc: 96.750% | Wgt Acc: 96.771%
	I - Batch: 200 | Loss: 0.097 | Acc: 96.969% | Wgt Acc: 97.059%
	I - Batch: 250 | Loss: 0.103 | Acc: 96.775% | Wgt Acc: 96.853%
	I - Batch: 300 | Loss: 0.103 | Acc: 96.750% | Wgt Acc: 96.814%
	I - Batch: 350 | Loss: 0.100 | Acc: 96.857% | Wgt Acc: 96.910%
	I - Batch: 400 | Loss: 0.098 | Acc: 97.000% | Wgt Acc: 97.010%
	I - Batch: 450 | Loss: 0.095 | Acc: 97.097% | Wgt Acc: 97.117%
	I - Batch: 500 | Loss: 0.097 | Acc: 97.037% | Wgt Acc: 97.084%
	I - Batch: 550 | Loss: 0.094 | Acc: 97.193% | Wgt Acc: 97.242%
	I - Batch: 600 | Loss: 0.097 | Acc: 97.177% | Wgt Acc: 97.183%
	I - Batch: 650 | Loss: 0.095 | Acc: 97.231% | Wgt Acc: 97.277%
	I - Batch: 700 | Loss: 0.097 | Acc: 97.170% | Wgt Acc: 97.199%
	I - Batch: 750 | Loss: 0.098 | Acc: 97.092% | Wgt Acc: 97.129%
	I - Batch: 800 | Loss: 0.098 | Acc: 97.141% | Wgt Acc: 97.191%
	I - Batch: 850 | Loss: 0.097 | Acc: 97.147% | Wgt Acc: 97.203%
I - num batch: 876
I - Train -- Loss: 0.098 | Acc: 97.179% | Wgt Acc: 97.219% | LR: 1.250000e-04 | Dur: 544.13s
I - Confusion Matrix: [row->prediction - col->label]
[[1838.    1.    0.    6.   76.]
 [   1.  900.   22.    4.   19.]
 [   0.   20. 1276.    0.   76.]
 [   7.    4.    1. 1900.   64.]
 [  40.    2.   36.   16. 7695.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.541 | Acc: 43.375% | Wgt Acc: 41.878%
	I - Batch: 100 | Loss: 2.133 | Acc: 52.500% | Wgt Acc: 46.934%
	I - Batch: 150 | Loss: 1.998 | Acc: 56.250% | Wgt Acc: 49.482%
I - num batch: 193
I - Val -- Loss: 1.988 | Acc: 57.323% | Wgt Acc: 50.005% | Dur: 92.11s
I - Confusion Matrix: [row->prediction - col->label]
[[355.  13.  31. 134. 113.]
 [  5. 102.  34.  11.  35.]
 [  3.  36.  90.  11.  38.]
 [103.  50.  41. 306. 113.]
 [ 69. 169. 196. 112. 916.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.119 | Acc: 96.750% | Wgt Acc: 96.970%
	I - Batch: 100 | Loss: 0.100 | Acc: 97.062% | Wgt Acc: 97.429%
	I - Batch: 150 | Loss: 0.094 | Acc: 97.333% | Wgt Acc: 97.668%
	I - Batch: 200 | Loss: 0.084 | Acc: 97.750% | Wgt Acc: 98.077%
	I - Batch: 250 | Loss: 0.080 | Acc: 97.925% | Wgt Acc: 98.228%
	I - Batch: 300 | Loss: 0.075 | Acc: 98.083% | Wgt Acc: 98.355%
	I - Batch: 350 | Loss: 0.074 | Acc: 98.125% | Wgt Acc: 98.344%
	I - Batch: 400 | Loss: 0.072 | Acc: 98.203% | Wgt Acc: 98.399%
	I - Batch: 450 | Loss: 0.073 | Acc: 98.181% | Wgt Acc: 98.350%
	I - Batch: 500 | Loss: 0.072 | Acc: 98.237% | Wgt Acc: 98.400%
	I - Batch: 550 | Loss: 0.073 | Acc: 98.182% | Wgt Acc: 98.306%
	I - Batch: 600 | Loss: 0.073 | Acc: 98.177% | Wgt Acc: 98.318%
	I - Batch: 650 | Loss: 0.074 | Acc: 98.106% | Wgt Acc: 98.215%
	I - Batch: 700 | Loss: 0.077 | Acc: 98.045% | Wgt Acc: 98.142%
	I - Batch: 750 | Loss: 0.077 | Acc: 98.008% | Wgt Acc: 98.107%
	I - Batch: 800 | Loss: 0.078 | Acc: 97.969% | Wgt Acc: 98.047%
	I - Batch: 850 | Loss: 0.077 | Acc: 98.029% | Wgt Acc: 98.106%
I - num batch: 876
I - Train -- Loss: 0.076 | Acc: 98.065% | Wgt Acc: 98.124% | LR: 1.250000e-04 | Dur: 540.79s
I - Confusion Matrix: [row->prediction - col->label]
[[1861.    1.    0.    7.   53.]
 [   0.  905.   10.    5.   11.]
 [   0.   14. 1301.    0.   67.]
 [   4.    6.    1. 1902.   35.]
 [  21.    1.   23.   12. 7764.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.543 | Acc: 44.250% | Wgt Acc: 43.786%
	I - Batch: 100 | Loss: 2.170 | Acc: 55.062% | Wgt Acc: 48.820%
	I - Batch: 150 | Loss: 2.052 | Acc: 58.833% | Wgt Acc: 51.430%
I - num batch: 193
I - Val -- Loss: 2.069 | Acc: 59.235% | Wgt Acc: 51.069% | Dur: 90.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 313.    8.   26.   85.   43.]
 [   6.  142.   32.   28.   32.]
 [  15.   76.  172.   26.  106.]
 [  52.    9.   11.  198.   31.]
 [ 149.  135.  151.  237. 1003.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.068 | Acc: 98.500% | Wgt Acc: 98.503%
	I - Batch: 100 | Loss: 0.069 | Acc: 98.438% | Wgt Acc: 98.381%
	I - Batch: 150 | Loss: 0.059 | Acc: 98.792% | Wgt Acc: 98.721%
	I - Batch: 200 | Loss: 0.056 | Acc: 98.750% | Wgt Acc: 98.785%
	I - Batch: 250 | Loss: 0.055 | Acc: 98.725% | Wgt Acc: 98.731%
	I - Batch: 300 | Loss: 0.053 | Acc: 98.833% | Wgt Acc: 98.834%
	I - Batch: 350 | Loss: 0.056 | Acc: 98.732% | Wgt Acc: 98.703%
	I - Batch: 400 | Loss: 0.058 | Acc: 98.703% | Wgt Acc: 98.640%
	I - Batch: 450 | Loss: 0.057 | Acc: 98.722% | Wgt Acc: 98.692%
	I - Batch: 500 | Loss: 0.058 | Acc: 98.675% | Wgt Acc: 98.651%
	I - Batch: 550 | Loss: 0.057 | Acc: 98.648% | Wgt Acc: 98.620%
	I - Batch: 600 | Loss: 0.057 | Acc: 98.677% | Wgt Acc: 98.662%
	I - Batch: 650 | Loss: 0.058 | Acc: 98.596% | Wgt Acc: 98.612%
	I - Batch: 700 | Loss: 0.060 | Acc: 98.500% | Wgt Acc: 98.524%
	I - Batch: 750 | Loss: 0.060 | Acc: 98.508% | Wgt Acc: 98.508%
	I - Batch: 800 | Loss: 0.061 | Acc: 98.516% | Wgt Acc: 98.504%
	I - Batch: 850 | Loss: 0.061 | Acc: 98.515% | Wgt Acc: 98.508%
I - num batch: 876
I - Train -- Loss: 0.060 | Acc: 98.536% | Wgt Acc: 98.530% | LR: 1.250000e-04 | Dur: 535.31s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    1.    0.    6.   36.]
 [   1.  909.   14.    1.   10.]
 [   0.   12. 1302.    0.   46.]
 [   2.    3.    1. 1907.   28.]
 [  12.    2.   18.   12. 7810.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.678 | Acc: 43.625% | Wgt Acc: 42.654%
	I - Batch: 100 | Loss: 2.319 | Acc: 53.312% | Wgt Acc: 46.122%
	I - Batch: 150 | Loss: 2.161 | Acc: 57.875% | Wgt Acc: 48.854%
I - num batch: 193
I - Val -- Loss: 2.184 | Acc: 59.106% | Wgt Acc: 49.215% | Dur: 90.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 299.   11.   31.  105.   51.]
 [   0.  120.   27.   17.   32.]
 [   8.   48.  110.    9.   26.]
 [  65.   35.   23.  247.   58.]
 [ 163.  156.  201.  196. 1048.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.066 | Acc: 98.500% | Wgt Acc: 97.992%
	I - Batch: 100 | Loss: 0.055 | Acc: 98.875% | Wgt Acc: 98.653%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.917% | Wgt Acc: 98.718%
	I - Batch: 200 | Loss: 0.049 | Acc: 99.062% | Wgt Acc: 98.970%
	I - Batch: 250 | Loss: 0.050 | Acc: 99.025% | Wgt Acc: 98.978%
	I - Batch: 300 | Loss: 0.049 | Acc: 99.062% | Wgt Acc: 99.017%
	I - Batch: 350 | Loss: 0.051 | Acc: 99.036% | Wgt Acc: 99.030%
	I - Batch: 400 | Loss: 0.052 | Acc: 98.984% | Wgt Acc: 98.950%
	I - Batch: 450 | Loss: 0.054 | Acc: 98.875% | Wgt Acc: 98.843%
	I - Batch: 500 | Loss: 0.056 | Acc: 98.838% | Wgt Acc: 98.817%
	I - Batch: 550 | Loss: 0.054 | Acc: 98.852% | Wgt Acc: 98.861%
	I - Batch: 600 | Loss: 0.054 | Acc: 98.854% | Wgt Acc: 98.828%
	I - Batch: 650 | Loss: 0.063 | Acc: 98.615% | Wgt Acc: 98.595%
	I - Batch: 700 | Loss: 0.066 | Acc: 98.554% | Wgt Acc: 98.524%
	I - Batch: 750 | Loss: 0.065 | Acc: 98.542% | Wgt Acc: 98.526%
	I - Batch: 800 | Loss: 0.067 | Acc: 98.477% | Wgt Acc: 98.476%
	I - Batch: 850 | Loss: 0.067 | Acc: 98.478% | Wgt Acc: 98.460%
I - num batch: 876
I - Train -- Loss: 0.067 | Acc: 98.465% | Wgt Acc: 98.458% | LR: 1.250000e-04 | Dur: 538.52s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    2.    2.    5.   38.]
 [   1.  903.    9.    3.    7.]
 [   0.    9. 1308.    0.   38.]
 [   2.    7.    0. 1908.   43.]
 [  17.    6.   16.   10. 7804.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.002 | Acc: 38.250% | Wgt Acc: 37.416%
	I - Batch: 100 | Loss: 2.470 | Acc: 51.938% | Wgt Acc: 44.173%
	I - Batch: 150 | Loss: 2.303 | Acc: 56.625% | Wgt Acc: 47.250%
I - num batch: 193
I - Val -- Loss: 2.286 | Acc: 58.328% | Wgt Acc: 48.206% | Dur: 91.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 269.    5.   14.   77.   33.]
 [   2.   97.   11.   11.   17.]
 [   8.   72.  150.   15.   60.]
 [  72.   20.   14.  234.   55.]
 [ 184.  176.  203.  237. 1050.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.120 | Acc: 96.375% | Wgt Acc: 96.484%
	I - Batch: 100 | Loss: 0.106 | Acc: 97.125% | Wgt Acc: 97.301%
	I - Batch: 150 | Loss: 0.102 | Acc: 97.333% | Wgt Acc: 97.206%
	I - Batch: 200 | Loss: 0.101 | Acc: 97.406% | Wgt Acc: 97.256%
	I - Batch: 250 | Loss: 0.096 | Acc: 97.400% | Wgt Acc: 97.330%
	I - Batch: 300 | Loss: 0.096 | Acc: 97.375% | Wgt Acc: 97.304%
	I - Batch: 350 | Loss: 0.097 | Acc: 97.393% | Wgt Acc: 97.289%
	I - Batch: 400 | Loss: 0.094 | Acc: 97.406% | Wgt Acc: 97.343%
	I - Batch: 450 | Loss: 0.091 | Acc: 97.542% | Wgt Acc: 97.486%
	I - Batch: 500 | Loss: 0.088 | Acc: 97.600% | Wgt Acc: 97.541%
	I - Batch: 550 | Loss: 0.087 | Acc: 97.659% | Wgt Acc: 97.618%
	I - Batch: 600 | Loss: 0.083 | Acc: 97.771% | Wgt Acc: 97.761%
	I - Batch: 650 | Loss: 0.082 | Acc: 97.837% | Wgt Acc: 97.793%
	I - Batch: 700 | Loss: 0.080 | Acc: 97.920% | Wgt Acc: 97.871%
	I - Batch: 750 | Loss: 0.080 | Acc: 97.925% | Wgt Acc: 97.881%
	I - Batch: 800 | Loss: 0.079 | Acc: 97.898% | Wgt Acc: 97.842%
	I - Batch: 850 | Loss: 0.078 | Acc: 97.949% | Wgt Acc: 97.897%
I - num batch: 876
I - Train -- Loss: 0.079 | Acc: 97.929% | Wgt Acc: 97.875% | LR: 1.250000e-04 | Dur: 540.87s
I - Confusion Matrix: [row->prediction - col->label]
[[1864.    0.    1.    4.   48.]
 [   0.  903.   22.    4.   19.]
 [   0.   19. 1280.    0.   53.]
 [   4.    3.    2. 1901.   44.]
 [  18.    2.   30.   17. 7766.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.262 | Acc: 50.125% | Wgt Acc: 49.445%
	I - Batch: 100 | Loss: 1.958 | Acc: 58.062% | Wgt Acc: 53.734%
	I - Batch: 150 | Loss: 1.867 | Acc: 60.417% | Wgt Acc: 55.345%
I - num batch: 193
I - Val -- Loss: 1.897 | Acc: 60.078% | Wgt Acc: 54.457% | Dur: 91.56s
I - Confusion Matrix: [row->prediction - col->label]
[[343.   8.  30. 109.  69.]
 [  7. 167.  49.  38.  49.]
 [  6.  45. 159.  18.  92.]
 [ 89.  29.  18. 269.  89.]
 [ 90. 121. 136. 140. 916.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.074 | Acc: 97.375% | Wgt Acc: 97.743%
	I - Batch: 100 | Loss: 0.076 | Acc: 97.625% | Wgt Acc: 97.532%
	I - Batch: 150 | Loss: 0.078 | Acc: 97.750% | Wgt Acc: 97.735%
	I - Batch: 200 | Loss: 0.075 | Acc: 97.969% | Wgt Acc: 97.942%
	I - Batch: 250 | Loss: 0.072 | Acc: 98.000% | Wgt Acc: 98.061%
	I - Batch: 300 | Loss: 0.068 | Acc: 98.104% | Wgt Acc: 98.154%
	I - Batch: 350 | Loss: 0.065 | Acc: 98.214% | Wgt Acc: 98.309%
	I - Batch: 400 | Loss: 0.063 | Acc: 98.312% | Wgt Acc: 98.410%
	I - Batch: 450 | Loss: 0.063 | Acc: 98.347% | Wgt Acc: 98.383%
	I - Batch: 500 | Loss: 0.063 | Acc: 98.375% | Wgt Acc: 98.442%
	I - Batch: 550 | Loss: 0.062 | Acc: 98.420% | Wgt Acc: 98.476%
	I - Batch: 600 | Loss: 0.061 | Acc: 98.438% | Wgt Acc: 98.497%
	I - Batch: 650 | Loss: 0.061 | Acc: 98.442% | Wgt Acc: 98.481%
	I - Batch: 700 | Loss: 0.061 | Acc: 98.446% | Wgt Acc: 98.481%
	I - Batch: 750 | Loss: 0.061 | Acc: 98.408% | Wgt Acc: 98.445%
	I - Batch: 800 | Loss: 0.062 | Acc: 98.398% | Wgt Acc: 98.419%
	I - Batch: 850 | Loss: 0.062 | Acc: 98.404% | Wgt Acc: 98.422%
I - num batch: 876
I - Train -- Loss: 0.062 | Acc: 98.386% | Wgt Acc: 98.409% | LR: 1.250000e-04 | Dur: 541.59s
I - Confusion Matrix: [row->prediction - col->label]
[[1869.    0.    2.    4.   40.]
 [   0.  908.   11.    0.   14.]
 [   0.   13. 1296.    0.   52.]
 [   2.    2.    0. 1912.   31.]
 [  15.    4.   26.   10. 7793.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.727 | Acc: 42.750% | Wgt Acc: 41.271%
	I - Batch: 100 | Loss: 2.224 | Acc: 54.312% | Wgt Acc: 47.617%
	I - Batch: 150 | Loss: 2.065 | Acc: 59.625% | Wgt Acc: 51.442%
I - num batch: 193
I - Val -- Loss: 2.057 | Acc: 60.207% | Wgt Acc: 51.463% | Dur: 92.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 343.    8.   22.  115.   63.]
 [   0.  119.   30.   13.   20.]
 [   3.   24.   99.    5.   30.]
 [  77.   42.   28.  287.   92.]
 [ 112.  177.  213.  154. 1010.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 99.625% | Wgt Acc: 99.496%
	I - Batch: 100 | Loss: 0.034 | Acc: 99.375% | Wgt Acc: 99.444%
	I - Batch: 150 | Loss: 0.047 | Acc: 99.167% | Wgt Acc: 99.110%
	I - Batch: 200 | Loss: 0.048 | Acc: 99.094% | Wgt Acc: 99.097%
	I - Batch: 250 | Loss: 0.047 | Acc: 99.150% | Wgt Acc: 99.130%
	I - Batch: 300 | Loss: 0.050 | Acc: 99.000% | Wgt Acc: 99.003%
	I - Batch: 350 | Loss: 0.049 | Acc: 99.054% | Wgt Acc: 99.078%
	I - Batch: 400 | Loss: 0.046 | Acc: 99.109% | Wgt Acc: 99.145%
	I - Batch: 450 | Loss: 0.048 | Acc: 99.000% | Wgt Acc: 99.029%
	I - Batch: 500 | Loss: 0.048 | Acc: 98.987% | Wgt Acc: 99.007%
	I - Batch: 550 | Loss: 0.051 | Acc: 98.875% | Wgt Acc: 98.945%
	I - Batch: 600 | Loss: 0.051 | Acc: 98.865% | Wgt Acc: 98.935%
	I - Batch: 650 | Loss: 0.051 | Acc: 98.837% | Wgt Acc: 98.930%
	I - Batch: 700 | Loss: 0.053 | Acc: 98.821% | Wgt Acc: 98.915%
	I - Batch: 750 | Loss: 0.053 | Acc: 98.800% | Wgt Acc: 98.890%
	I - Batch: 800 | Loss: 0.051 | Acc: 98.844% | Wgt Acc: 98.935%
	I - Batch: 850 | Loss: 0.052 | Acc: 98.831% | Wgt Acc: 98.908%
I - num batch: 876
I - Train -- Loss: 0.052 | Acc: 98.807% | Wgt Acc: 98.894% | LR: 1.250000e-04 | Dur: 546.15s
I - Confusion Matrix: [row->prediction - col->label]
[[1869.    1.    0.    2.   41.]
 [   1.  920.    8.    2.    4.]
 [   0.    4. 1312.    0.   33.]
 [   3.    0.    1. 1914.   30.]
 [  13.    2.   14.    8. 7822.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.014 | Acc: 40.125% | Wgt Acc: 38.848%
	I - Batch: 100 | Loss: 2.479 | Acc: 53.062% | Wgt Acc: 45.001%
	I - Batch: 150 | Loss: 2.275 | Acc: 58.125% | Wgt Acc: 48.346%
I - num batch: 193
I - Val -- Loss: 2.251 | Acc: 59.106% | Wgt Acc: 48.834% | Dur: 91.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 373.   10.   23.  179.   65.]
 [   4.   78.   12.    6.   14.]
 [   5.   66.  140.   15.   45.]
 [  33.   22.   15.  179.   37.]
 [ 120.  194.  202.  195. 1054.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 98.875% | Wgt Acc: 98.727%
	I - Batch: 100 | Loss: 0.058 | Acc: 98.750% | Wgt Acc: 98.572%
	I - Batch: 150 | Loss: 0.061 | Acc: 98.708% | Wgt Acc: 98.653%
	I - Batch: 200 | Loss: 0.057 | Acc: 98.781% | Wgt Acc: 98.755%
	I - Batch: 250 | Loss: 0.052 | Acc: 98.875% | Wgt Acc: 98.889%
	I - Batch: 300 | Loss: 0.049 | Acc: 98.938% | Wgt Acc: 98.970%
	I - Batch: 350 | Loss: 0.048 | Acc: 99.000% | Wgt Acc: 99.066%
	I - Batch: 400 | Loss: 0.049 | Acc: 98.938% | Wgt Acc: 98.999%
	I - Batch: 450 | Loss: 0.049 | Acc: 98.903% | Wgt Acc: 98.991%
	I - Batch: 500 | Loss: 0.049 | Acc: 98.862% | Wgt Acc: 98.955%
	I - Batch: 550 | Loss: 0.047 | Acc: 98.943% | Wgt Acc: 99.037%
	I - Batch: 600 | Loss: 0.046 | Acc: 98.969% | Wgt Acc: 99.060%
	I - Batch: 650 | Loss: 0.047 | Acc: 98.923% | Wgt Acc: 99.000%
	I - Batch: 700 | Loss: 0.047 | Acc: 98.911% | Wgt Acc: 98.982%
	I - Batch: 750 | Loss: 0.048 | Acc: 98.850% | Wgt Acc: 98.913%
	I - Batch: 800 | Loss: 0.050 | Acc: 98.789% | Wgt Acc: 98.841%
	I - Batch: 850 | Loss: 0.050 | Acc: 98.779% | Wgt Acc: 98.840%
I - num batch: 876
I - Train -- Loss: 0.050 | Acc: 98.779% | Wgt Acc: 98.853% | LR: 1.250000e-04 | Dur: 541.94s
I - Confusion Matrix: [row->prediction - col->label]
[[1878.    1.    1.    3.   23.]
 [   0.  921.    4.    3.   12.]
 [   0.    3. 1302.    0.   60.]
 [   2.    2.    0. 1912.   15.]
 [   6.    0.   28.    8. 7820.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.069 | Acc: 39.250% | Wgt Acc: 37.667%
	I - Batch: 100 | Loss: 2.520 | Acc: 52.438% | Wgt Acc: 44.255%
	I - Batch: 150 | Loss: 2.324 | Acc: 57.333% | Wgt Acc: 47.672%
I - num batch: 193
I - Val -- Loss: 2.271 | Acc: 59.138% | Wgt Acc: 48.938% | Dur: 91.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 318.   10.   25.   97.   40.]
 [   0.   62.   14.    5.    3.]
 [   4.   66.  130.   12.   57.]
 [  70.   45.   24.  272.   72.]
 [ 143.  187.  199.  188. 1043.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 99.250% | Wgt Acc: 99.338%
	I - Batch: 100 | Loss: 0.044 | Acc: 99.000% | Wgt Acc: 98.987%
	I - Batch: 150 | Loss: 0.047 | Acc: 98.917% | Wgt Acc: 98.908%
	I - Batch: 200 | Loss: 0.048 | Acc: 98.969% | Wgt Acc: 98.951%
	I - Batch: 250 | Loss: 0.048 | Acc: 99.050% | Wgt Acc: 99.006%
	I - Batch: 300 | Loss: 0.050 | Acc: 98.896% | Wgt Acc: 98.802%
	I - Batch: 350 | Loss: 0.058 | Acc: 98.571% | Wgt Acc: 98.542%
	I - Batch: 400 | Loss: 0.057 | Acc: 98.609% | Wgt Acc: 98.596%
	I - Batch: 450 | Loss: 0.056 | Acc: 98.653% | Wgt Acc: 98.628%
	I - Batch: 500 | Loss: 0.058 | Acc: 98.612% | Wgt Acc: 98.534%
	I - Batch: 550 | Loss: 0.058 | Acc: 98.568% | Wgt Acc: 98.525%
	I - Batch: 600 | Loss: 0.059 | Acc: 98.521% | Wgt Acc: 98.487%
	I - Batch: 650 | Loss: 0.059 | Acc: 98.529% | Wgt Acc: 98.484%
	I - Batch: 700 | Loss: 0.061 | Acc: 98.473% | Wgt Acc: 98.447%
	I - Batch: 750 | Loss: 0.061 | Acc: 98.433% | Wgt Acc: 98.424%
	I - Batch: 800 | Loss: 0.061 | Acc: 98.445% | Wgt Acc: 98.438%
	I - Batch: 850 | Loss: 0.060 | Acc: 98.471% | Wgt Acc: 98.481%
I - num batch: 876
I - Train -- Loss: 0.060 | Acc: 98.486% | Wgt Acc: 98.493% | LR: 1.250000e-04 | Dur: 543.49s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    1.    1.    4.   45.]
 [   0.  909.    9.    2.   10.]
 [   0.   11. 1309.    1.   41.]
 [   5.    4.    0. 1902.   28.]
 [  15.    2.   16.   17. 7806.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.641 | Acc: 43.250% | Wgt Acc: 42.578%
	I - Batch: 100 | Loss: 2.234 | Acc: 54.562% | Wgt Acc: 48.051%
	I - Batch: 150 | Loss: 2.105 | Acc: 58.625% | Wgt Acc: 50.229%
I - num batch: 193
I - Val -- Loss: 2.107 | Acc: 59.657% | Wgt Acc: 50.677% | Dur: 92.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 304.    5.   21.  100.   46.]
 [   4.  131.   25.   37.   33.]
 [   9.   63.  144.   17.   62.]
 [  71.   21.   14.  233.   45.]
 [ 147.  150.  188.  187. 1029.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.101 | Acc: 96.875% | Wgt Acc: 97.156%
	I - Batch: 100 | Loss: 0.079 | Acc: 98.000% | Wgt Acc: 98.117%
	I - Batch: 150 | Loss: 0.071 | Acc: 98.208% | Wgt Acc: 98.286%
	I - Batch: 200 | Loss: 0.075 | Acc: 98.031% | Wgt Acc: 98.100%
	I - Batch: 250 | Loss: 0.077 | Acc: 97.925% | Wgt Acc: 97.978%
	I - Batch: 300 | Loss: 0.074 | Acc: 97.896% | Wgt Acc: 98.035%
	I - Batch: 350 | Loss: 0.073 | Acc: 97.857% | Wgt Acc: 97.965%
	I - Batch: 400 | Loss: 0.072 | Acc: 97.938% | Wgt Acc: 98.022%
	I - Batch: 450 | Loss: 0.071 | Acc: 97.972% | Wgt Acc: 98.045%
	I - Batch: 500 | Loss: 0.068 | Acc: 98.050% | Wgt Acc: 98.145%
	I - Batch: 550 | Loss: 0.067 | Acc: 98.148% | Wgt Acc: 98.239%
	I - Batch: 600 | Loss: 0.065 | Acc: 98.240% | Wgt Acc: 98.314%
	I - Batch: 650 | Loss: 0.064 | Acc: 98.269% | Wgt Acc: 98.326%
	I - Batch: 700 | Loss: 0.063 | Acc: 98.321% | Wgt Acc: 98.385%
	I - Batch: 750 | Loss: 0.062 | Acc: 98.333% | Wgt Acc: 98.385%
	I - Batch: 800 | Loss: 0.063 | Acc: 98.359% | Wgt Acc: 98.403%
	I - Batch: 850 | Loss: 0.063 | Acc: 98.353% | Wgt Acc: 98.389%
I - num batch: 876
I - Train -- Loss: 0.063 | Acc: 98.358% | Wgt Acc: 98.386% | LR: 1.250000e-04 | Dur: 549.00s
I - Confusion Matrix: [row->prediction - col->label]
[[1863.    2.    0.    4.   44.]
 [   1.  907.   13.    4.   12.]
 [   0.   11. 1302.    0.   53.]
 [   4.    2.    1. 1911.   30.]
 [  18.    5.   19.    7. 7791.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.149 | Acc: 35.250% | Wgt Acc: 34.715%
	I - Batch: 100 | Loss: 2.621 | Acc: 51.125% | Wgt Acc: 42.470%
	I - Batch: 150 | Loss: 2.470 | Acc: 55.500% | Wgt Acc: 44.817%
I - num batch: 193
I - Val -- Loss: 2.466 | Acc: 57.291% | Wgt Acc: 45.912% | Dur: 92.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 200.    5.   11.   47.   14.]
 [   4.  114.   29.   19.   23.]
 [   9.   62.  134.   14.   56.]
 [  80.   17.   14.  227.   29.]
 [ 242.  172.  204.  267. 1093.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 99.250% | Wgt Acc: 99.097%
	I - Batch: 100 | Loss: 0.055 | Acc: 98.750% | Wgt Acc: 98.546%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.917% | Wgt Acc: 98.797%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.906% | Wgt Acc: 98.810%
	I - Batch: 250 | Loss: 0.057 | Acc: 98.825% | Wgt Acc: 98.751%
	I - Batch: 300 | Loss: 0.067 | Acc: 98.562% | Wgt Acc: 98.435%
	I - Batch: 350 | Loss: 0.068 | Acc: 98.464% | Wgt Acc: 98.323%
	I - Batch: 400 | Loss: 0.067 | Acc: 98.469% | Wgt Acc: 98.328%
	I - Batch: 450 | Loss: 0.066 | Acc: 98.528% | Wgt Acc: 98.410%
	I - Batch: 500 | Loss: 0.065 | Acc: 98.562% | Wgt Acc: 98.450%
	I - Batch: 550 | Loss: 0.066 | Acc: 98.489% | Wgt Acc: 98.377%
	I - Batch: 600 | Loss: 0.070 | Acc: 98.365% | Wgt Acc: 98.283%
	I - Batch: 650 | Loss: 0.073 | Acc: 98.250% | Wgt Acc: 98.147%
	I - Batch: 700 | Loss: 0.075 | Acc: 98.152% | Wgt Acc: 98.051%
	I - Batch: 750 | Loss: 0.076 | Acc: 98.142% | Wgt Acc: 98.027%
	I - Batch: 800 | Loss: 0.075 | Acc: 98.109% | Wgt Acc: 98.032%
	I - Batch: 850 | Loss: 0.074 | Acc: 98.103% | Wgt Acc: 98.031%
I - num batch: 876
I - Train -- Loss: 0.076 | Acc: 98.072% | Wgt Acc: 98.004% | LR: 1.250000e-04 | Dur: 540.09s
I - Confusion Matrix: [row->prediction - col->label]
[[1855.    1.    2.    6.   51.]
 [   0.  900.   14.    3.   15.]
 [   0.   15. 1296.    0.   44.]
 [   9.    5.    0. 1902.   39.]
 [  22.    6.   23.   15. 7781.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.087 | Acc: 40.375% | Wgt Acc: 39.056%
	I - Batch: 100 | Loss: 2.512 | Acc: 54.312% | Wgt Acc: 46.125%
	I - Batch: 150 | Loss: 2.316 | Acc: 59.167% | Wgt Acc: 49.324%
I - num batch: 193
I - Val -- Loss: 2.312 | Acc: 60.110% | Wgt Acc: 49.459% | Dur: 91.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 320.    8.   21.  102.   41.]
 [   1.   93.   17.   10.    9.]
 [   3.   49.  119.   10.   35.]
 [  68.   29.   18.  243.   50.]
 [ 143.  191.  217.  209. 1080.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 98.000% | Wgt Acc: 97.642%
	I - Batch: 100 | Loss: 0.070 | Acc: 98.375% | Wgt Acc: 98.329%
	I - Batch: 150 | Loss: 0.063 | Acc: 98.583% | Wgt Acc: 98.526%
	I - Batch: 200 | Loss: 0.066 | Acc: 98.469% | Wgt Acc: 98.433%
	I - Batch: 250 | Loss: 0.060 | Acc: 98.575% | Wgt Acc: 98.576%
	I - Batch: 300 | Loss: 0.063 | Acc: 98.417% | Wgt Acc: 98.406%
	I - Batch: 350 | Loss: 0.065 | Acc: 98.339% | Wgt Acc: 98.348%
	I - Batch: 400 | Loss: 0.068 | Acc: 98.234% | Wgt Acc: 98.256%
	I - Batch: 450 | Loss: 0.071 | Acc: 98.014% | Wgt Acc: 97.999%
	I - Batch: 500 | Loss: 0.071 | Acc: 97.938% | Wgt Acc: 98.006%
	I - Batch: 550 | Loss: 0.070 | Acc: 97.989% | Wgt Acc: 98.044%
	I - Batch: 600 | Loss: 0.071 | Acc: 97.979% | Wgt Acc: 98.014%
	I - Batch: 650 | Loss: 0.070 | Acc: 98.019% | Wgt Acc: 98.049%
	I - Batch: 700 | Loss: 0.072 | Acc: 97.938% | Wgt Acc: 97.954%
	I - Batch: 750 | Loss: 0.072 | Acc: 97.950% | Wgt Acc: 97.986%
	I - Batch: 800 | Loss: 0.071 | Acc: 97.969% | Wgt Acc: 97.992%
	I - Batch: 850 | Loss: 0.072 | Acc: 97.971% | Wgt Acc: 97.972%
I - num batch: 876
I - Train -- Loss: 0.072 | Acc: 97.965% | Wgt Acc: 97.970% | LR: 1.250000e-04 | Dur: 540.18s
I - Confusion Matrix: [row->prediction - col->label]
[[1851.    2.    1.    7.   57.]
 [   0.  903.   13.    0.   17.]
 [   0.   10. 1300.    0.   59.]
 [   7.    4.    1. 1901.   33.]
 [  28.    8.   20.   18. 7764.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.804 | Acc: 43.000% | Wgt Acc: 41.626%
	I - Batch: 100 | Loss: 2.295 | Acc: 54.312% | Wgt Acc: 47.486%
	I - Batch: 150 | Loss: 2.129 | Acc: 58.708% | Wgt Acc: 50.750%
I - num batch: 193
I - Val -- Loss: 2.114 | Acc: 59.494% | Wgt Acc: 51.204% | Dur: 91.36s
I - Confusion Matrix: [row->prediction - col->label]
[[314.  12.  24.  78.  59.]
 [  1.  91.  14.  11.  16.]
 [  5.  56. 129.   9.  52.]
 [115.  61.  34. 321. 107.]
 [100. 150. 191. 155. 981.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.091 | Acc: 97.500% | Wgt Acc: 97.547%
	I - Batch: 100 | Loss: 0.070 | Acc: 98.000% | Wgt Acc: 98.091%
	I - Batch: 150 | Loss: 0.061 | Acc: 98.375% | Wgt Acc: 98.470%
	I - Batch: 200 | Loss: 0.063 | Acc: 98.375% | Wgt Acc: 98.447%
	I - Batch: 250 | Loss: 0.058 | Acc: 98.525% | Wgt Acc: 98.567%
	I - Batch: 300 | Loss: 0.058 | Acc: 98.500% | Wgt Acc: 98.556%
	I - Batch: 350 | Loss: 0.060 | Acc: 98.375% | Wgt Acc: 98.368%
	I - Batch: 400 | Loss: 0.061 | Acc: 98.375% | Wgt Acc: 98.429%
	I - Batch: 450 | Loss: 0.059 | Acc: 98.500% | Wgt Acc: 98.544%
	I - Batch: 500 | Loss: 0.058 | Acc: 98.562% | Wgt Acc: 98.600%
	I - Batch: 550 | Loss: 0.056 | Acc: 98.614% | Wgt Acc: 98.618%
	I - Batch: 600 | Loss: 0.058 | Acc: 98.573% | Wgt Acc: 98.565%
	I - Batch: 650 | Loss: 0.059 | Acc: 98.587% | Wgt Acc: 98.543%
	I - Batch: 700 | Loss: 0.058 | Acc: 98.634% | Wgt Acc: 98.580%
	I - Batch: 750 | Loss: 0.059 | Acc: 98.600% | Wgt Acc: 98.553%
	I - Batch: 800 | Loss: 0.058 | Acc: 98.625% | Wgt Acc: 98.587%
	I - Batch: 850 | Loss: 0.058 | Acc: 98.603% | Wgt Acc: 98.563%
I - num batch: 876
I - Train -- Loss: 0.061 | Acc: 98.550% | Wgt Acc: 98.535% | LR: 1.250000e-04 | Dur: 535.55s
I - Confusion Matrix: [row->prediction - col->label]
[[1860.    0.    1.    4.   44.]
 [   0.  905.    9.    0.    8.]
 [   0.   13. 1311.    0.   29.]
 [   6.    1.    0. 1912.   36.]
 [  20.    8.   14.   10. 7813.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.582 | Acc: 45.500% | Wgt Acc: 44.316%
	I - Batch: 100 | Loss: 2.127 | Acc: 54.688% | Wgt Acc: 49.228%
	I - Batch: 150 | Loss: 1.999 | Acc: 58.125% | Wgt Acc: 51.628%
I - num batch: 193
I - Val -- Loss: 1.972 | Acc: 58.846% | Wgt Acc: 52.065% | Dur: 90.68s
I - Confusion Matrix: [row->prediction - col->label]
[[322.  10.  28. 108.  88.]
 [  3. 119.  28.  17.  29.]
 [ 13.  58. 129.  14.  63.]
 [112.  49.  34. 321. 110.]
 [ 85. 134. 173. 114. 925.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 99.000% | Wgt Acc: 98.803%
	I - Batch: 100 | Loss: 0.061 | Acc: 98.688% | Wgt Acc: 98.756%
	I - Batch: 150 | Loss: 0.058 | Acc: 98.792% | Wgt Acc: 98.783%
	I - Batch: 200 | Loss: 0.057 | Acc: 98.781% | Wgt Acc: 98.788%
	I - Batch: 250 | Loss: 0.055 | Acc: 98.775% | Wgt Acc: 98.815%
	I - Batch: 300 | Loss: 0.054 | Acc: 98.792% | Wgt Acc: 98.823%
	I - Batch: 350 | Loss: 0.053 | Acc: 98.696% | Wgt Acc: 98.743%
	I - Batch: 400 | Loss: 0.052 | Acc: 98.766% | Wgt Acc: 98.814%
	I - Batch: 450 | Loss: 0.052 | Acc: 98.778% | Wgt Acc: 98.846%
	I - Batch: 500 | Loss: 0.052 | Acc: 98.825% | Wgt Acc: 98.898%
	I - Batch: 550 | Loss: 0.051 | Acc: 98.807% | Wgt Acc: 98.879%
	I - Batch: 600 | Loss: 0.054 | Acc: 98.750% | Wgt Acc: 98.788%
	I - Batch: 650 | Loss: 0.054 | Acc: 98.740% | Wgt Acc: 98.790%
	I - Batch: 700 | Loss: 0.054 | Acc: 98.714% | Wgt Acc: 98.761%
	I - Batch: 750 | Loss: 0.054 | Acc: 98.725% | Wgt Acc: 98.781%
	I - Batch: 800 | Loss: 0.053 | Acc: 98.750% | Wgt Acc: 98.818%
	I - Batch: 850 | Loss: 0.052 | Acc: 98.779% | Wgt Acc: 98.840%
I - num batch: 876
I - Train -- Loss: 0.054 | Acc: 98.765% | Wgt Acc: 98.814% | LR: 1.250000e-04 | Dur: 542.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    1.    0.    3.   36.]
 [   0.  914.    9.    2.    6.]
 [   0.   10. 1315.    0.   33.]
 [   5.    1.    1. 1913.   32.]
 [  15.    1.   10.    8. 7823.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.922 | Acc: 42.000% | Wgt Acc: 41.325%
	I - Batch: 100 | Loss: 2.425 | Acc: 54.688% | Wgt Acc: 47.620%
	I - Batch: 150 | Loss: 2.235 | Acc: 58.792% | Wgt Acc: 50.346%
I - num batch: 193
I - Val -- Loss: 2.239 | Acc: 59.624% | Wgt Acc: 50.512% | Dur: 91.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 293.    4.   18.   89.   33.]
 [   1.  137.   32.   17.   29.]
 [   5.   44.  121.    9.   46.]
 [  80.   29.   25.  258.   76.]
 [ 156.  156.  196.  201. 1031.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.125% | Wgt Acc: 99.213%
	I - Batch: 100 | Loss: 0.057 | Acc: 98.688% | Wgt Acc: 98.640%
	I - Batch: 150 | Loss: 0.059 | Acc: 98.542% | Wgt Acc: 98.662%
	I - Batch: 200 | Loss: 0.058 | Acc: 98.500% | Wgt Acc: 98.687%
	I - Batch: 250 | Loss: 0.054 | Acc: 98.700% | Wgt Acc: 98.804%
	I - Batch: 300 | Loss: 0.050 | Acc: 98.833% | Wgt Acc: 98.936%
	I - Batch: 350 | Loss: 0.049 | Acc: 98.821% | Wgt Acc: 98.969%
	I - Batch: 400 | Loss: 0.048 | Acc: 98.844% | Wgt Acc: 98.968%
	I - Batch: 450 | Loss: 0.047 | Acc: 98.875% | Wgt Acc: 99.005%
	I - Batch: 500 | Loss: 0.047 | Acc: 98.900% | Wgt Acc: 99.027%
	I - Batch: 550 | Loss: 0.047 | Acc: 98.909% | Wgt Acc: 99.031%
	I - Batch: 600 | Loss: 0.048 | Acc: 98.854% | Wgt Acc: 98.995%
	I - Batch: 650 | Loss: 0.047 | Acc: 98.837% | Wgt Acc: 98.976%
	I - Batch: 700 | Loss: 0.050 | Acc: 98.714% | Wgt Acc: 98.870%
	I - Batch: 750 | Loss: 0.054 | Acc: 98.575% | Wgt Acc: 98.702%
	I - Batch: 800 | Loss: 0.057 | Acc: 98.445% | Wgt Acc: 98.543%
	I - Batch: 850 | Loss: 0.058 | Acc: 98.360% | Wgt Acc: 98.482%
I - num batch: 876
I - Train -- Loss: 0.059 | Acc: 98.350% | Wgt Acc: 98.466% | LR: 1.250000e-04 | Dur: 542.58s
I - Confusion Matrix: [row->prediction - col->label]
[[1859.    0.    0.    5.   56.]
 [   1.  911.    5.    4.   15.]
 [   0.    4. 1312.    0.   50.]
 [   6.    6.    1. 1910.   28.]
 [  20.    6.   17.    7. 7781.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.590 | Acc: 46.375% | Wgt Acc: 45.661%
	I - Batch: 100 | Loss: 2.244 | Acc: 56.562% | Wgt Acc: 50.618%
	I - Batch: 150 | Loss: 2.135 | Acc: 60.000% | Wgt Acc: 52.466%
I - num batch: 193
I - Val -- Loss: 2.143 | Acc: 60.823% | Wgt Acc: 52.664% | Dur: 91.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 335.    7.   22.  112.   43.]
 [   7.  129.   30.   35.   36.]
 [   9.   77.  188.   25.   84.]
 [  46.   23.   10.  208.   35.]
 [ 138.  134.  142.  194. 1017.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.066 | Acc: 98.125% | Wgt Acc: 98.236%
	I - Batch: 100 | Loss: 0.061 | Acc: 98.375% | Wgt Acc: 98.460%
	I - Batch: 150 | Loss: 0.064 | Acc: 98.375% | Wgt Acc: 98.355%
	I - Batch: 200 | Loss: 0.075 | Acc: 98.125% | Wgt Acc: 97.956%
	I - Batch: 250 | Loss: 0.080 | Acc: 97.775% | Wgt Acc: 97.736%
	I - Batch: 300 | Loss: 0.076 | Acc: 97.896% | Wgt Acc: 97.872%
	I - Batch: 350 | Loss: 0.074 | Acc: 98.000% | Wgt Acc: 97.955%
	I - Batch: 400 | Loss: 0.071 | Acc: 98.156% | Wgt Acc: 98.122%
	I - Batch: 450 | Loss: 0.069 | Acc: 98.111% | Wgt Acc: 98.144%
	I - Batch: 500 | Loss: 0.067 | Acc: 98.188% | Wgt Acc: 98.174%
	I - Batch: 550 | Loss: 0.069 | Acc: 98.205% | Wgt Acc: 98.142%
	I - Batch: 600 | Loss: 0.069 | Acc: 98.240% | Wgt Acc: 98.170%
	I - Batch: 650 | Loss: 0.068 | Acc: 98.269% | Wgt Acc: 98.180%
	I - Batch: 700 | Loss: 0.069 | Acc: 98.259% | Wgt Acc: 98.145%
	I - Batch: 750 | Loss: 0.071 | Acc: 98.142% | Wgt Acc: 98.020%
	I - Batch: 800 | Loss: 0.073 | Acc: 98.039% | Wgt Acc: 97.924%
	I - Batch: 850 | Loss: 0.074 | Acc: 97.956% | Wgt Acc: 97.849%
I - num batch: 876
I - Train -- Loss: 0.075 | Acc: 97.972% | Wgt Acc: 97.877% | LR: 1.250000e-04 | Dur: 539.95s
I - Confusion Matrix: [row->prediction - col->label]
[[1857.    1.    1.    5.   51.]
 [   0.  900.   19.    7.   15.]
 [   0.   10. 1288.    0.   62.]
 [   8.    8.    0. 1899.   26.]
 [  21.    8.   27.   15. 7776.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.142 | Acc: 53.625% | Wgt Acc: 52.441%
	I - Batch: 100 | Loss: 1.936 | Acc: 56.562% | Wgt Acc: 54.260%
	I - Batch: 150 | Loss: 1.861 | Acc: 57.625% | Wgt Acc: 55.018%
I - num batch: 193
I - Val -- Loss: 1.896 | Acc: 57.259% | Wgt Acc: 54.751% | Dur: 90.87s
I - Confusion Matrix: [row->prediction - col->label]
[[420.  24.  41. 164. 162.]
 [  7. 178.  85.  24.  86.]
 [  2.  30. 103.   7.  60.]
 [ 66.  66.  60. 311. 152.]
 [ 40.  72. 103.  68. 755.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.072 | Acc: 97.875% | Wgt Acc: 97.745%
	I - Batch: 100 | Loss: 0.086 | Acc: 97.250% | Wgt Acc: 97.453%
	I - Batch: 150 | Loss: 0.074 | Acc: 97.583% | Wgt Acc: 97.896%
	I - Batch: 200 | Loss: 0.070 | Acc: 97.906% | Wgt Acc: 98.131%
	I - Batch: 250 | Loss: 0.062 | Acc: 98.175% | Wgt Acc: 98.358%
	I - Batch: 300 | Loss: 0.058 | Acc: 98.292% | Wgt Acc: 98.427%
	I - Batch: 350 | Loss: 0.056 | Acc: 98.411% | Wgt Acc: 98.545%
	I - Batch: 400 | Loss: 0.058 | Acc: 98.266% | Wgt Acc: 98.455%
	I - Batch: 450 | Loss: 0.058 | Acc: 98.278% | Wgt Acc: 98.451%
	I - Batch: 500 | Loss: 0.063 | Acc: 98.175% | Wgt Acc: 98.298%
	I - Batch: 550 | Loss: 0.062 | Acc: 98.170% | Wgt Acc: 98.324%
	I - Batch: 600 | Loss: 0.061 | Acc: 98.250% | Wgt Acc: 98.403%
	I - Batch: 650 | Loss: 0.061 | Acc: 98.269% | Wgt Acc: 98.380%
	I - Batch: 700 | Loss: 0.065 | Acc: 98.089% | Wgt Acc: 98.212%
	I - Batch: 750 | Loss: 0.066 | Acc: 98.075% | Wgt Acc: 98.183%
	I - Batch: 800 | Loss: 0.065 | Acc: 98.086% | Wgt Acc: 98.204%
	I - Batch: 850 | Loss: 0.065 | Acc: 98.125% | Wgt Acc: 98.213%
I - num batch: 876
I - Train -- Loss: 0.067 | Acc: 98.065% | Wgt Acc: 98.187% | LR: 1.250000e-04 | Dur: 541.20s
I - Confusion Matrix: [row->prediction - col->label]
[[1863.    2.    1.    4.   37.]
 [   1.  908.   10.    3.   20.]
 [   0.    7. 1303.    1.   65.]
 [   6.    2.    0. 1903.   52.]
 [  16.    8.   21.   15. 7756.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.235 | Acc: 50.125% | Wgt Acc: 49.675%
	I - Batch: 100 | Loss: 1.923 | Acc: 57.938% | Wgt Acc: 53.829%
	I - Batch: 150 | Loss: 1.836 | Acc: 59.958% | Wgt Acc: 55.436%
I - num batch: 193
I - Val -- Loss: 1.857 | Acc: 60.143% | Wgt Acc: 55.374% | Dur: 91.92s
I - Confusion Matrix: [row->prediction - col->label]
[[305.   9.  26.  88.  50.]
 [  8. 193.  74.  32.  75.]
 [  8.  43. 135.  10.  63.]
 [130.  46.  29. 336. 140.]
 [ 84.  79. 128. 108. 887.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 96.125% | Wgt Acc: 96.176%
	I - Batch: 100 | Loss: 0.118 | Acc: 96.375% | Wgt Acc: 96.239%
	I - Batch: 150 | Loss: 0.100 | Acc: 96.875% | Wgt Acc: 96.816%
	I - Batch: 200 | Loss: 0.097 | Acc: 97.000% | Wgt Acc: 96.941%
	I - Batch: 250 | Loss: 0.092 | Acc: 97.175% | Wgt Acc: 97.082%
	I - Batch: 300 | Loss: 0.083 | Acc: 97.438% | Wgt Acc: 97.383%
	I - Batch: 350 | Loss: 0.082 | Acc: 97.518% | Wgt Acc: 97.398%
	I - Batch: 400 | Loss: 0.085 | Acc: 97.438% | Wgt Acc: 97.329%
	I - Batch: 450 | Loss: 0.086 | Acc: 97.375% | Wgt Acc: 97.289%
	I - Batch: 500 | Loss: 0.086 | Acc: 97.400% | Wgt Acc: 97.291%
	I - Batch: 550 | Loss: 0.088 | Acc: 97.375% | Wgt Acc: 97.309%
	I - Batch: 600 | Loss: 0.085 | Acc: 97.417% | Wgt Acc: 97.351%
	I - Batch: 650 | Loss: 0.085 | Acc: 97.462% | Wgt Acc: 97.385%
	I - Batch: 700 | Loss: 0.084 | Acc: 97.509% | Wgt Acc: 97.461%
	I - Batch: 750 | Loss: 0.082 | Acc: 97.600% | Wgt Acc: 97.540%
	I - Batch: 800 | Loss: 0.081 | Acc: 97.633% | Wgt Acc: 97.596%
	I - Batch: 850 | Loss: 0.080 | Acc: 97.691% | Wgt Acc: 97.647%
I - num batch: 876
I - Train -- Loss: 0.082 | Acc: 97.722% | Wgt Acc: 97.679% | LR: 1.250000e-04 | Dur: 542.31s
I - Confusion Matrix: [row->prediction - col->label]
[[1852.    0.    1.    5.   59.]
 [   1.  904.   17.    1.   16.]
 [   0.   18. 1282.    0.   63.]
 [   7.    1.    0. 1897.   42.]
 [  26.    4.   35.   23. 7750.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.713 | Acc: 42.375% | Wgt Acc: 41.828%
	I - Batch: 100 | Loss: 2.335 | Acc: 54.250% | Wgt Acc: 47.752%
	I - Batch: 150 | Loss: 2.193 | Acc: 58.375% | Wgt Acc: 50.029%
I - num batch: 193
I - Val -- Loss: 2.207 | Acc: 59.300% | Wgt Acc: 50.343% | Dur: 91.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 317.    8.   22.  113.   57.]
 [   8.  151.   49.   23.   48.]
 [   5.   46.  121.   13.   53.]
 [  58.   18.   17.  214.   30.]
 [ 147.  147.  183.  211. 1027.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.062 | Acc: 98.125% | Wgt Acc: 98.290%
	I - Batch: 100 | Loss: 0.054 | Acc: 98.562% | Wgt Acc: 98.661%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.667% | Wgt Acc: 98.789%
	I - Batch: 200 | Loss: 0.051 | Acc: 98.688% | Wgt Acc: 98.827%
	I - Batch: 250 | Loss: 0.051 | Acc: 98.650% | Wgt Acc: 98.786%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.646% | Wgt Acc: 98.745%
	I - Batch: 350 | Loss: 0.051 | Acc: 98.714% | Wgt Acc: 98.763%
	I - Batch: 400 | Loss: 0.050 | Acc: 98.734% | Wgt Acc: 98.791%
	I - Batch: 450 | Loss: 0.051 | Acc: 98.750% | Wgt Acc: 98.815%
	I - Batch: 500 | Loss: 0.054 | Acc: 98.575% | Wgt Acc: 98.670%
	I - Batch: 550 | Loss: 0.059 | Acc: 98.341% | Wgt Acc: 98.437%
	I - Batch: 600 | Loss: 0.061 | Acc: 98.281% | Wgt Acc: 98.352%
	I - Batch: 650 | Loss: 0.062 | Acc: 98.250% | Wgt Acc: 98.331%
	I - Batch: 700 | Loss: 0.061 | Acc: 98.277% | Wgt Acc: 98.358%
	I - Batch: 750 | Loss: 0.061 | Acc: 98.308% | Wgt Acc: 98.389%
	I - Batch: 800 | Loss: 0.061 | Acc: 98.344% | Wgt Acc: 98.417%
	I - Batch: 850 | Loss: 0.060 | Acc: 98.346% | Wgt Acc: 98.416%
I - num batch: 876
I - Train -- Loss: 0.061 | Acc: 98.358% | Wgt Acc: 98.418% | LR: 1.250000e-04 | Dur: 542.07s
I - Confusion Matrix: [row->prediction - col->label]
[[1859.    2.    1.    4.   51.]
 [   0.  906.    7.    3.   12.]
 [   0.   12. 1312.    0.   49.]
 [   9.    4.    0. 1909.   30.]
 [  18.    3.   15.   10. 7788.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.225 | Acc: 37.250% | Wgt Acc: 36.968%
	I - Batch: 100 | Loss: 2.668 | Acc: 51.125% | Wgt Acc: 43.476%
	I - Batch: 150 | Loss: 2.468 | Acc: 56.208% | Wgt Acc: 46.469%
I - num batch: 193
I - Val -- Loss: 2.467 | Acc: 57.388% | Wgt Acc: 46.995% | Dur: 91.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 280.    6.   17.   98.   32.]
 [   3.  112.   20.   23.   21.]
 [  15.   66.  157.   25.   86.]
 [  28.   14.    9.  163.   17.]
 [ 209.  172.  189.  265. 1059.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.050 | Acc: 98.250% | Wgt Acc: 98.268%
	I - Batch: 100 | Loss: 0.054 | Acc: 98.188% | Wgt Acc: 98.439%
	I - Batch: 150 | Loss: 0.057 | Acc: 98.125% | Wgt Acc: 98.332%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.375% | Wgt Acc: 98.457%
	I - Batch: 250 | Loss: 0.059 | Acc: 98.275% | Wgt Acc: 98.304%
	I - Batch: 300 | Loss: 0.056 | Acc: 98.479% | Wgt Acc: 98.462%
	I - Batch: 350 | Loss: 0.055 | Acc: 98.482% | Wgt Acc: 98.541%
	I - Batch: 400 | Loss: 0.055 | Acc: 98.516% | Wgt Acc: 98.544%
	I - Batch: 450 | Loss: 0.054 | Acc: 98.514% | Wgt Acc: 98.579%
	I - Batch: 500 | Loss: 0.055 | Acc: 98.487% | Wgt Acc: 98.508%
	I - Batch: 550 | Loss: 0.056 | Acc: 98.466% | Wgt Acc: 98.492%
	I - Batch: 600 | Loss: 0.056 | Acc: 98.448% | Wgt Acc: 98.483%
	I - Batch: 650 | Loss: 0.055 | Acc: 98.490% | Wgt Acc: 98.527%
	I - Batch: 700 | Loss: 0.053 | Acc: 98.562% | Wgt Acc: 98.595%
	I - Batch: 750 | Loss: 0.052 | Acc: 98.600% | Wgt Acc: 98.631%
	I - Batch: 800 | Loss: 0.053 | Acc: 98.578% | Wgt Acc: 98.592%
	I - Batch: 850 | Loss: 0.054 | Acc: 98.537% | Wgt Acc: 98.531%
I - num batch: 876
I - Train -- Loss: 0.054 | Acc: 98.522% | Wgt Acc: 98.524% | LR: 1.250000e-04 | Dur: 541.47s
I - Confusion Matrix: [row->prediction - col->label]
[[1865.    2.    1.    3.   35.]
 [   1.  914.    8.    1.    6.]
 [   0.    9. 1299.    0.   45.]
 [   3.    1.    0. 1910.   35.]
 [  17.    1.   27.   12. 7809.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.174 | Acc: 51.125% | Wgt Acc: 50.057%
	I - Batch: 100 | Loss: 2.016 | Acc: 55.000% | Wgt Acc: 51.620%
	I - Batch: 150 | Loss: 1.941 | Acc: 57.625% | Wgt Acc: 53.349%
I - num batch: 193
I - Val -- Loss: 1.982 | Acc: 57.259% | Wgt Acc: 52.632% | Dur: 91.56s
I - Confusion Matrix: [row->prediction - col->label]
[[391.  22.  40. 156. 160.]
 [  6. 140.  36.  20.  41.]
 [  6.  51. 128.  12.  64.]
 [ 87.  45.  32. 277. 119.]
 [ 45. 112. 156. 109. 831.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.052 | Acc: 99.000% | Wgt Acc: 98.887%
	I - Batch: 100 | Loss: 0.062 | Acc: 98.312% | Wgt Acc: 98.274%
	I - Batch: 150 | Loss: 0.051 | Acc: 98.792% | Wgt Acc: 98.749%
	I - Batch: 200 | Loss: 0.053 | Acc: 98.688% | Wgt Acc: 98.691%
	I - Batch: 250 | Loss: 0.053 | Acc: 98.775% | Wgt Acc: 98.704%
	I - Batch: 300 | Loss: 0.058 | Acc: 98.562% | Wgt Acc: 98.542%
	I - Batch: 350 | Loss: 0.057 | Acc: 98.607% | Wgt Acc: 98.583%
	I - Batch: 400 | Loss: 0.057 | Acc: 98.594% | Wgt Acc: 98.557%
	I - Batch: 450 | Loss: 0.056 | Acc: 98.653% | Wgt Acc: 98.632%
	I - Batch: 500 | Loss: 0.056 | Acc: 98.650% | Wgt Acc: 98.644%
	I - Batch: 550 | Loss: 0.055 | Acc: 98.716% | Wgt Acc: 98.678%
	I - Batch: 600 | Loss: 0.054 | Acc: 98.677% | Wgt Acc: 98.658%
	I - Batch: 650 | Loss: 0.055 | Acc: 98.673% | Wgt Acc: 98.624%
	I - Batch: 700 | Loss: 0.054 | Acc: 98.661% | Wgt Acc: 98.632%
	I - Batch: 750 | Loss: 0.054 | Acc: 98.683% | Wgt Acc: 98.666%
	I - Batch: 800 | Loss: 0.054 | Acc: 98.711% | Wgt Acc: 98.686%
	I - Batch: 850 | Loss: 0.053 | Acc: 98.728% | Wgt Acc: 98.698%
I - num batch: 876
I - Train -- Loss: 0.052 | Acc: 98.743% | Wgt Acc: 98.716% | LR: 1.250000e-04 | Dur: 542.75s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    1.    0.    3.   33.]
 [   1.  910.    7.    2.   10.]
 [   0.   11. 1312.    0.   32.]
 [   1.    1.    1. 1909.   24.]
 [  18.    4.   15.   12. 7831.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.867 | Acc: 41.250% | Wgt Acc: 40.554%
	I - Batch: 100 | Loss: 2.400 | Acc: 54.062% | Wgt Acc: 47.114%
	I - Batch: 150 | Loss: 2.229 | Acc: 58.500% | Wgt Acc: 49.661%
I - num batch: 193
I - Val -- Loss: 2.248 | Acc: 59.721% | Wgt Acc: 50.389% | Dur: 91.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 266.    5.   19.   72.   22.]
 [   1.  121.   15.   17.   19.]
 [   6.   59.  153.   14.   56.]
 [  75.   31.   23.  261.   76.]
 [ 187.  154.  182.  210. 1042.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 98.625% | Wgt Acc: 98.599%
	I - Batch: 100 | Loss: 0.035 | Acc: 99.062% | Wgt Acc: 99.090%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.042% | Wgt Acc: 99.121%
	I - Batch: 200 | Loss: 0.039 | Acc: 99.125% | Wgt Acc: 99.221%
	I - Batch: 250 | Loss: 0.038 | Acc: 99.200% | Wgt Acc: 99.244%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.146% | Wgt Acc: 99.177%
	I - Batch: 350 | Loss: 0.038 | Acc: 99.143% | Wgt Acc: 99.186%
	I - Batch: 400 | Loss: 0.038 | Acc: 99.188% | Wgt Acc: 99.202%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.167% | Wgt Acc: 99.149%
	I - Batch: 500 | Loss: 0.042 | Acc: 99.062% | Wgt Acc: 99.008%
	I - Batch: 550 | Loss: 0.042 | Acc: 99.011% | Wgt Acc: 98.970%
	I - Batch: 600 | Loss: 0.043 | Acc: 99.010% | Wgt Acc: 98.952%
	I - Batch: 650 | Loss: 0.042 | Acc: 99.000% | Wgt Acc: 98.968%
	I - Batch: 700 | Loss: 0.042 | Acc: 99.000% | Wgt Acc: 98.969%
	I - Batch: 750 | Loss: 0.042 | Acc: 99.000% | Wgt Acc: 98.984%
	I - Batch: 800 | Loss: 0.044 | Acc: 98.953% | Wgt Acc: 98.925%
	I - Batch: 850 | Loss: 0.045 | Acc: 98.934% | Wgt Acc: 98.901%
I - num batch: 876
I - Train -- Loss: 0.044 | Acc: 98.950% | Wgt Acc: 98.912% | LR: 1.250000e-04 | Dur: 540.63s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    0.    2.   31.]
 [   0.  912.    9.    1.    5.]
 [   0.   10. 1314.    0.   24.]
 [   3.    2.    1. 1915.   21.]
 [  16.    3.   11.    8. 7849.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.688 | Acc: 30.750% | Wgt Acc: 30.067%
	I - Batch: 100 | Loss: 2.946 | Acc: 48.188% | Wgt Acc: 38.500%
	I - Batch: 150 | Loss: 2.675 | Acc: 54.750% | Wgt Acc: 42.564%
I - num batch: 193
I - Val -- Loss: 2.656 | Acc: 56.870% | Wgt Acc: 43.600% | Dur: 91.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 251.    2.   17.   58.   15.]
 [   1.   82.   10.   11.    7.]
 [   2.   44.  107.   10.   21.]
 [  52.   14.   12.  169.   26.]
 [ 229.  228.  246.  326. 1146.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 99.625% | Wgt Acc: 99.373%
	I - Batch: 100 | Loss: 0.044 | Acc: 98.750% | Wgt Acc: 98.475%
	I - Batch: 150 | Loss: 0.052 | Acc: 98.542% | Wgt Acc: 98.493%
	I - Batch: 200 | Loss: 0.050 | Acc: 98.656% | Wgt Acc: 98.699%
	I - Batch: 250 | Loss: 0.049 | Acc: 98.775% | Wgt Acc: 98.791%
	I - Batch: 300 | Loss: 0.045 | Acc: 98.896% | Wgt Acc: 98.881%
	I - Batch: 350 | Loss: 0.044 | Acc: 98.982% | Wgt Acc: 98.979%
	I - Batch: 400 | Loss: 0.045 | Acc: 98.969% | Wgt Acc: 98.909%
	I - Batch: 450 | Loss: 0.048 | Acc: 98.875% | Wgt Acc: 98.803%
	I - Batch: 500 | Loss: 0.049 | Acc: 98.812% | Wgt Acc: 98.745%
	I - Batch: 550 | Loss: 0.049 | Acc: 98.818% | Wgt Acc: 98.743%
	I - Batch: 600 | Loss: 0.049 | Acc: 98.833% | Wgt Acc: 98.738%
	I - Batch: 650 | Loss: 0.049 | Acc: 98.827% | Wgt Acc: 98.748%
	I - Batch: 700 | Loss: 0.049 | Acc: 98.795% | Wgt Acc: 98.736%
	I - Batch: 750 | Loss: 0.048 | Acc: 98.808% | Wgt Acc: 98.747%
	I - Batch: 800 | Loss: 0.049 | Acc: 98.789% | Wgt Acc: 98.738%
	I - Batch: 850 | Loss: 0.048 | Acc: 98.809% | Wgt Acc: 98.760%
I - num batch: 876
I - Train -- Loss: 0.049 | Acc: 98.800% | Wgt Acc: 98.755% | LR: 1.250000e-04 | Dur: 543.38s
I - Confusion Matrix: [row->prediction - col->label]
[[1872.    0.    1.    2.   26.]
 [   0.  912.    6.    2.    9.]
 [   0.    8. 1309.    1.   32.]
 [   5.    2.    0. 1905.   25.]
 [   9.    5.   19.   16. 7838.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.707 | Acc: 43.000% | Wgt Acc: 41.889%
	I - Batch: 100 | Loss: 2.296 | Acc: 53.688% | Wgt Acc: 47.417%
	I - Batch: 150 | Loss: 2.120 | Acc: 58.125% | Wgt Acc: 50.473%
I - num batch: 193
I - Val -- Loss: 2.107 | Acc: 59.332% | Wgt Acc: 51.419% | Dur: 91.36s
I - Confusion Matrix: [row->prediction - col->label]
[[341.  16.  32.  91.  56.]
 [  3. 119.  40.  14.  34.]
 [  4.  39. 120.  12.  57.]
 [ 71.  47.  34. 278.  95.]
 [116. 149. 166. 179. 973.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.307 | Acc: 92.875% | Wgt Acc: 91.537%
	I - Batch: 100 | Loss: 0.213 | Acc: 94.375% | Wgt Acc: 93.824%
	I - Batch: 150 | Loss: 0.178 | Acc: 95.083% | Wgt Acc: 94.697%
	I - Batch: 200 | Loss: 0.151 | Acc: 95.781% | Wgt Acc: 95.461%
	I - Batch: 250 | Loss: 0.134 | Acc: 96.300% | Wgt Acc: 96.049%
	I - Batch: 300 | Loss: 0.124 | Acc: 96.542% | Wgt Acc: 96.351%
	I - Batch: 350 | Loss: 0.118 | Acc: 96.625% | Wgt Acc: 96.427%
	I - Batch: 400 | Loss: 0.112 | Acc: 96.828% | Wgt Acc: 96.629%
	I - Batch: 450 | Loss: 0.106 | Acc: 97.014% | Wgt Acc: 96.853%
	I - Batch: 500 | Loss: 0.101 | Acc: 97.162% | Wgt Acc: 97.038%
	I - Batch: 550 | Loss: 0.099 | Acc: 97.250% | Wgt Acc: 97.133%
	I - Batch: 600 | Loss: 0.101 | Acc: 97.177% | Wgt Acc: 97.044%
	I - Batch: 650 | Loss: 0.100 | Acc: 97.163% | Wgt Acc: 97.038%
	I - Batch: 700 | Loss: 0.099 | Acc: 97.205% | Wgt Acc: 97.086%
	I - Batch: 750 | Loss: 0.099 | Acc: 97.200% | Wgt Acc: 97.094%
	I - Batch: 800 | Loss: 0.097 | Acc: 97.234% | Wgt Acc: 97.134%
	I - Batch: 850 | Loss: 0.094 | Acc: 97.338% | Wgt Acc: 97.262%
I - num batch: 876
I - Train -- Loss: 0.097 | Acc: 97.351% | Wgt Acc: 97.270% | LR: 1.250000e-04 | Dur: 547.39s
I - Confusion Matrix: [row->prediction - col->label]
[[1848.    2.    1.    9.   59.]
 [   2.  887.   11.    9.   25.]
 [   0.   11. 1289.    2.   64.]
 [   7.   17.    0. 1885.   58.]
 [  29.   10.   34.   21. 7724.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.927 | Acc: 40.625% | Wgt Acc: 39.423%
	I - Batch: 100 | Loss: 2.410 | Acc: 52.500% | Wgt Acc: 45.744%
	I - Batch: 150 | Loss: 2.232 | Acc: 57.125% | Wgt Acc: 48.952%
I - num batch: 193
I - Val -- Loss: 2.246 | Acc: 57.615% | Wgt Acc: 48.954% | Dur: 92.46s
I - Confusion Matrix: [row->prediction - col->label]
[[367.  39.  40. 179. 134.]
 [  2. 118.  40.  10.  21.]
 [  4.  24.  91.  10.  30.]
 [ 43.  40.  29. 223.  51.]
 [119. 149. 192. 152. 979.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.051 | Acc: 98.625% | Wgt Acc: 98.399%
	I - Batch: 100 | Loss: 0.050 | Acc: 98.562% | Wgt Acc: 98.577%
	I - Batch: 150 | Loss: 0.045 | Acc: 98.875% | Wgt Acc: 98.916%
	I - Batch: 200 | Loss: 0.045 | Acc: 98.812% | Wgt Acc: 98.793%
	I - Batch: 250 | Loss: 0.045 | Acc: 98.875% | Wgt Acc: 98.833%
	I - Batch: 300 | Loss: 0.045 | Acc: 98.833% | Wgt Acc: 98.756%
	I - Batch: 350 | Loss: 0.044 | Acc: 98.839% | Wgt Acc: 98.790%
	I - Batch: 400 | Loss: 0.045 | Acc: 98.844% | Wgt Acc: 98.771%
	I - Batch: 450 | Loss: 0.045 | Acc: 98.861% | Wgt Acc: 98.800%
	I - Batch: 500 | Loss: 0.046 | Acc: 98.850% | Wgt Acc: 98.813%
	I - Batch: 550 | Loss: 0.046 | Acc: 98.864% | Wgt Acc: 98.830%
	I - Batch: 600 | Loss: 0.045 | Acc: 98.906% | Wgt Acc: 98.867%
	I - Batch: 650 | Loss: 0.046 | Acc: 98.846% | Wgt Acc: 98.855%
	I - Batch: 700 | Loss: 0.046 | Acc: 98.848% | Wgt Acc: 98.848%
	I - Batch: 750 | Loss: 0.046 | Acc: 98.833% | Wgt Acc: 98.827%
	I - Batch: 800 | Loss: 0.047 | Acc: 98.820% | Wgt Acc: 98.836%
	I - Batch: 850 | Loss: 0.047 | Acc: 98.846% | Wgt Acc: 98.840%
I - num batch: 876
I - Train -- Loss: 0.048 | Acc: 98.843% | Wgt Acc: 98.843% | LR: 1.250000e-04 | Dur: 544.98s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    0.    3.   35.]
 [   1.  913.    7.    2.    7.]
 [   0.   13. 1311.    0.   37.]
 [   4.    1.    1. 1912.   16.]
 [  10.    0.   16.    9. 7835.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.747 | Acc: 42.625% | Wgt Acc: 41.342%
	I - Batch: 100 | Loss: 2.279 | Acc: 53.562% | Wgt Acc: 46.799%
	I - Batch: 150 | Loss: 2.055 | Acc: 58.625% | Wgt Acc: 50.664%
I - num batch: 193
I - Val -- Loss: 2.066 | Acc: 59.494% | Wgt Acc: 51.012% | Dur: 92.81s
I - Confusion Matrix: [row->prediction - col->label]
[[321.  17.  26. 102.  59.]
 [  1. 105.  25.   7.  14.]
 [  5.  43. 107.  11.  41.]
 [ 99.  46.  34. 314. 112.]
 [109. 159. 200. 140. 989.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.083 | Acc: 97.375% | Wgt Acc: 96.978%
	I - Batch: 100 | Loss: 0.082 | Acc: 97.500% | Wgt Acc: 97.412%
	I - Batch: 150 | Loss: 0.070 | Acc: 97.917% | Wgt Acc: 97.865%
	I - Batch: 200 | Loss: 0.072 | Acc: 98.000% | Wgt Acc: 97.859%
	I - Batch: 250 | Loss: 0.066 | Acc: 98.225% | Wgt Acc: 98.159%
	I - Batch: 300 | Loss: 0.064 | Acc: 98.354% | Wgt Acc: 98.290%
	I - Batch: 350 | Loss: 0.061 | Acc: 98.429% | Wgt Acc: 98.379%
	I - Batch: 400 | Loss: 0.059 | Acc: 98.500% | Wgt Acc: 98.490%
	I - Batch: 450 | Loss: 0.057 | Acc: 98.514% | Wgt Acc: 98.530%
	I - Batch: 500 | Loss: 0.056 | Acc: 98.612% | Wgt Acc: 98.597%
	I - Batch: 550 | Loss: 0.054 | Acc: 98.648% | Wgt Acc: 98.650%
	I - Batch: 600 | Loss: 0.053 | Acc: 98.677% | Wgt Acc: 98.670%
	I - Batch: 650 | Loss: 0.052 | Acc: 98.702% | Wgt Acc: 98.712%
	I - Batch: 700 | Loss: 0.052 | Acc: 98.723% | Wgt Acc: 98.719%
	I - Batch: 750 | Loss: 0.054 | Acc: 98.667% | Wgt Acc: 98.631%
	I - Batch: 800 | Loss: 0.055 | Acc: 98.656% | Wgt Acc: 98.597%
	I - Batch: 850 | Loss: 0.056 | Acc: 98.654% | Wgt Acc: 98.584%
I - num batch: 876
I - Train -- Loss: 0.056 | Acc: 98.650% | Wgt Acc: 98.574% | LR: 1.250000e-04 | Dur: 546.83s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    1.    1.    4.   26.]
 [   0.  904.   12.    2.   11.]
 [   0.   15. 1301.    0.   38.]
 [   3.    3.    0. 1912.   28.]
 [  12.    4.   21.    8. 7827.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.874 | Acc: 42.625% | Wgt Acc: 41.686%
	I - Batch: 100 | Loss: 2.396 | Acc: 53.562% | Wgt Acc: 46.556%
	I - Batch: 150 | Loss: 2.229 | Acc: 57.792% | Wgt Acc: 49.016%
I - num batch: 193
I - Val -- Loss: 2.196 | Acc: 58.684% | Wgt Acc: 49.446% | Dur: 93.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 354.   24.   35.  183.   69.]
 [   4.  113.   38.   14.   28.]
 [   4.   42.  114.    8.   43.]
 [  48.   42.   25.  214.   59.]
 [ 125.  149.  180.  155. 1016.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.044 | Acc: 99.625% | Wgt Acc: 99.507%
	I - Batch: 100 | Loss: 0.047 | Acc: 99.250% | Wgt Acc: 99.260%
	I - Batch: 150 | Loss: 0.054 | Acc: 98.833% | Wgt Acc: 98.955%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.625% | Wgt Acc: 98.736%
	I - Batch: 250 | Loss: 0.053 | Acc: 98.725% | Wgt Acc: 98.765%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.750% | Wgt Acc: 98.776%
	I - Batch: 350 | Loss: 0.052 | Acc: 98.804% | Wgt Acc: 98.781%
	I - Batch: 400 | Loss: 0.052 | Acc: 98.781% | Wgt Acc: 98.760%
	I - Batch: 450 | Loss: 0.051 | Acc: 98.833% | Wgt Acc: 98.809%
	I - Batch: 500 | Loss: 0.050 | Acc: 98.875% | Wgt Acc: 98.830%
	I - Batch: 550 | Loss: 0.050 | Acc: 98.875% | Wgt Acc: 98.840%
	I - Batch: 600 | Loss: 0.049 | Acc: 98.906% | Wgt Acc: 98.872%
	I - Batch: 650 | Loss: 0.048 | Acc: 98.923% | Wgt Acc: 98.909%
	I - Batch: 700 | Loss: 0.047 | Acc: 98.946% | Wgt Acc: 98.931%
	I - Batch: 750 | Loss: 0.046 | Acc: 98.992% | Wgt Acc: 98.979%
	I - Batch: 800 | Loss: 0.046 | Acc: 98.977% | Wgt Acc: 98.964%
	I - Batch: 850 | Loss: 0.045 | Acc: 98.985% | Wgt Acc: 98.981%
I - num batch: 876
I - Train -- Loss: 0.046 | Acc: 99.000% | Wgt Acc: 98.989% | LR: 1.250000e-04 | Dur: 539.66s
I - Confusion Matrix: [row->prediction - col->label]
[[1875.    2.    1.    4.   24.]
 [   0.  911.    9.    3.   10.]
 [   0.    7. 1318.    0.   26.]
 [   1.    6.    0. 1911.   21.]
 [  10.    1.    7.    8. 7849.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.070 | Acc: 41.375% | Wgt Acc: 40.035%
	I - Batch: 100 | Loss: 2.548 | Acc: 52.938% | Wgt Acc: 45.586%
	I - Batch: 150 | Loss: 2.309 | Acc: 57.792% | Wgt Acc: 49.000%
I - num batch: 193
I - Val -- Loss: 2.315 | Acc: 58.069% | Wgt Acc: 48.598% | Dur: 90.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 345.   20.   35.  134.   85.]
 [   4.  101.   24.   13.   18.]
 [   3.   34.   94.    7.   28.]
 [  65.   41.   27.  242.   74.]
 [ 118.  174.  212.  178. 1010.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.097 | Acc: 97.875% | Wgt Acc: 97.147%
	I - Batch: 100 | Loss: 0.079 | Acc: 98.062% | Wgt Acc: 97.590%
	I - Batch: 150 | Loss: 0.069 | Acc: 98.333% | Wgt Acc: 97.932%
	I - Batch: 200 | Loss: 0.064 | Acc: 98.531% | Wgt Acc: 98.225%
	I - Batch: 250 | Loss: 0.065 | Acc: 98.425% | Wgt Acc: 98.159%
	I - Batch: 300 | Loss: 0.060 | Acc: 98.500% | Wgt Acc: 98.290%
	I - Batch: 350 | Loss: 0.058 | Acc: 98.464% | Wgt Acc: 98.338%
	I - Batch: 400 | Loss: 0.056 | Acc: 98.531% | Wgt Acc: 98.419%
	I - Batch: 450 | Loss: 0.056 | Acc: 98.569% | Wgt Acc: 98.443%
	I - Batch: 500 | Loss: 0.054 | Acc: 98.650% | Wgt Acc: 98.534%
	I - Batch: 550 | Loss: 0.054 | Acc: 98.614% | Wgt Acc: 98.540%
	I - Batch: 600 | Loss: 0.054 | Acc: 98.594% | Wgt Acc: 98.566%
	I - Batch: 650 | Loss: 0.054 | Acc: 98.587% | Wgt Acc: 98.557%
	I - Batch: 700 | Loss: 0.053 | Acc: 98.598% | Wgt Acc: 98.584%
	I - Batch: 750 | Loss: 0.052 | Acc: 98.633% | Wgt Acc: 98.639%
	I - Batch: 800 | Loss: 0.052 | Acc: 98.656% | Wgt Acc: 98.658%
	I - Batch: 850 | Loss: 0.051 | Acc: 98.684% | Wgt Acc: 98.691%
I - num batch: 876
I - Train -- Loss: 0.052 | Acc: 98.679% | Wgt Acc: 98.675% | LR: 1.250000e-04 | Dur: 541.51s
I - Confusion Matrix: [row->prediction - col->label]
[[1864.    0.    0.    4.   37.]
 [   0.  911.    8.    0.   14.]
 [   0.    9. 1307.    0.   38.]
 [   4.    1.    3. 1915.   19.]
 [  18.    6.   17.    7. 7822.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.191 | Acc: 35.875% | Wgt Acc: 35.540%
	I - Batch: 100 | Loss: 2.628 | Acc: 51.125% | Wgt Acc: 42.769%
	I - Batch: 150 | Loss: 2.453 | Acc: 56.125% | Wgt Acc: 46.111%
I - num batch: 193
I - Val -- Loss: 2.458 | Acc: 57.647% | Wgt Acc: 46.857% | Dur: 91.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 257.    6.   16.   92.   23.]
 [   0.  129.   22.   16.   19.]
 [   2.   56.  131.   10.   57.]
 [  45.   20.   15.  184.   38.]
 [ 231.  159.  208.  272. 1078.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.125% | Wgt Acc: 99.045%
	I - Batch: 100 | Loss: 0.027 | Acc: 99.375% | Wgt Acc: 99.420%
	I - Batch: 150 | Loss: 0.030 | Acc: 99.250% | Wgt Acc: 99.256%
	I - Batch: 200 | Loss: 0.033 | Acc: 99.219% | Wgt Acc: 99.291%
	I - Batch: 250 | Loss: 0.037 | Acc: 99.100% | Wgt Acc: 99.167%
	I - Batch: 300 | Loss: 0.037 | Acc: 99.062% | Wgt Acc: 99.134%
	I - Batch: 350 | Loss: 0.035 | Acc: 99.125% | Wgt Acc: 99.203%
	I - Batch: 400 | Loss: 0.033 | Acc: 99.234% | Wgt Acc: 99.302%
	I - Batch: 450 | Loss: 0.032 | Acc: 99.292% | Wgt Acc: 99.337%
	I - Batch: 500 | Loss: 0.034 | Acc: 99.213% | Wgt Acc: 99.261%
	I - Batch: 550 | Loss: 0.034 | Acc: 99.205% | Wgt Acc: 99.253%
	I - Batch: 600 | Loss: 0.035 | Acc: 99.219% | Wgt Acc: 99.265%
	I - Batch: 650 | Loss: 0.035 | Acc: 99.221% | Wgt Acc: 99.280%
	I - Batch: 700 | Loss: 0.035 | Acc: 99.223% | Wgt Acc: 99.289%
	I - Batch: 750 | Loss: 0.036 | Acc: 99.175% | Wgt Acc: 99.238%
	I - Batch: 800 | Loss: 0.035 | Acc: 99.195% | Wgt Acc: 99.252%
	I - Batch: 850 | Loss: 0.036 | Acc: 99.199% | Wgt Acc: 99.249%
I - num batch: 876
I - Train -- Loss: 0.036 | Acc: 99.179% | Wgt Acc: 99.240% | LR: 1.250000e-04 | Dur: 538.14s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    1.    4.   25.]
 [   0.  921.    2.    1.    5.]
 [   0.    4. 1328.    0.   20.]
 [   2.    1.    0. 1912.   23.]
 [  13.    1.    4.    9. 7857.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.427 | Acc: 48.375% | Wgt Acc: 47.690%
	I - Batch: 100 | Loss: 2.091 | Acc: 56.500% | Wgt Acc: 51.502%
	I - Batch: 150 | Loss: 2.002 | Acc: 58.917% | Wgt Acc: 52.958%
I - num batch: 193
I - Val -- Loss: 1.981 | Acc: 60.143% | Wgt Acc: 53.762% | Dur: 90.52s
I - Confusion Matrix: [row->prediction - col->label]
[[279.  11.  24.  71.  41.]
 [  6. 164.  57.  25.  45.]
 [  4.  40. 129.  12.  59.]
 [121.  47.  46. 345. 131.]
 [125. 108. 136. 121. 939.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 99.250% | Wgt Acc: 99.135%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.188% | Wgt Acc: 99.027%
	I - Batch: 150 | Loss: 0.045 | Acc: 99.042% | Wgt Acc: 98.978%
	I - Batch: 200 | Loss: 0.042 | Acc: 99.062% | Wgt Acc: 99.074%
	I - Batch: 250 | Loss: 0.040 | Acc: 99.075% | Wgt Acc: 99.046%
	I - Batch: 300 | Loss: 0.043 | Acc: 98.958% | Wgt Acc: 98.989%
	I - Batch: 350 | Loss: 0.045 | Acc: 98.875% | Wgt Acc: 98.892%
	I - Batch: 400 | Loss: 0.049 | Acc: 98.719% | Wgt Acc: 98.743%
	I - Batch: 450 | Loss: 0.047 | Acc: 98.819% | Wgt Acc: 98.846%
	I - Batch: 500 | Loss: 0.046 | Acc: 98.812% | Wgt Acc: 98.845%
	I - Batch: 550 | Loss: 0.046 | Acc: 98.830% | Wgt Acc: 98.885%
	I - Batch: 600 | Loss: 0.044 | Acc: 98.844% | Wgt Acc: 98.907%
	I - Batch: 650 | Loss: 0.042 | Acc: 98.913% | Wgt Acc: 98.973%
	I - Batch: 700 | Loss: 0.042 | Acc: 98.946% | Wgt Acc: 99.021%
	I - Batch: 750 | Loss: 0.043 | Acc: 98.958% | Wgt Acc: 99.019%
	I - Batch: 800 | Loss: 0.044 | Acc: 98.891% | Wgt Acc: 98.981%
	I - Batch: 850 | Loss: 0.045 | Acc: 98.890% | Wgt Acc: 98.958%
I - num batch: 876
I - Train -- Loss: 0.046 | Acc: 98.872% | Wgt Acc: 98.945% | LR: 1.250000e-04 | Dur: 537.62s
I - Confusion Matrix: [row->prediction - col->label]
[[1873.    0.    1.    2.   27.]
 [   0.  916.    8.    0.    9.]
 [   0.    8. 1315.    1.   32.]
 [   3.    0.    1. 1914.   34.]
 [  10.    3.   10.    9. 7828.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.398 | Acc: 48.000% | Wgt Acc: 46.771%
	I - Batch: 100 | Loss: 2.120 | Acc: 52.562% | Wgt Acc: 49.615%
	I - Batch: 150 | Loss: 2.043 | Acc: 55.000% | Wgt Acc: 51.141%
I - num batch: 193
I - Val -- Loss: 2.032 | Acc: 55.152% | Wgt Acc: 51.175% | Dur: 90.74s
I - Confusion Matrix: [row->prediction - col->label]
[[333.  23.  36. 114. 115.]
 [ 10. 145.  70.  27.  66.]
 [  1.  19.  75.   6.  47.]
 [140.  87.  70. 375. 213.]
 [ 51.  96. 141.  52. 774.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.250% | Wgt Acc: 99.310%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.125% | Wgt Acc: 99.229%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.167% | Wgt Acc: 99.303%
	I - Batch: 200 | Loss: 0.028 | Acc: 99.344% | Wgt Acc: 99.423%
	I - Batch: 250 | Loss: 0.029 | Acc: 99.325% | Wgt Acc: 99.397%
	I - Batch: 300 | Loss: 0.030 | Acc: 99.271% | Wgt Acc: 99.311%
	I - Batch: 350 | Loss: 0.033 | Acc: 99.214% | Wgt Acc: 99.207%
	I - Batch: 400 | Loss: 0.040 | Acc: 99.000% | Wgt Acc: 99.029%
	I - Batch: 450 | Loss: 0.040 | Acc: 98.944% | Wgt Acc: 99.013%
	I - Batch: 500 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 99.065%
	I - Batch: 550 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 99.056%
	I - Batch: 600 | Loss: 0.039 | Acc: 99.031% | Wgt Acc: 99.092%
	I - Batch: 650 | Loss: 0.039 | Acc: 99.019% | Wgt Acc: 99.071%
	I - Batch: 700 | Loss: 0.039 | Acc: 99.027% | Wgt Acc: 99.084%
	I - Batch: 750 | Loss: 0.041 | Acc: 98.983% | Wgt Acc: 99.024%
	I - Batch: 800 | Loss: 0.041 | Acc: 98.961% | Wgt Acc: 98.990%
	I - Batch: 850 | Loss: 0.042 | Acc: 98.941% | Wgt Acc: 98.963%
I - num batch: 876
I - Train -- Loss: 0.042 | Acc: 98.936% | Wgt Acc: 98.945% | LR: 1.250000e-04 | Dur: 536.66s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    0.    2.   37.]
 [   1.  914.    5.    1.    9.]
 [   0.    8. 1316.    0.   23.]
 [   3.    1.    1. 1916.   19.]
 [  15.    4.   13.    7. 7842.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.995 | Acc: 39.875% | Wgt Acc: 39.466%
	I - Batch: 100 | Loss: 2.501 | Acc: 52.625% | Wgt Acc: 45.671%
	I - Batch: 150 | Loss: 2.339 | Acc: 56.792% | Wgt Acc: 48.069%
I - num batch: 193
I - Val -- Loss: 2.347 | Acc: 57.874% | Wgt Acc: 48.381% | Dur: 90.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 269.    7.   15.   79.   25.]
 [   4.  123.   25.   25.   34.]
 [   6.   57.  157.   27.   86.]
 [  77.   26.   13.  205.   38.]
 [ 179.  157.  182.  238. 1032.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 99.500% | Wgt Acc: 99.579%
	I - Batch: 100 | Loss: 0.043 | Acc: 98.812% | Wgt Acc: 98.766%
	I - Batch: 150 | Loss: 0.050 | Acc: 98.708% | Wgt Acc: 98.500%
	I - Batch: 200 | Loss: 0.051 | Acc: 98.781% | Wgt Acc: 98.632%
	I - Batch: 250 | Loss: 0.054 | Acc: 98.725% | Wgt Acc: 98.662%
	I - Batch: 300 | Loss: 0.054 | Acc: 98.604% | Wgt Acc: 98.528%
	I - Batch: 350 | Loss: 0.051 | Acc: 98.679% | Wgt Acc: 98.631%
	I - Batch: 400 | Loss: 0.051 | Acc: 98.656% | Wgt Acc: 98.626%
	I - Batch: 450 | Loss: 0.048 | Acc: 98.722% | Wgt Acc: 98.721%
	I - Batch: 500 | Loss: 0.047 | Acc: 98.763% | Wgt Acc: 98.751%
	I - Batch: 550 | Loss: 0.046 | Acc: 98.795% | Wgt Acc: 98.795%
	I - Batch: 600 | Loss: 0.046 | Acc: 98.802% | Wgt Acc: 98.780%
	I - Batch: 650 | Loss: 0.049 | Acc: 98.779% | Wgt Acc: 98.715%
	I - Batch: 700 | Loss: 0.051 | Acc: 98.661% | Wgt Acc: 98.610%
	I - Batch: 750 | Loss: 0.050 | Acc: 98.667% | Wgt Acc: 98.606%
	I - Batch: 800 | Loss: 0.050 | Acc: 98.656% | Wgt Acc: 98.606%
	I - Batch: 850 | Loss: 0.050 | Acc: 98.676% | Wgt Acc: 98.633%
I - num batch: 876
I - Train -- Loss: 0.049 | Acc: 98.700% | Wgt Acc: 98.657% | LR: 1.250000e-04 | Dur: 535.60s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    1.    1.    4.   27.]
 [   1.  910.   10.    3.    4.]
 [   0.    7. 1306.    0.   39.]
 [   3.    5.    0. 1906.   31.]
 [  11.    4.   18.   13. 7829.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.466 | Acc: 46.625% | Wgt Acc: 46.274%
	I - Batch: 100 | Loss: 2.066 | Acc: 55.812% | Wgt Acc: 51.131%
	I - Batch: 150 | Loss: 2.005 | Acc: 57.792% | Wgt Acc: 52.318%
I - num batch: 193
I - Val -- Loss: 1.995 | Acc: 58.360% | Wgt Acc: 52.549% | Dur: 90.46s
I - Confusion Matrix: [row->prediction - col->label]
[[307.   9.  27. 114.  63.]
 [  6. 172.  75.  38.  53.]
 [  2.  48. 130.  11.  91.]
 [112.  35.  25. 290. 106.]
 [108. 106. 135. 121. 902.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.054 | Acc: 98.000% | Wgt Acc: 98.092%
	I - Batch: 100 | Loss: 0.051 | Acc: 98.250% | Wgt Acc: 98.425%
	I - Batch: 150 | Loss: 0.050 | Acc: 98.542% | Wgt Acc: 98.571%
	I - Batch: 200 | Loss: 0.045 | Acc: 98.719% | Wgt Acc: 98.764%
	I - Batch: 250 | Loss: 0.047 | Acc: 98.825% | Wgt Acc: 98.789%
	I - Batch: 300 | Loss: 0.043 | Acc: 98.938% | Wgt Acc: 98.918%
	I - Batch: 350 | Loss: 0.040 | Acc: 99.000% | Wgt Acc: 98.986%
	I - Batch: 400 | Loss: 0.041 | Acc: 99.000% | Wgt Acc: 98.996%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.069% | Wgt Acc: 99.072%
	I - Batch: 500 | Loss: 0.041 | Acc: 99.013% | Wgt Acc: 98.998%
	I - Batch: 550 | Loss: 0.041 | Acc: 98.966% | Wgt Acc: 98.982%
	I - Batch: 600 | Loss: 0.040 | Acc: 99.021% | Wgt Acc: 99.028%
	I - Batch: 650 | Loss: 0.040 | Acc: 99.019% | Wgt Acc: 99.025%
	I - Batch: 700 | Loss: 0.041 | Acc: 98.982% | Wgt Acc: 98.969%
	I - Batch: 750 | Loss: 0.043 | Acc: 98.900% | Wgt Acc: 98.882%
	I - Batch: 800 | Loss: 0.043 | Acc: 98.867% | Wgt Acc: 98.836%
	I - Batch: 850 | Loss: 0.043 | Acc: 98.868% | Wgt Acc: 98.846%
I - num batch: 876
I - Train -- Loss: 0.043 | Acc: 98.865% | Wgt Acc: 98.851% | LR: 1.250000e-04 | Dur: 535.81s
I - Confusion Matrix: [row->prediction - col->label]
[[1864.    0.    0.    5.   35.]
 [   0.  914.    6.    1.    7.]
 [   0.   10. 1315.    0.   23.]
 [   8.    1.    1. 1912.   25.]
 [  14.    2.   13.    8. 7840.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.452 | Acc: 45.875% | Wgt Acc: 45.656%
	I - Batch: 100 | Loss: 2.124 | Acc: 55.250% | Wgt Acc: 51.246%
	I - Batch: 150 | Loss: 2.075 | Acc: 57.083% | Wgt Acc: 51.977%
I - num batch: 193
I - Val -- Loss: 2.090 | Acc: 57.550% | Wgt Acc: 51.865% | Dur: 90.31s
I - Confusion Matrix: [row->prediction - col->label]
[[309.   8.  23. 103.  56.]
 [ 15. 188.  86.  51.  99.]
 [ 13.  42. 138.  25. 103.]
 [ 66.  18.  21. 244.  60.]
 [132. 114. 124. 151. 897.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.042 | Acc: 98.875% | Wgt Acc: 99.056%
	I - Batch: 100 | Loss: 0.047 | Acc: 99.000% | Wgt Acc: 99.092%
	I - Batch: 150 | Loss: 0.045 | Acc: 98.958% | Wgt Acc: 99.069%
	I - Batch: 200 | Loss: 0.041 | Acc: 98.969% | Wgt Acc: 99.025%
	I - Batch: 250 | Loss: 0.043 | Acc: 98.925% | Wgt Acc: 99.006%
	I - Batch: 300 | Loss: 0.044 | Acc: 98.938% | Wgt Acc: 98.986%
	I - Batch: 350 | Loss: 0.044 | Acc: 98.946% | Wgt Acc: 98.979%
	I - Batch: 400 | Loss: 0.041 | Acc: 99.000% | Wgt Acc: 99.028%
	I - Batch: 450 | Loss: 0.041 | Acc: 99.000% | Wgt Acc: 99.033%
	I - Batch: 500 | Loss: 0.039 | Acc: 99.050% | Wgt Acc: 99.086%
	I - Batch: 550 | Loss: 0.041 | Acc: 99.011% | Wgt Acc: 99.028%
	I - Batch: 600 | Loss: 0.042 | Acc: 98.990% | Wgt Acc: 99.027%
	I - Batch: 650 | Loss: 0.041 | Acc: 99.010% | Wgt Acc: 99.040%
	I - Batch: 700 | Loss: 0.040 | Acc: 99.027% | Wgt Acc: 99.061%
	I - Batch: 750 | Loss: 0.042 | Acc: 98.975% | Wgt Acc: 99.007%
	I - Batch: 800 | Loss: 0.043 | Acc: 98.930% | Wgt Acc: 98.968%
	I - Batch: 850 | Loss: 0.045 | Acc: 98.875% | Wgt Acc: 98.920%
I - num batch: 876
I - Train -- Loss: 0.045 | Acc: 98.850% | Wgt Acc: 98.901% | LR: 1.250000e-04 | Dur: 535.55s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    0.    2.    5.   36.]
 [   0.  918.    5.    2.    9.]
 [   0.    4. 1317.    0.   34.]
 [   4.    2.    0. 1911.   20.]
 [  16.    3.   11.    8. 7831.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.411 | Acc: 50.500% | Wgt Acc: 49.516%
	I - Batch: 100 | Loss: 2.119 | Acc: 55.875% | Wgt Acc: 51.995%
	I - Batch: 150 | Loss: 1.995 | Acc: 59.042% | Wgt Acc: 54.536%
I - num batch: 193
I - Val -- Loss: 2.010 | Acc: 59.041% | Wgt Acc: 54.323% | Dur: 90.55s
I - Confusion Matrix: [row->prediction - col->label]
[[344.  21.  41.  98. 100.]
 [  3. 167.  44.  18.  54.]
 [  1.  35. 104.   7.  40.]
 [116.  57.  45. 350. 164.]
 [ 71.  90. 158. 101. 857.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.250% | Wgt Acc: 99.212%
	I - Batch: 100 | Loss: 0.034 | Acc: 99.125% | Wgt Acc: 99.036%
	I - Batch: 150 | Loss: 0.041 | Acc: 98.958% | Wgt Acc: 98.793%
	I - Batch: 200 | Loss: 0.040 | Acc: 98.969% | Wgt Acc: 98.894%
	I - Batch: 250 | Loss: 0.037 | Acc: 99.100% | Wgt Acc: 99.016%
	I - Batch: 300 | Loss: 0.037 | Acc: 99.083% | Wgt Acc: 99.040%
	I - Batch: 350 | Loss: 0.038 | Acc: 99.054% | Wgt Acc: 99.002%
	I - Batch: 400 | Loss: 0.040 | Acc: 99.016% | Wgt Acc: 98.927%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.042% | Wgt Acc: 98.987%
	I - Batch: 500 | Loss: 0.039 | Acc: 99.037% | Wgt Acc: 98.949%
	I - Batch: 550 | Loss: 0.038 | Acc: 99.068% | Wgt Acc: 98.982%
	I - Batch: 600 | Loss: 0.038 | Acc: 99.073% | Wgt Acc: 98.995%
	I - Batch: 650 | Loss: 0.038 | Acc: 99.096% | Wgt Acc: 99.034%
	I - Batch: 700 | Loss: 0.040 | Acc: 99.036% | Wgt Acc: 98.961%
	I - Batch: 750 | Loss: 0.042 | Acc: 98.942% | Wgt Acc: 98.883%
	I - Batch: 800 | Loss: 0.043 | Acc: 98.906% | Wgt Acc: 98.862%
	I - Batch: 850 | Loss: 0.042 | Acc: 98.934% | Wgt Acc: 98.891%
I - num batch: 876
I - Train -- Loss: 0.045 | Acc: 98.922% | Wgt Acc: 98.877% | LR: 1.250000e-04 | Dur: 535.85s
I - Confusion Matrix: [row->prediction - col->label]
[[1868.    0.    0.   10.   31.]
 [   0.  912.    3.    4.    6.]
 [   0.    8. 1319.    0.   23.]
 [   7.    4.    1. 1905.   21.]
 [  11.    3.   12.    7. 7849.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.762 | Acc: 28.750% | Wgt Acc: 27.815%
	I - Batch: 100 | Loss: 3.067 | Acc: 46.500% | Wgt Acc: 36.732%
	I - Batch: 150 | Loss: 2.801 | Acc: 53.417% | Wgt Acc: 41.225%
I - num batch: 193
I - Val -- Loss: 2.789 | Acc: 55.379% | Wgt Acc: 42.210% | Dur: 90.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 207.    4.   10.   46.   19.]
 [   0.   68.   13.    7.   10.]
 [   3.   44.  103.   15.   31.]
 [  76.   32.   17.  210.   34.]
 [ 249.  222.  249.  296. 1121.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.036 | Acc: 99.250% | Wgt Acc: 99.054%
	I - Batch: 100 | Loss: 0.047 | Acc: 98.688% | Wgt Acc: 98.752%
	I - Batch: 150 | Loss: 0.047 | Acc: 98.958% | Wgt Acc: 98.953%
	I - Batch: 200 | Loss: 0.044 | Acc: 98.938% | Wgt Acc: 98.990%
	I - Batch: 250 | Loss: 0.048 | Acc: 98.775% | Wgt Acc: 98.851%
	I - Batch: 300 | Loss: 0.046 | Acc: 98.833% | Wgt Acc: 98.855%
	I - Batch: 350 | Loss: 0.046 | Acc: 98.857% | Wgt Acc: 98.854%
	I - Batch: 400 | Loss: 0.046 | Acc: 98.781% | Wgt Acc: 98.777%
	I - Batch: 450 | Loss: 0.047 | Acc: 98.750% | Wgt Acc: 98.755%
	I - Batch: 500 | Loss: 0.047 | Acc: 98.713% | Wgt Acc: 98.738%
	I - Batch: 550 | Loss: 0.048 | Acc: 98.705% | Wgt Acc: 98.737%
	I - Batch: 600 | Loss: 0.047 | Acc: 98.771% | Wgt Acc: 98.797%
	I - Batch: 650 | Loss: 0.047 | Acc: 98.740% | Wgt Acc: 98.763%
	I - Batch: 700 | Loss: 0.048 | Acc: 98.741% | Wgt Acc: 98.753%
	I - Batch: 750 | Loss: 0.046 | Acc: 98.792% | Wgt Acc: 98.799%
	I - Batch: 800 | Loss: 0.045 | Acc: 98.805% | Wgt Acc: 98.817%
	I - Batch: 850 | Loss: 0.044 | Acc: 98.838% | Wgt Acc: 98.857%
I - num batch: 876
I - Train -- Loss: 0.044 | Acc: 98.836% | Wgt Acc: 98.855% | LR: 1.250000e-04 | Dur: 535.41s
I - Confusion Matrix: [row->prediction - col->label]
[[1864.    0.    1.    3.   43.]
 [   0.  915.    7.    1.    6.]
 [   0.    7. 1314.    0.   28.]
 [   3.    2.    0. 1915.   20.]
 [  19.    3.   13.    7. 7833.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.781 | Acc: 44.375% | Wgt Acc: 43.321%
	I - Batch: 100 | Loss: 2.344 | Acc: 54.812% | Wgt Acc: 48.485%
	I - Batch: 150 | Loss: 2.167 | Acc: 59.667% | Wgt Acc: 51.967%
I - num batch: 193
I - Val -- Loss: 2.184 | Acc: 60.110% | Wgt Acc: 52.013% | Dur: 90.22s
I - Confusion Matrix: [row->prediction - col->label]
[[354.  22.  32. 134.  88.]
 [  3. 142.  44.  16.  33.]
 [  1.  26.  99.   6.  24.]
 [ 73.  40.  24. 268.  78.]
 [104. 140. 193. 150. 992.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.375% | Wgt Acc: 99.278%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.188% | Wgt Acc: 99.069%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.083% | Wgt Acc: 98.942%
	I - Batch: 200 | Loss: 0.042 | Acc: 99.062% | Wgt Acc: 98.986%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.175% | Wgt Acc: 99.121%
	I - Batch: 300 | Loss: 0.041 | Acc: 99.083% | Wgt Acc: 98.932%
	I - Batch: 350 | Loss: 0.042 | Acc: 98.982% | Wgt Acc: 98.862%
	I - Batch: 400 | Loss: 0.047 | Acc: 98.797% | Wgt Acc: 98.676%
	I - Batch: 450 | Loss: 0.047 | Acc: 98.792% | Wgt Acc: 98.727%
	I - Batch: 500 | Loss: 0.049 | Acc: 98.700% | Wgt Acc: 98.632%
	I - Batch: 550 | Loss: 0.049 | Acc: 98.705% | Wgt Acc: 98.664%
	I - Batch: 600 | Loss: 0.048 | Acc: 98.719% | Wgt Acc: 98.702%
	I - Batch: 650 | Loss: 0.046 | Acc: 98.788% | Wgt Acc: 98.774%
	I - Batch: 700 | Loss: 0.045 | Acc: 98.839% | Wgt Acc: 98.814%
	I - Batch: 750 | Loss: 0.045 | Acc: 98.808% | Wgt Acc: 98.797%
	I - Batch: 800 | Loss: 0.045 | Acc: 98.812% | Wgt Acc: 98.797%
	I - Batch: 850 | Loss: 0.044 | Acc: 98.838% | Wgt Acc: 98.829%
I - num batch: 876
I - Train -- Loss: 0.044 | Acc: 98.850% | Wgt Acc: 98.829% | LR: 1.250000e-04 | Dur: 537.38s
I - Confusion Matrix: [row->prediction - col->label]
[[1868.    0.    0.    7.   29.]
 [   1.  913.    2.    3.    9.]
 [   0.    4. 1316.    0.   30.]
 [   6.    4.    1. 1906.   22.]
 [  11.    6.   16.   10. 7840.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.936 | Acc: 41.500% | Wgt Acc: 40.505%
	I - Batch: 100 | Loss: 2.458 | Acc: 52.625% | Wgt Acc: 45.869%
	I - Batch: 150 | Loss: 2.294 | Acc: 56.833% | Wgt Acc: 48.625%
I - num batch: 193
I - Val -- Loss: 2.297 | Acc: 58.101% | Wgt Acc: 49.194% | Dur: 91.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 387.   21.   43.  186.  105.]
 [   3.  120.   25.   22.   23.]
 [   4.   54.  124.    9.   55.]
 [  28.   20.   10.  160.   30.]
 [ 113.  155.  190.  197. 1002.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.745%
	I - Batch: 100 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.903%
	I - Batch: 150 | Loss: 0.038 | Acc: 99.000% | Wgt Acc: 99.049%
	I - Batch: 200 | Loss: 0.036 | Acc: 99.125% | Wgt Acc: 99.158%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.075% | Wgt Acc: 99.078%
	I - Batch: 300 | Loss: 0.037 | Acc: 99.167% | Wgt Acc: 99.195%
	I - Batch: 350 | Loss: 0.037 | Acc: 99.161% | Wgt Acc: 99.204%
	I - Batch: 400 | Loss: 0.037 | Acc: 99.156% | Wgt Acc: 99.213%
	I - Batch: 450 | Loss: 0.037 | Acc: 99.139% | Wgt Acc: 99.212%
	I - Batch: 500 | Loss: 0.035 | Acc: 99.225% | Wgt Acc: 99.289%
	I - Batch: 550 | Loss: 0.036 | Acc: 99.205% | Wgt Acc: 99.246%
	I - Batch: 600 | Loss: 0.035 | Acc: 99.208% | Wgt Acc: 99.251%
	I - Batch: 650 | Loss: 0.036 | Acc: 99.192% | Wgt Acc: 99.218%
	I - Batch: 700 | Loss: 0.037 | Acc: 99.179% | Wgt Acc: 99.165%
	I - Batch: 750 | Loss: 0.039 | Acc: 99.117% | Wgt Acc: 99.083%
	I - Batch: 800 | Loss: 0.039 | Acc: 99.109% | Wgt Acc: 99.096%
	I - Batch: 850 | Loss: 0.039 | Acc: 99.096% | Wgt Acc: 99.089%
I - num batch: 876
I - Train -- Loss: 0.040 | Acc: 99.093% | Wgt Acc: 99.078% | LR: 1.250000e-04 | Dur: 541.32s
I - Confusion Matrix: [row->prediction - col->label]
[[1869.    1.    0.    2.   29.]
 [   0.  916.    6.    2.    5.]
 [   0.    7. 1317.    0.   23.]
 [   3.    1.    1. 1917.   15.]
 [  14.    2.   11.    5. 7858.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.113 | Acc: 38.750% | Wgt Acc: 37.624%
	I - Batch: 100 | Loss: 2.585 | Acc: 52.312% | Wgt Acc: 44.524%
	I - Batch: 150 | Loss: 2.363 | Acc: 57.458% | Wgt Acc: 48.064%
I - num batch: 193
I - Val -- Loss: 2.322 | Acc: 59.268% | Wgt Acc: 49.104% | Dur: 91.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 324.   14.   26.  121.   59.]
 [   4.  104.   23.   20.   20.]
 [   6.   34.  104.   12.   27.]
 [  70.   28.   20.  244.   56.]
 [ 131.  190.  219.  177. 1053.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 98.750% | Wgt Acc: 98.747%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.188% | Wgt Acc: 99.205%
	I - Batch: 150 | Loss: 0.027 | Acc: 99.375% | Wgt Acc: 99.422%
	I - Batch: 200 | Loss: 0.036 | Acc: 99.156% | Wgt Acc: 99.064%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.025% | Wgt Acc: 98.974%
	I - Batch: 300 | Loss: 0.042 | Acc: 98.917% | Wgt Acc: 98.878%
	I - Batch: 350 | Loss: 0.043 | Acc: 98.821% | Wgt Acc: 98.777%
	I - Batch: 400 | Loss: 0.045 | Acc: 98.828% | Wgt Acc: 98.786%
	I - Batch: 450 | Loss: 0.044 | Acc: 98.847% | Wgt Acc: 98.776%
	I - Batch: 500 | Loss: 0.043 | Acc: 98.888% | Wgt Acc: 98.831%
	I - Batch: 550 | Loss: 0.041 | Acc: 98.932% | Wgt Acc: 98.878%
	I - Batch: 600 | Loss: 0.040 | Acc: 98.990% | Wgt Acc: 98.945%
	I - Batch: 650 | Loss: 0.038 | Acc: 99.058% | Wgt Acc: 99.019%
	I - Batch: 700 | Loss: 0.037 | Acc: 99.098% | Wgt Acc: 99.062%
	I - Batch: 750 | Loss: 0.036 | Acc: 99.125% | Wgt Acc: 99.090%
	I - Batch: 800 | Loss: 0.037 | Acc: 99.109% | Wgt Acc: 99.073%
	I - Batch: 850 | Loss: 0.039 | Acc: 99.037% | Wgt Acc: 99.009%
I - num batch: 876
I - Train -- Loss: 0.039 | Acc: 99.029% | Wgt Acc: 99.010% | LR: 1.250000e-04 | Dur: 533.73s
I - Confusion Matrix: [row->prediction - col->label]
[[1874.    0.    0.    3.   18.]
 [   0.  914.    6.    1.    6.]
 [   0.    6. 1312.    0.   33.]
 [   4.    3.    1. 1916.   21.]
 [   8.    4.   16.    6. 7852.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.590 | Acc: 44.625% | Wgt Acc: 43.698%
	I - Batch: 100 | Loss: 2.266 | Acc: 54.312% | Wgt Acc: 49.139%
	I - Batch: 150 | Loss: 2.145 | Acc: 57.583% | Wgt Acc: 51.129%
I - num batch: 193
I - Val -- Loss: 2.143 | Acc: 57.907% | Wgt Acc: 50.902% | Dur: 89.95s
I - Confusion Matrix: [row->prediction - col->label]
[[412.  27.  41. 203. 126.]
 [  7. 133.  36.  24.  40.]
 [  5.  66. 133.  17.  76.]
 [ 34.  18.   9. 178.  42.]
 [ 77. 126. 173. 152. 931.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.105 | Acc: 96.375% | Wgt Acc: 96.250%
	I - Batch: 100 | Loss: 0.089 | Acc: 96.938% | Wgt Acc: 97.017%
	I - Batch: 150 | Loss: 0.076 | Acc: 97.500% | Wgt Acc: 97.610%
	I - Batch: 200 | Loss: 0.072 | Acc: 97.750% | Wgt Acc: 97.829%
	I - Batch: 250 | Loss: 0.071 | Acc: 97.800% | Wgt Acc: 97.909%
	I - Batch: 300 | Loss: 0.071 | Acc: 97.792% | Wgt Acc: 97.865%
	I - Batch: 350 | Loss: 0.075 | Acc: 97.625% | Wgt Acc: 97.707%
	I - Batch: 400 | Loss: 0.072 | Acc: 97.719% | Wgt Acc: 97.799%
	I - Batch: 450 | Loss: 0.072 | Acc: 97.694% | Wgt Acc: 97.773%
	I - Batch: 500 | Loss: 0.074 | Acc: 97.612% | Wgt Acc: 97.707%
	I - Batch: 550 | Loss: 0.074 | Acc: 97.625% | Wgt Acc: 97.715%
	I - Batch: 600 | Loss: 0.075 | Acc: 97.604% | Wgt Acc: 97.709%
	I - Batch: 650 | Loss: 0.073 | Acc: 97.692% | Wgt Acc: 97.787%
	I - Batch: 700 | Loss: 0.071 | Acc: 97.786% | Wgt Acc: 97.862%
	I - Batch: 750 | Loss: 0.070 | Acc: 97.808% | Wgt Acc: 97.891%
	I - Batch: 800 | Loss: 0.068 | Acc: 97.844% | Wgt Acc: 97.942%
	I - Batch: 850 | Loss: 0.066 | Acc: 97.934% | Wgt Acc: 98.013%
I - num batch: 876
I - Train -- Loss: 0.066 | Acc: 97.972% | Wgt Acc: 98.045% | LR: 1.250000e-04 | Dur: 537.88s
I - Confusion Matrix: [row->prediction - col->label]
[[1857.    0.    1.    7.   46.]
 [   0.  908.   11.    2.   19.]
 [   0.    9. 1300.    1.   65.]
 [   6.    2.    1. 1899.   44.]
 [  23.    8.   22.   17. 7756.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.528 | Acc: 48.375% | Wgt Acc: 47.597%
	I - Batch: 100 | Loss: 2.139 | Acc: 57.000% | Wgt Acc: 52.067%
	I - Batch: 150 | Loss: 2.033 | Acc: 59.500% | Wgt Acc: 53.485%
I - num batch: 193
I - Val -- Loss: 2.074 | Acc: 59.527% | Wgt Acc: 53.087% | Dur: 90.68s
I - Confusion Matrix: [row->prediction - col->label]
[[293.  10.  27.  90.  48.]
 [  6. 157.  50.  18.  48.]
 [  5.  48. 122.  11.  55.]
 [125.  47.  33. 334. 133.]
 [106. 108. 160. 121. 931.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.433%
	I - Batch: 100 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 98.670%
	I - Batch: 150 | Loss: 0.041 | Acc: 99.042% | Wgt Acc: 98.820%
	I - Batch: 200 | Loss: 0.045 | Acc: 98.875% | Wgt Acc: 98.715%
	I - Batch: 250 | Loss: 0.043 | Acc: 98.950% | Wgt Acc: 98.831%
	I - Batch: 300 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.829%
	I - Batch: 350 | Loss: 0.045 | Acc: 98.821% | Wgt Acc: 98.833%
	I - Batch: 400 | Loss: 0.044 | Acc: 98.891% | Wgt Acc: 98.918%
	I - Batch: 450 | Loss: 0.044 | Acc: 98.903% | Wgt Acc: 98.913%
	I - Batch: 500 | Loss: 0.049 | Acc: 98.725% | Wgt Acc: 98.756%
	I - Batch: 550 | Loss: 0.049 | Acc: 98.727% | Wgt Acc: 98.752%
	I - Batch: 600 | Loss: 0.049 | Acc: 98.729% | Wgt Acc: 98.745%
	I - Batch: 650 | Loss: 0.047 | Acc: 98.750% | Wgt Acc: 98.771%
	I - Batch: 700 | Loss: 0.048 | Acc: 98.723% | Wgt Acc: 98.723%
	I - Batch: 750 | Loss: 0.050 | Acc: 98.658% | Wgt Acc: 98.633%
	I - Batch: 800 | Loss: 0.050 | Acc: 98.633% | Wgt Acc: 98.625%
	I - Batch: 850 | Loss: 0.052 | Acc: 98.574% | Wgt Acc: 98.591%
I - num batch: 876
I - Train -- Loss: 0.052 | Acc: 98.593% | Wgt Acc: 98.604% | LR: 1.250000e-04 | Dur: 547.93s
I - Confusion Matrix: [row->prediction - col->label]
[[1865.    0.    0.    3.   41.]
 [   0.  911.   14.    2.   10.]
 [   0.   11. 1305.    0.   38.]
 [   3.    2.    1. 1913.   28.]
 [  18.    3.   15.    8. 7813.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.785 | Acc: 43.500% | Wgt Acc: 42.331%
	I - Batch: 100 | Loss: 2.273 | Acc: 54.500% | Wgt Acc: 48.238%
	I - Batch: 150 | Loss: 2.116 | Acc: 58.750% | Wgt Acc: 51.282%
I - num batch: 193
I - Val -- Loss: 2.101 | Acc: 59.041% | Wgt Acc: 51.133% | Dur: 93.17s
I - Confusion Matrix: [row->prediction - col->label]
[[344.  13.  33. 149.  86.]
 [  4. 125.  42.  11.  22.]
 [  4.  35. 106.  12.  33.]
 [ 70.  48.  31. 278. 105.]
 [113. 149. 180. 124. 969.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.375% | Wgt Acc: 99.542%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.250% | Wgt Acc: 99.318%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.333% | Wgt Acc: 99.361%
	I - Batch: 200 | Loss: 0.036 | Acc: 99.188% | Wgt Acc: 99.159%
	I - Batch: 250 | Loss: 0.043 | Acc: 98.975% | Wgt Acc: 98.882%
	I - Batch: 300 | Loss: 0.041 | Acc: 99.000% | Wgt Acc: 98.969%
	I - Batch: 350 | Loss: 0.040 | Acc: 99.036% | Wgt Acc: 99.000%
	I - Batch: 400 | Loss: 0.039 | Acc: 99.062% | Wgt Acc: 99.044%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.056% | Wgt Acc: 99.033%
	I - Batch: 500 | Loss: 0.040 | Acc: 99.000% | Wgt Acc: 99.009%
	I - Batch: 550 | Loss: 0.041 | Acc: 98.943% | Wgt Acc: 98.962%
	I - Batch: 600 | Loss: 0.042 | Acc: 98.875% | Wgt Acc: 98.903%
	I - Batch: 650 | Loss: 0.044 | Acc: 98.837% | Wgt Acc: 98.830%
	I - Batch: 700 | Loss: 0.044 | Acc: 98.795% | Wgt Acc: 98.799%
	I - Batch: 750 | Loss: 0.044 | Acc: 98.833% | Wgt Acc: 98.848%
	I - Batch: 800 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.892%
	I - Batch: 850 | Loss: 0.042 | Acc: 98.897% | Wgt Acc: 98.916%
I - num batch: 876
I - Train -- Loss: 0.043 | Acc: 98.872% | Wgt Acc: 98.897% | LR: 1.250000e-04 | Dur: 548.02s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    1.    4.   27.]
 [   1.  916.    5.    4.    7.]
 [   0.    4. 1318.    1.   36.]
 [   2.    4.    0. 1905.   24.]
 [  12.    3.   11.   12. 7836.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.073 | Acc: 40.375% | Wgt Acc: 39.149%
	I - Batch: 100 | Loss: 2.564 | Acc: 53.188% | Wgt Acc: 45.169%
	I - Batch: 150 | Loss: 2.385 | Acc: 58.292% | Wgt Acc: 48.276%
I - num batch: 193
I - Val -- Loss: 2.372 | Acc: 59.430% | Wgt Acc: 48.852% | Dur: 92.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 268.    9.   19.   73.   42.]
 [   0.   87.   10.   12.    8.]
 [   8.   56.  136.    8.   38.]
 [  87.   26.   16.  271.   55.]
 [ 172.  192.  211.  210. 1072.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.125% | Wgt Acc: 99.111%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.250% | Wgt Acc: 99.272%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.417% | Wgt Acc: 99.469%
	I - Batch: 200 | Loss: 0.025 | Acc: 99.438% | Wgt Acc: 99.429%
	I - Batch: 250 | Loss: 0.028 | Acc: 99.300% | Wgt Acc: 99.289%
	I - Batch: 300 | Loss: 0.032 | Acc: 99.104% | Wgt Acc: 99.073%
	I - Batch: 350 | Loss: 0.033 | Acc: 99.107% | Wgt Acc: 99.065%
	I - Batch: 400 | Loss: 0.035 | Acc: 99.078% | Wgt Acc: 99.038%
	I - Batch: 450 | Loss: 0.034 | Acc: 99.097% | Wgt Acc: 99.070%
	I - Batch: 500 | Loss: 0.034 | Acc: 99.138% | Wgt Acc: 99.107%
	I - Batch: 550 | Loss: 0.035 | Acc: 99.091% | Wgt Acc: 99.077%
	I - Batch: 600 | Loss: 0.038 | Acc: 99.052% | Wgt Acc: 99.013%
	I - Batch: 650 | Loss: 0.039 | Acc: 98.981% | Wgt Acc: 98.967%
	I - Batch: 700 | Loss: 0.038 | Acc: 99.000% | Wgt Acc: 98.991%
	I - Batch: 750 | Loss: 0.039 | Acc: 98.983% | Wgt Acc: 98.985%
	I - Batch: 800 | Loss: 0.038 | Acc: 99.000% | Wgt Acc: 99.006%
	I - Batch: 850 | Loss: 0.040 | Acc: 98.985% | Wgt Acc: 98.986%
I - num batch: 876
I - Train -- Loss: 0.040 | Acc: 98.972% | Wgt Acc: 98.985% | LR: 1.250000e-04 | Dur: 540.77s
I - Confusion Matrix: [row->prediction - col->label]
[[1872.    0.    1.    3.   28.]
 [   0.  917.    5.    2.   11.]
 [   0.    7. 1316.    0.   18.]
 [   2.    0.    0. 1910.   28.]
 [  12.    3.   13.   11. 7845.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.076 | Acc: 39.500% | Wgt Acc: 38.203%
	I - Batch: 100 | Loss: 2.545 | Acc: 52.438% | Wgt Acc: 44.922%
	I - Batch: 150 | Loss: 2.352 | Acc: 57.708% | Wgt Acc: 48.350%
I - num batch: 193
I - Val -- Loss: 2.325 | Acc: 59.073% | Wgt Acc: 49.071% | Dur: 91.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 279.   14.   24.   82.   44.]
 [   3.   98.   16.    9.   17.]
 [   4.   43.  107.    9.   41.]
 [ 121.   29.   28.  296.   70.]
 [ 128.  186.  217.  178. 1043.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.053 | Acc: 98.125% | Wgt Acc: 97.938%
	I - Batch: 100 | Loss: 0.049 | Acc: 98.375% | Wgt Acc: 98.411%
	I - Batch: 150 | Loss: 0.045 | Acc: 98.583% | Wgt Acc: 98.636%
	I - Batch: 200 | Loss: 0.042 | Acc: 98.688% | Wgt Acc: 98.724%
	I - Batch: 250 | Loss: 0.045 | Acc: 98.725% | Wgt Acc: 98.703%
	I - Batch: 300 | Loss: 0.053 | Acc: 98.521% | Wgt Acc: 98.425%
	I - Batch: 350 | Loss: 0.060 | Acc: 98.411% | Wgt Acc: 98.315%
	I - Batch: 400 | Loss: 0.057 | Acc: 98.484% | Wgt Acc: 98.388%
	I - Batch: 450 | Loss: 0.056 | Acc: 98.486% | Wgt Acc: 98.426%
	I - Batch: 500 | Loss: 0.057 | Acc: 98.438% | Wgt Acc: 98.354%
	I - Batch: 550 | Loss: 0.057 | Acc: 98.409% | Wgt Acc: 98.334%
	I - Batch: 600 | Loss: 0.057 | Acc: 98.417% | Wgt Acc: 98.329%
	I - Batch: 650 | Loss: 0.062 | Acc: 98.231% | Wgt Acc: 98.196%
	I - Batch: 700 | Loss: 0.062 | Acc: 98.214% | Wgt Acc: 98.171%
	I - Batch: 750 | Loss: 0.064 | Acc: 98.142% | Wgt Acc: 98.071%
	I - Batch: 800 | Loss: 0.064 | Acc: 98.125% | Wgt Acc: 98.059%
	I - Batch: 850 | Loss: 0.063 | Acc: 98.140% | Wgt Acc: 98.096%
I - num batch: 876
I - Train -- Loss: 0.063 | Acc: 98.158% | Wgt Acc: 98.108% | LR: 1.250000e-04 | Dur: 545.35s
I - Confusion Matrix: [row->prediction - col->label]
[[1850.    0.    0.   15.   39.]
 [   1.  914.   11.    3.   14.]
 [   1.    7. 1301.    0.   57.]
 [  13.    3.    1. 1890.   29.]
 [  21.    3.   22.   18. 7791.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.021 | Acc: 40.500% | Wgt Acc: 39.029%
	I - Batch: 100 | Loss: 2.415 | Acc: 53.750% | Wgt Acc: 46.510%
	I - Batch: 150 | Loss: 2.213 | Acc: 59.167% | Wgt Acc: 50.408%
I - num batch: 193
I - Val -- Loss: 2.227 | Acc: 59.624% | Wgt Acc: 50.545% | Dur: 93.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 376.   19.   35.  171.   89.]
 [   4.   96.   12.    8.    9.]
 [   8.   36.  117.   13.   33.]
 [  61.   34.   19.  238.   71.]
 [  86.  185.  209.  144. 1013.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.051 | Acc: 98.625% | Wgt Acc: 98.566%
	I - Batch: 100 | Loss: 0.041 | Acc: 98.688% | Wgt Acc: 98.794%
	I - Batch: 150 | Loss: 0.047 | Acc: 98.583% | Wgt Acc: 98.653%
	I - Batch: 200 | Loss: 0.058 | Acc: 98.375% | Wgt Acc: 98.436%
	I - Batch: 250 | Loss: 0.056 | Acc: 98.450% | Wgt Acc: 98.588%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.542% | Wgt Acc: 98.677%
	I - Batch: 350 | Loss: 0.050 | Acc: 98.643% | Wgt Acc: 98.743%
	I - Batch: 400 | Loss: 0.047 | Acc: 98.750% | Wgt Acc: 98.864%
	I - Batch: 450 | Loss: 0.044 | Acc: 98.819% | Wgt Acc: 98.923%
	I - Batch: 500 | Loss: 0.043 | Acc: 98.838% | Wgt Acc: 98.947%
	I - Batch: 550 | Loss: 0.042 | Acc: 98.875% | Wgt Acc: 98.975%
	I - Batch: 600 | Loss: 0.043 | Acc: 98.844% | Wgt Acc: 98.934%
	I - Batch: 650 | Loss: 0.043 | Acc: 98.856% | Wgt Acc: 98.961%
	I - Batch: 700 | Loss: 0.043 | Acc: 98.857% | Wgt Acc: 98.938%
	I - Batch: 750 | Loss: 0.043 | Acc: 98.867% | Wgt Acc: 98.939%
	I - Batch: 800 | Loss: 0.042 | Acc: 98.883% | Wgt Acc: 98.935%
	I - Batch: 850 | Loss: 0.043 | Acc: 98.860% | Wgt Acc: 98.906%
I - num batch: 876
I - Train -- Loss: 0.043 | Acc: 98.850% | Wgt Acc: 98.901% | LR: 1.250000e-04 | Dur: 548.65s
I - Confusion Matrix: [row->prediction - col->label]
[[1870.    0.    1.    5.   31.]
 [   1.  919.    1.    2.   10.]
 [   0.    4. 1315.    0.   34.]
 [   7.    1.    0. 1908.   24.]
 [   8.    3.   18.   11. 7831.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.477 | Acc: 48.250% | Wgt Acc: 47.537%
	I - Batch: 100 | Loss: 2.103 | Acc: 57.938% | Wgt Acc: 52.642%
	I - Batch: 150 | Loss: 1.993 | Acc: 61.125% | Wgt Acc: 54.684%
I - num batch: 193
I - Val -- Loss: 2.016 | Acc: 61.115% | Wgt Acc: 54.000% | Dur: 92.18s
I - Confusion Matrix: [row->prediction - col->label]
[[363.  13.  31. 130.  55.]
 [  4. 136.  15.  26.  24.]
 [ 10.  83. 189.  15. 103.]
 [ 51.  25.  16. 217.  52.]
 [107. 113. 141. 186. 981.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 98.250% | Wgt Acc: 98.137%
	I - Batch: 100 | Loss: 0.049 | Acc: 98.188% | Wgt Acc: 98.085%
	I - Batch: 150 | Loss: 0.049 | Acc: 98.417% | Wgt Acc: 98.335%
	I - Batch: 200 | Loss: 0.047 | Acc: 98.500% | Wgt Acc: 98.433%
	I - Batch: 250 | Loss: 0.047 | Acc: 98.525% | Wgt Acc: 98.500%
	I - Batch: 300 | Loss: 0.045 | Acc: 98.625% | Wgt Acc: 98.607%
	I - Batch: 350 | Loss: 0.045 | Acc: 98.661% | Wgt Acc: 98.664%
	I - Batch: 400 | Loss: 0.049 | Acc: 98.594% | Wgt Acc: 98.557%
	I - Batch: 450 | Loss: 0.051 | Acc: 98.611% | Wgt Acc: 98.540%
	I - Batch: 500 | Loss: 0.051 | Acc: 98.575% | Wgt Acc: 98.527%
	I - Batch: 550 | Loss: 0.052 | Acc: 98.568% | Wgt Acc: 98.507%
	I - Batch: 600 | Loss: 0.051 | Acc: 98.625% | Wgt Acc: 98.576%
	I - Batch: 650 | Loss: 0.051 | Acc: 98.596% | Wgt Acc: 98.573%
	I - Batch: 700 | Loss: 0.051 | Acc: 98.598% | Wgt Acc: 98.573%
	I - Batch: 750 | Loss: 0.051 | Acc: 98.583% | Wgt Acc: 98.560%
	I - Batch: 800 | Loss: 0.052 | Acc: 98.516% | Wgt Acc: 98.491%
	I - Batch: 850 | Loss: 0.053 | Acc: 98.493% | Wgt Acc: 98.445%
I - num batch: 876
I - Train -- Loss: 0.055 | Acc: 98.458% | Wgt Acc: 98.429% | LR: 1.250000e-04 | Dur: 543.59s
I - Confusion Matrix: [row->prediction - col->label]
[[1863.    1.    0.   12.   39.]
 [   0.  908.    9.    2.   13.]
 [   0.   10. 1309.    0.   38.]
 [   9.    1.    1. 1899.   31.]
 [  14.    7.   16.   13. 7809.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.525 | Acc: 46.000% | Wgt Acc: 45.743%
	I - Batch: 100 | Loss: 2.134 | Acc: 56.062% | Wgt Acc: 51.134%
	I - Batch: 150 | Loss: 2.028 | Acc: 59.708% | Wgt Acc: 53.500%
I - num batch: 193
I - Val -- Loss: 2.070 | Acc: 59.494% | Wgt Acc: 52.578% | Dur: 91.40s
I - Confusion Matrix: [row->prediction - col->label]
[[346.  10.  25. 116.  73.]
 [ 16. 190.  72.  57.  70.]
 [  9.  32. 133.  19.  61.]
 [ 53.  14.  12. 202.  46.]
 [111. 124. 150. 180. 965.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.062 | Acc: 98.500% | Wgt Acc: 98.359%
	I - Batch: 100 | Loss: 0.050 | Acc: 98.750% | Wgt Acc: 98.772%
	I - Batch: 150 | Loss: 0.046 | Acc: 98.917% | Wgt Acc: 98.953%
	I - Batch: 200 | Loss: 0.041 | Acc: 99.062% | Wgt Acc: 99.112%
	I - Batch: 250 | Loss: 0.040 | Acc: 99.075% | Wgt Acc: 99.110%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.146% | Wgt Acc: 99.156%
	I - Batch: 350 | Loss: 0.038 | Acc: 99.107% | Wgt Acc: 99.118%
	I - Batch: 400 | Loss: 0.039 | Acc: 99.062% | Wgt Acc: 99.053%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 99.047%
	I - Batch: 500 | Loss: 0.039 | Acc: 99.013% | Wgt Acc: 99.064%
	I - Batch: 550 | Loss: 0.039 | Acc: 98.955% | Wgt Acc: 99.021%
	I - Batch: 600 | Loss: 0.040 | Acc: 98.958% | Wgt Acc: 99.025%
	I - Batch: 650 | Loss: 0.040 | Acc: 98.952% | Wgt Acc: 99.008%
	I - Batch: 700 | Loss: 0.039 | Acc: 98.973% | Wgt Acc: 99.046%
	I - Batch: 750 | Loss: 0.038 | Acc: 99.033% | Wgt Acc: 99.105%
	I - Batch: 800 | Loss: 0.037 | Acc: 99.031% | Wgt Acc: 99.103%
	I - Batch: 850 | Loss: 0.037 | Acc: 99.037% | Wgt Acc: 99.108%
I - num batch: 876
I - Train -- Loss: 0.037 | Acc: 99.050% | Wgt Acc: 99.111% | LR: 1.250000e-04 | Dur: 540.36s
I - Confusion Matrix: [row->prediction - col->label]
[[1868.    1.    2.    2.   23.]
 [   0.  919.    0.    4.   11.]
 [   0.    1. 1324.    0.   30.]
 [   2.    1.    0. 1914.   20.]
 [  16.    5.    9.    6. 7846.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.894 | Acc: 40.375% | Wgt Acc: 39.603%
	I - Batch: 100 | Loss: 2.392 | Acc: 53.062% | Wgt Acc: 46.102%
	I - Batch: 150 | Loss: 2.241 | Acc: 58.042% | Wgt Acc: 49.577%
I - num batch: 193
I - Val -- Loss: 2.265 | Acc: 58.911% | Wgt Acc: 49.715% | Dur: 91.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 278.   10.   18.   74.   29.]
 [   1.  105.   22.   19.   21.]
 [  15.   59.  151.   14.   81.]
 [  91.   28.   28.  262.   62.]
 [ 150.  168.  173.  205. 1022.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.375% | Wgt Acc: 99.536%
	I - Batch: 100 | Loss: 0.022 | Acc: 99.625% | Wgt Acc: 99.730%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.583% | Wgt Acc: 99.687%
	I - Batch: 200 | Loss: 0.021 | Acc: 99.656% | Wgt Acc: 99.747%
	I - Batch: 250 | Loss: 0.021 | Acc: 99.650% | Wgt Acc: 99.756%
	I - Batch: 300 | Loss: 0.021 | Acc: 99.604% | Wgt Acc: 99.696%
	I - Batch: 350 | Loss: 0.021 | Acc: 99.643% | Wgt Acc: 99.729%
	I - Batch: 400 | Loss: 0.021 | Acc: 99.609% | Wgt Acc: 99.686%
	I - Batch: 450 | Loss: 0.022 | Acc: 99.569% | Wgt Acc: 99.626%
	I - Batch: 500 | Loss: 0.024 | Acc: 99.562% | Wgt Acc: 99.598%
	I - Batch: 550 | Loss: 0.024 | Acc: 99.545% | Wgt Acc: 99.577%
	I - Batch: 600 | Loss: 0.026 | Acc: 99.427% | Wgt Acc: 99.448%
	I - Batch: 650 | Loss: 0.027 | Acc: 99.365% | Wgt Acc: 99.389%
	I - Batch: 700 | Loss: 0.031 | Acc: 99.232% | Wgt Acc: 99.255%
	I - Batch: 750 | Loss: 0.034 | Acc: 99.150% | Wgt Acc: 99.142%
	I - Batch: 800 | Loss: 0.034 | Acc: 99.141% | Wgt Acc: 99.132%
	I - Batch: 850 | Loss: 0.034 | Acc: 99.140% | Wgt Acc: 99.119%
I - num batch: 876
I - Train -- Loss: 0.034 | Acc: 99.136% | Wgt Acc: 99.115% | LR: 1.250000e-04 | Dur: 535.82s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    1.    0.    2.   16.]
 [   1.  915.   11.    2.    9.]
 [   0.    5. 1314.    0.   25.]
 [   2.    3.    1. 1917.   19.]
 [   7.    3.    9.    5. 7861.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.237 | Acc: 37.375% | Wgt Acc: 36.454%
	I - Batch: 100 | Loss: 2.667 | Acc: 51.625% | Wgt Acc: 43.200%
	I - Batch: 150 | Loss: 2.445 | Acc: 57.333% | Wgt Acc: 47.262%
I - num batch: 193
I - Val -- Loss: 2.474 | Acc: 58.198% | Wgt Acc: 47.184% | Dur: 89.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 305.    9.   27.   96.   38.]
 [   0.   92.   14.   20.   10.]
 [   6.   71.  126.   16.   59.]
 [  53.   15.   15.  196.   31.]
 [ 171.  183.  210.  246. 1077.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.071 | Acc: 98.250% | Wgt Acc: 98.143%
	I - Batch: 100 | Loss: 0.070 | Acc: 98.062% | Wgt Acc: 98.090%
	I - Batch: 150 | Loss: 0.065 | Acc: 98.333% | Wgt Acc: 98.211%
	I - Batch: 200 | Loss: 0.068 | Acc: 98.250% | Wgt Acc: 98.153%
	I - Batch: 250 | Loss: 0.070 | Acc: 98.025% | Wgt Acc: 98.027%
	I - Batch: 300 | Loss: 0.069 | Acc: 97.958% | Wgt Acc: 97.992%
	I - Batch: 350 | Loss: 0.069 | Acc: 98.000% | Wgt Acc: 98.003%
	I - Batch: 400 | Loss: 0.071 | Acc: 97.922% | Wgt Acc: 97.925%
	I - Batch: 450 | Loss: 0.067 | Acc: 98.042% | Wgt Acc: 98.020%
	I - Batch: 500 | Loss: 0.066 | Acc: 98.075% | Wgt Acc: 98.077%
	I - Batch: 550 | Loss: 0.065 | Acc: 98.125% | Wgt Acc: 98.113%
	I - Batch: 600 | Loss: 0.063 | Acc: 98.146% | Wgt Acc: 98.143%
	I - Batch: 650 | Loss: 0.063 | Acc: 98.173% | Wgt Acc: 98.164%
	I - Batch: 700 | Loss: 0.061 | Acc: 98.241% | Wgt Acc: 98.244%
	I - Batch: 750 | Loss: 0.059 | Acc: 98.308% | Wgt Acc: 98.335%
	I - Batch: 800 | Loss: 0.059 | Acc: 98.297% | Wgt Acc: 98.302%
	I - Batch: 850 | Loss: 0.060 | Acc: 98.265% | Wgt Acc: 98.264%
I - num batch: 876
I - Train -- Loss: 0.060 | Acc: 98.243% | Wgt Acc: 98.252% | LR: 1.250000e-04 | Dur: 531.27s
I - Confusion Matrix: [row->prediction - col->label]
[[1848.    0.    0.   14.   38.]
 [   0.  914.    7.    2.    9.]
 [   0.    9. 1309.    0.   50.]
 [   8.    4.    1. 1897.   43.]
 [  30.    0.   18.   13. 7790.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.884 | Acc: 40.875% | Wgt Acc: 39.691%
	I - Batch: 100 | Loss: 2.370 | Acc: 54.438% | Wgt Acc: 47.042%
	I - Batch: 150 | Loss: 2.176 | Acc: 58.833% | Wgt Acc: 50.270%
I - num batch: 193
I - Val -- Loss: 2.191 | Acc: 59.559% | Wgt Acc: 50.418% | Dur: 89.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 331.   12.   22.  107.   44.]
 [   2.  101.   17.    8.   14.]
 [   7.   63.  144.   17.   69.]
 [  59.   35.   23.  239.   65.]
 [ 136.  159.  186.  203. 1023.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.078 | Acc: 97.875% | Wgt Acc: 97.907%
	I - Batch: 100 | Loss: 0.055 | Acc: 98.500% | Wgt Acc: 98.695%
	I - Batch: 150 | Loss: 0.044 | Acc: 98.875% | Wgt Acc: 99.060%
	I - Batch: 200 | Loss: 0.038 | Acc: 99.062% | Wgt Acc: 99.211%
	I - Batch: 250 | Loss: 0.035 | Acc: 99.150% | Wgt Acc: 99.285%
	I - Batch: 300 | Loss: 0.042 | Acc: 99.000% | Wgt Acc: 99.074%
	I - Batch: 350 | Loss: 0.043 | Acc: 98.982% | Wgt Acc: 99.025%
	I - Batch: 400 | Loss: 0.041 | Acc: 98.984% | Wgt Acc: 99.035%
	I - Batch: 450 | Loss: 0.045 | Acc: 98.931% | Wgt Acc: 98.942%
	I - Batch: 500 | Loss: 0.045 | Acc: 98.975% | Wgt Acc: 98.984%
	I - Batch: 550 | Loss: 0.044 | Acc: 98.977% | Wgt Acc: 98.974%
	I - Batch: 600 | Loss: 0.043 | Acc: 98.990% | Wgt Acc: 99.007%
	I - Batch: 650 | Loss: 0.041 | Acc: 99.019% | Wgt Acc: 99.047%
	I - Batch: 700 | Loss: 0.040 | Acc: 99.071% | Wgt Acc: 99.107%
	I - Batch: 750 | Loss: 0.038 | Acc: 99.117% | Wgt Acc: 99.157%
	I - Batch: 800 | Loss: 0.037 | Acc: 99.141% | Wgt Acc: 99.177%
	I - Batch: 850 | Loss: 0.037 | Acc: 99.147% | Wgt Acc: 99.170%
I - num batch: 876
I - Train -- Loss: 0.039 | Acc: 99.150% | Wgt Acc: 99.172% | LR: 1.250000e-04 | Dur: 538.60s
I - Confusion Matrix: [row->prediction - col->label]
[[1881.    1.    0.    0.   19.]
 [   0.  916.    7.    1.    3.]
 [   0.    8. 1315.    0.   35.]
 [   1.    1.    0. 1917.   17.]
 [   4.    1.   13.    8. 7856.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.277 | Acc: 52.500% | Wgt Acc: 51.993%
	I - Batch: 100 | Loss: 2.025 | Acc: 57.125% | Wgt Acc: 54.687%
	I - Batch: 150 | Loss: 1.997 | Acc: 58.208% | Wgt Acc: 55.307%
I - num batch: 193
I - Val -- Loss: 2.051 | Acc: 57.356% | Wgt Acc: 54.177% | Dur: 92.00s
I - Confusion Matrix: [row->prediction - col->label]
[[364.  17.  35. 117. 131.]
 [  4. 212.  95.  26. 115.]
 [  7.  22.  99.  15.  56.]
 [ 83.  44.  44. 300. 118.]
 [ 77.  75. 119. 116. 795.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 98.625% | Wgt Acc: 98.253%
	I - Batch: 100 | Loss: 0.039 | Acc: 98.812% | Wgt Acc: 98.705%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.000% | Wgt Acc: 98.974%
	I - Batch: 200 | Loss: 0.037 | Acc: 99.031% | Wgt Acc: 98.951%
	I - Batch: 250 | Loss: 0.034 | Acc: 99.075% | Wgt Acc: 99.047%
	I - Batch: 300 | Loss: 0.032 | Acc: 99.167% | Wgt Acc: 99.174%
	I - Batch: 350 | Loss: 0.030 | Acc: 99.250% | Wgt Acc: 99.255%
	I - Batch: 400 | Loss: 0.030 | Acc: 99.266% | Wgt Acc: 99.276%
	I - Batch: 450 | Loss: 0.029 | Acc: 99.306% | Wgt Acc: 99.305%
	I - Batch: 500 | Loss: 0.029 | Acc: 99.325% | Wgt Acc: 99.315%
	I - Batch: 550 | Loss: 0.028 | Acc: 99.330% | Wgt Acc: 99.328%
	I - Batch: 600 | Loss: 0.028 | Acc: 99.323% | Wgt Acc: 99.318%
	I - Batch: 650 | Loss: 0.028 | Acc: 99.337% | Wgt Acc: 99.350%
	I - Batch: 700 | Loss: 0.028 | Acc: 99.357% | Wgt Acc: 99.361%
	I - Batch: 750 | Loss: 0.028 | Acc: 99.358% | Wgt Acc: 99.364%
	I - Batch: 800 | Loss: 0.029 | Acc: 99.312% | Wgt Acc: 99.325%
	I - Batch: 850 | Loss: 0.029 | Acc: 99.316% | Wgt Acc: 99.315%
I - num batch: 876
I - Train -- Loss: 0.032 | Acc: 99.257% | Wgt Acc: 99.234% | LR: 1.250000e-04 | Dur: 543.33s
I - Confusion Matrix: [row->prediction - col->label]
[[1873.    0.    0.    4.   24.]
 [   0.  917.    6.    4.    4.]
 [   1.    4. 1323.    0.   13.]
 [   3.    5.    0. 1914.   16.]
 [   9.    1.    6.    4. 7873.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.314 | Acc: 34.500% | Wgt Acc: 34.179%
	I - Batch: 100 | Loss: 2.694 | Acc: 50.500% | Wgt Acc: 42.178%
	I - Batch: 150 | Loss: 2.523 | Acc: 55.917% | Wgt Acc: 45.591%
I - num batch: 193
I - Val -- Loss: 2.524 | Acc: 57.032% | Wgt Acc: 45.773% | Dur: 91.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 216.    3.   15.   60.   18.]
 [   1.  120.   24.   19.   20.]
 [   7.   45.  130.   12.   45.]
 [  66.   27.   14.  207.   45.]
 [ 245.  175.  209.  276. 1087.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 98.625% | Wgt Acc: 98.714%
	I - Batch: 100 | Loss: 0.035 | Acc: 98.812% | Wgt Acc: 98.946%
	I - Batch: 150 | Loss: 0.043 | Acc: 98.708% | Wgt Acc: 98.647%
	I - Batch: 200 | Loss: 0.044 | Acc: 98.750% | Wgt Acc: 98.662%
	I - Batch: 250 | Loss: 0.042 | Acc: 98.900% | Wgt Acc: 98.826%
	I - Batch: 300 | Loss: 0.043 | Acc: 98.875% | Wgt Acc: 98.838%
	I - Batch: 350 | Loss: 0.043 | Acc: 98.911% | Wgt Acc: 98.886%
	I - Batch: 400 | Loss: 0.040 | Acc: 99.000% | Wgt Acc: 98.986%
	I - Batch: 450 | Loss: 0.039 | Acc: 99.042% | Wgt Acc: 99.009%
	I - Batch: 500 | Loss: 0.038 | Acc: 99.100% | Wgt Acc: 99.072%
	I - Batch: 550 | Loss: 0.037 | Acc: 99.136% | Wgt Acc: 99.104%
	I - Batch: 600 | Loss: 0.037 | Acc: 99.125% | Wgt Acc: 99.101%
	I - Batch: 650 | Loss: 0.035 | Acc: 99.154% | Wgt Acc: 99.139%
	I - Batch: 700 | Loss: 0.034 | Acc: 99.188% | Wgt Acc: 99.157%
	I - Batch: 750 | Loss: 0.036 | Acc: 99.150% | Wgt Acc: 99.144%
	I - Batch: 800 | Loss: 0.036 | Acc: 99.156% | Wgt Acc: 99.152%
	I - Batch: 850 | Loss: 0.036 | Acc: 99.154% | Wgt Acc: 99.157%
I - num batch: 876
I - Train -- Loss: 0.036 | Acc: 99.157% | Wgt Acc: 99.156% | LR: 1.250000e-04 | Dur: 541.38s
I - Confusion Matrix: [row->prediction - col->label]
[[1878.    0.    0.    2.   16.]
 [   0.  917.    5.    3.    6.]
 [   0.    3. 1317.    0.   23.]
 [   3.    4.    0. 1913.   24.]
 [   5.    3.   13.    8. 7861.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.068 | Acc: 40.375% | Wgt Acc: 40.008%
	I - Batch: 100 | Loss: 2.511 | Acc: 54.000% | Wgt Acc: 46.605%
	I - Batch: 150 | Loss: 2.335 | Acc: 58.583% | Wgt Acc: 49.460%
I - num batch: 193
I - Val -- Loss: 2.354 | Acc: 59.365% | Wgt Acc: 49.415% | Dur: 91.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 307.    9.   23.  108.   36.]
 [   3.  155.   44.   35.   42.]
 [   8.   27.  117.   10.   41.]
 [  39.   13.   11.  185.   28.]
 [ 178.  166.  197.  236. 1068.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 99.625% | Wgt Acc: 99.671%
	I - Batch: 100 | Loss: 0.021 | Acc: 99.625% | Wgt Acc: 99.672%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.667% | Wgt Acc: 99.733%
	I - Batch: 200 | Loss: 0.020 | Acc: 99.656% | Wgt Acc: 99.671%
	I - Batch: 250 | Loss: 0.022 | Acc: 99.675% | Wgt Acc: 99.664%
	I - Batch: 300 | Loss: 0.023 | Acc: 99.688% | Wgt Acc: 99.648%
	I - Batch: 350 | Loss: 0.023 | Acc: 99.679% | Wgt Acc: 99.636%
	I - Batch: 400 | Loss: 0.024 | Acc: 99.609% | Wgt Acc: 99.563%
	I - Batch: 450 | Loss: 0.026 | Acc: 99.556% | Wgt Acc: 99.511%
	I - Batch: 500 | Loss: 0.027 | Acc: 99.525% | Wgt Acc: 99.505%
	I - Batch: 550 | Loss: 0.027 | Acc: 99.500% | Wgt Acc: 99.468%
	I - Batch: 600 | Loss: 0.027 | Acc: 99.510% | Wgt Acc: 99.494%
	I - Batch: 650 | Loss: 0.026 | Acc: 99.529% | Wgt Acc: 99.513%
	I - Batch: 700 | Loss: 0.026 | Acc: 99.509% | Wgt Acc: 99.480%
	I - Batch: 750 | Loss: 0.027 | Acc: 99.483% | Wgt Acc: 99.472%
	I - Batch: 800 | Loss: 0.027 | Acc: 99.484% | Wgt Acc: 99.468%
	I - Batch: 850 | Loss: 0.027 | Acc: 99.456% | Wgt Acc: 99.440%
I - num batch: 876
I - Train -- Loss: 0.028 | Acc: 99.429% | Wgt Acc: 99.407% | LR: 1.250000e-04 | Dur: 540.04s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    1.    0.    0.   17.]
 [   1.  921.    2.    2.    2.]
 [   0.    3. 1324.    0.   13.]
 [   1.    2.    0. 1916.   11.]
 [   8.    0.    9.    8. 7887.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.577 | Acc: 45.375% | Wgt Acc: 44.508%
	I - Batch: 100 | Loss: 2.228 | Acc: 54.062% | Wgt Acc: 49.359%
	I - Batch: 150 | Loss: 2.153 | Acc: 56.083% | Wgt Acc: 50.265%
I - num batch: 193
I - Val -- Loss: 2.140 | Acc: 56.999% | Wgt Acc: 50.750% | Dur: 89.99s
I - Confusion Matrix: [row->prediction - col->label]
[[252.   6.  16.  63.  45.]
 [  3.  97.   7.  11.  19.]
 [ 17. 122. 198.  31. 149.]
 [142.  46.  37. 319. 109.]
 [121.  99. 134. 150. 893.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 99.125% | Wgt Acc: 99.238%
	I - Batch: 100 | Loss: 0.050 | Acc: 98.750% | Wgt Acc: 98.978%
	I - Batch: 150 | Loss: 0.056 | Acc: 98.625% | Wgt Acc: 98.754%
	I - Batch: 200 | Loss: 0.049 | Acc: 98.875% | Wgt Acc: 98.976%
	I - Batch: 250 | Loss: 0.051 | Acc: 98.750% | Wgt Acc: 98.765%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.688% | Wgt Acc: 98.717%
	I - Batch: 350 | Loss: 0.051 | Acc: 98.696% | Wgt Acc: 98.693%
	I - Batch: 400 | Loss: 0.049 | Acc: 98.703% | Wgt Acc: 98.685%
	I - Batch: 450 | Loss: 0.048 | Acc: 98.764% | Wgt Acc: 98.758%
	I - Batch: 500 | Loss: 0.045 | Acc: 98.825% | Wgt Acc: 98.837%
	I - Batch: 550 | Loss: 0.044 | Acc: 98.898% | Wgt Acc: 98.915%
	I - Batch: 600 | Loss: 0.043 | Acc: 98.885% | Wgt Acc: 98.884%
	I - Batch: 650 | Loss: 0.042 | Acc: 98.904% | Wgt Acc: 98.913%
	I - Batch: 700 | Loss: 0.044 | Acc: 98.848% | Wgt Acc: 98.861%
	I - Batch: 750 | Loss: 0.043 | Acc: 98.892% | Wgt Acc: 98.908%
	I - Batch: 800 | Loss: 0.042 | Acc: 98.938% | Wgt Acc: 98.962%
	I - Batch: 850 | Loss: 0.041 | Acc: 98.941% | Wgt Acc: 98.966%
I - num batch: 876
I - Train -- Loss: 0.041 | Acc: 98.950% | Wgt Acc: 98.969% | LR: 1.250000e-04 | Dur: 532.28s
I - Confusion Matrix: [row->prediction - col->label]
[[1868.    0.    0.    2.   29.]
 [   0.  916.    2.    3.    4.]
 [   0.    4. 1319.    0.   28.]
 [   5.    4.    0. 1911.   26.]
 [  13.    3.   14.   10. 7843.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.942 | Acc: 39.750% | Wgt Acc: 39.461%
	I - Batch: 100 | Loss: 2.406 | Acc: 53.812% | Wgt Acc: 46.414%
	I - Batch: 150 | Loss: 2.267 | Acc: 58.083% | Wgt Acc: 49.107%
I - num batch: 193
I - Val -- Loss: 2.249 | Acc: 59.365% | Wgt Acc: 49.761% | Dur: 89.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 281.   11.   16.   81.   31.]
 [   4.  142.   34.   28.   29.]
 [   7.   51.  138.   14.   58.]
 [  65.   19.   25.  217.   43.]
 [ 178.  147.  179.  234. 1054.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 99.750% | Wgt Acc: 99.710%
	I - Batch: 100 | Loss: 0.028 | Acc: 99.500% | Wgt Acc: 99.444%
	I - Batch: 150 | Loss: 0.030 | Acc: 99.333% | Wgt Acc: 99.318%
	I - Batch: 200 | Loss: 0.037 | Acc: 98.969% | Wgt Acc: 99.020%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 99.065%
	I - Batch: 300 | Loss: 0.039 | Acc: 99.000% | Wgt Acc: 99.084%
	I - Batch: 350 | Loss: 0.037 | Acc: 99.054% | Wgt Acc: 99.164%
	I - Batch: 400 | Loss: 0.037 | Acc: 99.109% | Wgt Acc: 99.192%
	I - Batch: 450 | Loss: 0.036 | Acc: 99.125% | Wgt Acc: 99.200%
	I - Batch: 500 | Loss: 0.035 | Acc: 99.138% | Wgt Acc: 99.225%
	I - Batch: 550 | Loss: 0.033 | Acc: 99.193% | Wgt Acc: 99.258%
	I - Batch: 600 | Loss: 0.034 | Acc: 99.198% | Wgt Acc: 99.230%
	I - Batch: 650 | Loss: 0.035 | Acc: 99.212% | Wgt Acc: 99.245%
	I - Batch: 700 | Loss: 0.034 | Acc: 99.205% | Wgt Acc: 99.248%
	I - Batch: 750 | Loss: 0.035 | Acc: 99.183% | Wgt Acc: 99.232%
	I - Batch: 800 | Loss: 0.035 | Acc: 99.180% | Wgt Acc: 99.234%
	I - Batch: 850 | Loss: 0.035 | Acc: 99.162% | Wgt Acc: 99.212%
I - num batch: 876
I - Train -- Loss: 0.035 | Acc: 99.179% | Wgt Acc: 99.231% | LR: 1.250000e-04 | Dur: 535.23s
I - Confusion Matrix: [row->prediction - col->label]
[[1869.    0.    0.    3.   34.]
 [   0.  919.    4.    0.   11.]
 [   0.    4. 1325.    0.   17.]
 [   2.    1.    1. 1919.   11.]
 [  15.    3.    5.    4. 7857.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.021 | Acc: 39.625% | Wgt Acc: 38.805%
	I - Batch: 100 | Loss: 2.491 | Acc: 53.312% | Wgt Acc: 45.964%
	I - Batch: 150 | Loss: 2.289 | Acc: 58.250% | Wgt Acc: 49.446%
I - num batch: 193
I - Val -- Loss: 2.280 | Acc: 59.365% | Wgt Acc: 49.847% | Dur: 88.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 261.   11.   23.   88.   31.]
 [   2.  116.   22.   14.   17.]
 [   9.   50.  140.   15.   55.]
 [ 107.   38.   29.  274.   71.]
 [ 156.  155.  178.  183. 1041.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.375% | Wgt Acc: 99.356%
	I - Batch: 100 | Loss: 0.027 | Acc: 99.562% | Wgt Acc: 99.534%
	I - Batch: 150 | Loss: 0.028 | Acc: 99.375% | Wgt Acc: 99.332%
	I - Batch: 200 | Loss: 0.028 | Acc: 99.375% | Wgt Acc: 99.303%
	I - Batch: 250 | Loss: 0.028 | Acc: 99.325% | Wgt Acc: 99.262%
	I - Batch: 300 | Loss: 0.029 | Acc: 99.292% | Wgt Acc: 99.257%
	I - Batch: 350 | Loss: 0.029 | Acc: 99.250% | Wgt Acc: 99.225%
	I - Batch: 400 | Loss: 0.028 | Acc: 99.297% | Wgt Acc: 99.267%
	I - Batch: 450 | Loss: 0.029 | Acc: 99.278% | Wgt Acc: 99.262%
	I - Batch: 500 | Loss: 0.029 | Acc: 99.325% | Wgt Acc: 99.309%
	I - Batch: 550 | Loss: 0.029 | Acc: 99.330% | Wgt Acc: 99.300%
	I - Batch: 600 | Loss: 0.030 | Acc: 99.312% | Wgt Acc: 99.287%
	I - Batch: 650 | Loss: 0.029 | Acc: 99.327% | Wgt Acc: 99.312%
	I - Batch: 700 | Loss: 0.028 | Acc: 99.357% | Wgt Acc: 99.351%
	I - Batch: 750 | Loss: 0.028 | Acc: 99.383% | Wgt Acc: 99.383%
	I - Batch: 800 | Loss: 0.027 | Acc: 99.383% | Wgt Acc: 99.368%
	I - Batch: 850 | Loss: 0.028 | Acc: 99.368% | Wgt Acc: 99.346%
I - num batch: 876
I - Train -- Loss: 0.028 | Acc: 99.329% | Wgt Acc: 99.312% | LR: 1.250000e-04 | Dur: 533.05s
I - Confusion Matrix: [row->prediction - col->label]
[[1877.    0.    0.    1.   16.]
 [   0.  917.    8.    0.    4.]
 [   0.    7. 1322.    0.   18.]
 [   1.    3.    0. 1917.   15.]
 [   8.    0.    5.    8. 7877.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.004 | Acc: 43.125% | Wgt Acc: 42.506%
	I - Batch: 100 | Loss: 2.487 | Acc: 54.625% | Wgt Acc: 48.419%
	I - Batch: 150 | Loss: 2.341 | Acc: 58.083% | Wgt Acc: 50.403%
I - num batch: 193
I - Val -- Loss: 2.372 | Acc: 58.296% | Wgt Acc: 49.972% | Dur: 90.02s
I - Confusion Matrix: [row->prediction - col->label]
[[339.  11.  19. 125.  65.]
 [  2. 132.  24.  26.  38.]
 [  7.  64. 145.  23.  75.]
 [ 47.  15.  18. 193.  47.]
 [140. 148. 186. 207. 990.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.625% | Wgt Acc: 99.571%
	I - Batch: 100 | Loss: 0.021 | Acc: 99.562% | Wgt Acc: 99.592%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.625% | Wgt Acc: 99.636%
	I - Batch: 200 | Loss: 0.020 | Acc: 99.625% | Wgt Acc: 99.599%
	I - Batch: 250 | Loss: 0.023 | Acc: 99.500% | Wgt Acc: 99.480%
	I - Batch: 300 | Loss: 0.027 | Acc: 99.312% | Wgt Acc: 99.247%
	I - Batch: 350 | Loss: 0.029 | Acc: 99.268% | Wgt Acc: 99.236%
	I - Batch: 400 | Loss: 0.028 | Acc: 99.297% | Wgt Acc: 99.281%
	I - Batch: 450 | Loss: 0.027 | Acc: 99.347% | Wgt Acc: 99.330%
	I - Batch: 500 | Loss: 0.028 | Acc: 99.312% | Wgt Acc: 99.329%
	I - Batch: 550 | Loss: 0.027 | Acc: 99.352% | Wgt Acc: 99.377%
	I - Batch: 600 | Loss: 0.027 | Acc: 99.375% | Wgt Acc: 99.398%
	I - Batch: 650 | Loss: 0.027 | Acc: 99.394% | Wgt Acc: 99.409%
	I - Batch: 700 | Loss: 0.029 | Acc: 99.277% | Wgt Acc: 99.272%
	I - Batch: 750 | Loss: 0.030 | Acc: 99.267% | Wgt Acc: 99.247%
	I - Batch: 800 | Loss: 0.032 | Acc: 99.219% | Wgt Acc: 99.224%
	I - Batch: 850 | Loss: 0.032 | Acc: 99.184% | Wgt Acc: 99.203%
I - num batch: 876
I - Train -- Loss: 0.034 | Acc: 99.136% | Wgt Acc: 99.153% | LR: 1.250000e-04 | Dur: 534.50s
I - Confusion Matrix: [row->prediction - col->label]
[[1873.    0.    0.    5.   17.]
 [   0.  919.    3.    1.    9.]
 [   0.    4. 1324.    0.   22.]
 [   6.    2.    0. 1908.   23.]
 [   7.    2.    8.   12. 7859.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.815 | Acc: 42.500% | Wgt Acc: 41.785%
	I - Batch: 100 | Loss: 2.419 | Acc: 51.562% | Wgt Acc: 45.635%
	I - Batch: 150 | Loss: 2.229 | Acc: 56.208% | Wgt Acc: 48.852%
I - num batch: 193
I - Val -- Loss: 2.246 | Acc: 57.097% | Wgt Acc: 48.996% | Dur: 90.20s
I - Confusion Matrix: [row->prediction - col->label]
[[293.  10.  23.  96.  77.]
 [  6. 145.  48.  31.  55.]
 [  3.  21.  96.   6.  36.]
 [110.  31.  28. 265.  84.]
 [123. 163. 197. 176. 963.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.085 | Acc: 97.625% | Wgt Acc: 97.415%
	I - Batch: 100 | Loss: 0.062 | Acc: 98.375% | Wgt Acc: 98.197%
	I - Batch: 150 | Loss: 0.056 | Acc: 98.542% | Wgt Acc: 98.462%
	I - Batch: 200 | Loss: 0.049 | Acc: 98.812% | Wgt Acc: 98.754%
	I - Batch: 250 | Loss: 0.048 | Acc: 98.775% | Wgt Acc: 98.734%
	I - Batch: 300 | Loss: 0.046 | Acc: 98.896% | Wgt Acc: 98.829%
	I - Batch: 350 | Loss: 0.044 | Acc: 98.929% | Wgt Acc: 98.870%
	I - Batch: 400 | Loss: 0.047 | Acc: 98.781% | Wgt Acc: 98.748%
	I - Batch: 450 | Loss: 0.050 | Acc: 98.639% | Wgt Acc: 98.630%
	I - Batch: 500 | Loss: 0.052 | Acc: 98.588% | Wgt Acc: 98.550%
	I - Batch: 550 | Loss: 0.051 | Acc: 98.636% | Wgt Acc: 98.600%
	I - Batch: 600 | Loss: 0.049 | Acc: 98.677% | Wgt Acc: 98.655%
	I - Batch: 650 | Loss: 0.049 | Acc: 98.712% | Wgt Acc: 98.651%
	I - Batch: 700 | Loss: 0.048 | Acc: 98.723% | Wgt Acc: 98.652%
	I - Batch: 750 | Loss: 0.051 | Acc: 98.658% | Wgt Acc: 98.571%
	I - Batch: 800 | Loss: 0.052 | Acc: 98.594% | Wgt Acc: 98.525%
	I - Batch: 850 | Loss: 0.051 | Acc: 98.610% | Wgt Acc: 98.551%
I - num batch: 876
I - Train -- Loss: 0.052 | Acc: 98.608% | Wgt Acc: 98.547% | LR: 1.250000e-04 | Dur: 539.63s
I - Confusion Matrix: [row->prediction - col->label]
[[1863.    1.    0.   11.   26.]
 [   1.  908.    2.    5.   11.]
 [   0.    7. 1314.    0.   30.]
 [  11.    6.    0. 1898.   37.]
 [  11.    5.   19.   12. 7826.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.466 | Acc: 47.125% | Wgt Acc: 47.023%
	I - Batch: 100 | Loss: 2.179 | Acc: 55.062% | Wgt Acc: 51.193%
	I - Batch: 150 | Loss: 2.105 | Acc: 57.000% | Wgt Acc: 52.251%
I - num batch: 193
I - Val -- Loss: 2.123 | Acc: 57.097% | Wgt Acc: 51.930% | Dur: 91.40s
I - Confusion Matrix: [row->prediction - col->label]
[[306.   8.  24.  85.  62.]
 [ 11. 184.  51.  49.  92.]
 [ 11.  58. 163.  28. 111.]
 [ 84.  26.  28. 233.  74.]
 [123.  94. 126. 179. 876.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.042 | Acc: 98.625% | Wgt Acc: 98.969%
	I - Batch: 100 | Loss: 0.042 | Acc: 98.812% | Wgt Acc: 98.940%
	I - Batch: 150 | Loss: 0.040 | Acc: 98.958% | Wgt Acc: 99.105%
	I - Batch: 200 | Loss: 0.034 | Acc: 99.188% | Wgt Acc: 99.312%
	I - Batch: 250 | Loss: 0.031 | Acc: 99.275% | Wgt Acc: 99.354%
	I - Batch: 300 | Loss: 0.032 | Acc: 99.208% | Wgt Acc: 99.308%
	I - Batch: 350 | Loss: 0.032 | Acc: 99.232% | Wgt Acc: 99.326%
	I - Batch: 400 | Loss: 0.031 | Acc: 99.234% | Wgt Acc: 99.357%
	I - Batch: 450 | Loss: 0.033 | Acc: 99.208% | Wgt Acc: 99.315%
	I - Batch: 500 | Loss: 0.032 | Acc: 99.213% | Wgt Acc: 99.343%
	I - Batch: 550 | Loss: 0.032 | Acc: 99.193% | Wgt Acc: 99.321%
	I - Batch: 600 | Loss: 0.031 | Acc: 99.240% | Wgt Acc: 99.356%
	I - Batch: 650 | Loss: 0.031 | Acc: 99.260% | Wgt Acc: 99.362%
	I - Batch: 700 | Loss: 0.030 | Acc: 99.295% | Wgt Acc: 99.398%
	I - Batch: 750 | Loss: 0.029 | Acc: 99.325% | Wgt Acc: 99.410%
	I - Batch: 800 | Loss: 0.030 | Acc: 99.305% | Wgt Acc: 99.390%
	I - Batch: 850 | Loss: 0.031 | Acc: 99.279% | Wgt Acc: 99.363%
I - num batch: 876
I - Train -- Loss: 0.031 | Acc: 99.286% | Wgt Acc: 99.366% | LR: 1.250000e-04 | Dur: 539.04s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    0.    0.   28.]
 [   0.  924.    2.    1.    4.]
 [   0.    2. 1328.    0.   16.]
 [   2.    0.    0. 1918.   19.]
 [  13.    1.    5.    7. 7863.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.476 | Acc: 34.250% | Wgt Acc: 33.747%
	I - Batch: 100 | Loss: 2.821 | Acc: 50.438% | Wgt Acc: 41.902%
	I - Batch: 150 | Loss: 2.630 | Acc: 55.625% | Wgt Acc: 45.030%
I - num batch: 193
I - Val -- Loss: 2.602 | Acc: 57.259% | Wgt Acc: 46.158% | Dur: 91.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 200.    4.   12.   44.   23.]
 [   5.  109.   23.   27.   18.]
 [   9.   53.  127.   18.   40.]
 [ 114.   21.   25.  253.   56.]
 [ 207.  183.  205.  232. 1078.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 98.750% | Wgt Acc: 98.930%
	I - Batch: 100 | Loss: 0.042 | Acc: 98.812% | Wgt Acc: 98.937%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.083% | Wgt Acc: 99.215%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.156% | Wgt Acc: 99.282%
	I - Batch: 250 | Loss: 0.035 | Acc: 99.075% | Wgt Acc: 99.186%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.062% | Wgt Acc: 99.174%
	I - Batch: 350 | Loss: 0.038 | Acc: 98.964% | Wgt Acc: 99.028%
	I - Batch: 400 | Loss: 0.036 | Acc: 99.062% | Wgt Acc: 99.120%
	I - Batch: 450 | Loss: 0.036 | Acc: 99.083% | Wgt Acc: 99.112%
	I - Batch: 500 | Loss: 0.036 | Acc: 99.125% | Wgt Acc: 99.156%
	I - Batch: 550 | Loss: 0.037 | Acc: 99.091% | Wgt Acc: 99.108%
	I - Batch: 600 | Loss: 0.040 | Acc: 98.969% | Wgt Acc: 98.964%
	I - Batch: 650 | Loss: 0.041 | Acc: 98.894% | Wgt Acc: 98.929%
	I - Batch: 700 | Loss: 0.042 | Acc: 98.884% | Wgt Acc: 98.922%
	I - Batch: 750 | Loss: 0.042 | Acc: 98.867% | Wgt Acc: 98.884%
	I - Batch: 800 | Loss: 0.043 | Acc: 98.797% | Wgt Acc: 98.837%
	I - Batch: 850 | Loss: 0.043 | Acc: 98.809% | Wgt Acc: 98.840%
I - num batch: 876
I - Train -- Loss: 0.042 | Acc: 98.815% | Wgt Acc: 98.843% | LR: 1.250000e-04 | Dur: 543.11s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    1.    5.   25.]
 [   0.  918.    8.    3.    5.]
 [   0.    8. 1313.    0.   40.]
 [   3.    0.    0. 1909.   29.]
 [  16.    1.   13.    9. 7831.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.914 | Acc: 40.500% | Wgt Acc: 39.324%
	I - Batch: 100 | Loss: 2.451 | Acc: 53.438% | Wgt Acc: 45.934%
	I - Batch: 150 | Loss: 2.277 | Acc: 57.875% | Wgt Acc: 49.150%
I - num batch: 193
I - Val -- Loss: 2.266 | Acc: 58.814% | Wgt Acc: 49.505% | Dur: 92.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 302.   11.   25.   93.   52.]
 [   2.   97.   18.    9.   11.]
 [   6.   44.  123.   13.   47.]
 [  86.   47.   33.  277.   89.]
 [ 139.  171.  193.  182. 1016.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.000% | Wgt Acc: 98.795%
	I - Batch: 100 | Loss: 0.044 | Acc: 98.938% | Wgt Acc: 99.075%
	I - Batch: 150 | Loss: 0.044 | Acc: 98.792% | Wgt Acc: 98.880%
	I - Batch: 200 | Loss: 0.049 | Acc: 98.594% | Wgt Acc: 98.592%
	I - Batch: 250 | Loss: 0.052 | Acc: 98.550% | Wgt Acc: 98.474%
	I - Batch: 300 | Loss: 0.050 | Acc: 98.583% | Wgt Acc: 98.506%
	I - Batch: 350 | Loss: 0.052 | Acc: 98.446% | Wgt Acc: 98.357%
	I - Batch: 400 | Loss: 0.055 | Acc: 98.375% | Wgt Acc: 98.319%
	I - Batch: 450 | Loss: 0.053 | Acc: 98.417% | Wgt Acc: 98.384%
	I - Batch: 500 | Loss: 0.055 | Acc: 98.375% | Wgt Acc: 98.331%
	I - Batch: 550 | Loss: 0.055 | Acc: 98.386% | Wgt Acc: 98.351%
	I - Batch: 600 | Loss: 0.054 | Acc: 98.396% | Wgt Acc: 98.396%
	I - Batch: 650 | Loss: 0.053 | Acc: 98.433% | Wgt Acc: 98.425%
	I - Batch: 700 | Loss: 0.051 | Acc: 98.500% | Wgt Acc: 98.505%
	I - Batch: 750 | Loss: 0.050 | Acc: 98.558% | Wgt Acc: 98.574%
	I - Batch: 800 | Loss: 0.049 | Acc: 98.570% | Wgt Acc: 98.594%
	I - Batch: 850 | Loss: 0.048 | Acc: 98.603% | Wgt Acc: 98.641%
I - num batch: 876
I - Train -- Loss: 0.047 | Acc: 98.636% | Wgt Acc: 98.669% | LR: 1.250000e-04 | Dur: 544.78s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    0.    5.   37.]
 [   0.  911.   11.    1.   10.]
 [   0.    7. 1310.    0.   41.]
 [   7.    1.    0. 1911.   28.]
 [  12.    8.   14.    9. 7814.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.126 | Acc: 38.000% | Wgt Acc: 37.547%
	I - Batch: 100 | Loss: 2.637 | Acc: 51.125% | Wgt Acc: 43.739%
	I - Batch: 150 | Loss: 2.451 | Acc: 55.708% | Wgt Acc: 46.629%
I - num batch: 193
I - Val -- Loss: 2.442 | Acc: 57.129% | Wgt Acc: 47.382% | Dur: 91.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 263.    3.   23.   72.   31.]
 [   2.  108.   19.   20.   39.]
 [   8.   67.  148.   18.   71.]
 [  74.   23.   22.  217.   47.]
 [ 188.  169.  180.  247. 1027.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 99.500% | Wgt Acc: 99.439%
	I - Batch: 100 | Loss: 0.025 | Acc: 99.375% | Wgt Acc: 99.375%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.458% | Wgt Acc: 99.511%
	I - Batch: 200 | Loss: 0.021 | Acc: 99.531% | Wgt Acc: 99.568%
	I - Batch: 250 | Loss: 0.022 | Acc: 99.475% | Wgt Acc: 99.518%
	I - Batch: 300 | Loss: 0.024 | Acc: 99.458% | Wgt Acc: 99.498%
	I - Batch: 350 | Loss: 0.025 | Acc: 99.446% | Wgt Acc: 99.496%
	I - Batch: 400 | Loss: 0.027 | Acc: 99.328% | Wgt Acc: 99.375%
	I - Batch: 450 | Loss: 0.027 | Acc: 99.319% | Wgt Acc: 99.356%
	I - Batch: 500 | Loss: 0.027 | Acc: 99.338% | Wgt Acc: 99.372%
	I - Batch: 550 | Loss: 0.027 | Acc: 99.352% | Wgt Acc: 99.379%
	I - Batch: 600 | Loss: 0.028 | Acc: 99.323% | Wgt Acc: 99.363%
	I - Batch: 650 | Loss: 0.028 | Acc: 99.308% | Wgt Acc: 99.357%
	I - Batch: 700 | Loss: 0.028 | Acc: 99.312% | Wgt Acc: 99.359%
	I - Batch: 750 | Loss: 0.027 | Acc: 99.333% | Wgt Acc: 99.367%
	I - Batch: 800 | Loss: 0.030 | Acc: 99.273% | Wgt Acc: 99.272%
	I - Batch: 850 | Loss: 0.029 | Acc: 99.279% | Wgt Acc: 99.279%
I - num batch: 876
I - Train -- Loss: 0.031 | Acc: 99.215% | Wgt Acc: 99.224% | LR: 1.250000e-04 | Dur: 536.80s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    0.    0.   20.]
 [   1.  919.    3.    0.    4.]
 [   0.    5. 1320.    0.   23.]
 [   1.    1.    0. 1919.   18.]
 [  13.    2.   12.    7. 7865.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.761 | Acc: 32.625% | Wgt Acc: 31.489%
	I - Batch: 100 | Loss: 3.043 | Acc: 48.812% | Wgt Acc: 39.716%
	I - Batch: 150 | Loss: 2.772 | Acc: 54.042% | Wgt Acc: 43.065%
I - num batch: 193
I - Val -- Loss: 2.787 | Acc: 55.250% | Wgt Acc: 43.565% | Dur: 90.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 315.    9.   26.  149.   43.]
 [   2.   32.    0.    4.    1.]
 [  12.  130.  179.   24.   88.]
 [  16.   10.    4.  115.   19.]
 [ 190.  189.  183.  282. 1064.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.096 | Acc: 97.125% | Wgt Acc: 96.976%
	I - Batch: 100 | Loss: 0.087 | Acc: 97.375% | Wgt Acc: 97.528%
	I - Batch: 150 | Loss: 0.083 | Acc: 97.583% | Wgt Acc: 97.600%
	I - Batch: 200 | Loss: 0.072 | Acc: 97.875% | Wgt Acc: 97.880%
	I - Batch: 250 | Loss: 0.067 | Acc: 98.050% | Wgt Acc: 98.056%
	I - Batch: 300 | Loss: 0.063 | Acc: 98.167% | Wgt Acc: 98.205%
	I - Batch: 350 | Loss: 0.059 | Acc: 98.375% | Wgt Acc: 98.395%
	I - Batch: 400 | Loss: 0.056 | Acc: 98.484% | Wgt Acc: 98.518%
	I - Batch: 450 | Loss: 0.055 | Acc: 98.486% | Wgt Acc: 98.494%
	I - Batch: 500 | Loss: 0.056 | Acc: 98.500% | Wgt Acc: 98.485%
	I - Batch: 550 | Loss: 0.054 | Acc: 98.557% | Wgt Acc: 98.533%
	I - Batch: 600 | Loss: 0.052 | Acc: 98.604% | Wgt Acc: 98.583%
	I - Batch: 650 | Loss: 0.050 | Acc: 98.663% | Wgt Acc: 98.640%
	I - Batch: 700 | Loss: 0.049 | Acc: 98.696% | Wgt Acc: 98.675%
	I - Batch: 750 | Loss: 0.049 | Acc: 98.725% | Wgt Acc: 98.683%
	I - Batch: 800 | Loss: 0.049 | Acc: 98.703% | Wgt Acc: 98.654%
	I - Batch: 850 | Loss: 0.050 | Acc: 98.662% | Wgt Acc: 98.622%
I - num batch: 876
I - Train -- Loss: 0.049 | Acc: 98.679% | Wgt Acc: 98.632% | LR: 1.250000e-04 | Dur: 540.51s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    2.    0.    3.   33.]
 [   0.  907.   12.    6.   14.]
 [   0.    9. 1311.    0.   23.]
 [   4.    4.    0. 1902.   32.]
 [  11.    5.   12.   15. 7828.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.648 | Acc: 44.000% | Wgt Acc: 43.327%
	I - Batch: 100 | Loss: 2.230 | Acc: 55.312% | Wgt Acc: 49.454%
	I - Batch: 150 | Loss: 2.076 | Acc: 59.083% | Wgt Acc: 52.275%
I - num batch: 193
I - Val -- Loss: 2.094 | Acc: 59.268% | Wgt Acc: 51.761% | Dur: 91.82s
I - Confusion Matrix: [row->prediction - col->label]
[[290.   8.  18.  81.  40.]
 [  6. 136.  28.  24.  31.]
 [ 10.  52. 165.  17.  97.]
 [114.  25.  21. 265.  74.]
 [115. 149. 160. 187. 973.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.125% | Wgt Acc: 99.265%
	I - Batch: 100 | Loss: 0.039 | Acc: 98.812% | Wgt Acc: 98.729%
	I - Batch: 150 | Loss: 0.041 | Acc: 98.708% | Wgt Acc: 98.725%
	I - Batch: 200 | Loss: 0.037 | Acc: 98.844% | Wgt Acc: 98.911%
	I - Batch: 250 | Loss: 0.038 | Acc: 98.900% | Wgt Acc: 98.926%
	I - Batch: 300 | Loss: 0.041 | Acc: 98.771% | Wgt Acc: 98.783%
	I - Batch: 350 | Loss: 0.042 | Acc: 98.768% | Wgt Acc: 98.782%
	I - Batch: 400 | Loss: 0.042 | Acc: 98.812% | Wgt Acc: 98.800%
	I - Batch: 450 | Loss: 0.043 | Acc: 98.778% | Wgt Acc: 98.769%
	I - Batch: 500 | Loss: 0.043 | Acc: 98.775% | Wgt Acc: 98.808%
	I - Batch: 550 | Loss: 0.043 | Acc: 98.784% | Wgt Acc: 98.812%
	I - Batch: 600 | Loss: 0.043 | Acc: 98.708% | Wgt Acc: 98.760%
	I - Batch: 650 | Loss: 0.043 | Acc: 98.740% | Wgt Acc: 98.800%
	I - Batch: 700 | Loss: 0.041 | Acc: 98.812% | Wgt Acc: 98.873%
	I - Batch: 750 | Loss: 0.040 | Acc: 98.875% | Wgt Acc: 98.930%
	I - Batch: 800 | Loss: 0.040 | Acc: 98.883% | Wgt Acc: 98.913%
	I - Batch: 850 | Loss: 0.042 | Acc: 98.809% | Wgt Acc: 98.853%
I - num batch: 876
I - Train -- Loss: 0.042 | Acc: 98.793% | Wgt Acc: 98.810% | LR: 1.250000e-04 | Dur: 540.91s
I - Confusion Matrix: [row->prediction - col->label]
[[1863.    1.    0.    3.   34.]
 [   2.  915.    5.    1.   10.]
 [   0.    5. 1317.    0.   38.]
 [   7.    1.    0. 1909.   17.]
 [  14.    5.   13.   13. 7831.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.932 | Acc: 41.875% | Wgt Acc: 40.762%
	I - Batch: 100 | Loss: 2.405 | Acc: 54.000% | Wgt Acc: 46.996%
	I - Batch: 150 | Loss: 2.245 | Acc: 58.125% | Wgt Acc: 49.893%
I - num batch: 193
I - Val -- Loss: 2.244 | Acc: 58.458% | Wgt Acc: 49.722% | Dur: 91.19s
I - Confusion Matrix: [row->prediction - col->label]
[[308.  10.  15.  95.  41.]
 [  4. 122.  34.  19.  47.]
 [  4.  30.  92.  11.  32.]
 [ 83.  43.  38. 290. 103.]
 [136. 165. 213. 159. 992.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.064 | Acc: 98.125% | Wgt Acc: 98.527%
	I - Batch: 100 | Loss: 0.056 | Acc: 98.312% | Wgt Acc: 98.495%
	I - Batch: 150 | Loss: 0.049 | Acc: 98.583% | Wgt Acc: 98.778%
	I - Batch: 200 | Loss: 0.045 | Acc: 98.781% | Wgt Acc: 98.924%
	I - Batch: 250 | Loss: 0.045 | Acc: 98.825% | Wgt Acc: 98.942%
	I - Batch: 300 | Loss: 0.042 | Acc: 98.938% | Wgt Acc: 99.050%
	I - Batch: 350 | Loss: 0.040 | Acc: 98.964% | Wgt Acc: 99.032%
	I - Batch: 400 | Loss: 0.042 | Acc: 98.906% | Wgt Acc: 98.905%
	I - Batch: 450 | Loss: 0.046 | Acc: 98.778% | Wgt Acc: 98.763%
	I - Batch: 500 | Loss: 0.046 | Acc: 98.737% | Wgt Acc: 98.729%
	I - Batch: 550 | Loss: 0.046 | Acc: 98.739% | Wgt Acc: 98.756%
	I - Batch: 600 | Loss: 0.046 | Acc: 98.729% | Wgt Acc: 98.766%
	I - Batch: 650 | Loss: 0.047 | Acc: 98.702% | Wgt Acc: 98.724%
	I - Batch: 700 | Loss: 0.048 | Acc: 98.696% | Wgt Acc: 98.723%
	I - Batch: 750 | Loss: 0.048 | Acc: 98.725% | Wgt Acc: 98.744%
	I - Batch: 800 | Loss: 0.047 | Acc: 98.758% | Wgt Acc: 98.789%
	I - Batch: 850 | Loss: 0.047 | Acc: 98.757% | Wgt Acc: 98.771%
I - num batch: 876
I - Train -- Loss: 0.047 | Acc: 98.765% | Wgt Acc: 98.778% | LR: 1.250000e-04 | Dur: 542.08s
I - Confusion Matrix: [row->prediction - col->label]
[[1867.    0.    1.    3.   31.]
 [   1.  913.   10.    2.   14.]
 [   0.    6. 1310.    0.   33.]
 [   5.    4.    0. 1914.   25.]
 [  13.    4.   14.    7. 7827.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.881 | Acc: 40.500% | Wgt Acc: 40.013%
	I - Batch: 100 | Loss: 2.394 | Acc: 53.000% | Wgt Acc: 46.345%
	I - Batch: 150 | Loss: 2.207 | Acc: 56.792% | Wgt Acc: 48.861%
I - num batch: 193
I - Val -- Loss: 2.250 | Acc: 57.259% | Wgt Acc: 48.850% | Dur: 92.10s
I - Confusion Matrix: [row->prediction - col->label]
[[249.   7.  18.  68.  32.]
 [  6. 132.  23.  23.  39.]
 [ 11.  56. 144.  21.  99.]
 [ 86.  31.  23. 259.  62.]
 [183. 144. 184. 203. 983.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 99.625% | Wgt Acc: 99.670%
	I - Batch: 100 | Loss: 0.029 | Acc: 99.438% | Wgt Acc: 99.507%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.542% | Wgt Acc: 99.624%
	I - Batch: 200 | Loss: 0.029 | Acc: 99.344% | Wgt Acc: 99.384%
	I - Batch: 250 | Loss: 0.027 | Acc: 99.400% | Wgt Acc: 99.436%
	I - Batch: 300 | Loss: 0.026 | Acc: 99.438% | Wgt Acc: 99.471%
	I - Batch: 350 | Loss: 0.027 | Acc: 99.429% | Wgt Acc: 99.460%
	I - Batch: 400 | Loss: 0.026 | Acc: 99.484% | Wgt Acc: 99.519%
	I - Batch: 450 | Loss: 0.025 | Acc: 99.500% | Wgt Acc: 99.521%
	I - Batch: 500 | Loss: 0.026 | Acc: 99.438% | Wgt Acc: 99.454%
	I - Batch: 550 | Loss: 0.025 | Acc: 99.443% | Wgt Acc: 99.443%
	I - Batch: 600 | Loss: 0.027 | Acc: 99.375% | Wgt Acc: 99.383%
	I - Batch: 650 | Loss: 0.029 | Acc: 99.288% | Wgt Acc: 99.317%
	I - Batch: 700 | Loss: 0.029 | Acc: 99.321% | Wgt Acc: 99.343%
	I - Batch: 750 | Loss: 0.029 | Acc: 99.325% | Wgt Acc: 99.345%
	I - Batch: 800 | Loss: 0.029 | Acc: 99.297% | Wgt Acc: 99.323%
	I - Batch: 850 | Loss: 0.030 | Acc: 99.243% | Wgt Acc: 99.273%
I - num batch: 876
I - Train -- Loss: 0.033 | Acc: 99.236% | Wgt Acc: 99.262% | LR: 1.250000e-04 | Dur: 544.71s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    0.    0.    3.   12.]
 [   0.  921.    4.    2.    8.]
 [   0.    2. 1321.    0.   25.]
 [   0.    2.    0. 1914.   20.]
 [  10.    2.   10.    7. 7865.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.036 | Acc: 42.125% | Wgt Acc: 40.658%
	I - Batch: 100 | Loss: 2.525 | Acc: 54.188% | Wgt Acc: 46.736%
	I - Batch: 150 | Loss: 2.307 | Acc: 59.167% | Wgt Acc: 50.532%
I - num batch: 193
I - Val -- Loss: 2.305 | Acc: 59.559% | Wgt Acc: 50.433% | Dur: 92.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 342.   10.   30.  112.   71.]
 [   1.   98.   22.    7.   22.]
 [   1.   32.  104.    8.   31.]
 [  86.   50.   32.  282.   79.]
 [ 105.  180.  204.  165. 1012.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 97.500% | Wgt Acc: 98.086%
	I - Batch: 100 | Loss: 0.047 | Acc: 98.000% | Wgt Acc: 98.501%
	I - Batch: 150 | Loss: 0.051 | Acc: 98.083% | Wgt Acc: 98.385%
	I - Batch: 200 | Loss: 0.045 | Acc: 98.406% | Wgt Acc: 98.648%
	I - Batch: 250 | Loss: 0.043 | Acc: 98.600% | Wgt Acc: 98.781%
	I - Batch: 300 | Loss: 0.041 | Acc: 98.667% | Wgt Acc: 98.814%
	I - Batch: 350 | Loss: 0.040 | Acc: 98.696% | Wgt Acc: 98.800%
	I - Batch: 400 | Loss: 0.041 | Acc: 98.656% | Wgt Acc: 98.777%
	I - Batch: 450 | Loss: 0.042 | Acc: 98.694% | Wgt Acc: 98.775%
	I - Batch: 500 | Loss: 0.044 | Acc: 98.638% | Wgt Acc: 98.698%
	I - Batch: 550 | Loss: 0.043 | Acc: 98.659% | Wgt Acc: 98.741%
	I - Batch: 600 | Loss: 0.042 | Acc: 98.729% | Wgt Acc: 98.798%
	I - Batch: 650 | Loss: 0.043 | Acc: 98.673% | Wgt Acc: 98.736%
	I - Batch: 700 | Loss: 0.043 | Acc: 98.696% | Wgt Acc: 98.734%
	I - Batch: 750 | Loss: 0.045 | Acc: 98.600% | Wgt Acc: 98.625%
	I - Batch: 800 | Loss: 0.048 | Acc: 98.523% | Wgt Acc: 98.538%
	I - Batch: 850 | Loss: 0.047 | Acc: 98.544% | Wgt Acc: 98.555%
I - num batch: 876
I - Train -- Loss: 0.047 | Acc: 98.579% | Wgt Acc: 98.583% | LR: 1.250000e-04 | Dur: 545.57s
I - Confusion Matrix: [row->prediction - col->label]
[[1866.    0.    0.    5.   33.]
 [   0.  913.    7.    6.   11.]
 [   0.    8. 1310.    1.   40.]
 [   5.    3.    2. 1901.   31.]
 [  15.    3.   16.   13. 7815.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.949 | Acc: 41.750% | Wgt Acc: 41.293%
	I - Batch: 100 | Loss: 2.502 | Acc: 53.688% | Wgt Acc: 46.533%
	I - Batch: 150 | Loss: 2.322 | Acc: 58.042% | Wgt Acc: 49.489%
I - num batch: 193
I - Val -- Loss: 2.324 | Acc: 58.587% | Wgt Acc: 49.534% | Dur: 90.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 297.   11.   21.   82.   42.]
 [   8.  139.   40.   28.   40.]
 [  13.   34.  120.   16.   63.]
 [  68.   32.   16.  233.   51.]
 [ 149.  154.  195.  215. 1019.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.025 | Acc: 99.250% | Wgt Acc: 99.464%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.250% | Wgt Acc: 99.408%
	I - Batch: 150 | Loss: 0.030 | Acc: 99.125% | Wgt Acc: 99.216%
	I - Batch: 200 | Loss: 0.033 | Acc: 99.125% | Wgt Acc: 99.152%
	I - Batch: 250 | Loss: 0.033 | Acc: 99.175% | Wgt Acc: 99.173%
	I - Batch: 300 | Loss: 0.032 | Acc: 99.167% | Wgt Acc: 99.184%
	I - Batch: 350 | Loss: 0.032 | Acc: 99.161% | Wgt Acc: 99.192%
	I - Batch: 400 | Loss: 0.034 | Acc: 99.172% | Wgt Acc: 99.175%
	I - Batch: 450 | Loss: 0.036 | Acc: 99.083% | Wgt Acc: 99.112%
	I - Batch: 500 | Loss: 0.034 | Acc: 99.138% | Wgt Acc: 99.180%
	I - Batch: 550 | Loss: 0.033 | Acc: 99.148% | Wgt Acc: 99.194%
	I - Batch: 600 | Loss: 0.033 | Acc: 99.156% | Wgt Acc: 99.205%
	I - Batch: 650 | Loss: 0.033 | Acc: 99.163% | Wgt Acc: 99.204%
	I - Batch: 700 | Loss: 0.032 | Acc: 99.161% | Wgt Acc: 99.226%
	I - Batch: 750 | Loss: 0.032 | Acc: 99.200% | Wgt Acc: 99.252%
	I - Batch: 800 | Loss: 0.032 | Acc: 99.195% | Wgt Acc: 99.242%
	I - Batch: 850 | Loss: 0.032 | Acc: 99.213% | Wgt Acc: 99.257%
I - num batch: 876
I - Train -- Loss: 0.032 | Acc: 99.207% | Wgt Acc: 99.249% | LR: 1.250000e-04 | Dur: 543.60s
I - Confusion Matrix: [row->prediction - col->label]
[[1875.    0.    0.    2.   19.]
 [   1.  923.    2.    2.    7.]
 [   0.    2. 1320.    0.   22.]
 [   4.    1.    0. 1914.   21.]
 [   6.    1.   13.    8. 7861.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.127 | Acc: 41.625% | Wgt Acc: 40.877%
	I - Batch: 100 | Loss: 2.567 | Acc: 54.250% | Wgt Acc: 46.671%
	I - Batch: 150 | Loss: 2.354 | Acc: 58.833% | Wgt Acc: 49.914%
I - num batch: 193
I - Val -- Loss: 2.341 | Acc: 60.110% | Wgt Acc: 50.737% | Dur: 91.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 320.    9.   26.  104.   49.]
 [   4.  124.   19.   26.   27.]
 [   8.   43.  133.   18.   45.]
 [  59.   25.   19.  234.   50.]
 [ 144.  169.  195.  192. 1044.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 99.812% | Wgt Acc: 99.838%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.792% | Wgt Acc: 99.807%
	I - Batch: 200 | Loss: 0.018 | Acc: 99.812% | Wgt Acc: 99.838%
	I - Batch: 250 | Loss: 0.019 | Acc: 99.775% | Wgt Acc: 99.774%
	I - Batch: 300 | Loss: 0.018 | Acc: 99.750% | Wgt Acc: 99.753%
	I - Batch: 350 | Loss: 0.019 | Acc: 99.732% | Wgt Acc: 99.723%
	I - Batch: 400 | Loss: 0.020 | Acc: 99.688% | Wgt Acc: 99.682%
	I - Batch: 450 | Loss: 0.021 | Acc: 99.597% | Wgt Acc: 99.574%
	I - Batch: 500 | Loss: 0.021 | Acc: 99.575% | Wgt Acc: 99.569%
	I - Batch: 550 | Loss: 0.022 | Acc: 99.591% | Wgt Acc: 99.570%
	I - Batch: 600 | Loss: 0.025 | Acc: 99.479% | Wgt Acc: 99.470%
	I - Batch: 650 | Loss: 0.028 | Acc: 99.404% | Wgt Acc: 99.395%
	I - Batch: 700 | Loss: 0.028 | Acc: 99.384% | Wgt Acc: 99.392%
	I - Batch: 750 | Loss: 0.030 | Acc: 99.333% | Wgt Acc: 99.323%
	I - Batch: 800 | Loss: 0.032 | Acc: 99.273% | Wgt Acc: 99.277%
	I - Batch: 850 | Loss: 0.032 | Acc: 99.265% | Wgt Acc: 99.274%
I - num batch: 876
I - Train -- Loss: 0.033 | Acc: 99.243% | Wgt Acc: 99.242% | LR: 1.250000e-04 | Dur: 540.80s
I - Confusion Matrix: [row->prediction - col->label]
[[1873.    0.    0.    3.   16.]
 [   0.  918.    3.    2.    6.]
 [   1.    2. 1323.    0.   24.]
 [   5.    5.    0. 1915.   15.]
 [   7.    2.    9.    6. 7869.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.509 | Acc: 49.375% | Wgt Acc: 49.029%
	I - Batch: 100 | Loss: 2.169 | Acc: 55.938% | Wgt Acc: 52.110%
	I - Batch: 150 | Loss: 2.059 | Acc: 58.250% | Wgt Acc: 53.657%
I - num batch: 193
I - Val -- Loss: 2.082 | Acc: 58.490% | Wgt Acc: 53.374% | Dur: 91.53s
I - Confusion Matrix: [row->prediction - col->label]
[[360.  14.  28. 146.  75.]
 [ 13. 204.  78.  39.  82.]
 [  4.  30. 131.  20.  78.]
 [ 61.  28.  32. 222.  92.]
 [ 97.  94. 123. 147. 888.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.375% | Wgt Acc: 99.540%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.375% | Wgt Acc: 99.464%
	I - Batch: 150 | Loss: 0.027 | Acc: 99.417% | Wgt Acc: 99.434%
	I - Batch: 200 | Loss: 0.028 | Acc: 99.406% | Wgt Acc: 99.428%
	I - Batch: 250 | Loss: 0.025 | Acc: 99.450% | Wgt Acc: 99.501%
	I - Batch: 300 | Loss: 0.026 | Acc: 99.458% | Wgt Acc: 99.512%
	I - Batch: 350 | Loss: 0.027 | Acc: 99.429% | Wgt Acc: 99.437%
	I - Batch: 400 | Loss: 0.026 | Acc: 99.469% | Wgt Acc: 99.486%
	I - Batch: 450 | Loss: 0.026 | Acc: 99.431% | Wgt Acc: 99.460%
	I - Batch: 500 | Loss: 0.027 | Acc: 99.425% | Wgt Acc: 99.430%
	I - Batch: 550 | Loss: 0.027 | Acc: 99.420% | Wgt Acc: 99.439%
	I - Batch: 600 | Loss: 0.027 | Acc: 99.438% | Wgt Acc: 99.449%
	I - Batch: 650 | Loss: 0.027 | Acc: 99.433% | Wgt Acc: 99.432%
	I - Batch: 700 | Loss: 0.027 | Acc: 99.438% | Wgt Acc: 99.452%
	I - Batch: 750 | Loss: 0.026 | Acc: 99.450% | Wgt Acc: 99.460%
	I - Batch: 800 | Loss: 0.026 | Acc: 99.430% | Wgt Acc: 99.456%
	I - Batch: 850 | Loss: 0.026 | Acc: 99.449% | Wgt Acc: 99.472%
I - num batch: 876
I - Train -- Loss: 0.026 | Acc: 99.450% | Wgt Acc: 99.473% | LR: 1.250000e-04 | Dur: 537.68s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    1.    0.    4.   16.]
 [   0.  922.    1.    4.    3.]
 [   0.    1. 1332.    0.   15.]
 [   3.    2.    0. 1913.   12.]
 [   7.    1.    2.    5. 7884.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.090 | Acc: 39.375% | Wgt Acc: 38.438%
	I - Batch: 100 | Loss: 2.568 | Acc: 51.375% | Wgt Acc: 43.726%
	I - Batch: 150 | Loss: 2.382 | Acc: 56.458% | Wgt Acc: 47.214%
I - num batch: 193
I - Val -- Loss: 2.345 | Acc: 58.393% | Wgt Acc: 48.656% | Dur: 89.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 261.   11.   21.   82.   48.]
 [   0.  107.   30.    2.   18.]
 [   9.   35.  115.   11.   36.]
 [ 104.   60.   31.  288.   82.]
 [ 161.  157.  195.  191. 1031.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 99.500% | Wgt Acc: 99.487%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.375% | Wgt Acc: 99.388%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.250% | Wgt Acc: 99.229%
	I - Batch: 200 | Loss: 0.031 | Acc: 99.250% | Wgt Acc: 99.272%
	I - Batch: 250 | Loss: 0.033 | Acc: 99.175% | Wgt Acc: 99.190%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.104% | Wgt Acc: 99.079%
	I - Batch: 350 | Loss: 0.034 | Acc: 99.125% | Wgt Acc: 99.113%
	I - Batch: 400 | Loss: 0.033 | Acc: 99.172% | Wgt Acc: 99.172%
	I - Batch: 450 | Loss: 0.032 | Acc: 99.222% | Wgt Acc: 99.223%
	I - Batch: 500 | Loss: 0.033 | Acc: 99.200% | Wgt Acc: 99.221%
	I - Batch: 550 | Loss: 0.031 | Acc: 99.239% | Wgt Acc: 99.273%
	I - Batch: 600 | Loss: 0.030 | Acc: 99.281% | Wgt Acc: 99.312%
	I - Batch: 650 | Loss: 0.028 | Acc: 99.327% | Wgt Acc: 99.358%
	I - Batch: 700 | Loss: 0.028 | Acc: 99.357% | Wgt Acc: 99.386%
	I - Batch: 750 | Loss: 0.027 | Acc: 99.383% | Wgt Acc: 99.417%
	I - Batch: 800 | Loss: 0.026 | Acc: 99.406% | Wgt Acc: 99.437%
	I - Batch: 850 | Loss: 0.026 | Acc: 99.412% | Wgt Acc: 99.446%
I - num batch: 876
I - Train -- Loss: 0.026 | Acc: 99.422% | Wgt Acc: 99.458% | LR: 1.250000e-04 | Dur: 534.88s
I - Confusion Matrix: [row->prediction - col->label]
[[1879.    0.    0.    0.   13.]
 [   0.  921.    2.    3.    5.]
 [   0.    2. 1326.    1.   21.]
 [   1.    2.    0. 1919.   13.]
 [   6.    2.    7.    3. 7878.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.831 | Acc: 45.500% | Wgt Acc: 44.529%
	I - Batch: 100 | Loss: 2.336 | Acc: 55.750% | Wgt Acc: 49.057%
	I - Batch: 150 | Loss: 2.203 | Acc: 58.833% | Wgt Acc: 51.194%
I - num batch: 193
I - Val -- Loss: 2.205 | Acc: 59.462% | Wgt Acc: 51.567% | Dur: 90.72s
I - Confusion Matrix: [row->prediction - col->label]
[[314.  14.  26. 104.  56.]
 [  0. 112.  20.  10.  29.]
 [  8.  45. 138.  14.  46.]
 [ 86.  47.  45. 296. 109.]
 [127. 152. 163. 150. 975.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 99.917% | Wgt Acc: 99.875%
	I - Batch: 200 | Loss: 0.014 | Acc: 99.906% | Wgt Acc: 99.889%
	I - Batch: 250 | Loss: 0.015 | Acc: 99.850% | Wgt Acc: 99.846%
	I - Batch: 300 | Loss: 0.017 | Acc: 99.750% | Wgt Acc: 99.782%
	I - Batch: 350 | Loss: 0.016 | Acc: 99.714% | Wgt Acc: 99.737%
	I - Batch: 400 | Loss: 0.016 | Acc: 99.719% | Wgt Acc: 99.738%
	I - Batch: 450 | Loss: 0.016 | Acc: 99.708% | Wgt Acc: 99.743%
	I - Batch: 500 | Loss: 0.016 | Acc: 99.725% | Wgt Acc: 99.750%
	I - Batch: 550 | Loss: 0.016 | Acc: 99.727% | Wgt Acc: 99.747%
	I - Batch: 600 | Loss: 0.017 | Acc: 99.677% | Wgt Acc: 99.683%
	I - Batch: 650 | Loss: 0.018 | Acc: 99.635% | Wgt Acc: 99.630%
	I - Batch: 700 | Loss: 0.018 | Acc: 99.643% | Wgt Acc: 99.637%
	I - Batch: 750 | Loss: 0.018 | Acc: 99.642% | Wgt Acc: 99.640%
	I - Batch: 800 | Loss: 0.018 | Acc: 99.648% | Wgt Acc: 99.645%
	I - Batch: 850 | Loss: 0.018 | Acc: 99.654% | Wgt Acc: 99.657%
I - num batch: 876
I - Train -- Loss: 0.019 | Acc: 99.643% | Wgt Acc: 99.655% | LR: 1.250000e-04 | Dur: 537.95s
I - Confusion Matrix: [row->prediction - col->label]
[[1880.    0.    0.    1.   12.]
 [   0.  925.    2.    0.    3.]
 [   0.    2. 1329.    0.    6.]
 [   0.    0.    0. 1920.    9.]
 [   6.    0.    4.    5. 7900.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.910 | Acc: 44.625% | Wgt Acc: 43.780%
	I - Batch: 100 | Loss: 2.414 | Acc: 55.375% | Wgt Acc: 49.326%
	I - Batch: 150 | Loss: 2.263 | Acc: 59.125% | Wgt Acc: 52.027%
I - num batch: 193
I - Val -- Loss: 2.244 | Acc: 59.851% | Wgt Acc: 52.442% | Dur: 90.86s
I - Confusion Matrix: [row->prediction - col->label]
[[316.  11.  26. 101.  57.]
 [  4. 141.  27.  16.  33.]
 [ 11.  35. 127.  13.  49.]
 [ 86.  38.  33. 295. 108.]
 [118. 145. 179. 149. 968.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 99.375% | Wgt Acc: 99.034%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.312% | Wgt Acc: 99.140%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.208% | Wgt Acc: 99.149%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.125% | Wgt Acc: 99.042%
	I - Batch: 250 | Loss: 0.030 | Acc: 99.275% | Wgt Acc: 99.217%
	I - Batch: 300 | Loss: 0.031 | Acc: 99.271% | Wgt Acc: 99.256%
	I - Batch: 350 | Loss: 0.028 | Acc: 99.357% | Wgt Acc: 99.340%
	I - Batch: 400 | Loss: 0.026 | Acc: 99.422% | Wgt Acc: 99.400%
	I - Batch: 450 | Loss: 0.025 | Acc: 99.444% | Wgt Acc: 99.428%
	I - Batch: 500 | Loss: 0.025 | Acc: 99.475% | Wgt Acc: 99.459%
	I - Batch: 550 | Loss: 0.025 | Acc: 99.477% | Wgt Acc: 99.473%
	I - Batch: 600 | Loss: 0.024 | Acc: 99.490% | Wgt Acc: 99.488%
	I - Batch: 650 | Loss: 0.024 | Acc: 99.510% | Wgt Acc: 99.503%
	I - Batch: 700 | Loss: 0.023 | Acc: 99.536% | Wgt Acc: 99.522%
	I - Batch: 750 | Loss: 0.023 | Acc: 99.542% | Wgt Acc: 99.530%
	I - Batch: 800 | Loss: 0.023 | Acc: 99.523% | Wgt Acc: 99.517%
	I - Batch: 850 | Loss: 0.023 | Acc: 99.507% | Wgt Acc: 99.507%
I - num batch: 876
I - Train -- Loss: 0.024 | Acc: 99.493% | Wgt Acc: 99.496% | LR: 1.250000e-04 | Dur: 537.68s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    1.    0.    2.   17.]
 [   0.  921.    1.    1.    6.]
 [   0.    2. 1329.    0.   11.]
 [   2.    1.    0. 1918.    7.]
 [   8.    2.    5.    5. 7889.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.132 | Acc: 40.250% | Wgt Acc: 39.078%
	I - Batch: 100 | Loss: 2.589 | Acc: 53.625% | Wgt Acc: 45.520%
	I - Batch: 150 | Loss: 2.387 | Acc: 58.333% | Wgt Acc: 48.601%
I - num batch: 193
I - Val -- Loss: 2.365 | Acc: 59.819% | Wgt Acc: 49.655% | Dur: 90.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 294.    6.   23.   81.   35.]
 [   0.   94.   19.   16.   13.]
 [   8.   45.  132.    9.   41.]
 [  69.   33.   20.  265.   65.]
 [ 164.  192.  198.  203. 1061.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.219 | Acc: 94.375% | Wgt Acc: 93.956%
	I - Batch: 100 | Loss: 0.159 | Acc: 96.062% | Wgt Acc: 95.710%
	I - Batch: 150 | Loss: 0.120 | Acc: 97.042% | Wgt Acc: 96.822%
	I - Batch: 200 | Loss: 0.106 | Acc: 97.406% | Wgt Acc: 97.230%
	I - Batch: 250 | Loss: 0.092 | Acc: 97.700% | Wgt Acc: 97.626%
	I - Batch: 300 | Loss: 0.091 | Acc: 97.708% | Wgt Acc: 97.626%
	I - Batch: 350 | Loss: 0.082 | Acc: 97.929% | Wgt Acc: 97.851%
	I - Batch: 400 | Loss: 0.075 | Acc: 98.094% | Wgt Acc: 98.066%
	I - Batch: 450 | Loss: 0.071 | Acc: 98.125% | Wgt Acc: 98.137%
	I - Batch: 500 | Loss: 0.067 | Acc: 98.237% | Wgt Acc: 98.257%
	I - Batch: 550 | Loss: 0.064 | Acc: 98.284% | Wgt Acc: 98.309%
	I - Batch: 600 | Loss: 0.061 | Acc: 98.396% | Wgt Acc: 98.413%
	I - Batch: 650 | Loss: 0.059 | Acc: 98.452% | Wgt Acc: 98.475%
	I - Batch: 700 | Loss: 0.059 | Acc: 98.375% | Wgt Acc: 98.416%
	I - Batch: 750 | Loss: 0.060 | Acc: 98.325% | Wgt Acc: 98.349%
	I - Batch: 800 | Loss: 0.060 | Acc: 98.297% | Wgt Acc: 98.331%
	I - Batch: 850 | Loss: 0.059 | Acc: 98.316% | Wgt Acc: 98.354%
I - num batch: 876
I - Train -- Loss: 0.059 | Acc: 98.336% | Wgt Acc: 98.359% | LR: 1.250000e-04 | Dur: 537.24s
I - Confusion Matrix: [row->prediction - col->label]
[[1860.    1.    0.    5.   43.]
 [   1.  905.    6.   11.   21.]
 [   1.    8. 1313.    0.   51.]
 [   2.    5.    0. 1901.   23.]
 [  22.    8.   16.    9. 7792.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.294 | Acc: 40.250% | Wgt Acc: 39.133%
	I - Batch: 100 | Loss: 2.689 | Acc: 53.938% | Wgt Acc: 45.596%
	I - Batch: 150 | Loss: 2.465 | Acc: 58.833% | Wgt Acc: 48.611%
I - num batch: 193
I - Val -- Loss: 2.436 | Acc: 60.110% | Wgt Acc: 49.107% | Dur: 90.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 280.    9.   19.   74.   25.]
 [   1.   96.    7.   10.    6.]
 [   4.   45.  118.    9.   30.]
 [  77.   33.   20.  266.   59.]
 [ 173.  187.  228.  215. 1095.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.062 | Acc: 97.500% | Wgt Acc: 97.798%
	I - Batch: 100 | Loss: 0.054 | Acc: 98.250% | Wgt Acc: 98.183%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.250% | Wgt Acc: 98.298%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.406% | Wgt Acc: 98.394%
	I - Batch: 250 | Loss: 0.055 | Acc: 98.450% | Wgt Acc: 98.370%
	I - Batch: 300 | Loss: 0.057 | Acc: 98.354% | Wgt Acc: 98.318%
	I - Batch: 350 | Loss: 0.056 | Acc: 98.393% | Wgt Acc: 98.361%
	I - Batch: 400 | Loss: 0.054 | Acc: 98.484% | Wgt Acc: 98.429%
	I - Batch: 450 | Loss: 0.054 | Acc: 98.417% | Wgt Acc: 98.401%
	I - Batch: 500 | Loss: 0.053 | Acc: 98.450% | Wgt Acc: 98.420%
	I - Batch: 550 | Loss: 0.052 | Acc: 98.500% | Wgt Acc: 98.466%
	I - Batch: 600 | Loss: 0.051 | Acc: 98.510% | Wgt Acc: 98.471%
	I - Batch: 650 | Loss: 0.051 | Acc: 98.519% | Wgt Acc: 98.495%
	I - Batch: 700 | Loss: 0.051 | Acc: 98.545% | Wgt Acc: 98.534%
	I - Batch: 750 | Loss: 0.050 | Acc: 98.567% | Wgt Acc: 98.574%
	I - Batch: 800 | Loss: 0.050 | Acc: 98.586% | Wgt Acc: 98.579%
	I - Batch: 850 | Loss: 0.051 | Acc: 98.581% | Wgt Acc: 98.549%
I - num batch: 876
I - Train -- Loss: 0.051 | Acc: 98.572% | Wgt Acc: 98.541% | LR: 1.250000e-04 | Dur: 538.16s
I - Confusion Matrix: [row->prediction - col->label]
[[1862.    1.    0.    8.   31.]
 [   2.  914.    6.    5.   14.]
 [   0.    6. 1309.    0.   45.]
 [   7.    1.    2. 1899.   20.]
 [  15.    5.   18.   14. 7820.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.926 | Acc: 44.250% | Wgt Acc: 42.944%
	I - Batch: 100 | Loss: 2.494 | Acc: 54.875% | Wgt Acc: 47.949%
	I - Batch: 150 | Loss: 2.289 | Acc: 59.167% | Wgt Acc: 50.948%
I - num batch: 193
I - Val -- Loss: 2.294 | Acc: 60.434% | Wgt Acc: 51.500% | Dur: 92.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 332.   10.   26.   90.   44.]
 [   1.  110.   20.    4.   17.]
 [   8.   43.  106.   18.   47.]
 [  85.   58.   35.  299.   89.]
 [ 109.  149.  205.  163. 1018.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 98.625% | Wgt Acc: 98.870%
	I - Batch: 100 | Loss: 0.044 | Acc: 98.750% | Wgt Acc: 98.823%
	I - Batch: 150 | Loss: 0.043 | Acc: 98.917% | Wgt Acc: 99.011%
	I - Batch: 200 | Loss: 0.041 | Acc: 98.938% | Wgt Acc: 98.991%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.075% | Wgt Acc: 99.084%
	I - Batch: 300 | Loss: 0.039 | Acc: 99.062% | Wgt Acc: 99.102%
	I - Batch: 350 | Loss: 0.035 | Acc: 99.179% | Wgt Acc: 99.200%
	I - Batch: 400 | Loss: 0.035 | Acc: 99.203% | Wgt Acc: 99.225%
	I - Batch: 450 | Loss: 0.033 | Acc: 99.222% | Wgt Acc: 99.256%
	I - Batch: 500 | Loss: 0.033 | Acc: 99.225% | Wgt Acc: 99.235%
	I - Batch: 550 | Loss: 0.034 | Acc: 99.170% | Wgt Acc: 99.186%
	I - Batch: 600 | Loss: 0.035 | Acc: 99.156% | Wgt Acc: 99.154%
	I - Batch: 650 | Loss: 0.037 | Acc: 99.077% | Wgt Acc: 99.112%
	I - Batch: 700 | Loss: 0.038 | Acc: 99.036% | Wgt Acc: 99.047%
	I - Batch: 750 | Loss: 0.039 | Acc: 98.967% | Wgt Acc: 98.991%
	I - Batch: 800 | Loss: 0.041 | Acc: 98.898% | Wgt Acc: 98.938%
	I - Batch: 850 | Loss: 0.041 | Acc: 98.882% | Wgt Acc: 98.927%
I - num batch: 876
I - Train -- Loss: 0.041 | Acc: 98.893% | Wgt Acc: 98.930% | LR: 1.250000e-04 | Dur: 542.81s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    1.    7.   30.]
 [   1.  919.    4.    2.    9.]
 [   1.    5. 1314.    0.   30.]
 [   3.    1.    0. 1909.   25.]
 [  10.    2.   16.    8. 7836.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.532 | Acc: 49.625% | Wgt Acc: 48.811%
	I - Batch: 100 | Loss: 2.224 | Acc: 57.438% | Wgt Acc: 52.084%
	I - Batch: 150 | Loss: 2.141 | Acc: 59.083% | Wgt Acc: 53.053%
I - num batch: 193
I - Val -- Loss: 2.152 | Acc: 59.300% | Wgt Acc: 52.745% | Dur: 91.33s
I - Confusion Matrix: [row->prediction - col->label]
[[336.   9.  26.  97.  60.]
 [  3. 153.  43.  18.  51.]
 [  8.  63. 140.  11.  88.]
 [ 67.  26.  24. 265.  80.]
 [121. 119. 159. 183. 936.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.250% | Wgt Acc: 99.486%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.250% | Wgt Acc: 99.404%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.375% | Wgt Acc: 99.535%
	I - Batch: 200 | Loss: 0.029 | Acc: 99.156% | Wgt Acc: 99.280%
	I - Batch: 250 | Loss: 0.034 | Acc: 98.975% | Wgt Acc: 99.097%
	I - Batch: 300 | Loss: 0.035 | Acc: 99.000% | Wgt Acc: 99.118%
	I - Batch: 350 | Loss: 0.035 | Acc: 99.000% | Wgt Acc: 99.068%
	I - Batch: 400 | Loss: 0.036 | Acc: 99.000% | Wgt Acc: 99.054%
	I - Batch: 450 | Loss: 0.035 | Acc: 99.028% | Wgt Acc: 99.089%
	I - Batch: 500 | Loss: 0.034 | Acc: 99.050% | Wgt Acc: 99.120%
	I - Batch: 550 | Loss: 0.033 | Acc: 99.068% | Wgt Acc: 99.149%
	I - Batch: 600 | Loss: 0.034 | Acc: 99.083% | Wgt Acc: 99.149%
	I - Batch: 650 | Loss: 0.035 | Acc: 99.077% | Wgt Acc: 99.125%
	I - Batch: 700 | Loss: 0.034 | Acc: 99.089% | Wgt Acc: 99.131%
	I - Batch: 750 | Loss: 0.034 | Acc: 99.100% | Wgt Acc: 99.137%
	I - Batch: 800 | Loss: 0.033 | Acc: 99.117% | Wgt Acc: 99.160%
	I - Batch: 850 | Loss: 0.034 | Acc: 99.074% | Wgt Acc: 99.116%
I - num batch: 876
I - Train -- Loss: 0.034 | Acc: 99.072% | Wgt Acc: 99.110% | LR: 1.250000e-04 | Dur: 540.71s
I - Confusion Matrix: [row->prediction - col->label]
[[1873.    0.    0.    4.   23.]
 [   0.  917.    5.    1.    7.]
 [   0.    6. 1323.    0.   25.]
 [   4.    1.    0. 1911.   25.]
 [   9.    3.    7.   10. 7850.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.383 | Acc: 37.125% | Wgt Acc: 36.645%
	I - Batch: 100 | Loss: 2.751 | Acc: 52.062% | Wgt Acc: 43.897%
	I - Batch: 150 | Loss: 2.533 | Acc: 57.250% | Wgt Acc: 47.465%
I - num batch: 193
I - Val -- Loss: 2.569 | Acc: 58.328% | Wgt Acc: 47.772% | Dur: 91.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 258.    1.   14.   62.   13.]
 [   2.  116.   19.   14.   25.]
 [   9.   59.  147.   26.   78.]
 [  54.   15.   12.  205.   25.]
 [ 212.  179.  200.  267. 1074.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.027 | Acc: 99.250% | Wgt Acc: 99.154%
	I - Batch: 100 | Loss: 0.034 | Acc: 99.000% | Wgt Acc: 98.965%
	I - Batch: 150 | Loss: 0.037 | Acc: 98.958% | Wgt Acc: 98.977%
	I - Batch: 200 | Loss: 0.043 | Acc: 98.781% | Wgt Acc: 98.774%
	I - Batch: 250 | Loss: 0.041 | Acc: 98.925% | Wgt Acc: 98.880%
	I - Batch: 300 | Loss: 0.040 | Acc: 98.979% | Wgt Acc: 98.894%
	I - Batch: 350 | Loss: 0.038 | Acc: 99.036% | Wgt Acc: 98.978%
	I - Batch: 400 | Loss: 0.040 | Acc: 98.938% | Wgt Acc: 98.893%
	I - Batch: 450 | Loss: 0.039 | Acc: 98.986% | Wgt Acc: 98.960%
	I - Batch: 500 | Loss: 0.039 | Acc: 98.987% | Wgt Acc: 98.954%
	I - Batch: 550 | Loss: 0.037 | Acc: 99.034% | Wgt Acc: 99.021%
	I - Batch: 600 | Loss: 0.036 | Acc: 99.073% | Wgt Acc: 99.072%
	I - Batch: 650 | Loss: 0.034 | Acc: 99.115% | Wgt Acc: 99.119%
	I - Batch: 700 | Loss: 0.034 | Acc: 99.116% | Wgt Acc: 99.113%
	I - Batch: 750 | Loss: 0.033 | Acc: 99.150% | Wgt Acc: 99.132%
	I - Batch: 800 | Loss: 0.032 | Acc: 99.180% | Wgt Acc: 99.155%
	I - Batch: 850 | Loss: 0.032 | Acc: 99.176% | Wgt Acc: 99.159%
I - num batch: 876
I - Train -- Loss: 0.036 | Acc: 99.172% | Wgt Acc: 99.136% | LR: 1.250000e-04 | Dur: 540.53s
I - Confusion Matrix: [row->prediction - col->label]
[[1874.    0.    0.    1.   16.]
 [   0.  916.    6.    1.   11.]
 [   0.    5. 1313.    0.   25.]
 [   3.    2.    1. 1919.   12.]
 [   9.    4.   15.    5. 7866.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.316 | Acc: 38.750% | Wgt Acc: 37.804%
	I - Batch: 100 | Loss: 2.708 | Acc: 52.938% | Wgt Acc: 44.840%
	I - Batch: 150 | Loss: 2.495 | Acc: 58.417% | Wgt Acc: 48.606%
I - num batch: 193
I - Val -- Loss: 2.491 | Acc: 59.624% | Wgt Acc: 49.025% | Dur: 91.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 336.   10.   25.  146.   48.]
 [   2.  119.   19.    5.   11.]
 [   3.   30.  101.    8.   21.]
 [  47.   18.   17.  205.   56.]
 [ 147.  193.  230.  210. 1079.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.250% | Wgt Acc: 99.422%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.125% | Wgt Acc: 99.159%
	I - Batch: 150 | Loss: 0.044 | Acc: 98.708% | Wgt Acc: 98.696%
	I - Batch: 200 | Loss: 0.059 | Acc: 98.344% | Wgt Acc: 98.280%
	I - Batch: 250 | Loss: 0.056 | Acc: 98.450% | Wgt Acc: 98.400%
	I - Batch: 300 | Loss: 0.055 | Acc: 98.542% | Wgt Acc: 98.490%
	I - Batch: 350 | Loss: 0.051 | Acc: 98.643% | Wgt Acc: 98.607%
	I - Batch: 400 | Loss: 0.052 | Acc: 98.672% | Wgt Acc: 98.607%
	I - Batch: 450 | Loss: 0.054 | Acc: 98.639% | Wgt Acc: 98.560%
	I - Batch: 500 | Loss: 0.053 | Acc: 98.638% | Wgt Acc: 98.560%
	I - Batch: 550 | Loss: 0.052 | Acc: 98.636% | Wgt Acc: 98.562%
	I - Batch: 600 | Loss: 0.053 | Acc: 98.625% | Wgt Acc: 98.542%
	I - Batch: 650 | Loss: 0.052 | Acc: 98.625% | Wgt Acc: 98.539%
	I - Batch: 700 | Loss: 0.053 | Acc: 98.554% | Wgt Acc: 98.462%
	I - Batch: 750 | Loss: 0.053 | Acc: 98.517% | Wgt Acc: 98.446%
	I - Batch: 800 | Loss: 0.052 | Acc: 98.547% | Wgt Acc: 98.474%
	I - Batch: 850 | Loss: 0.052 | Acc: 98.529% | Wgt Acc: 98.453%
I - num batch: 876
I - Train -- Loss: 0.051 | Acc: 98.543% | Wgt Acc: 98.475% | LR: 1.250000e-04 | Dur: 541.15s
I - Confusion Matrix: [row->prediction - col->label]
[[1860.    2.    0.    9.   30.]
 [   1.  909.    8.    5.   13.]
 [   0.   10. 1310.    0.   36.]
 [  12.    3.    0. 1899.   29.]
 [  13.    3.   17.   13. 7822.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.376 | Acc: 37.250% | Wgt Acc: 36.054%
	I - Batch: 100 | Loss: 2.732 | Acc: 52.500% | Wgt Acc: 44.176%
	I - Batch: 150 | Loss: 2.500 | Acc: 57.625% | Wgt Acc: 47.596%
I - num batch: 193
I - Val -- Loss: 2.495 | Acc: 58.846% | Wgt Acc: 48.091% | Dur: 91.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 300.    6.   21.   89.   38.]
 [   1.   85.   12.    8.   13.]
 [   4.   41.  129.   15.   51.]
 [  77.   24.   14.  231.   42.]
 [ 153.  214.  216.  231. 1071.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.056 | Acc: 98.500% | Wgt Acc: 98.447%
	I - Batch: 100 | Loss: 0.059 | Acc: 98.125% | Wgt Acc: 98.187%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.333% | Wgt Acc: 98.440%
	I - Batch: 200 | Loss: 0.047 | Acc: 98.531% | Wgt Acc: 98.598%
	I - Batch: 250 | Loss: 0.048 | Acc: 98.575% | Wgt Acc: 98.610%
	I - Batch: 300 | Loss: 0.046 | Acc: 98.625% | Wgt Acc: 98.665%
	I - Batch: 350 | Loss: 0.043 | Acc: 98.732% | Wgt Acc: 98.785%
	I - Batch: 400 | Loss: 0.040 | Acc: 98.844% | Wgt Acc: 98.870%
	I - Batch: 450 | Loss: 0.041 | Acc: 98.792% | Wgt Acc: 98.817%
	I - Batch: 500 | Loss: 0.040 | Acc: 98.838% | Wgt Acc: 98.862%
	I - Batch: 550 | Loss: 0.040 | Acc: 98.841% | Wgt Acc: 98.836%
	I - Batch: 600 | Loss: 0.041 | Acc: 98.823% | Wgt Acc: 98.814%
	I - Batch: 650 | Loss: 0.042 | Acc: 98.788% | Wgt Acc: 98.747%
	I - Batch: 700 | Loss: 0.043 | Acc: 98.741% | Wgt Acc: 98.724%
	I - Batch: 750 | Loss: 0.045 | Acc: 98.658% | Wgt Acc: 98.658%
	I - Batch: 800 | Loss: 0.046 | Acc: 98.633% | Wgt Acc: 98.614%
	I - Batch: 850 | Loss: 0.046 | Acc: 98.632% | Wgt Acc: 98.608%
I - num batch: 876
I - Train -- Loss: 0.047 | Acc: 98.629% | Wgt Acc: 98.607% | LR: 1.250000e-04 | Dur: 538.47s
I - Confusion Matrix: [row->prediction - col->label]
[[1868.    1.    0.    6.   37.]
 [   1.  909.    9.    3.    8.]
 [   0.    9. 1310.    0.   36.]
 [   5.    1.    0. 1904.   28.]
 [  12.    7.   16.   13. 7821.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.561 | Acc: 48.625% | Wgt Acc: 47.816%
	I - Batch: 100 | Loss: 2.207 | Acc: 56.812% | Wgt Acc: 51.650%
	I - Batch: 150 | Loss: 2.076 | Acc: 59.708% | Wgt Acc: 53.638%
I - num batch: 193
I - Val -- Loss: 2.097 | Acc: 59.657% | Wgt Acc: 52.972% | Dur: 91.53s
I - Confusion Matrix: [row->prediction - col->label]
[[344.  10.  22. 109.  62.]
 [  7. 139.  26.  28.  41.]
 [ 13.  54. 156.  22.  88.]
 [ 75.  30.  27. 259.  81.]
 [ 96. 137. 161. 156. 943.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.076 | Acc: 97.375% | Wgt Acc: 97.047%
	I - Batch: 100 | Loss: 0.061 | Acc: 98.000% | Wgt Acc: 97.932%
	I - Batch: 150 | Loss: 0.056 | Acc: 98.208% | Wgt Acc: 98.181%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.312% | Wgt Acc: 98.239%
	I - Batch: 250 | Loss: 0.057 | Acc: 98.350% | Wgt Acc: 98.257%
	I - Batch: 300 | Loss: 0.056 | Acc: 98.292% | Wgt Acc: 98.237%
	I - Batch: 350 | Loss: 0.053 | Acc: 98.429% | Wgt Acc: 98.380%
	I - Batch: 400 | Loss: 0.050 | Acc: 98.531% | Wgt Acc: 98.519%
	I - Batch: 450 | Loss: 0.048 | Acc: 98.597% | Wgt Acc: 98.609%
	I - Batch: 500 | Loss: 0.048 | Acc: 98.612% | Wgt Acc: 98.620%
	I - Batch: 550 | Loss: 0.047 | Acc: 98.659% | Wgt Acc: 98.665%
	I - Batch: 600 | Loss: 0.046 | Acc: 98.708% | Wgt Acc: 98.705%
	I - Batch: 650 | Loss: 0.045 | Acc: 98.760% | Wgt Acc: 98.770%
	I - Batch: 700 | Loss: 0.043 | Acc: 98.812% | Wgt Acc: 98.822%
	I - Batch: 750 | Loss: 0.043 | Acc: 98.850% | Wgt Acc: 98.866%
	I - Batch: 800 | Loss: 0.042 | Acc: 98.875% | Wgt Acc: 98.886%
	I - Batch: 850 | Loss: 0.042 | Acc: 98.890% | Wgt Acc: 98.903%
I - num batch: 876
I - Train -- Loss: 0.041 | Acc: 98.922% | Wgt Acc: 98.935% | LR: 1.250000e-04 | Dur: 543.88s
I - Confusion Matrix: [row->prediction - col->label]
[[1871.    0.    0.    2.   30.]
 [   0.  916.    7.    1.   10.]
 [   0.    7. 1316.    0.   25.]
 [   3.    1.    0. 1909.   24.]
 [  12.    3.   12.   14. 7841.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.148 | Acc: 40.750% | Wgt Acc: 39.931%
	I - Batch: 100 | Loss: 2.590 | Acc: 54.188% | Wgt Acc: 46.427%
	I - Batch: 150 | Loss: 2.405 | Acc: 58.458% | Wgt Acc: 48.997%
I - num batch: 193
I - Val -- Loss: 2.423 | Acc: 59.268% | Wgt Acc: 49.050% | Dur: 92.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 304.    6.   20.  105.   38.]
 [   2.  132.   27.   16.   33.]
 [   7.   29.  100.    9.   31.]
 [  61.   23.   16.  228.   48.]
 [ 161.  180.  229.  216. 1065.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.250% | Wgt Acc: 99.178%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.188% | Wgt Acc: 99.166%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.083% | Wgt Acc: 99.141%
	I - Batch: 200 | Loss: 0.028 | Acc: 99.250% | Wgt Acc: 99.319%
	I - Batch: 250 | Loss: 0.028 | Acc: 99.275% | Wgt Acc: 99.352%
	I - Batch: 300 | Loss: 0.026 | Acc: 99.375% | Wgt Acc: 99.422%
	I - Batch: 350 | Loss: 0.025 | Acc: 99.429% | Wgt Acc: 99.450%
	I - Batch: 400 | Loss: 0.025 | Acc: 99.453% | Wgt Acc: 99.461%
	I - Batch: 450 | Loss: 0.025 | Acc: 99.431% | Wgt Acc: 99.424%
	I - Batch: 500 | Loss: 0.025 | Acc: 99.412% | Wgt Acc: 99.399%
	I - Batch: 550 | Loss: 0.026 | Acc: 99.398% | Wgt Acc: 99.390%
	I - Batch: 600 | Loss: 0.025 | Acc: 99.396% | Wgt Acc: 99.389%
	I - Batch: 650 | Loss: 0.025 | Acc: 99.385% | Wgt Acc: 99.394%
	I - Batch: 700 | Loss: 0.026 | Acc: 99.357% | Wgt Acc: 99.362%
	I - Batch: 750 | Loss: 0.026 | Acc: 99.367% | Wgt Acc: 99.369%
	I - Batch: 800 | Loss: 0.026 | Acc: 99.383% | Wgt Acc: 99.380%
	I - Batch: 850 | Loss: 0.027 | Acc: 99.353% | Wgt Acc: 99.347%
I - num batch: 876
I - Train -- Loss: 0.027 | Acc: 99.329% | Wgt Acc: 99.333% | LR: 1.250000e-04 | Dur: 543.61s
I - Confusion Matrix: [row->prediction - col->label]
[[1876.    1.    0.    1.   22.]
 [   1.  916.    7.    1.    4.]
 [   0.    5. 1325.    0.   17.]
 [   2.    0.    0. 1919.   13.]
 [   7.    5.    3.    5. 7874.]]

I - Validation: 
	I - Batch: 50 | Loss: 3.042 | Acc: 42.375% | Wgt Acc: 41.172%
	I - Batch: 100 | Loss: 2.433 | Acc: 55.875% | Wgt Acc: 48.620%
	I - Batch: 150 | Loss: 2.285 | Acc: 59.875% | Wgt Acc: 51.234%
I - num batch: 193
I - Val -- Loss: 2.273 | Acc: 60.823% | Wgt Acc: 51.721% | Dur: 92.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 361.   11.   31.  139.   52.]
 [   3.  136.   34.   12.   27.]
 [   3.   31.   95.    8.   29.]
 [  64.   36.   24.  249.   71.]
 [ 104.  156.  208.  166. 1036.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.625% | Wgt Acc: 99.641%
	I - Batch: 100 | Loss: 0.024 | Acc: 99.562% | Wgt Acc: 99.538%
	I - Batch: 150 | Loss: 0.029 | Acc: 99.333% | Wgt Acc: 99.164%
	I - Batch: 200 | Loss: 0.028 | Acc: 99.281% | Wgt Acc: 99.250%
	I - Batch: 250 | Loss: 0.027 | Acc: 99.300% | Wgt Acc: 99.310%
	I - Batch: 300 | Loss: 0.027 | Acc: 99.333% | Wgt Acc: 99.335%
	I - Batch: 350 | Loss: 0.025 | Acc: 99.393% | Wgt Acc: 99.392%
	I - Batch: 400 | Loss: 0.024 | Acc: 99.438% | Wgt Acc: 99.450%
	I - Batch: 450 | Loss: 0.024 | Acc: 99.486% | Wgt Acc: 99.491%
	I - Batch: 500 | Loss: 0.024 | Acc: 99.487% | Wgt Acc: 99.481%
	I - Batch: 550 | Loss: 0.025 | Acc: 99.477% | Wgt Acc: 99.473%
	I - Batch: 600 | Loss: 0.026 | Acc: 99.417% | Wgt Acc: 99.392%
	I - Batch: 650 | Loss: 0.026 | Acc: 99.404% | Wgt Acc: 99.406%
	I - Batch: 700 | Loss: 0.027 | Acc: 99.357% | Wgt Acc: 99.352%
	I - Batch: 750 | Loss: 0.029 | Acc: 99.308% | Wgt Acc: 99.326%
	I - Batch: 800 | Loss: 0.030 | Acc: 99.266% | Wgt Acc: 99.275%
	I - Batch: 850 | Loss: 0.031 | Acc: 99.213% | Wgt Acc: 99.240%
I - num batch: 876
I - Train -- Loss: 0.032 | Acc: 99.200% | Wgt Acc: 99.225% | LR: 1.250000e-04 | Dur: 543.70s
I - Confusion Matrix: [row->prediction - col->label]
[[1875.    1.    0.    5.   21.]
 [   0.  919.    5.    1.    6.]
 [   0.    3. 1322.    0.   27.]
 [   1.    1.    0. 1914.   14.]
 [  10.    3.    8.    6. 7862.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.427 | Acc: 49.500% | Wgt Acc: 49.008%
	I - Batch: 100 | Loss: 2.038 | Acc: 57.750% | Wgt Acc: 53.790%
	I - Batch: 150 | Loss: 1.955 | Acc: 59.208% | Wgt Acc: 55.042%
I - num batch: 193
I - Val -- Loss: 1.994 | Acc: 58.846% | Wgt Acc: 54.469% | Dur: 92.12s
I - Confusion Matrix: [row->prediction - col->label]
[[356.  13.  26. 127.  73.]
 [  9. 173.  63.  27.  84.]
 [ 13.  62. 183.  25. 138.]
 [ 55.  26.  16. 242.  58.]
 [102.  96. 104. 153. 862.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.052 | Acc: 98.750% | Wgt Acc: 98.656%
	I - Batch: 100 | Loss: 0.047 | Acc: 98.812% | Wgt Acc: 98.829%
	I - Batch: 150 | Loss: 0.041 | Acc: 98.958% | Wgt Acc: 99.053%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.188% | Wgt Acc: 99.272%
	I - Batch: 250 | Loss: 0.034 | Acc: 99.100% | Wgt Acc: 99.233%
	I - Batch: 300 | Loss: 0.035 | Acc: 99.125% | Wgt Acc: 99.212%
	I - Batch: 350 | Loss: 0.035 | Acc: 99.143% | Wgt Acc: 99.224%
	I - Batch: 400 | Loss: 0.037 | Acc: 99.094% | Wgt Acc: 99.171%
	I - Batch: 450 | Loss: 0.039 | Acc: 98.972% | Wgt Acc: 99.027%
	I - Batch: 500 | Loss: 0.042 | Acc: 98.925% | Wgt Acc: 98.964%
	I - Batch: 550 | Loss: 0.043 | Acc: 98.909% | Wgt Acc: 98.945%
	I - Batch: 600 | Loss: 0.042 | Acc: 98.958% | Wgt Acc: 98.989%
	I - Batch: 650 | Loss: 0.041 | Acc: 98.942% | Wgt Acc: 98.966%
	I - Batch: 700 | Loss: 0.040 | Acc: 98.955% | Wgt Acc: 98.988%
	I - Batch: 750 | Loss: 0.040 | Acc: 98.933% | Wgt Acc: 98.946%
	I - Batch: 800 | Loss: 0.040 | Acc: 98.938% | Wgt Acc: 98.958%
	I - Batch: 850 | Loss: 0.040 | Acc: 98.904% | Wgt Acc: 98.918%
I - num batch: 876
I - Train -- Loss: 0.042 | Acc: 98.907% | Wgt Acc: 98.906% | LR: 1.250000e-04 | Dur: 545.41s
I - Confusion Matrix: [row->prediction - col->label]
[[1869.    0.    0.    6.   25.]
 [   0.  915.    7.    2.    9.]
 [   0.    6. 1317.    0.   27.]
 [   4.    0.    0. 1908.   27.]
 [  13.    6.   11.   10. 7842.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.384 | Acc: 51.500% | Wgt Acc: 50.872%
	I - Batch: 100 | Loss: 2.014 | Acc: 58.938% | Wgt Acc: 54.736%
	I - Batch: 150 | Loss: 1.974 | Acc: 60.625% | Wgt Acc: 55.426%
I - num batch: 193
I - Val -- Loss: 1.972 | Acc: 60.758% | Wgt Acc: 55.093% | Dur: 91.12s
I - Confusion Matrix: [row->prediction - col->label]
[[318.  14.  29.  90.  75.]
 [  3. 170.  44.  20.  48.]
 [ 12.  51. 152.  21.  86.]
 [109.  30.  27. 311.  82.]
 [ 93. 105. 140. 132. 924.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 98.750% | Wgt Acc: 98.922%
	I - Batch: 100 | Loss: 0.059 | Acc: 97.750% | Wgt Acc: 98.046%
	I - Batch: 150 | Loss: 0.059 | Acc: 98.125% | Wgt Acc: 98.293%
	I - Batch: 200 | Loss: 0.062 | Acc: 98.062% | Wgt Acc: 98.120%
	I - Batch: 250 | Loss: 0.057 | Acc: 98.275% | Wgt Acc: 98.252%
	I - Batch: 300 | Loss: 0.056 | Acc: 98.312% | Wgt Acc: 98.280%
	I - Batch: 350 | Loss: 0.052 | Acc: 98.411% | Wgt Acc: 98.425%
	I - Batch: 400 | Loss: 0.053 | Acc: 98.375% | Wgt Acc: 98.387%
	I - Batch: 450 | Loss: 0.050 | Acc: 98.472% | Wgt Acc: 98.491%
	I - Batch: 500 | Loss: 0.049 | Acc: 98.537% | Wgt Acc: 98.555%
