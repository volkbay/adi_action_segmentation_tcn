Wed Oct 26 13:10:07 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.2, 0.25, 0.2, 0.25, 0.1], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': '/new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat'], 'lastLayerInitUniform': False, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 71.55963302752293, 'maxValidationTrainNo': 53, 'modelVersion': 15, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 55, 'validationAccThr': 70, 'warmStartConfig': {'checkpointFile': './sav/model9_trainNo39_at_epoch_22_with_acc_70_34_checkpoint.pth.tar', 'checkpointModelNo': 9, 'freezeSpatialCNN': True, 'warmStartFlag': False}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Train set length:  2547
I - Label distribution: [697. 578. 734. 538.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Test set length:  327
I - Label distribution: [88. 78. 75. 86.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(3) data number in dataset:  tensor([ 82166, 116634, 141980,  31734, 112471,  28776, 101454,  74522,  49352,
        102073,  73860,  43042, 162934,  72440, 183667, 208051])
I - Initializing model TCNv15
I - Number of Model Parameters: 949408
I - Model output shape:  torch.Size([16, 4])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv15                                   [16, 4]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         6,278
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [128, 48, 1, 1]           --
│    └─Empty: 2-5                        [128, 48, 1, 1]           --
│    └─Empty: 2-6                        [128]                     --
│    └─Empty: 2-7                        [128]                     --
│    └─BatchNorm2d: 2-8                  [16, 128, 64, 64]         --
│    └─Scaler: 2-9                       [16, 128, 64, 64]         --
│    └─ReLU: 2-10                        [16, 128, 64, 64]         --
│    └─Empty: 2-11                       [16, 128, 64, 64]         --
│    └─Clamp: 2-12                       [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-2                 [16, 128, 64, 64]         147,590
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [128, 128, 3, 3]          --
│    └─Empty: 2-17                       [128, 128, 3, 3]          --
│    └─Empty: 2-18                       [128]                     --
│    └─Empty: 2-19                       [128]                     --
│    └─BatchNorm2d: 2-20                 [16, 128, 64, 64]         --
│    └─Scaler: 2-21                      [16, 128, 64, 64]         --
│    └─ReLU: 2-22                        [16, 128, 64, 64]         --
│    └─Empty: 2-23                       [16, 128, 64, 64]         --
│    └─Clamp: 2-24                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-3          [16, 128, 32, 32]         147,590
│    └─MaxPool2d: 2-25                   [16, 128, 32, 32]         --
│    └─Empty: 2-26                       [16, 128, 32, 32]         --
│    └─Empty: 2-27                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-28          --                        --
│    └─One: 2-29                         [1]                       --
│    └─OutputScale: 2-30                 --                        --
│    └─Empty: 2-31                       [128, 128, 3, 3]          --
│    └─Empty: 2-32                       [128, 128, 3, 3]          --
│    └─Empty: 2-33                       [128]                     --
│    └─Empty: 2-34                       [128]                     --
│    └─BatchNorm2d: 2-35                 [16, 128, 32, 32]         --
│    └─Scaler: 2-36                      [16, 128, 32, 32]         --
│    └─ReLU: 2-37                        [16, 128, 32, 32]         --
│    └─Empty: 2-38                       [16, 128, 32, 32]         --
│    └─Clamp: 2-39                       [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-4                 [16, 128, 32, 32]         16,518
│    └─OutputShiftSqueeze: 2-40          --                        --
│    └─One: 2-41                         [1]                       --
│    └─OutputScale: 2-42                 --                        --
│    └─Empty: 2-43                       [128, 128, 1, 1]          --
│    └─Empty: 2-44                       [128, 128, 1, 1]          --
│    └─Empty: 2-45                       [128]                     --
│    └─Empty: 2-46                       [128]                     --
│    └─BatchNorm2d: 2-47                 [16, 128, 32, 32]         --
│    └─Scaler: 2-48                      [16, 128, 32, 32]         --
│    └─ReLU: 2-49                        [16, 128, 32, 32]         --
│    └─Empty: 2-50                       [16, 128, 32, 32]         --
│    └─Clamp: 2-51                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 128, 32, 32]         147,590
│    └─MaxPool2d: 2-52                   [16, 128, 32, 32]         --
│    └─Empty: 2-53                       [16, 128, 32, 32]         --
│    └─Empty: 2-54                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-55          --                        --
│    └─One: 2-56                         [1]                       --
│    └─OutputScale: 2-57                 --                        --
│    └─Empty: 2-58                       [128, 128, 3, 3]          --
│    └─Empty: 2-59                       [128, 128, 3, 3]          --
│    └─Empty: 2-60                       [128]                     --
│    └─Empty: 2-61                       [128]                     --
│    └─BatchNorm2d: 2-62                 [16, 128, 32, 32]         --
│    └─Scaler: 2-63                      [16, 128, 32, 32]         --
│    └─ReLU: 2-64                        [16, 128, 32, 32]         --
│    └─Empty: 2-65                       [16, 128, 32, 32]         --
│    └─Clamp: 2-66                       [16, 128, 32, 32]         --
├─Dropout2d: 1-6                         [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-67                   [16, 128, 16, 16]         --
│    └─Empty: 2-68                       [16, 128, 16, 16]         --
│    └─Empty: 2-69                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-70          --                        --
│    └─One: 2-71                         [1]                       --
│    └─OutputScale: 2-72                 --                        --
│    └─Empty: 2-73                       [128, 128, 3, 3]          --
│    └─Empty: 2-74                       [128, 128, 3, 3]          --
│    └─Empty: 2-75                       [128]                     --
│    └─Empty: 2-76                       [128]                     --
│    └─BatchNorm2d: 2-77                 [16, 128, 16, 16]         --
│    └─Scaler: 2-78                      [16, 128, 16, 16]         --
│    └─ReLU: 2-79                        [16, 128, 16, 16]         --
│    └─Empty: 2-80                       [16, 128, 16, 16]         --
│    └─Clamp: 2-81                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-8                 [16, 128, 16, 16]         16,518
│    └─OutputShiftSqueeze: 2-82          --                        --
│    └─One: 2-83                         [1]                       --
│    └─OutputScale: 2-84                 --                        --
│    └─Empty: 2-85                       [128, 128, 1, 1]          --
│    └─Empty: 2-86                       [128, 128, 1, 1]          --
│    └─Empty: 2-87                       [128]                     --
│    └─Empty: 2-88                       [128]                     --
│    └─BatchNorm2d: 2-89                 [16, 128, 16, 16]         --
│    └─Scaler: 2-90                      [16, 128, 16, 16]         --
│    └─ReLU: 2-91                        [16, 128, 16, 16]         --
│    └─Empty: 2-92                       [16, 128, 16, 16]         --
│    └─Clamp: 2-93                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-94                   [16, 128, 16, 16]         --
│    └─Empty: 2-95                       [16, 128, 16, 16]         --
│    └─Empty: 2-96                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-97          --                        --
│    └─One: 2-98                         [1]                       --
│    └─OutputScale: 2-99                 --                        --
│    └─Empty: 2-100                      [128, 128, 3, 3]          --
│    └─Empty: 2-101                      [128, 128, 3, 3]          --
│    └─Empty: 2-102                      [128]                     --
│    └─Empty: 2-103                      [128]                     --
│    └─BatchNorm2d: 2-104                [16, 128, 16, 16]         --
│    └─Scaler: 2-105                     [16, 128, 16, 16]         --
│    └─ReLU: 2-106                       [16, 128, 16, 16]         --
│    └─Empty: 2-107                      [16, 128, 16, 16]         --
│    └─Clamp: 2-108                      [16, 128, 16, 16]         --
├─Dropout2d: 1-10                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-109                  [16, 128, 8, 8]           --
│    └─Empty: 2-110                      [16, 128, 8, 8]           --
│    └─Empty: 2-111                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-112         --                        --
│    └─One: 2-113                        [1]                       --
│    └─OutputScale: 2-114                --                        --
│    └─Empty: 2-115                      [128, 128, 3, 3]          --
│    └─Empty: 2-116                      [128, 128, 3, 3]          --
│    └─Empty: 2-117                      [128]                     --
│    └─Empty: 2-118                      [128]                     --
│    └─BatchNorm2d: 2-119                [16, 128, 8, 8]           --
│    └─Scaler: 2-120                     [16, 128, 8, 8]           --
│    └─ReLU: 2-121                       [16, 128, 8, 8]           --
│    └─Empty: 2-122                      [16, 128, 8, 8]           --
│    └─Clamp: 2-123                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-12                [16, 16, 8, 8]            2,070
│    └─OutputShiftSqueeze: 2-124         --                        --
│    └─One: 2-125                        [1]                       --
│    └─OutputScale: 2-126                --                        --
│    └─Empty: 2-127                      [16, 128, 1, 1]           --
│    └─Empty: 2-128                      [16, 128, 1, 1]           --
│    └─Empty: 2-129                      [16]                      --
│    └─Empty: 2-130                      [16]                      --
│    └─BatchNorm2d: 2-131                [16, 16, 8, 8]            --
│    └─Scaler: 2-132                     [16, 16, 8, 8]            --
│    └─ReLU: 2-133                       [16, 16, 8, 8]            --
│    └─Empty: 2-134                      [16, 16, 8, 8]            --
│    └─Clamp: 2-135                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 16, 8, 8]            18,454
│    └─MaxPool2d: 2-136                  [16, 128, 8, 8]           --
│    └─Empty: 2-137                      [16, 128, 8, 8]           --
│    └─Empty: 2-138                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-139         --                        --
│    └─One: 2-140                        [1]                       --
│    └─OutputScale: 2-141                --                        --
│    └─Empty: 2-142                      [16, 128, 3, 3]           --
│    └─Empty: 2-143                      [16, 128, 3, 3]           --
│    └─Empty: 2-144                      [16]                      --
│    └─Empty: 2-145                      [16]                      --
│    └─BatchNorm2d: 2-146                [16, 16, 8, 8]            --
│    └─Scaler: 2-147                     [16, 16, 8, 8]            --
│    └─ReLU: 2-148                       [16, 16, 8, 8]            --
│    └─Empty: 2-149                      [16, 16, 8, 8]            --
│    └─Clamp: 2-150                      [16, 16, 8, 8]            --
├─Dropout2d: 1-14                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-15                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-151         --                        --
│    └─One: 2-152                        [1]                       --
│    └─OutputScale: 2-153                --                        --
│    └─Empty: 2-154                      [128, 48, 1, 1]           --
│    └─Empty: 2-155                      [128, 48, 1, 1]           --
│    └─Empty: 2-156                      [128]                     --
│    └─Empty: 2-157                      [128]                     --
│    └─BatchNorm2d: 2-158                [16, 128, 64, 64]         --
│    └─Scaler: 2-159                     [16, 128, 64, 64]         --
│    └─ReLU: 2-160                       [16, 128, 64, 64]         --
│    └─Empty: 2-161                      [16, 128, 64, 64]         --
│    └─Clamp: 2-162                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-16                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-163         --                        --
│    └─One: 2-164                        [1]                       --
│    └─OutputScale: 2-165                --                        --
│    └─Empty: 2-166                      [128, 128, 3, 3]          --
│    └─Empty: 2-167                      [128, 128, 3, 3]          --
│    └─Empty: 2-168                      [128]                     --
│    └─Empty: 2-169                      [128]                     --
│    └─BatchNorm2d: 2-170                [16, 128, 64, 64]         --
│    └─Scaler: 2-171                     [16, 128, 64, 64]         --
│    └─ReLU: 2-172                       [16, 128, 64, 64]         --
│    └─Empty: 2-173                      [16, 128, 64, 64]         --
│    └─Clamp: 2-174                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-175                  [16, 128, 32, 32]         --
│    └─Empty: 2-176                      [16, 128, 32, 32]         --
│    └─Empty: 2-177                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-178         --                        --
│    └─One: 2-179                        [1]                       --
│    └─OutputScale: 2-180                --                        --
│    └─Empty: 2-181                      [128, 128, 3, 3]          --
│    └─Empty: 2-182                      [128, 128, 3, 3]          --
│    └─Empty: 2-183                      [128]                     --
│    └─Empty: 2-184                      [128]                     --
│    └─BatchNorm2d: 2-185                [16, 128, 32, 32]         --
│    └─Scaler: 2-186                     [16, 128, 32, 32]         --
│    └─ReLU: 2-187                       [16, 128, 32, 32]         --
│    └─Empty: 2-188                      [16, 128, 32, 32]         --
│    └─Clamp: 2-189                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-18                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-190         --                        --
│    └─One: 2-191                        [1]                       --
│    └─OutputScale: 2-192                --                        --
│    └─Empty: 2-193                      [128, 128, 1, 1]          --
│    └─Empty: 2-194                      [128, 128, 1, 1]          --
│    └─Empty: 2-195                      [128]                     --
│    └─Empty: 2-196                      [128]                     --
│    └─BatchNorm2d: 2-197                [16, 128, 32, 32]         --
│    └─Scaler: 2-198                     [16, 128, 32, 32]         --
│    └─ReLU: 2-199                       [16, 128, 32, 32]         --
│    └─Empty: 2-200                      [16, 128, 32, 32]         --
│    └─Clamp: 2-201                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-19         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-202                  [16, 128, 32, 32]         --
│    └─Empty: 2-203                      [16, 128, 32, 32]         --
│    └─Empty: 2-204                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-205         --                        --
│    └─One: 2-206                        [1]                       --
│    └─OutputScale: 2-207                --                        --
│    └─Empty: 2-208                      [128, 128, 3, 3]          --
│    └─Empty: 2-209                      [128, 128, 3, 3]          --
│    └─Empty: 2-210                      [128]                     --
│    └─Empty: 2-211                      [128]                     --
│    └─BatchNorm2d: 2-212                [16, 128, 32, 32]         --
│    └─Scaler: 2-213                     [16, 128, 32, 32]         --
│    └─ReLU: 2-214                       [16, 128, 32, 32]         --
│    └─Empty: 2-215                      [16, 128, 32, 32]         --
│    └─Clamp: 2-216                      [16, 128, 32, 32]         --
├─Dropout2d: 1-20                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-21         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-217                  [16, 128, 16, 16]         --
│    └─Empty: 2-218                      [16, 128, 16, 16]         --
│    └─Empty: 2-219                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-220         --                        --
│    └─One: 2-221                        [1]                       --
│    └─OutputScale: 2-222                --                        --
│    └─Empty: 2-223                      [128, 128, 3, 3]          --
│    └─Empty: 2-224                      [128, 128, 3, 3]          --
│    └─Empty: 2-225                      [128]                     --
│    └─Empty: 2-226                      [128]                     --
│    └─BatchNorm2d: 2-227                [16, 128, 16, 16]         --
│    └─Scaler: 2-228                     [16, 128, 16, 16]         --
│    └─ReLU: 2-229                       [16, 128, 16, 16]         --
│    └─Empty: 2-230                      [16, 128, 16, 16]         --
│    └─Clamp: 2-231                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-22                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-232         --                        --
│    └─One: 2-233                        [1]                       --
│    └─OutputScale: 2-234                --                        --
│    └─Empty: 2-235                      [128, 128, 1, 1]          --
│    └─Empty: 2-236                      [128, 128, 1, 1]          --
│    └─Empty: 2-237                      [128]                     --
│    └─Empty: 2-238                      [128]                     --
│    └─BatchNorm2d: 2-239                [16, 128, 16, 16]         --
│    └─Scaler: 2-240                     [16, 128, 16, 16]         --
│    └─ReLU: 2-241                       [16, 128, 16, 16]         --
│    └─Empty: 2-242                      [16, 128, 16, 16]         --
│    └─Clamp: 2-243                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-244                  [16, 128, 16, 16]         --
│    └─Empty: 2-245                      [16, 128, 16, 16]         --
│    └─Empty: 2-246                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-247         --                        --
│    └─One: 2-248                        [1]                       --
│    └─OutputScale: 2-249                --                        --
│    └─Empty: 2-250                      [128, 128, 3, 3]          --
│    └─Empty: 2-251                      [128, 128, 3, 3]          --
│    └─Empty: 2-252                      [128]                     --
│    └─Empty: 2-253                      [128]                     --
│    └─BatchNorm2d: 2-254                [16, 128, 16, 16]         --
│    └─Scaler: 2-255                     [16, 128, 16, 16]         --
│    └─ReLU: 2-256                       [16, 128, 16, 16]         --
│    └─Empty: 2-257                      [16, 128, 16, 16]         --
│    └─Clamp: 2-258                      [16, 128, 16, 16]         --
├─Dropout2d: 1-24                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-259                  [16, 128, 8, 8]           --
│    └─Empty: 2-260                      [16, 128, 8, 8]           --
│    └─Empty: 2-261                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-262         --                        --
│    └─One: 2-263                        [1]                       --
│    └─OutputScale: 2-264                --                        --
│    └─Empty: 2-265                      [128, 128, 3, 3]          --
│    └─Empty: 2-266                      [128, 128, 3, 3]          --
│    └─Empty: 2-267                      [128]                     --
│    └─Empty: 2-268                      [128]                     --
│    └─BatchNorm2d: 2-269                [16, 128, 8, 8]           --
│    └─Scaler: 2-270                     [16, 128, 8, 8]           --
│    └─ReLU: 2-271                       [16, 128, 8, 8]           --
│    └─Empty: 2-272                      [16, 128, 8, 8]           --
│    └─Clamp: 2-273                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-26                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-274         --                        --
│    └─One: 2-275                        [1]                       --
│    └─OutputScale: 2-276                --                        --
│    └─Empty: 2-277                      [16, 128, 1, 1]           --
│    └─Empty: 2-278                      [16, 128, 1, 1]           --
│    └─Empty: 2-279                      [16]                      --
│    └─Empty: 2-280                      [16]                      --
│    └─BatchNorm2d: 2-281                [16, 16, 8, 8]            --
│    └─Scaler: 2-282                     [16, 16, 8, 8]            --
│    └─ReLU: 2-283                       [16, 16, 8, 8]            --
│    └─Empty: 2-284                      [16, 16, 8, 8]            --
│    └─Clamp: 2-285                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-27         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-286                  [16, 128, 8, 8]           --
│    └─Empty: 2-287                      [16, 128, 8, 8]           --
│    └─Empty: 2-288                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-289         --                        --
│    └─One: 2-290                        [1]                       --
│    └─OutputScale: 2-291                --                        --
│    └─Empty: 2-292                      [16, 128, 3, 3]           --
│    └─Empty: 2-293                      [16, 128, 3, 3]           --
│    └─Empty: 2-294                      [16]                      --
│    └─Empty: 2-295                      [16]                      --
│    └─BatchNorm2d: 2-296                [16, 16, 8, 8]            --
│    └─Scaler: 2-297                     [16, 16, 8, 8]            --
│    └─ReLU: 2-298                       [16, 16, 8, 8]            --
│    └─Empty: 2-299                      [16, 16, 8, 8]            --
│    └─Clamp: 2-300                      [16, 16, 8, 8]            --
├─Dropout2d: 1-28                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-29                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-301         --                        --
│    └─One: 2-302                        [1]                       --
│    └─OutputScale: 2-303                --                        --
│    └─Empty: 2-304                      [128, 48, 1, 1]           --
│    └─Empty: 2-305                      [128, 48, 1, 1]           --
│    └─Empty: 2-306                      [128]                     --
│    └─Empty: 2-307                      [128]                     --
│    └─BatchNorm2d: 2-308                [16, 128, 64, 64]         --
│    └─Scaler: 2-309                     [16, 128, 64, 64]         --
│    └─ReLU: 2-310                       [16, 128, 64, 64]         --
│    └─Empty: 2-311                      [16, 128, 64, 64]         --
│    └─Clamp: 2-312                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-30                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-313         --                        --
│    └─One: 2-314                        [1]                       --
│    └─OutputScale: 2-315                --                        --
│    └─Empty: 2-316                      [128, 128, 3, 3]          --
│    └─Empty: 2-317                      [128, 128, 3, 3]          --
│    └─Empty: 2-318                      [128]                     --
│    └─Empty: 2-319                      [128]                     --
│    └─BatchNorm2d: 2-320                [16, 128, 64, 64]         --
│    └─Scaler: 2-321                     [16, 128, 64, 64]         --
│    └─ReLU: 2-322                       [16, 128, 64, 64]         --
│    └─Empty: 2-323                      [16, 128, 64, 64]         --
│    └─Clamp: 2-324                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-325                  [16, 128, 32, 32]         --
│    └─Empty: 2-326                      [16, 128, 32, 32]         --
│    └─Empty: 2-327                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-328         --                        --
│    └─One: 2-329                        [1]                       --
│    └─OutputScale: 2-330                --                        --
│    └─Empty: 2-331                      [128, 128, 3, 3]          --
│    └─Empty: 2-332                      [128, 128, 3, 3]          --
│    └─Empty: 2-333                      [128]                     --
│    └─Empty: 2-334                      [128]                     --
│    └─BatchNorm2d: 2-335                [16, 128, 32, 32]         --
│    └─Scaler: 2-336                     [16, 128, 32, 32]         --
│    └─ReLU: 2-337                       [16, 128, 32, 32]         --
│    └─Empty: 2-338                      [16, 128, 32, 32]         --
│    └─Clamp: 2-339                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-32                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-340         --                        --
│    └─One: 2-341                        [1]                       --
│    └─OutputScale: 2-342                --                        --
│    └─Empty: 2-343                      [128, 128, 1, 1]          --
│    └─Empty: 2-344                      [128, 128, 1, 1]          --
│    └─Empty: 2-345                      [128]                     --
│    └─Empty: 2-346                      [128]                     --
│    └─BatchNorm2d: 2-347                [16, 128, 32, 32]         --
│    └─Scaler: 2-348                     [16, 128, 32, 32]         --
│    └─ReLU: 2-349                       [16, 128, 32, 32]         --
│    └─Empty: 2-350                      [16, 128, 32, 32]         --
│    └─Clamp: 2-351                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-352                  [16, 128, 32, 32]         --
│    └─Empty: 2-353                      [16, 128, 32, 32]         --
│    └─Empty: 2-354                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-355         --                        --
│    └─One: 2-356                        [1]                       --
│    └─OutputScale: 2-357                --                        --
│    └─Empty: 2-358                      [128, 128, 3, 3]          --
│    └─Empty: 2-359                      [128, 128, 3, 3]          --
│    └─Empty: 2-360                      [128]                     --
│    └─Empty: 2-361                      [128]                     --
│    └─BatchNorm2d: 2-362                [16, 128, 32, 32]         --
│    └─Scaler: 2-363                     [16, 128, 32, 32]         --
│    └─ReLU: 2-364                       [16, 128, 32, 32]         --
│    └─Empty: 2-365                      [16, 128, 32, 32]         --
│    └─Clamp: 2-366                      [16, 128, 32, 32]         --
├─Dropout2d: 1-34                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-35         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-367                  [16, 128, 16, 16]         --
│    └─Empty: 2-368                      [16, 128, 16, 16]         --
│    └─Empty: 2-369                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-370         --                        --
│    └─One: 2-371                        [1]                       --
│    └─OutputScale: 2-372                --                        --
│    └─Empty: 2-373                      [128, 128, 3, 3]          --
│    └─Empty: 2-374                      [128, 128, 3, 3]          --
│    └─Empty: 2-375                      [128]                     --
│    └─Empty: 2-376                      [128]                     --
│    └─BatchNorm2d: 2-377                [16, 128, 16, 16]         --
│    └─Scaler: 2-378                     [16, 128, 16, 16]         --
│    └─ReLU: 2-379                       [16, 128, 16, 16]         --
│    └─Empty: 2-380                      [16, 128, 16, 16]         --
│    └─Clamp: 2-381                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-36                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-382         --                        --
│    └─One: 2-383                        [1]                       --
│    └─OutputScale: 2-384                --                        --
│    └─Empty: 2-385                      [128, 128, 1, 1]          --
│    └─Empty: 2-386                      [128, 128, 1, 1]          --
│    └─Empty: 2-387                      [128]                     --
│    └─Empty: 2-388                      [128]                     --
│    └─BatchNorm2d: 2-389                [16, 128, 16, 16]         --
│    └─Scaler: 2-390                     [16, 128, 16, 16]         --
│    └─ReLU: 2-391                       [16, 128, 16, 16]         --
│    └─Empty: 2-392                      [16, 128, 16, 16]         --
│    └─Clamp: 2-393                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-37         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-394                  [16, 128, 16, 16]         --
│    └─Empty: 2-395                      [16, 128, 16, 16]         --
│    └─Empty: 2-396                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-397         --                        --
│    └─One: 2-398                        [1]                       --
│    └─OutputScale: 2-399                --                        --
│    └─Empty: 2-400                      [128, 128, 3, 3]          --
│    └─Empty: 2-401                      [128, 128, 3, 3]          --
│    └─Empty: 2-402                      [128]                     --
│    └─Empty: 2-403                      [128]                     --
│    └─BatchNorm2d: 2-404                [16, 128, 16, 16]         --
│    └─Scaler: 2-405                     [16, 128, 16, 16]         --
│    └─ReLU: 2-406                       [16, 128, 16, 16]         --
│    └─Empty: 2-407                      [16, 128, 16, 16]         --
│    └─Clamp: 2-408                      [16, 128, 16, 16]         --
├─Dropout2d: 1-38                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-409                  [16, 128, 8, 8]           --
│    └─Empty: 2-410                      [16, 128, 8, 8]           --
│    └─Empty: 2-411                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-412         --                        --
│    └─One: 2-413                        [1]                       --
│    └─OutputScale: 2-414                --                        --
│    └─Empty: 2-415                      [128, 128, 3, 3]          --
│    └─Empty: 2-416                      [128, 128, 3, 3]          --
│    └─Empty: 2-417                      [128]                     --
│    └─Empty: 2-418                      [128]                     --
│    └─BatchNorm2d: 2-419                [16, 128, 8, 8]           --
│    └─Scaler: 2-420                     [16, 128, 8, 8]           --
│    └─ReLU: 2-421                       [16, 128, 8, 8]           --
│    └─Empty: 2-422                      [16, 128, 8, 8]           --
│    └─Clamp: 2-423                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-40                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-424         --                        --
│    └─One: 2-425                        [1]                       --
│    └─OutputScale: 2-426                --                        --
│    └─Empty: 2-427                      [16, 128, 1, 1]           --
│    └─Empty: 2-428                      [16, 128, 1, 1]           --
│    └─Empty: 2-429                      [16]                      --
│    └─Empty: 2-430                      [16]                      --
│    └─BatchNorm2d: 2-431                [16, 16, 8, 8]            --
│    └─Scaler: 2-432                     [16, 16, 8, 8]            --
│    └─ReLU: 2-433                       [16, 16, 8, 8]            --
│    └─Empty: 2-434                      [16, 16, 8, 8]            --
│    └─Clamp: 2-435                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-436                  [16, 128, 8, 8]           --
│    └─Empty: 2-437                      [16, 128, 8, 8]           --
│    └─Empty: 2-438                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-439         --                        --
│    └─One: 2-440                        [1]                       --
│    └─OutputScale: 2-441                --                        --
│    └─Empty: 2-442                      [16, 128, 3, 3]           --
│    └─Empty: 2-443                      [16, 128, 3, 3]           --
│    └─Empty: 2-444                      [16]                      --
│    └─Empty: 2-445                      [16]                      --
│    └─BatchNorm2d: 2-446                [16, 16, 8, 8]            --
│    └─Scaler: 2-447                     [16, 16, 8, 8]            --
│    └─ReLU: 2-448                       [16, 16, 8, 8]            --
│    └─Empty: 2-449                      [16, 16, 8, 8]            --
│    └─Clamp: 2-450                      [16, 16, 8, 8]            --
├─Dropout2d: 1-42                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-43                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-451         --                        --
│    └─One: 2-452                        [1]                       --
│    └─OutputScale: 2-453                --                        --
│    └─Empty: 2-454                      [128, 48, 1, 1]           --
│    └─Empty: 2-455                      [128, 48, 1, 1]           --
│    └─Empty: 2-456                      [128]                     --
│    └─Empty: 2-457                      [128]                     --
│    └─BatchNorm2d: 2-458                [16, 128, 64, 64]         --
│    └─Scaler: 2-459                     [16, 128, 64, 64]         --
│    └─ReLU: 2-460                       [16, 128, 64, 64]         --
│    └─Empty: 2-461                      [16, 128, 64, 64]         --
│    └─Clamp: 2-462                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-44                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-463         --                        --
│    └─One: 2-464                        [1]                       --
│    └─OutputScale: 2-465                --                        --
│    └─Empty: 2-466                      [128, 128, 3, 3]          --
│    └─Empty: 2-467                      [128, 128, 3, 3]          --
│    └─Empty: 2-468                      [128]                     --
│    └─Empty: 2-469                      [128]                     --
│    └─BatchNorm2d: 2-470                [16, 128, 64, 64]         --
│    └─Scaler: 2-471                     [16, 128, 64, 64]         --
│    └─ReLU: 2-472                       [16, 128, 64, 64]         --
│    └─Empty: 2-473                      [16, 128, 64, 64]         --
│    └─Clamp: 2-474                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-475                  [16, 128, 32, 32]         --
│    └─Empty: 2-476                      [16, 128, 32, 32]         --
│    └─Empty: 2-477                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-478         --                        --
│    └─One: 2-479                        [1]                       --
│    └─OutputScale: 2-480                --                        --
│    └─Empty: 2-481                      [128, 128, 3, 3]          --
│    └─Empty: 2-482                      [128, 128, 3, 3]          --
│    └─Empty: 2-483                      [128]                     --
│    └─Empty: 2-484                      [128]                     --
│    └─BatchNorm2d: 2-485                [16, 128, 32, 32]         --
│    └─Scaler: 2-486                     [16, 128, 32, 32]         --
│    └─ReLU: 2-487                       [16, 128, 32, 32]         --
│    └─Empty: 2-488                      [16, 128, 32, 32]         --
│    └─Clamp: 2-489                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-46                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-490         --                        --
│    └─One: 2-491                        [1]                       --
│    └─OutputScale: 2-492                --                        --
│    └─Empty: 2-493                      [128, 128, 1, 1]          --
│    └─Empty: 2-494                      [128, 128, 1, 1]          --
│    └─Empty: 2-495                      [128]                     --
│    └─Empty: 2-496                      [128]                     --
│    └─BatchNorm2d: 2-497                [16, 128, 32, 32]         --
│    └─Scaler: 2-498                     [16, 128, 32, 32]         --
│    └─ReLU: 2-499                       [16, 128, 32, 32]         --
│    └─Empty: 2-500                      [16, 128, 32, 32]         --
│    └─Clamp: 2-501                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-502                  [16, 128, 32, 32]         --
│    └─Empty: 2-503                      [16, 128, 32, 32]         --
│    └─Empty: 2-504                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-505         --                        --
│    └─One: 2-506                        [1]                       --
│    └─OutputScale: 2-507                --                        --
│    └─Empty: 2-508                      [128, 128, 3, 3]          --
│    └─Empty: 2-509                      [128, 128, 3, 3]          --
│    └─Empty: 2-510                      [128]                     --
│    └─Empty: 2-511                      [128]                     --
│    └─BatchNorm2d: 2-512                [16, 128, 32, 32]         --
│    └─Scaler: 2-513                     [16, 128, 32, 32]         --
│    └─ReLU: 2-514                       [16, 128, 32, 32]         --
│    └─Empty: 2-515                      [16, 128, 32, 32]         --
│    └─Clamp: 2-516                      [16, 128, 32, 32]         --
├─Dropout2d: 1-48                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-517                  [16, 128, 16, 16]         --
│    └─Empty: 2-518                      [16, 128, 16, 16]         --
│    └─Empty: 2-519                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-520         --                        --
│    └─One: 2-521                        [1]                       --
│    └─OutputScale: 2-522                --                        --
│    └─Empty: 2-523                      [128, 128, 3, 3]          --
│    └─Empty: 2-524                      [128, 128, 3, 3]          --
│    └─Empty: 2-525                      [128]                     --
│    └─Empty: 2-526                      [128]                     --
│    └─BatchNorm2d: 2-527                [16, 128, 16, 16]         --
│    └─Scaler: 2-528                     [16, 128, 16, 16]         --
│    └─ReLU: 2-529                       [16, 128, 16, 16]         --
│    └─Empty: 2-530                      [16, 128, 16, 16]         --
│    └─Clamp: 2-531                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-50                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-532         --                        --
│    └─One: 2-533                        [1]                       --
│    └─OutputScale: 2-534                --                        --
│    └─Empty: 2-535                      [128, 128, 1, 1]          --
│    └─Empty: 2-536                      [128, 128, 1, 1]          --
│    └─Empty: 2-537                      [128]                     --
│    └─Empty: 2-538                      [128]                     --
│    └─BatchNorm2d: 2-539                [16, 128, 16, 16]         --
│    └─Scaler: 2-540                     [16, 128, 16, 16]         --
│    └─ReLU: 2-541                       [16, 128, 16, 16]         --
│    └─Empty: 2-542                      [16, 128, 16, 16]         --
│    └─Clamp: 2-543                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-544                  [16, 128, 16, 16]         --
│    └─Empty: 2-545                      [16, 128, 16, 16]         --
│    └─Empty: 2-546                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-547         --                        --
│    └─One: 2-548                        [1]                       --
│    └─OutputScale: 2-549                --                        --
│    └─Empty: 2-550                      [128, 128, 3, 3]          --
│    └─Empty: 2-551                      [128, 128, 3, 3]          --
│    └─Empty: 2-552                      [128]                     --
│    └─Empty: 2-553                      [128]                     --
│    └─BatchNorm2d: 2-554                [16, 128, 16, 16]         --
│    └─Scaler: 2-555                     [16, 128, 16, 16]         --
│    └─ReLU: 2-556                       [16, 128, 16, 16]         --
│    └─Empty: 2-557                      [16, 128, 16, 16]         --
│    └─Clamp: 2-558                      [16, 128, 16, 16]         --
├─Dropout2d: 1-52                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-53         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-559                  [16, 128, 8, 8]           --
│    └─Empty: 2-560                      [16, 128, 8, 8]           --
│    └─Empty: 2-561                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-562         --                        --
│    └─One: 2-563                        [1]                       --
│    └─OutputScale: 2-564                --                        --
│    └─Empty: 2-565                      [128, 128, 3, 3]          --
│    └─Empty: 2-566                      [128, 128, 3, 3]          --
│    └─Empty: 2-567                      [128]                     --
│    └─Empty: 2-568                      [128]                     --
│    └─BatchNorm2d: 2-569                [16, 128, 8, 8]           --
│    └─Scaler: 2-570                     [16, 128, 8, 8]           --
│    └─ReLU: 2-571                       [16, 128, 8, 8]           --
│    └─Empty: 2-572                      [16, 128, 8, 8]           --
│    └─Clamp: 2-573                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-54                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-574         --                        --
│    └─One: 2-575                        [1]                       --
│    └─OutputScale: 2-576                --                        --
│    └─Empty: 2-577                      [16, 128, 1, 1]           --
│    └─Empty: 2-578                      [16, 128, 1, 1]           --
│    └─Empty: 2-579                      [16]                      --
│    └─Empty: 2-580                      [16]                      --
│    └─BatchNorm2d: 2-581                [16, 16, 8, 8]            --
│    └─Scaler: 2-582                     [16, 16, 8, 8]            --
│    └─ReLU: 2-583                       [16, 16, 8, 8]            --
│    └─Empty: 2-584                      [16, 16, 8, 8]            --
│    └─Clamp: 2-585                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-586                  [16, 128, 8, 8]           --
│    └─Empty: 2-587                      [16, 128, 8, 8]           --
│    └─Empty: 2-588                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-589         --                        --
│    └─One: 2-590                        [1]                       --
│    └─OutputScale: 2-591                --                        --
│    └─Empty: 2-592                      [16, 128, 3, 3]           --
│    └─Empty: 2-593                      [16, 128, 3, 3]           --
│    └─Empty: 2-594                      [16]                      --
│    └─Empty: 2-595                      [16]                      --
│    └─BatchNorm2d: 2-596                [16, 16, 8, 8]            --
│    └─Scaler: 2-597                     [16, 16, 8, 8]            --
│    └─ReLU: 2-598                       [16, 16, 8, 8]            --
│    └─Empty: 2-599                      [16, 16, 8, 8]            --
│    └─Clamp: 2-600                      [16, 16, 8, 8]            --
├─Dropout2d: 1-56                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-57                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-601         --                        --
│    └─One: 2-602                        [1]                       --
│    └─OutputScale: 2-603                --                        --
│    └─Empty: 2-604                      [128, 48, 1, 1]           --
│    └─Empty: 2-605                      [128, 48, 1, 1]           --
│    └─Empty: 2-606                      [128]                     --
│    └─Empty: 2-607                      [128]                     --
│    └─BatchNorm2d: 2-608                [16, 128, 64, 64]         --
│    └─Scaler: 2-609                     [16, 128, 64, 64]         --
│    └─ReLU: 2-610                       [16, 128, 64, 64]         --
│    └─Empty: 2-611                      [16, 128, 64, 64]         --
│    └─Clamp: 2-612                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-58                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-613         --                        --
│    └─One: 2-614                        [1]                       --
│    └─OutputScale: 2-615                --                        --
│    └─Empty: 2-616                      [128, 128, 3, 3]          --
│    └─Empty: 2-617                      [128, 128, 3, 3]          --
│    └─Empty: 2-618                      [128]                     --
│    └─Empty: 2-619                      [128]                     --
│    └─BatchNorm2d: 2-620                [16, 128, 64, 64]         --
│    └─Scaler: 2-621                     [16, 128, 64, 64]         --
│    └─ReLU: 2-622                       [16, 128, 64, 64]         --
│    └─Empty: 2-623                      [16, 128, 64, 64]         --
│    └─Clamp: 2-624                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-59         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-625                  [16, 128, 32, 32]         --
│    └─Empty: 2-626                      [16, 128, 32, 32]         --
│    └─Empty: 2-627                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-628         --                        --
│    └─One: 2-629                        [1]                       --
│    └─OutputScale: 2-630                --                        --
│    └─Empty: 2-631                      [128, 128, 3, 3]          --
│    └─Empty: 2-632                      [128, 128, 3, 3]          --
│    └─Empty: 2-633                      [128]                     --
│    └─Empty: 2-634                      [128]                     --
│    └─BatchNorm2d: 2-635                [16, 128, 32, 32]         --
│    └─Scaler: 2-636                     [16, 128, 32, 32]         --
│    └─ReLU: 2-637                       [16, 128, 32, 32]         --
│    └─Empty: 2-638                      [16, 128, 32, 32]         --
│    └─Clamp: 2-639                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-60                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-640         --                        --
│    └─One: 2-641                        [1]                       --
│    └─OutputScale: 2-642                --                        --
│    └─Empty: 2-643                      [128, 128, 1, 1]          --
│    └─Empty: 2-644                      [128, 128, 1, 1]          --
│    └─Empty: 2-645                      [128]                     --
│    └─Empty: 2-646                      [128]                     --
│    └─BatchNorm2d: 2-647                [16, 128, 32, 32]         --
│    └─Scaler: 2-648                     [16, 128, 32, 32]         --
│    └─ReLU: 2-649                       [16, 128, 32, 32]         --
│    └─Empty: 2-650                      [16, 128, 32, 32]         --
│    └─Clamp: 2-651                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-61         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-652                  [16, 128, 32, 32]         --
│    └─Empty: 2-653                      [16, 128, 32, 32]         --
│    └─Empty: 2-654                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-655         --                        --
│    └─One: 2-656                        [1]                       --
│    └─OutputScale: 2-657                --                        --
│    └─Empty: 2-658                      [128, 128, 3, 3]          --
│    └─Empty: 2-659                      [128, 128, 3, 3]          --
│    └─Empty: 2-660                      [128]                     --
│    └─Empty: 2-661                      [128]                     --
│    └─BatchNorm2d: 2-662                [16, 128, 32, 32]         --
│    └─Scaler: 2-663                     [16, 128, 32, 32]         --
│    └─ReLU: 2-664                       [16, 128, 32, 32]         --
│    └─Empty: 2-665                      [16, 128, 32, 32]         --
│    └─Clamp: 2-666                      [16, 128, 32, 32]         --
├─Dropout2d: 1-62                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-667                  [16, 128, 16, 16]         --
│    └─Empty: 2-668                      [16, 128, 16, 16]         --
│    └─Empty: 2-669                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-670         --                        --
│    └─One: 2-671                        [1]                       --
│    └─OutputScale: 2-672                --                        --
│    └─Empty: 2-673                      [128, 128, 3, 3]          --
│    └─Empty: 2-674                      [128, 128, 3, 3]          --
│    └─Empty: 2-675                      [128]                     --
│    └─Empty: 2-676                      [128]                     --
│    └─BatchNorm2d: 2-677                [16, 128, 16, 16]         --
│    └─Scaler: 2-678                     [16, 128, 16, 16]         --
│    └─ReLU: 2-679                       [16, 128, 16, 16]         --
│    └─Empty: 2-680                      [16, 128, 16, 16]         --
│    └─Clamp: 2-681                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-64                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-682         --                        --
│    └─One: 2-683                        [1]                       --
│    └─OutputScale: 2-684                --                        --
│    └─Empty: 2-685                      [128, 128, 1, 1]          --
│    └─Empty: 2-686                      [128, 128, 1, 1]          --
│    └─Empty: 2-687                      [128]                     --
│    └─Empty: 2-688                      [128]                     --
│    └─BatchNorm2d: 2-689                [16, 128, 16, 16]         --
│    └─Scaler: 2-690                     [16, 128, 16, 16]         --
│    └─ReLU: 2-691                       [16, 128, 16, 16]         --
│    └─Empty: 2-692                      [16, 128, 16, 16]         --
│    └─Clamp: 2-693                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-694                  [16, 128, 16, 16]         --
│    └─Empty: 2-695                      [16, 128, 16, 16]         --
│    └─Empty: 2-696                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-697         --                        --
│    └─One: 2-698                        [1]                       --
│    └─OutputScale: 2-699                --                        --
│    └─Empty: 2-700                      [128, 128, 3, 3]          --
│    └─Empty: 2-701                      [128, 128, 3, 3]          --
│    └─Empty: 2-702                      [128]                     --
│    └─Empty: 2-703                      [128]                     --
│    └─BatchNorm2d: 2-704                [16, 128, 16, 16]         --
│    └─Scaler: 2-705                     [16, 128, 16, 16]         --
│    └─ReLU: 2-706                       [16, 128, 16, 16]         --
│    └─Empty: 2-707                      [16, 128, 16, 16]         --
│    └─Clamp: 2-708                      [16, 128, 16, 16]         --
├─Dropout2d: 1-66                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-67         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-709                  [16, 128, 8, 8]           --
│    └─Empty: 2-710                      [16, 128, 8, 8]           --
│    └─Empty: 2-711                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-712         --                        --
│    └─One: 2-713                        [1]                       --
│    └─OutputScale: 2-714                --                        --
│    └─Empty: 2-715                      [128, 128, 3, 3]          --
│    └─Empty: 2-716                      [128, 128, 3, 3]          --
│    └─Empty: 2-717                      [128]                     --
│    └─Empty: 2-718                      [128]                     --
│    └─BatchNorm2d: 2-719                [16, 128, 8, 8]           --
│    └─Scaler: 2-720                     [16, 128, 8, 8]           --
│    └─ReLU: 2-721                       [16, 128, 8, 8]           --
│    └─Empty: 2-722                      [16, 128, 8, 8]           --
│    └─Clamp: 2-723                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-68                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-724         --                        --
│    └─One: 2-725                        [1]                       --
│    └─OutputScale: 2-726                --                        --
│    └─Empty: 2-727                      [16, 128, 1, 1]           --
│    └─Empty: 2-728                      [16, 128, 1, 1]           --
│    └─Empty: 2-729                      [16]                      --
│    └─Empty: 2-730                      [16]                      --
│    └─BatchNorm2d: 2-731                [16, 16, 8, 8]            --
│    └─Scaler: 2-732                     [16, 16, 8, 8]            --
│    └─ReLU: 2-733                       [16, 16, 8, 8]            --
│    └─Empty: 2-734                      [16, 16, 8, 8]            --
│    └─Clamp: 2-735                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-69         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-736                  [16, 128, 8, 8]           --
│    └─Empty: 2-737                      [16, 128, 8, 8]           --
│    └─Empty: 2-738                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-739         --                        --
│    └─One: 2-740                        [1]                       --
│    └─OutputScale: 2-741                --                        --
│    └─Empty: 2-742                      [16, 128, 3, 3]           --
│    └─Empty: 2-743                      [16, 128, 3, 3]           --
│    └─Empty: 2-744                      [16]                      --
│    └─Empty: 2-745                      [16]                      --
│    └─BatchNorm2d: 2-746                [16, 16, 8, 8]            --
│    └─Scaler: 2-747                     [16, 16, 8, 8]            --
│    └─ReLU: 2-748                       [16, 16, 8, 8]            --
│    └─Empty: 2-749                      [16, 16, 8, 8]            --
│    └─Clamp: 2-750                      [16, 16, 8, 8]            --
├─Dropout2d: 1-70                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-71                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-751         --                        --
│    └─One: 2-752                        [1]                       --
│    └─OutputScale: 2-753                --                        --
│    └─Empty: 2-754                      [128, 48, 1, 1]           --
│    └─Empty: 2-755                      [128, 48, 1, 1]           --
│    └─Empty: 2-756                      [128]                     --
│    └─Empty: 2-757                      [128]                     --
│    └─BatchNorm2d: 2-758                [16, 128, 64, 64]         --
│    └─Scaler: 2-759                     [16, 128, 64, 64]         --
│    └─ReLU: 2-760                       [16, 128, 64, 64]         --
│    └─Empty: 2-761                      [16, 128, 64, 64]         --
│    └─Clamp: 2-762                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-72                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-763         --                        --
│    └─One: 2-764                        [1]                       --
│    └─OutputScale: 2-765                --                        --
│    └─Empty: 2-766                      [128, 128, 3, 3]          --
│    └─Empty: 2-767                      [128, 128, 3, 3]          --
│    └─Empty: 2-768                      [128]                     --
│    └─Empty: 2-769                      [128]                     --
│    └─BatchNorm2d: 2-770                [16, 128, 64, 64]         --
│    └─Scaler: 2-771                     [16, 128, 64, 64]         --
│    └─ReLU: 2-772                       [16, 128, 64, 64]         --
│    └─Empty: 2-773                      [16, 128, 64, 64]         --
│    └─Clamp: 2-774                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-775                  [16, 128, 32, 32]         --
│    └─Empty: 2-776                      [16, 128, 32, 32]         --
│    └─Empty: 2-777                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-778         --                        --
│    └─One: 2-779                        [1]                       --
│    └─OutputScale: 2-780                --                        --
│    └─Empty: 2-781                      [128, 128, 3, 3]          --
│    └─Empty: 2-782                      [128, 128, 3, 3]          --
│    └─Empty: 2-783                      [128]                     --
│    └─Empty: 2-784                      [128]                     --
│    └─BatchNorm2d: 2-785                [16, 128, 32, 32]         --
│    └─Scaler: 2-786                     [16, 128, 32, 32]         --
│    └─ReLU: 2-787                       [16, 128, 32, 32]         --
│    └─Empty: 2-788                      [16, 128, 32, 32]         --
│    └─Clamp: 2-789                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-74                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-790         --                        --
│    └─One: 2-791                        [1]                       --
│    └─OutputScale: 2-792                --                        --
│    └─Empty: 2-793                      [128, 128, 1, 1]          --
│    └─Empty: 2-794                      [128, 128, 1, 1]          --
│    └─Empty: 2-795                      [128]                     --
│    └─Empty: 2-796                      [128]                     --
│    └─BatchNorm2d: 2-797                [16, 128, 32, 32]         --
│    └─Scaler: 2-798                     [16, 128, 32, 32]         --
│    └─ReLU: 2-799                       [16, 128, 32, 32]         --
│    └─Empty: 2-800                      [16, 128, 32, 32]         --
│    └─Clamp: 2-801                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-802                  [16, 128, 32, 32]         --
│    └─Empty: 2-803                      [16, 128, 32, 32]         --
│    └─Empty: 2-804                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-805         --                        --
│    └─One: 2-806                        [1]                       --
│    └─OutputScale: 2-807                --                        --
│    └─Empty: 2-808                      [128, 128, 3, 3]          --
│    └─Empty: 2-809                      [128, 128, 3, 3]          --
│    └─Empty: 2-810                      [128]                     --
│    └─Empty: 2-811                      [128]                     --
│    └─BatchNorm2d: 2-812                [16, 128, 32, 32]         --
│    └─Scaler: 2-813                     [16, 128, 32, 32]         --
│    └─ReLU: 2-814                       [16, 128, 32, 32]         --
│    └─Empty: 2-815                      [16, 128, 32, 32]         --
│    └─Clamp: 2-816                      [16, 128, 32, 32]         --
├─Dropout2d: 1-76                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-817                  [16, 128, 16, 16]         --
│    └─Empty: 2-818                      [16, 128, 16, 16]         --
│    └─Empty: 2-819                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-820         --                        --
│    └─One: 2-821                        [1]                       --
│    └─OutputScale: 2-822                --                        --
│    └─Empty: 2-823                      [128, 128, 3, 3]          --
│    └─Empty: 2-824                      [128, 128, 3, 3]          --
│    └─Empty: 2-825                      [128]                     --
│    └─Empty: 2-826                      [128]                     --
│    └─BatchNorm2d: 2-827                [16, 128, 16, 16]         --
│    └─Scaler: 2-828                     [16, 128, 16, 16]         --
│    └─ReLU: 2-829                       [16, 128, 16, 16]         --
│    └─Empty: 2-830                      [16, 128, 16, 16]         --
│    └─Clamp: 2-831                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-78                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-832         --                        --
│    └─One: 2-833                        [1]                       --
│    └─OutputScale: 2-834                --                        --
│    └─Empty: 2-835                      [128, 128, 1, 1]          --
│    └─Empty: 2-836                      [128, 128, 1, 1]          --
│    └─Empty: 2-837                      [128]                     --
│    └─Empty: 2-838                      [128]                     --
│    └─BatchNorm2d: 2-839                [16, 128, 16, 16]         --
│    └─Scaler: 2-840                     [16, 128, 16, 16]         --
│    └─ReLU: 2-841                       [16, 128, 16, 16]         --
│    └─Empty: 2-842                      [16, 128, 16, 16]         --
│    └─Clamp: 2-843                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-844                  [16, 128, 16, 16]         --
│    └─Empty: 2-845                      [16, 128, 16, 16]         --
│    └─Empty: 2-846                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-847         --                        --
│    └─One: 2-848                        [1]                       --
│    └─OutputScale: 2-849                --                        --
│    └─Empty: 2-850                      [128, 128, 3, 3]          --
│    └─Empty: 2-851                      [128, 128, 3, 3]          --
│    └─Empty: 2-852                      [128]                     --
│    └─Empty: 2-853                      [128]                     --
│    └─BatchNorm2d: 2-854                [16, 128, 16, 16]         --
│    └─Scaler: 2-855                     [16, 128, 16, 16]         --
│    └─ReLU: 2-856                       [16, 128, 16, 16]         --
│    └─Empty: 2-857                      [16, 128, 16, 16]         --
│    └─Clamp: 2-858                      [16, 128, 16, 16]         --
├─Dropout2d: 1-80                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-859                  [16, 128, 8, 8]           --
│    └─Empty: 2-860                      [16, 128, 8, 8]           --
│    └─Empty: 2-861                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-862         --                        --
│    └─One: 2-863                        [1]                       --
│    └─OutputScale: 2-864                --                        --
│    └─Empty: 2-865                      [128, 128, 3, 3]          --
│    └─Empty: 2-866                      [128, 128, 3, 3]          --
│    └─Empty: 2-867                      [128]                     --
│    └─Empty: 2-868                      [128]                     --
│    └─BatchNorm2d: 2-869                [16, 128, 8, 8]           --
│    └─Scaler: 2-870                     [16, 128, 8, 8]           --
│    └─ReLU: 2-871                       [16, 128, 8, 8]           --
│    └─Empty: 2-872                      [16, 128, 8, 8]           --
│    └─Clamp: 2-873                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-82                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-874         --                        --
│    └─One: 2-875                        [1]                       --
│    └─OutputScale: 2-876                --                        --
│    └─Empty: 2-877                      [16, 128, 1, 1]           --
│    └─Empty: 2-878                      [16, 128, 1, 1]           --
│    └─Empty: 2-879                      [16]                      --
│    └─Empty: 2-880                      [16]                      --
│    └─BatchNorm2d: 2-881                [16, 16, 8, 8]            --
│    └─Scaler: 2-882                     [16, 16, 8, 8]            --
│    └─ReLU: 2-883                       [16, 16, 8, 8]            --
│    └─Empty: 2-884                      [16, 16, 8, 8]            --
│    └─Clamp: 2-885                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-886                  [16, 128, 8, 8]           --
│    └─Empty: 2-887                      [16, 128, 8, 8]           --
│    └─Empty: 2-888                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-889         --                        --
│    └─One: 2-890                        [1]                       --
│    └─OutputScale: 2-891                --                        --
│    └─Empty: 2-892                      [16, 128, 3, 3]           --
│    └─Empty: 2-893                      [16, 128, 3, 3]           --
│    └─Empty: 2-894                      [16]                      --
│    └─Empty: 2-895                      [16]                      --
│    └─BatchNorm2d: 2-896                [16, 16, 8, 8]            --
│    └─Scaler: 2-897                     [16, 16, 8, 8]            --
│    └─ReLU: 2-898                       [16, 16, 8, 8]            --
│    └─Empty: 2-899                      [16, 16, 8, 8]            --
│    └─Clamp: 2-900                      [16, 16, 8, 8]            --
├─Dropout2d: 1-84                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-85                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-901         --                        --
│    └─One: 2-902                        [1]                       --
│    └─OutputScale: 2-903                --                        --
│    └─Empty: 2-904                      [128, 48, 1, 1]           --
│    └─Empty: 2-905                      [128, 48, 1, 1]           --
│    └─Empty: 2-906                      [128]                     --
│    └─Empty: 2-907                      [128]                     --
│    └─BatchNorm2d: 2-908                [16, 128, 64, 64]         --
│    └─Scaler: 2-909                     [16, 128, 64, 64]         --
│    └─ReLU: 2-910                       [16, 128, 64, 64]         --
│    └─Empty: 2-911                      [16, 128, 64, 64]         --
│    └─Clamp: 2-912                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-86                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-913         --                        --
│    └─One: 2-914                        [1]                       --
│    └─OutputScale: 2-915                --                        --
│    └─Empty: 2-916                      [128, 128, 3, 3]          --
│    └─Empty: 2-917                      [128, 128, 3, 3]          --
│    └─Empty: 2-918                      [128]                     --
│    └─Empty: 2-919                      [128]                     --
│    └─BatchNorm2d: 2-920                [16, 128, 64, 64]         --
│    └─Scaler: 2-921                     [16, 128, 64, 64]         --
│    └─ReLU: 2-922                       [16, 128, 64, 64]         --
│    └─Empty: 2-923                      [16, 128, 64, 64]         --
│    └─Clamp: 2-924                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-87         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-925                  [16, 128, 32, 32]         --
│    └─Empty: 2-926                      [16, 128, 32, 32]         --
│    └─Empty: 2-927                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-928         --                        --
│    └─One: 2-929                        [1]                       --
│    └─OutputScale: 2-930                --                        --
│    └─Empty: 2-931                      [128, 128, 3, 3]          --
│    └─Empty: 2-932                      [128, 128, 3, 3]          --
│    └─Empty: 2-933                      [128]                     --
│    └─Empty: 2-934                      [128]                     --
│    └─BatchNorm2d: 2-935                [16, 128, 32, 32]         --
│    └─Scaler: 2-936                     [16, 128, 32, 32]         --
│    └─ReLU: 2-937                       [16, 128, 32, 32]         --
│    └─Empty: 2-938                      [16, 128, 32, 32]         --
│    └─Clamp: 2-939                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-88                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-940         --                        --
│    └─One: 2-941                        [1]                       --
│    └─OutputScale: 2-942                --                        --
│    └─Empty: 2-943                      [128, 128, 1, 1]          --
│    └─Empty: 2-944                      [128, 128, 1, 1]          --
│    └─Empty: 2-945                      [128]                     --
│    └─Empty: 2-946                      [128]                     --
│    └─BatchNorm2d: 2-947                [16, 128, 32, 32]         --
│    └─Scaler: 2-948                     [16, 128, 32, 32]         --
│    └─ReLU: 2-949                       [16, 128, 32, 32]         --
│    └─Empty: 2-950                      [16, 128, 32, 32]         --
│    └─Clamp: 2-951                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-952                  [16, 128, 32, 32]         --
│    └─Empty: 2-953                      [16, 128, 32, 32]         --
│    └─Empty: 2-954                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-955         --                        --
│    └─One: 2-956                        [1]                       --
│    └─OutputScale: 2-957                --                        --
│    └─Empty: 2-958                      [128, 128, 3, 3]          --
│    └─Empty: 2-959                      [128, 128, 3, 3]          --
│    └─Empty: 2-960                      [128]                     --
│    └─Empty: 2-961                      [128]                     --
│    └─BatchNorm2d: 2-962                [16, 128, 32, 32]         --
│    └─Scaler: 2-963                     [16, 128, 32, 32]         --
│    └─ReLU: 2-964                       [16, 128, 32, 32]         --
│    └─Empty: 2-965                      [16, 128, 32, 32]         --
│    └─Clamp: 2-966                      [16, 128, 32, 32]         --
├─Dropout2d: 1-90                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-91         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-967                  [16, 128, 16, 16]         --
│    └─Empty: 2-968                      [16, 128, 16, 16]         --
│    └─Empty: 2-969                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-970         --                        --
│    └─One: 2-971                        [1]                       --
│    └─OutputScale: 2-972                --                        --
│    └─Empty: 2-973                      [128, 128, 3, 3]          --
│    └─Empty: 2-974                      [128, 128, 3, 3]          --
│    └─Empty: 2-975                      [128]                     --
│    └─Empty: 2-976                      [128]                     --
│    └─BatchNorm2d: 2-977                [16, 128, 16, 16]         --
│    └─Scaler: 2-978                     [16, 128, 16, 16]         --
│    └─ReLU: 2-979                       [16, 128, 16, 16]         --
│    └─Empty: 2-980                      [16, 128, 16, 16]         --
│    └─Clamp: 2-981                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-92                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-982         --                        --
│    └─One: 2-983                        [1]                       --
│    └─OutputScale: 2-984                --                        --
│    └─Empty: 2-985                      [128, 128, 1, 1]          --
│    └─Empty: 2-986                      [128, 128, 1, 1]          --
│    └─Empty: 2-987                      [128]                     --
│    └─Empty: 2-988                      [128]                     --
│    └─BatchNorm2d: 2-989                [16, 128, 16, 16]         --
│    └─Scaler: 2-990                     [16, 128, 16, 16]         --
│    └─ReLU: 2-991                       [16, 128, 16, 16]         --
│    └─Empty: 2-992                      [16, 128, 16, 16]         --
│    └─Clamp: 2-993                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-93         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-994                  [16, 128, 16, 16]         --
│    └─Empty: 2-995                      [16, 128, 16, 16]         --
│    └─Empty: 2-996                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-997         --                        --
│    └─One: 2-998                        [1]                       --
│    └─OutputScale: 2-999                --                        --
│    └─Empty: 2-1000                     [128, 128, 3, 3]          --
│    └─Empty: 2-1001                     [128, 128, 3, 3]          --
│    └─Empty: 2-1002                     [128]                     --
│    └─Empty: 2-1003                     [128]                     --
│    └─BatchNorm2d: 2-1004               [16, 128, 16, 16]         --
│    └─Scaler: 2-1005                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1006                      [16, 128, 16, 16]         --
│    └─Empty: 2-1007                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1008                     [16, 128, 16, 16]         --
├─Dropout2d: 1-94                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1009                 [16, 128, 8, 8]           --
│    └─Empty: 2-1010                     [16, 128, 8, 8]           --
│    └─Empty: 2-1011                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1012        --                        --
│    └─One: 2-1013                       [1]                       --
│    └─OutputScale: 2-1014               --                        --
│    └─Empty: 2-1015                     [128, 128, 3, 3]          --
│    └─Empty: 2-1016                     [128, 128, 3, 3]          --
│    └─Empty: 2-1017                     [128]                     --
│    └─Empty: 2-1018                     [128]                     --
│    └─BatchNorm2d: 2-1019               [16, 128, 8, 8]           --
│    └─Scaler: 2-1020                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1021                      [16, 128, 8, 8]           --
│    └─Empty: 2-1022                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1023                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-96                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1024        --                        --
│    └─One: 2-1025                       [1]                       --
│    └─OutputScale: 2-1026               --                        --
│    └─Empty: 2-1027                     [16, 128, 1, 1]           --
│    └─Empty: 2-1028                     [16, 128, 1, 1]           --
│    └─Empty: 2-1029                     [16]                      --
│    └─Empty: 2-1030                     [16]                      --
│    └─BatchNorm2d: 2-1031               [16, 16, 8, 8]            --
│    └─Scaler: 2-1032                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1033                      [16, 16, 8, 8]            --
│    └─Empty: 2-1034                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1035                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1036                 [16, 128, 8, 8]           --
│    └─Empty: 2-1037                     [16, 128, 8, 8]           --
│    └─Empty: 2-1038                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1039        --                        --
│    └─One: 2-1040                       [1]                       --
│    └─OutputScale: 2-1041               --                        --
│    └─Empty: 2-1042                     [16, 128, 3, 3]           --
│    └─Empty: 2-1043                     [16, 128, 3, 3]           --
│    └─Empty: 2-1044                     [16]                      --
│    └─Empty: 2-1045                     [16]                      --
│    └─BatchNorm2d: 2-1046               [16, 16, 8, 8]            --
│    └─Scaler: 2-1047                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1048                      [16, 16, 8, 8]            --
│    └─Empty: 2-1049                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1050                     [16, 16, 8, 8]            --
├─Dropout2d: 1-98                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-99                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1051        --                        --
│    └─One: 2-1052                       [1]                       --
│    └─OutputScale: 2-1053               --                        --
│    └─Empty: 2-1054                     [128, 48, 1, 1]           --
│    └─Empty: 2-1055                     [128, 48, 1, 1]           --
│    └─Empty: 2-1056                     [128]                     --
│    └─Empty: 2-1057                     [128]                     --
│    └─BatchNorm2d: 2-1058               [16, 128, 64, 64]         --
│    └─Scaler: 2-1059                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1060                      [16, 128, 64, 64]         --
│    └─Empty: 2-1061                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1062                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-100               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1063        --                        --
│    └─One: 2-1064                       [1]                       --
│    └─OutputScale: 2-1065               --                        --
│    └─Empty: 2-1066                     [128, 128, 3, 3]          --
│    └─Empty: 2-1067                     [128, 128, 3, 3]          --
│    └─Empty: 2-1068                     [128]                     --
│    └─Empty: 2-1069                     [128]                     --
│    └─BatchNorm2d: 2-1070               [16, 128, 64, 64]         --
│    └─Scaler: 2-1071                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1072                      [16, 128, 64, 64]         --
│    └─Empty: 2-1073                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1074                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-101        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1075                 [16, 128, 32, 32]         --
│    └─Empty: 2-1076                     [16, 128, 32, 32]         --
│    └─Empty: 2-1077                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1078        --                        --
│    └─One: 2-1079                       [1]                       --
│    └─OutputScale: 2-1080               --                        --
│    └─Empty: 2-1081                     [128, 128, 3, 3]          --
│    └─Empty: 2-1082                     [128, 128, 3, 3]          --
│    └─Empty: 2-1083                     [128]                     --
│    └─Empty: 2-1084                     [128]                     --
│    └─BatchNorm2d: 2-1085               [16, 128, 32, 32]         --
│    └─Scaler: 2-1086                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1087                      [16, 128, 32, 32]         --
│    └─Empty: 2-1088                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1089                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-102               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1090        --                        --
│    └─One: 2-1091                       [1]                       --
│    └─OutputScale: 2-1092               --                        --
│    └─Empty: 2-1093                     [128, 128, 1, 1]          --
│    └─Empty: 2-1094                     [128, 128, 1, 1]          --
│    └─Empty: 2-1095                     [128]                     --
│    └─Empty: 2-1096                     [128]                     --
│    └─BatchNorm2d: 2-1097               [16, 128, 32, 32]         --
│    └─Scaler: 2-1098                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1099                      [16, 128, 32, 32]         --
│    └─Empty: 2-1100                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1101                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1102                 [16, 128, 32, 32]         --
│    └─Empty: 2-1103                     [16, 128, 32, 32]         --
│    └─Empty: 2-1104                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1105        --                        --
│    └─One: 2-1106                       [1]                       --
│    └─OutputScale: 2-1107               --                        --
│    └─Empty: 2-1108                     [128, 128, 3, 3]          --
│    └─Empty: 2-1109                     [128, 128, 3, 3]          --
│    └─Empty: 2-1110                     [128]                     --
│    └─Empty: 2-1111                     [128]                     --
│    └─BatchNorm2d: 2-1112               [16, 128, 32, 32]         --
│    └─Scaler: 2-1113                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1114                      [16, 128, 32, 32]         --
│    └─Empty: 2-1115                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1116                     [16, 128, 32, 32]         --
├─Dropout2d: 1-104                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-105        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1117                 [16, 128, 16, 16]         --
│    └─Empty: 2-1118                     [16, 128, 16, 16]         --
│    └─Empty: 2-1119                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1120        --                        --
│    └─One: 2-1121                       [1]                       --
│    └─OutputScale: 2-1122               --                        --
│    └─Empty: 2-1123                     [128, 128, 3, 3]          --
│    └─Empty: 2-1124                     [128, 128, 3, 3]          --
│    └─Empty: 2-1125                     [128]                     --
│    └─Empty: 2-1126                     [128]                     --
│    └─BatchNorm2d: 2-1127               [16, 128, 16, 16]         --
│    └─Scaler: 2-1128                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1129                      [16, 128, 16, 16]         --
│    └─Empty: 2-1130                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1131                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-106               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1132        --                        --
│    └─One: 2-1133                       [1]                       --
│    └─OutputScale: 2-1134               --                        --
│    └─Empty: 2-1135                     [128, 128, 1, 1]          --
│    └─Empty: 2-1136                     [128, 128, 1, 1]          --
│    └─Empty: 2-1137                     [128]                     --
│    └─Empty: 2-1138                     [128]                     --
│    └─BatchNorm2d: 2-1139               [16, 128, 16, 16]         --
│    └─Scaler: 2-1140                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1141                      [16, 128, 16, 16]         --
│    └─Empty: 2-1142                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1143                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1144                 [16, 128, 16, 16]         --
│    └─Empty: 2-1145                     [16, 128, 16, 16]         --
│    └─Empty: 2-1146                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1147        --                        --
│    └─One: 2-1148                       [1]                       --
│    └─OutputScale: 2-1149               --                        --
│    └─Empty: 2-1150                     [128, 128, 3, 3]          --
│    └─Empty: 2-1151                     [128, 128, 3, 3]          --
│    └─Empty: 2-1152                     [128]                     --
│    └─Empty: 2-1153                     [128]                     --
│    └─BatchNorm2d: 2-1154               [16, 128, 16, 16]         --
│    └─Scaler: 2-1155                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1156                      [16, 128, 16, 16]         --
│    └─Empty: 2-1157                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1158                     [16, 128, 16, 16]         --
├─Dropout2d: 1-108                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1159                 [16, 128, 8, 8]           --
│    └─Empty: 2-1160                     [16, 128, 8, 8]           --
│    └─Empty: 2-1161                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1162        --                        --
│    └─One: 2-1163                       [1]                       --
│    └─OutputScale: 2-1164               --                        --
│    └─Empty: 2-1165                     [128, 128, 3, 3]          --
│    └─Empty: 2-1166                     [128, 128, 3, 3]          --
│    └─Empty: 2-1167                     [128]                     --
│    └─Empty: 2-1168                     [128]                     --
│    └─BatchNorm2d: 2-1169               [16, 128, 8, 8]           --
│    └─Scaler: 2-1170                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1171                      [16, 128, 8, 8]           --
│    └─Empty: 2-1172                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1173                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-110               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1174        --                        --
│    └─One: 2-1175                       [1]                       --
│    └─OutputScale: 2-1176               --                        --
│    └─Empty: 2-1177                     [16, 128, 1, 1]           --
│    └─Empty: 2-1178                     [16, 128, 1, 1]           --
│    └─Empty: 2-1179                     [16]                      --
│    └─Empty: 2-1180                     [16]                      --
│    └─BatchNorm2d: 2-1181               [16, 16, 8, 8]            --
│    └─Scaler: 2-1182                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1183                      [16, 16, 8, 8]            --
│    └─Empty: 2-1184                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1185                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1186                 [16, 128, 8, 8]           --
│    └─Empty: 2-1187                     [16, 128, 8, 8]           --
│    └─Empty: 2-1188                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1189        --                        --
│    └─One: 2-1190                       [1]                       --
│    └─OutputScale: 2-1191               --                        --
│    └─Empty: 2-1192                     [16, 128, 3, 3]           --
│    └─Empty: 2-1193                     [16, 128, 3, 3]           --
│    └─Empty: 2-1194                     [16]                      --
│    └─Empty: 2-1195                     [16]                      --
│    └─BatchNorm2d: 2-1196               [16, 16, 8, 8]            --
│    └─Scaler: 2-1197                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1198                      [16, 16, 8, 8]            --
│    └─Empty: 2-1199                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1200                     [16, 16, 8, 8]            --
├─Dropout2d: 1-112                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-113               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1201        --                        --
│    └─One: 2-1202                       [1]                       --
│    └─OutputScale: 2-1203               --                        --
│    └─Empty: 2-1204                     [128, 48, 1, 1]           --
│    └─Empty: 2-1205                     [128, 48, 1, 1]           --
│    └─Empty: 2-1206                     [128]                     --
│    └─Empty: 2-1207                     [128]                     --
│    └─BatchNorm2d: 2-1208               [16, 128, 64, 64]         --
│    └─Scaler: 2-1209                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1210                      [16, 128, 64, 64]         --
│    └─Empty: 2-1211                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1212                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-114               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1213        --                        --
│    └─One: 2-1214                       [1]                       --
│    └─OutputScale: 2-1215               --                        --
│    └─Empty: 2-1216                     [128, 128, 3, 3]          --
│    └─Empty: 2-1217                     [128, 128, 3, 3]          --
│    └─Empty: 2-1218                     [128]                     --
│    └─Empty: 2-1219                     [128]                     --
│    └─BatchNorm2d: 2-1220               [16, 128, 64, 64]         --
│    └─Scaler: 2-1221                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1222                      [16, 128, 64, 64]         --
│    └─Empty: 2-1223                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1224                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-115        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1225                 [16, 128, 32, 32]         --
│    └─Empty: 2-1226                     [16, 128, 32, 32]         --
│    └─Empty: 2-1227                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1228        --                        --
│    └─One: 2-1229                       [1]                       --
│    └─OutputScale: 2-1230               --                        --
│    └─Empty: 2-1231                     [128, 128, 3, 3]          --
│    └─Empty: 2-1232                     [128, 128, 3, 3]          --
│    └─Empty: 2-1233                     [128]                     --
│    └─Empty: 2-1234                     [128]                     --
│    └─BatchNorm2d: 2-1235               [16, 128, 32, 32]         --
│    └─Scaler: 2-1236                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1237                      [16, 128, 32, 32]         --
│    └─Empty: 2-1238                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1239                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-116               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1240        --                        --
│    └─One: 2-1241                       [1]                       --
│    └─OutputScale: 2-1242               --                        --
│    └─Empty: 2-1243                     [128, 128, 1, 1]          --
│    └─Empty: 2-1244                     [128, 128, 1, 1]          --
│    └─Empty: 2-1245                     [128]                     --
│    └─Empty: 2-1246                     [128]                     --
│    └─BatchNorm2d: 2-1247               [16, 128, 32, 32]         --
│    └─Scaler: 2-1248                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1249                      [16, 128, 32, 32]         --
│    └─Empty: 2-1250                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1251                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1252                 [16, 128, 32, 32]         --
│    └─Empty: 2-1253                     [16, 128, 32, 32]         --
│    └─Empty: 2-1254                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1255        --                        --
│    └─One: 2-1256                       [1]                       --
│    └─OutputScale: 2-1257               --                        --
│    └─Empty: 2-1258                     [128, 128, 3, 3]          --
│    └─Empty: 2-1259                     [128, 128, 3, 3]          --
│    └─Empty: 2-1260                     [128]                     --
│    └─Empty: 2-1261                     [128]                     --
│    └─BatchNorm2d: 2-1262               [16, 128, 32, 32]         --
│    └─Scaler: 2-1263                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1264                      [16, 128, 32, 32]         --
│    └─Empty: 2-1265                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1266                     [16, 128, 32, 32]         --
├─Dropout2d: 1-118                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1267                 [16, 128, 16, 16]         --
│    └─Empty: 2-1268                     [16, 128, 16, 16]         --
│    └─Empty: 2-1269                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1270        --                        --
│    └─One: 2-1271                       [1]                       --
│    └─OutputScale: 2-1272               --                        --
│    └─Empty: 2-1273                     [128, 128, 3, 3]          --
│    └─Empty: 2-1274                     [128, 128, 3, 3]          --
│    └─Empty: 2-1275                     [128]                     --
│    └─Empty: 2-1276                     [128]                     --
│    └─BatchNorm2d: 2-1277               [16, 128, 16, 16]         --
│    └─Scaler: 2-1278                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1279                      [16, 128, 16, 16]         --
│    └─Empty: 2-1280                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1281                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-120               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1282        --                        --
│    └─One: 2-1283                       [1]                       --
│    └─OutputScale: 2-1284               --                        --
│    └─Empty: 2-1285                     [128, 128, 1, 1]          --
│    └─Empty: 2-1286                     [128, 128, 1, 1]          --
│    └─Empty: 2-1287                     [128]                     --
│    └─Empty: 2-1288                     [128]                     --
│    └─BatchNorm2d: 2-1289               [16, 128, 16, 16]         --
│    └─Scaler: 2-1290                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1291                      [16, 128, 16, 16]         --
│    └─Empty: 2-1292                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1293                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1294                 [16, 128, 16, 16]         --
│    └─Empty: 2-1295                     [16, 128, 16, 16]         --
│    └─Empty: 2-1296                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1297        --                        --
│    └─One: 2-1298                       [1]                       --
│    └─OutputScale: 2-1299               --                        --
│    └─Empty: 2-1300                     [128, 128, 3, 3]          --
│    └─Empty: 2-1301                     [128, 128, 3, 3]          --
│    └─Empty: 2-1302                     [128]                     --
│    └─Empty: 2-1303                     [128]                     --
│    └─BatchNorm2d: 2-1304               [16, 128, 16, 16]         --
│    └─Scaler: 2-1305                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1306                      [16, 128, 16, 16]         --
│    └─Empty: 2-1307                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1308                     [16, 128, 16, 16]         --
├─Dropout2d: 1-122                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-123        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1309                 [16, 128, 8, 8]           --
│    └─Empty: 2-1310                     [16, 128, 8, 8]           --
│    └─Empty: 2-1311                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1312        --                        --
│    └─One: 2-1313                       [1]                       --
│    └─OutputScale: 2-1314               --                        --
│    └─Empty: 2-1315                     [128, 128, 3, 3]          --
│    └─Empty: 2-1316                     [128, 128, 3, 3]          --
│    └─Empty: 2-1317                     [128]                     --
│    └─Empty: 2-1318                     [128]                     --
│    └─BatchNorm2d: 2-1319               [16, 128, 8, 8]           --
│    └─Scaler: 2-1320                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1321                      [16, 128, 8, 8]           --
│    └─Empty: 2-1322                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1323                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-124               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1324        --                        --
│    └─One: 2-1325                       [1]                       --
│    └─OutputScale: 2-1326               --                        --
│    └─Empty: 2-1327                     [16, 128, 1, 1]           --
│    └─Empty: 2-1328                     [16, 128, 1, 1]           --
│    └─Empty: 2-1329                     [16]                      --
│    └─Empty: 2-1330                     [16]                      --
│    └─BatchNorm2d: 2-1331               [16, 16, 8, 8]            --
│    └─Scaler: 2-1332                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1333                      [16, 16, 8, 8]            --
│    └─Empty: 2-1334                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1335                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-125        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1336                 [16, 128, 8, 8]           --
│    └─Empty: 2-1337                     [16, 128, 8, 8]           --
│    └─Empty: 2-1338                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1339        --                        --
│    └─One: 2-1340                       [1]                       --
│    └─OutputScale: 2-1341               --                        --
│    └─Empty: 2-1342                     [16, 128, 3, 3]           --
│    └─Empty: 2-1343                     [16, 128, 3, 3]           --
│    └─Empty: 2-1344                     [16]                      --
│    └─Empty: 2-1345                     [16]                      --
│    └─BatchNorm2d: 2-1346               [16, 16, 8, 8]            --
│    └─Scaler: 2-1347                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1348                      [16, 16, 8, 8]            --
│    └─Empty: 2-1349                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1350                     [16, 16, 8, 8]            --
├─Dropout2d: 1-126                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-127               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1351        --                        --
│    └─One: 2-1352                       [1]                       --
│    └─OutputScale: 2-1353               --                        --
│    └─Empty: 2-1354                     [128, 48, 1, 1]           --
│    └─Empty: 2-1355                     [128, 48, 1, 1]           --
│    └─Empty: 2-1356                     [128]                     --
│    └─Empty: 2-1357                     [128]                     --
│    └─BatchNorm2d: 2-1358               [16, 128, 64, 64]         --
│    └─Scaler: 2-1359                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1360                      [16, 128, 64, 64]         --
│    └─Empty: 2-1361                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1362                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-128               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1363        --                        --
│    └─One: 2-1364                       [1]                       --
│    └─OutputScale: 2-1365               --                        --
│    └─Empty: 2-1366                     [128, 128, 3, 3]          --
│    └─Empty: 2-1367                     [128, 128, 3, 3]          --
│    └─Empty: 2-1368                     [128]                     --
│    └─Empty: 2-1369                     [128]                     --
│    └─BatchNorm2d: 2-1370               [16, 128, 64, 64]         --
│    └─Scaler: 2-1371                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1372                      [16, 128, 64, 64]         --
│    └─Empty: 2-1373                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1374                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1375                 [16, 128, 32, 32]         --
│    └─Empty: 2-1376                     [16, 128, 32, 32]         --
│    └─Empty: 2-1377                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1378        --                        --
│    └─One: 2-1379                       [1]                       --
│    └─OutputScale: 2-1380               --                        --
│    └─Empty: 2-1381                     [128, 128, 3, 3]          --
│    └─Empty: 2-1382                     [128, 128, 3, 3]          --
│    └─Empty: 2-1383                     [128]                     --
│    └─Empty: 2-1384                     [128]                     --
│    └─BatchNorm2d: 2-1385               [16, 128, 32, 32]         --
│    └─Scaler: 2-1386                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1387                      [16, 128, 32, 32]         --
│    └─Empty: 2-1388                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1389                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-130               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1390        --                        --
│    └─One: 2-1391                       [1]                       --
│    └─OutputScale: 2-1392               --                        --
│    └─Empty: 2-1393                     [128, 128, 1, 1]          --
│    └─Empty: 2-1394                     [128, 128, 1, 1]          --
│    └─Empty: 2-1395                     [128]                     --
│    └─Empty: 2-1396                     [128]                     --
│    └─BatchNorm2d: 2-1397               [16, 128, 32, 32]         --
│    └─Scaler: 2-1398                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1399                      [16, 128, 32, 32]         --
│    └─Empty: 2-1400                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1401                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1402                 [16, 128, 32, 32]         --
│    └─Empty: 2-1403                     [16, 128, 32, 32]         --
│    └─Empty: 2-1404                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1405        --                        --
│    └─One: 2-1406                       [1]                       --
│    └─OutputScale: 2-1407               --                        --
│    └─Empty: 2-1408                     [128, 128, 3, 3]          --
│    └─Empty: 2-1409                     [128, 128, 3, 3]          --
│    └─Empty: 2-1410                     [128]                     --
│    └─Empty: 2-1411                     [128]                     --
│    └─BatchNorm2d: 2-1412               [16, 128, 32, 32]         --
│    └─Scaler: 2-1413                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1414                      [16, 128, 32, 32]         --
│    └─Empty: 2-1415                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1416                     [16, 128, 32, 32]         --
├─Dropout2d: 1-132                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1417                 [16, 128, 16, 16]         --
│    └─Empty: 2-1418                     [16, 128, 16, 16]         --
│    └─Empty: 2-1419                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1420        --                        --
│    └─One: 2-1421                       [1]                       --
│    └─OutputScale: 2-1422               --                        --
│    └─Empty: 2-1423                     [128, 128, 3, 3]          --
│    └─Empty: 2-1424                     [128, 128, 3, 3]          --
│    └─Empty: 2-1425                     [128]                     --
│    └─Empty: 2-1426                     [128]                     --
│    └─BatchNorm2d: 2-1427               [16, 128, 16, 16]         --
│    └─Scaler: 2-1428                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1429                      [16, 128, 16, 16]         --
│    └─Empty: 2-1430                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1431                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-134               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1432        --                        --
│    └─One: 2-1433                       [1]                       --
│    └─OutputScale: 2-1434               --                        --
│    └─Empty: 2-1435                     [128, 128, 1, 1]          --
│    └─Empty: 2-1436                     [128, 128, 1, 1]          --
│    └─Empty: 2-1437                     [128]                     --
│    └─Empty: 2-1438                     [128]                     --
│    └─BatchNorm2d: 2-1439               [16, 128, 16, 16]         --
│    └─Scaler: 2-1440                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1441                      [16, 128, 16, 16]         --
│    └─Empty: 2-1442                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1443                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-135        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1444                 [16, 128, 16, 16]         --
│    └─Empty: 2-1445                     [16, 128, 16, 16]         --
│    └─Empty: 2-1446                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1447        --                        --
│    └─One: 2-1448                       [1]                       --
│    └─OutputScale: 2-1449               --                        --
│    └─Empty: 2-1450                     [128, 128, 3, 3]          --
│    └─Empty: 2-1451                     [128, 128, 3, 3]          --
│    └─Empty: 2-1452                     [128]                     --
│    └─Empty: 2-1453                     [128]                     --
│    └─BatchNorm2d: 2-1454               [16, 128, 16, 16]         --
│    └─Scaler: 2-1455                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1456                      [16, 128, 16, 16]         --
│    └─Empty: 2-1457                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1458                     [16, 128, 16, 16]         --
├─Dropout2d: 1-136                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-137        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1459                 [16, 128, 8, 8]           --
│    └─Empty: 2-1460                     [16, 128, 8, 8]           --
│    └─Empty: 2-1461                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1462        --                        --
│    └─One: 2-1463                       [1]                       --
│    └─OutputScale: 2-1464               --                        --
│    └─Empty: 2-1465                     [128, 128, 3, 3]          --
│    └─Empty: 2-1466                     [128, 128, 3, 3]          --
│    └─Empty: 2-1467                     [128]                     --
│    └─Empty: 2-1468                     [128]                     --
│    └─BatchNorm2d: 2-1469               [16, 128, 8, 8]           --
│    └─Scaler: 2-1470                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1471                      [16, 128, 8, 8]           --
│    └─Empty: 2-1472                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1473                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-138               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1474        --                        --
│    └─One: 2-1475                       [1]                       --
│    └─OutputScale: 2-1476               --                        --
│    └─Empty: 2-1477                     [16, 128, 1, 1]           --
│    └─Empty: 2-1478                     [16, 128, 1, 1]           --
│    └─Empty: 2-1479                     [16]                      --
│    └─Empty: 2-1480                     [16]                      --
│    └─BatchNorm2d: 2-1481               [16, 16, 8, 8]            --
│    └─Scaler: 2-1482                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1483                      [16, 16, 8, 8]            --
│    └─Empty: 2-1484                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1485                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-139        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1486                 [16, 128, 8, 8]           --
│    └─Empty: 2-1487                     [16, 128, 8, 8]           --
│    └─Empty: 2-1488                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1489        --                        --
│    └─One: 2-1490                       [1]                       --
│    └─OutputScale: 2-1491               --                        --
│    └─Empty: 2-1492                     [16, 128, 3, 3]           --
│    └─Empty: 2-1493                     [16, 128, 3, 3]           --
│    └─Empty: 2-1494                     [16]                      --
│    └─Empty: 2-1495                     [16]                      --
│    └─BatchNorm2d: 2-1496               [16, 16, 8, 8]            --
│    └─Scaler: 2-1497                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1498                      [16, 16, 8, 8]            --
│    └─Empty: 2-1499                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1500                     [16, 16, 8, 8]            --
├─Dropout2d: 1-140                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-141               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1501        --                        --
│    └─One: 2-1502                       [1]                       --
│    └─OutputScale: 2-1503               --                        --
│    └─Empty: 2-1504                     [128, 48, 1, 1]           --
│    └─Empty: 2-1505                     [128, 48, 1, 1]           --
│    └─Empty: 2-1506                     [128]                     --
│    └─Empty: 2-1507                     [128]                     --
│    └─BatchNorm2d: 2-1508               [16, 128, 64, 64]         --
│    └─Scaler: 2-1509                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1510                      [16, 128, 64, 64]         --
│    └─Empty: 2-1511                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1512                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-142               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1513        --                        --
│    └─One: 2-1514                       [1]                       --
│    └─OutputScale: 2-1515               --                        --
│    └─Empty: 2-1516                     [128, 128, 3, 3]          --
│    └─Empty: 2-1517                     [128, 128, 3, 3]          --
│    └─Empty: 2-1518                     [128]                     --
│    └─Empty: 2-1519                     [128]                     --
│    └─BatchNorm2d: 2-1520               [16, 128, 64, 64]         --
│    └─Scaler: 2-1521                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1522                      [16, 128, 64, 64]         --
│    └─Empty: 2-1523                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1524                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1525                 [16, 128, 32, 32]         --
│    └─Empty: 2-1526                     [16, 128, 32, 32]         --
│    └─Empty: 2-1527                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1528        --                        --
│    └─One: 2-1529                       [1]                       --
│    └─OutputScale: 2-1530               --                        --
│    └─Empty: 2-1531                     [128, 128, 3, 3]          --
│    └─Empty: 2-1532                     [128, 128, 3, 3]          --
│    └─Empty: 2-1533                     [128]                     --
│    └─Empty: 2-1534                     [128]                     --
│    └─BatchNorm2d: 2-1535               [16, 128, 32, 32]         --
│    └─Scaler: 2-1536                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1537                      [16, 128, 32, 32]         --
│    └─Empty: 2-1538                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1539                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-144               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1540        --                        --
│    └─One: 2-1541                       [1]                       --
│    └─OutputScale: 2-1542               --                        --
│    └─Empty: 2-1543                     [128, 128, 1, 1]          --
│    └─Empty: 2-1544                     [128, 128, 1, 1]          --
│    └─Empty: 2-1545                     [128]                     --
│    └─Empty: 2-1546                     [128]                     --
│    └─BatchNorm2d: 2-1547               [16, 128, 32, 32]         --
│    └─Scaler: 2-1548                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1549                      [16, 128, 32, 32]         --
│    └─Empty: 2-1550                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1551                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1552                 [16, 128, 32, 32]         --
│    └─Empty: 2-1553                     [16, 128, 32, 32]         --
│    └─Empty: 2-1554                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1555        --                        --
│    └─One: 2-1556                       [1]                       --
│    └─OutputScale: 2-1557               --                        --
│    └─Empty: 2-1558                     [128, 128, 3, 3]          --
│    └─Empty: 2-1559                     [128, 128, 3, 3]          --
│    └─Empty: 2-1560                     [128]                     --
│    └─Empty: 2-1561                     [128]                     --
│    └─BatchNorm2d: 2-1562               [16, 128, 32, 32]         --
│    └─Scaler: 2-1563                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1564                      [16, 128, 32, 32]         --
│    └─Empty: 2-1565                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1566                     [16, 128, 32, 32]         --
├─Dropout2d: 1-146                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1567                 [16, 128, 16, 16]         --
│    └─Empty: 2-1568                     [16, 128, 16, 16]         --
│    └─Empty: 2-1569                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1570        --                        --
│    └─One: 2-1571                       [1]                       --
│    └─OutputScale: 2-1572               --                        --
│    └─Empty: 2-1573                     [128, 128, 3, 3]          --
│    └─Empty: 2-1574                     [128, 128, 3, 3]          --
│    └─Empty: 2-1575                     [128]                     --
│    └─Empty: 2-1576                     [128]                     --
│    └─BatchNorm2d: 2-1577               [16, 128, 16, 16]         --
│    └─Scaler: 2-1578                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1579                      [16, 128, 16, 16]         --
│    └─Empty: 2-1580                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1581                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-148               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1582        --                        --
│    └─One: 2-1583                       [1]                       --
│    └─OutputScale: 2-1584               --                        --
│    └─Empty: 2-1585                     [128, 128, 1, 1]          --
│    └─Empty: 2-1586                     [128, 128, 1, 1]          --
│    └─Empty: 2-1587                     [128]                     --
│    └─Empty: 2-1588                     [128]                     --
│    └─BatchNorm2d: 2-1589               [16, 128, 16, 16]         --
│    └─Scaler: 2-1590                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1591                      [16, 128, 16, 16]         --
│    └─Empty: 2-1592                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1593                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-149        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1594                 [16, 128, 16, 16]         --
│    └─Empty: 2-1595                     [16, 128, 16, 16]         --
│    └─Empty: 2-1596                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1597        --                        --
│    └─One: 2-1598                       [1]                       --
│    └─OutputScale: 2-1599               --                        --
│    └─Empty: 2-1600                     [128, 128, 3, 3]          --
│    └─Empty: 2-1601                     [128, 128, 3, 3]          --
│    └─Empty: 2-1602                     [128]                     --
│    └─Empty: 2-1603                     [128]                     --
│    └─BatchNorm2d: 2-1604               [16, 128, 16, 16]         --
│    └─Scaler: 2-1605                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1606                      [16, 128, 16, 16]         --
│    └─Empty: 2-1607                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1608                     [16, 128, 16, 16]         --
├─Dropout2d: 1-150                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1609                 [16, 128, 8, 8]           --
│    └─Empty: 2-1610                     [16, 128, 8, 8]           --
│    └─Empty: 2-1611                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1612        --                        --
│    └─One: 2-1613                       [1]                       --
│    └─OutputScale: 2-1614               --                        --
│    └─Empty: 2-1615                     [128, 128, 3, 3]          --
│    └─Empty: 2-1616                     [128, 128, 3, 3]          --
│    └─Empty: 2-1617                     [128]                     --
│    └─Empty: 2-1618                     [128]                     --
│    └─BatchNorm2d: 2-1619               [16, 128, 8, 8]           --
│    └─Scaler: 2-1620                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1621                      [16, 128, 8, 8]           --
│    └─Empty: 2-1622                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1623                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-152               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1624        --                        --
│    └─One: 2-1625                       [1]                       --
│    └─OutputScale: 2-1626               --                        --
│    └─Empty: 2-1627                     [16, 128, 1, 1]           --
│    └─Empty: 2-1628                     [16, 128, 1, 1]           --
│    └─Empty: 2-1629                     [16]                      --
│    └─Empty: 2-1630                     [16]                      --
│    └─BatchNorm2d: 2-1631               [16, 16, 8, 8]            --
│    └─Scaler: 2-1632                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1633                      [16, 16, 8, 8]            --
│    └─Empty: 2-1634                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1635                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1636                 [16, 128, 8, 8]           --
│    └─Empty: 2-1637                     [16, 128, 8, 8]           --
│    └─Empty: 2-1638                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1639        --                        --
│    └─One: 2-1640                       [1]                       --
│    └─OutputScale: 2-1641               --                        --
│    └─Empty: 2-1642                     [16, 128, 3, 3]           --
│    └─Empty: 2-1643                     [16, 128, 3, 3]           --
│    └─Empty: 2-1644                     [16]                      --
│    └─Empty: 2-1645                     [16]                      --
│    └─BatchNorm2d: 2-1646               [16, 16, 8, 8]            --
│    └─Scaler: 2-1647                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1648                      [16, 16, 8, 8]            --
│    └─Empty: 2-1649                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1650                     [16, 16, 8, 8]            --
├─Dropout2d: 1-154                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-155               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1651        --                        --
│    └─One: 2-1652                       [1]                       --
│    └─OutputScale: 2-1653               --                        --
│    └─Empty: 2-1654                     [128, 48, 1, 1]           --
│    └─Empty: 2-1655                     [128, 48, 1, 1]           --
│    └─Empty: 2-1656                     [128]                     --
│    └─Empty: 2-1657                     [128]                     --
│    └─BatchNorm2d: 2-1658               [16, 128, 64, 64]         --
│    └─Scaler: 2-1659                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1660                      [16, 128, 64, 64]         --
│    └─Empty: 2-1661                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1662                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-156               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1663        --                        --
│    └─One: 2-1664                       [1]                       --
│    └─OutputScale: 2-1665               --                        --
│    └─Empty: 2-1666                     [128, 128, 3, 3]          --
│    └─Empty: 2-1667                     [128, 128, 3, 3]          --
│    └─Empty: 2-1668                     [128]                     --
│    └─Empty: 2-1669                     [128]                     --
│    └─BatchNorm2d: 2-1670               [16, 128, 64, 64]         --
│    └─Scaler: 2-1671                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1672                      [16, 128, 64, 64]         --
│    └─Empty: 2-1673                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1674                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-157        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1675                 [16, 128, 32, 32]         --
│    └─Empty: 2-1676                     [16, 128, 32, 32]         --
│    └─Empty: 2-1677                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1678        --                        --
│    └─One: 2-1679                       [1]                       --
│    └─OutputScale: 2-1680               --                        --
│    └─Empty: 2-1681                     [128, 128, 3, 3]          --
│    └─Empty: 2-1682                     [128, 128, 3, 3]          --
│    └─Empty: 2-1683                     [128]                     --
│    └─Empty: 2-1684                     [128]                     --
│    └─BatchNorm2d: 2-1685               [16, 128, 32, 32]         --
│    └─Scaler: 2-1686                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1687                      [16, 128, 32, 32]         --
│    └─Empty: 2-1688                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1689                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-158               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1690        --                        --
│    └─One: 2-1691                       [1]                       --
│    └─OutputScale: 2-1692               --                        --
│    └─Empty: 2-1693                     [128, 128, 1, 1]          --
│    └─Empty: 2-1694                     [128, 128, 1, 1]          --
│    └─Empty: 2-1695                     [128]                     --
│    └─Empty: 2-1696                     [128]                     --
│    └─BatchNorm2d: 2-1697               [16, 128, 32, 32]         --
│    └─Scaler: 2-1698                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1699                      [16, 128, 32, 32]         --
│    └─Empty: 2-1700                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1701                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-159        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1702                 [16, 128, 32, 32]         --
│    └─Empty: 2-1703                     [16, 128, 32, 32]         --
│    └─Empty: 2-1704                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1705        --                        --
│    └─One: 2-1706                       [1]                       --
│    └─OutputScale: 2-1707               --                        --
│    └─Empty: 2-1708                     [128, 128, 3, 3]          --
│    └─Empty: 2-1709                     [128, 128, 3, 3]          --
│    └─Empty: 2-1710                     [128]                     --
│    └─Empty: 2-1711                     [128]                     --
│    └─BatchNorm2d: 2-1712               [16, 128, 32, 32]         --
│    └─Scaler: 2-1713                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1714                      [16, 128, 32, 32]         --
│    └─Empty: 2-1715                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1716                     [16, 128, 32, 32]         --
├─Dropout2d: 1-160                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-161        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1717                 [16, 128, 16, 16]         --
│    └─Empty: 2-1718                     [16, 128, 16, 16]         --
│    └─Empty: 2-1719                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1720        --                        --
│    └─One: 2-1721                       [1]                       --
│    └─OutputScale: 2-1722               --                        --
│    └─Empty: 2-1723                     [128, 128, 3, 3]          --
│    └─Empty: 2-1724                     [128, 128, 3, 3]          --
│    └─Empty: 2-1725                     [128]                     --
│    └─Empty: 2-1726                     [128]                     --
│    └─BatchNorm2d: 2-1727               [16, 128, 16, 16]         --
│    └─Scaler: 2-1728                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1729                      [16, 128, 16, 16]         --
│    └─Empty: 2-1730                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1731                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-162               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1732        --                        --
│    └─One: 2-1733                       [1]                       --
│    └─OutputScale: 2-1734               --                        --
│    └─Empty: 2-1735                     [128, 128, 1, 1]          --
│    └─Empty: 2-1736                     [128, 128, 1, 1]          --
│    └─Empty: 2-1737                     [128]                     --
│    └─Empty: 2-1738                     [128]                     --
│    └─BatchNorm2d: 2-1739               [16, 128, 16, 16]         --
│    └─Scaler: 2-1740                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1741                      [16, 128, 16, 16]         --
│    └─Empty: 2-1742                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1743                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-163        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1744                 [16, 128, 16, 16]         --
│    └─Empty: 2-1745                     [16, 128, 16, 16]         --
│    └─Empty: 2-1746                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1747        --                        --
│    └─One: 2-1748                       [1]                       --
│    └─OutputScale: 2-1749               --                        --
│    └─Empty: 2-1750                     [128, 128, 3, 3]          --
│    └─Empty: 2-1751                     [128, 128, 3, 3]          --
│    └─Empty: 2-1752                     [128]                     --
│    └─Empty: 2-1753                     [128]                     --
│    └─BatchNorm2d: 2-1754               [16, 128, 16, 16]         --
│    └─Scaler: 2-1755                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1756                      [16, 128, 16, 16]         --
│    └─Empty: 2-1757                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1758                     [16, 128, 16, 16]         --
├─Dropout2d: 1-164                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1759                 [16, 128, 8, 8]           --
│    └─Empty: 2-1760                     [16, 128, 8, 8]           --
│    └─Empty: 2-1761                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1762        --                        --
│    └─One: 2-1763                       [1]                       --
│    └─OutputScale: 2-1764               --                        --
│    └─Empty: 2-1765                     [128, 128, 3, 3]          --
│    └─Empty: 2-1766                     [128, 128, 3, 3]          --
│    └─Empty: 2-1767                     [128]                     --
│    └─Empty: 2-1768                     [128]                     --
│    └─BatchNorm2d: 2-1769               [16, 128, 8, 8]           --
│    └─Scaler: 2-1770                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1771                      [16, 128, 8, 8]           --
│    └─Empty: 2-1772                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1773                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-166               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1774        --                        --
│    └─One: 2-1775                       [1]                       --
│    └─OutputScale: 2-1776               --                        --
│    └─Empty: 2-1777                     [16, 128, 1, 1]           --
│    └─Empty: 2-1778                     [16, 128, 1, 1]           --
│    └─Empty: 2-1779                     [16]                      --
│    └─Empty: 2-1780                     [16]                      --
│    └─BatchNorm2d: 2-1781               [16, 16, 8, 8]            --
│    └─Scaler: 2-1782                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1783                      [16, 16, 8, 8]            --
│    └─Empty: 2-1784                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1785                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1786                 [16, 128, 8, 8]           --
│    └─Empty: 2-1787                     [16, 128, 8, 8]           --
│    └─Empty: 2-1788                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1789        --                        --
│    └─One: 2-1790                       [1]                       --
│    └─OutputScale: 2-1791               --                        --
│    └─Empty: 2-1792                     [16, 128, 3, 3]           --
│    └─Empty: 2-1793                     [16, 128, 3, 3]           --
│    └─Empty: 2-1794                     [16]                      --
│    └─Empty: 2-1795                     [16]                      --
│    └─BatchNorm2d: 2-1796               [16, 16, 8, 8]            --
│    └─Scaler: 2-1797                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1798                      [16, 16, 8, 8]            --
│    └─Empty: 2-1799                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1800                     [16, 16, 8, 8]            --
├─Dropout2d: 1-168                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-169               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1801        --                        --
│    └─One: 2-1802                       [1]                       --
│    └─OutputScale: 2-1803               --                        --
│    └─Empty: 2-1804                     [128, 48, 1, 1]           --
│    └─Empty: 2-1805                     [128, 48, 1, 1]           --
│    └─Empty: 2-1806                     [128]                     --
│    └─Empty: 2-1807                     [128]                     --
│    └─BatchNorm2d: 2-1808               [16, 128, 64, 64]         --
│    └─Scaler: 2-1809                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1810                      [16, 128, 64, 64]         --
│    └─Empty: 2-1811                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1812                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-170               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1813        --                        --
│    └─One: 2-1814                       [1]                       --
│    └─OutputScale: 2-1815               --                        --
│    └─Empty: 2-1816                     [128, 128, 3, 3]          --
│    └─Empty: 2-1817                     [128, 128, 3, 3]          --
│    └─Empty: 2-1818                     [128]                     --
│    └─Empty: 2-1819                     [128]                     --
│    └─BatchNorm2d: 2-1820               [16, 128, 64, 64]         --
│    └─Scaler: 2-1821                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1822                      [16, 128, 64, 64]         --
│    └─Empty: 2-1823                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1824                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-171        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1825                 [16, 128, 32, 32]         --
│    └─Empty: 2-1826                     [16, 128, 32, 32]         --
│    └─Empty: 2-1827                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1828        --                        --
│    └─One: 2-1829                       [1]                       --
│    └─OutputScale: 2-1830               --                        --
│    └─Empty: 2-1831                     [128, 128, 3, 3]          --
│    └─Empty: 2-1832                     [128, 128, 3, 3]          --
│    └─Empty: 2-1833                     [128]                     --
│    └─Empty: 2-1834                     [128]                     --
│    └─BatchNorm2d: 2-1835               [16, 128, 32, 32]         --
│    └─Scaler: 2-1836                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1837                      [16, 128, 32, 32]         --
│    └─Empty: 2-1838                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1839                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-172               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1840        --                        --
│    └─One: 2-1841                       [1]                       --
│    └─OutputScale: 2-1842               --                        --
│    └─Empty: 2-1843                     [128, 128, 1, 1]          --
│    └─Empty: 2-1844                     [128, 128, 1, 1]          --
│    └─Empty: 2-1845                     [128]                     --
│    └─Empty: 2-1846                     [128]                     --
│    └─BatchNorm2d: 2-1847               [16, 128, 32, 32]         --
│    └─Scaler: 2-1848                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1849                      [16, 128, 32, 32]         --
│    └─Empty: 2-1850                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1851                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-173        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1852                 [16, 128, 32, 32]         --
│    └─Empty: 2-1853                     [16, 128, 32, 32]         --
│    └─Empty: 2-1854                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1855        --                        --
│    └─One: 2-1856                       [1]                       --
│    └─OutputScale: 2-1857               --                        --
│    └─Empty: 2-1858                     [128, 128, 3, 3]          --
│    └─Empty: 2-1859                     [128, 128, 3, 3]          --
│    └─Empty: 2-1860                     [128]                     --
│    └─Empty: 2-1861                     [128]                     --
│    └─BatchNorm2d: 2-1862               [16, 128, 32, 32]         --
│    └─Scaler: 2-1863                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1864                      [16, 128, 32, 32]         --
│    └─Empty: 2-1865                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1866                     [16, 128, 32, 32]         --
├─Dropout2d: 1-174                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1867                 [16, 128, 16, 16]         --
│    └─Empty: 2-1868                     [16, 128, 16, 16]         --
│    └─Empty: 2-1869                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1870        --                        --
│    └─One: 2-1871                       [1]                       --
│    └─OutputScale: 2-1872               --                        --
│    └─Empty: 2-1873                     [128, 128, 3, 3]          --
│    └─Empty: 2-1874                     [128, 128, 3, 3]          --
│    └─Empty: 2-1875                     [128]                     --
│    └─Empty: 2-1876                     [128]                     --
│    └─BatchNorm2d: 2-1877               [16, 128, 16, 16]         --
│    └─Scaler: 2-1878                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1879                      [16, 128, 16, 16]         --
│    └─Empty: 2-1880                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1881                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-176               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1882        --                        --
│    └─One: 2-1883                       [1]                       --
│    └─OutputScale: 2-1884               --                        --
│    └─Empty: 2-1885                     [128, 128, 1, 1]          --
│    └─Empty: 2-1886                     [128, 128, 1, 1]          --
│    └─Empty: 2-1887                     [128]                     --
│    └─Empty: 2-1888                     [128]                     --
│    └─BatchNorm2d: 2-1889               [16, 128, 16, 16]         --
│    └─Scaler: 2-1890                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1891                      [16, 128, 16, 16]         --
│    └─Empty: 2-1892                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1893                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1894                 [16, 128, 16, 16]         --
│    └─Empty: 2-1895                     [16, 128, 16, 16]         --
│    └─Empty: 2-1896                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1897        --                        --
│    └─One: 2-1898                       [1]                       --
│    └─OutputScale: 2-1899               --                        --
│    └─Empty: 2-1900                     [128, 128, 3, 3]          --
│    └─Empty: 2-1901                     [128, 128, 3, 3]          --
│    └─Empty: 2-1902                     [128]                     --
│    └─Empty: 2-1903                     [128]                     --
│    └─BatchNorm2d: 2-1904               [16, 128, 16, 16]         --
│    └─Scaler: 2-1905                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1906                      [16, 128, 16, 16]         --
│    └─Empty: 2-1907                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1908                     [16, 128, 16, 16]         --
├─Dropout2d: 1-178                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1909                 [16, 128, 8, 8]           --
│    └─Empty: 2-1910                     [16, 128, 8, 8]           --
│    └─Empty: 2-1911                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1912        --                        --
│    └─One: 2-1913                       [1]                       --
│    └─OutputScale: 2-1914               --                        --
│    └─Empty: 2-1915                     [128, 128, 3, 3]          --
│    └─Empty: 2-1916                     [128, 128, 3, 3]          --
│    └─Empty: 2-1917                     [128]                     --
│    └─Empty: 2-1918                     [128]                     --
│    └─BatchNorm2d: 2-1919               [16, 128, 8, 8]           --
│    └─Scaler: 2-1920                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1921                      [16, 128, 8, 8]           --
│    └─Empty: 2-1922                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1923                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-180               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1924        --                        --
│    └─One: 2-1925                       [1]                       --
│    └─OutputScale: 2-1926               --                        --
│    └─Empty: 2-1927                     [16, 128, 1, 1]           --
│    └─Empty: 2-1928                     [16, 128, 1, 1]           --
│    └─Empty: 2-1929                     [16]                      --
│    └─Empty: 2-1930                     [16]                      --
│    └─BatchNorm2d: 2-1931               [16, 16, 8, 8]            --
│    └─Scaler: 2-1932                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1933                      [16, 16, 8, 8]            --
│    └─Empty: 2-1934                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1935                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1936                 [16, 128, 8, 8]           --
│    └─Empty: 2-1937                     [16, 128, 8, 8]           --
│    └─Empty: 2-1938                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1939        --                        --
│    └─One: 2-1940                       [1]                       --
│    └─OutputScale: 2-1941               --                        --
│    └─Empty: 2-1942                     [16, 128, 3, 3]           --
│    └─Empty: 2-1943                     [16, 128, 3, 3]           --
│    └─Empty: 2-1944                     [16]                      --
│    └─Empty: 2-1945                     [16]                      --
│    └─BatchNorm2d: 2-1946               [16, 16, 8, 8]            --
│    └─Scaler: 2-1947                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1948                      [16, 16, 8, 8]            --
│    └─Empty: 2-1949                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1950                     [16, 16, 8, 8]            --
├─Dropout2d: 1-182                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-183               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1951        --                        --
│    └─One: 2-1952                       [1]                       --
│    └─OutputScale: 2-1953               --                        --
│    └─Empty: 2-1954                     [128, 48, 1, 1]           --
│    └─Empty: 2-1955                     [128, 48, 1, 1]           --
│    └─Empty: 2-1956                     [128]                     --
│    └─Empty: 2-1957                     [128]                     --
│    └─BatchNorm2d: 2-1958               [16, 128, 64, 64]         --
│    └─Scaler: 2-1959                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1960                      [16, 128, 64, 64]         --
│    └─Empty: 2-1961                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1962                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-184               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1963        --                        --
│    └─One: 2-1964                       [1]                       --
│    └─OutputScale: 2-1965               --                        --
│    └─Empty: 2-1966                     [128, 128, 3, 3]          --
│    └─Empty: 2-1967                     [128, 128, 3, 3]          --
│    └─Empty: 2-1968                     [128]                     --
│    └─Empty: 2-1969                     [128]                     --
│    └─BatchNorm2d: 2-1970               [16, 128, 64, 64]         --
│    └─Scaler: 2-1971                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1972                      [16, 128, 64, 64]         --
│    └─Empty: 2-1973                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1974                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1975                 [16, 128, 32, 32]         --
│    └─Empty: 2-1976                     [16, 128, 32, 32]         --
│    └─Empty: 2-1977                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1978        --                        --
│    └─One: 2-1979                       [1]                       --
│    └─OutputScale: 2-1980               --                        --
│    └─Empty: 2-1981                     [128, 128, 3, 3]          --
│    └─Empty: 2-1982                     [128, 128, 3, 3]          --
│    └─Empty: 2-1983                     [128]                     --
│    └─Empty: 2-1984                     [128]                     --
│    └─BatchNorm2d: 2-1985               [16, 128, 32, 32]         --
│    └─Scaler: 2-1986                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1987                      [16, 128, 32, 32]         --
│    └─Empty: 2-1988                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1989                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-186               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1990        --                        --
│    └─One: 2-1991                       [1]                       --
│    └─OutputScale: 2-1992               --                        --
│    └─Empty: 2-1993                     [128, 128, 1, 1]          --
│    └─Empty: 2-1994                     [128, 128, 1, 1]          --
│    └─Empty: 2-1995                     [128]                     --
│    └─Empty: 2-1996                     [128]                     --
│    └─BatchNorm2d: 2-1997               [16, 128, 32, 32]         --
│    └─Scaler: 2-1998                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1999                      [16, 128, 32, 32]         --
│    └─Empty: 2-2000                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2001                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2002                 [16, 128, 32, 32]         --
│    └─Empty: 2-2003                     [16, 128, 32, 32]         --
│    └─Empty: 2-2004                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2005        --                        --
│    └─One: 2-2006                       [1]                       --
│    └─OutputScale: 2-2007               --                        --
│    └─Empty: 2-2008                     [128, 128, 3, 3]          --
│    └─Empty: 2-2009                     [128, 128, 3, 3]          --
│    └─Empty: 2-2010                     [128]                     --
│    └─Empty: 2-2011                     [128]                     --
│    └─BatchNorm2d: 2-2012               [16, 128, 32, 32]         --
│    └─Scaler: 2-2013                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2014                      [16, 128, 32, 32]         --
│    └─Empty: 2-2015                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2016                     [16, 128, 32, 32]         --
├─Dropout2d: 1-188                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-189        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2017                 [16, 128, 16, 16]         --
│    └─Empty: 2-2018                     [16, 128, 16, 16]         --
│    └─Empty: 2-2019                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2020        --                        --
│    └─One: 2-2021                       [1]                       --
│    └─OutputScale: 2-2022               --                        --
│    └─Empty: 2-2023                     [128, 128, 3, 3]          --
│    └─Empty: 2-2024                     [128, 128, 3, 3]          --
│    └─Empty: 2-2025                     [128]                     --
│    └─Empty: 2-2026                     [128]                     --
│    └─BatchNorm2d: 2-2027               [16, 128, 16, 16]         --
│    └─Scaler: 2-2028                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2029                      [16, 128, 16, 16]         --
│    └─Empty: 2-2030                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2031                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-190               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2032        --                        --
│    └─One: 2-2033                       [1]                       --
│    └─OutputScale: 2-2034               --                        --
│    └─Empty: 2-2035                     [128, 128, 1, 1]          --
│    └─Empty: 2-2036                     [128, 128, 1, 1]          --
│    └─Empty: 2-2037                     [128]                     --
│    └─Empty: 2-2038                     [128]                     --
│    └─BatchNorm2d: 2-2039               [16, 128, 16, 16]         --
│    └─Scaler: 2-2040                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2041                      [16, 128, 16, 16]         --
│    └─Empty: 2-2042                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2043                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-191        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2044                 [16, 128, 16, 16]         --
│    └─Empty: 2-2045                     [16, 128, 16, 16]         --
│    └─Empty: 2-2046                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2047        --                        --
│    └─One: 2-2048                       [1]                       --
│    └─OutputScale: 2-2049               --                        --
│    └─Empty: 2-2050                     [128, 128, 3, 3]          --
│    └─Empty: 2-2051                     [128, 128, 3, 3]          --
│    └─Empty: 2-2052                     [128]                     --
│    └─Empty: 2-2053                     [128]                     --
│    └─BatchNorm2d: 2-2054               [16, 128, 16, 16]         --
│    └─Scaler: 2-2055                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2056                      [16, 128, 16, 16]         --
│    └─Empty: 2-2057                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2058                     [16, 128, 16, 16]         --
├─Dropout2d: 1-192                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-193        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2059                 [16, 128, 8, 8]           --
│    └─Empty: 2-2060                     [16, 128, 8, 8]           --
│    └─Empty: 2-2061                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2062        --                        --
│    └─One: 2-2063                       [1]                       --
│    └─OutputScale: 2-2064               --                        --
│    └─Empty: 2-2065                     [128, 128, 3, 3]          --
│    └─Empty: 2-2066                     [128, 128, 3, 3]          --
│    └─Empty: 2-2067                     [128]                     --
│    └─Empty: 2-2068                     [128]                     --
│    └─BatchNorm2d: 2-2069               [16, 128, 8, 8]           --
│    └─Scaler: 2-2070                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2071                      [16, 128, 8, 8]           --
│    └─Empty: 2-2072                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2073                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-194               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2074        --                        --
│    └─One: 2-2075                       [1]                       --
│    └─OutputScale: 2-2076               --                        --
│    └─Empty: 2-2077                     [16, 128, 1, 1]           --
│    └─Empty: 2-2078                     [16, 128, 1, 1]           --
│    └─Empty: 2-2079                     [16]                      --
│    └─Empty: 2-2080                     [16]                      --
│    └─BatchNorm2d: 2-2081               [16, 16, 8, 8]            --
│    └─Scaler: 2-2082                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2083                      [16, 16, 8, 8]            --
│    └─Empty: 2-2084                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2085                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-195        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2086                 [16, 128, 8, 8]           --
│    └─Empty: 2-2087                     [16, 128, 8, 8]           --
│    └─Empty: 2-2088                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2089        --                        --
│    └─One: 2-2090                       [1]                       --
│    └─OutputScale: 2-2091               --                        --
│    └─Empty: 2-2092                     [16, 128, 3, 3]           --
│    └─Empty: 2-2093                     [16, 128, 3, 3]           --
│    └─Empty: 2-2094                     [16]                      --
│    └─Empty: 2-2095                     [16]                      --
│    └─BatchNorm2d: 2-2096               [16, 16, 8, 8]            --
│    └─Scaler: 2-2097                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2098                      [16, 16, 8, 8]            --
│    └─Empty: 2-2099                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2100                     [16, 16, 8, 8]            --
├─Dropout2d: 1-196                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2101        --                        --
│    └─One: 2-2102                       [1]                       --
│    └─OutputScale: 2-2103               --                        --
│    └─Empty: 2-2104                     [128, 48, 1, 1]           --
│    └─Empty: 2-2105                     [128, 48, 1, 1]           --
│    └─Empty: 2-2106                     [128]                     --
│    └─Empty: 2-2107                     [128]                     --
│    └─BatchNorm2d: 2-2108               [16, 128, 64, 64]         --
│    └─Scaler: 2-2109                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2110                      [16, 128, 64, 64]         --
│    └─Empty: 2-2111                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2112                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-198               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2113        --                        --
│    └─One: 2-2114                       [1]                       --
│    └─OutputScale: 2-2115               --                        --
│    └─Empty: 2-2116                     [128, 128, 3, 3]          --
│    └─Empty: 2-2117                     [128, 128, 3, 3]          --
│    └─Empty: 2-2118                     [128]                     --
│    └─Empty: 2-2119                     [128]                     --
│    └─BatchNorm2d: 2-2120               [16, 128, 64, 64]         --
│    └─Scaler: 2-2121                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2122                      [16, 128, 64, 64]         --
│    └─Empty: 2-2123                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2124                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2125                 [16, 128, 32, 32]         --
│    └─Empty: 2-2126                     [16, 128, 32, 32]         --
│    └─Empty: 2-2127                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2128        --                        --
│    └─One: 2-2129                       [1]                       --
│    └─OutputScale: 2-2130               --                        --
│    └─Empty: 2-2131                     [128, 128, 3, 3]          --
│    └─Empty: 2-2132                     [128, 128, 3, 3]          --
│    └─Empty: 2-2133                     [128]                     --
│    └─Empty: 2-2134                     [128]                     --
│    └─BatchNorm2d: 2-2135               [16, 128, 32, 32]         --
│    └─Scaler: 2-2136                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2137                      [16, 128, 32, 32]         --
│    └─Empty: 2-2138                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2139                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-200               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2140        --                        --
│    └─One: 2-2141                       [1]                       --
│    └─OutputScale: 2-2142               --                        --
│    └─Empty: 2-2143                     [128, 128, 1, 1]          --
│    └─Empty: 2-2144                     [128, 128, 1, 1]          --
│    └─Empty: 2-2145                     [128]                     --
│    └─Empty: 2-2146                     [128]                     --
│    └─BatchNorm2d: 2-2147               [16, 128, 32, 32]         --
│    └─Scaler: 2-2148                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2149                      [16, 128, 32, 32]         --
│    └─Empty: 2-2150                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2151                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2152                 [16, 128, 32, 32]         --
│    └─Empty: 2-2153                     [16, 128, 32, 32]         --
│    └─Empty: 2-2154                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2155        --                        --
│    └─One: 2-2156                       [1]                       --
│    └─OutputScale: 2-2157               --                        --
│    └─Empty: 2-2158                     [128, 128, 3, 3]          --
│    └─Empty: 2-2159                     [128, 128, 3, 3]          --
│    └─Empty: 2-2160                     [128]                     --
│    └─Empty: 2-2161                     [128]                     --
│    └─BatchNorm2d: 2-2162               [16, 128, 32, 32]         --
│    └─Scaler: 2-2163                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2164                      [16, 128, 32, 32]         --
│    └─Empty: 2-2165                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2166                     [16, 128, 32, 32]         --
├─Dropout2d: 1-202                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-203        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2167                 [16, 128, 16, 16]         --
│    └─Empty: 2-2168                     [16, 128, 16, 16]         --
│    └─Empty: 2-2169                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2170        --                        --
│    └─One: 2-2171                       [1]                       --
│    └─OutputScale: 2-2172               --                        --
│    └─Empty: 2-2173                     [128, 128, 3, 3]          --
│    └─Empty: 2-2174                     [128, 128, 3, 3]          --
│    └─Empty: 2-2175                     [128]                     --
│    └─Empty: 2-2176                     [128]                     --
│    └─BatchNorm2d: 2-2177               [16, 128, 16, 16]         --
│    └─Scaler: 2-2178                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2179                      [16, 128, 16, 16]         --
│    └─Empty: 2-2180                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2181                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-204               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2182        --                        --
│    └─One: 2-2183                       [1]                       --
│    └─OutputScale: 2-2184               --                        --
│    └─Empty: 2-2185                     [128, 128, 1, 1]          --
│    └─Empty: 2-2186                     [128, 128, 1, 1]          --
│    └─Empty: 2-2187                     [128]                     --
│    └─Empty: 2-2188                     [128]                     --
│    └─BatchNorm2d: 2-2189               [16, 128, 16, 16]         --
│    └─Scaler: 2-2190                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2191                      [16, 128, 16, 16]         --
│    └─Empty: 2-2192                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2193                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-205        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2194                 [16, 128, 16, 16]         --
│    └─Empty: 2-2195                     [16, 128, 16, 16]         --
│    └─Empty: 2-2196                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2197        --                        --
│    └─One: 2-2198                       [1]                       --
│    └─OutputScale: 2-2199               --                        --
│    └─Empty: 2-2200                     [128, 128, 3, 3]          --
│    └─Empty: 2-2201                     [128, 128, 3, 3]          --
│    └─Empty: 2-2202                     [128]                     --
│    └─Empty: 2-2203                     [128]                     --
│    └─BatchNorm2d: 2-2204               [16, 128, 16, 16]         --
│    └─Scaler: 2-2205                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2206                      [16, 128, 16, 16]         --
│    └─Empty: 2-2207                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2208                     [16, 128, 16, 16]         --
├─Dropout2d: 1-206                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-207        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2209                 [16, 128, 8, 8]           --
│    └─Empty: 2-2210                     [16, 128, 8, 8]           --
│    └─Empty: 2-2211                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2212        --                        --
│    └─One: 2-2213                       [1]                       --
│    └─OutputScale: 2-2214               --                        --
│    └─Empty: 2-2215                     [128, 128, 3, 3]          --
│    └─Empty: 2-2216                     [128, 128, 3, 3]          --
│    └─Empty: 2-2217                     [128]                     --
│    └─Empty: 2-2218                     [128]                     --
│    └─BatchNorm2d: 2-2219               [16, 128, 8, 8]           --
│    └─Scaler: 2-2220                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2221                      [16, 128, 8, 8]           --
│    └─Empty: 2-2222                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2223                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-208               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2224        --                        --
│    └─One: 2-2225                       [1]                       --
│    └─OutputScale: 2-2226               --                        --
│    └─Empty: 2-2227                     [16, 128, 1, 1]           --
│    └─Empty: 2-2228                     [16, 128, 1, 1]           --
│    └─Empty: 2-2229                     [16]                      --
│    └─Empty: 2-2230                     [16]                      --
│    └─BatchNorm2d: 2-2231               [16, 16, 8, 8]            --
│    └─Scaler: 2-2232                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2233                      [16, 16, 8, 8]            --
│    └─Empty: 2-2234                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2235                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2236                 [16, 128, 8, 8]           --
│    └─Empty: 2-2237                     [16, 128, 8, 8]           --
│    └─Empty: 2-2238                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2239        --                        --
│    └─One: 2-2240                       [1]                       --
│    └─OutputScale: 2-2241               --                        --
│    └─Empty: 2-2242                     [16, 128, 3, 3]           --
│    └─Empty: 2-2243                     [16, 128, 3, 3]           --
│    └─Empty: 2-2244                     [16]                      --
│    └─Empty: 2-2245                     [16]                      --
│    └─BatchNorm2d: 2-2246               [16, 16, 8, 8]            --
│    └─Scaler: 2-2247                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2248                      [16, 16, 8, 8]            --
│    └─Empty: 2-2249                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2250                     [16, 16, 8, 8]            --
├─Dropout2d: 1-210                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-211               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2251        --                        --
│    └─One: 2-2252                       [1]                       --
│    └─OutputScale: 2-2253               --                        --
│    └─Empty: 2-2254                     [128, 48, 1, 1]           --
│    └─Empty: 2-2255                     [128, 48, 1, 1]           --
│    └─Empty: 2-2256                     [128]                     --
│    └─Empty: 2-2257                     [128]                     --
│    └─BatchNorm2d: 2-2258               [16, 128, 64, 64]         --
│    └─Scaler: 2-2259                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2260                      [16, 128, 64, 64]         --
│    └─Empty: 2-2261                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2262                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-212               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2263        --                        --
│    └─One: 2-2264                       [1]                       --
│    └─OutputScale: 2-2265               --                        --
│    └─Empty: 2-2266                     [128, 128, 3, 3]          --
│    └─Empty: 2-2267                     [128, 128, 3, 3]          --
│    └─Empty: 2-2268                     [128]                     --
│    └─Empty: 2-2269                     [128]                     --
│    └─BatchNorm2d: 2-2270               [16, 128, 64, 64]         --
│    └─Scaler: 2-2271                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2272                      [16, 128, 64, 64]         --
│    └─Empty: 2-2273                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2274                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2275                 [16, 128, 32, 32]         --
│    └─Empty: 2-2276                     [16, 128, 32, 32]         --
│    └─Empty: 2-2277                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2278        --                        --
│    └─One: 2-2279                       [1]                       --
│    └─OutputScale: 2-2280               --                        --
│    └─Empty: 2-2281                     [128, 128, 3, 3]          --
│    └─Empty: 2-2282                     [128, 128, 3, 3]          --
│    └─Empty: 2-2283                     [128]                     --
│    └─Empty: 2-2284                     [128]                     --
│    └─BatchNorm2d: 2-2285               [16, 128, 32, 32]         --
│    └─Scaler: 2-2286                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2287                      [16, 128, 32, 32]         --
│    └─Empty: 2-2288                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2289                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-214               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2290        --                        --
│    └─One: 2-2291                       [1]                       --
│    └─OutputScale: 2-2292               --                        --
│    └─Empty: 2-2293                     [128, 128, 1, 1]          --
│    └─Empty: 2-2294                     [128, 128, 1, 1]          --
│    └─Empty: 2-2295                     [128]                     --
│    └─Empty: 2-2296                     [128]                     --
│    └─BatchNorm2d: 2-2297               [16, 128, 32, 32]         --
│    └─Scaler: 2-2298                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2299                      [16, 128, 32, 32]         --
│    └─Empty: 2-2300                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2301                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2302                 [16, 128, 32, 32]         --
│    └─Empty: 2-2303                     [16, 128, 32, 32]         --
│    └─Empty: 2-2304                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2305        --                        --
│    └─One: 2-2306                       [1]                       --
│    └─OutputScale: 2-2307               --                        --
│    └─Empty: 2-2308                     [128, 128, 3, 3]          --
│    └─Empty: 2-2309                     [128, 128, 3, 3]          --
│    └─Empty: 2-2310                     [128]                     --
│    └─Empty: 2-2311                     [128]                     --
│    └─BatchNorm2d: 2-2312               [16, 128, 32, 32]         --
│    └─Scaler: 2-2313                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2314                      [16, 128, 32, 32]         --
│    └─Empty: 2-2315                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2316                     [16, 128, 32, 32]         --
├─Dropout2d: 1-216                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-217        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2317                 [16, 128, 16, 16]         --
│    └─Empty: 2-2318                     [16, 128, 16, 16]         --
│    └─Empty: 2-2319                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2320        --                        --
│    └─One: 2-2321                       [1]                       --
│    └─OutputScale: 2-2322               --                        --
│    └─Empty: 2-2323                     [128, 128, 3, 3]          --
│    └─Empty: 2-2324                     [128, 128, 3, 3]          --
│    └─Empty: 2-2325                     [128]                     --
│    └─Empty: 2-2326                     [128]                     --
│    └─BatchNorm2d: 2-2327               [16, 128, 16, 16]         --
│    └─Scaler: 2-2328                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2329                      [16, 128, 16, 16]         --
│    └─Empty: 2-2330                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2331                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-218               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2332        --                        --
│    └─One: 2-2333                       [1]                       --
│    └─OutputScale: 2-2334               --                        --
│    └─Empty: 2-2335                     [128, 128, 1, 1]          --
│    └─Empty: 2-2336                     [128, 128, 1, 1]          --
│    └─Empty: 2-2337                     [128]                     --
│    └─Empty: 2-2338                     [128]                     --
│    └─BatchNorm2d: 2-2339               [16, 128, 16, 16]         --
│    └─Scaler: 2-2340                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2341                      [16, 128, 16, 16]         --
│    └─Empty: 2-2342                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2343                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2344                 [16, 128, 16, 16]         --
│    └─Empty: 2-2345                     [16, 128, 16, 16]         --
│    └─Empty: 2-2346                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2347        --                        --
│    └─One: 2-2348                       [1]                       --
│    └─OutputScale: 2-2349               --                        --
│    └─Empty: 2-2350                     [128, 128, 3, 3]          --
│    └─Empty: 2-2351                     [128, 128, 3, 3]          --
│    └─Empty: 2-2352                     [128]                     --
│    └─Empty: 2-2353                     [128]                     --
│    └─BatchNorm2d: 2-2354               [16, 128, 16, 16]         --
│    └─Scaler: 2-2355                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2356                      [16, 128, 16, 16]         --
│    └─Empty: 2-2357                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2358                     [16, 128, 16, 16]         --
├─Dropout2d: 1-220                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2359                 [16, 128, 8, 8]           --
│    └─Empty: 2-2360                     [16, 128, 8, 8]           --
│    └─Empty: 2-2361                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2362        --                        --
│    └─One: 2-2363                       [1]                       --
│    └─OutputScale: 2-2364               --                        --
│    └─Empty: 2-2365                     [128, 128, 3, 3]          --
│    └─Empty: 2-2366                     [128, 128, 3, 3]          --
│    └─Empty: 2-2367                     [128]                     --
│    └─Empty: 2-2368                     [128]                     --
│    └─BatchNorm2d: 2-2369               [16, 128, 8, 8]           --
│    └─Scaler: 2-2370                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2371                      [16, 128, 8, 8]           --
│    └─Empty: 2-2372                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2373                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-222               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2374        --                        --
│    └─One: 2-2375                       [1]                       --
│    └─OutputScale: 2-2376               --                        --
│    └─Empty: 2-2377                     [16, 128, 1, 1]           --
│    └─Empty: 2-2378                     [16, 128, 1, 1]           --
│    └─Empty: 2-2379                     [16]                      --
│    └─Empty: 2-2380                     [16]                      --
│    └─BatchNorm2d: 2-2381               [16, 16, 8, 8]            --
│    └─Scaler: 2-2382                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2383                      [16, 16, 8, 8]            --
│    └─Empty: 2-2384                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2385                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-223        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2386                 [16, 128, 8, 8]           --
│    └─Empty: 2-2387                     [16, 128, 8, 8]           --
│    └─Empty: 2-2388                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2389        --                        --
│    └─One: 2-2390                       [1]                       --
│    └─OutputScale: 2-2391               --                        --
│    └─Empty: 2-2392                     [16, 128, 3, 3]           --
│    └─Empty: 2-2393                     [16, 128, 3, 3]           --
│    └─Empty: 2-2394                     [16]                      --
│    └─Empty: 2-2395                     [16]                      --
│    └─BatchNorm2d: 2-2396               [16, 16, 8, 8]            --
│    └─Scaler: 2-2397                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2398                      [16, 16, 8, 8]            --
│    └─Empty: 2-2399                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2400                     [16, 16, 8, 8]            --
├─Dropout2d: 1-224                       [16, 16, 8, 8]            --
├─Linear: 1-225                          [16, 4]                   4,102
│    └─OutputShiftSqueeze: 2-2401        --                        --
│    └─One: 2-2402                       [1]                       --
│    └─OutputScale: 2-2403               --                        --
│    └─Empty: 2-2404                     [4, 1024]                 --
│    └─Empty: 2-2405                     [4, 1024]                 --
│    └─Empty: 2-2406                     [16, 4]                   --
│    └─Empty: 2-2407                     [16, 4]                   --
│    └─Clamp: 2-2408                     [16, 4]                   --
├─Linear: 1-226                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2409        --                        --
│    └─One: 2-2410                       [1]                       --
│    └─OutputScale: 2-2411               --                        --
│    └─Empty: 2-2412                     [4, 1024]                 --
│    └─Empty: 2-2413                     [4, 1024]                 --
│    └─Empty: 2-2414                     [16, 4]                   --
│    └─Empty: 2-2415                     [16, 4]                   --
│    └─Clamp: 2-2416                     [16, 4]                   --
├─Linear: 1-227                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2417        --                        --
│    └─One: 2-2418                       [1]                       --
│    └─OutputScale: 2-2419               --                        --
│    └─Empty: 2-2420                     [4, 1024]                 --
│    └─Empty: 2-2421                     [4, 1024]                 --
│    └─Empty: 2-2422                     [16, 4]                   --
│    └─Empty: 2-2423                     [16, 4]                   --
│    └─Clamp: 2-2424                     [16, 4]                   --
├─Linear: 1-228                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2425        --                        --
│    └─One: 2-2426                       [1]                       --
│    └─OutputScale: 2-2427               --                        --
│    └─Empty: 2-2428                     [4, 1024]                 --
│    └─Empty: 2-2429                     [4, 1024]                 --
│    └─Empty: 2-2430                     [16, 4]                   --
│    └─Empty: 2-2431                     [16, 4]                   --
│    └─Clamp: 2-2432                     [16, 4]                   --
├─Linear: 1-229                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2433        --                        --
│    └─One: 2-2434                       [1]                       --
│    └─OutputScale: 2-2435               --                        --
│    └─Empty: 2-2436                     [4, 1024]                 --
│    └─Empty: 2-2437                     [4, 1024]                 --
│    └─Empty: 2-2438                     [16, 4]                   --
│    └─Empty: 2-2439                     [16, 4]                   --
│    └─Clamp: 2-2440                     [16, 4]                   --
├─Linear: 1-230                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2441        --                        --
│    └─One: 2-2442                       [1]                       --
│    └─OutputScale: 2-2443               --                        --
│    └─Empty: 2-2444                     [4, 1024]                 --
│    └─Empty: 2-2445                     [4, 1024]                 --
│    └─Empty: 2-2446                     [16, 4]                   --
│    └─Empty: 2-2447                     [16, 4]                   --
│    └─Clamp: 2-2448                     [16, 4]                   --
├─Linear: 1-231                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2449        --                        --
│    └─One: 2-2450                       [1]                       --
│    └─OutputScale: 2-2451               --                        --
│    └─Empty: 2-2452                     [4, 1024]                 --
│    └─Empty: 2-2453                     [4, 1024]                 --
│    └─Empty: 2-2454                     [16, 4]                   --
│    └─Empty: 2-2455                     [16, 4]                   --
│    └─Clamp: 2-2456                     [16, 4]                   --
├─Linear: 1-232                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2457        --                        --
│    └─One: 2-2458                       [1]                       --
│    └─OutputScale: 2-2459               --                        --
│    └─Empty: 2-2460                     [4, 1024]                 --
│    └─Empty: 2-2461                     [4, 1024]                 --
│    └─Empty: 2-2462                     [16, 4]                   --
│    └─Empty: 2-2463                     [16, 4]                   --
│    └─Clamp: 2-2464                     [16, 4]                   --
├─Linear: 1-233                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2465        --                        --
│    └─One: 2-2466                       [1]                       --
│    └─OutputScale: 2-2467               --                        --
│    └─Empty: 2-2468                     [4, 1024]                 --
│    └─Empty: 2-2469                     [4, 1024]                 --
│    └─Empty: 2-2470                     [16, 4]                   --
│    └─Empty: 2-2471                     [16, 4]                   --
│    └─Clamp: 2-2472                     [16, 4]                   --
├─Linear: 1-234                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2473        --                        --
│    └─One: 2-2474                       [1]                       --
│    └─OutputScale: 2-2475               --                        --
│    └─Empty: 2-2476                     [4, 1024]                 --
│    └─Empty: 2-2477                     [4, 1024]                 --
│    └─Empty: 2-2478                     [16, 4]                   --
│    └─Empty: 2-2479                     [16, 4]                   --
│    └─Clamp: 2-2480                     [16, 4]                   --
├─Linear: 1-235                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2481        --                        --
│    └─One: 2-2482                       [1]                       --
│    └─OutputScale: 2-2483               --                        --
│    └─Empty: 2-2484                     [4, 1024]                 --
│    └─Empty: 2-2485                     [4, 1024]                 --
│    └─Empty: 2-2486                     [16, 4]                   --
│    └─Empty: 2-2487                     [16, 4]                   --
│    └─Clamp: 2-2488                     [16, 4]                   --
├─Linear: 1-236                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2489        --                        --
│    └─One: 2-2490                       [1]                       --
│    └─OutputScale: 2-2491               --                        --
│    └─Empty: 2-2492                     [4, 1024]                 --
│    └─Empty: 2-2493                     [4, 1024]                 --
│    └─Empty: 2-2494                     [16, 4]                   --
│    └─Empty: 2-2495                     [16, 4]                   --
│    └─Clamp: 2-2496                     [16, 4]                   --
├─Linear: 1-237                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2497        --                        --
│    └─One: 2-2498                       [1]                       --
│    └─OutputScale: 2-2499               --                        --
│    └─Empty: 2-2500                     [4, 1024]                 --
│    └─Empty: 2-2501                     [4, 1024]                 --
│    └─Empty: 2-2502                     [16, 4]                   --
│    └─Empty: 2-2503                     [16, 4]                   --
│    └─Clamp: 2-2504                     [16, 4]                   --
├─Linear: 1-238                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2505        --                        --
│    └─One: 2-2506                       [1]                       --
│    └─OutputScale: 2-2507               --                        --
│    └─Empty: 2-2508                     [4, 1024]                 --
│    └─Empty: 2-2509                     [4, 1024]                 --
│    └─Empty: 2-2510                     [16, 4]                   --
│    └─Empty: 2-2511                     [16, 4]                   --
│    └─Clamp: 2-2512                     [16, 4]                   --
├─Linear: 1-239                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2513        --                        --
│    └─One: 2-2514                       [1]                       --
│    └─OutputScale: 2-2515               --                        --
│    └─Empty: 2-2516                     [4, 1024]                 --
│    └─Empty: 2-2517                     [4, 1024]                 --
│    └─Empty: 2-2518                     [16, 4]                   --
│    └─Empty: 2-2519                     [16, 4]                   --
│    └─Clamp: 2-2520                     [16, 4]                   --
├─Linear: 1-240                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2521        --                        --
│    └─One: 2-2522                       [1]                       --
│    └─OutputScale: 2-2523               --                        --
│    └─Empty: 2-2524                     [4, 1024]                 --
│    └─Empty: 2-2525                     [4, 1024]                 --
│    └─Empty: 2-2526                     [16, 4]                   --
│    └─Empty: 2-2527                     [16, 4]                   --
│    └─Clamp: 2-2528                     [16, 4]                   --
==========================================================================================
Total params: 949,480
Trainable params: 949,408
Non-trainable params: 72
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.310 | Acc: 36.250% | Wgt Acc: 36.981%
	I - Batch: 100 | Loss: 1.221 | Acc: 41.500% | Wgt Acc: 41.982%
	I - Batch: 150 | Loss: 1.137 | Acc: 46.125% | Wgt Acc: 46.269%
I - num batch: 160
I - Train -- Loss: 1.125 | Acc: 46.761% | Wgt Acc: 46.913% | LR: 1.000000e-03 | Dur: 142.26s
I - Confusion Matrix: [row->prediction - col->label]
[[318.  48.  59. 154.]
 [ 80. 296. 236.  66.]
 [ 89. 168. 334.  75.]
 [210.  66. 105. 243.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.177 | Acc: 49.847% | Wgt Acc: 47.418% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  9.  9. 58.]
 [ 7. 34. 11.  5.]
 [ 8. 34. 49. 11.]
 [ 5.  1.  6. 12.]]

I - Local maximum validation set accuracy:  49.85

I - Validation set results: 
[14-1-2-1.15][50-3-1-1.58][124-2-2-0.48][127-0-0-3.44][443-2-2-2.62][567-0-0-2.07][573-1-1-1.10][615-0-0-2.53][695-1-2-0.62][722-3-0-3.30]
[826-0-0-4.42][878-0-0-2.31][1103-0-2-0.32][1212-3-0-1.11][1368-0-0-0.91][2181-2-3-0.47][2476-2-2-0.61][2721-2-2-1.06][2818-1-2-1.36][2886-2-2-2.21]
[3231-2-2-2.60][3333-2-3-0.23][3482-2-2-0.51][3536-3-3-0.17][3625-1-1-2.51][3909-0-2--0.01][4035-0-3-1.01][4140-0-0-1.10][4214-1-3--0.07][4346-1-0-2.01]
[4581-2-2-1.99][4708-3-2-0.25][4838-3-1-1.07][4845-1-2-1.45][4868-0-0-3.16][4939-0-2-1.26][4984-2-0-1.15][5078-1-2-1.12][5396-0-0-5.23][5479-1-1-1.59]
[5717-0-0-1.04][5843-1-1-1.71][5949-3-0-1.62][5987-2-1-1.94][6014-3-0-0.95][6033-3-0-3.20][6313-0-0-1.99][6421-3-0-1.69][6500-1-1-0.22][6583-3-0-0.85]
[6683-3-0-0.39][6825-2-0-1.50][6998-3-2-1.27][7049-3-3-0.57][7517-1-1-2.15][7521-1-1-0.76][7528-1-2-0.34][7949-1-2-2.09][8135-1-2-0.34][8185-3-0-3.15]
[8269-3-2-1.95][8273-3-0-1.77][8543-3-0-4.30][8666-1-1-1.48][8672-0-0-2.85][8903-1-0-0.60][9001-2-1-2.91][9036-2-2-2.61][9281-3-2-0.67][9300-2-2-1.63]
[9571-0-0-1.51][9617-1-1-2.15][9644-2-2-1.31][9705-2-0-0.23][9801-0-3-1.64][9803-3-0-1.13][9865-3-0-3.97][9896-2-2-1.55][10314-1-2-1.63][10337-3-0-2.62]
[10403-0-2-1.05][10653-2-1-1.39][10704-2-1-1.32][10719-1-1-1.82][10727-1-2-0.96][10836-0-0-3.88][10969-2-3-0.59][11042-0-0-1.28][11088-1-1-1.11][11322-0-0-2.89]
[11398-2-2-2.88][11499-0-0-0.98][11502-3-0-1.88][11512-3-2-0.65][11608-1-1-3.62][11610-0-0-0.97][11692-0-0-3.06][11905-0-0-3.22][11993-1-2-2.02][12002-2-0-4.08]
[12052-0-0-2.17][12201-0-0-3.99][12235-2-1-1.84][12320-1-2-1.71][12377-2-2-1.87][12398-2-3--0.13][12503-1-2-1.05][12617-0-1-1.89][12685-3-3--0.01][12738-2-0-0.97]
[12742-2-2-2.29][12823-0-0-2.51][13110-1-1-1.21][13240-3-0-2.02][13253-1-1-2.54][13273-0-0-3.94][13634-1-1-1.05][13763-2-2-0.40][13905-3-0-0.91][14060-2-1-1.93]
[14065-3-0-2.23][14147-3-0-0.40][14595-2-2-0.84][14687-2-2-1.43][14788-2-2-1.37][14869-1-1-1.70][14872-3-0-0.78][14877-1-0-0.41][14927-0-0-1.30][15066-0-0-3.80]
[15175-1-2-1.22][15178-2-0-1.85][15375-3-0-0.77][15389-3-0-3.56][15568-2-1-0.80][15675-3-0-0.09][15869-1-2-1.17][16207-3-0-1.24][16236-0-0-1.90][16302-3-0-3.02]
[16331-2-2-2.47][16381-0-0-1.36][16488-1-1-1.62][16495-0-0-0.82][16650-0-0-3.37][16719-1-1-1.17][16801-0-0-2.86][16828-0-0-1.13][17137-3-0-2.54][17245-1-0-0.12]
[17278-3-0-0.00][17282-0-1-0.18][17311-2-2-1.66][17336-2-2-0.67][17608-3-0-3.16][17627-0-0-0.58][17877-3-2-2.60][17924-1-0-1.27][17984-3-0-2.82][18211-0-3-0.08]
[18276-3-0-1.89][18287-1-1-0.28][18394-0-0-2.73][18428-0-0-3.20][18442-0-0-2.99][18478-3-0-2.67][18607-0-1-1.19][18616-0-1-0.09][18663-0-0-0.57][18718-0-0-3.32]
[18766-2-2-1.66][18824-2-2-1.52][18890-3-2-1.19][18930-3-2-1.28][18938-3-0-1.27][19817-1-2-2.03][19839-0-0-0.51][19930-3-0-1.61][19944-0-2-0.57][20036-2-2-1.58]
[20101-3-0-1.44][20474-1-2-2.24][20547-3-2-0.33][20929-2-2-2.22][21245-1-2-1.29][21257-3-3-0.38][21293-1-1-2.28][21316-1-1-1.03][21384-1-2-1.07][21448-1-2-1.70]
[21483-0-0-2.45][21487-2-2-0.80][21714-0-0-1.46][21943-3-2-1.42][21947-0-0-1.11][21948-0-0-2.12][21965-2-2-2.92][21998-1-2-0.80][22025-0-3-0.52][22228-3-0-1.14]
[22446-1-1-2.20][22494-3-0-3.47][22757-0-0-4.00][22811-3-0-2.29][22976-3-1-1.24][22985-3-0-2.61][23014-0-0-3.62][23112-1-1-2.55][23144-3-0-3.45][23168-2-1-0.58]
[23219-0-0-1.18][23363-3-3-0.76][23470-0-2-0.56][23486-2-3-0.43][23497-0-0-3.11][23516-0-0-3.71][23690-1-2-0.23][23921-2-2-1.42][23936-1-2-2.04][24040-3-0-1.09]
[24111-1-1-1.92][24182-0-0-3.39][24238-3-0-1.70][24290-2-0-1.39][24345-0-0-0.74][24364-1-2-0.19][24427-3-0-1.26][24477-2-2-0.99][24495-2-1-0.74][24893-2-2-2.29]
[25012-1-1-0.86][25121-2-2-0.76][25165-3-0-1.18][25183-0-0-0.31][25297-3-3-0.68][25398-0-0-1.92][25574-2-1-0.17][25644-1-2-1.66][25718-1-1-0.23][25774-2-2-0.74]
[26032-3-0-2.79][26051-3-0-3.06][26120-0-2-0.28][26321-1-2-0.89][26732-1-1-1.69][26784-3-0-3.47][26827-3-0-2.07][26833-0-3-1.74][26838-2-2-0.24][26860-1-0-0.47]
[26948-0-0-1.63][27049-3-0-1.05][27098-1-0-0.50][27526-0-0-3.56][27639-3-3-0.56][27698-3-0-1.66][27772-0-0-2.68][27890-1-1-2.34][28040-0-0-1.42][28503-2-2-2.49]
[28577-1-2-1.74][28959-0-0-3.23][29198-3-1-1.16][29777-0-0-4.90][29877-2-2-0.99][30035-1-2-2.38][30098-0-0-1.35][30326-1-1-2.32][30572-2-2-0.63][30716-0-1-1.03]
[30806-2-3-0.06][30906-1-2-1.72][31007-0-0-1.05][31181-3-0-2.38][31238-0-0-3.36][31347-0-0-3.35][31422-2-2-0.94][31429-3-0-1.55][31431-0-0-0.55][31432-1-1-1.60]
[31477-0-0-4.32][31524-1-2-0.11][31597-1-1-1.36][31619-1-0-0.40][31701-0-0-3.08][31755-0-0-2.80][31854-3-3-1.18][32074-1-2-0.18][32078-3-3-1.06][32111-1-1-1.49]
[32127-1-2-3.18][32140-3-0-2.77][32263-2-2-1.23][32365-0-2-0.49][32411-2-0-2.62][32429-3-0-3.14][32473-3-0-1.89][32574-3-0-3.28][32584-0-0-0.56][32622-0-1-1.10]
[32858-3-0-2.37][32969-3-0-4.22][33016-2-2-1.67][33031-1-0-0.34][33035-2-2-1.77][33133-2-2-1.10][33173-2-2-1.50][33175-3-2-1.51][33306-3-1-1.11][33309-2-2-0.31]
[33474-0-1-0.16][33478-2-0-1.33][33618-1-1-1.64][33712-0-0-0.86][33782-2-2-1.95][33914-3-3-0.45][34076-3-3-0.82][34112-2-1-0.39][34138-2-2-0.85][34239-1-2-1.22]
[34364-2-2-1.46][34617-1-1-1.77][34751-3-3-1.68][34783-2-2-1.48][35015-3-0-1.19][35018-1-2-1.83][35288-2-2-0.22]
---------------------------
I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 0.959 | Acc: 58.375% | Wgt Acc: 58.708%
	I - Batch: 100 | Loss: 0.940 | Acc: 60.000% | Wgt Acc: 59.611%
	I - Batch: 150 | Loss: 0.916 | Acc: 61.042% | Wgt Acc: 60.751%
I - num batch: 160
I - Train -- Loss: 0.921 | Acc: 60.934% | Wgt Acc: 60.642% | LR: 1.000000e-03 | Dur: 141.56s
I - Confusion Matrix: [row->prediction - col->label]
[[458.  22.  42. 150.]
 [ 49. 369. 172.  48.]
 [ 44. 154. 447.  62.]
 [146.  33.  73. 278.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 58.104% | Wgt Acc: 58.764% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[44.  4.  5. 13.]
 [ 5. 46. 12.  6.]
 [ 2. 20. 41.  8.]
 [37.  8. 17. 59.]]

I - Local maximum validation set accuracy:  58.10

I - Validation set results: 
[14-1-2-1.30][50-3-3-0.57][124-2-2-0.85][127-0-0-3.07][443-2-2-2.29][567-0-0-2.09][573-1-1-1.49][615-0-0-1.85][695-1-2-1.02][722-3-3-2.10]
[826-0-0-3.36][878-0-3-2.50][1103-0-0-0.93][1212-3-3-1.91][1368-0-0-0.66][2181-2-3-0.91][2476-2-2-0.61][2721-2-2-1.72][2818-1-2-0.21][2886-2-1-1.92]
[3231-2-1-1.88][3333-2-3-1.44][3482-2-2-0.12][3536-3-3-1.52][3625-1-1-2.36][3909-0-3-0.64][4035-0-3-1.98][4140-0-0-1.00][4214-1-3-1.70][4346-1-0-1.79]
[4581-2-2-2.26][4708-3-3-0.60][4838-3-2-0.37][4845-1-1-1.10][4868-0-0-1.69][4939-0-1-1.12][4984-2-3-0.72][5078-1-1-0.67][5396-0-0-4.58][5479-1-1-1.92]
[5717-0-0-2.12][5843-1-1-1.22][5949-3-3-2.04][5987-2-1-0.63][6014-3-3-0.81][6033-3-0-0.83][6313-0-3-1.64][6421-3-3-1.81][6500-1-1-0.47][6583-3-3-1.70]
[6683-3-3-1.23][6825-2-0-0.52][6998-3-2-1.07][7049-3-3-1.15][7517-1-1-2.01][7521-1-1-0.21][7528-1-3-0.73][7949-1-2-1.76][8135-1-0-0.37][8185-3-0-1.64]
[8269-3-1-0.07][8273-3-3-1.66][8543-3-0-3.32][8666-1-3-0.22][8672-0-0-4.49][8903-1-2-0.22][9001-2-1-1.54][9036-2-2-2.28][9281-3-3-0.56][9300-2-2-1.09]
[9571-0-3-1.18][9617-1-1-1.69][9644-2-2-1.30][9705-2-2--0.15][9801-0-3-3.24][9803-3-3-1.16][9865-3-3-2.88][9896-2-2-1.77][10314-1-1-0.85][10337-3-3-3.33]
[10403-0-2-0.82][10653-2-1-0.61][10704-2-3-0.51][10719-1-1-1.02][10727-1-2-0.69][10836-0-3-3.46][10969-2-3-1.43][11042-0-0-1.27][11088-1-1-2.41][11322-0-3-2.71]
[11398-2-2-2.24][11499-0-3-0.90][11502-3-3-1.27][11512-3-3-0.61][11608-1-1-3.40][11610-0-3-1.33][11692-0-3-1.38][11905-0-0-3.12][11993-1-2-1.21][12002-2-3-0.28]
[12052-0-0-1.22][12201-0-3-2.91][12235-2-2-1.20][12320-1-2-0.37][12377-2-2-0.86][12398-2-3-0.53][12503-1-2-0.80][12617-0-3-0.13][12685-3-1-0.44][12738-2-3-0.40]
[12742-2-2-3.14][12823-0-3-3.15][13110-1-1-1.27][13240-3-3-1.86][13253-1-1-2.12][13273-0-0-4.05][13634-1-1-0.74][13763-2-3-0.69][13905-3-3-0.62][14060-2-1-1.75]
[14065-3-3-1.21][14147-3-3-1.16][14595-2-2-1.88][14687-2-2-1.31][14788-2-2-0.94][14869-1-1-1.48][14872-3-0-1.11][14877-1-1-0.87][14927-0-3-2.08][15066-0-0-3.21]
[15175-1-1-0.22][15178-2-0-0.63][15375-3-3-2.33][15389-3-3-2.79][15568-2-1-0.09][15675-3-3-1.53][15869-1-1-0.10][16207-3-3-0.81][16236-0-3-0.33][16302-3-0-2.33]
[16331-2-2-2.99][16381-0-0-1.25][16488-1-1-2.19][16495-0-0-1.82][16650-0-0-3.17][16719-1-2-0.11][16801-0-0-3.51][16828-0-3-1.37][17137-3-0-1.39][17245-1-2-1.10]
[17278-3-3-0.14][17282-0-1-0.47][17311-2-2-2.28][17336-2-2-1.22][17608-3-3-2.72][17627-0-3-0.77][17877-3-2-1.89][17924-1-1-0.20][17984-3-0-2.37][18211-0-3-1.91]
[18276-3-3-1.94][18287-1-1-1.20][18394-0-0-2.14][18428-0-1-0.58][18442-0-3-2.76][18478-3-3-1.69][18607-0-0-1.58][18616-0-3-1.47][18663-0-3-1.41][18718-0-0-2.95]
[18766-2-1-1.91][18824-2-2-1.18][18890-3-2-0.42][18930-3-2-0.09][18938-3-3-1.45][19817-1-2-1.64][19839-0-2-0.74][19930-3-3-0.93][19944-0-0-1.52][20036-2-2-1.08]
[20101-3-3-1.42][20474-1-2-1.72][20547-3-3-0.77][20929-2-2-2.44][21245-1-2-0.66][21257-3-1-0.76][21293-1-1-2.32][21316-1-1-1.40][21384-1-2-1.65][21448-1-2-0.92]
[21483-0-0-1.74][21487-2-2-1.46][21714-0-3-0.87][21943-3-1-1.32][21947-0-0-2.75][21948-0-0-2.83][21965-2-2-1.67][21998-1-1-0.29][22025-0-3-1.86][22228-3-3-1.85]
[22446-1-1-2.34][22494-3-0-2.71][22757-0-3-2.36][22811-3-3-3.55][22976-3-2-1.01][22985-3-3-3.00][23014-0-3-4.20][23112-1-1-1.66][23144-3-3-3.41][23168-2-0-0.49]
[23219-0-0-1.87][23363-3-3-2.51][23470-0-1--0.28][23486-2-3-0.70][23497-0-3-3.37][23516-0-0-3.66][23690-1-1-0.85][23921-2-2-1.69][23936-1-2-1.56][24040-3-2--0.03]
[24111-1-1-0.58][24182-0-3-3.83][24238-3-3-2.63][24290-2-0-1.70][24345-0-3-0.98][24364-1-2-0.78][24427-3-3-2.55][24477-2-2-1.97][24495-2-1-0.71][24893-2-1-1.63]
[25012-1-3--0.28][25121-2-0-0.76][25165-3-3-1.72][25183-0-0-0.98][25297-3-3-1.85][25398-0-0-1.83][25574-2-3-0.40][25644-1-1-1.13][25718-1-0--0.11][25774-2-3-1.12]
[26032-3-3-2.13][26051-3-3-2.84][26120-0-0-1.08][26321-1-1-0.64][26732-1-1-0.93][26784-3-3-3.74][26827-3-3-2.71][26833-0-3-2.81][26838-2-2-0.35][26860-1-1-0.48]
[26948-0-0-0.35][27049-3-3-1.15][27098-1-3-0.10][27526-0-0-3.83][27639-3-3-2.08][27698-3-3-2.53][27772-0-3-2.60][27890-1-1-1.57][28040-0-0-1.63][28503-2-2-3.81]
[28577-1-1-1.60][28959-0-0-3.17][29198-3-1--0.04][29777-0-0-4.47][29877-2-2-0.67][30035-1-1-1.40][30098-0-3-2.25][30326-1-1-1.63][30572-2-2-1.44][30716-0-3-0.26]
[30806-2-2-0.41][30906-1-1-0.96][31007-0-0-1.51][31181-3-3-0.94][31238-0-3-1.94][31347-0-3-3.69][31422-2-2-0.60][31429-3-0-0.91][31431-0-0-1.23][31432-1-1-1.76]
[31477-0-3-3.66][31524-1-3-0.29][31597-1-1-1.99][31619-1-0-0.40][31701-0-0-3.12][31755-0-0-2.19][31854-3-3-1.75][32074-1-3-2.29][32078-3-3-2.06][32111-1-2-0.47]
[32127-1-2-2.92][32140-3-3-1.50][32263-2-2-0.43][32365-0-0-1.19][32411-2-3-3.18][32429-3-0-2.51][32473-3-0-1.61][32574-3-3-2.92][32584-0-0-0.77][32622-0-1-0.32]
[32858-3-0-1.15][32969-3-0-2.58][33016-2-1-0.90][33031-1-3-0.44][33035-2-2-2.86][33133-2-2-0.93][33173-2-2-1.37][33175-3-2-1.92][33306-3-1-1.19][33309-2-3-0.08]
[33474-0-0-0.24][33478-2-3-0.33][33618-1-1-0.32][33712-0-3-1.21][33782-2-2-2.30][33914-3-3-2.81][34076-3-3-1.17][34112-2-3-0.19][34138-2-2-1.54][34239-1-1-0.98]
[34364-2-1-1.76][34617-1-1-0.60][34751-3-3-2.40][34783-2-2-1.02][35015-3-3-1.31][35018-1-1-1.27][35288-2-3-0.64]
---------------------------
I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.860 | Acc: 63.125% | Wgt Acc: 62.708%
	I - Batch: 100 | Loss: 0.824 | Acc: 65.188% | Wgt Acc: 64.627%
	I - Batch: 150 | Loss: 0.822 | Acc: 65.333% | Wgt Acc: 64.817%
I - num batch: 160
I - Train -- Loss: 0.828 | Acc: 65.410% | Wgt Acc: 64.959% | LR: 1.000000e-03 | Dur: 141.36s
I - Confusion Matrix: [row->prediction - col->label]
[[496.  19.  22. 126.]
 [ 31. 372. 166.  49.]
 [ 33. 145. 491.  56.]
 [137.  42.  55. 307.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.005 | Acc: 58.716% | Wgt Acc: 57.133% | Dur: 11.77s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  6.  5. 37.]
 [ 5. 47. 13.  8.]
 [ 7. 24. 53. 15.]
 [10.  1.  4. 26.]]

I - Local maximum validation set accuracy:  58.72

I - Validation set results: 
[14-1-2-2.25][50-3-1-0.44][124-2-2-2.10][127-0-0-3.38][443-2-2-1.80][567-0-0-2.16][573-1-1-1.35][615-0-0-1.95][695-1-2-1.62][722-3-0-2.42]
[826-0-0-2.48][878-0-0-2.31][1103-0-0-0.28][1212-3-2-0.48][1368-0-0-2.01][2181-2-3--0.11][2476-2-2-0.67][2721-2-2-3.54][2818-1-1-0.14][2886-2-1-2.22]
[3231-2-2-2.80][3333-2-1-1.35][3482-2-2-0.72][3536-3-3-0.54][3625-1-1-2.54][3909-0-0-0.67][4035-0-3-1.13][4140-0-0-1.19][4214-1-2-0.91][4346-1-0-1.22]
[4581-2-2-1.99][4708-3-2-0.45][4838-3-2-0.46][4845-1-2-1.43][4868-0-0-3.05][4939-0-2-1.06][4984-2-2-1.20][5078-1-1-1.06][5396-0-0-4.40][5479-1-1-1.91]
[5717-0-0-1.93][5843-1-1-2.00][5949-3-0-1.42][5987-2-1-1.52][6014-3-3-0.69][6033-3-0-0.98][6313-0-0-2.13][6421-3-3-0.43][6500-1-1-0.43][6583-3-2-0.66]
[6683-3-3-0.60][6825-2-0-0.84][6998-3-2-1.55][7049-3-3-0.50][7517-1-1-1.99][7521-1-1-0.56][7528-1-3-0.66][7949-1-2-1.76][8135-1-0-3.38][8185-3-0-0.60]
[8269-3-1-0.44][8273-3-0-2.51][8543-3-0-4.97][8666-1-1-1.37][8672-0-0-3.67][8903-1-2-2.83][9001-2-1-1.80][9036-2-2-2.37][9281-3-1-0.01][9300-2-2-1.61]
[9571-0-3-0.21][9617-1-1-1.30][9644-2-2-1.64][9705-2-2-0.63][9801-0-3-1.37][9803-3-0-1.58][9865-3-0-1.59][9896-2-2-2.69][10314-1-1-1.41][10337-3-3-2.23]
[10403-0-2-1.33][10653-2-1-1.21][10704-2-1-1.07][10719-1-1-2.99][10727-1-1-0.99][10836-0-0-4.42][10969-2-3-0.67][11042-0-0-0.83][11088-1-1-1.75][11322-0-0-4.03]
[11398-2-2-2.18][11499-0-0-0.62][11502-3-0-0.38][11512-3-0-0.17][11608-1-1-2.53][11610-0-0-1.79][11692-0-3-0.77][11905-0-0-2.61][11993-1-2-1.93][12002-2-3--0.17]
[12052-0-0-2.94][12201-0-0-1.99][12235-2-2-1.83][12320-1-2-0.71][12377-2-1-1.08][12398-2-3-0.13][12503-1-1-1.78][12617-0-1-1.22][12685-3-2-0.30][12738-2-2-0.81]
[12742-2-2-3.51][12823-0-3-1.33][13110-1-1-0.84][13240-3-0-2.39][13253-1-1-2.12][13273-0-0-4.42][13634-1-2-1.66][13763-2-2-0.38][13905-3-0--0.10][14060-2-1-2.03]
[14065-3-3-1.31][14147-3-2-1.12][14595-2-2-2.30][14687-2-2-1.99][14788-2-2-1.32][14869-1-1-2.34][14872-3-0-0.95][14877-1-1-1.12][14927-0-3-0.20][15066-0-0-4.85]
[15175-1-1-0.57][15178-2-2-0.58][15375-3-3-0.72][15389-3-3-1.46][15568-2-1-1.77][15675-3-0-1.07][15869-1-2-0.95][16207-3-0-0.17][16236-0-3-0.31][16302-3-3-0.57]
[16331-2-2-2.73][16381-0-0-1.45][16488-1-1-2.33][16495-0-0-2.60][16650-0-0-2.62][16719-1-2-0.35][16801-0-0-4.51][16828-0-0-1.83][17137-3-0-1.42][17245-1-2-1.60]
[17278-3-1-0.02][17282-0-0-0.72][17311-2-2-3.16][17336-2-2-2.23][17608-3-3-1.71][17627-0-1-0.43][17877-3-0-1.30][17924-1-2-0.16][17984-3-0-3.83][18211-0-0-0.56]
[18276-3-0-1.85][18287-1-0-0.41][18394-0-0-2.52][18428-0-0-0.46][18442-0-0-1.84][18478-3-0-0.91][18607-0-0-2.55][18616-0-0-0.58][18663-0-0-0.54][18718-0-0-3.42]
[18766-2-2-3.70][18824-2-1-1.47][18890-3-2-0.33][18930-3-2-0.49][18938-3-3-0.57][19817-1-2-2.22][19839-0-2-1.16][19930-3-3-0.11][19944-0-2-1.92][20036-2-2-1.90]
[20101-3-0-0.85][20474-1-1-1.69][20547-3-0-0.90][20929-2-2-2.00][21245-1-2-1.76][21257-3-1-0.04][21293-1-1-2.53][21316-1-1-0.10][21384-1-1-1.84][21448-1-2-1.82]
[21483-0-0-2.34][21487-2-2-3.23][21714-0-0--0.13][21943-3-2-0.67][21947-0-0-2.04][21948-0-0-3.74][21965-2-2-2.00][21998-1-1-0.98][22025-0-2-0.11][22228-3-0-2.08]
[22446-1-1-2.41][22494-3-0-2.57][22757-0-0-3.26][22811-3-3-2.14][22976-3-1-1.37][22985-3-3-1.72][23014-0-3-2.34][23112-1-1-2.13][23144-3-0-2.40][23168-2-0-1.33]
[23219-0-0-0.39][23363-3-3-0.87][23470-0-1-0.47][23486-2-2-0.87][23497-0-0-3.60][23516-0-0-3.35][23690-1-2-1.17][23921-2-2-1.60][23936-1-2-1.71][24040-3-2-1.13]
[24111-1-1-1.54][24182-0-0-3.41][24238-3-3-1.29][24290-2-0-1.93][24345-0-0-0.31][24364-1-2-1.64][24427-3-0-1.36][24477-2-2-3.32][24495-2-1-0.89][24893-2-2-1.67]
[25012-1-1-0.39][25121-2-2-0.82][25165-3-0-0.90][25183-0-0-2.17][25297-3-2-0.92][25398-0-0-1.63][25574-2-1-1.39][25644-1-1-2.64][25718-1-1-0.68][25774-2-2-1.22]
[26032-3-3-1.52][26051-3-3-1.83][26120-0-0-0.26][26321-1-1-1.40][26732-1-1-1.25][26784-3-3-2.23][26827-3-3-0.87][26833-0-3-2.07][26838-2-2-1.69][26860-1-2-1.28]
[26948-0-0-0.57][27049-3-0-1.26][27098-1-1-0.53][27526-0-0-2.05][27639-3-1-0.10][27698-3-3-1.26][27772-0-0-0.92][27890-1-1-1.74][28040-0-2-0.97][28503-2-2-3.24]
[28577-1-2-1.89][28959-0-0-2.96][29198-3-0-0.45][29777-0-0-4.52][29877-2-2-1.31][30035-1-1-1.52][30098-0-0-0.55][30326-1-1-1.49][30572-2-2-1.37][30716-0-1-0.64]
[30806-2-2-0.79][30906-1-1-2.01][31007-0-2-0.69][31181-3-0-0.92][31238-0-0-1.17][31347-0-3-1.73][31422-2-2-1.71][31429-3-0-0.23][31431-0-0-0.52][31432-1-1-2.14]
[31477-0-0-1.96][31524-1-0-0.40][31597-1-2-1.98][31619-1-2-0.64][31701-0-0-2.50][31755-0-0-1.82][31854-3-0-0.84][32074-1-0-0.06][32078-3-3-0.88][32111-1-1-0.80]
[32127-1-2-2.74][32140-3-3-1.12][32263-2-0-0.48][32365-0-0-1.47][32411-2-0-2.76][32429-3-0-2.79][32473-3-0-1.09][32574-3-0-4.59][32584-0-0-1.38][32622-0-1-0.78]
[32858-3-0-1.65][32969-3-0-2.24][33016-2-2-1.81][33031-1-0-1.02][33035-2-2-2.89][33133-2-2-2.43][33173-2-2-0.81][33175-3-1-2.09][33306-3-2-1.79][33309-2-1-0.22]
[33474-0-0-0.59][33478-2-2-0.90][33618-1-1-1.38][33712-0-0-0.70][33782-2-2-2.28][33914-3-2-1.43][34076-3-3-0.61][34112-2-2-1.28][34138-2-2-2.78][34239-1-1-1.00]
[34364-2-2-3.03][34617-1-1-1.14][34751-3-3-1.52][34783-2-2-1.78][35015-3-2-1.34][35018-1-1-2.35][35288-2-2-0.59]
---------------------------
I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.752 | Acc: 67.500% | Wgt Acc: 66.516%
	I - Batch: 100 | Loss: 0.762 | Acc: 68.812% | Wgt Acc: 68.177%
	I - Batch: 150 | Loss: 0.772 | Acc: 68.042% | Wgt Acc: 67.524%
I - num batch: 160
I - Train -- Loss: 0.777 | Acc: 68.355% | Wgt Acc: 67.861% | LR: 1.000000e-03 | Dur: 142.13s
I - Confusion Matrix: [row->prediction - col->label]
[[510.  22.  21. 138.]
 [ 29. 387. 134.  34.]
 [ 32. 143. 524.  46.]
 [126.  26.  55. 320.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.022 | Acc: 55.352% | Wgt Acc: 54.484% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[49.  4.  0. 22.]
 [ 2. 38. 14.  5.]
 [16. 35. 54. 19.]
 [21.  1.  7. 40.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.687 | Acc: 71.000% | Wgt Acc: 71.056%
	I - Batch: 100 | Loss: 0.720 | Acc: 70.500% | Wgt Acc: 70.343%
	I - Batch: 150 | Loss: 0.725 | Acc: 70.500% | Wgt Acc: 70.157%
I - num batch: 160
I - Train -- Loss: 0.727 | Acc: 70.357% | Wgt Acc: 70.046% | LR: 1.000000e-03 | Dur: 140.36s
I - Confusion Matrix: [row->prediction - col->label]
[[525.  27.  27. 116.]
 [ 27. 397. 142.  27.]
 [ 32. 125. 517.  42.]
 [113.  29.  48. 353.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.936 | Acc: 60.856% | Wgt Acc: 61.549% | Dur: 11.50s
I - Confusion Matrix: [row->prediction - col->label]
[[43.  3.  4. 13.]
 [ 4. 46. 14.  2.]
 [ 5. 25. 46.  7.]
 [36.  4. 11. 64.]]

I - Local maximum validation set accuracy:  60.86

I - Validation set results: 
[14-1-2-1.95][50-3-0-0.39][124-2-2-0.90][127-0-0-2.33][443-2-2-1.20][567-0-0-2.00][573-1-1-1.48][615-0-0-1.11][695-1-2-1.03][722-3-3-2.39]
[826-0-0-1.50][878-0-3-1.98][1103-0-0-0.89][1212-3-3-1.05][1368-0-0-1.54][2181-2-3-0.86][2476-2-2-0.29][2721-2-2-1.88][2818-1-0--0.05][2886-2-1-2.42]
[3231-2-2-3.01][3333-2-2-0.76][3482-2-2-1.65][3536-3-3-2.50][3625-1-1-3.03][3909-0-0-0.73][4035-0-3-2.45][4140-0-0-1.77][4214-1-2-0.77][4346-1-0-0.34]
[4581-2-2-2.71][4708-3-3-0.71][4838-3-3-0.08][4845-1-2-0.40][4868-0-0-1.30][4939-0-1-1.18][4984-2-2-1.23][5078-1-1-0.80][5396-0-3-2.55][5479-1-1-2.66]
[5717-0-0-2.07][5843-1-1-3.04][5949-3-3-1.14][5987-2-1-1.53][6014-3-3-1.50][6033-3-0-0.70][6313-0-0-1.37][6421-3-3-2.20][6500-1-1-0.22][6583-3-3-0.96]
[6683-3-3-0.36][6825-2-3-1.46][6998-3-3-0.25][7049-3-3-1.59][7517-1-1-1.94][7521-1-1-1.15][7528-1-3-0.34][7949-1-2-1.05][8135-1-0-1.36][8185-3-0-1.03]
[8269-3-2-0.04][8273-3-3-1.75][8543-3-0-2.38][8666-1-1-1.27][8672-0-3-1.99][8903-1-1-0.07][9001-2-1-1.01][9036-2-2-1.21][9281-3-3-0.47][9300-2-2-2.10]
[9571-0-3-1.31][9617-1-1-0.40][9644-2-2-1.31][9705-2-2-0.84][9801-0-3-1.18][9803-3-3-1.45][9865-3-3-2.84][9896-2-2-1.71][10314-1-2-1.43][10337-3-3-3.54]
[10403-0-2--0.29][10653-2-1-2.07][10704-2-1-0.74][10719-1-1-2.15][10727-1-1-1.77][10836-0-0-3.13][10969-2-3-1.87][11042-0-0-1.46][11088-1-1-1.82][11322-0-0-1.94]
[11398-2-2-1.81][11499-0-3-0.57][11502-3-0-1.12][11512-3-3-0.79][11608-1-1-2.88][11610-0-0-0.77][11692-0-0-0.91][11905-0-0-2.52][11993-1-2-1.65][12002-2-2-0.10]
[12052-0-0-0.88][12201-0-3-2.74][12235-2-1-1.71][12320-1-2-0.14][12377-2-1-0.60][12398-2-3-0.61][12503-1-2-1.33][12617-0-1-1.12][12685-3-3-0.66][12738-2-3-0.44]
[12742-2-2-2.06][12823-0-3-1.78][13110-1-1-0.81][13240-3-3-1.27][13253-1-1-3.15][13273-0-0-2.29][13634-1-2-1.31][13763-2-3-0.72][13905-3-3-0.56][14060-2-1-2.66]
[14065-3-3-1.14][14147-3-3-0.57][14595-2-2-1.88][14687-2-2-1.34][14788-2-2-1.27][14869-1-1-1.94][14872-3-0--0.24][14877-1-1-2.33][14927-0-3-0.65][15066-0-0-3.20]
[15175-1-1-0.41][15178-2-2-0.36][15375-3-3-1.81][15389-3-3-2.18][15568-2-1-2.65][15675-3-3-0.92][15869-1-2-0.09][16207-3-0-0.85][16236-0-3-0.28][16302-3-3-0.98]
[16331-2-2-3.07][16381-0-3-0.81][16488-1-1-4.09][16495-0-0-0.59][16650-0-3-2.54][16719-1-1-1.26][16801-0-0-4.26][16828-0-3-1.19][17137-3-0-1.40][17245-1-2-1.16]
[17278-3-3-0.10][17282-0-1--0.09][17311-2-2-2.18][17336-2-2-1.47][17608-3-3-3.38][17627-0-2-0.30][17877-3-1-1.75][17924-1-2-0.46][17984-3-0-2.67][18211-0-3-1.58]
[18276-3-3-2.74][18287-1-1-1.14][18394-0-3-1.77][18428-0-3-0.41][18442-0-3-2.23][18478-3-3-1.51][18607-0-0-2.07][18616-0-3-0.43][18663-0-0-0.79][18718-0-0-2.52]
[18766-2-2-2.02][18824-2-1-0.97][18890-3-3-0.79][18930-3-2-0.29][18938-3-3-1.08][19817-1-2-1.49][19839-0-2-1.11][19930-3-3-1.38][19944-0-2-0.82][20036-2-2-1.87]
[20101-3-3-1.92][20474-1-1-2.02][20547-3-0-0.88][20929-2-2-1.68][21245-1-2-1.29][21257-3-3-0.57][21293-1-1-1.76][21316-1-1-2.97][21384-1-1-1.61][21448-1-2-1.26]
[21483-0-3-1.49][21487-2-2-1.71][21714-0-3--0.04][21943-3-2-0.38][21947-0-0-1.84][21948-0-0-3.89][21965-2-2-1.99][21998-1-1-0.76][22025-0-3-0.85][22228-3-3-2.89]
[22446-1-1-3.41][22494-3-3-1.76][22757-0-3-2.28][22811-3-3-2.39][22976-3-1-1.14][22985-3-3-2.70][23014-0-3-3.01][23112-1-1-2.27][23144-3-3-3.32][23168-2-0-1.88]
[23219-0-3-1.61][23363-3-3-0.72][23470-0-0-0.69][23486-2-3-0.78][23497-0-3-2.75][23516-0-0-1.95][23690-1-2--0.10][23921-2-2-1.77][23936-1-2-1.55][24040-3-2-0.28]
[24111-1-1-1.51][24182-0-3-2.57][24238-3-3-1.83][24290-2-0-1.40][24345-0-0-2.51][24364-1-2-0.72][24427-3-0-1.06][24477-2-2-1.93][24495-2-1-0.86][24893-2-2-1.02]
[25012-1-1-0.70][25121-2-1-1.45][25165-3-3-1.38][25183-0-0-1.72][25297-3-3-1.96][25398-0-0-1.08][25574-2-2-0.57][25644-1-1-1.51][25718-1-1-0.84][25774-2-2-1.18]
[26032-3-3-1.37][26051-3-3-2.35][26120-0-0-0.78][26321-1-1-0.59][26732-1-1-1.53][26784-3-3-2.99][26827-3-3-1.83][26833-0-3-2.27][26838-2-1-0.97][26860-1-2-1.73]
[26948-0-0-0.92][27049-3-0-0.85][27098-1-2-0.11][27526-0-0-2.94][27639-3-3-0.80][27698-3-3-2.32][27772-0-3-1.48][27890-1-1-2.14][28040-0-2-0.64][28503-2-2-3.35]
[28577-1-1-2.14][28959-0-0-2.44][29198-3-3-0.68][29777-0-0-2.98][29877-2-2-0.82][30035-1-1-1.72][30098-0-0-1.34][30326-1-1-2.71][30572-2-2-0.67][30716-0-1-0.05]
[30806-2-3-0.72][30906-1-1-2.88][31007-0-0-1.67][31181-3-3-1.24][31238-0-3-2.15][31347-0-3-1.88][31422-2-2-0.60][31429-3-3-0.21][31431-0-0-1.30][31432-1-1-2.58]
[31477-0-3-2.62][31524-1-2-0.73][31597-1-2-1.31][31619-1-3-0.88][31701-0-3-2.03][31755-0-0-1.09][31854-3-3-0.84][32074-1-3--0.18][32078-3-3-1.25][32111-1-1-1.47]
[32127-1-2-1.34][32140-3-3-1.99][32263-2-0-0.68][32365-0-0-1.20][32411-2-0-2.28][32429-3-3-1.70][32473-3-0-0.14][32574-3-3-2.10][32584-0-0-0.51][32622-0-3--0.08]
[32858-3-3-1.44][32969-3-3-2.13][33016-2-2-2.08][33031-1-3-1.66][33035-2-2-2.07][33133-2-1-1.17][33173-2-2-0.85][33175-3-2-1.02][33306-3-2-1.00][33309-2-3-0.85]
[33474-0-3-0.91][33478-2-3-0.55][33618-1-1-1.67][33712-0-3-1.30][33782-2-2-1.28][33914-3-3-0.86][34076-3-3-1.42][34112-2-2-1.13][34138-2-2-0.93][34239-1-1-0.54]
[34364-2-2-2.39][34617-1-2-0.16][34751-3-3-2.34][34783-2-2-0.89][35015-3-2-1.15][35018-1-1-2.76][35288-2-3-0.09]
---------------------------
I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.665 | Acc: 74.625% | Wgt Acc: 74.215%
	I - Batch: 100 | Loss: 0.690 | Acc: 72.750% | Wgt Acc: 72.357%
	I - Batch: 150 | Loss: 0.688 | Acc: 72.208% | Wgt Acc: 71.834%
I - num batch: 160
I - Train -- Loss: 0.688 | Acc: 71.967% | Wgt Acc: 71.621% | LR: 1.000000e-03 | Dur: 140.84s
I - Confusion Matrix: [row->prediction - col->label]
[[535.  10.  20. 116.]
 [ 26. 429. 128.  37.]
 [ 39. 106. 534.  50.]
 [ 97.  33.  52. 335.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.934 | Acc: 58.410% | Wgt Acc: 58.628% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[51.  4.  3. 13.]
 [ 5. 37. 17.  6.]
 [ 2. 28. 41.  5.]
 [30.  9. 14. 62.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.625 | Acc: 76.375% | Wgt Acc: 76.130%
	I - Batch: 100 | Loss: 0.652 | Acc: 74.500% | Wgt Acc: 74.217%
	I - Batch: 150 | Loss: 0.665 | Acc: 74.333% | Wgt Acc: 74.045%
I - num batch: 160
I - Train -- Loss: 0.658 | Acc: 74.441% | Wgt Acc: 74.195% | LR: 1.000000e-03 | Dur: 140.81s
I - Confusion Matrix: [row->prediction - col->label]
[[528.  18.  23. 110.]
 [ 30. 451. 110.  39.]
 [ 32.  86. 565.  37.]
 [107.  23.  36. 352.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.042 | Acc: 55.963% | Wgt Acc: 55.163% | Dur: 11.90s
I - Confusion Matrix: [row->prediction - col->label]
[[51.  4.  5. 19.]
 [ 7. 41. 15.  9.]
 [10. 30. 52. 19.]
 [20.  3.  3. 39.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.588 | Acc: 78.250% | Wgt Acc: 77.825%
	I - Batch: 100 | Loss: 0.605 | Acc: 77.625% | Wgt Acc: 77.241%
	I - Batch: 150 | Loss: 0.601 | Acc: 77.125% | Wgt Acc: 76.874%
I - num batch: 160
I - Train -- Loss: 0.600 | Acc: 77.032% | Wgt Acc: 76.805% | LR: 1.000000e-03 | Dur: 141.03s
I - Confusion Matrix: [row->prediction - col->label]
[[556.  17.  19.  91.]
 [ 28. 453. 109.  35.]
 [ 23.  82. 572.  31.]
 [ 90.  26.  34. 381.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.104 | Acc: 53.517% | Wgt Acc: 53.533% | Dur: 11.74s
I - Confusion Matrix: [row->prediction - col->label]
[[53.  1.  2. 24.]
 [11. 42. 27.  8.]
 [ 6. 27. 34.  8.]
 [18.  8. 12. 46.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.582 | Acc: 77.000% | Wgt Acc: 76.856%
	I - Batch: 100 | Loss: 0.580 | Acc: 77.750% | Wgt Acc: 77.588%
	I - Batch: 150 | Loss: 0.599 | Acc: 76.750% | Wgt Acc: 76.554%
I - num batch: 160
I - Train -- Loss: 0.599 | Acc: 76.757% | Wgt Acc: 76.584% | LR: 1.000000e-03 | Dur: 141.14s
I - Confusion Matrix: [row->prediction - col->label]
[[537.  15.  20.  92.]
 [ 34. 461.  90.  35.]
 [ 26.  74. 581.  35.]
 [100.  28.  43. 376.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.094 | Acc: 58.410% | Wgt Acc: 58.084% | Dur: 11.85s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  8. 10. 23.]
 [ 0. 33. 12.  2.]
 [ 1. 23. 33.  3.]
 [20. 14. 20. 58.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.608 | Acc: 75.875% | Wgt Acc: 75.806%
	I - Batch: 100 | Loss: 0.587 | Acc: 77.812% | Wgt Acc: 77.519%
	I - Batch: 150 | Loss: 0.572 | Acc: 78.667% | Wgt Acc: 78.402%
I - num batch: 160
I - Train -- Loss: 0.575 | Acc: 78.406% | Wgt Acc: 78.114% | LR: 1.000000e-03 | Dur: 140.41s
I - Confusion Matrix: [row->prediction - col->label]
[[556.  20.  31.  90.]
 [ 29. 466.  72.  36.]
 [ 24.  64. 599.  36.]
 [ 88.  28.  32. 376.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.041 | Acc: 55.963% | Wgt Acc: 55.503% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[53.  3.  5. 19.]
 [ 7. 42. 23.  5.]
 [12. 30. 45. 19.]
 [16.  3.  2. 43.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.519 | Acc: 81.000% | Wgt Acc: 80.661%
	I - Batch: 100 | Loss: 0.493 | Acc: 81.750% | Wgt Acc: 81.551%
	I - Batch: 150 | Loss: 0.480 | Acc: 82.708% | Wgt Acc: 82.561%
I - num batch: 160
I - Train -- Loss: 0.479 | Acc: 82.764% | Wgt Acc: 82.599% | LR: 5.000000e-04 | Dur: 139.78s
I - Confusion Matrix: [row->prediction - col->label]
[[573.  12.  15.  77.]
 [ 32. 497.  60.  17.]
 [ 21.  55. 630.  36.]
 [ 71.  14.  29. 408.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.011 | Acc: 61.162% | Wgt Acc: 59.171% | Dur: 11.99s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  9.  5. 31.]
 [ 1. 33. 12.  2.]
 [ 0. 34. 53. 15.]
 [11.  2.  5. 38.]]

I - Local maximum validation set accuracy:  61.16

I - Validation set results: 
[14-1-2-2.28][50-3-0-0.08][124-2-2-1.04][127-0-0-3.42][443-2-2-2.11][567-0-0-1.87][573-1-1-2.35][615-0-0-0.72][695-1-2-2.43][722-3-0-3.06]
[826-0-0-3.44][878-0-3-2.32][1103-0-0-1.24][1212-3-0-0.22][1368-0-0-5.11][2181-2-3-0.19][2476-2-2-1.05][2721-2-2-2.92][2818-1-0-0.99][2886-2-2-1.03]
[3231-2-2-2.00][3333-2-1-0.98][3482-2-2-2.90][3536-3-3-1.07][3625-1-1-3.68][3909-0-0-2.04][4035-0-0-0.57][4140-0-0-1.56][4214-1-2-0.45][4346-1-0-1.20]
[4581-2-2-1.79][4708-3-2-1.24][4838-3-0-1.40][4845-1-2-1.19][4868-0-0-3.93][4939-0-3--0.29][4984-2-2-2.07][5078-1-2--0.16][5396-0-0-4.87][5479-1-1-1.78]
[5717-0-0-3.25][5843-1-1-0.77][5949-3-0-1.49][5987-2-1--0.10][6014-3-3-1.72][6033-3-0--0.27][6313-0-0-2.20][6421-3-3-1.30][6500-1-2--0.13][6583-3-2-0.59]
[6683-3-0-1.07][6825-2-0-0.55][6998-3-2--0.23][7049-3-3-0.64][7517-1-1-2.73][7521-1-2-0.17][7528-1-3-0.82][7949-1-2-2.41][8135-1-0-3.47][8185-3-0-2.37]
[8269-3-1-0.46][8273-3-3-2.02][8543-3-0-5.16][8666-1-1-1.85][8672-0-0-2.16][8903-1-2-0.05][9001-2-1-1.51][9036-2-2-2.47][9281-3-0-0.44][9300-2-2-3.25]
[9571-0-3-0.32][9617-1-0--0.12][9644-2-2-1.03][9705-2-2--0.12][9801-0-0-1.25][9803-3-3-1.48][9865-3-3-3.43][9896-2-2-2.77][10314-1-2-0.61][10337-3-3-3.52]
[10403-0-0-1.37][10653-2-1-0.77][10704-2-2-1.03][10719-1-1-2.46][10727-1-2--0.00][10836-0-0-8.19][10969-2-3-0.22][11042-0-0-2.63][11088-1-2-2.10][11322-0-0-4.31]
[11398-2-2-1.38][11499-0-0-2.43][11502-3-0-2.10][11512-3-3-0.74][11608-1-2-1.33][11610-0-0-3.80][11692-0-0-2.00][11905-0-0-0.77][11993-1-2-1.73][12002-2-0-0.21]
[12052-0-0-3.77][12201-0-3-2.61][12235-2-1-1.08][12320-1-0-0.43][12377-2-1--0.22][12398-2-3-0.31][12503-1-1-0.39][12617-0-3-0.63][12685-3-3--0.21][12738-2-3-0.26]
[12742-2-2-2.67][12823-0-0-1.78][13110-1-1-0.95][13240-3-0-3.19][13253-1-2-1.43][13273-0-0-5.60][13634-1-2-1.00][13763-2-2-1.10][13905-3-2--0.62][14060-2-1-3.43]
[14065-3-3-0.80][14147-3-0-0.60][14595-2-2-1.87][14687-2-2-3.82][14788-2-2-2.69][14869-1-1-2.67][14872-3-0-1.34][14877-1-1-1.58][14927-0-0-0.60][15066-0-0-4.33]
[15175-1-1-0.17][15178-2-2-0.78][15375-3-3-1.08][15389-3-3-2.97][15568-2-1-1.86][15675-3-0-0.60][15869-1-2-1.98][16207-3-0-0.67][16236-0-3--0.13][16302-3-0-1.52]
[16331-2-2-4.38][16381-0-3--0.44][16488-1-1-1.92][16495-0-0-3.92][16650-0-0-3.11][16719-1-0--0.48][16801-0-0-6.22][16828-0-0-3.44][17137-3-0-2.06][17245-1-2-1.27]
[17278-3-0--0.24][17282-0-0-0.31][17311-2-2-2.98][17336-2-2-1.04][17608-3-3-3.14][17627-0-0-1.54][17877-3-0-1.32][17924-1-2-0.69][17984-3-0-4.89][18211-0-3-1.56]
[18276-3-3-1.05][18287-1-1-1.16][18394-0-0-3.33][18428-0-0-1.47][18442-0-3-1.31][18478-3-3-0.53][18607-0-0-3.70][18616-0-0-1.68][18663-0-0-1.82][18718-0-0-5.23]
[18766-2-2-2.65][18824-2-2-1.45][18890-3-3-1.25][18930-3-2-1.02][18938-3-3-0.32][19817-1-2-0.65][19839-0-0-0.79][19930-3-3-1.17][19944-0-0-0.41][20036-2-2-3.42]
[20101-3-1-0.93][20474-1-1-1.99][20547-3-0-1.90][20929-2-2-2.40][21245-1-2-0.72][21257-3-3--0.83][21293-1-2-2.00][21316-1-3--0.64][21384-1-2-0.64][21448-1-1-0.87]
[21483-0-0-3.30][21487-2-2-2.76][21714-0-0-0.54][21943-3-2-1.87][21947-0-0-0.60][21948-0-0-7.81][21965-2-2-2.66][21998-1-1-0.88][22025-0-3-0.49][22228-3-3-1.73]
[22446-1-1-3.24][22494-3-3-2.22][22757-0-0-4.03][22811-3-3-1.56][22976-3-2-2.01][22985-3-3-2.47][23014-0-0-3.42][23112-1-1-1.12][23144-3-3-2.48][23168-2-0-0.32]
[23219-0-0--0.08][23363-3-3-0.67][23470-0-0-2.12][23486-2-2-2.48][23497-0-0-3.33][23516-0-0-3.28][23690-1-2-0.49][23921-2-2-1.16][23936-1-2-2.48][24040-3-2-0.67]
[24111-1-2-0.45][24182-0-0-5.22][24238-3-3-0.90][24290-2-0-1.28][24345-0-0-4.33][24364-1-2-2.19][24427-3-0-0.93][24477-2-2-3.26][24495-2-1-0.53][24893-2-2-1.44]
[25012-1-2-1.42][25121-2-2-0.94][25165-3-3-0.46][25183-0-0-4.28][25297-3-3-1.33][25398-0-0-2.68][25574-2-1-0.84][25644-1-1-2.86][25718-1-1-0.65][25774-2-2-0.83]
[26032-3-3-0.81][26051-3-3-3.19][26120-0-0-1.89][26321-1-1-2.02][26732-1-1-1.93][26784-3-3-3.91][26827-3-3-1.23][26833-0-3-2.79][26838-2-2-0.54][26860-1-2-1.30]
[26948-0-0-4.20][27049-3-0-2.63][27098-1-0-0.39][27526-0-0-3.24][27639-3-3-1.71][27698-3-3-2.13][27772-0-0-3.47][27890-1-1-2.17][28040-0-0-1.43][28503-2-2-3.63]
[28577-1-1-2.36][28959-0-0-4.77][29198-3-0-0.50][29777-0-0-5.86][29877-2-2-0.57][30035-1-2-1.49][30098-0-0-2.25][30326-1-1-3.45][30572-2-2-1.29][30716-0-0-0.13]
[30806-2-2-1.79][30906-1-1-1.97][31007-0-0-2.78][31181-3-2-1.96][31238-0-0-1.08][31347-0-0-5.05][31422-2-2-1.32][31429-3-2-0.64][31431-0-0-1.28][31432-1-1-2.07]
[31477-0-0-3.25][31524-1-0-0.26][31597-1-2-2.55][31619-1-2-0.31][31701-0-0-3.29][31755-0-0-2.78][31854-3-0-0.13][32074-1-2-1.11][32078-3-0-0.83][32111-1-1-1.27]
[32127-1-2-1.77][32140-3-3-2.09][32263-2-2-0.49][32365-0-0-4.23][32411-2-0-3.64][32429-3-0-2.71][32473-3-0-1.40][32574-3-0-2.37][32584-0-0-0.58][32622-0-1-0.02]
[32858-3-0-3.71][32969-3-3-1.96][33016-2-1-0.39][33031-1-0-0.70][33035-2-2-3.46][33133-2-2-1.94][33173-2-2--0.07][33175-3-2-1.32][33306-3-2-0.76][33309-2-3-0.72]
[33474-0-0-0.68][33478-2-2-0.41][33618-1-1-1.97][33712-0-0-0.83][33782-2-2-0.98][33914-3-2-1.86][34076-3-2-0.94][34112-2-1-1.69][34138-2-2-0.54][34239-1-1-0.32]
[34364-2-2-2.61][34617-1-1-1.51][34751-3-3-1.80][34783-2-2-1.59][35015-3-2-2.01][35018-1-1-0.88][35288-2-2-0.97]
---------------------------
I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.374 | Acc: 86.500% | Wgt Acc: 86.530%
	I - Batch: 100 | Loss: 0.406 | Acc: 85.062% | Wgt Acc: 85.006%
	I - Batch: 150 | Loss: 0.420 | Acc: 84.167% | Wgt Acc: 84.099%
I - num batch: 160
I - Train -- Loss: 0.423 | Acc: 84.138% | Wgt Acc: 84.068% | LR: 5.000000e-04 | Dur: 140.54s
I - Confusion Matrix: [row->prediction - col->label]
[[570.   9.  13.  79.]
 [ 19. 509.  55.  16.]
 [ 24.  49. 642.  21.]
 [ 84.  11.  24. 422.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.081 | Acc: 60.856% | Wgt Acc: 60.734% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[47.  1.  2. 10.]
 [ 5. 41. 13.  8.]
 [10. 29. 54. 11.]
 [26.  7.  6. 57.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.423 | Acc: 84.750% | Wgt Acc: 84.723%
	I - Batch: 100 | Loss: 0.418 | Acc: 84.938% | Wgt Acc: 84.788%
	I - Batch: 150 | Loss: 0.404 | Acc: 85.542% | Wgt Acc: 85.470%
I - num batch: 160
I - Train -- Loss: 0.409 | Acc: 85.512% | Wgt Acc: 85.448% | LR: 5.000000e-04 | Dur: 141.36s
I - Confusion Matrix: [row->prediction - col->label]
[[583.  10.  11.  51.]
 [ 22. 514.  50.  25.]
 [ 16.  43. 648.  29.]
 [ 76.  11.  25. 433.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.091 | Acc: 59.327% | Wgt Acc: 57.201% | Dur: 11.62s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  6.  4. 35.]
 [ 3. 36. 15.  8.]
 [ 5. 34. 53. 13.]
 [ 5.  2.  3. 30.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.388 | Acc: 85.875% | Wgt Acc: 85.662%
	I - Batch: 100 | Loss: 0.393 | Acc: 86.125% | Wgt Acc: 86.054%
	I - Batch: 150 | Loss: 0.385 | Acc: 86.917% | Wgt Acc: 86.815%
I - num batch: 160
I - Train -- Loss: 0.391 | Acc: 86.690% | Wgt Acc: 86.598% | LR: 5.000000e-04 | Dur: 139.92s
I - Confusion Matrix: [row->prediction - col->label]
[[594.   9.  16.  64.]
 [ 20. 524.  39.  17.]
 [ 21.  31. 657.  24.]
 [ 62.  14.  22. 433.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.070 | Acc: 59.633% | Wgt Acc: 57.813% | Dur: 11.60s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  4.  8. 43.]
 [ 8. 47. 15. 11.]
 [ 1. 25. 50.  8.]
 [ 5.  2.  2. 24.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.387 | Acc: 86.625% | Wgt Acc: 86.428%
	I - Batch: 100 | Loss: 0.380 | Acc: 86.875% | Wgt Acc: 86.825%
	I - Batch: 150 | Loss: 0.367 | Acc: 87.250% | Wgt Acc: 87.196%
I - num batch: 160
I - Train -- Loss: 0.372 | Acc: 87.161% | Wgt Acc: 87.128% | LR: 5.000000e-04 | Dur: 140.56s
I - Confusion Matrix: [row->prediction - col->label]
[[600.   9.  12.  60.]
 [ 20. 531.  44.  15.]
 [ 13.  29. 651.  25.]
 [ 64.   9.  27. 438.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.065 | Acc: 64.832% | Wgt Acc: 64.470% | Dur: 11.46s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  7.  6. 20.]
 [ 3. 44. 12.  2.]
 [ 0. 20. 42.  7.]
 [16.  7. 15. 57.]]

I - Local maximum validation set accuracy:  64.83

I - Validation set results: 
[14-1-2-1.72][50-3-3-0.38][124-2-2-1.97][127-0-0-4.44][443-2-2-2.70][567-0-0-2.44][573-1-1-2.45][615-0-3-2.15][695-1-2-3.54][722-3-3-3.09]
[826-0-0-4.22][878-0-0-3.67][1103-0-0-1.35][1212-3-3-1.15][1368-0-0-4.95][2181-2-3-1.08][2476-2-2-1.45][2721-2-2-2.45][2818-1-3-1.38][2886-2-1-2.38]
[3231-2-2-2.52][3333-2-3-1.54][3482-2-2-2.28][3536-3-3-4.27][3625-1-1-5.09][3909-0-0-2.40][4035-0-0-2.46][4140-0-0-1.82][4214-1-3-1.22][4346-1-0-2.19]
[4581-2-1-2.00][4708-3-2-1.00][4838-3-0-1.60][4845-1-2-0.37][4868-0-0-5.62][4939-0-1-0.53][4984-2-2-0.69][5078-1-2--0.10][5396-0-0-6.05][5479-1-1-1.33]
[5717-0-0-4.48][5843-1-1-1.33][5949-3-3-2.11][5987-2-1-0.36][6014-3-3-3.98][6033-3-3-0.06][6313-0-0-3.47][6421-3-3-3.48][6500-1-2-0.42][6583-3-3-1.83]
[6683-3-3-1.28][6825-2-0-0.89][6998-3-2--0.04][7049-3-3-2.71][7517-1-1-2.04][7521-1-0-0.01][7528-1-3-1.11][7949-1-2-2.24][8135-1-0-1.84][8185-3-0-2.27]
[8269-3-2-0.45][8273-3-3-3.72][8543-3-0-6.02][8666-1-1-1.52][8672-0-0-5.87][8903-1-1-1.02][9001-2-2-1.80][9036-2-2-3.57][9281-3-3-0.63][9300-2-2-4.25]
[9571-0-3-1.99][9617-1-1-2.75][9644-2-2-3.03][9705-2-0-0.07][9801-0-3-3.92][9803-3-3-3.20][9865-3-3-4.01][9896-2-2-1.71][10314-1-2-0.60][10337-3-3-5.42]
[10403-0-0-0.17][10653-2-1-0.68][10704-2-3-0.53][10719-1-1-3.12][10727-1-1-0.82][10836-0-0-9.23][10969-2-3-2.56][11042-0-0-2.41][11088-1-1-3.28][11322-0-0-4.15]
[11398-2-2-4.60][11499-0-0-3.19][11502-3-0-3.21][11512-3-3-2.27][11608-1-2-2.11][11610-0-0-3.61][11692-0-0-2.37][11905-0-0-4.14][11993-1-1-0.70][12002-2-2-2.31]
[12052-0-0-2.45][12201-0-3-4.34][12235-2-2-1.34][12320-1-0-0.52][12377-2-1-0.54][12398-2-3-2.22][12503-1-2-1.84][12617-0-3-0.85][12685-3-3-2.00][12738-2-3-1.12]
[12742-2-2-4.92][12823-0-0-3.16][13110-1-1-0.85][13240-3-0-4.34][13253-1-1-3.08][13273-0-0-7.99][13634-1-1-0.30][13763-2-2-1.17][13905-3-3-0.94][14060-2-1-2.17]
[14065-3-0-1.71][14147-3-3-2.48][14595-2-2-1.24][14687-2-2-2.87][14788-2-2-3.61][14869-1-1-4.08][14872-3-0-1.18][14877-1-1-2.50][14927-0-0-1.60][15066-0-0-5.72]
[15175-1-3-0.13][15178-2-3-0.95][15375-3-3-0.77][15389-3-3-2.24][15568-2-1-1.19][15675-3-3-3.18][15869-1-2-0.43][16207-3-0-0.64][16236-0-3-0.32][16302-3-0-3.79]
[16331-2-2-5.54][16381-0-3-0.83][16488-1-1-1.43][16495-0-0-4.43][16650-0-0-4.51][16719-1-2-0.35][16801-0-0-7.96][16828-0-0-3.65][17137-3-0-3.99][17245-1-1-0.80]
[17278-3-3-0.04][17282-0-1--0.80][17311-2-2-2.18][17336-2-3-1.18][17608-3-3-4.89][17627-0-0-0.25][17877-3-0-1.24][17924-1-3-0.23][17984-3-0-4.49][18211-0-3-2.00]
[18276-3-3-2.51][18287-1-1-1.25][18394-0-0-3.40][18428-0-0-1.62][18442-0-3-3.87][18478-3-3-2.12][18607-0-0-3.47][18616-0-0-2.23][18663-0-0-1.47][18718-0-0-6.80]
[18766-2-2-1.62][18824-2-2-1.51][18890-3-3-1.17][18930-3-2--0.10][18938-3-3-2.50][19817-1-1-0.94][19839-0-0-0.00][19930-3-3-3.50][19944-0-0-3.14][20036-2-2-4.38]
[20101-3-3-2.74][20474-1-1-1.13][20547-3-0-0.48][20929-2-2-3.55][21245-1-3-0.33][21257-3-3-0.84][21293-1-2-1.49][21316-1-1-2.96][21384-1-1-0.80][21448-1-1-0.82]
[21483-0-0-4.27][21487-2-2-2.87][21714-0-3-1.30][21943-3-3--0.09][21947-0-0-1.99][21948-0-0-5.75][21965-2-2-1.04][21998-1-1-1.41][22025-0-3-0.43][22228-3-3-4.47]
[22446-1-1-1.91][22494-3-0-3.81][22757-0-0-6.15][22811-3-3-3.86][22976-3-1-1.45][22985-3-3-3.82][23014-0-3-5.62][23112-1-1-1.70][23144-3-3-3.91][23168-2-0-1.51]
[23219-0-0-2.09][23363-3-3-4.41][23470-0-0-2.45][23486-2-3-0.46][23497-0-3-5.26][23516-0-0-4.08][23690-1-2-0.63][23921-2-2-0.83][23936-1-2-2.46][24040-3-2-0.22]
[24111-1-1-0.92][24182-0-0-6.01][24238-3-3-2.87][24290-2-0-3.24][24345-0-0-2.76][24364-1-2-3.07][24427-3-0-2.67][24477-2-2-4.29][24495-2-1--0.09][24893-2-2-0.05]
[25012-1-1--0.44][25121-2-2-1.18][25165-3-3-2.65][25183-0-0-2.06][25297-3-3-3.49][25398-0-0-2.81][25574-2-2-0.82][25644-1-1-2.80][25718-1-0-0.21][25774-2-3-1.16]
[26032-3-3-2.48][26051-3-3-4.74][26120-0-0-3.05][26321-1-1-0.80][26732-1-1-2.70][26784-3-3-4.71][26827-3-3-3.45][26833-0-3-4.40][26838-2-2-0.21][26860-1-1-0.46]
[26948-0-0-3.37][27049-3-0-1.60][27098-1-0-2.30][27526-0-0-4.23][27639-3-3-1.90][27698-3-3-3.60][27772-0-0-5.08][27890-1-1-2.62][28040-0-0-0.77][28503-2-2-5.05]
[28577-1-1-1.44][28959-0-0-4.72][29198-3-3-1.14][29777-0-0-7.05][29877-2-3-0.41][30035-1-2-0.99][30098-0-0-2.96][30326-1-1-4.24][30572-2-2-2.79][30716-0-3-0.76]
[30806-2-3-0.71][30906-1-1-3.91][31007-0-0-2.78][31181-3-3-0.96][31238-0-3-2.79][31347-0-0-6.48][31422-2-2-0.06][31429-3-3-0.53][31431-0-0-2.09][31432-1-1-2.25]
[31477-0-0-5.47][31524-1-2-0.74][31597-1-2-2.10][31619-1-0-1.34][31701-0-0-5.41][31755-0-0-3.60][31854-3-3-3.85][32074-1-1--0.07][32078-3-3-3.49][32111-1-1-0.68]
[32127-1-2-3.25][32140-3-3-2.69][32263-2-2--0.21][32365-0-0-2.45][32411-2-0-5.89][32429-3-0-1.95][32473-3-0-2.35][32574-3-0-5.70][32584-0-0-1.63][32622-0-1--0.10]
[32858-3-0-5.07][32969-3-3-3.01][33016-2-2-3.59][33031-1-3-3.01][33035-2-2-4.73][33133-2-1-0.37][33173-2-2-0.12][33175-3-2-1.34][33306-3-1-1.24][33309-2-3-1.95]
[33474-0-0-1.29][33478-2-0-0.90][33618-1-1-1.12][33712-0-0-1.62][33782-2-1-1.88][33914-3-3-2.50][34076-3-3-1.40][34112-2-1-0.26][34138-2-3--0.02][34239-1-1--0.44]
[34364-2-2-2.76][34617-1-2-1.16][34751-3-3-3.75][34783-2-1-0.64][35015-3-2-2.96][35018-1-1-1.06][35288-2-3-0.91]
---------------------------
I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.362 | Acc: 87.875% | Wgt Acc: 87.962%
	I - Batch: 100 | Loss: 0.365 | Acc: 87.438% | Wgt Acc: 87.347%
	I - Batch: 150 | Loss: 0.365 | Acc: 87.625% | Wgt Acc: 87.542%
I - num batch: 160
I - Train -- Loss: 0.366 | Acc: 87.554% | Wgt Acc: 87.482% | LR: 5.000000e-04 | Dur: 141.03s
I - Confusion Matrix: [row->prediction - col->label]
[[596.   8.  13.  56.]
 [ 23. 524.  37.  16.]
 [ 14.  37. 665.  21.]
 [ 64.   9.  19. 445.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 61.468% | Wgt Acc: 61.481% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  4.  3. 18.]
 [10. 49. 23.  6.]
 [ 4. 20. 43. 10.]
 [17.  5.  6. 52.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.337 | Acc: 87.500% | Wgt Acc: 87.542%
	I - Batch: 100 | Loss: 0.337 | Acc: 87.812% | Wgt Acc: 87.810%
	I - Batch: 150 | Loss: 0.340 | Acc: 87.667% | Wgt Acc: 87.670%
I - num batch: 160
I - Train -- Loss: 0.341 | Acc: 87.515% | Wgt Acc: 87.527% | LR: 5.000000e-04 | Dur: 140.90s
I - Confusion Matrix: [row->prediction - col->label]
[[591.   8.  11.  61.]
 [ 19. 532.  39.  12.]
 [ 21.  29. 660.  19.]
 [ 66.   9.  24. 446.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.110 | Acc: 62.385% | Wgt Acc: 61.821% | Dur: 12.00s
I - Confusion Matrix: [row->prediction - col->label]
[[50.  4.  2. 13.]
 [ 2. 37.  7.  3.]
 [14. 35. 60. 13.]
 [22.  2.  6. 57.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.307 | Acc: 90.375% | Wgt Acc: 90.200%
	I - Batch: 100 | Loss: 0.306 | Acc: 90.000% | Wgt Acc: 89.940%
	I - Batch: 150 | Loss: 0.317 | Acc: 89.667% | Wgt Acc: 89.597%
I - num batch: 160
I - Train -- Loss: 0.317 | Acc: 89.674% | Wgt Acc: 89.579% | LR: 5.000000e-04 | Dur: 142.12s
I - Confusion Matrix: [row->prediction - col->label]
[[620.   9.  14.  46.]
 [ 17. 529.  35.  12.]
 [ 16.  28. 674.  19.]
 [ 44.  12.  11. 461.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.029 | Acc: 62.691% | Wgt Acc: 61.753% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  4.  7. 20.]
 [ 4. 40. 16.  5.]
 [ 7. 30. 48. 12.]
 [ 9.  4.  4. 49.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.292 | Acc: 90.375% | Wgt Acc: 90.144%
	I - Batch: 100 | Loss: 0.290 | Acc: 90.438% | Wgt Acc: 90.215%
	I - Batch: 150 | Loss: 0.285 | Acc: 90.542% | Wgt Acc: 90.385%
I - num batch: 160
I - Train -- Loss: 0.291 | Acc: 90.263% | Wgt Acc: 90.110% | LR: 5.000000e-04 | Dur: 140.87s
I - Confusion Matrix: [row->prediction - col->label]
[[616.  12.   6.  53.]
 [ 15. 538.  24.  13.]
 [ 10.  18. 693.  20.]
 [ 56.  10.  11. 452.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.971 | Acc: 62.997% | Wgt Acc: 62.568% | Dur: 11.74s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  5.  5. 13.]
 [ 3. 40. 13.  5.]
 [ 9. 28. 52. 11.]
 [19.  5.  5. 57.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.321 | Acc: 89.500% | Wgt Acc: 89.364%
	I - Batch: 100 | Loss: 0.307 | Acc: 89.688% | Wgt Acc: 89.590%
	I - Batch: 150 | Loss: 0.315 | Acc: 89.083% | Wgt Acc: 89.068%
I - num batch: 160
I - Train -- Loss: 0.313 | Acc: 89.282% | Wgt Acc: 89.252% | LR: 5.000000e-04 | Dur: 140.82s
I - Confusion Matrix: [row->prediction - col->label]
[[603.  12.   9.  45.]
 [ 15. 530.  25.  10.]
 [ 18.  26. 678.  20.]
 [ 61.  10.  22. 463.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.074 | Acc: 62.691% | Wgt Acc: 62.364% | Dur: 11.60s
I - Confusion Matrix: [row->prediction - col->label]
[[54.  3.  2.  8.]
 [ 8. 44. 17.  7.]
 [ 8. 28. 53. 17.]
 [18.  3.  3. 54.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.247 | Acc: 91.375% | Wgt Acc: 91.286%
	I - Batch: 100 | Loss: 0.234 | Acc: 93.250% | Wgt Acc: 93.187%
	I - Batch: 150 | Loss: 0.226 | Acc: 93.375% | Wgt Acc: 93.360%
I - num batch: 160
I - Train -- Loss: 0.223 | Acc: 93.561% | Wgt Acc: 93.542% | LR: 2.500000e-04 | Dur: 139.53s
I - Confusion Matrix: [row->prediction - col->label]
[[631.   4.   6.  33.]
 [ 10. 562.  15.   6.]
 [ 12.   9. 710.  19.]
 [ 44.   3.   3. 480.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.994 | Acc: 63.609% | Wgt Acc: 63.247% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  6.  4. 23.]
 [ 3. 45. 18.  2.]
 [ 4. 20. 43.  7.]
 [15.  7. 10. 54.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.172 | Acc: 95.500% | Wgt Acc: 95.629%
	I - Batch: 100 | Loss: 0.174 | Acc: 95.375% | Wgt Acc: 95.451%
	I - Batch: 150 | Loss: 0.178 | Acc: 95.542% | Wgt Acc: 95.609%
I - num batch: 160
I - Train -- Loss: 0.184 | Acc: 95.406% | Wgt Acc: 95.479% | LR: 2.500000e-04 | Dur: 140.56s
I - Confusion Matrix: [row->prediction - col->label]
[[646.   4.   6.  16.]
 [ 15. 561.  12.   2.]
 [ 10.   8. 711.   8.]
 [ 26.   5.   5. 512.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.022 | Acc: 63.303% | Wgt Acc: 62.568% | Dur: 11.54s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  8.  4. 18.]
 [ 2. 40. 15.  5.]
 [ 6. 28. 49. 10.]
 [15.  2.  7. 53.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.174 | Acc: 94.625% | Wgt Acc: 94.611%
	I - Batch: 100 | Loss: 0.170 | Acc: 95.125% | Wgt Acc: 95.076%
	I - Batch: 150 | Loss: 0.171 | Acc: 95.250% | Wgt Acc: 95.204%
I - num batch: 160
I - Train -- Loss: 0.171 | Acc: 95.289% | Wgt Acc: 95.258% | LR: 2.500000e-04 | Dur: 140.65s
I - Confusion Matrix: [row->prediction - col->label]
[[652.   3.   2.  23.]
 [ 12. 567.  10.   5.]
 [  8.   5. 715.  17.]
 [ 25.   3.   7. 493.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.036 | Acc: 64.220% | Wgt Acc: 63.927% | Dur: 11.76s
I - Confusion Matrix: [row->prediction - col->label]
[[56.  4.  5. 15.]
 [ 5. 46. 13.  3.]
 [ 9. 23. 53. 13.]
 [18.  5.  4. 55.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.164 | Acc: 95.625% | Wgt Acc: 95.589%
	I - Batch: 100 | Loss: 0.155 | Acc: 95.875% | Wgt Acc: 95.856%
	I - Batch: 150 | Loss: 0.162 | Acc: 95.333% | Wgt Acc: 95.346%
I - num batch: 160
I - Train -- Loss: 0.161 | Acc: 95.485% | Wgt Acc: 95.497% | LR: 2.500000e-04 | Dur: 139.25s
I - Confusion Matrix: [row->prediction - col->label]
[[645.   1.   5.  23.]
 [  9. 568.   2.   3.]
 [ 10.   6. 720.  13.]
 [ 33.   3.   7. 499.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.990 | Acc: 64.526% | Wgt Acc: 62.976% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  7. 32.]
 [ 4. 43. 12.  3.]
 [ 6. 27. 55. 11.]
 [ 5.  2.  1. 40.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.163 | Acc: 95.750% | Wgt Acc: 95.780%
	I - Batch: 100 | Loss: 0.151 | Acc: 96.500% | Wgt Acc: 96.545%
	I - Batch: 150 | Loss: 0.147 | Acc: 96.625% | Wgt Acc: 96.639%
I - num batch: 160
I - Train -- Loss: 0.150 | Acc: 96.545% | Wgt Acc: 96.559% | LR: 2.500000e-04 | Dur: 139.81s
I - Confusion Matrix: [row->prediction - col->label]
[[667.   2.   4.  12.]
 [  2. 564.  14.   2.]
 [  8.  10. 713.   9.]
 [ 20.   2.   3. 515.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.167 | Acc: 65.138% | Wgt Acc: 64.946% | Dur: 11.58s
I - Confusion Matrix: [row->prediction - col->label]
[[55.  3.  3.  9.]
 [ 2. 39. 10.  4.]
 [ 6. 27. 54.  8.]
 [25.  9.  8. 65.]]

I - Local maximum validation set accuracy:  65.14

I - Validation set results: 
[14-1-2-3.90][50-3-1-0.47][124-2-2-2.64][127-0-0-4.30][443-2-2-2.63][567-0-3-2.07][573-1-1-4.12][615-0-3-2.21][695-1-2-2.86][722-3-3-3.22]
[826-0-0-4.31][878-0-0-3.66][1103-0-0-0.43][1212-3-3-1.86][1368-0-0-3.94][2181-2-2-1.41][2476-2-2-2.56][2721-2-2-5.08][2818-1-3-2.31][2886-2-1-2.70]
[3231-2-2-4.92][3333-2-1-0.65][3482-2-2-3.36][3536-3-3-1.92][3625-1-1-5.81][3909-0-1-0.14][4035-0-0-0.97][4140-0-0-2.65][4214-1-3-3.89][4346-1-3-1.34]
[4581-2-2-2.73][4708-3-2-2.19][4838-3-0-1.00][4845-1-2-2.21][4868-0-0-6.71][4939-0-2-0.23][4984-2-2-1.55][5078-1-3-1.31][5396-0-0-4.73][5479-1-1-1.31]
[5717-0-0-0.38][5843-1-1-1.54][5949-3-3-3.32][5987-2-2-0.67][6014-3-3-1.84][6033-3-3-1.63][6313-0-3-3.14][6421-3-3-4.65][6500-1-2-2.25][6583-3-3-2.44]
[6683-3-3-1.27][6825-2-1-0.30][6998-3-2-0.47][7049-3-3-2.04][7517-1-1-2.97][7521-1-1-0.37][7528-1-3-1.78][7949-1-2-2.90][8135-1-0-1.54][8185-3-0-2.93]
[8269-3-1-0.89][8273-3-3-5.53][8543-3-0-5.01][8666-1-1-1.63][8672-0-0-5.75][8903-1-2-1.10][9001-2-1-3.49][9036-2-2-6.48][9281-3-3-0.68][9300-2-2-5.48]
[9571-0-3-2.69][9617-1-1--0.39][9644-2-2-0.86][9705-2-2-0.37][9801-0-3-3.03][9803-3-3-1.78][9865-3-3-5.42][9896-2-2-3.26][10314-1-2-2.07][10337-3-3-5.18]
[10403-0-2-1.01][10653-2-1-0.98][10704-2-2-0.60][10719-1-1-3.38][10727-1-2-0.31][10836-0-0-8.65][10969-2-3-1.58][11042-0-0-0.23][11088-1-1-2.40][11322-0-0-4.25]
[11398-2-2-1.07][11499-0-0-1.07][11502-3-3-1.93][11512-3-3-2.06][11608-1-2-2.15][11610-0-0-2.12][11692-0-3--0.02][11905-0-3-2.39][11993-1-2-2.20][12002-2-0-3.42]
[12052-0-0-1.67][12201-0-3-4.12][12235-2-2-1.11][12320-1-0--0.09][12377-2-2-0.78][12398-2-3-1.70][12503-1-2-0.69][12617-0-3-0.27][12685-3-3-2.37][12738-2-2-0.90]
[12742-2-2-5.47][12823-0-3-2.98][13110-1-1-1.77][13240-3-3-3.34][13253-1-1-3.79][13273-0-0-8.05][13634-1-2-0.75][13763-2-2-1.92][13905-3-3-0.58][14060-2-1-3.51]
[14065-3-3-1.82][14147-3-3-3.05][14595-2-2-3.21][14687-2-2-4.51][14788-2-2-4.02][14869-1-1-4.32][14872-3-0-0.50][14877-1-1-5.36][14927-0-3-0.31][15066-0-0-3.93]
[15175-1-3-0.12][15178-2-3-1.22][15375-3-3-0.80][15389-3-3-4.50][15568-2-1-3.52][15675-3-3-2.42][15869-1-2-0.97][16207-3-0-1.14][16236-0-2--0.33][16302-3-3-2.05]
[16331-2-2-7.26][16381-0-3-1.33][16488-1-1-1.41][16495-0-0-3.37][16650-0-0-2.62][16719-1-1-0.92][16801-0-0-8.00][16828-0-0-2.99][17137-3-0-1.65][17245-1-2-1.89]
[17278-3-3-0.48][17282-0-0--0.84][17311-2-2-3.82][17336-2-2-2.59][17608-3-3-5.97][17627-0-3--1.07][17877-3-0-0.69][17924-1-2-1.57][17984-3-0-3.23][18211-0-3-1.44]
[18276-3-3-3.21][18287-1-1-0.69][18394-0-0-2.10][18428-0-0-5.72][18442-0-3-3.08][18478-3-3-2.65][18607-0-0-2.91][18616-0-0-2.16][18663-0-0-1.84][18718-0-0-4.67]
[18766-2-2-4.30][18824-2-2-2.95][18890-3-3-1.96][18930-3-2-1.13][18938-3-3-1.86][19817-1-2-1.36][19839-0-2-1.11][19930-3-3-3.65][19944-0-0-1.44][20036-2-2-2.89]
[20101-3-1-0.66][20474-1-1-2.35][20547-3-3-0.77][20929-2-2-6.60][21245-1-1-0.81][21257-3-3-0.75][21293-1-2-2.64][21316-1-1-0.51][21384-1-1-2.25][21448-1-2-1.80]
[21483-0-0-2.55][21487-2-2-4.07][21714-0-3-1.40][21943-3-2-2.33][21947-0-0-1.90][21948-0-0-8.08][21965-2-2-4.65][21998-1-1-3.16][22025-0-2--0.35][22228-3-3-4.35]
[22446-1-1-5.27][22494-3-3-3.20][22757-0-0-3.89][22811-3-3-1.23][22976-3-1-0.87][22985-3-3-4.64][23014-0-3-4.60][23112-1-1-3.57][23144-3-3-5.07][23168-2-3-0.93]
[23219-0-3-0.86][23363-3-3-4.51][23470-0-3--0.42][23486-2-2-1.53][23497-0-3-5.49][23516-0-0-3.20][23690-1-1--0.33][23921-2-2-3.32][23936-1-2-5.25][24040-3-2-1.03]
[24111-1-1-0.98][24182-0-0-5.57][24238-3-3-2.23][24290-2-0-2.14][24345-0-0-2.70][24364-1-2-1.26][24427-3-3-0.37][24477-2-2-3.59][24495-2-1-1.54][24893-2-2-2.17]
[25012-1-2-1.37][25121-2-1-1.55][25165-3-3-3.48][25183-0-0-2.50][25297-3-3-3.05][25398-0-0-2.19][25574-2-2-0.91][25644-1-1-2.69][25718-1-1-0.11][25774-2-3-1.70]
[26032-3-3-2.88][26051-3-3-5.09][26120-0-0-0.73][26321-1-1-1.49][26732-1-1-4.06][26784-3-3-5.10][26827-3-3-2.80][26833-0-3-3.88][26838-2-2-0.67][26860-1-2-1.56]
[26948-0-0-1.23][27049-3-0-0.24][27098-1-0-0.38][27526-0-0-3.01][27639-3-3-2.91][27698-3-3-4.08][27772-0-0-3.25][27890-1-1-3.50][28040-0-3-0.38][28503-2-2-4.73]
[28577-1-1-2.76][28959-0-0-5.74][29198-3-3-1.59][29777-0-0-5.96][29877-2-1-0.95][30035-1-1-1.24][30098-0-0-1.14][30326-1-1-5.76][30572-2-2-3.39][30716-0-1-1.05]
[30806-2-2-1.88][30906-1-1-5.57][31007-0-0-1.79][31181-3-2-0.89][31238-0-3-2.93][31347-0-0-3.77][31422-2-2-1.31][31429-3-3-0.49][31431-0-0-1.91][31432-1-1-2.81]
[31477-0-3-4.54][31524-1-2-0.99][31597-1-2-2.72][31619-1-3-0.66][31701-0-0-3.41][31755-0-0-1.71][31854-3-3-2.40][32074-1-3--0.21][32078-3-3-2.84][32111-1-1-0.10]
[32127-1-2-1.50][32140-3-3-5.25][32263-2-0-0.15][32365-0-0-3.52][32411-2-3-4.86][32429-3-3-1.12][32473-3-3-2.09][32574-3-3-3.80][32584-0-0-1.05][32622-0-2--0.59]
[32858-3-3-1.51][32969-3-3-4.31][33016-2-2-1.55][33031-1-3-3.07][33035-2-2-3.70][33133-2-2-3.16][33173-2-2-0.81][33175-3-2-2.47][33306-3-3-1.24][33309-2-3-2.54]
[33474-0-0-0.55][33478-2-3--0.16][33618-1-1-1.90][33712-0-3-3.23][33782-2-2-2.09][33914-3-3-3.63][34076-3-3-0.97][34112-2-2-0.38][34138-2-2-0.67][34239-1-2-1.87]
[34364-2-2-3.95][34617-1-2-2.24][34751-3-3-2.03][34783-2-2-1.48][35015-3-2-3.99][35018-1-1-1.24][35288-2-2-1.25]
---------------------------
I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.117 | Acc: 97.750% | Wgt Acc: 97.838%
	I - Batch: 100 | Loss: 0.116 | Acc: 98.062% | Wgt Acc: 98.115%
	I - Batch: 150 | Loss: 0.117 | Acc: 97.875% | Wgt Acc: 97.916%
I - num batch: 160
I - Train -- Loss: 0.118 | Acc: 97.919% | Wgt Acc: 97.956% | LR: 1.250000e-04 | Dur: 140.47s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   0.   2.  12.]
 [  5. 574.   6.   1.]
 [  7.   3. 725.   2.]
 [ 13.   1.   1. 523.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.060 | Acc: 65.749% | Wgt Acc: 65.489% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  5.  2.  9.]
 [ 4. 42. 14.  4.]
 [ 8. 29. 53. 11.]
 [18.  2.  6. 62.]]

I - Local maximum validation set accuracy:  65.75

I - Validation set results: 
[14-1-2-2.94][50-3-1-0.86][124-2-2-2.70][127-0-0-3.88][443-2-2-2.69][567-0-0-0.52][573-1-1-1.59][615-0-3-1.29][695-1-2-2.15][722-3-3-3.33]
[826-0-0-2.89][878-0-0-3.34][1103-0-0-1.60][1212-3-3-1.59][1368-0-0-3.71][2181-2-2-1.54][2476-2-2-2.26][2721-2-2-3.65][2818-1-1--0.04][2886-2-1-2.28]
[3231-2-2-4.76][3333-2-2-3.75][3482-2-2-3.85][3536-3-3-1.55][3625-1-1-6.08][3909-0-0-1.14][4035-0-0--0.17][4140-0-0-1.90][4214-1-2-0.11][4346-1-0-1.51]
[4581-2-2-2.62][4708-3-2-3.96][4838-3-0-0.51][4845-1-2-1.97][4868-0-0-5.89][4939-0-1-0.57][4984-2-2-3.67][5078-1-2-1.45][5396-0-0-5.31][5479-1-1-4.89]
[5717-0-0-4.05][5843-1-1-2.27][5949-3-3-1.90][5987-2-1-0.80][6014-3-1-1.14][6033-3-3-0.77][6313-0-0-1.98][6421-3-3-3.02][6500-1-2-4.26][6583-3-3-1.54]
[6683-3-3-1.45][6825-2-1-2.92][6998-3-3--0.52][7049-3-3-1.68][7517-1-1-4.74][7521-1-2-0.23][7528-1-2-0.81][7949-1-2-4.60][8135-1-0-1.11][8185-3-0-3.25]
[8269-3-2-0.05][8273-3-3-2.39][8543-3-0-5.28][8666-1-1-5.26][8672-0-0-3.58][8903-1-2-3.33][9001-2-1-1.53][9036-2-2-4.28][9281-3-3-1.20][9300-2-2-5.13]
[9571-0-3-0.39][9617-1-1-4.54][9644-2-2-2.78][9705-2-1-0.15][9801-0-3-2.25][9803-3-3-1.99][9865-3-3-4.90][9896-2-2-2.76][10314-1-2-0.46][10337-3-3-5.59]
[10403-0-2-1.01][10653-2-2-1.23][10704-2-2-2.98][10719-1-1-4.67][10727-1-1-0.75][10836-0-0-8.56][10969-2-3-0.98][11042-0-0-1.24][11088-1-1-6.03][11322-0-0-4.00]
[11398-2-2-1.81][11499-0-0-1.72][11502-3-0-1.26][11512-3-2-1.07][11608-1-2-2.51][11610-0-0-2.88][11692-0-0--0.39][11905-0-3-0.64][11993-1-1-2.43][12002-2-2-0.77]
[12052-0-0-3.28][12201-0-3-3.36][12235-2-2-2.35][12320-1-0-0.20][12377-2-2-0.97][12398-2-3-0.85][12503-1-2-1.15][12617-0-2-0.11][12685-3-3-0.44][12738-2-2-0.31]
[12742-2-2-5.74][12823-0-0-1.84][13110-1-2-2.84][13240-3-3-3.07][13253-1-1-3.96][13273-0-0-6.80][13634-1-2-1.13][13763-2-2-0.99][13905-3-3--0.50][14060-2-1-3.08]
[14065-3-3-1.24][14147-3-3-2.38][14595-2-2-1.84][14687-2-2-5.05][14788-2-2-3.74][14869-1-1-4.93][14872-3-0-0.30][14877-1-1-5.37][14927-0-3-0.59][15066-0-0-3.94]
[15175-1-1-0.08][15178-2-3-1.22][15375-3-3-2.12][15389-3-3-2.81][15568-2-1-3.43][15675-3-3-1.24][15869-1-2-1.64][16207-3-0-1.10][16236-0-2-0.70][16302-3-3-1.44]
[16331-2-2-6.36][16381-0-3-0.06][16488-1-1-1.77][16495-0-0-3.83][16650-0-0-2.22][16719-1-2-0.67][16801-0-0-7.81][16828-0-0-2.37][17137-3-3-0.67][17245-1-2-2.67]
[17278-3-3--0.87][17282-0-2-0.52][17311-2-2-3.59][17336-2-1-4.10][17608-3-3-5.77][17627-0-0--0.57][17877-3-0-0.49][17924-1-2-0.92][17984-3-3-2.27][18211-0-3-1.12]
[18276-3-3-1.57][18287-1-1-2.76][18394-0-0-2.20][18428-0-0-4.73][18442-0-3-2.61][18478-3-3-1.99][18607-0-0-2.84][18616-0-0-2.44][18663-0-0-1.51][18718-0-0-5.00]
[18766-2-2-4.62][18824-2-2-2.62][18890-3-3-2.64][18930-3-2-2.11][18938-3-3-0.62][19817-1-2-1.11][19839-0-2-1.10][19930-3-3-2.03][19944-0-2-0.55][20036-2-2-5.04]
[20101-3-3-0.73][20474-1-1-3.25][20547-3-0-0.92][20929-2-2-7.28][21245-1-1-2.33][21257-3-2-0.74][21293-1-1-3.12][21316-1-1-0.75][21384-1-1-1.65][21448-1-1-1.81]
[21483-0-0-2.51][21487-2-2-4.29][21714-0-3-1.02][21943-3-2-1.60][21947-0-0-0.06][21948-0-0-8.06][21965-2-2-5.94][21998-1-1-3.79][22025-0-2-1.47][22228-3-3-4.63]
[22446-1-1-7.39][22494-3-3-3.02][22757-0-0-3.65][22811-3-3-2.49][22976-3-2-2.33][22985-3-3-3.34][23014-0-3-3.61][23112-1-1-2.56][23144-3-3-5.04][23168-2-3-0.44]
[23219-0-3-0.41][23363-3-3-1.87][23470-0-0-1.94][23486-2-2-3.16][23497-0-3-5.40][23516-0-0-2.94][23690-1-1-1.75][23921-2-2-1.64][23936-1-2-5.18][24040-3-2-0.82]
[24111-1-1-0.52][24182-0-0-5.32][24238-3-3-1.57][24290-2-0-0.56][24345-0-0-2.49][24364-1-2-1.69][24427-3-0-0.40][24477-2-2-3.72][24495-2-1-1.36][24893-2-2-1.69]
[25012-1-2-2.12][25121-2-1-1.84][25165-3-3-2.58][25183-0-0-4.33][25297-3-3-2.17][25398-0-0-0.89][25574-2-2-2.54][25644-1-2-3.72][25718-1-1-0.39][25774-2-2-1.66]
[26032-3-3-2.09][26051-3-3-3.73][26120-0-0-2.37][26321-1-1-3.88][26732-1-1-3.98][26784-3-3-5.01][26827-3-3-1.30][26833-0-3-3.56][26838-2-2-1.18][26860-1-2-0.88]
[26948-0-0-0.93][27049-3-1--1.06][27098-1-0-1.08][27526-0-0-1.50][27639-3-3-1.82][27698-3-3-3.12][27772-0-0-4.23][27890-1-1-4.32][28040-0-2-0.26][28503-2-2-4.27]
[28577-1-1-3.23][28959-0-0-4.80][29198-3-3-0.80][29777-0-0-6.55][29877-2-2-1.46][30035-1-1-2.03][30098-0-0-0.92][30326-1-1-5.77][30572-2-2-3.10][30716-0-1-0.56]
[30806-2-2-0.79][30906-1-1-4.79][31007-0-0-2.31][31181-3-3-1.52][31238-0-3-2.07][31347-0-0-5.51][31422-2-2-2.37][31429-3-2-0.98][31431-0-3-1.02][31432-1-1-4.57]
[31477-0-3-3.56][31524-1-2-1.36][31597-1-2-2.01][31619-1-0-0.60][31701-0-0-2.96][31755-0-0-2.56][31854-3-3-0.99][32074-1-3-0.87][32078-3-3-2.60][32111-1-1-2.62]
[32127-1-2-2.57][32140-3-3-4.53][32263-2-2-1.06][32365-0-0-2.24][32411-2-0-3.50][32429-3-3-0.13][32473-3-3-0.95][32574-3-3-2.62][32584-0-0-0.12][32622-0-1-0.63]
[32858-3-3-2.33][32969-3-3-3.51][33016-2-2-4.60][33031-1-3-2.39][33035-2-2-4.79][33133-2-2-3.56][33173-2-2-0.44][33175-3-2-2.16][33306-3-1-0.86][33309-2-3-2.47]
[33474-0-1-1.90][33478-2-3--0.37][33618-1-1-3.14][33712-0-3-1.42][33782-2-1-2.31][33914-3-3-2.89][34076-3-2-1.05][34112-2-2-2.65][34138-2-1-1.51][34239-1-1-0.53]
[34364-2-1-2.89][34617-1-2-2.95][34751-3-3-0.85][34783-2-2-1.57][35015-3-3-2.75][35018-1-1-1.86][35288-2-1-1.67]
---------------------------
I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.108 | Acc: 97.625% | Wgt Acc: 97.648%
	I - Batch: 100 | Loss: 0.116 | Acc: 97.312% | Wgt Acc: 97.343%
	I - Batch: 150 | Loss: 0.118 | Acc: 97.292% | Wgt Acc: 97.318%
I - num batch: 160
I - Train -- Loss: 0.120 | Acc: 97.291% | Wgt Acc: 97.311% | LR: 1.250000e-04 | Dur: 140.46s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   0.   4.  13.]
 [  4. 571.   4.   3.]
 [  9.   5. 720.   5.]
 [ 14.   2.   6. 517.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.126 | Acc: 67.278% | Wgt Acc: 66.644% | Dur: 11.98s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  7.  6. 21.]
 [ 2. 44. 10.  3.]
 [ 4. 18. 48.  5.]
 [11.  9. 11. 57.]]

I - Local maximum validation set accuracy:  67.28

I - Validation set results: 
[14-1-2-2.00][50-3-1-1.53][124-2-2-2.09][127-0-0-5.36][443-2-2-2.00][567-0-0-4.52][573-1-1-2.21][615-0-3-2.57][695-1-2-0.82][722-3-0-2.97]
[826-0-0-5.40][878-0-0-4.92][1103-0-0-3.16][1212-3-3-1.02][1368-0-0-4.09][2181-2-2-1.22][2476-2-2-0.77][2721-2-2-4.32][2818-1-3-0.52][2886-2-1-1.41]
[3231-2-2-2.22][3333-2-2-1.29][3482-2-2-2.07][3536-3-3-3.20][3625-1-1-4.00][3909-0-0-0.87][4035-0-0-2.51][4140-0-0-3.10][4214-1-3-1.95][4346-1-0-1.68]
[4581-2-2-1.14][4708-3-2-2.41][4838-3-3-1.28][4845-1-1-0.54][4868-0-0-4.94][4939-0-3-0.24][4984-2-2-0.22][5078-1-3-1.58][5396-0-0-7.52][5479-1-1-2.46]
[5717-0-0-4.51][5843-1-2-0.42][5949-3-3-3.23][5987-2-2-0.96][6014-3-3-2.41][6033-3-3-0.87][6313-0-0-3.88][6421-3-3-2.45][6500-1-2-1.83][6583-3-3-1.86]
[6683-3-3-2.54][6825-2-1-1.23][6998-3-2--0.23][7049-3-3-1.29][7517-1-1-3.89][7521-1-0--1.02][7528-1-3-1.24][7949-1-2-2.03][8135-1-0-2.85][8185-3-0-5.02]
[8269-3-1-2.53][8273-3-3-3.33][8543-3-0-6.23][8666-1-1-2.34][8672-0-0-3.12][8903-1-1-0.86][9001-2-1-1.18][9036-2-2-3.06][9281-3-3-0.78][9300-2-2-2.89]
[9571-0-0-0.85][9617-1-1-5.04][9644-2-2-1.64][9705-2-0--0.41][9801-0-0-3.12][9803-3-0-2.58][9865-3-3-4.72][9896-2-2-2.04][10314-1-2--0.03][10337-3-3-6.37]
[10403-0-0-0.88][10653-2-1-0.35][10704-2-2-0.71][10719-1-1-2.89][10727-1-3--0.39][10836-0-0-10.56][10969-2-3-2.78][11042-0-2--0.00][11088-1-1-4.51][11322-0-0-6.42]
[11398-2-2-2.23][11499-0-0-2.32][11502-3-3-0.99][11512-3-3-3.33][11608-1-2-2.91][11610-0-0-2.16][11692-0-0-2.00][11905-0-0-4.44][11993-1-1-2.28][12002-2-0-3.85]
[12052-0-0-3.51][12201-0-0-3.77][12235-2-2-1.39][12320-1-0-0.76][12377-2-2-0.38][12398-2-3-1.37][12503-1-2-0.02][12617-0-2--0.83][12685-3-3-2.24][12738-2-3-0.24]
[12742-2-2-4.40][12823-0-0-2.92][13110-1-1-0.79][13240-3-3-3.36][13253-1-1-3.45][13273-0-0-10.14][13634-1-1-0.74][13763-2-3-0.89][13905-3-0-1.36][14060-2-1-1.58]
[14065-3-3-0.33][14147-3-3-3.09][14595-2-2-0.01][14687-2-2-3.27][14788-2-2-1.78][14869-1-1-4.96][14872-3-0-1.75][14877-1-1-4.01][14927-0-3-0.36][15066-0-0-5.61]
[15175-1-3-0.26][15178-2-3-0.09][15375-3-3-0.70][15389-3-3-2.32][15568-2-1-2.97][15675-3-0-1.96][15869-1-0-0.06][16207-3-0-2.86][16236-0-3--0.18][16302-3-0-1.23]
[16331-2-2-5.21][16381-0-0-1.82][16488-1-1-7.29][16495-0-0-5.06][16650-0-0-4.50][16719-1-1-1.37][16801-0-0-7.22][16828-0-0-3.55][17137-3-0-2.81][17245-1-1-0.36]
[17278-3-0--0.24][17282-0-2--0.13][17311-2-2-1.66][17336-2-2-0.81][17608-3-3-5.26][17627-0-0-0.57][17877-3-1-0.53][17924-1-3-1.58][17984-3-0-3.97][18211-0-3-1.05]
[18276-3-0-1.70][18287-1-1-0.78][18394-0-0-4.71][18428-0-0-6.53][18442-0-3-2.65][18478-3-3-1.73][18607-0-0-3.18][18616-0-0-3.42][18663-0-0-2.26][18718-0-0-6.88]
[18766-2-2-3.13][18824-2-2-1.76][18890-3-3-1.98][18930-3-0--0.03][18938-3-3-2.91][19817-1-2-1.60][19839-0-0--0.21][19930-3-3-1.58][19944-0-2--0.10][20036-2-2-2.31]
[20101-3-3-2.15][20474-1-1-3.16][20547-3-0-1.97][20929-2-2-6.13][21245-1-1-1.92][21257-3-3-0.17][21293-1-1-3.08][21316-1-1-3.61][21384-1-1-2.16][21448-1-1-0.55]
[21483-0-0-4.49][21487-2-2-3.19][21714-0-3-1.56][21943-3-0-0.84][21947-0-0-2.31][21948-0-0-7.80][21965-2-2-3.62][21998-1-1-3.07][22025-0-0--0.69][22228-3-3-6.17]
[22446-1-1-4.81][22494-3-3-2.60][22757-0-0-6.45][22811-3-3-3.26][22976-3-2-0.82][22985-3-3-3.78][23014-0-0-4.83][23112-1-1-2.32][23144-3-3-5.51][23168-2-0-1.08]
[23219-0-0-1.66][23363-3-3-2.55][23470-0-0-3.42][23486-2-2-0.22][23497-0-3-6.86][23516-0-0-5.24][23690-1-1-0.95][23921-2-1-1.69][23936-1-2-3.55][24040-3-0-0.16]
[24111-1-1-0.66][24182-0-0-7.02][24238-3-3-1.85][24290-2-0-2.74][24345-0-0-1.49][24364-1-2-0.39][24427-3-0-3.89][24477-2-2-3.96][24495-2-1-1.00][24893-2-2-0.64]
[25012-1-1-0.24][25121-2-1-1.02][25165-3-3-3.30][25183-0-0-3.32][25297-3-3-2.79][25398-0-0-3.12][25574-2-2-0.75][25644-1-2-3.18][25718-1-0--0.22][25774-2-2--0.30]
[26032-3-3-3.28][26051-3-3-4.78][26120-0-0-3.87][26321-1-1-1.78][26732-1-1-3.83][26784-3-3-4.72][26827-3-3-1.86][26833-0-3-4.64][26838-2-3-1.18][26860-1-2--0.17]
[26948-0-0-3.86][27049-3-0-1.15][27098-1-0-1.25][27526-0-0-4.56][27639-3-3-0.97][27698-3-3-4.11][27772-0-0-3.22][27890-1-1-4.39][28040-0-0-2.23][28503-2-2-2.94]
[28577-1-1-2.92][28959-0-0-6.40][29198-3-3-2.31][29777-0-0-9.08][29877-2-3-1.14][30035-1-1-2.16][30098-0-0-2.98][30326-1-1-5.31][30572-2-2-2.07][30716-0-1-1.52]
[30806-2-3-1.77][30906-1-1-3.10][31007-0-0-2.21][31181-3-3-1.34][31238-0-3-2.92][31347-0-0-8.24][31422-2-2--0.15][31429-3-3-2.04][31431-0-3-0.99][31432-1-1-4.48]
[31477-0-0-5.71][31524-1-2-1.22][31597-1-2-1.40][31619-1-3-0.83][31701-0-0-6.10][31755-0-0-5.01][31854-3-3-4.41][32074-1-1-1.05][32078-3-3-4.40][32111-1-1-1.90]
[32127-1-1-3.29][32140-3-3-4.07][32263-2-0-1.73][32365-0-0-1.78][32411-2-0-6.40][32429-3-3-1.07][32473-3-0-2.55][32574-3-3-3.56][32584-0-0-2.01][32622-0-1-0.60]
[32858-3-0-3.15][32969-3-3-4.05][33016-2-2-1.95][33031-1-3-1.91][33035-2-2-3.75][33133-2-2-1.22][33173-2-2-0.14][33175-3-2-1.56][33306-3-3-1.19][33309-2-3-3.01]
[33474-0-0-1.71][33478-2-3-1.03][33618-1-1-1.77][33712-0-0-1.66][33782-2-2-0.91][33914-3-3-3.58][34076-3-3-1.09][34112-2-2-1.16][34138-2-3-1.90][34239-1-2-0.45]
[34364-2-2-2.12][34617-1-2-1.78][34751-3-3-0.84][34783-2-2-0.21][35015-3-2-2.53][35018-1-2-0.64][35288-2-1-0.00]
---------------------------
I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.107 | Acc: 98.125% | Wgt Acc: 98.081%
	I - Batch: 100 | Loss: 0.113 | Acc: 97.750% | Wgt Acc: 97.675%
	I - Batch: 150 | Loss: 0.112 | Acc: 98.000% | Wgt Acc: 97.954%
I - num batch: 160
I - Train -- Loss: 0.112 | Acc: 97.958% | Wgt Acc: 97.921% | LR: 1.250000e-04 | Dur: 140.53s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   2.   3.  14.]
 [  4. 574.   4.   4.]
 [  2.   2. 725.   5.]
 [ 10.   0.   2. 515.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.026 | Acc: 64.220% | Wgt Acc: 63.451% | Dur: 11.19s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  7.  6. 20.]
 [ 2. 40. 12.  1.]
 [ 6. 26. 49. 11.]
 [13.  5.  8. 54.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.085 | Acc: 98.375% | Wgt Acc: 98.322%
	I - Batch: 100 | Loss: 0.090 | Acc: 98.688% | Wgt Acc: 98.664%
	I - Batch: 150 | Loss: 0.092 | Acc: 98.542% | Wgt Acc: 98.516%
I - num batch: 160
I - Train -- Loss: 0.094 | Acc: 98.430% | Wgt Acc: 98.408% | LR: 1.250000e-04 | Dur: 139.96s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   1.   2.  13.]
 [  0. 576.   3.   3.]
 [  6.   1. 727.   2.]
 [  7.   0.   2. 520.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.004 | Acc: 68.196% | Wgt Acc: 67.867% | Dur: 11.85s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  5.  5. 14.]
 [ 2. 47. 12.  2.]
 [ 7. 22. 52. 10.]
 [15.  4.  6. 60.]]

I - Local maximum validation set accuracy:  68.20

I - Validation set results: 
[14-1-2-2.37][50-3-1-0.57][124-2-2-1.76][127-0-0-4.23][443-2-2-3.24][567-0-0-1.62][573-1-1-2.65][615-0-3-2.11][695-1-2-2.42][722-3-0-3.09]
[826-0-0-3.44][878-0-0-3.27][1103-0-0-2.96][1212-3-3-1.57][1368-0-0-3.44][2181-2-2-1.26][2476-2-2-1.28][2721-2-2-4.01][2818-1-3-0.19][2886-2-1-1.79]
[3231-2-2-3.84][3333-2-2-3.13][3482-2-2-3.30][3536-3-3-1.06][3625-1-1-6.25][3909-0-0-1.79][4035-0-0-1.45][4140-0-0-2.48][4214-1-3-2.20][4346-1-0-0.85]
[4581-2-2-1.88][4708-3-2-2.79][4838-3-0-0.92][4845-1-2-0.70][4868-0-0-6.37][4939-0-1-0.80][4984-2-2-2.29][5078-1-2-0.81][5396-0-0-5.00][5479-1-1-3.54]
[5717-0-0-1.83][5843-1-1-2.10][5949-3-3-0.92][5987-2-1-1.00][6014-3-3-0.69][6033-3-3-0.50][6313-0-0-2.94][6421-3-3-3.59][6500-1-2-3.59][6583-3-3-2.07]
[6683-3-3-2.20][6825-2-1-2.45][6998-3-3-0.22][7049-3-3-1.79][7517-1-1-5.51][7521-1-2-0.22][7528-1-2-1.34][7949-1-2-2.37][8135-1-0-2.88][8185-3-0-3.85]
[8269-3-1-1.19][8273-3-3-3.08][8543-3-0-6.20][8666-1-1-3.20][8672-0-0-4.03][8903-1-1-0.86][9001-2-1-3.03][9036-2-2-4.26][9281-3-3-0.30][9300-2-2-5.17]
[9571-0-3-0.20][9617-1-1-3.43][9644-2-2-3.81][9705-2-2-0.16][9801-0-0-1.66][9803-3-3-1.75][9865-3-3-4.32][9896-2-2-3.14][10314-1-2-0.59][10337-3-3-4.97]
[10403-0-2--0.34][10653-2-2-0.55][10704-2-2-1.70][10719-1-1-3.82][10727-1-1-0.27][10836-0-0-9.66][10969-2-3-1.29][11042-0-2--0.40][11088-1-1-3.21][11322-0-0-4.51]
[11398-2-2-1.53][11499-0-0-2.01][11502-3-3-1.53][11512-3-3-2.72][11608-1-2-2.61][11610-0-0-2.06][11692-0-0-0.62][11905-0-3-1.54][11993-1-1-2.36][12002-2-2-0.40]
[12052-0-0-3.56][12201-0-3-2.95][12235-2-2-3.30][12320-1-0-0.64][12377-2-1-0.62][12398-2-3-0.99][12503-1-2-2.05][12617-0-3--0.32][12685-3-3-1.60][12738-2-0-0.82]
[12742-2-2-6.08][12823-0-3-1.69][13110-1-1-1.04][13240-3-3-3.62][13253-1-1-3.02][13273-0-0-8.20][13634-1-2-0.99][13763-2-2-0.49][13905-3-3--0.35][14060-2-1-2.70]
[14065-3-3-1.70][14147-3-3-1.73][14595-2-2-2.22][14687-2-2-4.41][14788-2-2-5.06][14869-1-1-4.81][14872-3-0-0.02][14877-1-1-3.68][14927-0-3-0.58][15066-0-0-5.16]
[15175-1-1-0.25][15178-2-3-0.65][15375-3-0-2.92][15389-3-3-2.75][15568-2-1-2.85][15675-3-3-2.71][15869-1-2-0.59][16207-3-0-1.59][16236-0-2-0.04][16302-3-2-0.79]
[16331-2-2-6.73][16381-0-0--0.08][16488-1-1-7.56][16495-0-0-4.06][16650-0-0-2.36][16719-1-2-1.69][16801-0-0-7.43][16828-0-0-3.57][17137-3-0-1.97][17245-1-1-0.83]
[17278-3-0-0.39][17282-0-0--0.27][17311-2-2-3.43][17336-2-1-0.43][17608-3-3-5.48][17627-0-0--0.12][17877-3-0-0.78][17924-1-2-0.25][17984-3-3-3.40][18211-0-3-1.51]
[18276-3-3-1.60][18287-1-1-0.87][18394-0-0-3.68][18428-0-0-4.02][18442-0-3-1.74][18478-3-3-2.29][18607-0-0-3.90][18616-0-0-3.27][18663-0-0-2.70][18718-0-0-5.78]
[18766-2-2-4.00][18824-2-2-2.72][18890-3-3-1.49][18930-3-2-0.81][18938-3-3-2.36][19817-1-2-1.53][19839-0-2-0.34][19930-3-3-2.60][19944-0-2-0.69][20036-2-2-4.60]
[20101-3-3--0.18][20474-1-1-4.04][20547-3-0-1.88][20929-2-2-7.06][21245-1-2-1.54][21257-3-3-0.44][21293-1-1-3.20][21316-1-1-1.44][21384-1-1-2.07][21448-1-2-1.71]
[21483-0-0-2.93][21487-2-2-4.93][21714-0-3-1.77][21943-3-2-0.56][21947-0-0-1.45][21948-0-0-6.41][21965-2-2-5.66][21998-1-1-4.11][22025-0-2-1.74][22228-3-3-5.11]
[22446-1-1-5.06][22494-3-3-1.82][22757-0-0-5.11][22811-3-3-1.65][22976-3-2-1.42][22985-3-3-3.64][23014-0-0-3.01][23112-1-1-2.63][23144-3-3-5.10][23168-2-0-1.56]
[23219-0-0-1.33][23363-3-3-1.24][23470-0-0-1.79][23486-2-2-2.67][23497-0-3-5.18][23516-0-0-4.05][23690-1-2-1.67][23921-2-2-2.45][23936-1-2-3.83][24040-3-2-0.70]
[24111-1-1-0.93][24182-0-0-5.73][24238-3-3-1.42][24290-2-0-2.53][24345-0-0-1.69][24364-1-3-1.88][24427-3-0-0.50][24477-2-2-3.38][24495-2-1-1.87][24893-2-2-2.46]
[25012-1-2-1.51][25121-2-1-2.67][25165-3-3-2.51][25183-0-0-5.04][25297-3-3-2.94][25398-0-0-3.13][25574-2-2-3.69][25644-1-1-3.22][25718-1-1-0.12][25774-2-3--0.45]
[26032-3-3-3.20][26051-3-3-4.16][26120-0-0-3.03][26321-1-1-1.28][26732-1-1-4.30][26784-3-3-4.44][26827-3-3-2.02][26833-0-3-3.51][26838-2-2-1.43][26860-1-1-0.85]
[26948-0-0-1.64][27049-3-2--0.76][27098-1-0-2.63][27526-0-0-2.08][27639-3-3-1.35][27698-3-3-2.60][27772-0-0-4.68][27890-1-1-4.17][28040-0-3--0.04][28503-2-2-5.17]
[28577-1-1-3.20][28959-0-0-5.78][29198-3-3-1.50][29777-0-0-6.59][29877-2-2-0.73][30035-1-1-2.01][30098-0-0-1.54][30326-1-1-6.46][30572-2-2-2.92][30716-0-1-0.72]
[30806-2-2-0.77][30906-1-1-4.12][31007-0-0-1.50][31181-3-3-1.06][31238-0-3-1.62][31347-0-0-5.72][31422-2-2-0.71][31429-3-3-1.38][31431-0-0-0.76][31432-1-1-4.63]
[31477-0-0-2.76][31524-1-1-1.29][31597-1-2-2.63][31619-1-0-0.72][31701-0-0-4.46][31755-0-0-3.87][31854-3-3-1.94][32074-1-1-1.29][32078-3-3-3.46][32111-1-1-1.29]
[32127-1-1-2.05][32140-3-3-4.05][32263-2-0-0.29][32365-0-0-2.84][32411-2-0-4.74][32429-3-3-1.68][32473-3-0-2.00][32574-3-3-2.38][32584-0-0-1.17][32622-0-2-0.08]
[32858-3-0-2.34][32969-3-3-4.31][33016-2-2-4.24][33031-1-3-3.33][33035-2-2-4.49][33133-2-2-3.27][33173-2-2-2.15][33175-3-2-2.55][33306-3-3-0.66][33309-2-3-2.79]
[33474-0-0-0.51][33478-2-3--0.27][33618-1-1-2.08][33712-0-3-1.50][33782-2-2-2.52][33914-3-3-3.02][34076-3-2-2.92][34112-2-1-1.80][34138-2-1-1.07][34239-1-1-0.43]
[34364-2-2-3.24][34617-1-1-0.47][34751-3-3-1.05][34783-2-2-1.60][35015-3-2-3.71][35018-1-1-1.39][35288-2-2-1.03]
---------------------------
I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.103 | Acc: 97.750% | Wgt Acc: 97.770%
	I - Batch: 100 | Loss: 0.101 | Acc: 98.125% | Wgt Acc: 98.124%
	I - Batch: 150 | Loss: 0.096 | Acc: 98.333% | Wgt Acc: 98.329%
I - num batch: 160
I - Train -- Loss: 0.097 | Acc: 98.233% | Wgt Acc: 98.231% | LR: 1.250000e-04 | Dur: 140.58s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   2.   2.  10.]
 [  6. 574.   3.   1.]
 [  5.   1. 728.   5.]
 [  8.   1.   1. 522.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.018 | Acc: 65.443% | Wgt Acc: 64.810% | Dur: 11.62s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  4.  3. 15.]
 [ 3. 40. 12.  3.]
 [ 7. 29. 55. 10.]
 [17.  5.  5. 58.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 98.375% | Wgt Acc: 98.480%
	I - Batch: 100 | Loss: 0.080 | Acc: 98.938% | Wgt Acc: 98.999%
	I - Batch: 150 | Loss: 0.088 | Acc: 98.458% | Wgt Acc: 98.488%
I - num batch: 160
I - Train -- Loss: 0.091 | Acc: 98.390% | Wgt Acc: 98.434% | LR: 1.250000e-04 | Dur: 140.30s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   1.   4.   6.]
 [  6. 575.   1.   1.]
 [  5.   2. 726.   3.]
 [  9.   0.   3. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.158 | Acc: 65.443% | Wgt Acc: 64.470% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 15.  6. 24.]
 [ 0. 35.  7.  0.]
 [ 3. 16. 47.  4.]
 [11. 12. 15. 58.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.102 | Acc: 98.250% | Wgt Acc: 98.168%
	I - Batch: 100 | Loss: 0.096 | Acc: 98.312% | Wgt Acc: 98.294%
	I - Batch: 150 | Loss: 0.092 | Acc: 98.333% | Wgt Acc: 98.309%
I - num batch: 160
I - Train -- Loss: 0.091 | Acc: 98.312% | Wgt Acc: 98.284% | LR: 1.250000e-04 | Dur: 141.46s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   0.   1.  10.]
 [  1. 576.   2.   4.]
 [  5.   1. 728.   6.]
 [  9.   1.   3. 518.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.093 | Acc: 68.196% | Wgt Acc: 67.527% | Dur: 11.75s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  5.  4. 14.]
 [ 2. 45. 13.  5.]
 [ 4. 23. 50. 10.]
 [11.  5.  8. 57.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.077 | Acc: 98.750% | Wgt Acc: 98.761%
	I - Batch: 100 | Loss: 0.071 | Acc: 99.125% | Wgt Acc: 99.125%
	I - Batch: 150 | Loss: 0.074 | Acc: 98.917% | Wgt Acc: 98.940%
I - num batch: 160
I - Train -- Loss: 0.073 | Acc: 98.979% | Wgt Acc: 99.000% | LR: 1.250000e-04 | Dur: 140.20s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   2.   7.]
 [  2. 577.   1.   0.]
 [  0.   1. 727.   1.]
 [  8.   0.   4. 530.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.010 | Acc: 65.749% | Wgt Acc: 65.149% | Dur: 11.53s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  4.  3. 18.]
 [ 2. 42. 14.  1.]
 [ 7. 28. 53. 10.]
 [16.  4.  5. 57.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.069 | Acc: 98.875% | Wgt Acc: 98.846%
	I - Batch: 100 | Loss: 0.084 | Acc: 98.375% | Wgt Acc: 98.408%
	I - Batch: 150 | Loss: 0.082 | Acc: 98.625% | Wgt Acc: 98.620%
I - num batch: 160
I - Train -- Loss: 0.081 | Acc: 98.665% | Wgt Acc: 98.664% | LR: 1.250000e-04 | Dur: 140.19s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   2.   0.   7.]
 [  3. 575.   3.   3.]
 [  3.   1. 730.   2.]
 [  9.   0.   1. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.007 | Acc: 66.667% | Wgt Acc: 65.761% | Dur: 11.64s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  5.  7. 22.]
 [ 2. 50. 16.  6.]
 [ 5. 21. 48. 12.]
 [ 7.  2.  4. 46.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 98.750% | Wgt Acc: 98.725%
	I - Batch: 100 | Loss: 0.078 | Acc: 98.812% | Wgt Acc: 98.830%
	I - Batch: 150 | Loss: 0.076 | Acc: 98.833% | Wgt Acc: 98.854%
I - num batch: 160
I - Train -- Loss: 0.078 | Acc: 98.783% | Wgt Acc: 98.788% | LR: 1.250000e-04 | Dur: 140.27s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   1.   6.]
 [  3. 575.   2.   1.]
 [  4.   3. 729.   3.]
 [  6.   0.   2. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.115 | Acc: 65.138% | Wgt Acc: 65.353% | Dur: 11.64s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  7.  4. 16.]
 [ 2. 49. 15.  4.]
 [ 5. 17. 42.  5.]
 [20.  5. 14. 61.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.070 | Acc: 98.750% | Wgt Acc: 98.705%
	I - Batch: 100 | Loss: 0.067 | Acc: 98.938% | Wgt Acc: 98.942%
	I - Batch: 150 | Loss: 0.071 | Acc: 98.708% | Wgt Acc: 98.704%
I - num batch: 160
I - Train -- Loss: 0.072 | Acc: 98.744% | Wgt Acc: 98.744% | LR: 1.250000e-04 | Dur: 140.50s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   2.   6.]
 [  3. 576.   1.   1.]
 [  3.   1. 730.   5.]
 [  8.   1.   1. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.199 | Acc: 62.691% | Wgt Acc: 62.772% | Dur: 11.37s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  7.  7. 21.]
 [ 1. 47. 16.  3.]
 [ 2. 14. 39.  5.]
 [23. 10. 13. 57.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.101 | Acc: 97.375% | Wgt Acc: 97.419%
	I - Batch: 100 | Loss: 0.094 | Acc: 97.875% | Wgt Acc: 97.908%
	I - Batch: 150 | Loss: 0.088 | Acc: 98.125% | Wgt Acc: 98.131%
I - num batch: 160
I - Train -- Loss: 0.087 | Acc: 98.194% | Wgt Acc: 98.195% | LR: 1.250000e-04 | Dur: 140.44s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   1.   2.  12.]
 [  2. 574.   4.   0.]
 [  4.   3. 727.   4.]
 [ 13.   0.   1. 522.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.049 | Acc: 67.584% | Wgt Acc: 66.440% | Dur: 11.58s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  3. 24.]
 [ 2. 46. 12.  5.]
 [ 4. 22. 54.  9.]
 [ 9.  4.  6. 48.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.064 | Acc: 98.875% | Wgt Acc: 98.902%
	I - Batch: 100 | Loss: 0.061 | Acc: 99.250% | Wgt Acc: 99.269%
	I - Batch: 150 | Loss: 0.063 | Acc: 99.083% | Wgt Acc: 99.089%
I - num batch: 160
I - Train -- Loss: 0.062 | Acc: 99.136% | Wgt Acc: 99.142% | LR: 1.250000e-04 | Dur: 140.23s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   1.   6.]
 [  2. 578.   0.   0.]
 [  2.   0. 732.   3.]
 [  7.   0.   1. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.007 | Acc: 66.667% | Wgt Acc: 66.508% | Dur: 11.60s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  5.  4. 15.]
 [ 2. 45. 11.  1.]
 [ 2. 23. 48.  8.]
 [21.  5. 12. 62.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.047 | Acc: 99.625% | Wgt Acc: 99.662%
	I - Batch: 100 | Loss: 0.053 | Acc: 99.500% | Wgt Acc: 99.520%
	I - Batch: 150 | Loss: 0.056 | Acc: 99.292% | Wgt Acc: 99.305%
I - num batch: 160
I - Train -- Loss: 0.059 | Acc: 99.176% | Wgt Acc: 99.195% | LR: 1.250000e-04 | Dur: 139.81s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   3.   4.]
 [  1. 577.   1.   1.]
 [  4.   0. 729.   1.]
 [  4.   1.   1. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.087 | Acc: 66.055% | Wgt Acc: 65.082% | Dur: 11.48s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  4.  7. 30.]
 [ 2. 50. 15.  5.]
 [ 4. 19. 47.  7.]
 [ 7.  5.  6. 44.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.079 | Acc: 98.250% | Wgt Acc: 98.311%
	I - Batch: 100 | Loss: 0.072 | Acc: 98.750% | Wgt Acc: 98.762%
	I - Batch: 150 | Loss: 0.068 | Acc: 98.875% | Wgt Acc: 98.874%
I - num batch: 160
I - Train -- Loss: 0.067 | Acc: 98.901% | Wgt Acc: 98.894% | LR: 1.250000e-04 | Dur: 139.97s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   1.   0.   8.]
 [  3. 575.   1.   0.]
 [  3.   2. 731.   2.]
 [  6.   0.   2. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.153 | Acc: 68.196% | Wgt Acc: 67.120% | Dur: 11.43s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 10. 11. 33.]
 [ 0. 45.  6.  0.]
 [ 1. 16. 46.  2.]
 [ 6.  7. 12. 51.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.058 | Acc: 99.125% | Wgt Acc: 99.127%
	I - Batch: 100 | Loss: 0.061 | Acc: 99.062% | Wgt Acc: 99.027%
	I - Batch: 150 | Loss: 0.059 | Acc: 99.167% | Wgt Acc: 99.155%
I - num batch: 160
I - Train -- Loss: 0.067 | Acc: 99.136% | Wgt Acc: 99.115% | LR: 1.250000e-04 | Dur: 140.27s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   1.   7.]
 [  2. 576.   2.   1.]
 [  0.   2. 731.   2.]
 [  5.   0.   0. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.239 | Acc: 66.361% | Wgt Acc: 65.489% | Dur: 11.89s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 14.  9. 26.]
 [ 0. 40. 11.  1.]
 [ 0. 14. 40.  3.]
 [ 7. 10. 15. 56.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.088 | Acc: 98.000% | Wgt Acc: 98.061%
	I - Batch: 100 | Loss: 0.074 | Acc: 98.812% | Wgt Acc: 98.858%
	I - Batch: 150 | Loss: 0.067 | Acc: 99.125% | Wgt Acc: 99.164%
I - num batch: 160
I - Train -- Loss: 0.066 | Acc: 99.176% | Wgt Acc: 99.213% | LR: 1.250000e-04 | Dur: 140.48s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   2.   1.]
 [  2. 576.   4.   1.]
 [  1.   1. 728.   1.]
 [  7.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.116 | Acc: 67.584% | Wgt Acc: 66.712% | Dur: 11.60s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  8. 26.]
 [ 3. 50. 13.  5.]
 [ 2. 17. 48.  7.]
 [ 8.  6.  6. 48.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 98.875% | Wgt Acc: 98.875%
	I - Batch: 100 | Loss: 0.057 | Acc: 98.875% | Wgt Acc: 98.861%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.000% | Wgt Acc: 98.995%
I - num batch: 160
I - Train -- Loss: 0.058 | Acc: 99.018% | Wgt Acc: 99.009% | LR: 1.250000e-04 | Dur: 140.62s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   1.   8.]
 [  2. 575.   1.   0.]
 [  0.   1. 731.   1.]
 [  8.   1.   1. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.009 | Acc: 67.890% | Wgt Acc: 67.120% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  5.  3. 17.]
 [ 2. 43. 12.  2.]
 [ 8. 27. 55. 10.]
 [11.  3.  5. 57.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.047 | Acc: 99.500% | Wgt Acc: 99.494%
	I - Batch: 100 | Loss: 0.061 | Acc: 98.812% | Wgt Acc: 98.820%
	I - Batch: 150 | Loss: 0.054 | Acc: 99.125% | Wgt Acc: 99.127%
I - num batch: 160
I - Train -- Loss: 0.055 | Acc: 99.176% | Wgt Acc: 99.177% | LR: 1.250000e-04 | Dur: 141.73s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   1.   2.   6.]
 [  2. 576.   0.   1.]
 [  0.   1. 730.   0.]
 [  6.   0.   2. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.171 | Acc: 67.584% | Wgt Acc: 66.780% | Dur: 11.52s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  4.  3. 17.]
 [ 1. 42.  8.  3.]
 [ 8. 26. 58.  9.]
 [15.  6.  6. 57.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.073 | Acc: 98.250% | Wgt Acc: 98.342%
	I - Batch: 100 | Loss: 0.067 | Acc: 98.625% | Wgt Acc: 98.677%
	I - Batch: 150 | Loss: 0.061 | Acc: 98.958% | Wgt Acc: 99.005%
I - num batch: 160
I - Train -- Loss: 0.061 | Acc: 99.018% | Wgt Acc: 99.062% | LR: 1.250000e-04 | Dur: 140.87s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   2.   3.]
 [  2. 576.   3.   1.]
 [  5.   1. 725.   0.]
 [  3.   0.   4. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.093 | Acc: 67.584% | Wgt Acc: 66.984% | Dur: 11.22s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  5.  4. 13.]
 [ 2. 40.  8.  3.]
 [ 6. 28. 56.  8.]
 [17.  5.  7. 62.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.625% | Wgt Acc: 99.578%
	I - Batch: 100 | Loss: 0.045 | Acc: 99.500% | Wgt Acc: 99.465%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.417% | Wgt Acc: 99.409%
I - num batch: 160
I - Train -- Loss: 0.047 | Acc: 99.450% | Wgt Acc: 99.443% | LR: 1.250000e-04 | Dur: 140.02s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   2.]
 [  2. 575.   1.   1.]
 [  2.   2. 732.   1.]
 [  1.   1.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.065 | Acc: 64.832% | Wgt Acc: 64.062% | Dur: 11.96s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  4.  3. 18.]
 [ 3. 41. 11.  3.]
 [ 7. 28. 54. 11.]
 [15.  5.  7. 54.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 99.625% | Wgt Acc: 99.579%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.562% | Wgt Acc: 99.520%
	I - Batch: 150 | Loss: 0.039 | Acc: 99.667% | Wgt Acc: 99.643%
I - num batch: 160
I - Train -- Loss: 0.040 | Acc: 99.647% | Wgt Acc: 99.628% | LR: 1.250000e-04 | Dur: 140.52s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   3.]
 [  0. 578.   1.   1.]
 [  0.   0. 732.   2.]
 [  1.   0.   1. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.116 | Acc: 64.526% | Wgt Acc: 63.383% | Dur: 11.14s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 10.  8. 30.]
 [ 2. 45. 14.  5.]
 [ 3. 19. 44.  7.]
 [ 5.  4.  9. 44.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.037 | Acc: 99.500% | Wgt Acc: 99.465%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.562% | Wgt Acc: 99.536%
	I - Batch: 150 | Loss: 0.040 | Acc: 99.542% | Wgt Acc: 99.521%
I - num batch: 160
I - Train -- Loss: 0.041 | Acc: 99.529% | Wgt Acc: 99.513% | LR: 1.250000e-04 | Dur: 139.39s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.]
 [  0. 575.   1.   2.]
 [  2.   3. 732.   2.]
 [  1.   0.   1. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.207 | Acc: 67.890% | Wgt Acc: 67.391% | Dur: 11.84s
I - Confusion Matrix: [row->prediction - col->label]
[[82. 10. 11. 25.]
 [ 2. 48. 17.  2.]
 [ 0. 13. 36.  3.]
 [ 4.  7. 11. 56.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 99.250% | Wgt Acc: 99.240%
	I - Batch: 100 | Loss: 0.050 | Acc: 99.500% | Wgt Acc: 99.494%
	I - Batch: 150 | Loss: 0.050 | Acc: 99.417% | Wgt Acc: 99.409%
I - num batch: 160
I - Train -- Loss: 0.049 | Acc: 99.411% | Wgt Acc: 99.407% | LR: 1.250000e-04 | Dur: 139.56s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   1.   0.   2.]
 [  0. 576.   1.   1.]
 [  2.   1. 733.   2.]
 [  5.   0.   0. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.058 | Acc: 65.138% | Wgt Acc: 64.334% | Dur: 11.37s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  7.  7. 20.]
 [ 4. 42. 13.  0.]
 [ 8. 25. 52. 13.]
 [10.  4.  3. 53.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.833% | Wgt Acc: 99.822%
I - num batch: 160
I - Train -- Loss: 0.037 | Acc: 99.764% | Wgt Acc: 99.752% | LR: 1.250000e-04 | Dur: 139.69s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   4.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  1.   0.   1. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.235 | Acc: 60.856% | Wgt Acc: 59.307% | Dur: 11.42s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  8. 26.]
 [ 2. 34. 11.  2.]
 [ 7. 34. 53. 15.]
 [10.  4.  3. 43.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.052 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 100 | Loss: 0.050 | Acc: 99.438% | Wgt Acc: 99.451%
	I - Batch: 150 | Loss: 0.047 | Acc: 99.542% | Wgt Acc: 99.559%
I - num batch: 160
I - Train -- Loss: 0.047 | Acc: 99.568% | Wgt Acc: 99.584% | LR: 1.250000e-04 | Dur: 139.61s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   2.   0.]
 [  0. 577.   2.   1.]
 [  2.   0. 729.   1.]
 [  1.   1.   1. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.008 | Acc: 66.361% | Wgt Acc: 65.761% | Dur: 11.50s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  5.  4. 20.]
 [ 2. 46. 14.  4.]
 [ 5. 23. 50.  8.]
 [14.  4.  7. 54.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.500% | Wgt Acc: 99.495%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.500% | Wgt Acc: 99.508%
	I - Batch: 150 | Loss: 0.037 | Acc: 99.625% | Wgt Acc: 99.634%
I - num batch: 160
I - Train -- Loss: 0.037 | Acc: 99.647% | Wgt Acc: 99.655% | LR: 1.250000e-04 | Dur: 139.10s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   1.]
 [  2. 576.   0.   0.]
 [  1.   2. 733.   0.]
 [  2.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.089 | Acc: 66.361% | Wgt Acc: 66.372% | Dur: 11.38s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  4.  1.  9.]
 [ 1. 47. 12.  3.]
 [ 9. 21. 51. 12.]
 [21.  6. 11. 62.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.792% | Wgt Acc: 99.793%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.804% | Wgt Acc: 99.805% | LR: 1.250000e-04 | Dur: 139.02s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   1.   0.]
 [  1.   0. 732.   1.]
 [  0.   0.   1. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.209 | Acc: 63.609% | Wgt Acc: 62.228% | Dur: 11.78s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  4.  5. 19.]
 [ 2. 35.  7.  2.]
 [10. 35. 58. 16.]
 [10.  4.  5. 49.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.812% | Wgt Acc: 99.831%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.833% | Wgt Acc: 99.850%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.804% | Wgt Acc: 99.814% | LR: 1.250000e-04 | Dur: 140.53s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   1.   0.   0.]
 [  1. 577.   0.   0.]
 [  0.   0. 733.   0.]
 [  2.   0.   1. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.023 | Acc: 67.584% | Wgt Acc: 67.255% | Dur: 11.23s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  5.  3. 10.]
 [ 2. 42.  9.  4.]
 [ 4. 24. 52.  8.]
 [19.  7. 11. 64.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.625% | Wgt Acc: 99.619%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.750% | Wgt Acc: 99.746%
I - num batch: 160
I - Train -- Loss: 0.035 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-04 | Dur: 139.84s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   1.   0.   1.]
 [  1. 576.   1.   0.]
 [  1.   0. 733.   0.]
 [  0.   1.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 68.196% | Wgt Acc: 68.139% | Dur: 11.36s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  4.  2. 12.]
 [ 3. 44.  7.  1.]
 [ 2. 20. 51.  6.]
 [22. 10. 15. 67.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.833% | Wgt Acc: 99.831%
I - num batch: 160
I - Train -- Loss: 0.031 | Acc: 99.843% | Wgt Acc: 99.841% | LR: 1.250000e-04 | Dur: 139.76s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   1.   0.]
 [  0. 577.   0.   0.]
 [  0.   1. 733.   1.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.075 | Acc: 67.890% | Wgt Acc: 67.255% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  4.  2. 14.]
 [ 6. 46. 13.  4.]
 [ 8. 25. 56. 12.]
 [10.  3.  4. 56.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.025 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.833% | Wgt Acc: 99.831%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 99.843% | Wgt Acc: 99.841% | LR: 1.250000e-04 | Dur: 139.94s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   1.]
 [  2.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.173 | Acc: 62.997% | Wgt Acc: 62.024% | Dur: 11.72s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  2.  3. 21.]
 [ 5. 43.  9.  3.]
 [11. 29. 58. 16.]
 [13.  4.  5. 46.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.028 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.625% | Wgt Acc: 99.606%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.529% | Wgt Acc: 99.505% | LR: 1.250000e-04 | Dur: 139.93s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   2.]
 [  0. 576.   2.   0.]
 [  1.   2. 732.   4.]
 [  1.   0.   0. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.094 | Acc: 67.584% | Wgt Acc: 66.372% | Dur: 11.49s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  7.  6. 20.]
 [ 3. 42.  7.  4.]
 [ 4. 25. 57. 11.]
 [10.  4.  5. 51.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 99.250% | Wgt Acc: 99.269%
	I - Batch: 100 | Loss: 0.052 | Acc: 99.125% | Wgt Acc: 99.156%
	I - Batch: 150 | Loss: 0.049 | Acc: 99.208% | Wgt Acc: 99.239%
I - num batch: 160
I - Train -- Loss: 0.047 | Acc: 99.254% | Wgt Acc: 99.283% | LR: 1.250000e-04 | Dur: 140.39s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   1.]
 [  2. 575.   3.   0.]
 [  2.   3. 728.   1.]
 [  4.   0.   2. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.018 | Acc: 67.890% | Wgt Acc: 67.595% | Dur: 11.25s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  7. 15.]
 [ 4. 45. 13.  2.]
 [ 3. 21. 46.  7.]
 [12.  6.  9. 62.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 99.375% | Wgt Acc: 99.381%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.562% | Wgt Acc: 99.564%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.583% | Wgt Acc: 99.577%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.568% | Wgt Acc: 99.558% | LR: 1.250000e-04 | Dur: 140.06s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   5.]
 [  1. 578.   2.   1.]
 [  1.   0. 731.   0.]
 [  0.   0.   0. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.087 | Acc: 67.278% | Wgt Acc: 66.168% | Dur: 11.56s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  6.  3. 26.]
 [ 2. 47. 10.  4.]
 [ 6. 22. 56.  9.]
 [10.  3.  6. 47.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.030 | Acc: 99.625% | Wgt Acc: 99.605%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.562% | Wgt Acc: 99.577%
	I - Batch: 150 | Loss: 0.028 | Acc: 99.667% | Wgt Acc: 99.681%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 99.647% | Wgt Acc: 99.664% | LR: 1.250000e-04 | Dur: 140.47s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   1.]
 [  2. 577.   1.   0.]
 [  1.   1. 732.   0.]
 [  2.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.103 | Acc: 67.584% | Wgt Acc: 66.508% | Dur: 11.53s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  6.  6. 26.]
 [ 2. 45. 11.  3.]
 [ 3. 22. 50.  7.]
 [ 7.  5.  8. 50.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 99.375% | Wgt Acc: 99.380%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.562% | Wgt Acc: 99.549%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.583% | Wgt Acc: 99.577%
I - num batch: 160
I - Train -- Loss: 0.034 | Acc: 99.607% | Wgt Acc: 99.602% | LR: 1.250000e-04 | Dur: 140.58s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   1.   4.]
 [  0. 577.   0.   0.]
 [  2.   0. 732.   0.]
 [  1.   1.   1. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.201 | Acc: 64.832% | Wgt Acc: 64.130% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  5.  5. 12.]
 [ 3. 36.  8.  3.]
 [10. 30. 55. 11.]
 [14.  7.  7. 60.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 99.750% | Wgt Acc: 99.745%
	I - Batch: 100 | Loss: 0.027 | Acc: 99.812% | Wgt Acc: 99.817%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.792% | Wgt Acc: 99.793%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-04 | Dur: 140.56s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   2.]
 [  2. 578.   0.   0.]
 [  2.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.068 | Acc: 69.419% | Wgt Acc: 69.769% | Dur: 11.47s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  5.  6. 10.]
 [ 3. 52. 13.  5.]
 [ 7. 15. 47.  4.]
 [17.  6.  9. 67.]]

I - Local maximum validation set accuracy:  69.42

I - Validation set results: 
[14-1-2-2.49][50-3-1-0.42][124-2-1-1.46][127-0-0-7.36][443-2-2-2.78][567-0-0-2.54][573-1-1-3.08][615-0-3-2.67][695-1-2-3.13][722-3-3-3.52]
[826-0-0-4.04][878-0-3-3.03][1103-0-0-2.62][1212-3-3-1.38][1368-0-0-4.57][2181-2-3--0.34][2476-2-2-1.97][2721-2-2-3.50][2818-1-3-1.80][2886-2-1-2.25]
[3231-2-2-5.65][3333-2-2-3.13][3482-2-2-2.41][3536-3-3-3.25][3625-1-1-7.81][3909-0-0-1.84][4035-0-0-2.86][4140-0-0-3.73][4214-1-1-1.51][4346-1-0-0.24]
[4581-2-1-2.29][4708-3-2-1.99][4838-3-0-0.68][4845-1-1-1.82][4868-0-0-6.69][4939-0-1-0.38][4984-2-3-1.68][5078-1-3-1.80][5396-0-0-5.34][5479-1-1-4.90]
[5717-0-0-2.84][5843-1-1-1.61][5949-3-3-1.62][5987-2-2-2.10][6014-3-3-1.53][6033-3-3-0.82][6313-0-0-3.12][6421-3-3-3.92][6500-1-2-3.52][6583-3-3-4.22]
[6683-3-3-2.10][6825-2-1-3.70][6998-3-3-0.47][7049-3-3-2.61][7517-1-1-6.75][7521-1-1-1.06][7528-1-3-1.27][7949-1-2-3.48][8135-1-0-3.43][8185-3-0-3.50]
[8269-3-1-2.96][8273-3-3-5.19][8543-3-0-6.68][8666-1-1-5.46][8672-0-0-5.63][8903-1-1-0.57][9001-2-1-1.84][9036-2-2-4.15][9281-3-3-0.58][9300-2-2-6.04]
[9571-0-0-1.37][9617-1-1-0.20][9644-2-2-3.29][9705-2-0--0.87][9801-0-0-2.72][9803-3-3-0.72][9865-3-3-5.04][9896-2-2-4.78][10314-1-1-1.31][10337-3-3-5.13]
[10403-0-2--0.17][10653-2-2-1.56][10704-2-2-0.57][10719-1-1-3.09][10727-1-1-0.84][10836-0-0-10.42][10969-2-3-2.75][11042-0-0-0.12][11088-1-1-5.31][11322-0-0-5.54]
[11398-2-2-1.66][11499-0-0-2.94][11502-3-3-0.70][11512-3-3-0.80][11608-1-2-2.17][11610-0-0-4.58][11692-0-3-1.10][11905-0-0-5.11][11993-1-1-4.39][12002-2-2-0.98]
[12052-0-0-4.29][12201-0-3-3.49][12235-2-2-5.07][12320-1-0-2.64][12377-2-2-1.04][12398-2-3-1.63][12503-1-1-0.90][12617-0-2--0.07][12685-3-3-0.93][12738-2-0-2.06]
[12742-2-2-5.27][12823-0-3-2.91][13110-1-1-1.04][13240-3-3-5.38][13253-1-1-2.79][13273-0-0-7.85][13634-1-1-0.43][13763-2-3-0.42][13905-3-3-0.12][14060-2-1-3.83]
[14065-3-3-1.74][14147-3-3-2.98][14595-2-2-3.93][14687-2-2-4.50][14788-2-2-3.49][14869-1-1-6.05][14872-3-3-0.73][14877-1-1-4.63][14927-0-3-3.01][15066-0-0-5.72]
[15175-1-1-0.57][15178-2-2-0.50][15375-3-3-3.57][15389-3-3-3.84][15568-2-1-2.47][15675-3-3-2.36][15869-1-1--0.32][16207-3-0-3.32][16236-0-0-1.37][16302-3-3-2.17]
[16331-2-2-8.02][16381-0-0-0.56][16488-1-1-6.72][16495-0-0-5.02][16650-0-0-3.71][16719-1-2-1.65][16801-0-0-8.90][16828-0-0-4.28][17137-3-0-1.63][17245-1-1-1.52]
[17278-3-0-0.05][17282-0-2-0.51][17311-2-2-3.48][17336-2-1-0.84][17608-3-3-5.66][17627-0-3-0.70][17877-3-0-1.69][17924-1-3-0.73][17984-3-3-2.36][18211-0-3-1.26]
[18276-3-3-2.99][18287-1-1-1.52][18394-0-0-3.56][18428-0-0-6.39][18442-0-3-3.79][18478-3-3-2.80][18607-0-0-5.35][18616-0-0-3.18][18663-0-0-4.42][18718-0-0-5.77]
[18766-2-2-3.75][18824-2-2-2.76][18890-3-3-1.96][18930-3-1--0.44][18938-3-3-2.16][19817-1-2-2.73][19839-0-2-0.88][19930-3-3-3.50][19944-0-2-1.63][20036-2-2-4.35]
[20101-3-3-2.63][20474-1-1-5.15][20547-3-0-0.75][20929-2-2-7.42][21245-1-1-1.72][21257-3-3--0.41][21293-1-1-4.13][21316-1-1-6.48][21384-1-1-3.20][21448-1-1-1.79]
[21483-0-0-3.69][21487-2-2-3.01][21714-0-3-2.19][21943-3-3-1.03][21947-0-0-3.20][21948-0-0-8.59][21965-2-2-3.45][21998-1-1-3.85][22025-0-2--0.28][22228-3-3-6.39]
[22446-1-1-3.72][22494-3-3-3.27][22757-0-0-5.44][22811-3-3-3.89][22976-3-1-1.43][22985-3-3-4.73][23014-0-3-4.53][23112-1-1-4.31][23144-3-3-6.75][23168-2-0-0.23]
[23219-0-0-1.66][23363-3-3-5.12][23470-0-0-1.43][23486-2-2-1.47][23497-0-3-6.29][23516-0-0-3.68][23690-1-1-0.70][23921-2-2-3.81][23936-1-2-1.48][24040-3-2-1.39]
[24111-1-2-0.89][24182-0-0-8.14][24238-3-3-2.33][24290-2-0-2.88][24345-0-2-0.70][24364-1-2-0.44][24427-3-0-3.70][24477-2-2-2.20][24495-2-1-1.70][24893-2-2-1.45]
[25012-1-2-2.11][25121-2-1-2.19][25165-3-3-2.15][25183-0-0-2.34][25297-3-3-2.92][25398-0-0-3.02][25574-2-2-2.74][25644-1-2-4.82][25718-1-1-0.98][25774-2-2--0.55]
[26032-3-3-2.27][26051-3-3-4.79][26120-0-0-0.65][26321-1-1-3.35][26732-1-1-4.49][26784-3-3-7.03][26827-3-3-1.86][26833-0-3-3.09][26838-2-2-0.74][26860-1-2-2.35]
[26948-0-0-2.35][27049-3-0-1.25][27098-1-0-1.92][27526-0-0-2.08][27639-3-3-0.47][27698-3-3-3.92][27772-0-0-4.52][27890-1-1-5.33][28040-0-0-1.14][28503-2-2-4.65]
[28577-1-1-3.43][28959-0-0-6.24][29198-3-3-0.87][29777-0-0-6.81][29877-2-1-2.64][30035-1-1-4.22][30098-0-0-0.52][30326-1-1-5.82][30572-2-2-1.43][30716-0-1-2.16]
[30806-2-3-1.10][30906-1-1-6.56][31007-0-0-3.06][31181-3-3-1.36][31238-0-3-2.12][31347-0-0-6.01][31422-2-2-0.90][31429-3-3-1.83][31431-0-0--0.08][31432-1-1-5.11]
[31477-0-3-3.88][31524-1-1-1.21][31597-1-2-2.44][31619-1-0-0.16][31701-0-0-3.81][31755-0-0-4.37][31854-3-3-1.36][32074-1-3-0.22][32078-3-3-3.88][32111-1-1-2.58]
[32127-1-1-2.32][32140-3-3-4.06][32263-2-0-0.84][32365-0-0-4.96][32411-2-0-5.52][32429-3-3-1.43][32473-3-3-2.34][32574-3-3-3.22][32584-0-0-1.64][32622-0-1-0.72]
[32858-3-3-3.13][32969-3-3-4.50][33016-2-2-3.04][33031-1-3-3.44][33035-2-2-5.07][33133-2-2-4.83][33173-2-1-0.26][33175-3-2-3.03][33306-3-1-1.89][33309-2-3-2.39]
[33474-0-3-0.03][33478-2-3--0.01][33618-1-1-1.02][33712-0-3-1.79][33782-2-2-3.91][33914-3-3-2.92][34076-3-2-2.47][34112-2-1-0.89][34138-2-3-0.71][34239-1-1-0.34]
[34364-2-2-5.16][34617-1-2-2.38][34751-3-3-3.17][34783-2-2-2.44][35015-3-3-1.79][35018-1-1-2.44][35288-2-2-1.48]
---------------------------
I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.027 | Acc: 99.688% | Wgt Acc: 99.676%
	I - Batch: 150 | Loss: 0.029 | Acc: 99.667% | Wgt Acc: 99.643%
I - num batch: 160
I - Train -- Loss: 0.030 | Acc: 99.686% | Wgt Acc: 99.664% | LR: 1.250000e-04 | Dur: 136.06s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   4.]
 [  0. 577.   0.   1.]
 [  0.   1. 734.   0.]
 [  2.   0.   0. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.086 | Acc: 66.972% | Wgt Acc: 66.304% | Dur: 9.86s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  7.  5. 21.]
 [ 6. 44. 14.  4.]
 [ 3. 22. 50.  5.]
 [10.  5.  6. 56.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 99.500% | Wgt Acc: 99.491%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.375% | Wgt Acc: 99.352%
	I - Batch: 150 | Loss: 0.043 | Acc: 99.375% | Wgt Acc: 99.371%
I - num batch: 160
I - Train -- Loss: 0.045 | Acc: 99.372% | Wgt Acc: 99.363% | LR: 1.250000e-04 | Dur: 126.55s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   2.]
 [  2. 575.   1.   3.]
 [  1.   3. 731.   0.]
 [  2.   0.   2. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.297 | Acc: 62.997% | Wgt Acc: 61.277% | Dur: 9.93s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 13. 11. 28.]
 [ 1. 28.  6.  1.]
 [ 4. 27. 53.  7.]
 [ 8. 10.  5. 50.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 96.875% | Wgt Acc: 96.908%
	I - Batch: 100 | Loss: 0.082 | Acc: 97.562% | Wgt Acc: 97.565%
	I - Batch: 150 | Loss: 0.070 | Acc: 98.250% | Wgt Acc: 98.255%
I - num batch: 160
I - Train -- Loss: 0.070 | Acc: 98.312% | Wgt Acc: 98.310% | LR: 1.250000e-04 | Dur: 126.84s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   3.   2.   6.]
 [  0. 571.   8.   1.]
 [  6.   3. 723.   5.]
 [  7.   1.   1. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 66.972% | Wgt Acc: 65.557% | Dur: 9.89s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  4.  5. 22.]
 [ 3. 40.  8.  2.]
 [ 5. 30. 58. 13.]
 [ 8.  4.  4. 49.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.070 | Acc: 98.375% | Wgt Acc: 98.370%
	I - Batch: 100 | Loss: 0.058 | Acc: 98.875% | Wgt Acc: 98.873%
	I - Batch: 150 | Loss: 0.053 | Acc: 99.042% | Wgt Acc: 99.042%
I - num batch: 160
I - Train -- Loss: 0.053 | Acc: 99.058% | Wgt Acc: 99.053% | LR: 1.250000e-04 | Dur: 126.89s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   3.   0.   2.]
 [  1. 573.   2.   2.]
 [  0.   2. 729.   2.]
 [  7.   0.   3. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.106 | Acc: 67.890% | Wgt Acc: 67.595% | Dur: 9.89s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9. 10. 20.]
 [ 2. 48. 10.  3.]
 [ 2. 14. 43.  4.]
 [12.  7. 12. 59.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 100 | Loss: 0.029 | Acc: 99.688% | Wgt Acc: 99.689%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.792% | Wgt Acc: 99.793%
I - num batch: 160
I - Train -- Loss: 0.030 | Acc: 99.804% | Wgt Acc: 99.805% | LR: 1.250000e-04 | Dur: 126.70s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   1.   0.   1.]
 [  0. 577.   1.   0.]
 [  2.   0. 733.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.122 | Acc: 65.749% | Wgt Acc: 65.829% | Dur: 9.86s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  8.  6. 22.]
 [ 3. 53. 21.  5.]
 [ 2. 12. 33.  3.]
 [10.  5. 15. 56.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.071 | Acc: 98.500% | Wgt Acc: 98.453%
	I - Batch: 100 | Loss: 0.064 | Acc: 98.688% | Wgt Acc: 98.664%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.042% | Wgt Acc: 99.023%
I - num batch: 160
I - Train -- Loss: 0.056 | Acc: 99.058% | Wgt Acc: 99.045% | LR: 1.250000e-04 | Dur: 127.47s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   2.   2.   4.]
 [  2. 572.   3.   2.]
 [  2.   1. 729.   0.]
 [  3.   3.   0. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 67.584% | Wgt Acc: 67.595% | Dur: 9.98s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  5.  6. 11.]
 [ 5. 47. 12.  5.]
 [ 3. 20. 47.  6.]
 [17.  6. 10. 64.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 99.625% | Wgt Acc: 99.663%
	I - Batch: 100 | Loss: 0.021 | Acc: 99.812% | Wgt Acc: 99.831%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.756%
I - num batch: 160
I - Train -- Loss: 0.022 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-04 | Dur: 126.43s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   1.]
 [  0. 578.   1.   0.]
 [  1.   0. 732.   1.]
 [  1.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.090 | Acc: 69.419% | Wgt Acc: 68.682% | Dur: 9.83s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  6. 26.]
 [ 3. 51. 11.  2.]
 [ 2. 18. 49.  6.]
 [ 8.  4.  9. 52.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.024 | Acc: 99.812% | Wgt Acc: 99.817%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.833% | Wgt Acc: 99.840%
I - num batch: 160
I - Train -- Loss: 0.022 | Acc: 99.804% | Wgt Acc: 99.814% | LR: 1.250000e-04 | Dur: 126.21s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.]
 [  1. 577.   0.   0.]
 [  2.   1. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.114 | Acc: 66.972% | Wgt Acc: 66.304% | Dur: 9.79s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  5. 23.]
 [ 5. 52. 15.  6.]
 [ 4. 15. 46.  9.]
 [ 6.  5.  9. 48.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.750% | Wgt Acc: 99.748%
	I - Batch: 100 | Loss: 0.024 | Acc: 99.688% | Wgt Acc: 99.677%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.708% | Wgt Acc: 99.700%
I - num batch: 160
I - Train -- Loss: 0.025 | Acc: 99.686% | Wgt Acc: 99.673% | LR: 1.250000e-04 | Dur: 126.04s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   3.]
 [  0. 577.   0.   0.]
 [  0.   0. 734.   1.]
 [  3.   1.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.129 | Acc: 68.502% | Wgt Acc: 67.731% | Dur: 9.78s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  5.  8. 21.]
 [ 5. 49. 12.  5.]
 [ 4. 20. 50.  8.]
 [ 6.  4.  5. 52.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.023 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.023 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.021 | Acc: 99.917% | Wgt Acc: 99.906%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-04 | Dur: 126.13s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 577.   0.   0.]
 [  0.   1. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.249 | Acc: 65.443% | Wgt Acc: 64.538% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  5.  5. 19.]
 [ 3. 41. 12.  4.]
 [ 7. 27. 52. 10.]
 [10.  5.  6. 53.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 125.53s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.079 | Acc: 70.031% | Wgt Acc: 69.905% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  4. 13.]
 [ 3. 50. 14.  1.]
 [ 4. 19. 50.  9.]
 [15.  4.  7. 63.]]

I - Local maximum validation set accuracy:  70.03

I - Validation set results: 
[14-1-2-1.42][50-3-1-1.89][124-2-2-1.05][127-0-0-5.74][443-2-2-5.27][567-0-0-2.77][573-1-1-2.75][615-0-3-3.14][695-1-2-1.86][722-3-3-3.75]
[826-0-0-3.56][878-0-3-2.29][1103-0-0-1.81][1212-3-3-1.64][1368-0-0-4.30][2181-2-2-1.85][2476-2-2-1.78][2721-2-2-4.80][2818-1-1-0.65][2886-2-1-2.68]
[3231-2-2-4.60][3333-2-2-2.63][3482-2-2-4.22][3536-3-3-2.27][3625-1-1-5.90][3909-0-0-1.13][4035-0-0-2.12][4140-0-0-4.82][4214-1-3-0.80][4346-1-0-0.78]
[4581-2-2-0.73][4708-3-2-1.52][4838-3-3-1.61][4845-1-1-1.11][4868-0-0-3.20][4939-0-1--0.56][4984-2-2-1.88][5078-1-2-0.75][5396-0-0-6.14][5479-1-1-5.78]
[5717-0-0-6.21][5843-1-1-1.99][5949-3-3-3.13][5987-2-2-0.97][6014-3-3-0.01][6033-3-3-2.29][6313-0-0-2.89][6421-3-3-2.45][6500-1-2-3.12][6583-3-3-3.29]
[6683-3-3-2.99][6825-2-1-5.71][6998-3-0-0.50][7049-3-3-0.90][7517-1-1-6.33][7521-1-1-0.36][7528-1-3-1.55][7949-1-2-3.40][8135-1-0-3.05][8185-3-0-2.68]
[8269-3-2--0.01][8273-3-3-5.41][8543-3-0-4.92][8666-1-1-2.85][8672-0-3-1.77][8903-1-2-2.28][9001-2-1-3.24][9036-2-2-6.86][9281-3-3-0.72][9300-2-2-6.59]
[9571-0-0-0.83][9617-1-1-3.68][9644-2-2-5.58][9705-2-2--0.88][9801-0-0-3.45][9803-3-3-0.48][9865-3-3-5.27][9896-2-2-3.38][10314-1-1-0.77][10337-3-3-5.55]
[10403-0-0-0.43][10653-2-1-1.41][10704-2-2-4.11][10719-1-1-3.33][10727-1-1-1.56][10836-0-0-10.79][10969-2-3-2.31][11042-0-2--0.47][11088-1-1-4.40][11322-0-0-6.92]
[11398-2-2-2.76][11499-0-0-3.40][11502-3-3-0.88][11512-3-3-1.00][11608-1-2-2.78][11610-0-0-4.50][11692-0-0-1.56][11905-0-3-1.17][11993-1-1-4.55][12002-2-0-2.71]
[12052-0-0-3.78][12201-0-3-3.77][12235-2-2-4.40][12320-1-0-2.79][12377-2-1-0.24][12398-2-3-1.13][12503-1-2-1.08][12617-0-1-0.69][12685-3-3-0.50][12738-2-1--0.42]
[12742-2-2-4.38][12823-0-3-3.74][13110-1-1-0.37][13240-3-3-5.18][13253-1-1-5.52][13273-0-0-8.37][13634-1-1-1.01][13763-2-2-0.38][13905-3-3-0.00][14060-2-1-5.35]
[14065-3-3-1.35][14147-3-3-4.42][14595-2-2-1.63][14687-2-2-5.62][14788-2-2-4.51][14869-1-1-4.55][14872-3-0-0.85][14877-1-1-5.46][14927-0-3-4.20][15066-0-0-4.51]
[15175-1-1-0.33][15178-2-2-1.78][15375-3-3-2.67][15389-3-3-4.31][15568-2-1-2.84][15675-3-3-3.36][15869-1-1-0.42][16207-3-0-3.02][16236-0-0-0.68][16302-3-3-2.11]
[16331-2-2-7.78][16381-0-0--0.68][16488-1-1-5.97][16495-0-0-5.07][16650-0-0-4.96][16719-1-2-1.67][16801-0-0-9.39][16828-0-0-4.66][17137-3-3-0.71][17245-1-1-0.88]
[17278-3-0-1.17][17282-0-2-0.33][17311-2-2-2.91][17336-2-1-1.04][17608-3-3-5.41][17627-0-0-0.20][17877-3-0-2.95][17924-1-2-0.65][17984-3-3-1.92][18211-0-3-1.03]
[18276-3-3-2.11][18287-1-1-2.47][18394-0-0-4.51][18428-0-0-0.83][18442-0-3-3.46][18478-3-3-3.10][18607-0-0-5.93][18616-0-0-2.97][18663-0-0-3.15][18718-0-0-6.06]
[18766-2-2-5.26][18824-2-2-3.03][18890-3-3-2.60][18930-3-0--0.30][18938-3-3-2.75][19817-1-2-2.27][19839-0-0-0.34][19930-3-3-4.11][19944-0-2-0.30][20036-2-2-5.23]
[20101-3-3-1.85][20474-1-1-3.54][20547-3-0-1.55][20929-2-2-3.28][21245-1-1-2.01][21257-3-2-0.86][21293-1-1-5.93][21316-1-1-4.54][21384-1-1-4.62][21448-1-1-3.13]
[21483-0-0-4.33][21487-2-2-4.04][21714-0-3-4.50][21943-3-2-0.38][21947-0-0-3.50][21948-0-0-8.17][21965-2-2-4.77][21998-1-1-4.97][22025-0-2-0.80][22228-3-3-6.10]
[22446-1-1-5.97][22494-3-3-4.31][22757-0-0-5.30][22811-3-3-3.19][22976-3-2-1.94][22985-3-3-3.75][23014-0-3-4.33][23112-1-1-3.22][23144-3-3-6.90][23168-2-3-0.19]
[23219-0-0-3.08][23363-3-3-4.60][23470-0-0-2.39][23486-2-2-2.45][23497-0-3-6.59][23516-0-0-4.24][23690-1-2-0.61][23921-2-1-1.40][23936-1-2-4.03][24040-3-2-0.99]
[24111-1-2-0.78][24182-0-0-4.73][24238-3-3-3.18][24290-2-0-2.21][24345-0-0-3.89][24364-1-3-0.51][24427-3-0-3.67][24477-2-2-4.86][24495-2-1-1.50][24893-2-2-1.16]
[25012-1-1-0.38][25121-2-2-2.32][25165-3-3-1.66][25183-0-0-6.23][25297-3-3-3.36][25398-0-0-2.48][25574-2-2-2.43][25644-1-2-6.16][25718-1-1-1.54][25774-2-3-0.16]
[26032-3-3-5.24][26051-3-3-5.72][26120-0-0-1.39][26321-1-1-4.15][26732-1-1-5.40][26784-3-3-6.82][26827-3-3-1.87][26833-0-3-4.78][26838-2-2-0.68][26860-1-2-1.21]
[26948-0-0-3.18][27049-3-0--0.00][27098-1-0-2.86][27526-0-0-2.44][27639-3-2--0.33][27698-3-3-5.30][27772-0-0-3.69][27890-1-1-6.52][28040-0-0-0.93][28503-2-2-4.77]
[28577-1-1-4.06][28959-0-0-5.46][29198-3-3-0.98][29777-0-0-7.15][29877-2-1-2.20][30035-1-1-3.11][30098-0-3-0.62][30326-1-1-5.68][30572-2-2-4.21][30716-0-1-3.04]
[30806-2-3-1.64][30906-1-1-4.01][31007-0-0-4.61][31181-3-3-2.09][31238-0-0-1.39][31347-0-0-6.09][31422-2-2-1.78][31429-3-3-2.08][31431-0-0-0.25][31432-1-1-4.89]
[31477-0-3-5.13][31524-1-0-0.75][31597-1-2-2.21][31619-1-2-0.77][31701-0-0-4.63][31755-0-0-3.62][31854-3-3-2.10][32074-1-1-0.69][32078-3-3-5.50][32111-1-1-3.28]
[32127-1-1-3.38][32140-3-3-5.23][32263-2-0-0.96][32365-0-0-4.99][32411-2-0-2.87][32429-3-0-1.70][32473-3-3-2.65][32574-3-3-3.30][32584-0-0-1.41][32622-0-0-0.45]
[32858-3-0-3.62][32969-3-3-4.63][33016-2-2-3.36][33031-1-3-2.81][33035-2-2-4.35][33133-2-2-4.13][33173-2-2-2.52][33175-3-2-3.56][33306-3-3-1.86][33309-2-3-1.82]
[33474-0-0-0.31][33478-2-3-1.04][33618-1-1-2.25][33712-0-0-1.74][33782-2-2-2.45][33914-3-3-3.03][34076-3-2-2.52][34112-2-2-0.80][34138-2-1-0.52][34239-1-2--0.23]
[34364-2-2-4.41][34617-1-1-1.08][34751-3-3-1.89][34783-2-2-0.82][35015-3-3-0.73][35018-1-1-2.04][35288-2-1--0.15]
---------------------------
I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.10s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.105 | Acc: 68.807% | Wgt Acc: 68.274% | Dur: 9.78s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  4.  6. 21.]
 [ 5. 48. 15.  1.]
 [ 2. 21. 49.  7.]
 [10.  5.  5. 57.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.050 | Acc: 98.875% | Wgt Acc: 98.873%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.250% | Wgt Acc: 99.254%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.375% | Wgt Acc: 99.380%
I - num batch: 160
I - Train -- Loss: 0.034 | Acc: 99.411% | Wgt Acc: 99.416% | LR: 1.250000e-04 | Dur: 125.82s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   1.   5.]
 [  1. 577.   1.   0.]
 [  2.   1. 731.   0.]
 [  3.   0.   1. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.981 | Acc: 68.807% | Wgt Acc: 68.750% | Dur: 9.83s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  4.  5. 21.]
 [ 3. 57. 17.  1.]
 [ 3. 14. 44.  9.]
 [13.  3.  9. 55.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.023 | Acc: 99.750% | Wgt Acc: 99.761%
	I - Batch: 150 | Loss: 0.023 | Acc: 99.750% | Wgt Acc: 99.756%
I - num batch: 160
I - Train -- Loss: 0.022 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-04 | Dur: 125.56s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   1.   0.   1.]
 [  1. 577.   1.   0.]
 [  1.   0. 733.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.039 | Acc: 67.584% | Wgt Acc: 67.663% | Dur: 9.80s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  4.  5.  9.]
 [ 1. 46. 13.  3.]
 [ 3. 22. 47.  8.]
 [22.  6. 10. 66.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 99.750% | Wgt Acc: 99.718%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.562% | Wgt Acc: 99.535%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.583% | Wgt Acc: 99.568%
I - num batch: 160
I - Train -- Loss: 0.034 | Acc: 99.607% | Wgt Acc: 99.593% | LR: 1.250000e-04 | Dur: 125.18s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   1.   0.   2.]
 [  1. 575.   0.   0.]
 [  1.   2. 733.   1.]
 [  1.   0.   1. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.120 | Acc: 68.502% | Wgt Acc: 67.120% | Dur: 9.78s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  3.  3. 15.]
 [ 3. 38.  7.  3.]
 [ 8. 33. 63. 14.]
 [ 8.  4.  2. 54.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 98.500% | Wgt Acc: 98.418%
	I - Batch: 100 | Loss: 0.052 | Acc: 98.750% | Wgt Acc: 98.732%
	I - Batch: 150 | Loss: 0.046 | Acc: 99.000% | Wgt Acc: 98.985%
I - num batch: 160
I - Train -- Loss: 0.044 | Acc: 99.058% | Wgt Acc: 99.045% | LR: 1.250000e-04 | Dur: 125.77s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   5.   5.]
 [  1. 576.   0.   1.]
 [  1.   1. 728.   4.]
 [  4.   1.   1. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.219 | Acc: 64.220% | Wgt Acc: 63.315% | Dur: 9.79s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  8.  6. 27.]
 [ 2. 39.  9.  2.]
 [ 4. 25. 49.  4.]
 [13.  6. 11. 53.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.761%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.756%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-04 | Dur: 125.60s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   1.   0.]
 [  0. 577.   0.   0.]
 [  2.   1. 733.   1.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.120 | Acc: 68.196% | Wgt Acc: 68.071% | Dur: 9.77s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  7.  4. 13.]
 [ 2. 45. 13.  4.]
 [ 2. 21. 48.  4.]
 [19.  5. 10. 65.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 124.79s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.134 | Acc: 68.502% | Wgt Acc: 68.139% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  6.  4. 11.]
 [ 5. 44. 12.  3.]
 [ 3. 23. 50.  9.]
 [13.  5.  9. 63.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 126.60s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.126 | Acc: 68.502% | Wgt Acc: 67.459% | Dur: 9.88s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  5.  5. 20.]
 [ 3. 44. 11.  3.]
 [ 4. 26. 54. 10.]
 [ 8.  3.  5. 53.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 126.35s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.097 | Acc: 67.278% | Wgt Acc: 67.255% | Dur: 9.84s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  6.  6. 15.]
 [ 2. 46. 15.  2.]
 [ 5. 20. 45.  5.]
 [16.  6.  9. 64.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.021 | Acc: 99.750% | Wgt Acc: 99.760%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.792% | Wgt Acc: 99.803%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 99.804% | Wgt Acc: 99.814% | LR: 1.250000e-04 | Dur: 126.22s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   0.]
 [  0. 577.   1.   0.]
 [  1.   1. 732.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.176 | Acc: 69.113% | Wgt Acc: 68.478% | Dur: 9.76s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  4.  6. 14.]
 [ 3. 43.  8.  0.]
 [ 6. 23. 53. 11.]
 [10.  8.  8. 61.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 127.25s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.128 | Acc: 69.419% | Wgt Acc: 69.226% | Dur: 9.74s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  5.  5. 16.]
 [ 3. 47. 12.  2.]
 [ 4. 18. 48.  4.]
 [13.  8. 10. 64.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.013 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 126.04s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.215 | Acc: 68.807% | Wgt Acc: 67.663% | Dur: 9.77s
I - Confusion Matrix: [row->prediction - col->label]
[[80. 10.  9. 29.]
 [ 0. 48. 11.  3.]
 [ 2. 18. 49.  6.]
 [ 6.  2.  6. 48.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 127.06s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.077 | Acc: 69.113% | Wgt Acc: 68.750% | Dur: 10.16s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  7.  7. 19.]
 [ 1. 46. 10.  2.]
 [ 3. 14. 45.  3.]
 [11. 11. 13. 62.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 127.87s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.130 | Acc: 66.055% | Wgt Acc: 65.965% | Dur: 9.53s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  9.  9. 17.]
 [ 3. 48. 14.  3.]
 [ 7. 11. 44.  7.]
 [13. 10.  8. 59.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.78s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.053 | Acc: 71.254% | Wgt Acc: 70.856% | Dur: 9.74s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  7.  7. 16.]
 [ 0. 49. 11.  1.]
 [ 2. 11. 45.  7.]
 [ 9. 11. 12. 62.]]

I - Local maximum validation set accuracy:  71.25

I - Validation set results: 
[14-1-2-0.43][50-3-3-0.12][124-2-2-1.15][127-0-0-7.34][443-2-2-3.97][567-0-0-3.40][573-1-0-0.38][615-0-3-2.56][695-1-2-2.17][722-3-0-3.90]
[826-0-0-5.51][878-0-0-5.77][1103-0-0-4.95][1212-3-3-2.03][1368-0-0-5.15][2181-2-3-0.03][2476-2-2-1.47][2721-2-2-3.09][2818-1-3-1.01][2886-2-1-2.60]
[3231-2-2-4.31][3333-2-2-0.82][3482-2-2-3.12][3536-3-3-2.91][3625-1-1-6.28][3909-0-0-3.50][4035-0-0-4.64][4140-0-0-3.52][4214-1-1-1.49][4346-1-0-1.52]
[4581-2-2-1.33][4708-3-2-1.55][4838-3-3-1.01][4845-1-1-1.19][4868-0-0-5.01][4939-0-0--0.26][4984-2-2-2.16][5078-1-3-0.79][5396-0-0-7.03][5479-1-1-4.76]
[5717-0-0-4.68][5843-1-1-0.15][5949-3-3-2.34][5987-2-2-1.93][6014-3-3-0.34][6033-3-3-1.46][6313-0-0-4.66][6421-3-3-4.26][6500-1-2-3.17][6583-3-3-3.98]
[6683-3-3-3.41][6825-2-1-2.65][6998-3-3-1.83][7049-3-3-1.98][7517-1-1-4.84][7521-1-1-1.42][7528-1-3-1.78][7949-1-2-3.49][8135-1-0-1.31][8185-3-0-3.34]
[8269-3-2-1.37][8273-3-3-3.67][8543-3-0-6.05][8666-1-1-3.14][8672-0-0-6.45][8903-1-1-2.09][9001-2-1-1.57][9036-2-2-4.72][9281-3-0-0.15][9300-2-2-7.07]
[9571-0-3-1.13][9617-1-3--0.32][9644-2-2-3.62][9705-2-1--0.35][9801-0-0-3.39][9803-3-0-1.34][9865-3-3-5.84][9896-2-2-3.97][10314-1-1-0.52][10337-3-3-4.94]
[10403-0-0-0.16][10653-2-2-1.64][10704-2-1-0.60][10719-1-1-3.74][10727-1-1-2.58][10836-0-0-10.81][10969-2-3-3.57][11042-0-0-1.42][11088-1-1-6.39][11322-0-0-5.97]
[11398-2-2-1.02][11499-0-0-3.85][11502-3-3-1.63][11512-3-3-3.69][11608-1-2-1.84][11610-0-0-3.42][11692-0-0-1.00][11905-0-0-0.86][11993-1-1-6.58][12002-2-0-1.40]
[12052-0-0-4.00][12201-0-0-4.40][12235-2-2-4.94][12320-1-0-3.35][12377-2-2-0.95][12398-2-3-2.42][12503-1-1-1.04][12617-0-3-0.07][12685-3-3-0.95][12738-2-0-3.85]
[12742-2-2-7.80][12823-0-0-4.07][13110-1-3-0.30][13240-3-0-3.71][13253-1-1-4.73][13273-0-0-8.78][13634-1-1-0.29][13763-2-3-3.80][13905-3-3-0.63][14060-2-1-3.24]
[14065-3-0-2.05][14147-3-3-4.23][14595-2-2-1.29][14687-2-2-3.91][14788-2-2-5.28][14869-1-1-5.98][14872-3-0-1.59][14877-1-1-4.44][14927-0-3-1.70][15066-0-0-4.91]
[15175-1-3-0.15][15178-2-3-0.45][15375-3-3-2.26][15389-3-3-3.42][15568-2-1-2.47][15675-3-3-3.97][15869-1-0-1.18][16207-3-0-1.51][16236-0-0-5.07][16302-3-3-0.52]
[16331-2-2-8.69][16381-0-0-0.71][16488-1-1-5.18][16495-0-0-5.10][16650-0-0-6.13][16719-1-2-1.58][16801-0-0-7.61][16828-0-0-3.58][17137-3-0-2.64][17245-1-1-0.27]
[17278-3-0-2.94][17282-0-0-0.07][17311-2-2-2.07][17336-2-1-2.96][17608-3-3-6.23][17627-0-0-0.38][17877-3-1-0.92][17924-1-3-1.83][17984-3-3-2.48][18211-0-3-1.31]
[18276-3-3-2.38][18287-1-1-2.28][18394-0-0-5.25][18428-0-0-5.71][18442-0-0-1.84][18478-3-3-3.03][18607-0-0-7.00][18616-0-0-2.91][18663-0-0-4.30][18718-0-0-6.89]
[18766-2-2-2.92][18824-2-2-3.08][18890-3-3-1.67][18930-3-2--0.37][18938-3-3-4.16][19817-1-2-3.37][19839-0-0--0.04][19930-3-3-4.40][19944-0-2-0.06][20036-2-2-5.82]
[20101-3-3-1.81][20474-1-1-4.36][20547-3-0-1.87][20929-2-2-3.56][21245-1-1-1.27][21257-3-3-1.32][21293-1-1-3.48][21316-1-1-5.77][21384-1-1-4.90][21448-1-1-3.65]
[21483-0-0-6.35][21487-2-2-4.89][21714-0-3-3.81][21943-3-2-0.08][21947-0-0-4.95][21948-0-0-7.60][21965-2-2-4.87][21998-1-1-6.50][22025-0-2-0.57][22228-3-3-7.01]
[22446-1-1-2.82][22494-3-3-3.54][22757-0-0-6.16][22811-3-3-2.28][22976-3-2-1.56][22985-3-3-4.60][23014-0-0-5.54][23112-1-1-3.47][23144-3-3-6.02][23168-2-3-1.31]
[23219-0-0-2.80][23363-3-3-1.58][23470-0-0-2.53][23486-2-3-0.95][23497-0-3-6.40][23516-0-0-3.55][23690-1-2--0.01][23921-2-2-2.35][23936-1-2-2.52][24040-3-2-0.30]
[24111-1-2-1.44][24182-0-0-5.96][24238-3-3-1.90][24290-2-0-4.04][24345-0-0-3.79][24364-1-3-1.96][24427-3-0-4.55][24477-2-2-1.27][24495-2-1-2.16][24893-2-2-0.83]
[25012-1-3-0.28][25121-2-1-1.42][25165-3-3-3.37][25183-0-0-4.05][25297-3-3-2.30][25398-0-0-4.21][25574-2-2-3.21][25644-1-1-2.19][25718-1-1-0.90][25774-2-0-0.19]
[26032-3-3-2.45][26051-3-3-4.55][26120-0-0-4.28][26321-1-1-3.15][26732-1-1-4.36][26784-3-3-7.05][26827-3-3-1.40][26833-0-0-3.26][26838-2-2-0.99][26860-1-1-0.21]
[26948-0-0-4.17][27049-3-0-0.17][27098-1-0-2.49][27526-0-0-4.22][27639-3-3-1.80][27698-3-3-3.44][27772-0-0-4.46][27890-1-1-4.97][28040-0-0-1.62][28503-2-2-5.29]
[28577-1-1-5.05][28959-0-0-6.95][29198-3-3-4.41][29777-0-0-9.56][29877-2-1-1.62][30035-1-1-1.72][30098-0-0-0.86][30326-1-1-6.54][30572-2-2-3.16][30716-0-0-0.80]
[30806-2-3-2.39][30906-1-1-4.44][31007-0-0-4.61][31181-3-3-0.26][31238-0-3-3.24][31347-0-0-7.95][31422-2-2-0.68][31429-3-3-1.36][31431-0-0-0.36][31432-1-1-4.00]
[31477-0-0-4.07][31524-1-1-0.86][31597-1-1-1.10][31619-1-0-1.50][31701-0-0-4.49][31755-0-0-4.46][31854-3-3-3.00][32074-1-3-1.25][32078-3-3-6.18][32111-1-1-1.77]
[32127-1-1-2.52][32140-3-3-3.37][32263-2-0-2.41][32365-0-0-4.85][32411-2-0-5.15][32429-3-3-2.30][32473-3-0-2.14][32574-3-0-1.68][32584-0-0-3.66][32622-0-0-0.88]
[32858-3-3-2.42][32969-3-3-4.71][33016-2-2-3.25][33031-1-3-3.29][33035-2-2-5.09][33133-2-2-3.82][33173-2-2-1.81][33175-3-2-2.84][33306-3-3-2.63][33309-2-3-2.11]
[33474-0-0-2.26][33478-2-0-0.06][33618-1-1-1.72][33712-0-3-1.50][33782-2-2-2.26][33914-3-3-3.95][34076-3-3-1.30][34112-2-3-1.06][34138-2-3-1.99][34239-1-1--0.49]
[34364-2-2-4.62][34617-1-2-2.95][34751-3-3-1.05][34783-2-2-1.06][35015-3-3-1.96][35018-1-1-2.29][35288-2-3-1.33]
---------------------------
I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 127.60s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.109 | Acc: 67.278% | Wgt Acc: 66.848% | Dur: 9.64s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  7.  5. 15.]
 [ 5. 50. 14.  6.]
 [ 4. 17. 49. 11.]
 [12.  4.  7. 54.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.375% | Wgt Acc: 99.377%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.438% | Wgt Acc: 99.451%
	I - Batch: 150 | Loss: 0.043 | Acc: 99.083% | Wgt Acc: 99.099%
I - num batch: 160
I - Train -- Loss: 0.043 | Acc: 99.058% | Wgt Acc: 99.080% | LR: 1.250000e-04 | Dur: 125.39s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   1.   6.]
 [  3. 577.   3.   0.]
 [  1.   1. 728.   1.]
 [  6.   0.   2. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.238 | Acc: 67.278% | Wgt Acc: 66.168% | Dur: 9.59s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  6.  6. 28.]
 [ 4. 46. 15.  6.]
 [ 3. 23. 49.  4.]
 [ 4.  3.  5. 48.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.049 | Acc: 99.250% | Wgt Acc: 99.214%
	I - Batch: 100 | Loss: 0.043 | Acc: 99.312% | Wgt Acc: 99.297%
	I - Batch: 150 | Loss: 0.041 | Acc: 99.417% | Wgt Acc: 99.418%
I - num batch: 160
I - Train -- Loss: 0.041 | Acc: 99.411% | Wgt Acc: 99.407% | LR: 1.250000e-04 | Dur: 126.04s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   1.   0.]
 [  1. 575.   2.   3.]
 [  1.   3. 729.   1.]
 [  1.   0.   2. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.214 | Acc: 66.667% | Wgt Acc: 65.693% | Dur: 9.79s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  7.  6. 21.]
 [ 3. 44. 12.  3.]
 [ 8. 24. 51. 11.]
 [ 5.  3.  6. 51.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.023 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.812% | Wgt Acc: 99.831%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.750% | Wgt Acc: 99.765%
I - num batch: 160
I - Train -- Loss: 0.025 | Acc: 99.764% | Wgt Acc: 99.779% | LR: 1.250000e-04 | Dur: 130.14s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   1.   0.]
 [  1. 577.   0.   0.]
 [  1.   1. 733.   0.]
 [  2.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.152 | Acc: 68.196% | Wgt Acc: 67.731% | Dur: 10.35s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  5.  3. 11.]
 [ 0. 38.  8.  2.]
 [ 5. 27. 54.  6.]
 [19.  8. 10. 67.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 135.36s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.148 | Acc: 65.749% | Wgt Acc: 64.674% | Dur: 10.32s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  7. 29.]
 [ 6. 54. 15.  8.]
 [ 4. 15. 50. 11.]
 [ 5.  3.  3. 38.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.018 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.018 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 126.57s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.068 | Acc: 70.642% | Wgt Acc: 69.905% | Dur: 9.83s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  5.  8. 23.]
 [ 1. 52. 12.  5.]
 [ 4. 19. 49.  5.]
 [ 6.  2.  6. 53.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.19s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.210 | Acc: 68.807% | Wgt Acc: 67.799% | Dur: 9.83s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  7.  7. 24.]
 [ 0. 44.  8.  1.]
 [ 5. 23. 54.  7.]
 [10.  4.  6. 54.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 127.16s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.112 | Acc: 67.278% | Wgt Acc: 66.101% | Dur: 12.46s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  5. 19.]
 [ 2. 44.  9.  2.]
 [ 7. 26. 55. 16.]
 [ 7.  3.  6. 49.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.014 | Acc: 99.938% | Wgt Acc: 99.943%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 137.89s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.142 | Acc: 68.196% | Wgt Acc: 67.595% | Dur: 10.42s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  5.  6. 16.]
 [ 2. 47.  9.  3.]
 [ 6. 20. 53. 11.]
 [13.  6.  7. 56.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.010 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 132.30s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.089 | Acc: 69.113% | Wgt Acc: 68.478% | Dur: 9.91s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  5.  3. 22.]
 [ 6. 51. 12.  2.]
 [ 6. 19. 54.  9.]
 [ 8.  3.  6. 53.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.018 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 137.68s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.164 | Acc: 69.725% | Wgt Acc: 69.226% | Dur: 9.89s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  6.  8. 19.]
 [ 1. 48. 11.  3.]
 [ 3. 12. 47.  5.]
 [10. 12.  9. 59.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.29s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.119 | Acc: 66.055% | Wgt Acc: 65.217% | Dur: 9.65s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  5. 10. 31.]
 [ 2. 47. 12.  1.]
 [ 6. 21. 46.  5.]
 [ 6.  5.  7. 49.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.013 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 126.62s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.044 | Acc: 70.031% | Wgt Acc: 69.158% | Dur: 10.10s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  7.  6. 18.]
 [ 2. 46. 11.  2.]
 [ 4. 21. 51. 10.]
 [ 6.  4.  7. 56.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.188% | Wgt Acc: 99.197%
	I - Batch: 150 | Loss: 0.047 | Acc: 98.958% | Wgt Acc: 98.996%
I - num batch: 160
I - Train -- Loss: 0.047 | Acc: 99.018% | Wgt Acc: 99.053% | LR: 1.250000e-04 | Dur: 135.44s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   2.   4.]
 [  2. 575.   5.   0.]
 [  2.   3. 727.   0.]
 [  7.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.196 | Acc: 64.220% | Wgt Acc: 62.636% | Dur: 9.94s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  4.  6. 22.]
 [ 1. 39.  8.  4.]
 [ 9. 29. 57. 17.]
 [ 7.  6.  4. 43.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.044 | Acc: 99.500% | Wgt Acc: 99.523%
	I - Batch: 100 | Loss: 0.051 | Acc: 98.875% | Wgt Acc: 98.844%
	I - Batch: 150 | Loss: 0.055 | Acc: 98.625% | Wgt Acc: 98.601%
I - num batch: 160
I - Train -- Loss: 0.056 | Acc: 98.665% | Wgt Acc: 98.638% | LR: 1.250000e-04 | Dur: 127.64s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   2.   1.   8.]
 [  3. 571.   3.   1.]
 [  3.   3. 729.   2.]
 [  5.   2.   1. 527.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.259 | Acc: 65.749% | Wgt Acc: 64.334% | Dur: 9.59s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  6.  6. 23.]
 [ 6. 44. 12.  7.]
 [ 3. 23. 54. 13.]
 [ 5.  5.  3. 43.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.056 | Acc: 99.000% | Wgt Acc: 98.983%
	I - Batch: 100 | Loss: 0.050 | Acc: 99.000% | Wgt Acc: 99.014%
	I - Batch: 150 | Loss: 0.043 | Acc: 99.208% | Wgt Acc: 99.230%
I - num batch: 160
I - Train -- Loss: 0.042 | Acc: 99.215% | Wgt Acc: 99.239% | LR: 1.250000e-04 | Dur: 131.14s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   2.   3.   3.]
 [  2. 575.   1.   0.]
 [  1.   1. 729.   0.]
 [  6.   0.   1. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.160 | Acc: 67.584% | Wgt Acc: 66.440% | Dur: 9.92s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  7.  4. 19.]
 [ 4. 43. 11.  2.]
 [ 3. 24. 57. 14.]
 [11.  4.  3. 51.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.625% | Wgt Acc: 99.643%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 99.647% | Wgt Acc: 99.664% | LR: 1.250000e-04 | Dur: 130.23s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   1.   1.   1.]
 [  2. 577.   1.   0.]
 [  2.   0. 732.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.995 | Acc: 69.419% | Wgt Acc: 69.293% | Dur: 10.09s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  4. 18.]
 [ 5. 51. 11.  1.]
 [ 3. 18. 50.  6.]
 [15.  4. 10. 61.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 128.63s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   1. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.114 | Acc: 66.667% | Wgt Acc: 66.712% | Dur: 9.97s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  3.  4. 14.]
 [ 4. 54. 16.  3.]
 [ 4. 15. 48. 13.]
 [20.  6.  7. 56.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 130.04s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.165 | Acc: 68.502% | Wgt Acc: 67.731% | Dur: 9.58s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  6.  7. 24.]
 [ 1. 49. 13.  5.]
 [ 1. 19. 48.  5.]
 [11.  4.  7. 52.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 99.625% | Wgt Acc: 99.661%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.812% | Wgt Acc: 99.831%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.875% | Wgt Acc: 99.887%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.882% | Wgt Acc: 99.894% | LR: 1.250000e-04 | Dur: 132.23s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 733.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.253 | Acc: 66.667% | Wgt Acc: 65.693% | Dur: 9.88s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  4.  5. 21.]
 [ 3. 52. 10.  4.]
 [ 9. 20. 57. 18.]
 [10.  2.  3. 43.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.67s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.203 | Acc: 68.807% | Wgt Acc: 67.731% | Dur: 9.95s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  8.  6. 22.]
 [ 1. 45.  9.  1.]
 [ 6. 19. 54. 11.]
 [ 7.  6.  6. 52.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.009 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 126.86s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.106 | Acc: 69.725% | Wgt Acc: 68.954% | Dur: 9.88s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  6.  8. 28.]
 [ 2. 55. 11.  3.]
 [ 2. 15. 49.  7.]
 [ 8.  2.  7. 48.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 132.27s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.085 | Acc: 68.196% | Wgt Acc: 67.255% | Dur: 9.75s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  7.  6. 29.]
 [ 3. 50. 13.  3.]
 [ 5. 17. 50.  6.]
 [ 5.  4.  6. 48.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.011 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.010 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 130.94s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.172 | Acc: 67.278% | Wgt Acc: 66.780% | Dur: 12.20s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  6.  5. 20.]
 [ 4. 48. 14.  3.]
 [ 5. 18. 49.  8.]
 [11.  6.  7. 55.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.750% | Wgt Acc: 99.746%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-04 | Dur: 131.66s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   2.]
 [  0. 577.   0.   0.]
 [  0.   1. 733.   0.]
 [  2.   0.   1. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.161 | Acc: 67.584% | Wgt Acc: 66.712% | Dur: 9.81s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  5.  3. 21.]
 [ 7. 51. 11.  8.]
 [ 8. 20. 55. 10.]
 [ 5.  2.  6. 47.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.023 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.292% | Wgt Acc: 99.286%
I - num batch: 160
I - Train -- Loss: 0.035 | Acc: 99.333% | Wgt Acc: 99.328% | LR: 1.250000e-04 | Dur: 126.73s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   1.   4.]
 [  1. 576.   2.   2.]
 [  0.   0. 731.   0.]
 [  5.   2.   0. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.122 | Acc: 68.502% | Wgt Acc: 67.255% | Dur: 10.05s
I - Confusion Matrix: [row->prediction - col->label]
[[80.  5.  7. 22.]
 [ 4. 53. 16. 10.]
 [ 1. 17. 50. 13.]
 [ 3.  3.  2. 41.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.028 | Acc: 99.750% | Wgt Acc: 99.733%
	I - Batch: 150 | Loss: 0.029 | Acc: 99.625% | Wgt Acc: 99.615%
I - num batch: 160
I - Train -- Loss: 0.029 | Acc: 99.607% | Wgt Acc: 99.602% | LR: 1.250000e-04 | Dur: 127.64s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   1.   0.   2.]
 [  0. 575.   0.   0.]
 [  3.   1. 734.   0.]
 [  2.   1.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.128 | Acc: 69.113% | Wgt Acc: 68.682% | Dur: 9.74s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 11.  8. 22.]
 [ 2. 52. 17.  4.]
 [ 6. 11. 43.  5.]
 [ 4.  4.  7. 55.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 125.46s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.379 | Acc: 62.997% | Wgt Acc: 61.549% | Dur: 9.74s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  6. 26.]
 [ 4. 48. 14.  8.]
 [ 6. 22. 52. 18.]
 [ 6.  3.  3. 34.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.186 | Acc: 93.875% | Wgt Acc: 93.778%
	I - Batch: 100 | Loss: 0.150 | Acc: 95.188% | Wgt Acc: 95.162%
	I - Batch: 150 | Loss: 0.125 | Acc: 96.083% | Wgt Acc: 96.064%
I - num batch: 160
I - Train -- Loss: 0.120 | Acc: 96.270% | Wgt Acc: 96.258% | LR: 1.250000e-04 | Dur: 126.06s
I - Confusion Matrix: [row->prediction - col->label]
[[663.   7.   4.  16.]
 [  5. 562.  12.   4.]
 [  8.   5. 716.   7.]
 [ 21.   4.   2. 511.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.155 | Acc: 64.832% | Wgt Acc: 65.217% | Dur: 9.80s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  5.  3. 15.]
 [ 3. 48. 15.  3.]
 [ 3. 20. 38.  4.]
 [20.  5. 19. 64.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.045 | Acc: 99.125% | Wgt Acc: 99.124%
	I - Batch: 100 | Loss: 0.042 | Acc: 99.250% | Wgt Acc: 99.211%
	I - Batch: 150 | Loss: 0.036 | Acc: 99.458% | Wgt Acc: 99.437%
I - num batch: 160
I - Train -- Loss: 0.036 | Acc: 99.450% | Wgt Acc: 99.425% | LR: 1.250000e-04 | Dur: 131.12s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   1.   0.   1.]
 [  0. 574.   3.   3.]
 [  0.   2. 729.   1.]
 [  0.   1.   2. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.135 | Acc: 66.361% | Wgt Acc: 65.625% | Dur: 9.78s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  4.  3. 12.]
 [ 3. 43.  9.  2.]
 [10. 29. 59. 17.]
 [15.  2.  4. 55.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.024 | Acc: 99.625% | Wgt Acc: 99.633%
	I - Batch: 100 | Loss: 0.020 | Acc: 99.812% | Wgt Acc: 99.816%
	I - Batch: 150 | Loss: 0.017 | Acc: 99.875% | Wgt Acc: 99.878%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.882% | Wgt Acc: 99.885% | LR: 1.250000e-04 | Dur: 125.14s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  0. 577.   0.   0.]
 [  1.   1. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.974 | Acc: 73.700% | Wgt Acc: 73.302% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  5.  7. 18.]
 [ 2. 57. 13.  2.]
 [ 4. 13. 50.  8.]
 [ 6.  3.  5. 58.]]

I - Local maximum validation set accuracy:  73.70

I - Validation set results: 
[14-1-2-0.32][50-3-1-1.40][124-2-2-0.46][127-0-0-6.40][443-2-2-3.97][567-0-0-3.42][573-1-1-4.01][615-0-0-2.71][695-1-2-3.42][722-3-0-4.44]
[826-0-0-4.91][878-0-0-6.02][1103-0-0-4.64][1212-3-3-2.09][1368-0-0-4.15][2181-2-2-0.55][2476-2-2-1.49][2721-2-2-4.44][2818-1-1-0.54][2886-2-1-2.58]
[3231-2-2-5.83][3333-2-2-1.63][3482-2-2-4.11][3536-3-3-3.75][3625-1-1-7.43][3909-0-0-1.40][4035-0-0-3.25][4140-0-0-3.01][4214-1-1-2.01][4346-1-0-2.39]
[4581-2-1-2.91][4708-3-3-0.78][4838-3-3-0.36][4845-1-1-0.99][4868-0-0-8.26][4939-0-1--0.05][4984-2-2-0.98][5078-1-2-0.75][5396-0-0-7.09][5479-1-1-7.11]
[5717-0-0-7.35][5843-1-1-3.29][5949-3-3-2.55][5987-2-2-1.53][6014-3-3-0.06][6033-3-3-0.73][6313-0-0-4.55][6421-3-3-2.87][6500-1-2-3.50][6583-3-3-3.01]
[6683-3-3-3.22][6825-2-1-3.31][6998-3-3--0.06][7049-3-3-2.25][7517-1-1-5.23][7521-1-1-1.52][7528-1-3-0.74][7949-1-2-3.44][8135-1-0-1.76][8185-3-0-3.51]
[8269-3-2--0.56][8273-3-3-4.44][8543-3-0-6.30][8666-1-1-3.81][8672-0-0-8.46][8903-1-2-2.39][9001-2-1-4.81][9036-2-2-6.98][9281-3-3-1.07][9300-2-2-6.50]
[9571-0-0-0.50][9617-1-1-6.81][9644-2-2-2.53][9705-2-0--0.21][9801-0-0-4.37][9803-3-0-1.46][9865-3-3-5.62][9896-2-2-2.84][10314-1-1-0.98][10337-3-3-5.48]
[10403-0-2-0.41][10653-2-1-0.67][10704-2-2-3.25][10719-1-1-4.08][10727-1-1-1.64][10836-0-0-12.75][10969-2-3-2.90][11042-0-0-1.68][11088-1-1-5.30][11322-0-0-6.45]
[11398-2-2-1.71][11499-0-0-3.93][11502-3-3-1.01][11512-3-3-2.35][11608-1-2-3.28][11610-0-0-7.43][11692-0-0-2.44][11905-0-0-4.79][11993-1-1-5.68][12002-2-2-0.66]
[12052-0-0-4.52][12201-0-0-3.95][12235-2-2-1.09][12320-1-0-3.39][12377-2-2-0.68][12398-2-3-1.37][12503-1-2-2.01][12617-0-2--0.14][12685-3-3-0.97][12738-2-0-0.51]
[12742-2-2-6.44][12823-0-3-3.13][13110-1-1-1.04][13240-3-3-4.78][13253-1-1-4.66][13273-0-0-11.25][13634-1-1-2.05][13763-2-2-1.40][13905-3-0-1.24][14060-2-1-6.82]
[14065-3-0-1.91][14147-3-3-3.41][14595-2-2-1.24][14687-2-2-3.04][14788-2-2-3.94][14869-1-1-4.78][14872-3-0-2.12][14877-1-1-7.22][14927-0-3-2.73][15066-0-0-6.42]
[15175-1-1-0.50][15178-2-2-0.26][15375-3-3-2.48][15389-3-3-4.50][15568-2-1-2.81][15675-3-3-4.50][15869-1-1-1.62][16207-3-0-1.82][16236-0-0-2.93][16302-3-3-3.03]
[16331-2-2-8.42][16381-0-0-0.69][16488-1-1-1.96][16495-0-0-5.29][16650-0-0-6.34][16719-1-1-1.10][16801-0-0-9.29][16828-0-0-4.89][17137-3-3-0.73][17245-1-1-0.85]
[17278-3-0-2.02][17282-0-0-0.84][17311-2-2-2.86][17336-2-1-0.14][17608-3-3-4.31][17627-0-0-4.77][17877-3-0-2.24][17924-1-3--0.16][17984-3-3-1.78][18211-0-3-1.10]
[18276-3-3-2.48][18287-1-1-2.48][18394-0-0-5.07][18428-0-0-2.02][18442-0-3-4.02][18478-3-3-2.29][18607-0-0-5.59][18616-0-0-4.09][18663-0-0-5.69][18718-0-0-7.42]
[18766-2-2-5.51][18824-2-2-2.16][18890-3-3-2.30][18930-3-2-0.57][18938-3-3-3.43][19817-1-2-2.90][19839-0-0-0.71][19930-3-3-2.44][19944-0-2--0.05][20036-2-2-3.24]
[20101-3-3-2.07][20474-1-1-5.27][20547-3-0-2.10][20929-2-2-8.06][21245-1-1-1.55][21257-3-3--0.48][21293-1-1-5.15][21316-1-1-5.56][21384-1-1-4.75][21448-1-1-3.99]
[21483-0-0-5.85][21487-2-2-3.84][21714-0-0-2.28][21943-3-0-1.16][21947-0-0-5.33][21948-0-0-9.13][21965-2-2-6.56][21998-1-1-4.33][22025-0-2-0.31][22228-3-3-6.38]
[22446-1-1-7.63][22494-3-3-4.00][22757-0-0-5.89][22811-3-3-4.27][22976-3-2-0.85][22985-3-3-2.65][23014-0-0-4.56][23112-1-1-4.33][23144-3-3-5.13][23168-2-0-1.37]
[23219-0-0-2.28][23363-3-3-4.70][23470-0-0-3.61][23486-2-2-1.79][23497-0-3-4.58][23516-0-0-5.56][23690-1-1-0.21][23921-2-2-2.05][23936-1-2-4.04][24040-3-2-0.41]
[24111-1-1-1.31][24182-0-0-6.47][24238-3-3-2.72][24290-2-0-4.24][24345-0-0-3.92][24364-1-2-1.61][24427-3-0-2.38][24477-2-2-3.12][24495-2-1-2.46][24893-2-2-1.99]
[25012-1-1-1.65][25121-2-1-2.10][25165-3-3-3.08][25183-0-0-5.29][25297-3-3-3.20][25398-0-0-4.53][25574-2-2-1.58][25644-1-2-4.59][25718-1-1-1.07][25774-2-3--0.05]
[26032-3-3-5.49][26051-3-3-4.49][26120-0-0-4.84][26321-1-1-4.73][26732-1-1-5.41][26784-3-3-7.23][26827-3-3-2.32][26833-0-3-2.90][26838-2-2-0.06][26860-1-1-2.25]
[26948-0-0-2.21][27049-3-0-1.21][27098-1-0-2.01][27526-0-0-3.82][27639-3-3--0.54][27698-3-3-4.23][27772-0-0-5.67][27890-1-1-7.21][28040-0-0-2.38][28503-2-2-3.95]
[28577-1-1-4.00][28959-0-0-6.51][29198-3-3-2.05][29777-0-0-9.13][29877-2-1-1.68][30035-1-1-4.70][30098-0-0-2.39][30326-1-1-6.51][30572-2-2-2.10][30716-0-1-2.11]
[30806-2-3-1.08][30906-1-1-5.16][31007-0-0-1.64][31181-3-2-0.07][31238-0-0-1.95][31347-0-0-8.74][31422-2-2-0.94][31429-3-3-2.49][31431-0-0-2.89][31432-1-1-4.56]
[31477-0-0-3.61][31524-1-2-1.04][31597-1-1-1.93][31619-1-0-1.66][31701-0-0-5.40][31755-0-0-5.82][31854-3-3-2.56][32074-1-1-0.31][32078-3-3-6.52][32111-1-1-2.02]
[32127-1-1-3.29][32140-3-3-3.87][32263-2-0-1.29][32365-0-0-6.46][32411-2-0-5.04][32429-3-0-0.85][32473-3-0-2.96][32574-3-0-3.83][32584-0-0-2.29][32622-0-0-1.01]
[32858-3-0-4.75][32969-3-3-3.81][33016-2-2-3.93][33031-1-3-3.91][33035-2-2-5.15][33133-2-2-4.98][33173-2-2-0.38][33175-3-2-2.50][33306-3-1-1.52][33309-2-3-2.12]
[33474-0-0-1.62][33478-2-0--0.14][33618-1-1-1.04][33712-0-0-1.59][33782-2-1-1.79][33914-3-3-4.31][34076-3-2-3.41][34112-2-2-1.31][34138-2-1--0.55][34239-1-1-0.50]
[34364-2-2-4.95][34617-1-1-1.56][34751-3-3-1.59][34783-2-2-1.53][35015-3-2-1.24][35018-1-1-3.56][35288-2-2-0.60]
---------------------------
I - Global maximum validation set accuracy:  73.70
I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.013 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 126.14s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.995 | Acc: 70.031% | Wgt Acc: 69.769% | Dur: 9.85s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  5.  7. 16.]
 [ 2. 50. 11.  1.]
 [ 5. 17. 48.  8.]
 [11.  6.  9. 61.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 127.85s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   1.   0.   0.]
 [  1. 577.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.095 | Acc: 67.890% | Wgt Acc: 67.391% | Dur: 9.95s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  6. 18.]
 [ 2. 48. 15.  2.]
 [ 6. 18. 49. 10.]
 [11.  6.  5. 56.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 127.18s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.065 | Acc: 69.113% | Wgt Acc: 68.614% | Dur: 10.05s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  7.  6. 22.]
 [ 2. 47. 14.  1.]
 [ 3. 18. 49.  4.]
 [12.  6.  6. 59.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 129.50s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.107 | Acc: 68.502% | Wgt Acc: 68.139% | Dur: 13.04s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  8.  6. 20.]
 [ 1. 53. 16.  4.]
 [ 4. 13. 46.  8.]
 [12.  4.  7. 54.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 131.30s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   1.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.372 | Acc: 64.832% | Wgt Acc: 63.927% | Dur: 10.08s
I - Confusion Matrix: [row->prediction - col->label]
[[56.  2.  3.  3.]
 [ 1. 35.  4.  2.]
 [13. 37. 63. 23.]
 [18.  4.  5. 58.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.120 | Acc: 96.000% | Wgt Acc: 96.063%
	I - Batch: 100 | Loss: 0.104 | Acc: 96.938% | Wgt Acc: 96.939%
	I - Batch: 150 | Loss: 0.090 | Acc: 97.417% | Wgt Acc: 97.418%
I - num batch: 160
I - Train -- Loss: 0.087 | Acc: 97.527% | Wgt Acc: 97.532% | LR: 1.250000e-04 | Dur: 143.77s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   1.   8.   5.]
 [  3. 568.   7.   5.]
 [  6.   8. 714.   7.]
 [  7.   1.   5. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.150 | Acc: 63.609% | Wgt Acc: 63.043% | Dur: 9.74s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  6. 24.]
 [ 4. 51. 22.  6.]
 [ 7. 18. 43. 11.]
 [ 8.  4.  4. 45.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.037 | Acc: 99.625% | Wgt Acc: 99.635%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.688% | Wgt Acc: 99.691%
	I - Batch: 150 | Loss: 0.027 | Acc: 99.750% | Wgt Acc: 99.756%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-04 | Dur: 128.94s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.]
 [  1. 577.   0.   0.]
 [  1.   0. 734.   1.]
 [  2.   1.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.140 | Acc: 68.502% | Wgt Acc: 68.003% | Dur: 12.42s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  4. 16.]
 [ 1. 45.  7.  3.]
 [ 4. 21. 54.  7.]
 [18.  7. 10. 60.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.018 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 133.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.076 | Acc: 68.502% | Wgt Acc: 67.935% | Dur: 9.77s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  6.  3. 21.]
 [ 2. 50. 13.  3.]
 [ 7. 18. 52.  8.]
 [11.  4.  7. 54.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.792% | Wgt Acc: 99.784%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-04 | Dur: 131.80s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.]
 [  1. 577.   1.   0.]
 [  0.   1. 733.   1.]
 [  1.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.220 | Acc: 63.303% | Wgt Acc: 63.383% | Dur: 9.94s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  6.  3. 15.]
 [ 5. 47. 15.  4.]
 [ 8. 20. 45.  9.]
 [18.  5. 12. 58.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.882% | Wgt Acc: 99.894% | LR: 1.250000e-04 | Dur: 126.11s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.154 | Acc: 66.972% | Wgt Acc: 67.120% | Dur: 9.84s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  3.  4. 14.]
 [ 3. 49. 12.  1.]
 [ 9. 21. 45.  8.]
 [14.  5. 14. 63.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 126.93s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.163 | Acc: 65.443% | Wgt Acc: 64.538% | Dur: 10.90s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  7.  8. 23.]
 [ 2. 46. 12.  3.]
 [ 6. 21. 48. 12.]
 [ 8.  4.  7. 48.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 128.20s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.189 | Acc: 65.443% | Wgt Acc: 64.606% | Dur: 9.90s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  2.  4. 18.]
 [ 7. 47. 11.  4.]
 [11. 28. 56. 16.]
 [ 7.  1.  4. 48.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 133.89s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.192 | Acc: 69.725% | Wgt Acc: 68.682% | Dur: 9.83s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  5.  6. 25.]
 [ 3. 53. 12.  3.]
 [ 6. 18. 55. 12.]
 [ 5.  2.  2. 46.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.007 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.008 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 128.76s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.161 | Acc: 70.336% | Wgt Acc: 69.497% | Dur: 9.86s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  7. 18.]
 [ 3. 47. 10.  2.]
 [ 3. 21. 54. 10.]
 [ 9.  4.  4. 56.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.009 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.008 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 127.06s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.084 | Acc: 71.560% | Wgt Acc: 71.060% | Dur: 9.76s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  6.  9. 21.]
 [ 3. 55. 14.  4.]
 [ 2. 15. 47.  6.]
 [ 6.  2.  5. 55.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.008 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.007 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 125.79s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.207 | Acc: 70.642% | Wgt Acc: 69.769% | Dur: 9.81s
I - Confusion Matrix: [row->prediction - col->label]
[[80.  7. 11. 31.]
 [ 1. 52. 10.  1.]
 [ 2. 11. 48.  3.]
 [ 5.  8.  6. 51.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.24s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.243 | Acc: 69.419% | Wgt Acc: 68.139% | Dur: 9.88s
I - Confusion Matrix: [row->prediction - col->label]
[[81.  8.  9. 27.]
 [ 0. 41.  7.  2.]
 [ 4. 23. 51.  3.]
 [ 3.  6.  8. 54.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 128.60s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.120 | Acc: 70.031% | Wgt Acc: 69.429% | Dur: 9.77s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  6. 23.]
 [ 2. 52. 10.  4.]
 [ 5. 14. 50.  5.]
 [ 8.  6.  9. 54.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.006 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.006 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-04 | Dur: 127.98s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   1. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.202 | Acc: 68.502% | Wgt Acc: 68.003% | Dur: 10.81s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  6.  4. 15.]
 [ 1. 42.  7.  2.]
 [ 6. 23. 49.  6.]
 [11.  7. 15. 63.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.500% | Wgt Acc: 99.524%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.312% | Wgt Acc: 99.340%
	I - Batch: 150 | Loss: 0.029 | Acc: 99.500% | Wgt Acc: 99.521%
I - num batch: 160
I - Train -- Loss: 0.030 | Acc: 99.529% | Wgt Acc: 99.549% | LR: 1.250000e-04 | Dur: 136.66s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   3.   1.]
 [  1. 578.   1.   1.]
 [  1.   0. 730.   1.]
 [  3.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.158 | Acc: 67.278% | Wgt Acc: 66.304% | Dur: 9.91s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  5. 25.]
 [ 1. 45. 12.  2.]
 [ 6. 19. 49.  8.]
 [ 6.  9.  9. 51.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.375% | Wgt Acc: 99.437%
	I - Batch: 100 | Loss: 0.023 | Acc: 99.562% | Wgt Acc: 99.605%
	I - Batch: 150 | Loss: 0.023 | Acc: 99.667% | Wgt Acc: 99.690%
I - num batch: 160
I - Train -- Loss: 0.023 | Acc: 99.686% | Wgt Acc: 99.708% | LR: 1.250000e-04 | Dur: 127.36s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   0.]
 [  0. 577.   1.   0.]
 [  3.   1. 732.   0.]
 [  2.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.170 | Acc: 64.526% | Wgt Acc: 63.519% | Dur: 9.87s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  4.  6. 18.]
 [ 2. 42. 12.  3.]
 [11. 28. 53. 16.]
 [ 8.  4.  4. 49.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 128.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.097 | Acc: 70.948% | Wgt Acc: 70.177% | Dur: 9.79s
I - Confusion Matrix: [row->prediction - col->label]
[[80.  7. 10. 24.]
 [ 1. 49.  7.  1.]
 [ 0. 13. 47.  5.]
 [ 7.  9. 11. 56.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.006 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.006 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 127.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 577.   0.   0.]
 [  0.   1. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.081 | Acc: 68.807% | Wgt Acc: 68.003% | Dur: 9.64s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  5.  7. 21.]
 [ 3. 47.  9.  2.]
 [ 6. 21. 54.  9.]
 [ 9.  5.  5. 54.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.009 | Acc: 99.812% | Wgt Acc: 99.831%
	I - Batch: 150 | Loss: 0.009 | Acc: 99.875% | Wgt Acc: 99.887%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 99.882% | Wgt Acc: 99.894% | LR: 1.250000e-04 | Dur: 130.90s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   0.]
 [  2. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.054 | Acc: 71.865% | Wgt Acc: 71.196% | Dur: 9.71s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  7.  8. 22.]
 [ 3. 53.  9.  2.]
 [ 2. 15. 52.  7.]
 [ 8.  3.  6. 55.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 128.62s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.251 | Acc: 66.972% | Wgt Acc: 65.965% | Dur: 9.84s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  4. 16.]
 [ 1. 39.  9.  1.]
 [ 6. 25. 55. 13.]
 [12.  8.  7. 56.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 128.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.116 | Acc: 69.419% | Wgt Acc: 68.614% | Dur: 9.71s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  5. 20.]
 [ 3. 47. 13.  3.]
 [ 2. 21. 50.  8.]
 [ 8.  5.  7. 55.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 131.47s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.135 | Acc: 69.725% | Wgt Acc: 69.633% | Dur: 9.75s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  6. 10. 16.]
 [ 2. 53. 14.  5.]
 [ 2. 14. 44.  5.]
 [13.  5.  7. 60.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 134.81s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.074 | Acc: 69.725% | Wgt Acc: 68.750% | Dur: 11.05s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  6. 20.]
 [ 3. 46.  9.  2.]
 [ 6. 25. 56. 10.]
 [ 7.  1.  4. 54.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.004 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 126.05s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.193 | Acc: 70.948% | Wgt Acc: 70.380% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  6.  8. 27.]
 [ 4. 56. 10.  3.]
 [ 2. 12. 48.  4.]
 [ 6.  4.  9. 52.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 0.003 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.003 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.003 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.003 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 130.92s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.064 | Acc: 70.642% | Wgt Acc: 70.109% | Dur: 9.77s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  6.  4. 17.]
 [ 2. 47. 11.  2.]
 [ 5. 22. 55.  6.]
 [13.  3.  5. 61.]]

I - Epoch: 150
I - Training: 
