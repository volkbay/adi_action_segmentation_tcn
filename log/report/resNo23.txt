Fri Sep 30 18:49:28 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.21, 0.26, 0.24, 0.21, 0.08], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 5, 'doubleClasses': [1, 2], 'loadData2memory': True, 'multiplyData': False, 'tossFirstLastFrames': True}, 'dataPath': '/data/processed/Kinetics/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 6, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 23, 'validationAccThr': 60, 'weightDecay': 0.001}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Number of frames greater than dataset description, tossed data with #frames =  964
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  5815
I - Label distribution: [ 692.  668.  974.  718. 2763.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Tossed a data with insufficient frame number.
I - Test set length:  1392
I - Label distribution: [199. 268. 290. 204. 431.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([2851, 4521, 3646, 3912, 4908, 2141, 4436, 1865, 4073, 2088, 5147, 1398,
         883,  862, 3012, 1637])
I - Initializing model TCNv6
I - Number of Model Parameters: 646479
I - Model output shape:  torch.Size([3, 16, 5, 16])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv6                                    [3, 16, 5, 16]            --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─ReLU: 2-62                        [16, 64, 32, 32]          --
│    └─Empty: 2-63                       [16, 64, 32, 32]          --
│    └─Clamp: 2-64                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
│    └─OutputScale: 2-67                 --                        --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64, 64, 3, 3]            --
│    └─Empty: 2-70                       [64]                      --
│    └─Empty: 2-71                       [64]                      --
│    └─BatchNorm2d: 2-72                 [16, 64, 32, 32]          --
│    └─Scaler: 2-73                      [16, 64, 32, 32]          --
│    └─ReLU: 2-74                        [16, 64, 32, 32]          --
│    └─Empty: 2-75                       [16, 64, 32, 32]          --
│    └─Clamp: 2-76                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-77                   [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─Empty: 2-79                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-80          --                        --
│    └─One: 2-81                         [1]                       --
│    └─OutputScale: 2-82                 --                        --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64, 64, 3, 3]            --
│    └─Empty: 2-85                       [64]                      --
│    └─Empty: 2-86                       [64]                      --
│    └─BatchNorm2d: 2-87                 [16, 64, 16, 16]          --
│    └─Scaler: 2-88                      [16, 64, 16, 16]          --
│    └─ReLU: 2-89                        [16, 64, 16, 16]          --
│    └─Empty: 2-90                       [16, 64, 16, 16]          --
│    └─Clamp: 2-91                       [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-93          --                        --
│    └─One: 2-94                         [1]                       --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [64, 64, 3, 3]            --
│    └─Empty: 2-97                       [64, 64, 3, 3]            --
│    └─Empty: 2-98                       [64]                      --
│    └─Empty: 2-99                       [64]                      --
│    └─BatchNorm2d: 2-100                [16, 64, 16, 16]          --
│    └─Scaler: 2-101                     [16, 64, 16, 16]          --
│    └─ReLU: 2-102                       [16, 64, 16, 16]          --
│    └─Empty: 2-103                      [16, 64, 16, 16]          --
│    └─Clamp: 2-104                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-105                  [16, 64, 8, 8]            --
│    └─Empty: 2-106                      [16, 64, 8, 8]            --
│    └─Empty: 2-107                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-108         --                        --
│    └─One: 2-109                        [1]                       --
│    └─OutputScale: 2-110                --                        --
│    └─Empty: 2-111                      [64, 64, 3, 3]            --
│    └─Empty: 2-112                      [64, 64, 3, 3]            --
│    └─Empty: 2-113                      [64]                      --
│    └─Empty: 2-114                      [64]                      --
│    └─BatchNorm2d: 2-115                [16, 64, 8, 8]            --
│    └─Scaler: 2-116                     [16, 64, 8, 8]            --
│    └─ReLU: 2-117                       [16, 64, 8, 8]            --
│    └─Empty: 2-118                      [16, 64, 8, 8]            --
│    └─Clamp: 2-119                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-120         --                        --
│    └─One: 2-121                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-123                --                        --
│    └─Empty: 2-124                      [64, 64, 1, 1]            --
│    └─Empty: 2-125                      [64, 64, 1, 1]            --
│    └─Empty: 2-126                      [64]                      --
│    └─Empty: 2-127                      [64]                      --
│    └─BatchNorm2d: 2-128                [16, 64, 8, 8]            --
│    └─Scaler: 2-129                     [16, 64, 8, 8]            --
│    └─ReLU: 2-130                       [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Clamp: 2-132                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-133                  [16, 64, 8, 8]            --
│    └─Empty: 2-134                      [16, 64, 8, 8]            --
│    └─Empty: 2-135                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-136         --                        --
│    └─One: 2-137                        [1]                       --
│    └─OutputScale: 2-138                --                        --
│    └─Empty: 2-139                      [64, 64, 3, 3]            --
│    └─Empty: 2-140                      [64, 64, 3, 3]            --
│    └─Empty: 2-141                      [64]                      --
│    └─Empty: 2-142                      [64]                      --
│    └─BatchNorm2d: 2-143                [16, 64, 8, 8]            --
│    └─Scaler: 2-144                     [16, 64, 8, 8]            --
│    └─ReLU: 2-145                       [16, 64, 8, 8]            --
│    └─Empty: 2-146                      [16, 64, 8, 8]            --
│    └─Clamp: 2-147                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-148                  [16, 64, 4, 4]            --
│    └─Empty: 2-149                      [16, 64, 4, 4]            --
│    └─Empty: 2-150                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-151         --                        --
│    └─One: 2-152                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-154                --                        --
│    └─Empty: 2-155                      [64, 64, 3, 3]            --
│    └─Empty: 2-156                      [64, 64, 3, 3]            --
│    └─Empty: 2-157                      [64]                      --
│    └─Empty: 2-158                      [64]                      --
│    └─BatchNorm2d: 2-159                [16, 64, 4, 4]            --
│    └─Scaler: 2-160                     [16, 64, 4, 4]            --
│    └─ReLU: 2-161                       [16, 64, 4, 4]            --
│    └─Empty: 2-162                      [16, 64, 4, 4]            --
│    └─Clamp: 2-163                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-164         --                        --
│    └─One: 2-165                        [1]                       --
│    └─OutputScale: 2-166                --                        --
│    └─Empty: 2-167                      [64, 64, 1, 1]            --
│    └─Empty: 2-168                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-170                      [64]                      --
│    └─Empty: 2-171                      [64]                      --
│    └─BatchNorm2d: 2-172                [16, 64, 4, 4]            --
│    └─Scaler: 2-173                     [16, 64, 4, 4]            --
│    └─ReLU: 2-174                       [16, 64, 4, 4]            --
│    └─Empty: 2-175                      [16, 64, 4, 4]            --
│    └─Clamp: 2-176                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-177                  [16, 64, 4, 4]            --
│    └─Empty: 2-178                      [16, 64, 4, 4]            --
│    └─Empty: 2-179                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-180         --                        --
│    └─One: 2-181                        [1]                       --
│    └─OutputScale: 2-182                --                        --
│    └─Empty: 2-183                      [64, 64, 3, 3]            --
│    └─Empty: 2-184                      [64, 64, 3, 3]            --
│    └─Empty: 2-185                      [64]                      --
│    └─Empty: 2-186                      [64]                      --
│    └─BatchNorm2d: 2-187                [16, 64, 4, 4]            --
│    └─Scaler: 2-188                     [16, 64, 4, 4]            --
│    └─ReLU: 2-189                       [16, 64, 4, 4]            --
│    └─Empty: 2-190                      [16, 64, 4, 4]            --
│    └─Clamp: 2-191                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-192                  [16, 64, 2, 2]            --
│    └─Empty: 2-193                      [16, 64, 2, 2]            --
│    └─Empty: 2-194                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-195         --                        --
│    └─One: 2-196                        [1]                       --
│    └─OutputScale: 2-197                --                        --
│    └─Empty: 2-198                      [64, 64, 1, 1]            --
│    └─Empty: 2-199                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-201                      [64]                      --
│    └─Empty: 2-202                      [64]                      --
│    └─BatchNorm2d: 2-203                [16, 64, 2, 2]            --
│    └─Scaler: 2-204                     [16, 64, 2, 2]            --
│    └─ReLU: 2-205                       [16, 64, 2, 2]            --
│    └─Empty: 2-206                      [16, 64, 2, 2]            --
│    └─Clamp: 2-207                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-208         --                        --
│    └─One: 2-209                        [1]                       --
│    └─OutputScale: 2-210                --                        --
│    └─Empty: 2-211                      [64, 64, 1, 1]            --
│    └─Empty: 2-212                      [64, 64, 1, 1]            --
│    └─Empty: 2-213                      [64]                      --
│    └─Empty: 2-214                      [64]                      --
│    └─BatchNorm2d: 2-215                [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-217                     [16, 64, 2, 2]            --
│    └─ReLU: 2-218                       [16, 64, 2, 2]            --
│    └─Empty: 2-219                      [16, 64, 2, 2]            --
│    └─Clamp: 2-220                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-221                  [16, 64, 2, 2]            --
│    └─Empty: 2-222                      [16, 64, 2, 2]            --
│    └─Empty: 2-223                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-224         --                        --
│    └─One: 2-225                        [1]                       --
│    └─OutputScale: 2-226                --                        --
│    └─Empty: 2-227                      [64, 64, 3, 3]            --
│    └─Empty: 2-228                      [64, 64, 3, 3]            --
│    └─Empty: 2-229                      [64]                      --
│    └─Empty: 2-230                      [64]                      --
│    └─BatchNorm2d: 2-231                [16, 64, 2, 2]            --
│    └─Scaler: 2-232                     [16, 64, 2, 2]            --
│    └─ReLU: 2-233                       [16, 64, 2, 2]            --
│    └─Empty: 2-234                      [16, 64, 2, 2]            --
│    └─Clamp: 2-235                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-236         --                        --
│    └─One: 2-237                        [1]                       --
│    └─OutputScale: 2-238                --                        --
│    └─Empty: 2-239                      [64, 48, 1, 1]            --
│    └─Empty: 2-240                      [64, 48, 1, 1]            --
│    └─Empty: 2-241                      [64]                      --
│    └─Empty: 2-242                      [64]                      --
│    └─BatchNorm2d: 2-243                [16, 64, 64, 64]          --
│    └─Scaler: 2-244                     [16, 64, 64, 64]          --
│    └─ReLU: 2-245                       [16, 64, 64, 64]          --
│    └─Empty: 2-246                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-248                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-249         --                        --
│    └─One: 2-250                        [1]                       --
│    └─OutputScale: 2-251                --                        --
│    └─Empty: 2-252                      [64, 64, 3, 3]            --
│    └─Empty: 2-253                      [64, 64, 3, 3]            --
│    └─Empty: 2-254                      [64]                      --
│    └─Empty: 2-255                      [64]                      --
│    └─BatchNorm2d: 2-256                [16, 64, 64, 64]          --
│    └─Scaler: 2-257                     [16, 64, 64, 64]          --
│    └─ReLU: 2-258                       [16, 64, 64, 64]          --
│    └─Empty: 2-259                      [16, 64, 64, 64]          --
│    └─Clamp: 2-260                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-261         --                        --
│    └─One: 2-262                        [1]                       --
│    └─OutputScale: 2-263                --                        --
│    └─Empty: 2-264                      [64, 64, 1, 1]            --
│    └─Empty: 2-265                      [64, 64, 1, 1]            --
│    └─Empty: 2-266                      [64]                      --
│    └─Empty: 2-267                      [64]                      --
│    └─BatchNorm2d: 2-268                [16, 64, 64, 64]          --
│    └─Scaler: 2-269                     [16, 64, 64, 64]          --
│    └─ReLU: 2-270                       [16, 64, 64, 64]          --
│    └─Empty: 2-271                      [16, 64, 64, 64]          --
│    └─Clamp: 2-272                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-273         --                        --
│    └─One: 2-274                        [1]                       --
│    └─OutputScale: 2-275                --                        --
│    └─Empty: 2-276                      [64, 64, 3, 3]            --
│    └─Empty: 2-277                      [64, 64, 3, 3]            --
│    └─Empty: 2-278                      [64]                      --
│    └─Empty: 2-279                      [64]                      --
│    └─BatchNorm2d: 2-280                [16, 64, 64, 64]          --
│    └─Scaler: 2-281                     [16, 64, 64, 64]          --
│    └─ReLU: 2-282                       [16, 64, 64, 64]          --
│    └─Empty: 2-283                      [16, 64, 64, 64]          --
│    └─Clamp: 2-284                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-285                  [16, 64, 32, 32]          --
│    └─Empty: 2-286                      [16, 64, 32, 32]          --
│    └─Empty: 2-287                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-288         --                        --
│    └─One: 2-289                        [1]                       --
│    └─OutputScale: 2-290                --                        --
│    └─Empty: 2-291                      [64, 64, 3, 3]            --
│    └─Empty: 2-292                      [64, 64, 3, 3]            --
│    └─Empty: 2-293                      [64]                      --
│    └─Empty: 2-294                      [64]                      --
│    └─BatchNorm2d: 2-295                [16, 64, 32, 32]          --
│    └─Scaler: 2-296                     [16, 64, 32, 32]          --
│    └─ReLU: 2-297                       [16, 64, 32, 32]          --
│    └─Empty: 2-298                      [16, 64, 32, 32]          --
│    └─Clamp: 2-299                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-300         --                        --
│    └─One: 2-301                        [1]                       --
│    └─OutputScale: 2-302                --                        --
│    └─Empty: 2-303                      [64, 64, 3, 3]            --
│    └─Empty: 2-304                      [64, 64, 3, 3]            --
│    └─Empty: 2-305                      [64]                      --
│    └─Empty: 2-306                      [64]                      --
│    └─BatchNorm2d: 2-307                [16, 64, 32, 32]          --
│    └─Scaler: 2-308                     [16, 64, 32, 32]          --
│    └─ReLU: 2-309                       [16, 64, 32, 32]          --
│    └─Empty: 2-310                      [16, 64, 32, 32]          --
│    └─Clamp: 2-311                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-312                  [16, 64, 16, 16]          --
│    └─Empty: 2-313                      [16, 64, 16, 16]          --
│    └─Empty: 2-314                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-315         --                        --
│    └─One: 2-316                        [1]                       --
│    └─OutputScale: 2-317                --                        --
│    └─Empty: 2-318                      [64, 64, 3, 3]            --
│    └─Empty: 2-319                      [64, 64, 3, 3]            --
│    └─Empty: 2-320                      [64]                      --
│    └─Empty: 2-321                      [64]                      --
│    └─BatchNorm2d: 2-322                [16, 64, 16, 16]          --
│    └─Scaler: 2-323                     [16, 64, 16, 16]          --
│    └─ReLU: 2-324                       [16, 64, 16, 16]          --
│    └─Empty: 2-325                      [16, 64, 16, 16]          --
│    └─Clamp: 2-326                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-327         --                        --
│    └─One: 2-328                        [1]                       --
│    └─OutputScale: 2-329                --                        --
│    └─Empty: 2-330                      [64, 64, 3, 3]            --
│    └─Empty: 2-331                      [64, 64, 3, 3]            --
│    └─Empty: 2-332                      [64]                      --
│    └─Empty: 2-333                      [64]                      --
│    └─BatchNorm2d: 2-334                [16, 64, 16, 16]          --
│    └─Scaler: 2-335                     [16, 64, 16, 16]          --
│    └─ReLU: 2-336                       [16, 64, 16, 16]          --
│    └─Empty: 2-337                      [16, 64, 16, 16]          --
│    └─Clamp: 2-338                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-339                  [16, 64, 8, 8]            --
│    └─Empty: 2-340                      [16, 64, 8, 8]            --
│    └─Empty: 2-341                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-342         --                        --
│    └─One: 2-343                        [1]                       --
│    └─OutputScale: 2-344                --                        --
│    └─Empty: 2-345                      [64, 64, 3, 3]            --
│    └─Empty: 2-346                      [64, 64, 3, 3]            --
│    └─Empty: 2-347                      [64]                      --
│    └─Empty: 2-348                      [64]                      --
│    └─BatchNorm2d: 2-349                [16, 64, 8, 8]            --
│    └─Scaler: 2-350                     [16, 64, 8, 8]            --
│    └─ReLU: 2-351                       [16, 64, 8, 8]            --
│    └─Empty: 2-352                      [16, 64, 8, 8]            --
│    └─Clamp: 2-353                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-354         --                        --
│    └─One: 2-355                        [1]                       --
│    └─OutputScale: 2-356                --                        --
│    └─Empty: 2-357                      [64, 64, 1, 1]            --
│    └─Empty: 2-358                      [64, 64, 1, 1]            --
│    └─Empty: 2-359                      [64]                      --
│    └─Empty: 2-360                      [64]                      --
│    └─BatchNorm2d: 2-361                [16, 64, 8, 8]            --
│    └─Scaler: 2-362                     [16, 64, 8, 8]            --
│    └─ReLU: 2-363                       [16, 64, 8, 8]            --
│    └─Empty: 2-364                      [16, 64, 8, 8]            --
│    └─Clamp: 2-365                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-366                  [16, 64, 8, 8]            --
│    └─Empty: 2-367                      [16, 64, 8, 8]            --
│    └─Empty: 2-368                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-369         --                        --
│    └─One: 2-370                        [1]                       --
│    └─OutputScale: 2-371                --                        --
│    └─Empty: 2-372                      [64, 64, 3, 3]            --
│    └─Empty: 2-373                      [64, 64, 3, 3]            --
│    └─Empty: 2-374                      [64]                      --
│    └─Empty: 2-375                      [64]                      --
│    └─BatchNorm2d: 2-376                [16, 64, 8, 8]            --
│    └─Scaler: 2-377                     [16, 64, 8, 8]            --
│    └─ReLU: 2-378                       [16, 64, 8, 8]            --
│    └─Empty: 2-379                      [16, 64, 8, 8]            --
│    └─Clamp: 2-380                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-381                  [16, 64, 4, 4]            --
│    └─Empty: 2-382                      [16, 64, 4, 4]            --
│    └─Empty: 2-383                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-384         --                        --
│    └─One: 2-385                        [1]                       --
│    └─OutputScale: 2-386                --                        --
│    └─Empty: 2-387                      [64, 64, 3, 3]            --
│    └─Empty: 2-388                      [64, 64, 3, 3]            --
│    └─Empty: 2-389                      [64]                      --
│    └─Empty: 2-390                      [64]                      --
│    └─BatchNorm2d: 2-391                [16, 64, 4, 4]            --
│    └─Scaler: 2-392                     [16, 64, 4, 4]            --
│    └─ReLU: 2-393                       [16, 64, 4, 4]            --
│    └─Empty: 2-394                      [16, 64, 4, 4]            --
│    └─Clamp: 2-395                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-396         --                        --
│    └─One: 2-397                        [1]                       --
│    └─OutputScale: 2-398                --                        --
│    └─Empty: 2-399                      [64, 64, 1, 1]            --
│    └─Empty: 2-400                      [64, 64, 1, 1]            --
│    └─Empty: 2-401                      [64]                      --
│    └─Empty: 2-402                      [64]                      --
│    └─BatchNorm2d: 2-403                [16, 64, 4, 4]            --
│    └─Scaler: 2-404                     [16, 64, 4, 4]            --
│    └─ReLU: 2-405                       [16, 64, 4, 4]            --
│    └─Empty: 2-406                      [16, 64, 4, 4]            --
│    └─Clamp: 2-407                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-408                  [16, 64, 4, 4]            --
│    └─Empty: 2-409                      [16, 64, 4, 4]            --
│    └─Empty: 2-410                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-411         --                        --
│    └─One: 2-412                        [1]                       --
│    └─OutputScale: 2-413                --                        --
│    └─Empty: 2-414                      [64, 64, 3, 3]            --
│    └─Empty: 2-415                      [64, 64, 3, 3]            --
│    └─Empty: 2-416                      [64]                      --
│    └─Empty: 2-417                      [64]                      --
│    └─BatchNorm2d: 2-418                [16, 64, 4, 4]            --
│    └─Scaler: 2-419                     [16, 64, 4, 4]            --
│    └─ReLU: 2-420                       [16, 64, 4, 4]            --
│    └─Empty: 2-421                      [16, 64, 4, 4]            --
│    └─Clamp: 2-422                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-423                  [16, 64, 2, 2]            --
│    └─Empty: 2-424                      [16, 64, 2, 2]            --
│    └─Empty: 2-425                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-426         --                        --
│    └─One: 2-427                        [1]                       --
│    └─OutputScale: 2-428                --                        --
│    └─Empty: 2-429                      [64, 64, 1, 1]            --
│    └─Empty: 2-430                      [64, 64, 1, 1]            --
│    └─Empty: 2-431                      [64]                      --
│    └─Empty: 2-432                      [64]                      --
│    └─BatchNorm2d: 2-433                [16, 64, 2, 2]            --
│    └─Scaler: 2-434                     [16, 64, 2, 2]            --
│    └─ReLU: 2-435                       [16, 64, 2, 2]            --
│    └─Empty: 2-436                      [16, 64, 2, 2]            --
│    └─Clamp: 2-437                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-438         --                        --
│    └─One: 2-439                        [1]                       --
│    └─OutputScale: 2-440                --                        --
│    └─Empty: 2-441                      [64, 64, 1, 1]            --
│    └─Empty: 2-442                      [64, 64, 1, 1]            --
│    └─Empty: 2-443                      [64]                      --
│    └─Empty: 2-444                      [64]                      --
│    └─BatchNorm2d: 2-445                [16, 64, 2, 2]            --
│    └─Scaler: 2-446                     [16, 64, 2, 2]            --
│    └─ReLU: 2-447                       [16, 64, 2, 2]            --
│    └─Empty: 2-448                      [16, 64, 2, 2]            --
│    └─Clamp: 2-449                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-450                  [16, 64, 2, 2]            --
│    └─Empty: 2-451                      [16, 64, 2, 2]            --
│    └─Empty: 2-452                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-453         --                        --
│    └─One: 2-454                        [1]                       --
│    └─OutputScale: 2-455                --                        --
│    └─Empty: 2-456                      [64, 64, 3, 3]            --
│    └─Empty: 2-457                      [64, 64, 3, 3]            --
│    └─Empty: 2-458                      [64]                      --
│    └─Empty: 2-459                      [64]                      --
│    └─BatchNorm2d: 2-460                [16, 64, 2, 2]            --
│    └─Scaler: 2-461                     [16, 64, 2, 2]            --
│    └─ReLU: 2-462                       [16, 64, 2, 2]            --
│    └─Empty: 2-463                      [16, 64, 2, 2]            --
│    └─Clamp: 2-464                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-465         --                        --
│    └─One: 2-466                        [1]                       --
│    └─OutputScale: 2-467                --                        --
│    └─Empty: 2-468                      [64, 48, 1, 1]            --
│    └─Empty: 2-469                      [64, 48, 1, 1]            --
│    └─Empty: 2-470                      [64]                      --
│    └─Empty: 2-471                      [64]                      --
│    └─BatchNorm2d: 2-472                [16, 64, 64, 64]          --
│    └─Scaler: 2-473                     [16, 64, 64, 64]          --
│    └─ReLU: 2-474                       [16, 64, 64, 64]          --
│    └─Empty: 2-475                      [16, 64, 64, 64]          --
│    └─Clamp: 2-476                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-477         --                        --
│    └─One: 2-478                        [1]                       --
│    └─OutputScale: 2-479                --                        --
│    └─Empty: 2-480                      [64, 64, 3, 3]            --
│    └─Empty: 2-481                      [64, 64, 3, 3]            --
│    └─Empty: 2-482                      [64]                      --
│    └─Empty: 2-483                      [64]                      --
│    └─BatchNorm2d: 2-484                [16, 64, 64, 64]          --
│    └─Scaler: 2-485                     [16, 64, 64, 64]          --
│    └─ReLU: 2-486                       [16, 64, 64, 64]          --
│    └─Empty: 2-487                      [16, 64, 64, 64]          --
│    └─Clamp: 2-488                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-489         --                        --
│    └─One: 2-490                        [1]                       --
│    └─OutputScale: 2-491                --                        --
│    └─Empty: 2-492                      [64, 64, 1, 1]            --
│    └─Empty: 2-493                      [64, 64, 1, 1]            --
│    └─Empty: 2-494                      [64]                      --
│    └─Empty: 2-495                      [64]                      --
│    └─BatchNorm2d: 2-496                [16, 64, 64, 64]          --
│    └─Scaler: 2-497                     [16, 64, 64, 64]          --
│    └─ReLU: 2-498                       [16, 64, 64, 64]          --
│    └─Empty: 2-499                      [16, 64, 64, 64]          --
│    └─Clamp: 2-500                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-501         --                        --
│    └─One: 2-502                        [1]                       --
│    └─OutputScale: 2-503                --                        --
│    └─Empty: 2-504                      [64, 64, 3, 3]            --
│    └─Empty: 2-505                      [64, 64, 3, 3]            --
│    └─Empty: 2-506                      [64]                      --
│    └─Empty: 2-507                      [64]                      --
│    └─BatchNorm2d: 2-508                [16, 64, 64, 64]          --
│    └─Scaler: 2-509                     [16, 64, 64, 64]          --
│    └─ReLU: 2-510                       [16, 64, 64, 64]          --
│    └─Empty: 2-511                      [16, 64, 64, 64]          --
│    └─Clamp: 2-512                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-513                  [16, 64, 32, 32]          --
│    └─Empty: 2-514                      [16, 64, 32, 32]          --
│    └─Empty: 2-515                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-516         --                        --
│    └─One: 2-517                        [1]                       --
│    └─OutputScale: 2-518                --                        --
│    └─Empty: 2-519                      [64, 64, 3, 3]            --
│    └─Empty: 2-520                      [64, 64, 3, 3]            --
│    └─Empty: 2-521                      [64]                      --
│    └─Empty: 2-522                      [64]                      --
│    └─BatchNorm2d: 2-523                [16, 64, 32, 32]          --
│    └─Scaler: 2-524                     [16, 64, 32, 32]          --
│    └─ReLU: 2-525                       [16, 64, 32, 32]          --
│    └─Empty: 2-526                      [16, 64, 32, 32]          --
│    └─Clamp: 2-527                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-528         --                        --
│    └─One: 2-529                        [1]                       --
│    └─OutputScale: 2-530                --                        --
│    └─Empty: 2-531                      [64, 64, 3, 3]            --
│    └─Empty: 2-532                      [64, 64, 3, 3]            --
│    └─Empty: 2-533                      [64]                      --
│    └─Empty: 2-534                      [64]                      --
│    └─BatchNorm2d: 2-535                [16, 64, 32, 32]          --
│    └─Scaler: 2-536                     [16, 64, 32, 32]          --
│    └─ReLU: 2-537                       [16, 64, 32, 32]          --
│    └─Empty: 2-538                      [16, 64, 32, 32]          --
│    └─Clamp: 2-539                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-540                  [16, 64, 16, 16]          --
│    └─Empty: 2-541                      [16, 64, 16, 16]          --
│    └─Empty: 2-542                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-543         --                        --
│    └─One: 2-544                        [1]                       --
│    └─OutputScale: 2-545                --                        --
│    └─Empty: 2-546                      [64, 64, 3, 3]            --
│    └─Empty: 2-547                      [64, 64, 3, 3]            --
│    └─Empty: 2-548                      [64]                      --
│    └─Empty: 2-549                      [64]                      --
│    └─BatchNorm2d: 2-550                [16, 64, 16, 16]          --
│    └─Scaler: 2-551                     [16, 64, 16, 16]          --
│    └─ReLU: 2-552                       [16, 64, 16, 16]          --
│    └─Empty: 2-553                      [16, 64, 16, 16]          --
│    └─Clamp: 2-554                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-555         --                        --
│    └─One: 2-556                        [1]                       --
│    └─OutputScale: 2-557                --                        --
│    └─Empty: 2-558                      [64, 64, 3, 3]            --
│    └─Empty: 2-559                      [64, 64, 3, 3]            --
│    └─Empty: 2-560                      [64]                      --
│    └─Empty: 2-561                      [64]                      --
│    └─BatchNorm2d: 2-562                [16, 64, 16, 16]          --
│    └─Scaler: 2-563                     [16, 64, 16, 16]          --
│    └─ReLU: 2-564                       [16, 64, 16, 16]          --
│    └─Empty: 2-565                      [16, 64, 16, 16]          --
│    └─Clamp: 2-566                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-567                  [16, 64, 8, 8]            --
│    └─Empty: 2-568                      [16, 64, 8, 8]            --
│    └─Empty: 2-569                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-570         --                        --
│    └─One: 2-571                        [1]                       --
│    └─OutputScale: 2-572                --                        --
│    └─Empty: 2-573                      [64, 64, 3, 3]            --
│    └─Empty: 2-574                      [64, 64, 3, 3]            --
│    └─Empty: 2-575                      [64]                      --
│    └─Empty: 2-576                      [64]                      --
│    └─BatchNorm2d: 2-577                [16, 64, 8, 8]            --
│    └─Scaler: 2-578                     [16, 64, 8, 8]            --
│    └─ReLU: 2-579                       [16, 64, 8, 8]            --
│    └─Empty: 2-580                      [16, 64, 8, 8]            --
│    └─Clamp: 2-581                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-582         --                        --
│    └─One: 2-583                        [1]                       --
│    └─OutputScale: 2-584                --                        --
│    └─Empty: 2-585                      [64, 64, 1, 1]            --
│    └─Empty: 2-586                      [64, 64, 1, 1]            --
│    └─Empty: 2-587                      [64]                      --
│    └─Empty: 2-588                      [64]                      --
│    └─BatchNorm2d: 2-589                [16, 64, 8, 8]            --
│    └─Scaler: 2-590                     [16, 64, 8, 8]            --
│    └─ReLU: 2-591                       [16, 64, 8, 8]            --
│    └─Empty: 2-592                      [16, 64, 8, 8]            --
│    └─Clamp: 2-593                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-594                  [16, 64, 8, 8]            --
│    └─Empty: 2-595                      [16, 64, 8, 8]            --
│    └─Empty: 2-596                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-597         --                        --
│    └─One: 2-598                        [1]                       --
│    └─OutputScale: 2-599                --                        --
│    └─Empty: 2-600                      [64, 64, 3, 3]            --
│    └─Empty: 2-601                      [64, 64, 3, 3]            --
│    └─Empty: 2-602                      [64]                      --
│    └─Empty: 2-603                      [64]                      --
│    └─BatchNorm2d: 2-604                [16, 64, 8, 8]            --
│    └─Scaler: 2-605                     [16, 64, 8, 8]            --
│    └─ReLU: 2-606                       [16, 64, 8, 8]            --
│    └─Empty: 2-607                      [16, 64, 8, 8]            --
│    └─Clamp: 2-608                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-609                  [16, 64, 4, 4]            --
│    └─Empty: 2-610                      [16, 64, 4, 4]            --
│    └─Empty: 2-611                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-612         --                        --
│    └─One: 2-613                        [1]                       --
│    └─OutputScale: 2-614                --                        --
│    └─Empty: 2-615                      [64, 64, 3, 3]            --
│    └─Empty: 2-616                      [64, 64, 3, 3]            --
│    └─Empty: 2-617                      [64]                      --
│    └─Empty: 2-618                      [64]                      --
│    └─BatchNorm2d: 2-619                [16, 64, 4, 4]            --
│    └─Scaler: 2-620                     [16, 64, 4, 4]            --
│    └─ReLU: 2-621                       [16, 64, 4, 4]            --
│    └─Empty: 2-622                      [16, 64, 4, 4]            --
│    └─Clamp: 2-623                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-624         --                        --
│    └─One: 2-625                        [1]                       --
│    └─OutputScale: 2-626                --                        --
│    └─Empty: 2-627                      [64, 64, 1, 1]            --
│    └─Empty: 2-628                      [64, 64, 1, 1]            --
│    └─Empty: 2-629                      [64]                      --
│    └─Empty: 2-630                      [64]                      --
│    └─BatchNorm2d: 2-631                [16, 64, 4, 4]            --
│    └─Scaler: 2-632                     [16, 64, 4, 4]            --
│    └─ReLU: 2-633                       [16, 64, 4, 4]            --
│    └─Empty: 2-634                      [16, 64, 4, 4]            --
│    └─Clamp: 2-635                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-636                  [16, 64, 4, 4]            --
│    └─Empty: 2-637                      [16, 64, 4, 4]            --
│    └─Empty: 2-638                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-639         --                        --
│    └─One: 2-640                        [1]                       --
│    └─OutputScale: 2-641                --                        --
│    └─Empty: 2-642                      [64, 64, 3, 3]            --
│    └─Empty: 2-643                      [64, 64, 3, 3]            --
│    └─Empty: 2-644                      [64]                      --
│    └─Empty: 2-645                      [64]                      --
│    └─BatchNorm2d: 2-646                [16, 64, 4, 4]            --
│    └─Scaler: 2-647                     [16, 64, 4, 4]            --
│    └─ReLU: 2-648                       [16, 64, 4, 4]            --
│    └─Empty: 2-649                      [16, 64, 4, 4]            --
│    └─Clamp: 2-650                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-651                  [16, 64, 2, 2]            --
│    └─Empty: 2-652                      [16, 64, 2, 2]            --
│    └─Empty: 2-653                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-654         --                        --
│    └─One: 2-655                        [1]                       --
│    └─OutputScale: 2-656                --                        --
│    └─Empty: 2-657                      [64, 64, 1, 1]            --
│    └─Empty: 2-658                      [64, 64, 1, 1]            --
│    └─Empty: 2-659                      [64]                      --
│    └─Empty: 2-660                      [64]                      --
│    └─BatchNorm2d: 2-661                [16, 64, 2, 2]            --
│    └─Scaler: 2-662                     [16, 64, 2, 2]            --
│    └─ReLU: 2-663                       [16, 64, 2, 2]            --
│    └─Empty: 2-664                      [16, 64, 2, 2]            --
│    └─Clamp: 2-665                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-666         --                        --
│    └─One: 2-667                        [1]                       --
│    └─OutputScale: 2-668                --                        --
│    └─Empty: 2-669                      [64, 64, 1, 1]            --
│    └─Empty: 2-670                      [64, 64, 1, 1]            --
│    └─Empty: 2-671                      [64]                      --
│    └─Empty: 2-672                      [64]                      --
│    └─BatchNorm2d: 2-673                [16, 64, 2, 2]            --
│    └─Scaler: 2-674                     [16, 64, 2, 2]            --
│    └─ReLU: 2-675                       [16, 64, 2, 2]            --
│    └─Empty: 2-676                      [16, 64, 2, 2]            --
│    └─Clamp: 2-677                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-678                  [16, 64, 2, 2]            --
│    └─Empty: 2-679                      [16, 64, 2, 2]            --
│    └─Empty: 2-680                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-681         --                        --
│    └─One: 2-682                        [1]                       --
│    └─OutputScale: 2-683                --                        --
│    └─Empty: 2-684                      [64, 64, 3, 3]            --
│    └─Empty: 2-685                      [64, 64, 3, 3]            --
│    └─Empty: 2-686                      [64]                      --
│    └─Empty: 2-687                      [64]                      --
│    └─BatchNorm2d: 2-688                [16, 64, 2, 2]            --
│    └─Scaler: 2-689                     [16, 64, 2, 2]            --
│    └─ReLU: 2-690                       [16, 64, 2, 2]            --
│    └─Empty: 2-691                      [16, 64, 2, 2]            --
│    └─Clamp: 2-692                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-693         --                        --
│    └─One: 2-694                        [1]                       --
│    └─OutputScale: 2-695                --                        --
│    └─Empty: 2-696                      [64, 48, 1, 1]            --
│    └─Empty: 2-697                      [64, 48, 1, 1]            --
│    └─Empty: 2-698                      [64]                      --
│    └─Empty: 2-699                      [64]                      --
│    └─BatchNorm2d: 2-700                [16, 64, 64, 64]          --
│    └─Scaler: 2-701                     [16, 64, 64, 64]          --
│    └─ReLU: 2-702                       [16, 64, 64, 64]          --
│    └─Empty: 2-703                      [16, 64, 64, 64]          --
│    └─Clamp: 2-704                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-705         --                        --
│    └─One: 2-706                        [1]                       --
│    └─OutputScale: 2-707                --                        --
│    └─Empty: 2-708                      [64, 64, 3, 3]            --
│    └─Empty: 2-709                      [64, 64, 3, 3]            --
│    └─Empty: 2-710                      [64]                      --
│    └─Empty: 2-711                      [64]                      --
│    └─BatchNorm2d: 2-712                [16, 64, 64, 64]          --
│    └─Scaler: 2-713                     [16, 64, 64, 64]          --
│    └─ReLU: 2-714                       [16, 64, 64, 64]          --
│    └─Empty: 2-715                      [16, 64, 64, 64]          --
│    └─Clamp: 2-716                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-717         --                        --
│    └─One: 2-718                        [1]                       --
│    └─OutputScale: 2-719                --                        --
│    └─Empty: 2-720                      [64, 64, 1, 1]            --
│    └─Empty: 2-721                      [64, 64, 1, 1]            --
│    └─Empty: 2-722                      [64]                      --
│    └─Empty: 2-723                      [64]                      --
│    └─BatchNorm2d: 2-724                [16, 64, 64, 64]          --
│    └─Scaler: 2-725                     [16, 64, 64, 64]          --
│    └─ReLU: 2-726                       [16, 64, 64, 64]          --
│    └─Empty: 2-727                      [16, 64, 64, 64]          --
│    └─Clamp: 2-728                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-729         --                        --
│    └─One: 2-730                        [1]                       --
│    └─OutputScale: 2-731                --                        --
│    └─Empty: 2-732                      [64, 64, 3, 3]            --
│    └─Empty: 2-733                      [64, 64, 3, 3]            --
│    └─Empty: 2-734                      [64]                      --
│    └─Empty: 2-735                      [64]                      --
│    └─BatchNorm2d: 2-736                [16, 64, 64, 64]          --
│    └─Scaler: 2-737                     [16, 64, 64, 64]          --
│    └─ReLU: 2-738                       [16, 64, 64, 64]          --
│    └─Empty: 2-739                      [16, 64, 64, 64]          --
│    └─Clamp: 2-740                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-741                  [16, 64, 32, 32]          --
│    └─Empty: 2-742                      [16, 64, 32, 32]          --
│    └─Empty: 2-743                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-744         --                        --
│    └─One: 2-745                        [1]                       --
│    └─OutputScale: 2-746                --                        --
│    └─Empty: 2-747                      [64, 64, 3, 3]            --
│    └─Empty: 2-748                      [64, 64, 3, 3]            --
│    └─Empty: 2-749                      [64]                      --
│    └─Empty: 2-750                      [64]                      --
│    └─BatchNorm2d: 2-751                [16, 64, 32, 32]          --
│    └─Scaler: 2-752                     [16, 64, 32, 32]          --
│    └─ReLU: 2-753                       [16, 64, 32, 32]          --
│    └─Empty: 2-754                      [16, 64, 32, 32]          --
│    └─Clamp: 2-755                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-756         --                        --
│    └─One: 2-757                        [1]                       --
│    └─OutputScale: 2-758                --                        --
│    └─Empty: 2-759                      [64, 64, 3, 3]            --
│    └─Empty: 2-760                      [64, 64, 3, 3]            --
│    └─Empty: 2-761                      [64]                      --
│    └─Empty: 2-762                      [64]                      --
│    └─BatchNorm2d: 2-763                [16, 64, 32, 32]          --
│    └─Scaler: 2-764                     [16, 64, 32, 32]          --
│    └─ReLU: 2-765                       [16, 64, 32, 32]          --
│    └─Empty: 2-766                      [16, 64, 32, 32]          --
│    └─Clamp: 2-767                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-768                  [16, 64, 16, 16]          --
│    └─Empty: 2-769                      [16, 64, 16, 16]          --
│    └─Empty: 2-770                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-771         --                        --
│    └─One: 2-772                        [1]                       --
│    └─OutputScale: 2-773                --                        --
│    └─Empty: 2-774                      [64, 64, 3, 3]            --
│    └─Empty: 2-775                      [64, 64, 3, 3]            --
│    └─Empty: 2-776                      [64]                      --
│    └─Empty: 2-777                      [64]                      --
│    └─BatchNorm2d: 2-778                [16, 64, 16, 16]          --
│    └─Scaler: 2-779                     [16, 64, 16, 16]          --
│    └─ReLU: 2-780                       [16, 64, 16, 16]          --
│    └─Empty: 2-781                      [16, 64, 16, 16]          --
│    └─Clamp: 2-782                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [64, 64, 3, 3]            --
│    └─Empty: 2-787                      [64, 64, 3, 3]            --
│    └─Empty: 2-788                      [64]                      --
│    └─Empty: 2-789                      [64]                      --
│    └─BatchNorm2d: 2-790                [16, 64, 16, 16]          --
│    └─Scaler: 2-791                     [16, 64, 16, 16]          --
│    └─ReLU: 2-792                       [16, 64, 16, 16]          --
│    └─Empty: 2-793                      [16, 64, 16, 16]          --
│    └─Clamp: 2-794                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-795                  [16, 64, 8, 8]            --
│    └─Empty: 2-796                      [16, 64, 8, 8]            --
│    └─Empty: 2-797                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-798         --                        --
│    └─One: 2-799                        [1]                       --
│    └─OutputScale: 2-800                --                        --
│    └─Empty: 2-801                      [64, 64, 3, 3]            --
│    └─Empty: 2-802                      [64, 64, 3, 3]            --
│    └─Empty: 2-803                      [64]                      --
│    └─Empty: 2-804                      [64]                      --
│    └─BatchNorm2d: 2-805                [16, 64, 8, 8]            --
│    └─Scaler: 2-806                     [16, 64, 8, 8]            --
│    └─ReLU: 2-807                       [16, 64, 8, 8]            --
│    └─Empty: 2-808                      [16, 64, 8, 8]            --
│    └─Clamp: 2-809                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [64, 64, 1, 1]            --
│    └─Empty: 2-814                      [64, 64, 1, 1]            --
│    └─Empty: 2-815                      [64]                      --
│    └─Empty: 2-816                      [64]                      --
│    └─BatchNorm2d: 2-817                [16, 64, 8, 8]            --
│    └─Scaler: 2-818                     [16, 64, 8, 8]            --
│    └─ReLU: 2-819                       [16, 64, 8, 8]            --
│    └─Empty: 2-820                      [16, 64, 8, 8]            --
│    └─Clamp: 2-821                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-822                  [16, 64, 8, 8]            --
│    └─Empty: 2-823                      [16, 64, 8, 8]            --
│    └─Empty: 2-824                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-825         --                        --
│    └─One: 2-826                        [1]                       --
│    └─OutputScale: 2-827                --                        --
│    └─Empty: 2-828                      [64, 64, 3, 3]            --
│    └─Empty: 2-829                      [64, 64, 3, 3]            --
│    └─Empty: 2-830                      [64]                      --
│    └─Empty: 2-831                      [64]                      --
│    └─BatchNorm2d: 2-832                [16, 64, 8, 8]            --
│    └─Scaler: 2-833                     [16, 64, 8, 8]            --
│    └─ReLU: 2-834                       [16, 64, 8, 8]            --
│    └─Empty: 2-835                      [16, 64, 8, 8]            --
│    └─Clamp: 2-836                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-837                  [16, 64, 4, 4]            --
│    └─Empty: 2-838                      [16, 64, 4, 4]            --
│    └─Empty: 2-839                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-840         --                        --
│    └─One: 2-841                        [1]                       --
│    └─OutputScale: 2-842                --                        --
│    └─Empty: 2-843                      [64, 64, 3, 3]            --
│    └─Empty: 2-844                      [64, 64, 3, 3]            --
│    └─Empty: 2-845                      [64]                      --
│    └─Empty: 2-846                      [64]                      --
│    └─BatchNorm2d: 2-847                [16, 64, 4, 4]            --
│    └─Scaler: 2-848                     [16, 64, 4, 4]            --
│    └─ReLU: 2-849                       [16, 64, 4, 4]            --
│    └─Empty: 2-850                      [16, 64, 4, 4]            --
│    └─Clamp: 2-851                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-852         --                        --
│    └─One: 2-853                        [1]                       --
│    └─OutputScale: 2-854                --                        --
│    └─Empty: 2-855                      [64, 64, 1, 1]            --
│    └─Empty: 2-856                      [64, 64, 1, 1]            --
│    └─Empty: 2-857                      [64]                      --
│    └─Empty: 2-858                      [64]                      --
│    └─BatchNorm2d: 2-859                [16, 64, 4, 4]            --
│    └─Scaler: 2-860                     [16, 64, 4, 4]            --
│    └─ReLU: 2-861                       [16, 64, 4, 4]            --
│    └─Empty: 2-862                      [16, 64, 4, 4]            --
│    └─Clamp: 2-863                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-864                  [16, 64, 4, 4]            --
│    └─Empty: 2-865                      [16, 64, 4, 4]            --
│    └─Empty: 2-866                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-867         --                        --
│    └─One: 2-868                        [1]                       --
│    └─OutputScale: 2-869                --                        --
│    └─Empty: 2-870                      [64, 64, 3, 3]            --
│    └─Empty: 2-871                      [64, 64, 3, 3]            --
│    └─Empty: 2-872                      [64]                      --
│    └─Empty: 2-873                      [64]                      --
│    └─BatchNorm2d: 2-874                [16, 64, 4, 4]            --
│    └─Scaler: 2-875                     [16, 64, 4, 4]            --
│    └─ReLU: 2-876                       [16, 64, 4, 4]            --
│    └─Empty: 2-877                      [16, 64, 4, 4]            --
│    └─Clamp: 2-878                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-879                  [16, 64, 2, 2]            --
│    └─Empty: 2-880                      [16, 64, 2, 2]            --
│    └─Empty: 2-881                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-882         --                        --
│    └─One: 2-883                        [1]                       --
│    └─OutputScale: 2-884                --                        --
│    └─Empty: 2-885                      [64, 64, 1, 1]            --
│    └─Empty: 2-886                      [64, 64, 1, 1]            --
│    └─Empty: 2-887                      [64]                      --
│    └─Empty: 2-888                      [64]                      --
│    └─BatchNorm2d: 2-889                [16, 64, 2, 2]            --
│    └─Scaler: 2-890                     [16, 64, 2, 2]            --
│    └─ReLU: 2-891                       [16, 64, 2, 2]            --
│    └─Empty: 2-892                      [16, 64, 2, 2]            --
│    └─Clamp: 2-893                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-894         --                        --
│    └─One: 2-895                        [1]                       --
│    └─OutputScale: 2-896                --                        --
│    └─Empty: 2-897                      [64, 64, 1, 1]            --
│    └─Empty: 2-898                      [64, 64, 1, 1]            --
│    └─Empty: 2-899                      [64]                      --
│    └─Empty: 2-900                      [64]                      --
│    └─BatchNorm2d: 2-901                [16, 64, 2, 2]            --
│    └─Scaler: 2-902                     [16, 64, 2, 2]            --
│    └─ReLU: 2-903                       [16, 64, 2, 2]            --
│    └─Empty: 2-904                      [16, 64, 2, 2]            --
│    └─Clamp: 2-905                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-906                  [16, 64, 2, 2]            --
│    └─Empty: 2-907                      [16, 64, 2, 2]            --
│    └─Empty: 2-908                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-909         --                        --
│    └─One: 2-910                        [1]                       --
│    └─OutputScale: 2-911                --                        --
│    └─Empty: 2-912                      [64, 64, 3, 3]            --
│    └─Empty: 2-913                      [64, 64, 3, 3]            --
│    └─Empty: 2-914                      [64]                      --
│    └─Empty: 2-915                      [64]                      --
│    └─BatchNorm2d: 2-916                [16, 64, 2, 2]            --
│    └─Scaler: 2-917                     [16, 64, 2, 2]            --
│    └─ReLU: 2-918                       [16, 64, 2, 2]            --
│    └─Empty: 2-919                      [16, 64, 2, 2]            --
│    └─Clamp: 2-920                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [64, 48, 1, 1]            --
│    └─Empty: 2-925                      [64, 48, 1, 1]            --
│    └─Empty: 2-926                      [64]                      --
│    └─Empty: 2-927                      [64]                      --
│    └─BatchNorm2d: 2-928                [16, 64, 64, 64]          --
│    └─Scaler: 2-929                     [16, 64, 64, 64]          --
│    └─ReLU: 2-930                       [16, 64, 64, 64]          --
│    └─Empty: 2-931                      [16, 64, 64, 64]          --
│    └─Clamp: 2-932                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [64, 64, 3, 3]            --
│    └─Empty: 2-937                      [64, 64, 3, 3]            --
│    └─Empty: 2-938                      [64]                      --
│    └─Empty: 2-939                      [64]                      --
│    └─BatchNorm2d: 2-940                [16, 64, 64, 64]          --
│    └─Scaler: 2-941                     [16, 64, 64, 64]          --
│    └─ReLU: 2-942                       [16, 64, 64, 64]          --
│    └─Empty: 2-943                      [16, 64, 64, 64]          --
│    └─Clamp: 2-944                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-945         --                        --
│    └─One: 2-946                        [1]                       --
│    └─OutputScale: 2-947                --                        --
│    └─Empty: 2-948                      [64, 64, 1, 1]            --
│    └─Empty: 2-949                      [64, 64, 1, 1]            --
│    └─Empty: 2-950                      [64]                      --
│    └─Empty: 2-951                      [64]                      --
│    └─BatchNorm2d: 2-952                [16, 64, 64, 64]          --
│    └─Scaler: 2-953                     [16, 64, 64, 64]          --
│    └─ReLU: 2-954                       [16, 64, 64, 64]          --
│    └─Empty: 2-955                      [16, 64, 64, 64]          --
│    └─Clamp: 2-956                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-957         --                        --
│    └─One: 2-958                        [1]                       --
│    └─OutputScale: 2-959                --                        --
│    └─Empty: 2-960                      [64, 64, 3, 3]            --
│    └─Empty: 2-961                      [64, 64, 3, 3]            --
│    └─Empty: 2-962                      [64]                      --
│    └─Empty: 2-963                      [64]                      --
│    └─BatchNorm2d: 2-964                [16, 64, 64, 64]          --
│    └─Scaler: 2-965                     [16, 64, 64, 64]          --
│    └─ReLU: 2-966                       [16, 64, 64, 64]          --
│    └─Empty: 2-967                      [16, 64, 64, 64]          --
│    └─Clamp: 2-968                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-969                  [16, 64, 32, 32]          --
│    └─Empty: 2-970                      [16, 64, 32, 32]          --
│    └─Empty: 2-971                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-972         --                        --
│    └─One: 2-973                        [1]                       --
│    └─OutputScale: 2-974                --                        --
│    └─Empty: 2-975                      [64, 64, 3, 3]            --
│    └─Empty: 2-976                      [64, 64, 3, 3]            --
│    └─Empty: 2-977                      [64]                      --
│    └─Empty: 2-978                      [64]                      --
│    └─BatchNorm2d: 2-979                [16, 64, 32, 32]          --
│    └─Scaler: 2-980                     [16, 64, 32, 32]          --
│    └─ReLU: 2-981                       [16, 64, 32, 32]          --
│    └─Empty: 2-982                      [16, 64, 32, 32]          --
│    └─Clamp: 2-983                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-984         --                        --
│    └─One: 2-985                        [1]                       --
│    └─OutputScale: 2-986                --                        --
│    └─Empty: 2-987                      [64, 64, 3, 3]            --
│    └─Empty: 2-988                      [64, 64, 3, 3]            --
│    └─Empty: 2-989                      [64]                      --
│    └─Empty: 2-990                      [64]                      --
│    └─BatchNorm2d: 2-991                [16, 64, 32, 32]          --
│    └─Scaler: 2-992                     [16, 64, 32, 32]          --
│    └─ReLU: 2-993                       [16, 64, 32, 32]          --
│    └─Empty: 2-994                      [16, 64, 32, 32]          --
│    └─Clamp: 2-995                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-996                  [16, 64, 16, 16]          --
│    └─Empty: 2-997                      [16, 64, 16, 16]          --
│    └─Empty: 2-998                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-999         --                        --
│    └─One: 2-1000                       [1]                       --
│    └─OutputScale: 2-1001               --                        --
│    └─Empty: 2-1002                     [64, 64, 3, 3]            --
│    └─Empty: 2-1003                     [64, 64, 3, 3]            --
│    └─Empty: 2-1004                     [64]                      --
│    └─Empty: 2-1005                     [64]                      --
│    └─BatchNorm2d: 2-1006               [16, 64, 16, 16]          --
│    └─Scaler: 2-1007                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1008                      [16, 64, 16, 16]          --
│    └─Empty: 2-1009                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1010                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1011        --                        --
│    └─One: 2-1012                       [1]                       --
│    └─OutputScale: 2-1013               --                        --
│    └─Empty: 2-1014                     [64, 64, 3, 3]            --
│    └─Empty: 2-1015                     [64, 64, 3, 3]            --
│    └─Empty: 2-1016                     [64]                      --
│    └─Empty: 2-1017                     [64]                      --
│    └─BatchNorm2d: 2-1018               [16, 64, 16, 16]          --
│    └─Scaler: 2-1019                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1020                      [16, 64, 16, 16]          --
│    └─Empty: 2-1021                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1022                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1023                 [16, 64, 8, 8]            --
│    └─Empty: 2-1024                     [16, 64, 8, 8]            --
│    └─Empty: 2-1025                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1026        --                        --
│    └─One: 2-1027                       [1]                       --
│    └─OutputScale: 2-1028               --                        --
│    └─Empty: 2-1029                     [64, 64, 3, 3]            --
│    └─Empty: 2-1030                     [64, 64, 3, 3]            --
│    └─Empty: 2-1031                     [64]                      --
│    └─Empty: 2-1032                     [64]                      --
│    └─BatchNorm2d: 2-1033               [16, 64, 8, 8]            --
│    └─Scaler: 2-1034                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1035                      [16, 64, 8, 8]            --
│    └─Empty: 2-1036                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1037                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1038        --                        --
│    └─One: 2-1039                       [1]                       --
│    └─OutputScale: 2-1040               --                        --
│    └─Empty: 2-1041                     [64, 64, 1, 1]            --
│    └─Empty: 2-1042                     [64, 64, 1, 1]            --
│    └─Empty: 2-1043                     [64]                      --
│    └─Empty: 2-1044                     [64]                      --
│    └─BatchNorm2d: 2-1045               [16, 64, 8, 8]            --
│    └─Scaler: 2-1046                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1047                      [16, 64, 8, 8]            --
│    └─Empty: 2-1048                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1049                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1050                 [16, 64, 8, 8]            --
│    └─Empty: 2-1051                     [16, 64, 8, 8]            --
│    └─Empty: 2-1052                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1053        --                        --
│    └─One: 2-1054                       [1]                       --
│    └─OutputScale: 2-1055               --                        --
│    └─Empty: 2-1056                     [64, 64, 3, 3]            --
│    └─Empty: 2-1057                     [64, 64, 3, 3]            --
│    └─Empty: 2-1058                     [64]                      --
│    └─Empty: 2-1059                     [64]                      --
│    └─BatchNorm2d: 2-1060               [16, 64, 8, 8]            --
│    └─Scaler: 2-1061                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1062                      [16, 64, 8, 8]            --
│    └─Empty: 2-1063                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1064                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1065                 [16, 64, 4, 4]            --
│    └─Empty: 2-1066                     [16, 64, 4, 4]            --
│    └─Empty: 2-1067                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1068        --                        --
│    └─One: 2-1069                       [1]                       --
│    └─OutputScale: 2-1070               --                        --
│    └─Empty: 2-1071                     [64, 64, 3, 3]            --
│    └─Empty: 2-1072                     [64, 64, 3, 3]            --
│    └─Empty: 2-1073                     [64]                      --
│    └─Empty: 2-1074                     [64]                      --
│    └─BatchNorm2d: 2-1075               [16, 64, 4, 4]            --
│    └─Scaler: 2-1076                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1077                      [16, 64, 4, 4]            --
│    └─Empty: 2-1078                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1079                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1080        --                        --
│    └─One: 2-1081                       [1]                       --
│    └─OutputScale: 2-1082               --                        --
│    └─Empty: 2-1083                     [64, 64, 1, 1]            --
│    └─Empty: 2-1084                     [64, 64, 1, 1]            --
│    └─Empty: 2-1085                     [64]                      --
│    └─Empty: 2-1086                     [64]                      --
│    └─BatchNorm2d: 2-1087               [16, 64, 4, 4]            --
│    └─Scaler: 2-1088                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1089                      [16, 64, 4, 4]            --
│    └─Empty: 2-1090                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1091                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1092                 [16, 64, 4, 4]            --
│    └─Empty: 2-1093                     [16, 64, 4, 4]            --
│    └─Empty: 2-1094                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1095        --                        --
│    └─One: 2-1096                       [1]                       --
│    └─OutputScale: 2-1097               --                        --
│    └─Empty: 2-1098                     [64, 64, 3, 3]            --
│    └─Empty: 2-1099                     [64, 64, 3, 3]            --
│    └─Empty: 2-1100                     [64]                      --
│    └─Empty: 2-1101                     [64]                      --
│    └─BatchNorm2d: 2-1102               [16, 64, 4, 4]            --
│    └─Scaler: 2-1103                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1104                      [16, 64, 4, 4]            --
│    └─Empty: 2-1105                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1106                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1107                 [16, 64, 2, 2]            --
│    └─Empty: 2-1108                     [16, 64, 2, 2]            --
│    └─Empty: 2-1109                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1110        --                        --
│    └─One: 2-1111                       [1]                       --
│    └─OutputScale: 2-1112               --                        --
│    └─Empty: 2-1113                     [64, 64, 1, 1]            --
│    └─Empty: 2-1114                     [64, 64, 1, 1]            --
│    └─Empty: 2-1115                     [64]                      --
│    └─Empty: 2-1116                     [64]                      --
│    └─BatchNorm2d: 2-1117               [16, 64, 2, 2]            --
│    └─Scaler: 2-1118                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1119                      [16, 64, 2, 2]            --
│    └─Empty: 2-1120                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1121                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1122        --                        --
│    └─One: 2-1123                       [1]                       --
│    └─OutputScale: 2-1124               --                        --
│    └─Empty: 2-1125                     [64, 64, 1, 1]            --
│    └─Empty: 2-1126                     [64, 64, 1, 1]            --
│    └─Empty: 2-1127                     [64]                      --
│    └─Empty: 2-1128                     [64]                      --
│    └─BatchNorm2d: 2-1129               [16, 64, 2, 2]            --
│    └─Scaler: 2-1130                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1131                      [16, 64, 2, 2]            --
│    └─Empty: 2-1132                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1133                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1134                 [16, 64, 2, 2]            --
│    └─Empty: 2-1135                     [16, 64, 2, 2]            --
│    └─Empty: 2-1136                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1137        --                        --
│    └─One: 2-1138                       [1]                       --
│    └─OutputScale: 2-1139               --                        --
│    └─Empty: 2-1140                     [64, 64, 3, 3]            --
│    └─Empty: 2-1141                     [64, 64, 3, 3]            --
│    └─Empty: 2-1142                     [64]                      --
│    └─Empty: 2-1143                     [64]                      --
│    └─BatchNorm2d: 2-1144               [16, 64, 2, 2]            --
│    └─Scaler: 2-1145                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1146                      [16, 64, 2, 2]            --
│    └─Empty: 2-1147                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1148                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1149        --                        --
│    └─One: 2-1150                       [1]                       --
│    └─OutputScale: 2-1151               --                        --
│    └─Empty: 2-1152                     [64, 48, 1, 1]            --
│    └─Empty: 2-1153                     [64, 48, 1, 1]            --
│    └─Empty: 2-1154                     [64]                      --
│    └─Empty: 2-1155                     [64]                      --
│    └─BatchNorm2d: 2-1156               [16, 64, 64, 64]          --
│    └─Scaler: 2-1157                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1158                      [16, 64, 64, 64]          --
│    └─Empty: 2-1159                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1160                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1161        --                        --
│    └─One: 2-1162                       [1]                       --
│    └─OutputScale: 2-1163               --                        --
│    └─Empty: 2-1164                     [64, 64, 3, 3]            --
│    └─Empty: 2-1165                     [64, 64, 3, 3]            --
│    └─Empty: 2-1166                     [64]                      --
│    └─Empty: 2-1167                     [64]                      --
│    └─BatchNorm2d: 2-1168               [16, 64, 64, 64]          --
│    └─Scaler: 2-1169                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1170                      [16, 64, 64, 64]          --
│    └─Empty: 2-1171                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1172                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1173        --                        --
│    └─One: 2-1174                       [1]                       --
│    └─OutputScale: 2-1175               --                        --
│    └─Empty: 2-1176                     [64, 64, 1, 1]            --
│    └─Empty: 2-1177                     [64, 64, 1, 1]            --
│    └─Empty: 2-1178                     [64]                      --
│    └─Empty: 2-1179                     [64]                      --
│    └─BatchNorm2d: 2-1180               [16, 64, 64, 64]          --
│    └─Scaler: 2-1181                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1182                      [16, 64, 64, 64]          --
│    └─Empty: 2-1183                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1184                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1185        --                        --
│    └─One: 2-1186                       [1]                       --
│    └─OutputScale: 2-1187               --                        --
│    └─Empty: 2-1188                     [64, 64, 3, 3]            --
│    └─Empty: 2-1189                     [64, 64, 3, 3]            --
│    └─Empty: 2-1190                     [64]                      --
│    └─Empty: 2-1191                     [64]                      --
│    └─BatchNorm2d: 2-1192               [16, 64, 64, 64]          --
│    └─Scaler: 2-1193                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1194                      [16, 64, 64, 64]          --
│    └─Empty: 2-1195                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1196                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1197                 [16, 64, 32, 32]          --
│    └─Empty: 2-1198                     [16, 64, 32, 32]          --
│    └─Empty: 2-1199                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1200        --                        --
│    └─One: 2-1201                       [1]                       --
│    └─OutputScale: 2-1202               --                        --
│    └─Empty: 2-1203                     [64, 64, 3, 3]            --
│    └─Empty: 2-1204                     [64, 64, 3, 3]            --
│    └─Empty: 2-1205                     [64]                      --
│    └─Empty: 2-1206                     [64]                      --
│    └─BatchNorm2d: 2-1207               [16, 64, 32, 32]          --
│    └─Scaler: 2-1208                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1209                      [16, 64, 32, 32]          --
│    └─Empty: 2-1210                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1211                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1212        --                        --
│    └─One: 2-1213                       [1]                       --
│    └─OutputScale: 2-1214               --                        --
│    └─Empty: 2-1215                     [64, 64, 3, 3]            --
│    └─Empty: 2-1216                     [64, 64, 3, 3]            --
│    └─Empty: 2-1217                     [64]                      --
│    └─Empty: 2-1218                     [64]                      --
│    └─BatchNorm2d: 2-1219               [16, 64, 32, 32]          --
│    └─Scaler: 2-1220                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1221                      [16, 64, 32, 32]          --
│    └─Empty: 2-1222                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1223                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1224                 [16, 64, 16, 16]          --
│    └─Empty: 2-1225                     [16, 64, 16, 16]          --
│    └─Empty: 2-1226                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1227        --                        --
│    └─One: 2-1228                       [1]                       --
│    └─OutputScale: 2-1229               --                        --
│    └─Empty: 2-1230                     [64, 64, 3, 3]            --
│    └─Empty: 2-1231                     [64, 64, 3, 3]            --
│    └─Empty: 2-1232                     [64]                      --
│    └─Empty: 2-1233                     [64]                      --
│    └─BatchNorm2d: 2-1234               [16, 64, 16, 16]          --
│    └─Scaler: 2-1235                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1236                      [16, 64, 16, 16]          --
│    └─Empty: 2-1237                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1238                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1239        --                        --
│    └─One: 2-1240                       [1]                       --
│    └─OutputScale: 2-1241               --                        --
│    └─Empty: 2-1242                     [64, 64, 3, 3]            --
│    └─Empty: 2-1243                     [64, 64, 3, 3]            --
│    └─Empty: 2-1244                     [64]                      --
│    └─Empty: 2-1245                     [64]                      --
│    └─BatchNorm2d: 2-1246               [16, 64, 16, 16]          --
│    └─Scaler: 2-1247                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1248                      [16, 64, 16, 16]          --
│    └─Empty: 2-1249                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1250                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1251                 [16, 64, 8, 8]            --
│    └─Empty: 2-1252                     [16, 64, 8, 8]            --
│    └─Empty: 2-1253                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1254        --                        --
│    └─One: 2-1255                       [1]                       --
│    └─OutputScale: 2-1256               --                        --
│    └─Empty: 2-1257                     [64, 64, 3, 3]            --
│    └─Empty: 2-1258                     [64, 64, 3, 3]            --
│    └─Empty: 2-1259                     [64]                      --
│    └─Empty: 2-1260                     [64]                      --
│    └─BatchNorm2d: 2-1261               [16, 64, 8, 8]            --
│    └─Scaler: 2-1262                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1263                      [16, 64, 8, 8]            --
│    └─Empty: 2-1264                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1265                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1266        --                        --
│    └─One: 2-1267                       [1]                       --
│    └─OutputScale: 2-1268               --                        --
│    └─Empty: 2-1269                     [64, 64, 1, 1]            --
│    └─Empty: 2-1270                     [64, 64, 1, 1]            --
│    └─Empty: 2-1271                     [64]                      --
│    └─Empty: 2-1272                     [64]                      --
│    └─BatchNorm2d: 2-1273               [16, 64, 8, 8]            --
│    └─Scaler: 2-1274                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1275                      [16, 64, 8, 8]            --
│    └─Empty: 2-1276                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1277                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1278                 [16, 64, 8, 8]            --
│    └─Empty: 2-1279                     [16, 64, 8, 8]            --
│    └─Empty: 2-1280                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1281        --                        --
│    └─One: 2-1282                       [1]                       --
│    └─OutputScale: 2-1283               --                        --
│    └─Empty: 2-1284                     [64, 64, 3, 3]            --
│    └─Empty: 2-1285                     [64, 64, 3, 3]            --
│    └─Empty: 2-1286                     [64]                      --
│    └─Empty: 2-1287                     [64]                      --
│    └─BatchNorm2d: 2-1288               [16, 64, 8, 8]            --
│    └─Scaler: 2-1289                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1290                      [16, 64, 8, 8]            --
│    └─Empty: 2-1291                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1292                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1293                 [16, 64, 4, 4]            --
│    └─Empty: 2-1294                     [16, 64, 4, 4]            --
│    └─Empty: 2-1295                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1296        --                        --
│    └─One: 2-1297                       [1]                       --
│    └─OutputScale: 2-1298               --                        --
│    └─Empty: 2-1299                     [64, 64, 3, 3]            --
│    └─Empty: 2-1300                     [64, 64, 3, 3]            --
│    └─Empty: 2-1301                     [64]                      --
│    └─Empty: 2-1302                     [64]                      --
│    └─BatchNorm2d: 2-1303               [16, 64, 4, 4]            --
│    └─Scaler: 2-1304                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1305                      [16, 64, 4, 4]            --
│    └─Empty: 2-1306                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1307                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1308        --                        --
│    └─One: 2-1309                       [1]                       --
│    └─OutputScale: 2-1310               --                        --
│    └─Empty: 2-1311                     [64, 64, 1, 1]            --
│    └─Empty: 2-1312                     [64, 64, 1, 1]            --
│    └─Empty: 2-1313                     [64]                      --
│    └─Empty: 2-1314                     [64]                      --
│    └─BatchNorm2d: 2-1315               [16, 64, 4, 4]            --
│    └─Scaler: 2-1316                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1317                      [16, 64, 4, 4]            --
│    └─Empty: 2-1318                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1319                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1320                 [16, 64, 4, 4]            --
│    └─Empty: 2-1321                     [16, 64, 4, 4]            --
│    └─Empty: 2-1322                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1323        --                        --
│    └─One: 2-1324                       [1]                       --
│    └─OutputScale: 2-1325               --                        --
│    └─Empty: 2-1326                     [64, 64, 3, 3]            --
│    └─Empty: 2-1327                     [64, 64, 3, 3]            --
│    └─Empty: 2-1328                     [64]                      --
│    └─Empty: 2-1329                     [64]                      --
│    └─BatchNorm2d: 2-1330               [16, 64, 4, 4]            --
│    └─Scaler: 2-1331                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1332                      [16, 64, 4, 4]            --
│    └─Empty: 2-1333                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1334                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1335                 [16, 64, 2, 2]            --
│    └─Empty: 2-1336                     [16, 64, 2, 2]            --
│    └─Empty: 2-1337                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1338        --                        --
│    └─One: 2-1339                       [1]                       --
│    └─OutputScale: 2-1340               --                        --
│    └─Empty: 2-1341                     [64, 64, 1, 1]            --
│    └─Empty: 2-1342                     [64, 64, 1, 1]            --
│    └─Empty: 2-1343                     [64]                      --
│    └─Empty: 2-1344                     [64]                      --
│    └─BatchNorm2d: 2-1345               [16, 64, 2, 2]            --
│    └─Scaler: 2-1346                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1347                      [16, 64, 2, 2]            --
│    └─Empty: 2-1348                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1349                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1350        --                        --
│    └─One: 2-1351                       [1]                       --
│    └─OutputScale: 2-1352               --                        --
│    └─Empty: 2-1353                     [64, 64, 1, 1]            --
│    └─Empty: 2-1354                     [64, 64, 1, 1]            --
│    └─Empty: 2-1355                     [64]                      --
│    └─Empty: 2-1356                     [64]                      --
│    └─BatchNorm2d: 2-1357               [16, 64, 2, 2]            --
│    └─Scaler: 2-1358                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1359                      [16, 64, 2, 2]            --
│    └─Empty: 2-1360                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1361                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1362                 [16, 64, 2, 2]            --
│    └─Empty: 2-1363                     [16, 64, 2, 2]            --
│    └─Empty: 2-1364                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1365        --                        --
│    └─One: 2-1366                       [1]                       --
│    └─OutputScale: 2-1367               --                        --
│    └─Empty: 2-1368                     [64, 64, 3, 3]            --
│    └─Empty: 2-1369                     [64, 64, 3, 3]            --
│    └─Empty: 2-1370                     [64]                      --
│    └─Empty: 2-1371                     [64]                      --
│    └─BatchNorm2d: 2-1372               [16, 64, 2, 2]            --
│    └─Scaler: 2-1373                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1374                      [16, 64, 2, 2]            --
│    └─Empty: 2-1375                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1376                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1377        --                        --
│    └─One: 2-1378                       [1]                       --
│    └─OutputScale: 2-1379               --                        --
│    └─Empty: 2-1380                     [64, 48, 1, 1]            --
│    └─Empty: 2-1381                     [64, 48, 1, 1]            --
│    └─Empty: 2-1382                     [64]                      --
│    └─Empty: 2-1383                     [64]                      --
│    └─BatchNorm2d: 2-1384               [16, 64, 64, 64]          --
│    └─Scaler: 2-1385                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1386                      [16, 64, 64, 64]          --
│    └─Empty: 2-1387                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1388                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1389        --                        --
│    └─One: 2-1390                       [1]                       --
│    └─OutputScale: 2-1391               --                        --
│    └─Empty: 2-1392                     [64, 64, 3, 3]            --
│    └─Empty: 2-1393                     [64, 64, 3, 3]            --
│    └─Empty: 2-1394                     [64]                      --
│    └─Empty: 2-1395                     [64]                      --
│    └─BatchNorm2d: 2-1396               [16, 64, 64, 64]          --
│    └─Scaler: 2-1397                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1398                      [16, 64, 64, 64]          --
│    └─Empty: 2-1399                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1400                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1401        --                        --
│    └─One: 2-1402                       [1]                       --
│    └─OutputScale: 2-1403               --                        --
│    └─Empty: 2-1404                     [64, 64, 1, 1]            --
│    └─Empty: 2-1405                     [64, 64, 1, 1]            --
│    └─Empty: 2-1406                     [64]                      --
│    └─Empty: 2-1407                     [64]                      --
│    └─BatchNorm2d: 2-1408               [16, 64, 64, 64]          --
│    └─Scaler: 2-1409                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1410                      [16, 64, 64, 64]          --
│    └─Empty: 2-1411                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1412                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1413        --                        --
│    └─One: 2-1414                       [1]                       --
│    └─OutputScale: 2-1415               --                        --
│    └─Empty: 2-1416                     [64, 64, 3, 3]            --
│    └─Empty: 2-1417                     [64, 64, 3, 3]            --
│    └─Empty: 2-1418                     [64]                      --
│    └─Empty: 2-1419                     [64]                      --
│    └─BatchNorm2d: 2-1420               [16, 64, 64, 64]          --
│    └─Scaler: 2-1421                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1422                      [16, 64, 64, 64]          --
│    └─Empty: 2-1423                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1424                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1425                 [16, 64, 32, 32]          --
│    └─Empty: 2-1426                     [16, 64, 32, 32]          --
│    └─Empty: 2-1427                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1428        --                        --
│    └─One: 2-1429                       [1]                       --
│    └─OutputScale: 2-1430               --                        --
│    └─Empty: 2-1431                     [64, 64, 3, 3]            --
│    └─Empty: 2-1432                     [64, 64, 3, 3]            --
│    └─Empty: 2-1433                     [64]                      --
│    └─Empty: 2-1434                     [64]                      --
│    └─BatchNorm2d: 2-1435               [16, 64, 32, 32]          --
│    └─Scaler: 2-1436                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1437                      [16, 64, 32, 32]          --
│    └─Empty: 2-1438                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1439                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1440        --                        --
│    └─One: 2-1441                       [1]                       --
│    └─OutputScale: 2-1442               --                        --
│    └─Empty: 2-1443                     [64, 64, 3, 3]            --
│    └─Empty: 2-1444                     [64, 64, 3, 3]            --
│    └─Empty: 2-1445                     [64]                      --
│    └─Empty: 2-1446                     [64]                      --
│    └─BatchNorm2d: 2-1447               [16, 64, 32, 32]          --
│    └─Scaler: 2-1448                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1449                      [16, 64, 32, 32]          --
│    └─Empty: 2-1450                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1451                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1452                 [16, 64, 16, 16]          --
│    └─Empty: 2-1453                     [16, 64, 16, 16]          --
│    └─Empty: 2-1454                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1455        --                        --
│    └─One: 2-1456                       [1]                       --
│    └─OutputScale: 2-1457               --                        --
│    └─Empty: 2-1458                     [64, 64, 3, 3]            --
│    └─Empty: 2-1459                     [64, 64, 3, 3]            --
│    └─Empty: 2-1460                     [64]                      --
│    └─Empty: 2-1461                     [64]                      --
│    └─BatchNorm2d: 2-1462               [16, 64, 16, 16]          --
│    └─Scaler: 2-1463                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1464                      [16, 64, 16, 16]          --
│    └─Empty: 2-1465                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1466                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1467        --                        --
│    └─One: 2-1468                       [1]                       --
│    └─OutputScale: 2-1469               --                        --
│    └─Empty: 2-1470                     [64, 64, 3, 3]            --
│    └─Empty: 2-1471                     [64, 64, 3, 3]            --
│    └─Empty: 2-1472                     [64]                      --
│    └─Empty: 2-1473                     [64]                      --
│    └─BatchNorm2d: 2-1474               [16, 64, 16, 16]          --
│    └─Scaler: 2-1475                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1476                      [16, 64, 16, 16]          --
│    └─Empty: 2-1477                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1478                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1479                 [16, 64, 8, 8]            --
│    └─Empty: 2-1480                     [16, 64, 8, 8]            --
│    └─Empty: 2-1481                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1482        --                        --
│    └─One: 2-1483                       [1]                       --
│    └─OutputScale: 2-1484               --                        --
│    └─Empty: 2-1485                     [64, 64, 3, 3]            --
│    └─Empty: 2-1486                     [64, 64, 3, 3]            --
│    └─Empty: 2-1487                     [64]                      --
│    └─Empty: 2-1488                     [64]                      --
│    └─BatchNorm2d: 2-1489               [16, 64, 8, 8]            --
│    └─Scaler: 2-1490                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1491                      [16, 64, 8, 8]            --
│    └─Empty: 2-1492                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1493                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1494        --                        --
│    └─One: 2-1495                       [1]                       --
│    └─OutputScale: 2-1496               --                        --
│    └─Empty: 2-1497                     [64, 64, 1, 1]            --
│    └─Empty: 2-1498                     [64, 64, 1, 1]            --
│    └─Empty: 2-1499                     [64]                      --
│    └─Empty: 2-1500                     [64]                      --
│    └─BatchNorm2d: 2-1501               [16, 64, 8, 8]            --
│    └─Scaler: 2-1502                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1503                      [16, 64, 8, 8]            --
│    └─Empty: 2-1504                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1505                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1506                 [16, 64, 8, 8]            --
│    └─Empty: 2-1507                     [16, 64, 8, 8]            --
│    └─Empty: 2-1508                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1509        --                        --
│    └─One: 2-1510                       [1]                       --
│    └─OutputScale: 2-1511               --                        --
│    └─Empty: 2-1512                     [64, 64, 3, 3]            --
│    └─Empty: 2-1513                     [64, 64, 3, 3]            --
│    └─Empty: 2-1514                     [64]                      --
│    └─Empty: 2-1515                     [64]                      --
│    └─BatchNorm2d: 2-1516               [16, 64, 8, 8]            --
│    └─Scaler: 2-1517                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1518                      [16, 64, 8, 8]            --
│    └─Empty: 2-1519                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1520                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1521                 [16, 64, 4, 4]            --
│    └─Empty: 2-1522                     [16, 64, 4, 4]            --
│    └─Empty: 2-1523                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1524        --                        --
│    └─One: 2-1525                       [1]                       --
│    └─OutputScale: 2-1526               --                        --
│    └─Empty: 2-1527                     [64, 64, 3, 3]            --
│    └─Empty: 2-1528                     [64, 64, 3, 3]            --
│    └─Empty: 2-1529                     [64]                      --
│    └─Empty: 2-1530                     [64]                      --
│    └─BatchNorm2d: 2-1531               [16, 64, 4, 4]            --
│    └─Scaler: 2-1532                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1533                      [16, 64, 4, 4]            --
│    └─Empty: 2-1534                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1535                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1536        --                        --
│    └─One: 2-1537                       [1]                       --
│    └─OutputScale: 2-1538               --                        --
│    └─Empty: 2-1539                     [64, 64, 1, 1]            --
│    └─Empty: 2-1540                     [64, 64, 1, 1]            --
│    └─Empty: 2-1541                     [64]                      --
│    └─Empty: 2-1542                     [64]                      --
│    └─BatchNorm2d: 2-1543               [16, 64, 4, 4]            --
│    └─Scaler: 2-1544                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1545                      [16, 64, 4, 4]            --
│    └─Empty: 2-1546                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1547                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1548                 [16, 64, 4, 4]            --
│    └─Empty: 2-1549                     [16, 64, 4, 4]            --
│    └─Empty: 2-1550                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1551        --                        --
│    └─One: 2-1552                       [1]                       --
│    └─OutputScale: 2-1553               --                        --
│    └─Empty: 2-1554                     [64, 64, 3, 3]            --
│    └─Empty: 2-1555                     [64, 64, 3, 3]            --
│    └─Empty: 2-1556                     [64]                      --
│    └─Empty: 2-1557                     [64]                      --
│    └─BatchNorm2d: 2-1558               [16, 64, 4, 4]            --
│    └─Scaler: 2-1559                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1560                      [16, 64, 4, 4]            --
│    └─Empty: 2-1561                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1562                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1563                 [16, 64, 2, 2]            --
│    └─Empty: 2-1564                     [16, 64, 2, 2]            --
│    └─Empty: 2-1565                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1566        --                        --
│    └─One: 2-1567                       [1]                       --
│    └─OutputScale: 2-1568               --                        --
│    └─Empty: 2-1569                     [64, 64, 1, 1]            --
│    └─Empty: 2-1570                     [64, 64, 1, 1]            --
│    └─Empty: 2-1571                     [64]                      --
│    └─Empty: 2-1572                     [64]                      --
│    └─BatchNorm2d: 2-1573               [16, 64, 2, 2]            --
│    └─Scaler: 2-1574                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1575                      [16, 64, 2, 2]            --
│    └─Empty: 2-1576                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1577                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1578        --                        --
│    └─One: 2-1579                       [1]                       --
│    └─OutputScale: 2-1580               --                        --
│    └─Empty: 2-1581                     [64, 64, 1, 1]            --
│    └─Empty: 2-1582                     [64, 64, 1, 1]            --
│    └─Empty: 2-1583                     [64]                      --
│    └─Empty: 2-1584                     [64]                      --
│    └─BatchNorm2d: 2-1585               [16, 64, 2, 2]            --
│    └─Scaler: 2-1586                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1587                      [16, 64, 2, 2]            --
│    └─Empty: 2-1588                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1589                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1590                 [16, 64, 2, 2]            --
│    └─Empty: 2-1591                     [16, 64, 2, 2]            --
│    └─Empty: 2-1592                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1593        --                        --
│    └─One: 2-1594                       [1]                       --
│    └─OutputScale: 2-1595               --                        --
│    └─Empty: 2-1596                     [64, 64, 3, 3]            --
│    └─Empty: 2-1597                     [64, 64, 3, 3]            --
│    └─Empty: 2-1598                     [64]                      --
│    └─Empty: 2-1599                     [64]                      --
│    └─BatchNorm2d: 2-1600               [16, 64, 2, 2]            --
│    └─Scaler: 2-1601                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1602                      [16, 64, 2, 2]            --
│    └─Empty: 2-1603                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1604                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1605        --                        --
│    └─One: 2-1606                       [1]                       --
│    └─OutputScale: 2-1607               --                        --
│    └─Empty: 2-1608                     [64, 48, 1, 1]            --
│    └─Empty: 2-1609                     [64, 48, 1, 1]            --
│    └─Empty: 2-1610                     [64]                      --
│    └─Empty: 2-1611                     [64]                      --
│    └─BatchNorm2d: 2-1612               [16, 64, 64, 64]          --
│    └─Scaler: 2-1613                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1614                      [16, 64, 64, 64]          --
│    └─Empty: 2-1615                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1616                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1617        --                        --
│    └─One: 2-1618                       [1]                       --
│    └─OutputScale: 2-1619               --                        --
│    └─Empty: 2-1620                     [64, 64, 3, 3]            --
│    └─Empty: 2-1621                     [64, 64, 3, 3]            --
│    └─Empty: 2-1622                     [64]                      --
│    └─Empty: 2-1623                     [64]                      --
│    └─BatchNorm2d: 2-1624               [16, 64, 64, 64]          --
│    └─Scaler: 2-1625                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1626                      [16, 64, 64, 64]          --
│    └─Empty: 2-1627                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1628                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [64, 64, 1, 1]            --
│    └─Empty: 2-1633                     [64, 64, 1, 1]            --
│    └─Empty: 2-1634                     [64]                      --
│    └─Empty: 2-1635                     [64]                      --
│    └─BatchNorm2d: 2-1636               [16, 64, 64, 64]          --
│    └─Scaler: 2-1637                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1638                      [16, 64, 64, 64]          --
│    └─Empty: 2-1639                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1640                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [64, 64, 3, 3]            --
│    └─Empty: 2-1645                     [64, 64, 3, 3]            --
│    └─Empty: 2-1646                     [64]                      --
│    └─Empty: 2-1647                     [64]                      --
│    └─BatchNorm2d: 2-1648               [16, 64, 64, 64]          --
│    └─Scaler: 2-1649                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1650                      [16, 64, 64, 64]          --
│    └─Empty: 2-1651                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1652                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1653                 [16, 64, 32, 32]          --
│    └─Empty: 2-1654                     [16, 64, 32, 32]          --
│    └─Empty: 2-1655                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [64, 64, 3, 3]            --
│    └─Empty: 2-1660                     [64, 64, 3, 3]            --
│    └─Empty: 2-1661                     [64]                      --
│    └─Empty: 2-1662                     [64]                      --
│    └─BatchNorm2d: 2-1663               [16, 64, 32, 32]          --
│    └─Scaler: 2-1664                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1665                      [16, 64, 32, 32]          --
│    └─Empty: 2-1666                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1667                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1668        --                        --
│    └─One: 2-1669                       [1]                       --
│    └─OutputScale: 2-1670               --                        --
│    └─Empty: 2-1671                     [64, 64, 3, 3]            --
│    └─Empty: 2-1672                     [64, 64, 3, 3]            --
│    └─Empty: 2-1673                     [64]                      --
│    └─Empty: 2-1674                     [64]                      --
│    └─BatchNorm2d: 2-1675               [16, 64, 32, 32]          --
│    └─Scaler: 2-1676                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1677                      [16, 64, 32, 32]          --
│    └─Empty: 2-1678                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1679                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1680                 [16, 64, 16, 16]          --
│    └─Empty: 2-1681                     [16, 64, 16, 16]          --
│    └─Empty: 2-1682                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [64, 64, 3, 3]            --
│    └─Empty: 2-1687                     [64, 64, 3, 3]            --
│    └─Empty: 2-1688                     [64]                      --
│    └─Empty: 2-1689                     [64]                      --
│    └─BatchNorm2d: 2-1690               [16, 64, 16, 16]          --
│    └─Scaler: 2-1691                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1692                      [16, 64, 16, 16]          --
│    └─Empty: 2-1693                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1694                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1695        --                        --
│    └─One: 2-1696                       [1]                       --
│    └─OutputScale: 2-1697               --                        --
│    └─Empty: 2-1698                     [64, 64, 3, 3]            --
│    └─Empty: 2-1699                     [64, 64, 3, 3]            --
│    └─Empty: 2-1700                     [64]                      --
│    └─Empty: 2-1701                     [64]                      --
│    └─BatchNorm2d: 2-1702               [16, 64, 16, 16]          --
│    └─Scaler: 2-1703                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1704                      [16, 64, 16, 16]          --
│    └─Empty: 2-1705                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1706                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1707                 [16, 64, 8, 8]            --
│    └─Empty: 2-1708                     [16, 64, 8, 8]            --
│    └─Empty: 2-1709                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [64, 64, 3, 3]            --
│    └─Empty: 2-1714                     [64, 64, 3, 3]            --
│    └─Empty: 2-1715                     [64]                      --
│    └─Empty: 2-1716                     [64]                      --
│    └─BatchNorm2d: 2-1717               [16, 64, 8, 8]            --
│    └─Scaler: 2-1718                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1719                      [16, 64, 8, 8]            --
│    └─Empty: 2-1720                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1721                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1722        --                        --
│    └─One: 2-1723                       [1]                       --
│    └─OutputScale: 2-1724               --                        --
│    └─Empty: 2-1725                     [64, 64, 1, 1]            --
│    └─Empty: 2-1726                     [64, 64, 1, 1]            --
│    └─Empty: 2-1727                     [64]                      --
│    └─Empty: 2-1728                     [64]                      --
│    └─BatchNorm2d: 2-1729               [16, 64, 8, 8]            --
│    └─Scaler: 2-1730                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1731                      [16, 64, 8, 8]            --
│    └─Empty: 2-1732                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1733                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1734                 [16, 64, 8, 8]            --
│    └─Empty: 2-1735                     [16, 64, 8, 8]            --
│    └─Empty: 2-1736                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1737        --                        --
│    └─One: 2-1738                       [1]                       --
│    └─OutputScale: 2-1739               --                        --
│    └─Empty: 2-1740                     [64, 64, 3, 3]            --
│    └─Empty: 2-1741                     [64, 64, 3, 3]            --
│    └─Empty: 2-1742                     [64]                      --
│    └─Empty: 2-1743                     [64]                      --
│    └─BatchNorm2d: 2-1744               [16, 64, 8, 8]            --
│    └─Scaler: 2-1745                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1746                      [16, 64, 8, 8]            --
│    └─Empty: 2-1747                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1748                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1749                 [16, 64, 4, 4]            --
│    └─Empty: 2-1750                     [16, 64, 4, 4]            --
│    └─Empty: 2-1751                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1752        --                        --
│    └─One: 2-1753                       [1]                       --
│    └─OutputScale: 2-1754               --                        --
│    └─Empty: 2-1755                     [64, 64, 3, 3]            --
│    └─Empty: 2-1756                     [64, 64, 3, 3]            --
│    └─Empty: 2-1757                     [64]                      --
│    └─Empty: 2-1758                     [64]                      --
│    └─BatchNorm2d: 2-1759               [16, 64, 4, 4]            --
│    └─Scaler: 2-1760                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1761                      [16, 64, 4, 4]            --
│    └─Empty: 2-1762                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1763                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1764        --                        --
│    └─One: 2-1765                       [1]                       --
│    └─OutputScale: 2-1766               --                        --
│    └─Empty: 2-1767                     [64, 64, 1, 1]            --
│    └─Empty: 2-1768                     [64, 64, 1, 1]            --
│    └─Empty: 2-1769                     [64]                      --
│    └─Empty: 2-1770                     [64]                      --
│    └─BatchNorm2d: 2-1771               [16, 64, 4, 4]            --
│    └─Scaler: 2-1772                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1773                      [16, 64, 4, 4]            --
│    └─Empty: 2-1774                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1775                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1776                 [16, 64, 4, 4]            --
│    └─Empty: 2-1777                     [16, 64, 4, 4]            --
│    └─Empty: 2-1778                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1779        --                        --
│    └─One: 2-1780                       [1]                       --
│    └─OutputScale: 2-1781               --                        --
│    └─Empty: 2-1782                     [64, 64, 3, 3]            --
│    └─Empty: 2-1783                     [64, 64, 3, 3]            --
│    └─Empty: 2-1784                     [64]                      --
│    └─Empty: 2-1785                     [64]                      --
│    └─BatchNorm2d: 2-1786               [16, 64, 4, 4]            --
│    └─Scaler: 2-1787                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1788                      [16, 64, 4, 4]            --
│    └─Empty: 2-1789                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1790                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1791                 [16, 64, 2, 2]            --
│    └─Empty: 2-1792                     [16, 64, 2, 2]            --
│    └─Empty: 2-1793                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1794        --                        --
│    └─One: 2-1795                       [1]                       --
│    └─OutputScale: 2-1796               --                        --
│    └─Empty: 2-1797                     [64, 64, 1, 1]            --
│    └─Empty: 2-1798                     [64, 64, 1, 1]            --
│    └─Empty: 2-1799                     [64]                      --
│    └─Empty: 2-1800                     [64]                      --
│    └─BatchNorm2d: 2-1801               [16, 64, 2, 2]            --
│    └─Scaler: 2-1802                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1803                      [16, 64, 2, 2]            --
│    └─Empty: 2-1804                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1805                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1806        --                        --
│    └─One: 2-1807                       [1]                       --
│    └─OutputScale: 2-1808               --                        --
│    └─Empty: 2-1809                     [64, 64, 1, 1]            --
│    └─Empty: 2-1810                     [64, 64, 1, 1]            --
│    └─Empty: 2-1811                     [64]                      --
│    └─Empty: 2-1812                     [64]                      --
│    └─BatchNorm2d: 2-1813               [16, 64, 2, 2]            --
│    └─Scaler: 2-1814                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1815                      [16, 64, 2, 2]            --
│    └─Empty: 2-1816                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1817                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1818                 [16, 64, 2, 2]            --
│    └─Empty: 2-1819                     [16, 64, 2, 2]            --
│    └─Empty: 2-1820                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [64, 64, 3, 3]            --
│    └─Empty: 2-1825                     [64, 64, 3, 3]            --
│    └─Empty: 2-1826                     [64]                      --
│    └─Empty: 2-1827                     [64]                      --
│    └─BatchNorm2d: 2-1828               [16, 64, 2, 2]            --
│    └─Scaler: 2-1829                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1830                      [16, 64, 2, 2]            --
│    └─Empty: 2-1831                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1832                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1833        --                        --
│    └─One: 2-1834                       [1]                       --
│    └─OutputScale: 2-1835               --                        --
│    └─Empty: 2-1836                     [64, 48, 1, 1]            --
│    └─Empty: 2-1837                     [64, 48, 1, 1]            --
│    └─Empty: 2-1838                     [64]                      --
│    └─Empty: 2-1839                     [64]                      --
│    └─BatchNorm2d: 2-1840               [16, 64, 64, 64]          --
│    └─Scaler: 2-1841                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1842                      [16, 64, 64, 64]          --
│    └─Empty: 2-1843                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1844                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1845        --                        --
│    └─One: 2-1846                       [1]                       --
│    └─OutputScale: 2-1847               --                        --
│    └─Empty: 2-1848                     [64, 64, 3, 3]            --
│    └─Empty: 2-1849                     [64, 64, 3, 3]            --
│    └─Empty: 2-1850                     [64]                      --
│    └─Empty: 2-1851                     [64]                      --
│    └─BatchNorm2d: 2-1852               [16, 64, 64, 64]          --
│    └─Scaler: 2-1853                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1854                      [16, 64, 64, 64]          --
│    └─Empty: 2-1855                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1856                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1857        --                        --
│    └─One: 2-1858                       [1]                       --
│    └─OutputScale: 2-1859               --                        --
│    └─Empty: 2-1860                     [64, 64, 1, 1]            --
│    └─Empty: 2-1861                     [64, 64, 1, 1]            --
│    └─Empty: 2-1862                     [64]                      --
│    └─Empty: 2-1863                     [64]                      --
│    └─BatchNorm2d: 2-1864               [16, 64, 64, 64]          --
│    └─Scaler: 2-1865                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1866                      [16, 64, 64, 64]          --
│    └─Empty: 2-1867                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1868                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1869        --                        --
│    └─One: 2-1870                       [1]                       --
│    └─OutputScale: 2-1871               --                        --
│    └─Empty: 2-1872                     [64, 64, 3, 3]            --
│    └─Empty: 2-1873                     [64, 64, 3, 3]            --
│    └─Empty: 2-1874                     [64]                      --
│    └─Empty: 2-1875                     [64]                      --
│    └─BatchNorm2d: 2-1876               [16, 64, 64, 64]          --
│    └─Scaler: 2-1877                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1878                      [16, 64, 64, 64]          --
│    └─Empty: 2-1879                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1880                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1881                 [16, 64, 32, 32]          --
│    └─Empty: 2-1882                     [16, 64, 32, 32]          --
│    └─Empty: 2-1883                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1884        --                        --
│    └─One: 2-1885                       [1]                       --
│    └─OutputScale: 2-1886               --                        --
│    └─Empty: 2-1887                     [64, 64, 3, 3]            --
│    └─Empty: 2-1888                     [64, 64, 3, 3]            --
│    └─Empty: 2-1889                     [64]                      --
│    └─Empty: 2-1890                     [64]                      --
│    └─BatchNorm2d: 2-1891               [16, 64, 32, 32]          --
│    └─Scaler: 2-1892                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1893                      [16, 64, 32, 32]          --
│    └─Empty: 2-1894                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1895                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1896        --                        --
│    └─One: 2-1897                       [1]                       --
│    └─OutputScale: 2-1898               --                        --
│    └─Empty: 2-1899                     [64, 64, 3, 3]            --
│    └─Empty: 2-1900                     [64, 64, 3, 3]            --
│    └─Empty: 2-1901                     [64]                      --
│    └─Empty: 2-1902                     [64]                      --
│    └─BatchNorm2d: 2-1903               [16, 64, 32, 32]          --
│    └─Scaler: 2-1904                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1905                      [16, 64, 32, 32]          --
│    └─Empty: 2-1906                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1907                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1908                 [16, 64, 16, 16]          --
│    └─Empty: 2-1909                     [16, 64, 16, 16]          --
│    └─Empty: 2-1910                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1911        --                        --
│    └─One: 2-1912                       [1]                       --
│    └─OutputScale: 2-1913               --                        --
│    └─Empty: 2-1914                     [64, 64, 3, 3]            --
│    └─Empty: 2-1915                     [64, 64, 3, 3]            --
│    └─Empty: 2-1916                     [64]                      --
│    └─Empty: 2-1917                     [64]                      --
│    └─BatchNorm2d: 2-1918               [16, 64, 16, 16]          --
│    └─Scaler: 2-1919                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1920                      [16, 64, 16, 16]          --
│    └─Empty: 2-1921                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1922                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1923        --                        --
│    └─One: 2-1924                       [1]                       --
│    └─OutputScale: 2-1925               --                        --
│    └─Empty: 2-1926                     [64, 64, 3, 3]            --
│    └─Empty: 2-1927                     [64, 64, 3, 3]            --
│    └─Empty: 2-1928                     [64]                      --
│    └─Empty: 2-1929                     [64]                      --
│    └─BatchNorm2d: 2-1930               [16, 64, 16, 16]          --
│    └─Scaler: 2-1931                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1932                      [16, 64, 16, 16]          --
│    └─Empty: 2-1933                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1934                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1935                 [16, 64, 8, 8]            --
│    └─Empty: 2-1936                     [16, 64, 8, 8]            --
│    └─Empty: 2-1937                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1938        --                        --
│    └─One: 2-1939                       [1]                       --
│    └─OutputScale: 2-1940               --                        --
│    └─Empty: 2-1941                     [64, 64, 3, 3]            --
│    └─Empty: 2-1942                     [64, 64, 3, 3]            --
│    └─Empty: 2-1943                     [64]                      --
│    └─Empty: 2-1944                     [64]                      --
│    └─BatchNorm2d: 2-1945               [16, 64, 8, 8]            --
│    └─Scaler: 2-1946                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1947                      [16, 64, 8, 8]            --
│    └─Empty: 2-1948                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1949                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1950        --                        --
│    └─One: 2-1951                       [1]                       --
│    └─OutputScale: 2-1952               --                        --
│    └─Empty: 2-1953                     [64, 64, 1, 1]            --
│    └─Empty: 2-1954                     [64, 64, 1, 1]            --
│    └─Empty: 2-1955                     [64]                      --
│    └─Empty: 2-1956                     [64]                      --
│    └─BatchNorm2d: 2-1957               [16, 64, 8, 8]            --
│    └─Scaler: 2-1958                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1959                      [16, 64, 8, 8]            --
│    └─Empty: 2-1960                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1961                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1962                 [16, 64, 8, 8]            --
│    └─Empty: 2-1963                     [16, 64, 8, 8]            --
│    └─Empty: 2-1964                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1965        --                        --
│    └─One: 2-1966                       [1]                       --
│    └─OutputScale: 2-1967               --                        --
│    └─Empty: 2-1968                     [64, 64, 3, 3]            --
│    └─Empty: 2-1969                     [64, 64, 3, 3]            --
│    └─Empty: 2-1970                     [64]                      --
│    └─Empty: 2-1971                     [64]                      --
│    └─BatchNorm2d: 2-1972               [16, 64, 8, 8]            --
│    └─Scaler: 2-1973                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1974                      [16, 64, 8, 8]            --
│    └─Empty: 2-1975                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1976                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1977                 [16, 64, 4, 4]            --
│    └─Empty: 2-1978                     [16, 64, 4, 4]            --
│    └─Empty: 2-1979                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1980        --                        --
│    └─One: 2-1981                       [1]                       --
│    └─OutputScale: 2-1982               --                        --
│    └─Empty: 2-1983                     [64, 64, 3, 3]            --
│    └─Empty: 2-1984                     [64, 64, 3, 3]            --
│    └─Empty: 2-1985                     [64]                      --
│    └─Empty: 2-1986                     [64]                      --
│    └─BatchNorm2d: 2-1987               [16, 64, 4, 4]            --
│    └─Scaler: 2-1988                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1989                      [16, 64, 4, 4]            --
│    └─Empty: 2-1990                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1991                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1992        --                        --
│    └─One: 2-1993                       [1]                       --
│    └─OutputScale: 2-1994               --                        --
│    └─Empty: 2-1995                     [64, 64, 1, 1]            --
│    └─Empty: 2-1996                     [64, 64, 1, 1]            --
│    └─Empty: 2-1997                     [64]                      --
│    └─Empty: 2-1998                     [64]                      --
│    └─BatchNorm2d: 2-1999               [16, 64, 4, 4]            --
│    └─Scaler: 2-2000                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2001                      [16, 64, 4, 4]            --
│    └─Empty: 2-2002                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2003                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2004                 [16, 64, 4, 4]            --
│    └─Empty: 2-2005                     [16, 64, 4, 4]            --
│    └─Empty: 2-2006                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2007        --                        --
│    └─One: 2-2008                       [1]                       --
│    └─OutputScale: 2-2009               --                        --
│    └─Empty: 2-2010                     [64, 64, 3, 3]            --
│    └─Empty: 2-2011                     [64, 64, 3, 3]            --
│    └─Empty: 2-2012                     [64]                      --
│    └─Empty: 2-2013                     [64]                      --
│    └─BatchNorm2d: 2-2014               [16, 64, 4, 4]            --
│    └─Scaler: 2-2015                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2016                      [16, 64, 4, 4]            --
│    └─Empty: 2-2017                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2018                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2019                 [16, 64, 2, 2]            --
│    └─Empty: 2-2020                     [16, 64, 2, 2]            --
│    └─Empty: 2-2021                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2022        --                        --
│    └─One: 2-2023                       [1]                       --
│    └─OutputScale: 2-2024               --                        --
│    └─Empty: 2-2025                     [64, 64, 1, 1]            --
│    └─Empty: 2-2026                     [64, 64, 1, 1]            --
│    └─Empty: 2-2027                     [64]                      --
│    └─Empty: 2-2028                     [64]                      --
│    └─BatchNorm2d: 2-2029               [16, 64, 2, 2]            --
│    └─Scaler: 2-2030                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2031                      [16, 64, 2, 2]            --
│    └─Empty: 2-2032                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2033                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2034        --                        --
│    └─One: 2-2035                       [1]                       --
│    └─OutputScale: 2-2036               --                        --
│    └─Empty: 2-2037                     [64, 64, 1, 1]            --
│    └─Empty: 2-2038                     [64, 64, 1, 1]            --
│    └─Empty: 2-2039                     [64]                      --
│    └─Empty: 2-2040                     [64]                      --
│    └─BatchNorm2d: 2-2041               [16, 64, 2, 2]            --
│    └─Scaler: 2-2042                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2043                      [16, 64, 2, 2]            --
│    └─Empty: 2-2044                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2045                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2046                 [16, 64, 2, 2]            --
│    └─Empty: 2-2047                     [16, 64, 2, 2]            --
│    └─Empty: 2-2048                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2049        --                        --
│    └─One: 2-2050                       [1]                       --
│    └─OutputScale: 2-2051               --                        --
│    └─Empty: 2-2052                     [64, 64, 3, 3]            --
│    └─Empty: 2-2053                     [64, 64, 3, 3]            --
│    └─Empty: 2-2054                     [64]                      --
│    └─Empty: 2-2055                     [64]                      --
│    └─BatchNorm2d: 2-2056               [16, 64, 2, 2]            --
│    └─Scaler: 2-2057                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2058                      [16, 64, 2, 2]            --
│    └─Empty: 2-2059                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2060                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2061        --                        --
│    └─One: 2-2062                       [1]                       --
│    └─OutputScale: 2-2063               --                        --
│    └─Empty: 2-2064                     [64, 48, 1, 1]            --
│    └─Empty: 2-2065                     [64, 48, 1, 1]            --
│    └─Empty: 2-2066                     [64]                      --
│    └─Empty: 2-2067                     [64]                      --
│    └─BatchNorm2d: 2-2068               [16, 64, 64, 64]          --
│    └─Scaler: 2-2069                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2070                      [16, 64, 64, 64]          --
│    └─Empty: 2-2071                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2072                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2073        --                        --
│    └─One: 2-2074                       [1]                       --
│    └─OutputScale: 2-2075               --                        --
│    └─Empty: 2-2076                     [64, 64, 3, 3]            --
│    └─Empty: 2-2077                     [64, 64, 3, 3]            --
│    └─Empty: 2-2078                     [64]                      --
│    └─Empty: 2-2079                     [64]                      --
│    └─BatchNorm2d: 2-2080               [16, 64, 64, 64]          --
│    └─Scaler: 2-2081                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2082                      [16, 64, 64, 64]          --
│    └─Empty: 2-2083                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2084                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2085        --                        --
│    └─One: 2-2086                       [1]                       --
│    └─OutputScale: 2-2087               --                        --
│    └─Empty: 2-2088                     [64, 64, 1, 1]            --
│    └─Empty: 2-2089                     [64, 64, 1, 1]            --
│    └─Empty: 2-2090                     [64]                      --
│    └─Empty: 2-2091                     [64]                      --
│    └─BatchNorm2d: 2-2092               [16, 64, 64, 64]          --
│    └─Scaler: 2-2093                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2094                      [16, 64, 64, 64]          --
│    └─Empty: 2-2095                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2096                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2097        --                        --
│    └─One: 2-2098                       [1]                       --
│    └─OutputScale: 2-2099               --                        --
│    └─Empty: 2-2100                     [64, 64, 3, 3]            --
│    └─Empty: 2-2101                     [64, 64, 3, 3]            --
│    └─Empty: 2-2102                     [64]                      --
│    └─Empty: 2-2103                     [64]                      --
│    └─BatchNorm2d: 2-2104               [16, 64, 64, 64]          --
│    └─Scaler: 2-2105                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2106                      [16, 64, 64, 64]          --
│    └─Empty: 2-2107                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2108                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2109                 [16, 64, 32, 32]          --
│    └─Empty: 2-2110                     [16, 64, 32, 32]          --
│    └─Empty: 2-2111                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2112        --                        --
│    └─One: 2-2113                       [1]                       --
│    └─OutputScale: 2-2114               --                        --
│    └─Empty: 2-2115                     [64, 64, 3, 3]            --
│    └─Empty: 2-2116                     [64, 64, 3, 3]            --
│    └─Empty: 2-2117                     [64]                      --
│    └─Empty: 2-2118                     [64]                      --
│    └─BatchNorm2d: 2-2119               [16, 64, 32, 32]          --
│    └─Scaler: 2-2120                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2121                      [16, 64, 32, 32]          --
│    └─Empty: 2-2122                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2123                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2124        --                        --
│    └─One: 2-2125                       [1]                       --
│    └─OutputScale: 2-2126               --                        --
│    └─Empty: 2-2127                     [64, 64, 3, 3]            --
│    └─Empty: 2-2128                     [64, 64, 3, 3]            --
│    └─Empty: 2-2129                     [64]                      --
│    └─Empty: 2-2130                     [64]                      --
│    └─BatchNorm2d: 2-2131               [16, 64, 32, 32]          --
│    └─Scaler: 2-2132                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2133                      [16, 64, 32, 32]          --
│    └─Empty: 2-2134                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2135                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2136                 [16, 64, 16, 16]          --
│    └─Empty: 2-2137                     [16, 64, 16, 16]          --
│    └─Empty: 2-2138                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2139        --                        --
│    └─One: 2-2140                       [1]                       --
│    └─OutputScale: 2-2141               --                        --
│    └─Empty: 2-2142                     [64, 64, 3, 3]            --
│    └─Empty: 2-2143                     [64, 64, 3, 3]            --
│    └─Empty: 2-2144                     [64]                      --
│    └─Empty: 2-2145                     [64]                      --
│    └─BatchNorm2d: 2-2146               [16, 64, 16, 16]          --
│    └─Scaler: 2-2147                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2148                      [16, 64, 16, 16]          --
│    └─Empty: 2-2149                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2150                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2151        --                        --
│    └─One: 2-2152                       [1]                       --
│    └─OutputScale: 2-2153               --                        --
│    └─Empty: 2-2154                     [64, 64, 3, 3]            --
│    └─Empty: 2-2155                     [64, 64, 3, 3]            --
│    └─Empty: 2-2156                     [64]                      --
│    └─Empty: 2-2157                     [64]                      --
│    └─BatchNorm2d: 2-2158               [16, 64, 16, 16]          --
│    └─Scaler: 2-2159                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2160                      [16, 64, 16, 16]          --
│    └─Empty: 2-2161                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2162                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2163                 [16, 64, 8, 8]            --
│    └─Empty: 2-2164                     [16, 64, 8, 8]            --
│    └─Empty: 2-2165                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2166        --                        --
│    └─One: 2-2167                       [1]                       --
│    └─OutputScale: 2-2168               --                        --
│    └─Empty: 2-2169                     [64, 64, 3, 3]            --
│    └─Empty: 2-2170                     [64, 64, 3, 3]            --
│    └─Empty: 2-2171                     [64]                      --
│    └─Empty: 2-2172                     [64]                      --
│    └─BatchNorm2d: 2-2173               [16, 64, 8, 8]            --
│    └─Scaler: 2-2174                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2175                      [16, 64, 8, 8]            --
│    └─Empty: 2-2176                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2177                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2178        --                        --
│    └─One: 2-2179                       [1]                       --
│    └─OutputScale: 2-2180               --                        --
│    └─Empty: 2-2181                     [64, 64, 1, 1]            --
│    └─Empty: 2-2182                     [64, 64, 1, 1]            --
│    └─Empty: 2-2183                     [64]                      --
│    └─Empty: 2-2184                     [64]                      --
│    └─BatchNorm2d: 2-2185               [16, 64, 8, 8]            --
│    └─Scaler: 2-2186                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2187                      [16, 64, 8, 8]            --
│    └─Empty: 2-2188                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2189                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2190                 [16, 64, 8, 8]            --
│    └─Empty: 2-2191                     [16, 64, 8, 8]            --
│    └─Empty: 2-2192                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2193        --                        --
│    └─One: 2-2194                       [1]                       --
│    └─OutputScale: 2-2195               --                        --
│    └─Empty: 2-2196                     [64, 64, 3, 3]            --
│    └─Empty: 2-2197                     [64, 64, 3, 3]            --
│    └─Empty: 2-2198                     [64]                      --
│    └─Empty: 2-2199                     [64]                      --
│    └─BatchNorm2d: 2-2200               [16, 64, 8, 8]            --
│    └─Scaler: 2-2201                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2202                      [16, 64, 8, 8]            --
│    └─Empty: 2-2203                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2204                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2205                 [16, 64, 4, 4]            --
│    └─Empty: 2-2206                     [16, 64, 4, 4]            --
│    └─Empty: 2-2207                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2208        --                        --
│    └─One: 2-2209                       [1]                       --
│    └─OutputScale: 2-2210               --                        --
│    └─Empty: 2-2211                     [64, 64, 3, 3]            --
│    └─Empty: 2-2212                     [64, 64, 3, 3]            --
│    └─Empty: 2-2213                     [64]                      --
│    └─Empty: 2-2214                     [64]                      --
│    └─BatchNorm2d: 2-2215               [16, 64, 4, 4]            --
│    └─Scaler: 2-2216                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2217                      [16, 64, 4, 4]            --
│    └─Empty: 2-2218                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2219                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2220        --                        --
│    └─One: 2-2221                       [1]                       --
│    └─OutputScale: 2-2222               --                        --
│    └─Empty: 2-2223                     [64, 64, 1, 1]            --
│    └─Empty: 2-2224                     [64, 64, 1, 1]            --
│    └─Empty: 2-2225                     [64]                      --
│    └─Empty: 2-2226                     [64]                      --
│    └─BatchNorm2d: 2-2227               [16, 64, 4, 4]            --
│    └─Scaler: 2-2228                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2229                      [16, 64, 4, 4]            --
│    └─Empty: 2-2230                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2231                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2232                 [16, 64, 4, 4]            --
│    └─Empty: 2-2233                     [16, 64, 4, 4]            --
│    └─Empty: 2-2234                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2235        --                        --
│    └─One: 2-2236                       [1]                       --
│    └─OutputScale: 2-2237               --                        --
│    └─Empty: 2-2238                     [64, 64, 3, 3]            --
│    └─Empty: 2-2239                     [64, 64, 3, 3]            --
│    └─Empty: 2-2240                     [64]                      --
│    └─Empty: 2-2241                     [64]                      --
│    └─BatchNorm2d: 2-2242               [16, 64, 4, 4]            --
│    └─Scaler: 2-2243                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2244                      [16, 64, 4, 4]            --
│    └─Empty: 2-2245                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2246                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2247                 [16, 64, 2, 2]            --
│    └─Empty: 2-2248                     [16, 64, 2, 2]            --
│    └─Empty: 2-2249                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2250        --                        --
│    └─One: 2-2251                       [1]                       --
│    └─OutputScale: 2-2252               --                        --
│    └─Empty: 2-2253                     [64, 64, 1, 1]            --
│    └─Empty: 2-2254                     [64, 64, 1, 1]            --
│    └─Empty: 2-2255                     [64]                      --
│    └─Empty: 2-2256                     [64]                      --
│    └─BatchNorm2d: 2-2257               [16, 64, 2, 2]            --
│    └─Scaler: 2-2258                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2259                      [16, 64, 2, 2]            --
│    └─Empty: 2-2260                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2261                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2262        --                        --
│    └─One: 2-2263                       [1]                       --
│    └─OutputScale: 2-2264               --                        --
│    └─Empty: 2-2265                     [64, 64, 1, 1]            --
│    └─Empty: 2-2266                     [64, 64, 1, 1]            --
│    └─Empty: 2-2267                     [64]                      --
│    └─Empty: 2-2268                     [64]                      --
│    └─BatchNorm2d: 2-2269               [16, 64, 2, 2]            --
│    └─Scaler: 2-2270                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2271                      [16, 64, 2, 2]            --
│    └─Empty: 2-2272                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2273                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2274                 [16, 64, 2, 2]            --
│    └─Empty: 2-2275                     [16, 64, 2, 2]            --
│    └─Empty: 2-2276                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2277        --                        --
│    └─One: 2-2278                       [1]                       --
│    └─OutputScale: 2-2279               --                        --
│    └─Empty: 2-2280                     [64, 64, 3, 3]            --
│    └─Empty: 2-2281                     [64, 64, 3, 3]            --
│    └─Empty: 2-2282                     [64]                      --
│    └─Empty: 2-2283                     [64]                      --
│    └─BatchNorm2d: 2-2284               [16, 64, 2, 2]            --
│    └─Scaler: 2-2285                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2286                      [16, 64, 2, 2]            --
│    └─Empty: 2-2287                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2288                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2289        --                        --
│    └─One: 2-2290                       [1]                       --
│    └─OutputScale: 2-2291               --                        --
│    └─Empty: 2-2292                     [64, 48, 1, 1]            --
│    └─Empty: 2-2293                     [64, 48, 1, 1]            --
│    └─Empty: 2-2294                     [64]                      --
│    └─Empty: 2-2295                     [64]                      --
│    └─BatchNorm2d: 2-2296               [16, 64, 64, 64]          --
│    └─Scaler: 2-2297                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2298                      [16, 64, 64, 64]          --
│    └─Empty: 2-2299                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2300                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2301        --                        --
│    └─One: 2-2302                       [1]                       --
│    └─OutputScale: 2-2303               --                        --
│    └─Empty: 2-2304                     [64, 64, 3, 3]            --
│    └─Empty: 2-2305                     [64, 64, 3, 3]            --
│    └─Empty: 2-2306                     [64]                      --
│    └─Empty: 2-2307                     [64]                      --
│    └─BatchNorm2d: 2-2308               [16, 64, 64, 64]          --
│    └─Scaler: 2-2309                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2310                      [16, 64, 64, 64]          --
│    └─Empty: 2-2311                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2312                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2313        --                        --
│    └─One: 2-2314                       [1]                       --
│    └─OutputScale: 2-2315               --                        --
│    └─Empty: 2-2316                     [64, 64, 1, 1]            --
│    └─Empty: 2-2317                     [64, 64, 1, 1]            --
│    └─Empty: 2-2318                     [64]                      --
│    └─Empty: 2-2319                     [64]                      --
│    └─BatchNorm2d: 2-2320               [16, 64, 64, 64]          --
│    └─Scaler: 2-2321                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2322                      [16, 64, 64, 64]          --
│    └─Empty: 2-2323                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2324                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2325        --                        --
│    └─One: 2-2326                       [1]                       --
│    └─OutputScale: 2-2327               --                        --
│    └─Empty: 2-2328                     [64, 64, 3, 3]            --
│    └─Empty: 2-2329                     [64, 64, 3, 3]            --
│    └─Empty: 2-2330                     [64]                      --
│    └─Empty: 2-2331                     [64]                      --
│    └─BatchNorm2d: 2-2332               [16, 64, 64, 64]          --
│    └─Scaler: 2-2333                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2334                      [16, 64, 64, 64]          --
│    └─Empty: 2-2335                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2336                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2337                 [16, 64, 32, 32]          --
│    └─Empty: 2-2338                     [16, 64, 32, 32]          --
│    └─Empty: 2-2339                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2340        --                        --
│    └─One: 2-2341                       [1]                       --
│    └─OutputScale: 2-2342               --                        --
│    └─Empty: 2-2343                     [64, 64, 3, 3]            --
│    └─Empty: 2-2344                     [64, 64, 3, 3]            --
│    └─Empty: 2-2345                     [64]                      --
│    └─Empty: 2-2346                     [64]                      --
│    └─BatchNorm2d: 2-2347               [16, 64, 32, 32]          --
│    └─Scaler: 2-2348                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2349                      [16, 64, 32, 32]          --
│    └─Empty: 2-2350                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2351                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2352        --                        --
│    └─One: 2-2353                       [1]                       --
│    └─OutputScale: 2-2354               --                        --
│    └─Empty: 2-2355                     [64, 64, 3, 3]            --
│    └─Empty: 2-2356                     [64, 64, 3, 3]            --
│    └─Empty: 2-2357                     [64]                      --
│    └─Empty: 2-2358                     [64]                      --
│    └─BatchNorm2d: 2-2359               [16, 64, 32, 32]          --
│    └─Scaler: 2-2360                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2361                      [16, 64, 32, 32]          --
│    └─Empty: 2-2362                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2363                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2364                 [16, 64, 16, 16]          --
│    └─Empty: 2-2365                     [16, 64, 16, 16]          --
│    └─Empty: 2-2366                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2367        --                        --
│    └─One: 2-2368                       [1]                       --
│    └─OutputScale: 2-2369               --                        --
│    └─Empty: 2-2370                     [64, 64, 3, 3]            --
│    └─Empty: 2-2371                     [64, 64, 3, 3]            --
│    └─Empty: 2-2372                     [64]                      --
│    └─Empty: 2-2373                     [64]                      --
│    └─BatchNorm2d: 2-2374               [16, 64, 16, 16]          --
│    └─Scaler: 2-2375                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2376                      [16, 64, 16, 16]          --
│    └─Empty: 2-2377                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2378                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2379        --                        --
│    └─One: 2-2380                       [1]                       --
│    └─OutputScale: 2-2381               --                        --
│    └─Empty: 2-2382                     [64, 64, 3, 3]            --
│    └─Empty: 2-2383                     [64, 64, 3, 3]            --
│    └─Empty: 2-2384                     [64]                      --
│    └─Empty: 2-2385                     [64]                      --
│    └─BatchNorm2d: 2-2386               [16, 64, 16, 16]          --
│    └─Scaler: 2-2387                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2388                      [16, 64, 16, 16]          --
│    └─Empty: 2-2389                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2390                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2391                 [16, 64, 8, 8]            --
│    └─Empty: 2-2392                     [16, 64, 8, 8]            --
│    └─Empty: 2-2393                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2394        --                        --
│    └─One: 2-2395                       [1]                       --
│    └─OutputScale: 2-2396               --                        --
│    └─Empty: 2-2397                     [64, 64, 3, 3]            --
│    └─Empty: 2-2398                     [64, 64, 3, 3]            --
│    └─Empty: 2-2399                     [64]                      --
│    └─Empty: 2-2400                     [64]                      --
│    └─BatchNorm2d: 2-2401               [16, 64, 8, 8]            --
│    └─Scaler: 2-2402                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2403                      [16, 64, 8, 8]            --
│    └─Empty: 2-2404                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2405                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2406        --                        --
│    └─One: 2-2407                       [1]                       --
│    └─OutputScale: 2-2408               --                        --
│    └─Empty: 2-2409                     [64, 64, 1, 1]            --
│    └─Empty: 2-2410                     [64, 64, 1, 1]            --
│    └─Empty: 2-2411                     [64]                      --
│    └─Empty: 2-2412                     [64]                      --
│    └─BatchNorm2d: 2-2413               [16, 64, 8, 8]            --
│    └─Scaler: 2-2414                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2415                      [16, 64, 8, 8]            --
│    └─Empty: 2-2416                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2417                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2418                 [16, 64, 8, 8]            --
│    └─Empty: 2-2419                     [16, 64, 8, 8]            --
│    └─Empty: 2-2420                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2421        --                        --
│    └─One: 2-2422                       [1]                       --
│    └─OutputScale: 2-2423               --                        --
│    └─Empty: 2-2424                     [64, 64, 3, 3]            --
│    └─Empty: 2-2425                     [64, 64, 3, 3]            --
│    └─Empty: 2-2426                     [64]                      --
│    └─Empty: 2-2427                     [64]                      --
│    └─BatchNorm2d: 2-2428               [16, 64, 8, 8]            --
│    └─Scaler: 2-2429                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2430                      [16, 64, 8, 8]            --
│    └─Empty: 2-2431                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2432                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2433                 [16, 64, 4, 4]            --
│    └─Empty: 2-2434                     [16, 64, 4, 4]            --
│    └─Empty: 2-2435                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2436        --                        --
│    └─One: 2-2437                       [1]                       --
│    └─OutputScale: 2-2438               --                        --
│    └─Empty: 2-2439                     [64, 64, 3, 3]            --
│    └─Empty: 2-2440                     [64, 64, 3, 3]            --
│    └─Empty: 2-2441                     [64]                      --
│    └─Empty: 2-2442                     [64]                      --
│    └─BatchNorm2d: 2-2443               [16, 64, 4, 4]            --
│    └─Scaler: 2-2444                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2445                      [16, 64, 4, 4]            --
│    └─Empty: 2-2446                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2447                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2448        --                        --
│    └─One: 2-2449                       [1]                       --
│    └─OutputScale: 2-2450               --                        --
│    └─Empty: 2-2451                     [64, 64, 1, 1]            --
│    └─Empty: 2-2452                     [64, 64, 1, 1]            --
│    └─Empty: 2-2453                     [64]                      --
│    └─Empty: 2-2454                     [64]                      --
│    └─BatchNorm2d: 2-2455               [16, 64, 4, 4]            --
│    └─Scaler: 2-2456                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2457                      [16, 64, 4, 4]            --
│    └─Empty: 2-2458                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2459                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2460                 [16, 64, 4, 4]            --
│    └─Empty: 2-2461                     [16, 64, 4, 4]            --
│    └─Empty: 2-2462                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2463        --                        --
│    └─One: 2-2464                       [1]                       --
│    └─OutputScale: 2-2465               --                        --
│    └─Empty: 2-2466                     [64, 64, 3, 3]            --
│    └─Empty: 2-2467                     [64, 64, 3, 3]            --
│    └─Empty: 2-2468                     [64]                      --
│    └─Empty: 2-2469                     [64]                      --
│    └─BatchNorm2d: 2-2470               [16, 64, 4, 4]            --
│    └─Scaler: 2-2471                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2472                      [16, 64, 4, 4]            --
│    └─Empty: 2-2473                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2474                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2475                 [16, 64, 2, 2]            --
│    └─Empty: 2-2476                     [16, 64, 2, 2]            --
│    └─Empty: 2-2477                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2478        --                        --
│    └─One: 2-2479                       [1]                       --
│    └─OutputScale: 2-2480               --                        --
│    └─Empty: 2-2481                     [64, 64, 1, 1]            --
│    └─Empty: 2-2482                     [64, 64, 1, 1]            --
│    └─Empty: 2-2483                     [64]                      --
│    └─Empty: 2-2484                     [64]                      --
│    └─BatchNorm2d: 2-2485               [16, 64, 2, 2]            --
│    └─Scaler: 2-2486                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2487                      [16, 64, 2, 2]            --
│    └─Empty: 2-2488                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2489                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2490        --                        --
│    └─One: 2-2491                       [1]                       --
│    └─OutputScale: 2-2492               --                        --
│    └─Empty: 2-2493                     [64, 64, 1, 1]            --
│    └─Empty: 2-2494                     [64, 64, 1, 1]            --
│    └─Empty: 2-2495                     [64]                      --
│    └─Empty: 2-2496                     [64]                      --
│    └─BatchNorm2d: 2-2497               [16, 64, 2, 2]            --
│    └─Scaler: 2-2498                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2499                      [16, 64, 2, 2]            --
│    └─Empty: 2-2500                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2501                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2502                 [16, 64, 2, 2]            --
│    └─Empty: 2-2503                     [16, 64, 2, 2]            --
│    └─Empty: 2-2504                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2505        --                        --
│    └─One: 2-2506                       [1]                       --
│    └─OutputScale: 2-2507               --                        --
│    └─Empty: 2-2508                     [64, 64, 3, 3]            --
│    └─Empty: 2-2509                     [64, 64, 3, 3]            --
│    └─Empty: 2-2510                     [64]                      --
│    └─Empty: 2-2511                     [64]                      --
│    └─BatchNorm2d: 2-2512               [16, 64, 2, 2]            --
│    └─Scaler: 2-2513                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2514                      [16, 64, 2, 2]            --
│    └─Empty: 2-2515                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2516                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2517        --                        --
│    └─One: 2-2518                       [1]                       --
│    └─OutputScale: 2-2519               --                        --
│    └─Empty: 2-2520                     [64, 48, 1, 1]            --
│    └─Empty: 2-2521                     [64, 48, 1, 1]            --
│    └─Empty: 2-2522                     [64]                      --
│    └─Empty: 2-2523                     [64]                      --
│    └─BatchNorm2d: 2-2524               [16, 64, 64, 64]          --
│    └─Scaler: 2-2525                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2526                      [16, 64, 64, 64]          --
│    └─Empty: 2-2527                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2528                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2529        --                        --
│    └─One: 2-2530                       [1]                       --
│    └─OutputScale: 2-2531               --                        --
│    └─Empty: 2-2532                     [64, 64, 3, 3]            --
│    └─Empty: 2-2533                     [64, 64, 3, 3]            --
│    └─Empty: 2-2534                     [64]                      --
│    └─Empty: 2-2535                     [64]                      --
│    └─BatchNorm2d: 2-2536               [16, 64, 64, 64]          --
│    └─Scaler: 2-2537                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2538                      [16, 64, 64, 64]          --
│    └─Empty: 2-2539                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2540                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2541        --                        --
│    └─One: 2-2542                       [1]                       --
│    └─OutputScale: 2-2543               --                        --
│    └─Empty: 2-2544                     [64, 64, 1, 1]            --
│    └─Empty: 2-2545                     [64, 64, 1, 1]            --
│    └─Empty: 2-2546                     [64]                      --
│    └─Empty: 2-2547                     [64]                      --
│    └─BatchNorm2d: 2-2548               [16, 64, 64, 64]          --
│    └─Scaler: 2-2549                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2550                      [16, 64, 64, 64]          --
│    └─Empty: 2-2551                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2552                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2553        --                        --
│    └─One: 2-2554                       [1]                       --
│    └─OutputScale: 2-2555               --                        --
│    └─Empty: 2-2556                     [64, 64, 3, 3]            --
│    └─Empty: 2-2557                     [64, 64, 3, 3]            --
│    └─Empty: 2-2558                     [64]                      --
│    └─Empty: 2-2559                     [64]                      --
│    └─BatchNorm2d: 2-2560               [16, 64, 64, 64]          --
│    └─Scaler: 2-2561                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2562                      [16, 64, 64, 64]          --
│    └─Empty: 2-2563                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2564                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2565                 [16, 64, 32, 32]          --
│    └─Empty: 2-2566                     [16, 64, 32, 32]          --
│    └─Empty: 2-2567                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2568        --                        --
│    └─One: 2-2569                       [1]                       --
│    └─OutputScale: 2-2570               --                        --
│    └─Empty: 2-2571                     [64, 64, 3, 3]            --
│    └─Empty: 2-2572                     [64, 64, 3, 3]            --
│    └─Empty: 2-2573                     [64]                      --
│    └─Empty: 2-2574                     [64]                      --
│    └─BatchNorm2d: 2-2575               [16, 64, 32, 32]          --
│    └─Scaler: 2-2576                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2577                      [16, 64, 32, 32]          --
│    └─Empty: 2-2578                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2579                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2580        --                        --
│    └─One: 2-2581                       [1]                       --
│    └─OutputScale: 2-2582               --                        --
│    └─Empty: 2-2583                     [64, 64, 3, 3]            --
│    └─Empty: 2-2584                     [64, 64, 3, 3]            --
│    └─Empty: 2-2585                     [64]                      --
│    └─Empty: 2-2586                     [64]                      --
│    └─BatchNorm2d: 2-2587               [16, 64, 32, 32]          --
│    └─Scaler: 2-2588                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2589                      [16, 64, 32, 32]          --
│    └─Empty: 2-2590                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2591                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2592                 [16, 64, 16, 16]          --
│    └─Empty: 2-2593                     [16, 64, 16, 16]          --
│    └─Empty: 2-2594                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2595        --                        --
│    └─One: 2-2596                       [1]                       --
│    └─OutputScale: 2-2597               --                        --
│    └─Empty: 2-2598                     [64, 64, 3, 3]            --
│    └─Empty: 2-2599                     [64, 64, 3, 3]            --
│    └─Empty: 2-2600                     [64]                      --
│    └─Empty: 2-2601                     [64]                      --
│    └─BatchNorm2d: 2-2602               [16, 64, 16, 16]          --
│    └─Scaler: 2-2603                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2604                      [16, 64, 16, 16]          --
│    └─Empty: 2-2605                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2606                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2607        --                        --
│    └─One: 2-2608                       [1]                       --
│    └─OutputScale: 2-2609               --                        --
│    └─Empty: 2-2610                     [64, 64, 3, 3]            --
│    └─Empty: 2-2611                     [64, 64, 3, 3]            --
│    └─Empty: 2-2612                     [64]                      --
│    └─Empty: 2-2613                     [64]                      --
│    └─BatchNorm2d: 2-2614               [16, 64, 16, 16]          --
│    └─Scaler: 2-2615                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2616                      [16, 64, 16, 16]          --
│    └─Empty: 2-2617                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2618                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2619                 [16, 64, 8, 8]            --
│    └─Empty: 2-2620                     [16, 64, 8, 8]            --
│    └─Empty: 2-2621                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2622        --                        --
│    └─One: 2-2623                       [1]                       --
│    └─OutputScale: 2-2624               --                        --
│    └─Empty: 2-2625                     [64, 64, 3, 3]            --
│    └─Empty: 2-2626                     [64, 64, 3, 3]            --
│    └─Empty: 2-2627                     [64]                      --
│    └─Empty: 2-2628                     [64]                      --
│    └─BatchNorm2d: 2-2629               [16, 64, 8, 8]            --
│    └─Scaler: 2-2630                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2631                      [16, 64, 8, 8]            --
│    └─Empty: 2-2632                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2633                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2634        --                        --
│    └─One: 2-2635                       [1]                       --
│    └─OutputScale: 2-2636               --                        --
│    └─Empty: 2-2637                     [64, 64, 1, 1]            --
│    └─Empty: 2-2638                     [64, 64, 1, 1]            --
│    └─Empty: 2-2639                     [64]                      --
│    └─Empty: 2-2640                     [64]                      --
│    └─BatchNorm2d: 2-2641               [16, 64, 8, 8]            --
│    └─Scaler: 2-2642                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2643                      [16, 64, 8, 8]            --
│    └─Empty: 2-2644                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2645                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2646                 [16, 64, 8, 8]            --
│    └─Empty: 2-2647                     [16, 64, 8, 8]            --
│    └─Empty: 2-2648                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2649        --                        --
│    └─One: 2-2650                       [1]                       --
│    └─OutputScale: 2-2651               --                        --
│    └─Empty: 2-2652                     [64, 64, 3, 3]            --
│    └─Empty: 2-2653                     [64, 64, 3, 3]            --
│    └─Empty: 2-2654                     [64]                      --
│    └─Empty: 2-2655                     [64]                      --
│    └─BatchNorm2d: 2-2656               [16, 64, 8, 8]            --
│    └─Scaler: 2-2657                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2658                      [16, 64, 8, 8]            --
│    └─Empty: 2-2659                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2660                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2661                 [16, 64, 4, 4]            --
│    └─Empty: 2-2662                     [16, 64, 4, 4]            --
│    └─Empty: 2-2663                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2664        --                        --
│    └─One: 2-2665                       [1]                       --
│    └─OutputScale: 2-2666               --                        --
│    └─Empty: 2-2667                     [64, 64, 3, 3]            --
│    └─Empty: 2-2668                     [64, 64, 3, 3]            --
│    └─Empty: 2-2669                     [64]                      --
│    └─Empty: 2-2670                     [64]                      --
│    └─BatchNorm2d: 2-2671               [16, 64, 4, 4]            --
│    └─Scaler: 2-2672                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2673                      [16, 64, 4, 4]            --
│    └─Empty: 2-2674                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2675                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2676        --                        --
│    └─One: 2-2677                       [1]                       --
│    └─OutputScale: 2-2678               --                        --
│    └─Empty: 2-2679                     [64, 64, 1, 1]            --
│    └─Empty: 2-2680                     [64, 64, 1, 1]            --
│    └─Empty: 2-2681                     [64]                      --
│    └─Empty: 2-2682                     [64]                      --
│    └─BatchNorm2d: 2-2683               [16, 64, 4, 4]            --
│    └─Scaler: 2-2684                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2685                      [16, 64, 4, 4]            --
│    └─Empty: 2-2686                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2687                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2688                 [16, 64, 4, 4]            --
│    └─Empty: 2-2689                     [16, 64, 4, 4]            --
│    └─Empty: 2-2690                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2691        --                        --
│    └─One: 2-2692                       [1]                       --
│    └─OutputScale: 2-2693               --                        --
│    └─Empty: 2-2694                     [64, 64, 3, 3]            --
│    └─Empty: 2-2695                     [64, 64, 3, 3]            --
│    └─Empty: 2-2696                     [64]                      --
│    └─Empty: 2-2697                     [64]                      --
│    └─BatchNorm2d: 2-2698               [16, 64, 4, 4]            --
│    └─Scaler: 2-2699                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2700                      [16, 64, 4, 4]            --
│    └─Empty: 2-2701                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2702                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2703                 [16, 64, 2, 2]            --
│    └─Empty: 2-2704                     [16, 64, 2, 2]            --
│    └─Empty: 2-2705                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2706        --                        --
│    └─One: 2-2707                       [1]                       --
│    └─OutputScale: 2-2708               --                        --
│    └─Empty: 2-2709                     [64, 64, 1, 1]            --
│    └─Empty: 2-2710                     [64, 64, 1, 1]            --
│    └─Empty: 2-2711                     [64]                      --
│    └─Empty: 2-2712                     [64]                      --
│    └─BatchNorm2d: 2-2713               [16, 64, 2, 2]            --
│    └─Scaler: 2-2714                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2715                      [16, 64, 2, 2]            --
│    └─Empty: 2-2716                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2717                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2718        --                        --
│    └─One: 2-2719                       [1]                       --
│    └─OutputScale: 2-2720               --                        --
│    └─Empty: 2-2721                     [64, 64, 1, 1]            --
│    └─Empty: 2-2722                     [64, 64, 1, 1]            --
│    └─Empty: 2-2723                     [64]                      --
│    └─Empty: 2-2724                     [64]                      --
│    └─BatchNorm2d: 2-2725               [16, 64, 2, 2]            --
│    └─Scaler: 2-2726                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2727                      [16, 64, 2, 2]            --
│    └─Empty: 2-2728                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2729                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2730                 [16, 64, 2, 2]            --
│    └─Empty: 2-2731                     [16, 64, 2, 2]            --
│    └─Empty: 2-2732                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2733        --                        --
│    └─One: 2-2734                       [1]                       --
│    └─OutputScale: 2-2735               --                        --
│    └─Empty: 2-2736                     [64, 64, 3, 3]            --
│    └─Empty: 2-2737                     [64, 64, 3, 3]            --
│    └─Empty: 2-2738                     [64]                      --
│    └─Empty: 2-2739                     [64]                      --
│    └─BatchNorm2d: 2-2740               [16, 64, 2, 2]            --
│    └─Scaler: 2-2741                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2742                      [16, 64, 2, 2]            --
│    └─Empty: 2-2743                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2744                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2745        --                        --
│    └─One: 2-2746                       [1]                       --
│    └─OutputScale: 2-2747               --                        --
│    └─Empty: 2-2748                     [64, 48, 1, 1]            --
│    └─Empty: 2-2749                     [64, 48, 1, 1]            --
│    └─Empty: 2-2750                     [64]                      --
│    └─Empty: 2-2751                     [64]                      --
│    └─BatchNorm2d: 2-2752               [16, 64, 64, 64]          --
│    └─Scaler: 2-2753                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2754                      [16, 64, 64, 64]          --
│    └─Empty: 2-2755                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2756                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2757        --                        --
│    └─One: 2-2758                       [1]                       --
│    └─OutputScale: 2-2759               --                        --
│    └─Empty: 2-2760                     [64, 64, 3, 3]            --
│    └─Empty: 2-2761                     [64, 64, 3, 3]            --
│    └─Empty: 2-2762                     [64]                      --
│    └─Empty: 2-2763                     [64]                      --
│    └─BatchNorm2d: 2-2764               [16, 64, 64, 64]          --
│    └─Scaler: 2-2765                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2766                      [16, 64, 64, 64]          --
│    └─Empty: 2-2767                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2768                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2769        --                        --
│    └─One: 2-2770                       [1]                       --
│    └─OutputScale: 2-2771               --                        --
│    └─Empty: 2-2772                     [64, 64, 1, 1]            --
│    └─Empty: 2-2773                     [64, 64, 1, 1]            --
│    └─Empty: 2-2774                     [64]                      --
│    └─Empty: 2-2775                     [64]                      --
│    └─BatchNorm2d: 2-2776               [16, 64, 64, 64]          --
│    └─Scaler: 2-2777                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2778                      [16, 64, 64, 64]          --
│    └─Empty: 2-2779                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2780                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2781        --                        --
│    └─One: 2-2782                       [1]                       --
│    └─OutputScale: 2-2783               --                        --
│    └─Empty: 2-2784                     [64, 64, 3, 3]            --
│    └─Empty: 2-2785                     [64, 64, 3, 3]            --
│    └─Empty: 2-2786                     [64]                      --
│    └─Empty: 2-2787                     [64]                      --
│    └─BatchNorm2d: 2-2788               [16, 64, 64, 64]          --
│    └─Scaler: 2-2789                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2790                      [16, 64, 64, 64]          --
│    └─Empty: 2-2791                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2792                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2793                 [16, 64, 32, 32]          --
│    └─Empty: 2-2794                     [16, 64, 32, 32]          --
│    └─Empty: 2-2795                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2796        --                        --
│    └─One: 2-2797                       [1]                       --
│    └─OutputScale: 2-2798               --                        --
│    └─Empty: 2-2799                     [64, 64, 3, 3]            --
│    └─Empty: 2-2800                     [64, 64, 3, 3]            --
│    └─Empty: 2-2801                     [64]                      --
│    └─Empty: 2-2802                     [64]                      --
│    └─BatchNorm2d: 2-2803               [16, 64, 32, 32]          --
│    └─Scaler: 2-2804                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2805                      [16, 64, 32, 32]          --
│    └─Empty: 2-2806                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2807                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2808        --                        --
│    └─One: 2-2809                       [1]                       --
│    └─OutputScale: 2-2810               --                        --
│    └─Empty: 2-2811                     [64, 64, 3, 3]            --
│    └─Empty: 2-2812                     [64, 64, 3, 3]            --
│    └─Empty: 2-2813                     [64]                      --
│    └─Empty: 2-2814                     [64]                      --
│    └─BatchNorm2d: 2-2815               [16, 64, 32, 32]          --
│    └─Scaler: 2-2816                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2817                      [16, 64, 32, 32]          --
│    └─Empty: 2-2818                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2819                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2820                 [16, 64, 16, 16]          --
│    └─Empty: 2-2821                     [16, 64, 16, 16]          --
│    └─Empty: 2-2822                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2823        --                        --
│    └─One: 2-2824                       [1]                       --
│    └─OutputScale: 2-2825               --                        --
│    └─Empty: 2-2826                     [64, 64, 3, 3]            --
│    └─Empty: 2-2827                     [64, 64, 3, 3]            --
│    └─Empty: 2-2828                     [64]                      --
│    └─Empty: 2-2829                     [64]                      --
│    └─BatchNorm2d: 2-2830               [16, 64, 16, 16]          --
│    └─Scaler: 2-2831                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2832                      [16, 64, 16, 16]          --
│    └─Empty: 2-2833                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2834                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2835        --                        --
│    └─One: 2-2836                       [1]                       --
│    └─OutputScale: 2-2837               --                        --
│    └─Empty: 2-2838                     [64, 64, 3, 3]            --
│    └─Empty: 2-2839                     [64, 64, 3, 3]            --
│    └─Empty: 2-2840                     [64]                      --
│    └─Empty: 2-2841                     [64]                      --
│    └─BatchNorm2d: 2-2842               [16, 64, 16, 16]          --
│    └─Scaler: 2-2843                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2844                      [16, 64, 16, 16]          --
│    └─Empty: 2-2845                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2846                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2847                 [16, 64, 8, 8]            --
│    └─Empty: 2-2848                     [16, 64, 8, 8]            --
│    └─Empty: 2-2849                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2850        --                        --
│    └─One: 2-2851                       [1]                       --
│    └─OutputScale: 2-2852               --                        --
│    └─Empty: 2-2853                     [64, 64, 3, 3]            --
│    └─Empty: 2-2854                     [64, 64, 3, 3]            --
│    └─Empty: 2-2855                     [64]                      --
│    └─Empty: 2-2856                     [64]                      --
│    └─BatchNorm2d: 2-2857               [16, 64, 8, 8]            --
│    └─Scaler: 2-2858                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2859                      [16, 64, 8, 8]            --
│    └─Empty: 2-2860                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2861                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2862        --                        --
│    └─One: 2-2863                       [1]                       --
│    └─OutputScale: 2-2864               --                        --
│    └─Empty: 2-2865                     [64, 64, 1, 1]            --
│    └─Empty: 2-2866                     [64, 64, 1, 1]            --
│    └─Empty: 2-2867                     [64]                      --
│    └─Empty: 2-2868                     [64]                      --
│    └─BatchNorm2d: 2-2869               [16, 64, 8, 8]            --
│    └─Scaler: 2-2870                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2871                      [16, 64, 8, 8]            --
│    └─Empty: 2-2872                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2873                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2874                 [16, 64, 8, 8]            --
│    └─Empty: 2-2875                     [16, 64, 8, 8]            --
│    └─Empty: 2-2876                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2877        --                        --
│    └─One: 2-2878                       [1]                       --
│    └─OutputScale: 2-2879               --                        --
│    └─Empty: 2-2880                     [64, 64, 3, 3]            --
│    └─Empty: 2-2881                     [64, 64, 3, 3]            --
│    └─Empty: 2-2882                     [64]                      --
│    └─Empty: 2-2883                     [64]                      --
│    └─BatchNorm2d: 2-2884               [16, 64, 8, 8]            --
│    └─Scaler: 2-2885                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2886                      [16, 64, 8, 8]            --
│    └─Empty: 2-2887                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2888                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2889                 [16, 64, 4, 4]            --
│    └─Empty: 2-2890                     [16, 64, 4, 4]            --
│    └─Empty: 2-2891                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2892        --                        --
│    └─One: 2-2893                       [1]                       --
│    └─OutputScale: 2-2894               --                        --
│    └─Empty: 2-2895                     [64, 64, 3, 3]            --
│    └─Empty: 2-2896                     [64, 64, 3, 3]            --
│    └─Empty: 2-2897                     [64]                      --
│    └─Empty: 2-2898                     [64]                      --
│    └─BatchNorm2d: 2-2899               [16, 64, 4, 4]            --
│    └─Scaler: 2-2900                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2901                      [16, 64, 4, 4]            --
│    └─Empty: 2-2902                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2903                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2904        --                        --
│    └─One: 2-2905                       [1]                       --
│    └─OutputScale: 2-2906               --                        --
│    └─Empty: 2-2907                     [64, 64, 1, 1]            --
│    └─Empty: 2-2908                     [64, 64, 1, 1]            --
│    └─Empty: 2-2909                     [64]                      --
│    └─Empty: 2-2910                     [64]                      --
│    └─BatchNorm2d: 2-2911               [16, 64, 4, 4]            --
│    └─Scaler: 2-2912                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2913                      [16, 64, 4, 4]            --
│    └─Empty: 2-2914                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2915                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2916                 [16, 64, 4, 4]            --
│    └─Empty: 2-2917                     [16, 64, 4, 4]            --
│    └─Empty: 2-2918                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2919        --                        --
│    └─One: 2-2920                       [1]                       --
│    └─OutputScale: 2-2921               --                        --
│    └─Empty: 2-2922                     [64, 64, 3, 3]            --
│    └─Empty: 2-2923                     [64, 64, 3, 3]            --
│    └─Empty: 2-2924                     [64]                      --
│    └─Empty: 2-2925                     [64]                      --
│    └─BatchNorm2d: 2-2926               [16, 64, 4, 4]            --
│    └─Scaler: 2-2927                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2928                      [16, 64, 4, 4]            --
│    └─Empty: 2-2929                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2930                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2931                 [16, 64, 2, 2]            --
│    └─Empty: 2-2932                     [16, 64, 2, 2]            --
│    └─Empty: 2-2933                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2934        --                        --
│    └─One: 2-2935                       [1]                       --
│    └─OutputScale: 2-2936               --                        --
│    └─Empty: 2-2937                     [64, 64, 1, 1]            --
│    └─Empty: 2-2938                     [64, 64, 1, 1]            --
│    └─Empty: 2-2939                     [64]                      --
│    └─Empty: 2-2940                     [64]                      --
│    └─BatchNorm2d: 2-2941               [16, 64, 2, 2]            --
│    └─Scaler: 2-2942                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2943                      [16, 64, 2, 2]            --
│    └─Empty: 2-2944                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2945                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2946        --                        --
│    └─One: 2-2947                       [1]                       --
│    └─OutputScale: 2-2948               --                        --
│    └─Empty: 2-2949                     [64, 64, 1, 1]            --
│    └─Empty: 2-2950                     [64, 64, 1, 1]            --
│    └─Empty: 2-2951                     [64]                      --
│    └─Empty: 2-2952                     [64]                      --
│    └─BatchNorm2d: 2-2953               [16, 64, 2, 2]            --
│    └─Scaler: 2-2954                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2955                      [16, 64, 2, 2]            --
│    └─Empty: 2-2956                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2957                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2958                 [16, 64, 2, 2]            --
│    └─Empty: 2-2959                     [16, 64, 2, 2]            --
│    └─Empty: 2-2960                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2961        --                        --
│    └─One: 2-2962                       [1]                       --
│    └─OutputScale: 2-2963               --                        --
│    └─Empty: 2-2964                     [64, 64, 3, 3]            --
│    └─Empty: 2-2965                     [64, 64, 3, 3]            --
│    └─Empty: 2-2966                     [64]                      --
│    └─Empty: 2-2967                     [64]                      --
│    └─BatchNorm2d: 2-2968               [16, 64, 2, 2]            --
│    └─Scaler: 2-2969                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2970                      [16, 64, 2, 2]            --
│    └─Empty: 2-2971                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2972                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2973        --                        --
│    └─One: 2-2974                       [1]                       --
│    └─OutputScale: 2-2975               --                        --
│    └─Empty: 2-2976                     [64, 48, 1, 1]            --
│    └─Empty: 2-2977                     [64, 48, 1, 1]            --
│    └─Empty: 2-2978                     [64]                      --
│    └─Empty: 2-2979                     [64]                      --
│    └─BatchNorm2d: 2-2980               [16, 64, 64, 64]          --
│    └─Scaler: 2-2981                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2982                      [16, 64, 64, 64]          --
│    └─Empty: 2-2983                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2984                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2985        --                        --
│    └─One: 2-2986                       [1]                       --
│    └─OutputScale: 2-2987               --                        --
│    └─Empty: 2-2988                     [64, 64, 3, 3]            --
│    └─Empty: 2-2989                     [64, 64, 3, 3]            --
│    └─Empty: 2-2990                     [64]                      --
│    └─Empty: 2-2991                     [64]                      --
│    └─BatchNorm2d: 2-2992               [16, 64, 64, 64]          --
│    └─Scaler: 2-2993                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2994                      [16, 64, 64, 64]          --
│    └─Empty: 2-2995                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2996                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2997        --                        --
│    └─One: 2-2998                       [1]                       --
│    └─OutputScale: 2-2999               --                        --
│    └─Empty: 2-3000                     [64, 64, 1, 1]            --
│    └─Empty: 2-3001                     [64, 64, 1, 1]            --
│    └─Empty: 2-3002                     [64]                      --
│    └─Empty: 2-3003                     [64]                      --
│    └─BatchNorm2d: 2-3004               [16, 64, 64, 64]          --
│    └─Scaler: 2-3005                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3006                      [16, 64, 64, 64]          --
│    └─Empty: 2-3007                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3008                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3009        --                        --
│    └─One: 2-3010                       [1]                       --
│    └─OutputScale: 2-3011               --                        --
│    └─Empty: 2-3012                     [64, 64, 3, 3]            --
│    └─Empty: 2-3013                     [64, 64, 3, 3]            --
│    └─Empty: 2-3014                     [64]                      --
│    └─Empty: 2-3015                     [64]                      --
│    └─BatchNorm2d: 2-3016               [16, 64, 64, 64]          --
│    └─Scaler: 2-3017                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3018                      [16, 64, 64, 64]          --
│    └─Empty: 2-3019                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3020                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3021                 [16, 64, 32, 32]          --
│    └─Empty: 2-3022                     [16, 64, 32, 32]          --
│    └─Empty: 2-3023                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3024        --                        --
│    └─One: 2-3025                       [1]                       --
│    └─OutputScale: 2-3026               --                        --
│    └─Empty: 2-3027                     [64, 64, 3, 3]            --
│    └─Empty: 2-3028                     [64, 64, 3, 3]            --
│    └─Empty: 2-3029                     [64]                      --
│    └─Empty: 2-3030                     [64]                      --
│    └─BatchNorm2d: 2-3031               [16, 64, 32, 32]          --
│    └─Scaler: 2-3032                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3033                      [16, 64, 32, 32]          --
│    └─Empty: 2-3034                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3035                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3036        --                        --
│    └─One: 2-3037                       [1]                       --
│    └─OutputScale: 2-3038               --                        --
│    └─Empty: 2-3039                     [64, 64, 3, 3]            --
│    └─Empty: 2-3040                     [64, 64, 3, 3]            --
│    └─Empty: 2-3041                     [64]                      --
│    └─Empty: 2-3042                     [64]                      --
│    └─BatchNorm2d: 2-3043               [16, 64, 32, 32]          --
│    └─Scaler: 2-3044                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3045                      [16, 64, 32, 32]          --
│    └─Empty: 2-3046                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3047                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3048                 [16, 64, 16, 16]          --
│    └─Empty: 2-3049                     [16, 64, 16, 16]          --
│    └─Empty: 2-3050                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3051        --                        --
│    └─One: 2-3052                       [1]                       --
│    └─OutputScale: 2-3053               --                        --
│    └─Empty: 2-3054                     [64, 64, 3, 3]            --
│    └─Empty: 2-3055                     [64, 64, 3, 3]            --
│    └─Empty: 2-3056                     [64]                      --
│    └─Empty: 2-3057                     [64]                      --
│    └─BatchNorm2d: 2-3058               [16, 64, 16, 16]          --
│    └─Scaler: 2-3059                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3060                      [16, 64, 16, 16]          --
│    └─Empty: 2-3061                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3062                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3063        --                        --
│    └─One: 2-3064                       [1]                       --
│    └─OutputScale: 2-3065               --                        --
│    └─Empty: 2-3066                     [64, 64, 3, 3]            --
│    └─Empty: 2-3067                     [64, 64, 3, 3]            --
│    └─Empty: 2-3068                     [64]                      --
│    └─Empty: 2-3069                     [64]                      --
│    └─BatchNorm2d: 2-3070               [16, 64, 16, 16]          --
│    └─Scaler: 2-3071                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3072                      [16, 64, 16, 16]          --
│    └─Empty: 2-3073                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3074                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3075                 [16, 64, 8, 8]            --
│    └─Empty: 2-3076                     [16, 64, 8, 8]            --
│    └─Empty: 2-3077                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3078        --                        --
│    └─One: 2-3079                       [1]                       --
│    └─OutputScale: 2-3080               --                        --
│    └─Empty: 2-3081                     [64, 64, 3, 3]            --
│    └─Empty: 2-3082                     [64, 64, 3, 3]            --
│    └─Empty: 2-3083                     [64]                      --
│    └─Empty: 2-3084                     [64]                      --
│    └─BatchNorm2d: 2-3085               [16, 64, 8, 8]            --
│    └─Scaler: 2-3086                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3087                      [16, 64, 8, 8]            --
│    └─Empty: 2-3088                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3089                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3090        --                        --
│    └─One: 2-3091                       [1]                       --
│    └─OutputScale: 2-3092               --                        --
│    └─Empty: 2-3093                     [64, 64, 1, 1]            --
│    └─Empty: 2-3094                     [64, 64, 1, 1]            --
│    └─Empty: 2-3095                     [64]                      --
│    └─Empty: 2-3096                     [64]                      --
│    └─BatchNorm2d: 2-3097               [16, 64, 8, 8]            --
│    └─Scaler: 2-3098                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3099                      [16, 64, 8, 8]            --
│    └─Empty: 2-3100                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3101                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3102                 [16, 64, 8, 8]            --
│    └─Empty: 2-3103                     [16, 64, 8, 8]            --
│    └─Empty: 2-3104                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3105        --                        --
│    └─One: 2-3106                       [1]                       --
│    └─OutputScale: 2-3107               --                        --
│    └─Empty: 2-3108                     [64, 64, 3, 3]            --
│    └─Empty: 2-3109                     [64, 64, 3, 3]            --
│    └─Empty: 2-3110                     [64]                      --
│    └─Empty: 2-3111                     [64]                      --
│    └─BatchNorm2d: 2-3112               [16, 64, 8, 8]            --
│    └─Scaler: 2-3113                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3114                      [16, 64, 8, 8]            --
│    └─Empty: 2-3115                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3116                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3117                 [16, 64, 4, 4]            --
│    └─Empty: 2-3118                     [16, 64, 4, 4]            --
│    └─Empty: 2-3119                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3120        --                        --
│    └─One: 2-3121                       [1]                       --
│    └─OutputScale: 2-3122               --                        --
│    └─Empty: 2-3123                     [64, 64, 3, 3]            --
│    └─Empty: 2-3124                     [64, 64, 3, 3]            --
│    └─Empty: 2-3125                     [64]                      --
│    └─Empty: 2-3126                     [64]                      --
│    └─BatchNorm2d: 2-3127               [16, 64, 4, 4]            --
│    └─Scaler: 2-3128                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3129                      [16, 64, 4, 4]            --
│    └─Empty: 2-3130                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3131                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3132        --                        --
│    └─One: 2-3133                       [1]                       --
│    └─OutputScale: 2-3134               --                        --
│    └─Empty: 2-3135                     [64, 64, 1, 1]            --
│    └─Empty: 2-3136                     [64, 64, 1, 1]            --
│    └─Empty: 2-3137                     [64]                      --
│    └─Empty: 2-3138                     [64]                      --
│    └─BatchNorm2d: 2-3139               [16, 64, 4, 4]            --
│    └─Scaler: 2-3140                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3141                      [16, 64, 4, 4]            --
│    └─Empty: 2-3142                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3143                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3144                 [16, 64, 4, 4]            --
│    └─Empty: 2-3145                     [16, 64, 4, 4]            --
│    └─Empty: 2-3146                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3147        --                        --
│    └─One: 2-3148                       [1]                       --
│    └─OutputScale: 2-3149               --                        --
│    └─Empty: 2-3150                     [64, 64, 3, 3]            --
│    └─Empty: 2-3151                     [64, 64, 3, 3]            --
│    └─Empty: 2-3152                     [64]                      --
│    └─Empty: 2-3153                     [64]                      --
│    └─BatchNorm2d: 2-3154               [16, 64, 4, 4]            --
│    └─Scaler: 2-3155                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3156                      [16, 64, 4, 4]            --
│    └─Empty: 2-3157                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3158                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3159                 [16, 64, 2, 2]            --
│    └─Empty: 2-3160                     [16, 64, 2, 2]            --
│    └─Empty: 2-3161                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3162        --                        --
│    └─One: 2-3163                       [1]                       --
│    └─OutputScale: 2-3164               --                        --
│    └─Empty: 2-3165                     [64, 64, 1, 1]            --
│    └─Empty: 2-3166                     [64, 64, 1, 1]            --
│    └─Empty: 2-3167                     [64]                      --
│    └─Empty: 2-3168                     [64]                      --
│    └─BatchNorm2d: 2-3169               [16, 64, 2, 2]            --
│    └─Scaler: 2-3170                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3171                      [16, 64, 2, 2]            --
│    └─Empty: 2-3172                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3173                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3174        --                        --
│    └─One: 2-3175                       [1]                       --
│    └─OutputScale: 2-3176               --                        --
│    └─Empty: 2-3177                     [64, 64, 1, 1]            --
│    └─Empty: 2-3178                     [64, 64, 1, 1]            --
│    └─Empty: 2-3179                     [64]                      --
│    └─Empty: 2-3180                     [64]                      --
│    └─BatchNorm2d: 2-3181               [16, 64, 2, 2]            --
│    └─Scaler: 2-3182                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3183                      [16, 64, 2, 2]            --
│    └─Empty: 2-3184                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3185                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3186                 [16, 64, 2, 2]            --
│    └─Empty: 2-3187                     [16, 64, 2, 2]            --
│    └─Empty: 2-3188                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3189        --                        --
│    └─One: 2-3190                       [1]                       --
│    └─OutputScale: 2-3191               --                        --
│    └─Empty: 2-3192                     [64, 64, 3, 3]            --
│    └─Empty: 2-3193                     [64, 64, 3, 3]            --
│    └─Empty: 2-3194                     [64]                      --
│    └─Empty: 2-3195                     [64]                      --
│    └─BatchNorm2d: 2-3196               [16, 64, 2, 2]            --
│    └─Scaler: 2-3197                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3198                      [16, 64, 2, 2]            --
│    └─Empty: 2-3199                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3200                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3201        --                        --
│    └─One: 2-3202                       [1]                       --
│    └─OutputScale: 2-3203               --                        --
│    └─Empty: 2-3204                     [64, 48, 1, 1]            --
│    └─Empty: 2-3205                     [64, 48, 1, 1]            --
│    └─Empty: 2-3206                     [64]                      --
│    └─Empty: 2-3207                     [64]                      --
│    └─BatchNorm2d: 2-3208               [16, 64, 64, 64]          --
│    └─Scaler: 2-3209                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3210                      [16, 64, 64, 64]          --
│    └─Empty: 2-3211                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3212                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3213        --                        --
│    └─One: 2-3214                       [1]                       --
│    └─OutputScale: 2-3215               --                        --
│    └─Empty: 2-3216                     [64, 64, 3, 3]            --
│    └─Empty: 2-3217                     [64, 64, 3, 3]            --
│    └─Empty: 2-3218                     [64]                      --
│    └─Empty: 2-3219                     [64]                      --
│    └─BatchNorm2d: 2-3220               [16, 64, 64, 64]          --
│    └─Scaler: 2-3221                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3222                      [16, 64, 64, 64]          --
│    └─Empty: 2-3223                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3224                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3225        --                        --
│    └─One: 2-3226                       [1]                       --
│    └─OutputScale: 2-3227               --                        --
│    └─Empty: 2-3228                     [64, 64, 1, 1]            --
│    └─Empty: 2-3229                     [64, 64, 1, 1]            --
│    └─Empty: 2-3230                     [64]                      --
│    └─Empty: 2-3231                     [64]                      --
│    └─BatchNorm2d: 2-3232               [16, 64, 64, 64]          --
│    └─Scaler: 2-3233                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3234                      [16, 64, 64, 64]          --
│    └─Empty: 2-3235                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3236                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3237        --                        --
│    └─One: 2-3238                       [1]                       --
│    └─OutputScale: 2-3239               --                        --
│    └─Empty: 2-3240                     [64, 64, 3, 3]            --
│    └─Empty: 2-3241                     [64, 64, 3, 3]            --
│    └─Empty: 2-3242                     [64]                      --
│    └─Empty: 2-3243                     [64]                      --
│    └─BatchNorm2d: 2-3244               [16, 64, 64, 64]          --
│    └─Scaler: 2-3245                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3246                      [16, 64, 64, 64]          --
│    └─Empty: 2-3247                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3248                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3249                 [16, 64, 32, 32]          --
│    └─Empty: 2-3250                     [16, 64, 32, 32]          --
│    └─Empty: 2-3251                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3252        --                        --
│    └─One: 2-3253                       [1]                       --
│    └─OutputScale: 2-3254               --                        --
│    └─Empty: 2-3255                     [64, 64, 3, 3]            --
│    └─Empty: 2-3256                     [64, 64, 3, 3]            --
│    └─Empty: 2-3257                     [64]                      --
│    └─Empty: 2-3258                     [64]                      --
│    └─BatchNorm2d: 2-3259               [16, 64, 32, 32]          --
│    └─Scaler: 2-3260                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3261                      [16, 64, 32, 32]          --
│    └─Empty: 2-3262                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3263                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3264        --                        --
│    └─One: 2-3265                       [1]                       --
│    └─OutputScale: 2-3266               --                        --
│    └─Empty: 2-3267                     [64, 64, 3, 3]            --
│    └─Empty: 2-3268                     [64, 64, 3, 3]            --
│    └─Empty: 2-3269                     [64]                      --
│    └─Empty: 2-3270                     [64]                      --
│    └─BatchNorm2d: 2-3271               [16, 64, 32, 32]          --
│    └─Scaler: 2-3272                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3273                      [16, 64, 32, 32]          --
│    └─Empty: 2-3274                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3275                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3276                 [16, 64, 16, 16]          --
│    └─Empty: 2-3277                     [16, 64, 16, 16]          --
│    └─Empty: 2-3278                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3279        --                        --
│    └─One: 2-3280                       [1]                       --
│    └─OutputScale: 2-3281               --                        --
│    └─Empty: 2-3282                     [64, 64, 3, 3]            --
│    └─Empty: 2-3283                     [64, 64, 3, 3]            --
│    └─Empty: 2-3284                     [64]                      --
│    └─Empty: 2-3285                     [64]                      --
│    └─BatchNorm2d: 2-3286               [16, 64, 16, 16]          --
│    └─Scaler: 2-3287                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3288                      [16, 64, 16, 16]          --
│    └─Empty: 2-3289                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3290                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3291        --                        --
│    └─One: 2-3292                       [1]                       --
│    └─OutputScale: 2-3293               --                        --
│    └─Empty: 2-3294                     [64, 64, 3, 3]            --
│    └─Empty: 2-3295                     [64, 64, 3, 3]            --
│    └─Empty: 2-3296                     [64]                      --
│    └─Empty: 2-3297                     [64]                      --
│    └─BatchNorm2d: 2-3298               [16, 64, 16, 16]          --
│    └─Scaler: 2-3299                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3300                      [16, 64, 16, 16]          --
│    └─Empty: 2-3301                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3302                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3303                 [16, 64, 8, 8]            --
│    └─Empty: 2-3304                     [16, 64, 8, 8]            --
│    └─Empty: 2-3305                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3306        --                        --
│    └─One: 2-3307                       [1]                       --
│    └─OutputScale: 2-3308               --                        --
│    └─Empty: 2-3309                     [64, 64, 3, 3]            --
│    └─Empty: 2-3310                     [64, 64, 3, 3]            --
│    └─Empty: 2-3311                     [64]                      --
│    └─Empty: 2-3312                     [64]                      --
│    └─BatchNorm2d: 2-3313               [16, 64, 8, 8]            --
│    └─Scaler: 2-3314                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3315                      [16, 64, 8, 8]            --
│    └─Empty: 2-3316                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3317                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3318        --                        --
│    └─One: 2-3319                       [1]                       --
│    └─OutputScale: 2-3320               --                        --
│    └─Empty: 2-3321                     [64, 64, 1, 1]            --
│    └─Empty: 2-3322                     [64, 64, 1, 1]            --
│    └─Empty: 2-3323                     [64]                      --
│    └─Empty: 2-3324                     [64]                      --
│    └─BatchNorm2d: 2-3325               [16, 64, 8, 8]            --
│    └─Scaler: 2-3326                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3327                      [16, 64, 8, 8]            --
│    └─Empty: 2-3328                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3329                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3330                 [16, 64, 8, 8]            --
│    └─Empty: 2-3331                     [16, 64, 8, 8]            --
│    └─Empty: 2-3332                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3333        --                        --
│    └─One: 2-3334                       [1]                       --
│    └─OutputScale: 2-3335               --                        --
│    └─Empty: 2-3336                     [64, 64, 3, 3]            --
│    └─Empty: 2-3337                     [64, 64, 3, 3]            --
│    └─Empty: 2-3338                     [64]                      --
│    └─Empty: 2-3339                     [64]                      --
│    └─BatchNorm2d: 2-3340               [16, 64, 8, 8]            --
│    └─Scaler: 2-3341                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3342                      [16, 64, 8, 8]            --
│    └─Empty: 2-3343                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3344                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3345                 [16, 64, 4, 4]            --
│    └─Empty: 2-3346                     [16, 64, 4, 4]            --
│    └─Empty: 2-3347                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3348        --                        --
│    └─One: 2-3349                       [1]                       --
│    └─OutputScale: 2-3350               --                        --
│    └─Empty: 2-3351                     [64, 64, 3, 3]            --
│    └─Empty: 2-3352                     [64, 64, 3, 3]            --
│    └─Empty: 2-3353                     [64]                      --
│    └─Empty: 2-3354                     [64]                      --
│    └─BatchNorm2d: 2-3355               [16, 64, 4, 4]            --
│    └─Scaler: 2-3356                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3357                      [16, 64, 4, 4]            --
│    └─Empty: 2-3358                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3359                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3360        --                        --
│    └─One: 2-3361                       [1]                       --
│    └─OutputScale: 2-3362               --                        --
│    └─Empty: 2-3363                     [64, 64, 1, 1]            --
│    └─Empty: 2-3364                     [64, 64, 1, 1]            --
│    └─Empty: 2-3365                     [64]                      --
│    └─Empty: 2-3366                     [64]                      --
│    └─BatchNorm2d: 2-3367               [16, 64, 4, 4]            --
│    └─Scaler: 2-3368                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3369                      [16, 64, 4, 4]            --
│    └─Empty: 2-3370                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3371                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3372                 [16, 64, 4, 4]            --
│    └─Empty: 2-3373                     [16, 64, 4, 4]            --
│    └─Empty: 2-3374                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3375        --                        --
│    └─One: 2-3376                       [1]                       --
│    └─OutputScale: 2-3377               --                        --
│    └─Empty: 2-3378                     [64, 64, 3, 3]            --
│    └─Empty: 2-3379                     [64, 64, 3, 3]            --
│    └─Empty: 2-3380                     [64]                      --
│    └─Empty: 2-3381                     [64]                      --
│    └─BatchNorm2d: 2-3382               [16, 64, 4, 4]            --
│    └─Scaler: 2-3383                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3384                      [16, 64, 4, 4]            --
│    └─Empty: 2-3385                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3386                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3387                 [16, 64, 2, 2]            --
│    └─Empty: 2-3388                     [16, 64, 2, 2]            --
│    └─Empty: 2-3389                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3390        --                        --
│    └─One: 2-3391                       [1]                       --
│    └─OutputScale: 2-3392               --                        --
│    └─Empty: 2-3393                     [64, 64, 1, 1]            --
│    └─Empty: 2-3394                     [64, 64, 1, 1]            --
│    └─Empty: 2-3395                     [64]                      --
│    └─Empty: 2-3396                     [64]                      --
│    └─BatchNorm2d: 2-3397               [16, 64, 2, 2]            --
│    └─Scaler: 2-3398                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3399                      [16, 64, 2, 2]            --
│    └─Empty: 2-3400                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3401                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3402        --                        --
│    └─One: 2-3403                       [1]                       --
│    └─OutputScale: 2-3404               --                        --
│    └─Empty: 2-3405                     [64, 64, 1, 1]            --
│    └─Empty: 2-3406                     [64, 64, 1, 1]            --
│    └─Empty: 2-3407                     [64]                      --
│    └─Empty: 2-3408                     [64]                      --
│    └─BatchNorm2d: 2-3409               [16, 64, 2, 2]            --
│    └─Scaler: 2-3410                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3411                      [16, 64, 2, 2]            --
│    └─Empty: 2-3412                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3413                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3414                 [16, 64, 2, 2]            --
│    └─Empty: 2-3415                     [16, 64, 2, 2]            --
│    └─Empty: 2-3416                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3417        --                        --
│    └─One: 2-3418                       [1]                       --
│    └─OutputScale: 2-3419               --                        --
│    └─Empty: 2-3420                     [64, 64, 3, 3]            --
│    └─Empty: 2-3421                     [64, 64, 3, 3]            --
│    └─Empty: 2-3422                     [64]                      --
│    └─Empty: 2-3423                     [64]                      --
│    └─BatchNorm2d: 2-3424               [16, 64, 2, 2]            --
│    └─Scaler: 2-3425                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3426                      [16, 64, 2, 2]            --
│    └─Empty: 2-3427                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3428                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3429        --                        --
│    └─One: 2-3430                       [1]                       --
│    └─OutputScale: 2-3431               --                        --
│    └─Empty: 2-3432                     [64, 48, 1, 1]            --
│    └─Empty: 2-3433                     [64, 48, 1, 1]            --
│    └─Empty: 2-3434                     [64]                      --
│    └─Empty: 2-3435                     [64]                      --
│    └─BatchNorm2d: 2-3436               [16, 64, 64, 64]          --
│    └─Scaler: 2-3437                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3438                      [16, 64, 64, 64]          --
│    └─Empty: 2-3439                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3440                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3441        --                        --
│    └─One: 2-3442                       [1]                       --
│    └─OutputScale: 2-3443               --                        --
│    └─Empty: 2-3444                     [64, 64, 3, 3]            --
│    └─Empty: 2-3445                     [64, 64, 3, 3]            --
│    └─Empty: 2-3446                     [64]                      --
│    └─Empty: 2-3447                     [64]                      --
│    └─BatchNorm2d: 2-3448               [16, 64, 64, 64]          --
│    └─Scaler: 2-3449                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3450                      [16, 64, 64, 64]          --
│    └─Empty: 2-3451                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3452                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3453        --                        --
│    └─One: 2-3454                       [1]                       --
│    └─OutputScale: 2-3455               --                        --
│    └─Empty: 2-3456                     [64, 64, 1, 1]            --
│    └─Empty: 2-3457                     [64, 64, 1, 1]            --
│    └─Empty: 2-3458                     [64]                      --
│    └─Empty: 2-3459                     [64]                      --
│    └─BatchNorm2d: 2-3460               [16, 64, 64, 64]          --
│    └─Scaler: 2-3461                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3462                      [16, 64, 64, 64]          --
│    └─Empty: 2-3463                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3464                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3465        --                        --
│    └─One: 2-3466                       [1]                       --
│    └─OutputScale: 2-3467               --                        --
│    └─Empty: 2-3468                     [64, 64, 3, 3]            --
│    └─Empty: 2-3469                     [64, 64, 3, 3]            --
│    └─Empty: 2-3470                     [64]                      --
│    └─Empty: 2-3471                     [64]                      --
│    └─BatchNorm2d: 2-3472               [16, 64, 64, 64]          --
│    └─Scaler: 2-3473                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3474                      [16, 64, 64, 64]          --
│    └─Empty: 2-3475                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3476                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3477                 [16, 64, 32, 32]          --
│    └─Empty: 2-3478                     [16, 64, 32, 32]          --
│    └─Empty: 2-3479                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3480        --                        --
│    └─One: 2-3481                       [1]                       --
│    └─OutputScale: 2-3482               --                        --
│    └─Empty: 2-3483                     [64, 64, 3, 3]            --
│    └─Empty: 2-3484                     [64, 64, 3, 3]            --
│    └─Empty: 2-3485                     [64]                      --
│    └─Empty: 2-3486                     [64]                      --
│    └─BatchNorm2d: 2-3487               [16, 64, 32, 32]          --
│    └─Scaler: 2-3488                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─Empty: 2-3490                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3491                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3492        --                        --
│    └─One: 2-3493                       [1]                       --
│    └─OutputScale: 2-3494               --                        --
│    └─Empty: 2-3495                     [64, 64, 3, 3]            --
│    └─Empty: 2-3496                     [64, 64, 3, 3]            --
│    └─Empty: 2-3497                     [64]                      --
│    └─Empty: 2-3498                     [64]                      --
│    └─BatchNorm2d: 2-3499               [16, 64, 32, 32]          --
│    └─Scaler: 2-3500                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3501                      [16, 64, 32, 32]          --
│    └─Empty: 2-3502                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3503                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3504                 [16, 64, 16, 16]          --
│    └─Empty: 2-3505                     [16, 64, 16, 16]          --
│    └─Empty: 2-3506                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3507        --                        --
│    └─One: 2-3508                       [1]                       --
│    └─OutputScale: 2-3509               --                        --
│    └─Empty: 2-3510                     [64, 64, 3, 3]            --
│    └─Empty: 2-3511                     [64, 64, 3, 3]            --
│    └─Empty: 2-3512                     [64]                      --
│    └─Empty: 2-3513                     [64]                      --
│    └─BatchNorm2d: 2-3514               [16, 64, 16, 16]          --
│    └─Scaler: 2-3515                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
│    └─Empty: 2-3517                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3518                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3519        --                        --
│    └─One: 2-3520                       [1]                       --
│    └─OutputScale: 2-3521               --                        --
│    └─Empty: 2-3522                     [64, 64, 3, 3]            --
│    └─Empty: 2-3523                     [64, 64, 3, 3]            --
│    └─Empty: 2-3524                     [64]                      --
│    └─Empty: 2-3525                     [64]                      --
│    └─BatchNorm2d: 2-3526               [16, 64, 16, 16]          --
│    └─Scaler: 2-3527                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3528                      [16, 64, 16, 16]          --
│    └─Empty: 2-3529                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3530                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3531                 [16, 64, 8, 8]            --
│    └─Empty: 2-3532                     [16, 64, 8, 8]            --
│    └─Empty: 2-3533                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3534        --                        --
│    └─One: 2-3535                       [1]                       --
│    └─OutputScale: 2-3536               --                        --
│    └─Empty: 2-3537                     [64, 64, 3, 3]            --
│    └─Empty: 2-3538                     [64, 64, 3, 3]            --
│    └─Empty: 2-3539                     [64]                      --
│    └─Empty: 2-3540                     [64]                      --
│    └─BatchNorm2d: 2-3541               [16, 64, 8, 8]            --
│    └─Scaler: 2-3542                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
│    └─Empty: 2-3544                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3545                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3546        --                        --
│    └─One: 2-3547                       [1]                       --
│    └─OutputScale: 2-3548               --                        --
│    └─Empty: 2-3549                     [64, 64, 1, 1]            --
│    └─Empty: 2-3550                     [64, 64, 1, 1]            --
│    └─Empty: 2-3551                     [64]                      --
│    └─Empty: 2-3552                     [64]                      --
│    └─BatchNorm2d: 2-3553               [16, 64, 8, 8]            --
│    └─Scaler: 2-3554                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3555                      [16, 64, 8, 8]            --
│    └─Empty: 2-3556                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3557                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3558                 [16, 64, 8, 8]            --
│    └─Empty: 2-3559                     [16, 64, 8, 8]            --
│    └─Empty: 2-3560                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3561        --                        --
│    └─One: 2-3562                       [1]                       --
│    └─OutputScale: 2-3563               --                        --
│    └─Empty: 2-3564                     [64, 64, 3, 3]            --
│    └─Empty: 2-3565                     [64, 64, 3, 3]            --
│    └─Empty: 2-3566                     [64]                      --
│    └─Empty: 2-3567                     [64]                      --
│    └─BatchNorm2d: 2-3568               [16, 64, 8, 8]            --
│    └─Scaler: 2-3569                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
│    └─Empty: 2-3571                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3572                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3573                 [16, 64, 4, 4]            --
│    └─Empty: 2-3574                     [16, 64, 4, 4]            --
│    └─Empty: 2-3575                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3576        --                        --
│    └─One: 2-3577                       [1]                       --
│    └─OutputScale: 2-3578               --                        --
│    └─Empty: 2-3579                     [64, 64, 3, 3]            --
│    └─Empty: 2-3580                     [64, 64, 3, 3]            --
│    └─Empty: 2-3581                     [64]                      --
│    └─Empty: 2-3582                     [64]                      --
│    └─BatchNorm2d: 2-3583               [16, 64, 4, 4]            --
│    └─Scaler: 2-3584                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
│    └─Empty: 2-3586                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3587                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3588        --                        --
│    └─One: 2-3589                       [1]                       --
│    └─OutputScale: 2-3590               --                        --
│    └─Empty: 2-3591                     [64, 64, 1, 1]            --
│    └─Empty: 2-3592                     [64, 64, 1, 1]            --
│    └─Empty: 2-3593                     [64]                      --
│    └─Empty: 2-3594                     [64]                      --
│    └─BatchNorm2d: 2-3595               [16, 64, 4, 4]            --
│    └─Scaler: 2-3596                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3597                      [16, 64, 4, 4]            --
│    └─Empty: 2-3598                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3599                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3600                 [16, 64, 4, 4]            --
│    └─Empty: 2-3601                     [16, 64, 4, 4]            --
│    └─Empty: 2-3602                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3603        --                        --
│    └─One: 2-3604                       [1]                       --
│    └─OutputScale: 2-3605               --                        --
│    └─Empty: 2-3606                     [64, 64, 3, 3]            --
│    └─Empty: 2-3607                     [64, 64, 3, 3]            --
│    └─Empty: 2-3608                     [64]                      --
│    └─Empty: 2-3609                     [64]                      --
│    └─BatchNorm2d: 2-3610               [16, 64, 4, 4]            --
│    └─Scaler: 2-3611                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
│    └─Empty: 2-3613                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3614                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3615                 [16, 64, 2, 2]            --
│    └─Empty: 2-3616                     [16, 64, 2, 2]            --
│    └─Empty: 2-3617                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3618        --                        --
│    └─One: 2-3619                       [1]                       --
│    └─OutputScale: 2-3620               --                        --
│    └─Empty: 2-3621                     [64, 64, 1, 1]            --
│    └─Empty: 2-3622                     [64, 64, 1, 1]            --
│    └─Empty: 2-3623                     [64]                      --
│    └─Empty: 2-3624                     [64]                      --
│    └─BatchNorm2d: 2-3625               [16, 64, 2, 2]            --
│    └─Scaler: 2-3626                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
│    └─Empty: 2-3628                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3629                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3630        --                        --
│    └─One: 2-3631                       [1]                       --
│    └─OutputScale: 2-3632               --                        --
│    └─Empty: 2-3633                     [64, 64, 1, 1]            --
│    └─Empty: 2-3634                     [64, 64, 1, 1]            --
│    └─Empty: 2-3635                     [64]                      --
│    └─Empty: 2-3636                     [64]                      --
│    └─BatchNorm2d: 2-3637               [16, 64, 2, 2]            --
│    └─Scaler: 2-3638                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3639                      [16, 64, 2, 2]            --
│    └─Empty: 2-3640                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3641                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3642                 [16, 64, 2, 2]            --
│    └─Empty: 2-3643                     [16, 64, 2, 2]            --
│    └─Empty: 2-3644                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3645        --                        --
│    └─One: 2-3646                       [1]                       --
│    └─OutputScale: 2-3647               --                        --
│    └─Empty: 2-3648                     [64, 64, 3, 3]            --
│    └─Empty: 2-3649                     [64, 64, 3, 3]            --
│    └─Empty: 2-3650                     [64]                      --
│    └─Empty: 2-3651                     [64]                      --
│    └─BatchNorm2d: 2-3652               [16, 64, 2, 2]            --
│    └─Scaler: 2-3653                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
│    └─Empty: 2-3655                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3656                     [16, 64, 2, 2]            --
├─Conv1d: 1-273                          [16, 64, 16]              16,454
│    └─OutputShiftSqueeze: 2-3657        --                        --
│    └─One: 2-3658                       [1]                       --
│    └─OutputScale: 2-3659               --                        --
│    └─Empty: 2-3660                     [64, 256, 1]              --
│    └─Empty: 2-3661                     [64, 256, 1]              --
│    └─Empty: 2-3662                     [64]                      --
│    └─Empty: 2-3663                     [64]                      --
│    └─Scaler: 2-3664                    [16, 64, 16]              --
│    └─Empty: 2-3665                     [16, 64, 16]              --
│    └─Empty: 2-3666                     [16, 64, 16]              --
│    └─Clamp: 2-3667                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3668        --                        --
│    └─One: 2-3669                       [1]                       --
│    └─OutputScale: 2-3670               --                        --
│    └─Empty: 2-3671                     [64, 64, 3]               --
│    └─Empty: 2-3672                     [64, 64, 3]               --
│    └─Empty: 2-3673                     [64]                      --
│    └─Empty: 2-3674                     [64]                      --
│    └─BatchNorm1d: 2-3675               [16, 64, 16]              --
│    └─Scaler: 2-3676                    [16, 64, 16]              --
│    └─ReLU: 2-3677                      [16, 64, 16]              --
│    └─Empty: 2-3678                     [16, 64, 16]              --
│    └─Clamp: 2-3679                     [16, 64, 16]              --
├─Conv1d: 1-275                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3680        --                        --
│    └─One: 2-3681                       [1]                       --
│    └─OutputScale: 2-3682               --                        --
│    └─Empty: 2-3683                     [64, 64, 1]               --
│    └─Empty: 2-3684                     [64, 64, 1]               --
│    └─Empty: 2-3685                     [64]                      --
│    └─Empty: 2-3686                     [64]                      --
│    └─Scaler: 2-3687                    [16, 64, 16]              --
│    └─Empty: 2-3688                     [16, 64, 16]              --
│    └─Empty: 2-3689                     [16, 64, 16]              --
│    └─Clamp: 2-3690                     [16, 64, 16]              --
├─Dropout: 1-276                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-277               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3691        --                        --
│    └─One: 2-3692                       [1]                       --
│    └─OutputScale: 2-3693               --                        --
│    └─Empty: 2-3694                     [64, 64, 3]               --
│    └─Empty: 2-3695                     [64, 64, 3]               --
│    └─Empty: 2-3696                     [64]                      --
│    └─Empty: 2-3697                     [64]                      --
│    └─BatchNorm1d: 2-3698               [16, 64, 16]              --
│    └─Scaler: 2-3699                    [16, 64, 16]              --
│    └─ReLU: 2-3700                      [16, 64, 16]              --
│    └─Empty: 2-3701                     [16, 64, 16]              --
│    └─Clamp: 2-3702                     [16, 64, 16]              --
├─Conv1d: 1-278                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3703        --                        --
│    └─One: 2-3704                       [1]                       --
│    └─OutputScale: 2-3705               --                        --
│    └─Empty: 2-3706                     [64, 64, 1]               --
│    └─Empty: 2-3707                     [64, 64, 1]               --
│    └─Empty: 2-3708                     [64]                      --
│    └─Empty: 2-3709                     [64]                      --
│    └─Scaler: 2-3710                    [16, 64, 16]              --
│    └─Empty: 2-3711                     [16, 64, 16]              --
│    └─Empty: 2-3712                     [16, 64, 16]              --
│    └─Clamp: 2-3713                     [16, 64, 16]              --
├─Dropout: 1-279                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-280               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3714        --                        --
│    └─One: 2-3715                       [1]                       --
│    └─OutputScale: 2-3716               --                        --
│    └─Empty: 2-3717                     [64, 64, 3]               --
│    └─Empty: 2-3718                     [64, 64, 3]               --
│    └─Empty: 2-3719                     [64]                      --
│    └─Empty: 2-3720                     [64]                      --
│    └─BatchNorm1d: 2-3721               [16, 64, 16]              --
│    └─Scaler: 2-3722                    [16, 64, 16]              --
│    └─ReLU: 2-3723                      [16, 64, 16]              --
│    └─Empty: 2-3724                     [16, 64, 16]              --
│    └─Clamp: 2-3725                     [16, 64, 16]              --
├─Conv1d: 1-281                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3726        --                        --
│    └─One: 2-3727                       [1]                       --
│    └─OutputScale: 2-3728               --                        --
│    └─Empty: 2-3729                     [64, 64, 1]               --
│    └─Empty: 2-3730                     [64, 64, 1]               --
│    └─Empty: 2-3731                     [64]                      --
│    └─Empty: 2-3732                     [64]                      --
│    └─Scaler: 2-3733                    [16, 64, 16]              --
│    └─Empty: 2-3734                     [16, 64, 16]              --
│    └─Empty: 2-3735                     [16, 64, 16]              --
│    └─Clamp: 2-3736                     [16, 64, 16]              --
├─Dropout: 1-282                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-283               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3737        --                        --
│    └─One: 2-3738                       [1]                       --
│    └─OutputScale: 2-3739               --                        --
│    └─Empty: 2-3740                     [64, 64, 3]               --
│    └─Empty: 2-3741                     [64, 64, 3]               --
│    └─Empty: 2-3742                     [64]                      --
│    └─Empty: 2-3743                     [64]                      --
│    └─BatchNorm1d: 2-3744               [16, 64, 16]              --
│    └─Scaler: 2-3745                    [16, 64, 16]              --
│    └─ReLU: 2-3746                      [16, 64, 16]              --
│    └─Empty: 2-3747                     [16, 64, 16]              --
│    └─Clamp: 2-3748                     [16, 64, 16]              --
├─Conv1d: 1-284                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3749        --                        --
│    └─One: 2-3750                       [1]                       --
│    └─OutputScale: 2-3751               --                        --
│    └─Empty: 2-3752                     [64, 64, 1]               --
│    └─Empty: 2-3753                     [64, 64, 1]               --
│    └─Empty: 2-3754                     [64]                      --
│    └─Empty: 2-3755                     [64]                      --
│    └─Scaler: 2-3756                    [16, 64, 16]              --
│    └─Empty: 2-3757                     [16, 64, 16]              --
│    └─Empty: 2-3758                     [16, 64, 16]              --
│    └─Clamp: 2-3759                     [16, 64, 16]              --
├─Dropout: 1-285                         [16, 64, 16]              --
├─Conv1d: 1-286                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3760        --                        --
│    └─One: 2-3761                       [1]                       --
│    └─OutputScale: 2-3762               --                        --
│    └─Empty: 2-3763                     [5, 64, 1]                --
│    └─Empty: 2-3764                     [5, 64, 1]                --
│    └─Empty: 2-3765                     [5]                       --
│    └─Empty: 2-3766                     [5]                       --
│    └─Scaler: 2-3767                    [16, 5, 16]               --
│    └─Empty: 2-3768                     [16, 5, 16]               --
│    └─Empty: 2-3769                     [16, 5, 16]               --
│    └─Clamp: 2-3770                     [16, 5, 16]               --
├─Conv1d: 1-287                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3771        --                        --
│    └─One: 2-3772                       [1]                       --
│    └─OutputScale: 2-3773               --                        --
│    └─Empty: 2-3774                     [64, 5, 1]                --
│    └─Empty: 2-3775                     [64, 5, 1]                --
│    └─Empty: 2-3776                     [64]                      --
│    └─Empty: 2-3777                     [64]                      --
│    └─Scaler: 2-3778                    [16, 64, 16]              --
│    └─Empty: 2-3779                     [16, 64, 16]              --
│    └─Empty: 2-3780                     [16, 64, 16]              --
│    └─Clamp: 2-3781                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-288               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3782        --                        --
│    └─One: 2-3783                       [1]                       --
│    └─OutputScale: 2-3784               --                        --
│    └─Empty: 2-3785                     [64, 64, 3]               --
│    └─Empty: 2-3786                     [64, 64, 3]               --
│    └─Empty: 2-3787                     [64]                      --
│    └─Empty: 2-3788                     [64]                      --
│    └─BatchNorm1d: 2-3789               [16, 64, 16]              --
│    └─Scaler: 2-3790                    [16, 64, 16]              --
│    └─ReLU: 2-3791                      [16, 64, 16]              --
│    └─Empty: 2-3792                     [16, 64, 16]              --
│    └─Clamp: 2-3793                     [16, 64, 16]              --
├─Conv1d: 1-289                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3794        --                        --
│    └─One: 2-3795                       [1]                       --
│    └─OutputScale: 2-3796               --                        --
│    └─Empty: 2-3797                     [64, 64, 1]               --
│    └─Empty: 2-3798                     [64, 64, 1]               --
│    └─Empty: 2-3799                     [64]                      --
│    └─Empty: 2-3800                     [64]                      --
│    └─Scaler: 2-3801                    [16, 64, 16]              --
│    └─Empty: 2-3802                     [16, 64, 16]              --
│    └─Empty: 2-3803                     [16, 64, 16]              --
│    └─Clamp: 2-3804                     [16, 64, 16]              --
├─Dropout: 1-290                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-291               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3805        --                        --
│    └─One: 2-3806                       [1]                       --
│    └─OutputScale: 2-3807               --                        --
│    └─Empty: 2-3808                     [64, 64, 3]               --
│    └─Empty: 2-3809                     [64, 64, 3]               --
│    └─Empty: 2-3810                     [64]                      --
│    └─Empty: 2-3811                     [64]                      --
│    └─BatchNorm1d: 2-3812               [16, 64, 16]              --
│    └─Scaler: 2-3813                    [16, 64, 16]              --
│    └─ReLU: 2-3814                      [16, 64, 16]              --
│    └─Empty: 2-3815                     [16, 64, 16]              --
│    └─Clamp: 2-3816                     [16, 64, 16]              --
├─Conv1d: 1-292                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3817        --                        --
│    └─One: 2-3818                       [1]                       --
│    └─OutputScale: 2-3819               --                        --
│    └─Empty: 2-3820                     [64, 64, 1]               --
│    └─Empty: 2-3821                     [64, 64, 1]               --
│    └─Empty: 2-3822                     [64]                      --
│    └─Empty: 2-3823                     [64]                      --
│    └─Scaler: 2-3824                    [16, 64, 16]              --
│    └─Empty: 2-3825                     [16, 64, 16]              --
│    └─Empty: 2-3826                     [16, 64, 16]              --
│    └─Clamp: 2-3827                     [16, 64, 16]              --
├─Dropout: 1-293                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-294               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3828        --                        --
│    └─One: 2-3829                       [1]                       --
│    └─OutputScale: 2-3830               --                        --
│    └─Empty: 2-3831                     [64, 64, 3]               --
│    └─Empty: 2-3832                     [64, 64, 3]               --
│    └─Empty: 2-3833                     [64]                      --
│    └─Empty: 2-3834                     [64]                      --
│    └─BatchNorm1d: 2-3835               [16, 64, 16]              --
│    └─Scaler: 2-3836                    [16, 64, 16]              --
│    └─ReLU: 2-3837                      [16, 64, 16]              --
│    └─Empty: 2-3838                     [16, 64, 16]              --
│    └─Clamp: 2-3839                     [16, 64, 16]              --
├─Conv1d: 1-295                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3840        --                        --
│    └─One: 2-3841                       [1]                       --
│    └─OutputScale: 2-3842               --                        --
│    └─Empty: 2-3843                     [64, 64, 1]               --
│    └─Empty: 2-3844                     [64, 64, 1]               --
│    └─Empty: 2-3845                     [64]                      --
│    └─Empty: 2-3846                     [64]                      --
│    └─Scaler: 2-3847                    [16, 64, 16]              --
│    └─Empty: 2-3848                     [16, 64, 16]              --
│    └─Empty: 2-3849                     [16, 64, 16]              --
│    └─Clamp: 2-3850                     [16, 64, 16]              --
├─Dropout: 1-296                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-297               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3851        --                        --
│    └─One: 2-3852                       [1]                       --
│    └─OutputScale: 2-3853               --                        --
│    └─Empty: 2-3854                     [64, 64, 3]               --
│    └─Empty: 2-3855                     [64, 64, 3]               --
│    └─Empty: 2-3856                     [64]                      --
│    └─Empty: 2-3857                     [64]                      --
│    └─BatchNorm1d: 2-3858               [16, 64, 16]              --
│    └─Scaler: 2-3859                    [16, 64, 16]              --
│    └─ReLU: 2-3860                      [16, 64, 16]              --
│    └─Empty: 2-3861                     [16, 64, 16]              --
│    └─Clamp: 2-3862                     [16, 64, 16]              --
├─Conv1d: 1-298                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3863        --                        --
│    └─One: 2-3864                       [1]                       --
│    └─OutputScale: 2-3865               --                        --
│    └─Empty: 2-3866                     [64, 64, 1]               --
│    └─Empty: 2-3867                     [64, 64, 1]               --
│    └─Empty: 2-3868                     [64]                      --
│    └─Empty: 2-3869                     [64]                      --
│    └─Scaler: 2-3870                    [16, 64, 16]              --
│    └─Empty: 2-3871                     [16, 64, 16]              --
│    └─Empty: 2-3872                     [16, 64, 16]              --
│    └─Clamp: 2-3873                     [16, 64, 16]              --
├─Dropout: 1-299                         [16, 64, 16]              --
├─Conv1d: 1-300                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3874        --                        --
│    └─One: 2-3875                       [1]                       --
│    └─OutputScale: 2-3876               --                        --
│    └─Empty: 2-3877                     [5, 64, 1]                --
│    └─Empty: 2-3878                     [5, 64, 1]                --
│    └─Empty: 2-3879                     [5]                       --
│    └─Empty: 2-3880                     [5]                       --
│    └─Scaler: 2-3881                    [16, 5, 16]               --
│    └─Empty: 2-3882                     [16, 5, 16]               --
│    └─Empty: 2-3883                     [16, 5, 16]               --
│    └─Clamp: 2-3884                     [16, 5, 16]               --
├─Conv1d: 1-301                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3885        --                        --
│    └─One: 2-3886                       [1]                       --
│    └─OutputScale: 2-3887               --                        --
│    └─Empty: 2-3888                     [64, 5, 1]                --
│    └─Empty: 2-3889                     [64, 5, 1]                --
│    └─Empty: 2-3890                     [64]                      --
│    └─Empty: 2-3891                     [64]                      --
│    └─Scaler: 2-3892                    [16, 64, 16]              --
│    └─Empty: 2-3893                     [16, 64, 16]              --
│    └─Empty: 2-3894                     [16, 64, 16]              --
│    └─Clamp: 2-3895                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-302               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3896        --                        --
│    └─One: 2-3897                       [1]                       --
│    └─OutputScale: 2-3898               --                        --
│    └─Empty: 2-3899                     [64, 64, 3]               --
│    └─Empty: 2-3900                     [64, 64, 3]               --
│    └─Empty: 2-3901                     [64]                      --
│    └─Empty: 2-3902                     [64]                      --
│    └─BatchNorm1d: 2-3903               [16, 64, 16]              --
│    └─Scaler: 2-3904                    [16, 64, 16]              --
│    └─ReLU: 2-3905                      [16, 64, 16]              --
│    └─Empty: 2-3906                     [16, 64, 16]              --
│    └─Clamp: 2-3907                     [16, 64, 16]              --
├─Conv1d: 1-303                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3908        --                        --
│    └─One: 2-3909                       [1]                       --
│    └─OutputScale: 2-3910               --                        --
│    └─Empty: 2-3911                     [64, 64, 1]               --
│    └─Empty: 2-3912                     [64, 64, 1]               --
│    └─Empty: 2-3913                     [64]                      --
│    └─Empty: 2-3914                     [64]                      --
│    └─Scaler: 2-3915                    [16, 64, 16]              --
│    └─Empty: 2-3916                     [16, 64, 16]              --
│    └─Empty: 2-3917                     [16, 64, 16]              --
│    └─Clamp: 2-3918                     [16, 64, 16]              --
├─Dropout: 1-304                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-305               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3919        --                        --
│    └─One: 2-3920                       [1]                       --
│    └─OutputScale: 2-3921               --                        --
│    └─Empty: 2-3922                     [64, 64, 3]               --
│    └─Empty: 2-3923                     [64, 64, 3]               --
│    └─Empty: 2-3924                     [64]                      --
│    └─Empty: 2-3925                     [64]                      --
│    └─BatchNorm1d: 2-3926               [16, 64, 16]              --
│    └─Scaler: 2-3927                    [16, 64, 16]              --
│    └─ReLU: 2-3928                      [16, 64, 16]              --
│    └─Empty: 2-3929                     [16, 64, 16]              --
│    └─Clamp: 2-3930                     [16, 64, 16]              --
├─Conv1d: 1-306                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3931        --                        --
│    └─One: 2-3932                       [1]                       --
│    └─OutputScale: 2-3933               --                        --
│    └─Empty: 2-3934                     [64, 64, 1]               --
│    └─Empty: 2-3935                     [64, 64, 1]               --
│    └─Empty: 2-3936                     [64]                      --
│    └─Empty: 2-3937                     [64]                      --
│    └─Scaler: 2-3938                    [16, 64, 16]              --
│    └─Empty: 2-3939                     [16, 64, 16]              --
│    └─Empty: 2-3940                     [16, 64, 16]              --
│    └─Clamp: 2-3941                     [16, 64, 16]              --
├─Dropout: 1-307                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-308               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3942        --                        --
│    └─One: 2-3943                       [1]                       --
│    └─OutputScale: 2-3944               --                        --
│    └─Empty: 2-3945                     [64, 64, 3]               --
│    └─Empty: 2-3946                     [64, 64, 3]               --
│    └─Empty: 2-3947                     [64]                      --
│    └─Empty: 2-3948                     [64]                      --
│    └─BatchNorm1d: 2-3949               [16, 64, 16]              --
│    └─Scaler: 2-3950                    [16, 64, 16]              --
│    └─ReLU: 2-3951                      [16, 64, 16]              --
│    └─Empty: 2-3952                     [16, 64, 16]              --
│    └─Clamp: 2-3953                     [16, 64, 16]              --
├─Conv1d: 1-309                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3954        --                        --
│    └─One: 2-3955                       [1]                       --
│    └─OutputScale: 2-3956               --                        --
│    └─Empty: 2-3957                     [64, 64, 1]               --
│    └─Empty: 2-3958                     [64, 64, 1]               --
│    └─Empty: 2-3959                     [64]                      --
│    └─Empty: 2-3960                     [64]                      --
│    └─Scaler: 2-3961                    [16, 64, 16]              --
│    └─Empty: 2-3962                     [16, 64, 16]              --
│    └─Empty: 2-3963                     [16, 64, 16]              --
│    └─Clamp: 2-3964                     [16, 64, 16]              --
├─Dropout: 1-310                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-311               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3965        --                        --
│    └─One: 2-3966                       [1]                       --
│    └─OutputScale: 2-3967               --                        --
│    └─Empty: 2-3968                     [64, 64, 3]               --
│    └─Empty: 2-3969                     [64, 64, 3]               --
│    └─Empty: 2-3970                     [64]                      --
│    └─Empty: 2-3971                     [64]                      --
│    └─BatchNorm1d: 2-3972               [16, 64, 16]              --
│    └─Scaler: 2-3973                    [16, 64, 16]              --
│    └─ReLU: 2-3974                      [16, 64, 16]              --
│    └─Empty: 2-3975                     [16, 64, 16]              --
│    └─Clamp: 2-3976                     [16, 64, 16]              --
├─Conv1d: 1-312                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3977        --                        --
│    └─One: 2-3978                       [1]                       --
│    └─OutputScale: 2-3979               --                        --
│    └─Empty: 2-3980                     [64, 64, 1]               --
│    └─Empty: 2-3981                     [64, 64, 1]               --
│    └─Empty: 2-3982                     [64]                      --
│    └─Empty: 2-3983                     [64]                      --
│    └─Scaler: 2-3984                    [16, 64, 16]              --
│    └─Empty: 2-3985                     [16, 64, 16]              --
│    └─Empty: 2-3986                     [16, 64, 16]              --
│    └─Clamp: 2-3987                     [16, 64, 16]              --
├─Dropout: 1-313                         [16, 64, 16]              --
├─Conv1d: 1-314                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3988        --                        --
│    └─One: 2-3989                       [1]                       --
│    └─OutputScale: 2-3990               --                        --
│    └─Empty: 2-3991                     [5, 64, 1]                --
│    └─Empty: 2-3992                     [5, 64, 1]                --
│    └─Empty: 2-3993                     [5]                       --
│    └─Empty: 2-3994                     [5]                       --
│    └─Scaler: 2-3995                    [16, 5, 16]               --
│    └─Empty: 2-3996                     [16, 5, 16]               --
│    └─Empty: 2-3997                     [16, 5, 16]               --
│    └─Clamp: 2-3998                     [16, 5, 16]               --
==========================================================================================
Total params: 646,761
Trainable params: 646,479
Non-trainable params: 282
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 4.735 | Acc: 35.000% | Wgt Acc: 25.602%
	I - Batch: 100 | Loss: 4.564 | Acc: 37.125% | Wgt Acc: 27.421%
	I - Batch: 150 | Loss: 4.487 | Acc: 38.500% | Wgt Acc: 29.624%
	I - Batch: 200 | Loss: 4.462 | Acc: 35.969% | Wgt Acc: 29.692%
	I - Batch: 250 | Loss: 4.418 | Acc: 34.250% | Wgt Acc: 30.629%
	I - Batch: 300 | Loss: 4.397 | Acc: 34.208% | Wgt Acc: 30.833%
	I - Batch: 350 | Loss: 4.390 | Acc: 33.018% | Wgt Acc: 31.152%
I - num batch: 364
I - Train -- Loss: 4.377 | Acc: 32.898% | Wgt Acc: 31.129% | LR: 1.000000e-03 | Dur: 227.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 287.   36.   55.  238.  214.]
 [  16.   26.   43.   14.  139.]
 [ 105.  316.  471.  154. 1212.]
 [ 149.   26.   55.  134.  203.]
 [ 135.  264.  350.  178.  995.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.486 | Acc: 35.250% | Wgt Acc: 40.039%
I - num batch: 87
I - Val -- Loss: 5.503 | Acc: 30.244% | Wgt Acc: 36.902% | Dur: 40.85s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   9.  21. 109.  40.]
 [ 16. 209. 217.  39. 286.]
 [  0.   0.   0.   0.   0.]
 [ 41.  31.  40.  51.  78.]
 [  8.  19.  12.   5.  27.]]

I - Local maximum validation set accuracy:  30.24

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 4.213 | Acc: 31.375% | Wgt Acc: 31.377%
	I - Batch: 100 | Loss: 4.213 | Acc: 30.375% | Wgt Acc: 31.286%
	I - Batch: 150 | Loss: 4.173 | Acc: 29.958% | Wgt Acc: 33.199%
	I - Batch: 200 | Loss: 4.198 | Acc: 28.531% | Wgt Acc: 33.233%
	I - Batch: 250 | Loss: 4.207 | Acc: 29.300% | Wgt Acc: 33.060%
	I - Batch: 300 | Loss: 4.224 | Acc: 30.542% | Wgt Acc: 32.689%
	I - Batch: 350 | Loss: 4.222 | Acc: 31.625% | Wgt Acc: 33.207%
I - num batch: 364
I - Train -- Loss: 4.218 | Acc: 31.384% | Wgt Acc: 33.215% | LR: 1.000000e-03 | Dur: 225.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 277.   16.   29.  224.  193.]
 [   7.   52.   69.   15.  135.]
 [  93.  369.  560.  134. 1414.]
 [ 205.   51.   67.  201.  286.]
 [ 110.  180.  249.  144.  735.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.535 | Acc: 33.000% | Wgt Acc: 37.246%
I - num batch: 87
I - Val -- Loss: 5.524 | Acc: 28.664% | Wgt Acc: 34.893% | Dur: 41.46s
I - Confusion Matrix: [row->prediction - col->label]
[[168.  37.  46. 158.  98.]
 [  5. 140. 169.  18. 176.]
 [ 21.  81.  70.  24. 136.]
 [  0.   0.   0.   0.   0.]
 [  5.  10.   5.   4.  21.]]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 4.149 | Acc: 32.000% | Wgt Acc: 36.611%
	I - Batch: 100 | Loss: 4.176 | Acc: 35.375% | Wgt Acc: 34.861%
	I - Batch: 150 | Loss: 4.196 | Acc: 37.583% | Wgt Acc: 35.321%
	I - Batch: 200 | Loss: 4.193 | Acc: 38.531% | Wgt Acc: 36.165%
	I - Batch: 250 | Loss: 4.187 | Acc: 37.850% | Wgt Acc: 36.485%
	I - Batch: 300 | Loss: 4.163 | Acc: 38.604% | Wgt Acc: 36.923%
	I - Batch: 350 | Loss: 4.145 | Acc: 39.518% | Wgt Acc: 37.080%
I - num batch: 364
I - Train -- Loss: 4.147 | Acc: 39.742% | Wgt Acc: 37.187% | LR: 1.000000e-03 | Dur: 226.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 335.   24.   53.  274.  239.]
 [   7.   50.   48.   17.   75.]
 [  73.  395.  539.  157. 1019.]
 [ 168.   36.   52.  155.  198.]
 [ 109.  163.  282.  115. 1232.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.339 | Acc: 31.375% | Wgt Acc: 24.516%
I - num batch: 87
I - Val -- Loss: 5.319 | Acc: 36.925% | Wgt Acc: 27.157% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 27.   0.   1.  18.   4.]
 [  0.   0.   0.   0.   0.]
 [ 25. 164. 119.  65.  98.]
 [ 72.   3.   6.  50.  11.]
 [ 75. 101. 164.  71. 318.]]

I - Local maximum validation set accuracy:  36.93

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 4.070 | Acc: 45.000% | Wgt Acc: 39.150%
	I - Batch: 100 | Loss: 4.030 | Acc: 46.000% | Wgt Acc: 41.677%
	I - Batch: 150 | Loss: 4.040 | Acc: 45.375% | Wgt Acc: 40.719%
	I - Batch: 200 | Loss: 4.010 | Acc: 45.969% | Wgt Acc: 41.057%
	I - Batch: 250 | Loss: 4.016 | Acc: 45.300% | Wgt Acc: 40.514%
	I - Batch: 300 | Loss: 4.025 | Acc: 45.292% | Wgt Acc: 40.501%
	I - Batch: 350 | Loss: 4.037 | Acc: 45.446% | Wgt Acc: 40.057%
I - num batch: 364
I - Train -- Loss: 4.028 | Acc: 45.623% | Wgt Acc: 40.196% | LR: 1.000000e-03 | Dur: 229.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 392.   26.   39.  307.  260.]
 [   5.   56.   57.   13.   37.]
 [  50.  385.  514.  150.  744.]
 [ 126.   41.   48.  124.  155.]
 [ 119.  160.  316.  124. 1567.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.462 | Acc: 40.000% | Wgt Acc: 34.605%
I - num batch: 87
I - Val -- Loss: 5.409 | Acc: 43.247% | Wgt Acc: 36.836% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   1.   4.  71.  17.]
 [  0.  68.  51.   9.   9.]
 [ 11.  95.  76.  11.  57.]
 [ 49.  26.  44.  79.  64.]
 [ 44.  78. 115.  34. 284.]]

I - Local maximum validation set accuracy:  43.25

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 3.991 | Acc: 46.375% | Wgt Acc: 42.379%
	I - Batch: 100 | Loss: 3.989 | Acc: 44.000% | Wgt Acc: 40.100%
	I - Batch: 150 | Loss: 3.999 | Acc: 44.375% | Wgt Acc: 40.319%
	I - Batch: 200 | Loss: 3.997 | Acc: 44.938% | Wgt Acc: 40.431%
	I - Batch: 250 | Loss: 3.982 | Acc: 45.825% | Wgt Acc: 40.916%
	I - Batch: 300 | Loss: 3.979 | Acc: 46.396% | Wgt Acc: 41.046%
	I - Batch: 350 | Loss: 3.973 | Acc: 46.679% | Wgt Acc: 41.094%
I - num batch: 364
I - Train -- Loss: 3.975 | Acc: 46.741% | Wgt Acc: 41.135% | LR: 1.000000e-03 | Dur: 229.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 270.    8.   26.  206.  157.]
 [   4.  111.   97.   10.   69.]
 [  51.  375.  465.  111.  642.]
 [ 228.   43.   73.  257.  280.]
 [ 139.  131.  313.  134. 1615.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.491 | Acc: 36.250% | Wgt Acc: 28.394%
I - num batch: 87
I - Val -- Loss: 5.411 | Acc: 42.601% | Wgt Acc: 32.501% | Dur: 42.20s
I - Confusion Matrix: [row->prediction - col->label]
[[141.  10.  14. 109.  51.]
 [  0.   0.   0.   0.   0.]
 [  5.  96.  74.  16.  27.]
 [ 14.  19.  24.  49.  24.]
 [ 39. 143. 178.  30. 329.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 3.936 | Acc: 46.500% | Wgt Acc: 39.414%
	I - Batch: 100 | Loss: 3.942 | Acc: 47.312% | Wgt Acc: 41.608%
	I - Batch: 150 | Loss: 3.970 | Acc: 46.917% | Wgt Acc: 41.675%
	I - Batch: 200 | Loss: 3.979 | Acc: 47.281% | Wgt Acc: 41.836%
	I - Batch: 250 | Loss: 3.990 | Acc: 45.775% | Wgt Acc: 40.670%
	I - Batch: 300 | Loss: 3.992 | Acc: 45.792% | Wgt Acc: 40.856%
	I - Batch: 350 | Loss: 3.990 | Acc: 46.179% | Wgt Acc: 41.307%
I - num batch: 364
I - Train -- Loss: 3.992 | Acc: 46.053% | Wgt Acc: 41.258% | LR: 1.000000e-03 | Dur: 229.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 256.   11.   25.  183.  181.]
 [  14.  216.  225.   42.  196.]
 [  36.  273.  352.   88.  553.]
 [ 241.   41.   69.  298.  277.]
 [ 145.  127.  303.  107. 1556.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.237 | Acc: 37.625% | Wgt Acc: 33.350%
I - num batch: 87
I - Val -- Loss: 5.237 | Acc: 41.307% | Wgt Acc: 35.903% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 48.   3.   2.  19.   6.]
 [  0.   1.   0.   1.   1.]
 [ 11. 181. 162.  22. 121.]
 [ 80.  33.  40. 111.  50.]
 [ 60.  50.  86.  51. 253.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 3.892 | Acc: 45.875% | Wgt Acc: 42.974%
	I - Batch: 100 | Loss: 3.838 | Acc: 48.375% | Wgt Acc: 44.658%
	I - Batch: 150 | Loss: 3.865 | Acc: 49.208% | Wgt Acc: 44.092%
	I - Batch: 200 | Loss: 3.905 | Acc: 49.062% | Wgt Acc: 43.644%
	I - Batch: 250 | Loss: 3.895 | Acc: 49.050% | Wgt Acc: 43.566%
	I - Batch: 300 | Loss: 3.900 | Acc: 49.250% | Wgt Acc: 43.305%
	I - Batch: 350 | Loss: 3.886 | Acc: 50.446% | Wgt Acc: 44.282%
I - num batch: 364
I - Train -- Loss: 3.878 | Acc: 50.267% | Wgt Acc: 44.157% | LR: 1.000000e-03 | Dur: 229.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 307.   12.   30.  197.  202.]
 [  17.  135.  117.   33.   62.]
 [  38.  364.  489.  106.  580.]
 [ 198.   56.   61.  246.  173.]
 [ 132.  101.  277.  136. 1746.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.345 | Acc: 39.625% | Wgt Acc: 42.735%
I - num batch: 87
I - Val -- Loss: 5.428 | Acc: 37.284% | Wgt Acc: 42.355% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[132.  11.  15.  97.  39.]
 [ 11. 176. 164.  29.  74.]
 [ 12.  66.  90.  19. 223.]
 [ 13.   3.  11.  36.  10.]
 [ 31.  12.  10.  23.  85.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 3.715 | Acc: 48.500% | Wgt Acc: 44.180%
	I - Batch: 100 | Loss: 3.792 | Acc: 50.625% | Wgt Acc: 44.042%
	I - Batch: 150 | Loss: 3.770 | Acc: 51.958% | Wgt Acc: 44.896%
	I - Batch: 200 | Loss: 3.830 | Acc: 50.688% | Wgt Acc: 44.145%
	I - Batch: 250 | Loss: 3.835 | Acc: 50.450% | Wgt Acc: 43.858%
	I - Batch: 300 | Loss: 3.848 | Acc: 50.312% | Wgt Acc: 43.929%
	I - Batch: 350 | Loss: 3.853 | Acc: 50.339% | Wgt Acc: 43.907%
I - num batch: 364
I - Train -- Loss: 3.847 | Acc: 50.335% | Wgt Acc: 43.952% | LR: 1.000000e-03 | Dur: 229.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 332.   10.   20.  221.  204.]
 [   8.  220.  222.   37.   94.]
 [  29.  272.  360.   76.  506.]
 [ 186.   45.   68.  245.  189.]
 [ 137.  121.  304.  139. 1770.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.497 | Acc: 40.875% | Wgt Acc: 36.057%
I - num batch: 87
I - Val -- Loss: 5.493 | Acc: 46.264% | Wgt Acc: 40.183% | Dur: 41.65s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   8.   8.  76.  12.]
 [  0.  57.  28.   1.   6.]
 [  9. 118. 119.  27.  67.]
 [ 52.  14.  37.  65.  55.]
 [ 26.  71.  98.  35. 291.]]

I - Local maximum validation set accuracy:  46.26

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 3.819 | Acc: 52.375% | Wgt Acc: 45.341%
	I - Batch: 100 | Loss: 3.879 | Acc: 51.562% | Wgt Acc: 45.474%
	I - Batch: 150 | Loss: 3.827 | Acc: 52.417% | Wgt Acc: 45.901%
	I - Batch: 200 | Loss: 3.830 | Acc: 51.656% | Wgt Acc: 45.875%
	I - Batch: 250 | Loss: 3.822 | Acc: 52.225% | Wgt Acc: 45.765%
	I - Batch: 300 | Loss: 3.824 | Acc: 51.688% | Wgt Acc: 45.411%
	I - Batch: 350 | Loss: 3.811 | Acc: 51.250% | Wgt Acc: 45.308%
I - num batch: 364
I - Train -- Loss: 3.804 | Acc: 51.212% | Wgt Acc: 45.343% | LR: 1.000000e-03 | Dur: 227.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 304.    7.   20.  163.  191.]
 [   3.   88.   71.   15.   37.]
 [  32.  405.  539.  106.  584.]
 [ 209.   61.   65.  303.  207.]
 [ 144.  107.  279.  131. 1744.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.530 | Acc: 40.500% | Wgt Acc: 35.200%
I - num batch: 87
I - Val -- Loss: 5.548 | Acc: 43.606% | Wgt Acc: 37.954% | Dur: 42.38s
I - Confusion Matrix: [row->prediction - col->label]
[[168.  19.  25. 136.  91.]
 [  0.   4.   3.   1.   0.]
 [  7. 181. 140.  14.  55.]
 [  7.  17.  27.  35.  25.]
 [ 17.  47.  95.  18. 260.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 3.803 | Acc: 49.625% | Wgt Acc: 43.206%
	I - Batch: 100 | Loss: 3.758 | Acc: 51.188% | Wgt Acc: 44.799%
	I - Batch: 150 | Loss: 3.746 | Acc: 52.042% | Wgt Acc: 45.102%
	I - Batch: 200 | Loss: 3.787 | Acc: 50.688% | Wgt Acc: 44.386%
	I - Batch: 250 | Loss: 3.780 | Acc: 51.425% | Wgt Acc: 45.062%
	I - Batch: 300 | Loss: 3.794 | Acc: 51.083% | Wgt Acc: 44.771%
	I - Batch: 350 | Loss: 3.786 | Acc: 51.161% | Wgt Acc: 45.011%
I - num batch: 364
I - Train -- Loss: 3.792 | Acc: 51.178% | Wgt Acc: 44.884% | LR: 1.000000e-03 | Dur: 230.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 311.   14.   26.  195.  193.]
 [   6.  150.  130.   21.   61.]
 [  41.  350.  447.   92.  523.]
 [ 218.   41.   77.  292.  210.]
 [ 116.  113.  294.  118. 1776.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.558 | Acc: 35.750% | Wgt Acc: 29.643%
I - num batch: 87
I - Val -- Loss: 5.542 | Acc: 41.379% | Wgt Acc: 33.709% | Dur: 42.33s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  2.  67.  61.   7.  12.]
 [  8.  79.  64.  20.  47.]
 [165.  21.  40. 144.  71.]
 [ 24. 101. 125.  33. 301.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 3.654 | Acc: 55.125% | Wgt Acc: 46.977%
	I - Batch: 100 | Loss: 3.662 | Acc: 54.062% | Wgt Acc: 46.119%
	I - Batch: 150 | Loss: 3.610 | Acc: 55.458% | Wgt Acc: 48.215%
	I - Batch: 200 | Loss: 3.625 | Acc: 55.344% | Wgt Acc: 48.106%
	I - Batch: 250 | Loss: 3.632 | Acc: 55.875% | Wgt Acc: 48.377%
	I - Batch: 300 | Loss: 3.622 | Acc: 55.083% | Wgt Acc: 47.896%
	I - Batch: 350 | Loss: 3.624 | Acc: 54.696% | Wgt Acc: 47.729%
I - num batch: 364
I - Train -- Loss: 3.621 | Acc: 54.738% | Wgt Acc: 47.720% | LR: 5.000000e-04 | Dur: 231.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 307.    7.   19.  187.  178.]
 [   3.  152.  123.   14.   37.]
 [  20.  371.  497.   71.  441.]
 [ 222.   51.   51.  306.  186.]
 [ 140.   87.  284.  140. 1921.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.419 | Acc: 46.125% | Wgt Acc: 42.857%
I - num batch: 87
I - Val -- Loss: 5.444 | Acc: 49.497% | Wgt Acc: 44.321% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 13.   0.   3.   7.   7.]
 [  3. 129.  62.  17.  14.]
 [  9.  74. 101.  11.  48.]
 [148.  15.  32. 141.  57.]
 [ 26.  50.  92.  28. 305.]]

I - Local maximum validation set accuracy:  49.50

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 3.698 | Acc: 52.125% | Wgt Acc: 44.304%
	I - Batch: 100 | Loss: 3.597 | Acc: 53.188% | Wgt Acc: 46.440%
	I - Batch: 150 | Loss: 3.555 | Acc: 54.417% | Wgt Acc: 47.819%
	I - Batch: 200 | Loss: 3.579 | Acc: 54.219% | Wgt Acc: 48.553%
	I - Batch: 250 | Loss: 3.571 | Acc: 54.525% | Wgt Acc: 49.121%
	I - Batch: 300 | Loss: 3.577 | Acc: 54.375% | Wgt Acc: 49.368%
	I - Batch: 350 | Loss: 3.557 | Acc: 55.393% | Wgt Acc: 50.253%
I - num batch: 364
I - Train -- Loss: 3.560 | Acc: 55.391% | Wgt Acc: 50.228% | LR: 5.000000e-04 | Dur: 231.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 362.   10.   17.  181.  202.]
 [   1.  130.   88.   13.   25.]
 [  33.  409.  590.   85.  518.]
 [ 177.   44.   63.  322.  201.]
 [ 119.   75.  216.  117. 1817.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.616 | Acc: 38.625% | Wgt Acc: 33.938%
I - num batch: 87
I - Val -- Loss: 5.539 | Acc: 44.181% | Wgt Acc: 38.361% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[168.  14.  40. 125.  94.]
 [  0.   0.   0.   0.   0.]
 [  1. 147. 130.   5.  35.]
 [ 15.  49.  36.  56.  41.]
 [ 15.  58.  84.  18. 261.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 3.544 | Acc: 56.000% | Wgt Acc: 51.524%
	I - Batch: 100 | Loss: 3.519 | Acc: 55.250% | Wgt Acc: 51.620%
	I - Batch: 150 | Loss: 3.544 | Acc: 56.042% | Wgt Acc: 52.343%
	I - Batch: 200 | Loss: 3.528 | Acc: 55.562% | Wgt Acc: 52.260%
	I - Batch: 250 | Loss: 3.497 | Acc: 56.475% | Wgt Acc: 52.862%
	I - Batch: 300 | Loss: 3.503 | Acc: 56.917% | Wgt Acc: 53.414%
	I - Batch: 350 | Loss: 3.519 | Acc: 56.446% | Wgt Acc: 53.291%
I - num batch: 364
I - Train -- Loss: 3.524 | Acc: 56.371% | Wgt Acc: 53.147% | LR: 5.000000e-04 | Dur: 231.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 365.    8.   15.  170.  202.]
 [   9.  261.  129.   27.   76.]
 [  30.  277.  543.   60.  533.]
 [ 161.   60.   59.  368.  211.]
 [ 127.   62.  228.   93. 1741.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.721 | Acc: 42.750% | Wgt Acc: 35.849%
I - num batch: 87
I - Val -- Loss: 5.618 | Acc: 49.353% | Wgt Acc: 40.303% | Dur: 42.49s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   9.  16. 102.  32.]
 [  1.  76.  24.   3.   7.]
 [  2.  50.  74.   5.  21.]
 [  6.  15.  13.  39.  16.]
 [ 47. 118. 163.  55. 355.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 3.500 | Acc: 58.625% | Wgt Acc: 54.840%
	I - Batch: 100 | Loss: 3.444 | Acc: 59.062% | Wgt Acc: 55.821%
	I - Batch: 150 | Loss: 3.421 | Acc: 59.167% | Wgt Acc: 55.963%
	I - Batch: 200 | Loss: 3.448 | Acc: 58.625% | Wgt Acc: 55.847%
	I - Batch: 250 | Loss: 3.477 | Acc: 58.175% | Wgt Acc: 55.377%
	I - Batch: 300 | Loss: 3.468 | Acc: 58.438% | Wgt Acc: 55.554%
	I - Batch: 350 | Loss: 3.483 | Acc: 58.214% | Wgt Acc: 55.477%
I - num batch: 364
I - Train -- Loss: 3.477 | Acc: 58.143% | Wgt Acc: 55.454% | LR: 5.000000e-04 | Dur: 231.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 386.   11.   17.  174.  183.]
 [  10.  348.  182.   40.  120.]
 [  25.  197.  531.   59.  486.]
 [ 163.   41.   49.  342.  200.]
 [ 108.   71.  195.  103. 1774.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.606 | Acc: 48.500% | Wgt Acc: 48.726%
I - num batch: 87
I - Val -- Loss: 5.600 | Acc: 49.353% | Wgt Acc: 50.114% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   3.  13.  32.  38.]
 [  3. 152. 104.   8.  36.]
 [  2.  28.  86.   2.  64.]
 [ 78.  48.  51. 152. 101.]
 [ 11.  37.  36.  10. 192.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 3.408 | Acc: 58.875% | Wgt Acc: 57.845%
	I - Batch: 100 | Loss: 3.417 | Acc: 57.375% | Wgt Acc: 56.659%
	I - Batch: 150 | Loss: 3.398 | Acc: 58.583% | Wgt Acc: 57.205%
	I - Batch: 200 | Loss: 3.431 | Acc: 58.625% | Wgt Acc: 56.674%
	I - Batch: 250 | Loss: 3.413 | Acc: 59.325% | Wgt Acc: 57.626%
	I - Batch: 300 | Loss: 3.398 | Acc: 59.771% | Wgt Acc: 58.250%
	I - Batch: 350 | Loss: 3.407 | Acc: 59.446% | Wgt Acc: 57.827%
I - num batch: 364
I - Train -- Loss: 3.400 | Acc: 59.553% | Wgt Acc: 57.899% | LR: 5.000000e-04 | Dur: 231.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 403.    5.   13.  160.  205.]
 [  11.  402.  182.   47.  121.]
 [  31.  166.  551.   43.  470.]
 [ 160.   39.   49.  349.  209.]
 [  87.   56.  179.  119. 1758.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.596 | Acc: 50.750% | Wgt Acc: 49.142%
I - num batch: 87
I - Val -- Loss: 5.585 | Acc: 52.227% | Wgt Acc: 50.079% | Dur: 42.78s
I - Confusion Matrix: [row->prediction - col->label]
[[158.  13.  20. 117.  55.]
 [  2.  83.  16.   4.   9.]
 [  6. 106. 178.  12.  82.]
 [ 14.  22.  25.  56.  33.]
 [ 19.  44.  51.  15. 252.]]

I - Local maximum validation set accuracy:  52.23

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 3.340 | Acc: 60.250% | Wgt Acc: 60.778%
	I - Batch: 100 | Loss: 3.341 | Acc: 60.000% | Wgt Acc: 60.227%
	I - Batch: 150 | Loss: 3.312 | Acc: 60.833% | Wgt Acc: 60.583%
	I - Batch: 200 | Loss: 3.313 | Acc: 61.250% | Wgt Acc: 61.001%
	I - Batch: 250 | Loss: 3.322 | Acc: 60.625% | Wgt Acc: 59.954%
	I - Batch: 300 | Loss: 3.308 | Acc: 60.958% | Wgt Acc: 60.140%
	I - Batch: 350 | Loss: 3.325 | Acc: 60.786% | Wgt Acc: 60.122%
I - num batch: 364
I - Train -- Loss: 3.321 | Acc: 60.894% | Wgt Acc: 60.184% | LR: 5.000000e-04 | Dur: 231.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 401.    6.   11.  164.  197.]
 [  10.  428.  123.   38.  125.]
 [  23.  136.  601.   46.  487.]
 [ 152.   35.   52.  368.  211.]
 [ 106.   63.  187.  102. 1743.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.436 | Acc: 52.875% | Wgt Acc: 50.570%
I - num batch: 87
I - Val -- Loss: 5.436 | Acc: 55.316% | Wgt Acc: 52.278% | Dur: 42.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 48.   0.   4.   3.   6.]
 [ 11. 168.  59.  39.  49.]
 [  5.  30. 137.  15.  45.]
 [ 98.   8.  15. 116.  30.]
 [ 37.  62.  75.  31. 301.]]

I - Local maximum validation set accuracy:  55.32

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 3.265 | Acc: 61.750% | Wgt Acc: 60.708%
	I - Batch: 100 | Loss: 3.316 | Acc: 60.875% | Wgt Acc: 59.278%
	I - Batch: 150 | Loss: 3.306 | Acc: 61.250% | Wgt Acc: 59.804%
	I - Batch: 200 | Loss: 3.296 | Acc: 61.156% | Wgt Acc: 60.435%
	I - Batch: 250 | Loss: 3.288 | Acc: 61.875% | Wgt Acc: 61.108%
	I - Batch: 300 | Loss: 3.285 | Acc: 62.229% | Wgt Acc: 61.350%
	I - Batch: 350 | Loss: 3.278 | Acc: 62.268% | Wgt Acc: 61.288%
I - num batch: 364
I - Train -- Loss: 3.271 | Acc: 62.425% | Wgt Acc: 61.430% | LR: 5.000000e-04 | Dur: 231.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 385.    8.   10.  164.  174.]
 [   7.  450.  104.   49.  127.]
 [  17.  115.  633.   42.  446.]
 [ 156.   27.   57.  348.  202.]
 [ 127.   68.  170.  115. 1814.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.663 | Acc: 51.375% | Wgt Acc: 47.433%
I - num batch: 87
I - Val -- Loss: 5.603 | Acc: 54.813% | Wgt Acc: 48.945% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   1.   9.  16.  11.]
 [  3. 132.  38.   9.  19.]
 [  1.  47. 115.  10.  37.]
 [ 87.  11.  15. 117.  27.]
 [ 46.  77. 113.  52. 337.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 3.095 | Acc: 64.750% | Wgt Acc: 63.571%
	I - Batch: 100 | Loss: 3.137 | Acc: 63.938% | Wgt Acc: 63.918%
	I - Batch: 150 | Loss: 3.135 | Acc: 63.667% | Wgt Acc: 63.721%
	I - Batch: 200 | Loss: 3.165 | Acc: 63.688% | Wgt Acc: 63.339%
	I - Batch: 250 | Loss: 3.184 | Acc: 63.825% | Wgt Acc: 63.336%
	I - Batch: 300 | Loss: 3.190 | Acc: 63.979% | Wgt Acc: 63.090%
	I - Batch: 350 | Loss: 3.177 | Acc: 64.375% | Wgt Acc: 63.557%
I - num batch: 364
I - Train -- Loss: 3.181 | Acc: 64.316% | Wgt Acc: 63.555% | LR: 5.000000e-04 | Dur: 232.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 370.    9.   11.  118.  169.]
 [   8.  481.  100.   35.  133.]
 [  14.   93.  618.   38.  411.]
 [ 171.   31.   50.  422.  201.]
 [ 129.   54.  195.  105. 1849.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.586 | Acc: 54.375% | Wgt Acc: 53.149%
I - num batch: 87
I - Val -- Loss: 5.571 | Acc: 56.034% | Wgt Acc: 54.716% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   5.   7.  15.]
 [  4. 134.  24.  11.  36.]
 [  2.  61. 169.  15.  70.]
 [105.  20.  31. 149.  47.]
 [ 23.  50.  61.  22. 263.]]

I - Local maximum validation set accuracy:  56.03

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 2.985 | Acc: 66.875% | Wgt Acc: 67.148%
	I - Batch: 100 | Loss: 3.009 | Acc: 66.500% | Wgt Acc: 67.477%
	I - Batch: 150 | Loss: 3.035 | Acc: 66.083% | Wgt Acc: 66.805%
	I - Batch: 200 | Loss: 3.037 | Acc: 66.000% | Wgt Acc: 66.738%
	I - Batch: 250 | Loss: 3.068 | Acc: 66.125% | Wgt Acc: 66.555%
	I - Batch: 300 | Loss: 3.066 | Acc: 66.500% | Wgt Acc: 66.677%
	I - Batch: 350 | Loss: 3.083 | Acc: 66.429% | Wgt Acc: 66.426%
I - num batch: 364
I - Train -- Loss: 3.080 | Acc: 66.380% | Wgt Acc: 66.436% | LR: 5.000000e-04 | Dur: 231.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 418.   10.   12.  111.  169.]
 [  20.  496.   91.   36.  146.]
 [  16.   82.  658.   32.  379.]
 [ 132.   20.   36.  435.  216.]
 [ 106.   60.  177.  104. 1853.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.657 | Acc: 54.625% | Wgt Acc: 51.807%
I - num batch: 87
I - Val -- Loss: 5.603 | Acc: 56.609% | Wgt Acc: 53.295% | Dur: 42.75s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   1.   8.  33.  13.]
 [  5. 101.  15.  19.  14.]
 [ 12.  95. 193.  23.  87.]
 [ 35.  10.   7.  90.  20.]
 [ 40.  61.  67.  39. 297.]]

I - Local maximum validation set accuracy:  56.61

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 3.003 | Acc: 66.500% | Wgt Acc: 67.518%
	I - Batch: 100 | Loss: 2.967 | Acc: 67.500% | Wgt Acc: 68.515%
	I - Batch: 150 | Loss: 2.974 | Acc: 67.625% | Wgt Acc: 68.625%
	I - Batch: 200 | Loss: 2.993 | Acc: 67.188% | Wgt Acc: 67.701%
	I - Batch: 250 | Loss: 2.992 | Acc: 67.450% | Wgt Acc: 67.833%
	I - Batch: 300 | Loss: 2.993 | Acc: 67.458% | Wgt Acc: 67.716%
	I - Batch: 350 | Loss: 2.996 | Acc: 67.536% | Wgt Acc: 67.759%
I - num batch: 364
I - Train -- Loss: 2.996 | Acc: 67.463% | Wgt Acc: 67.696% | LR: 5.000000e-04 | Dur: 231.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 400.    9.   12.  104.  166.]
 [  13.  505.   61.   29.  139.]
 [  15.   76.  690.   28.  382.]
 [ 148.   23.   32.  452.  200.]
 [ 116.   55.  179.  105. 1876.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.520 | Acc: 51.750% | Wgt Acc: 50.833%
I - num batch: 87
I - Val -- Loss: 5.576 | Acc: 52.299% | Wgt Acc: 50.873% | Dur: 42.85s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   8.  15.  69.  29.]
 [  9. 169.  98.  50.  47.]
 [  4.  42. 109.  15.  83.]
 [ 18.  11.  12.  50.  17.]
 [ 23.  38.  56.  20. 255.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 3.041 | Acc: 68.750% | Wgt Acc: 68.109%
	I - Batch: 100 | Loss: 2.865 | Acc: 71.562% | Wgt Acc: 71.100%
	I - Batch: 150 | Loss: 2.900 | Acc: 71.250% | Wgt Acc: 70.511%
	I - Batch: 200 | Loss: 2.859 | Acc: 71.375% | Wgt Acc: 71.157%
	I - Batch: 250 | Loss: 2.846 | Acc: 71.125% | Wgt Acc: 71.293%
	I - Batch: 300 | Loss: 2.837 | Acc: 71.312% | Wgt Acc: 71.470%
	I - Batch: 350 | Loss: 2.837 | Acc: 71.214% | Wgt Acc: 71.499%
I - num batch: 364
I - Train -- Loss: 2.837 | Acc: 71.230% | Wgt Acc: 71.557% | LR: 2.500000e-04 | Dur: 232.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 439.    8.    7.   93.  168.]
 [   8.  523.   58.   31.  110.]
 [  12.   58.  733.   26.  350.]
 [ 112.   18.   37.  475.  163.]
 [ 121.   61.  139.   93. 1972.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.684 | Acc: 55.625% | Wgt Acc: 51.225%
I - num batch: 87
I - Val -- Loss: 5.633 | Acc: 59.914% | Wgt Acc: 54.077% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.   7.  40.   7.]
 [  6. 125.  32.  10.  17.]
 [  6.  57. 141.   8.  26.]
 [ 25.  13.  18. 104.  28.]
 [ 51.  72.  92.  42. 353.]]

I - Local maximum validation set accuracy:  59.91

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 2.794 | Acc: 70.000% | Wgt Acc: 72.218%
	I - Batch: 100 | Loss: 2.754 | Acc: 72.062% | Wgt Acc: 73.635%
	I - Batch: 150 | Loss: 2.763 | Acc: 71.875% | Wgt Acc: 73.309%
	I - Batch: 200 | Loss: 2.704 | Acc: 73.062% | Wgt Acc: 74.458%
	I - Batch: 250 | Loss: 2.701 | Acc: 73.000% | Wgt Acc: 74.274%
	I - Batch: 300 | Loss: 2.686 | Acc: 73.479% | Wgt Acc: 74.726%
	I - Batch: 350 | Loss: 2.687 | Acc: 73.250% | Wgt Acc: 74.637%
I - num batch: 364
I - Train -- Loss: 2.695 | Acc: 73.138% | Wgt Acc: 74.454% | LR: 2.500000e-04 | Dur: 229.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 452.    6.   13.   84.  165.]
 [   7.  556.   35.   22.  103.]
 [  17.   45.  781.   22.  306.]
 [ 116.   18.   24.  495.  220.]
 [ 100.   43.  121.   95. 1969.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.744 | Acc: 56.250% | Wgt Acc: 52.260%
I - num batch: 87
I - Val -- Loss: 5.690 | Acc: 59.555% | Wgt Acc: 54.584% | Dur: 42.14s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   4.  10.  36.  17.]
 [  1. 132.  39.   5.  15.]
 [  4.  40. 117.  13.  32.]
 [ 39.  20.  21. 126.  35.]
 [ 33.  72. 103.  24. 332.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 2.629 | Acc: 75.125% | Wgt Acc: 75.293%
	I - Batch: 100 | Loss: 2.630 | Acc: 74.750% | Wgt Acc: 75.157%
	I - Batch: 150 | Loss: 2.636 | Acc: 74.375% | Wgt Acc: 74.766%
	I - Batch: 200 | Loss: 2.646 | Acc: 73.938% | Wgt Acc: 74.359%
	I - Batch: 250 | Loss: 2.641 | Acc: 74.325% | Wgt Acc: 74.534%
	I - Batch: 300 | Loss: 2.643 | Acc: 74.375% | Wgt Acc: 74.538%
	I - Batch: 350 | Loss: 2.642 | Acc: 74.321% | Wgt Acc: 74.568%
I - num batch: 364
I - Train -- Loss: 2.637 | Acc: 74.428% | Wgt Acc: 74.704% | LR: 2.500000e-04 | Dur: 229.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 450.    7.   10.   87.  145.]
 [  13.  557.   39.   21.  102.]
 [  13.   41.  769.   27.  269.]
 [ 108.   14.   19.  482.  177.]
 [ 108.   49.  137.  101. 2070.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.639 | Acc: 59.250% | Wgt Acc: 57.884%
I - num batch: 87
I - Val -- Loss: 5.622 | Acc: 60.057% | Wgt Acc: 58.694% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   2.  12.  13.  12.]
 [  5. 130.  31.   2.  18.]
 [  4.  72. 161.  11.  68.]
 [ 57.  27.  36. 162.  62.]
 [ 21.  37.  50.  16. 271.]]

I - Local maximum validation set accuracy:  60.06

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 2.486 | Acc: 77.625% | Wgt Acc: 80.144%
	I - Batch: 100 | Loss: 2.539 | Acc: 76.062% | Wgt Acc: 78.260%
	I - Batch: 150 | Loss: 2.583 | Acc: 75.167% | Wgt Acc: 77.177%
	I - Batch: 200 | Loss: 2.558 | Acc: 75.656% | Wgt Acc: 77.376%
	I - Batch: 250 | Loss: 2.516 | Acc: 76.575% | Wgt Acc: 78.212%
	I - Batch: 300 | Loss: 2.523 | Acc: 76.604% | Wgt Acc: 78.193%
	I - Batch: 350 | Loss: 2.527 | Acc: 76.375% | Wgt Acc: 77.924%
I - num batch: 364
I - Train -- Loss: 2.532 | Acc: 76.303% | Wgt Acc: 77.691% | LR: 2.500000e-04 | Dur: 228.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 472.    8.    9.   65.  141.]
 [   4.  589.   31.   13.   86.]
 [   9.   29.  791.   22.  304.]
 [  97.   12.   27.  534.  181.]
 [ 110.   30.  116.   84. 2051.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.694 | Acc: 56.250% | Wgt Acc: 53.798%
I - num batch: 87
I - Val -- Loss: 5.647 | Acc: 57.830% | Wgt Acc: 54.944% | Dur: 42.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 88.   0.   9.  12.   6.]
 [  5. 113.  23.   5.  12.]
 [  7.  73. 170.   7.  76.]
 [ 52.  24.  30. 143.  46.]
 [ 47.  58.  58.  37. 291.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 2.457 | Acc: 76.750% | Wgt Acc: 79.285%
	I - Batch: 100 | Loss: 2.520 | Acc: 75.875% | Wgt Acc: 78.353%
	I - Batch: 150 | Loss: 2.482 | Acc: 77.042% | Wgt Acc: 79.106%
	I - Batch: 200 | Loss: 2.500 | Acc: 77.125% | Wgt Acc: 78.802%
	I - Batch: 250 | Loss: 2.517 | Acc: 77.075% | Wgt Acc: 78.451%
	I - Batch: 300 | Loss: 2.512 | Acc: 77.292% | Wgt Acc: 78.343%
	I - Batch: 350 | Loss: 2.523 | Acc: 76.750% | Wgt Acc: 77.936%
I - num batch: 364
I - Train -- Loss: 2.526 | Acc: 76.733% | Wgt Acc: 77.807% | LR: 2.500000e-04 | Dur: 228.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 495.    8.   10.   72.  147.]
 [   7.  572.   26.   23.   93.]
 [   7.   40.  810.   24.  276.]
 [  79.    8.   22.  504.  166.]
 [ 104.   40.  106.   95. 2081.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.747 | Acc: 55.375% | Wgt Acc: 51.244%
I - num batch: 87
I - Val -- Loss: 5.687 | Acc: 58.261% | Wgt Acc: 52.599% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   0.   7.  13.   8.]
 [  6. 134.  34.   9.  16.]
 [  7.  43. 138.  14.  42.]
 [ 28.   8.   9.  95.  17.]
 [ 62.  83. 102.  73. 348.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 2.313 | Acc: 81.375% | Wgt Acc: 82.631%
	I - Batch: 100 | Loss: 2.352 | Acc: 80.250% | Wgt Acc: 81.842%
	I - Batch: 150 | Loss: 2.319 | Acc: 80.958% | Wgt Acc: 82.364%
	I - Batch: 200 | Loss: 2.326 | Acc: 80.250% | Wgt Acc: 82.020%
	I - Batch: 250 | Loss: 2.342 | Acc: 79.925% | Wgt Acc: 81.595%
	I - Batch: 300 | Loss: 2.328 | Acc: 79.958% | Wgt Acc: 81.739%
	I - Batch: 350 | Loss: 2.338 | Acc: 79.732% | Wgt Acc: 81.468%
I - num batch: 364
I - Train -- Loss: 2.340 | Acc: 79.880% | Wgt Acc: 81.483% | LR: 1.250000e-04 | Dur: 228.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 510.    7.    9.   42.  150.]
 [   6.  592.   13.   12.   68.]
 [  14.   23.  841.   13.  252.]
 [  64.   12.   20.  572.  163.]
 [  98.   34.   91.   79. 2130.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.864 | Acc: 54.250% | Wgt Acc: 48.665%
I - num batch: 87
I - Val -- Loss: 5.784 | Acc: 58.693% | Wgt Acc: 51.484% | Dur: 41.86s
I - Confusion Matrix: [row->prediction - col->label]
[[156.  11.  23.  66.  30.]
 [  2. 106.  27.   5.  10.]
 [  2.  30. 103.   2.  11.]
 [ 11.  14.  23.  91.  19.]
 [ 28. 107. 114.  40. 361.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 2.125 | Acc: 82.875% | Wgt Acc: 84.070%
	I - Batch: 100 | Loss: 2.289 | Acc: 81.000% | Wgt Acc: 81.965%
	I - Batch: 150 | Loss: 2.283 | Acc: 81.333% | Wgt Acc: 82.502%
	I - Batch: 200 | Loss: 2.294 | Acc: 81.281% | Wgt Acc: 82.572%
	I - Batch: 250 | Loss: 2.303 | Acc: 81.200% | Wgt Acc: 82.342%
	I - Batch: 300 | Loss: 2.315 | Acc: 80.771% | Wgt Acc: 82.074%
	I - Batch: 350 | Loss: 2.310 | Acc: 80.964% | Wgt Acc: 82.236%
I - num batch: 364
I - Train -- Loss: 2.313 | Acc: 80.911% | Wgt Acc: 82.177% | LR: 1.250000e-04 | Dur: 228.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 533.    7.    9.   56.  152.]
 [   5.  585.   17.   13.   79.]
 [  12.   29.  850.   11.  209.]
 [  50.   15.   10.  560.  146.]
 [  92.   32.   88.   78. 2177.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.679 | Acc: 59.000% | Wgt Acc: 57.394%
I - num batch: 87
I - Val -- Loss: 5.657 | Acc: 59.842% | Wgt Acc: 58.149% | Dur: 41.79s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   6.  21.  38.  34.]
 [  0. 107.  19.   1.   8.]
 [  1.  71. 169.   9.  58.]
 [ 35.  29.  35. 140.  61.]
 [ 16.  55.  46.  16. 270.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 2.258 | Acc: 82.250% | Wgt Acc: 83.574%
	I - Batch: 100 | Loss: 2.206 | Acc: 82.562% | Wgt Acc: 83.585%
	I - Batch: 150 | Loss: 2.221 | Acc: 82.167% | Wgt Acc: 83.318%
	I - Batch: 200 | Loss: 2.244 | Acc: 81.875% | Wgt Acc: 83.211%
	I - Batch: 250 | Loss: 2.223 | Acc: 82.500% | Wgt Acc: 83.838%
	I - Batch: 300 | Loss: 2.229 | Acc: 82.438% | Wgt Acc: 83.736%
	I - Batch: 350 | Loss: 2.228 | Acc: 82.500% | Wgt Acc: 83.785%
I - num batch: 364
I - Train -- Loss: 2.227 | Acc: 82.476% | Wgt Acc: 83.815% | LR: 1.250000e-04 | Dur: 227.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 533.    8.    7.   35.  152.]
 [   6.  604.   16.   12.   50.]
 [  10.   18.  851.   10.  209.]
 [  53.    9.   12.  593.  137.]
 [  90.   29.   88.   68. 2215.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.740 | Acc: 55.500% | Wgt Acc: 51.672%
I - num batch: 87
I - Val -- Loss: 5.701 | Acc: 58.836% | Wgt Acc: 54.143% | Dur: 41.73s
I - Confusion Matrix: [row->prediction - col->label]
[[154.   9.  15.  56.  29.]
 [  1.  97.  16.   4.   3.]
 [  5.  74. 138.  10.  35.]
 [ 18.  27.  37. 114.  48.]
 [ 21.  61.  84.  20. 316.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 2.140 | Acc: 85.625% | Wgt Acc: 87.501%
	I - Batch: 100 | Loss: 2.168 | Acc: 84.625% | Wgt Acc: 86.310%
	I - Batch: 150 | Loss: 2.208 | Acc: 82.792% | Wgt Acc: 84.723%
	I - Batch: 200 | Loss: 2.202 | Acc: 82.781% | Wgt Acc: 84.581%
	I - Batch: 250 | Loss: 2.212 | Acc: 82.675% | Wgt Acc: 84.345%
	I - Batch: 300 | Loss: 2.199 | Acc: 82.812% | Wgt Acc: 84.608%
	I - Batch: 350 | Loss: 2.189 | Acc: 83.107% | Wgt Acc: 84.935%
I - num batch: 364
I - Train -- Loss: 2.188 | Acc: 83.233% | Wgt Acc: 85.028% | LR: 1.250000e-04 | Dur: 227.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 547.    3.    9.   31.  138.]
 [   5.  608.   10.   11.   53.]
 [   6.   17.  871.    8.  218.]
 [  44.    9.   10.  608.  148.]
 [  90.   31.   74.   60. 2206.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.674 | Acc: 57.375% | Wgt Acc: 54.068%
I - num batch: 87
I - Val -- Loss: 5.664 | Acc: 60.129% | Wgt Acc: 56.647% | Dur: 41.77s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   6.  10.  25.  17.]
 [  3. 114.  25.   9.  14.]
 [  4.  64. 169.  11.  62.]
 [ 25.  21.  28. 114.  29.]
 [ 36.  63.  58.  45. 309.]]

I - Local maximum validation set accuracy:  60.13

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 2.163 | Acc: 84.000% | Wgt Acc: 85.254%
	I - Batch: 100 | Loss: 2.166 | Acc: 84.250% | Wgt Acc: 84.865%
	I - Batch: 150 | Loss: 2.122 | Acc: 84.250% | Wgt Acc: 85.333%
	I - Batch: 200 | Loss: 2.144 | Acc: 84.031% | Wgt Acc: 85.169%
	I - Batch: 250 | Loss: 2.152 | Acc: 83.450% | Wgt Acc: 84.793%
	I - Batch: 300 | Loss: 2.143 | Acc: 83.396% | Wgt Acc: 84.806%
	I - Batch: 350 | Loss: 2.172 | Acc: 83.107% | Wgt Acc: 84.349%
I - num batch: 364
I - Train -- Loss: 2.171 | Acc: 83.147% | Wgt Acc: 84.392% | LR: 1.250000e-04 | Dur: 227.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 552.    5.   11.   52.  141.]
 [   4.  604.   11.   10.   55.]
 [   8.   18.  864.   12.  192.]
 [  44.   10.   13.  575.  135.]
 [  84.   31.   75.   69. 2240.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.799 | Acc: 56.500% | Wgt Acc: 51.813%
I - num batch: 87
I - Val -- Loss: 5.727 | Acc: 59.411% | Wgt Acc: 53.295% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   2.   8.  19.  10.]
 [  1.  85.  11.   0.   6.]
 [  5.  67. 146.  12.  27.]
 [ 29.  23.  26. 131.  45.]
 [ 42.  91.  99.  42. 343.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 2.128 | Acc: 84.125% | Wgt Acc: 85.661%
	I - Batch: 100 | Loss: 2.146 | Acc: 83.750% | Wgt Acc: 85.105%
	I - Batch: 150 | Loss: 2.179 | Acc: 83.208% | Wgt Acc: 84.467%
	I - Batch: 200 | Loss: 2.178 | Acc: 83.281% | Wgt Acc: 84.572%
	I - Batch: 250 | Loss: 2.145 | Acc: 83.825% | Wgt Acc: 85.238%
	I - Batch: 300 | Loss: 2.165 | Acc: 83.521% | Wgt Acc: 84.901%
	I - Batch: 350 | Loss: 2.166 | Acc: 83.304% | Wgt Acc: 84.851%
I - num batch: 364
I - Train -- Loss: 2.164 | Acc: 83.336% | Wgt Acc: 84.867% | LR: 1.250000e-04 | Dur: 228.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 549.    6.   11.   34.  151.]
 [   7.  604.    8.    9.   67.]
 [   6.   21.  877.   10.  172.]
 [  41.   10.   13.  589.  146.]
 [  89.   27.   65.   76. 2227.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.753 | Acc: 56.125% | Wgt Acc: 52.640%
I - num batch: 87
I - Val -- Loss: 5.695 | Acc: 58.405% | Wgt Acc: 54.302% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   1.  10.  14.   8.]
 [  0. 100.  29.   5.   4.]
 [  5.  74. 154.  10.  59.]
 [ 48.  24.  33. 141.  52.]
 [ 36.  69.  64.  34. 308.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 2.028 | Acc: 85.125% | Wgt Acc: 86.994%
	I - Batch: 100 | Loss: 2.091 | Acc: 84.438% | Wgt Acc: 85.754%
	I - Batch: 150 | Loss: 2.075 | Acc: 84.625% | Wgt Acc: 86.121%
	I - Batch: 200 | Loss: 2.093 | Acc: 84.781% | Wgt Acc: 86.049%
	I - Batch: 250 | Loss: 2.098 | Acc: 84.725% | Wgt Acc: 85.961%
	I - Batch: 300 | Loss: 2.095 | Acc: 84.688% | Wgt Acc: 85.835%
	I - Batch: 350 | Loss: 2.100 | Acc: 84.696% | Wgt Acc: 85.878%
I - num batch: 364
I - Train -- Loss: 2.102 | Acc: 84.729% | Wgt Acc: 85.835% | LR: 1.250000e-04 | Dur: 228.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 546.    5.   11.   37.  145.]
 [   2.  611.   11.    9.   57.]
 [  11.   16.  887.   16.  158.]
 [  43.   10.   10.  589.  109.]
 [  90.   26.   55.   67. 2294.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.728 | Acc: 56.500% | Wgt Acc: 52.487%
I - num batch: 87
I - Val -- Loss: 5.686 | Acc: 59.986% | Wgt Acc: 55.076% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   3.   9.  15.  12.]
 [  2. 117.  42.   6.   9.]
 [  7.  54. 138.  13.  43.]
 [ 45.  18.  25. 139.  36.]
 [ 35.  76.  76.  31. 331.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 2.001 | Acc: 86.625% | Wgt Acc: 88.271%
	I - Batch: 100 | Loss: 2.025 | Acc: 85.688% | Wgt Acc: 86.516%
	I - Batch: 150 | Loss: 2.049 | Acc: 86.000% | Wgt Acc: 86.821%
	I - Batch: 200 | Loss: 2.041 | Acc: 86.000% | Wgt Acc: 87.284%
	I - Batch: 250 | Loss: 2.046 | Acc: 85.900% | Wgt Acc: 87.184%
	I - Batch: 300 | Loss: 2.056 | Acc: 85.438% | Wgt Acc: 86.889%
	I - Batch: 350 | Loss: 2.076 | Acc: 85.179% | Wgt Acc: 86.548%
I - num batch: 364
I - Train -- Loss: 2.070 | Acc: 85.383% | Wgt Acc: 86.711% | LR: 1.250000e-04 | Dur: 227.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 548.    6.    8.   24.  145.]
 [   6.  617.   10.    7.   44.]
 [   7.   11.  894.   13.  141.]
 [  34.    8.    8.  609.  136.]
 [  97.   26.   54.   65. 2297.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.825 | Acc: 56.250% | Wgt Acc: 51.231%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 60.201% | Wgt Acc: 53.760% | Dur: 40.92s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.  10.  18.  10.]
 [  0.  93.  15.   3.   3.]
 [  6.  57. 152.  10.  29.]
 [ 40.  17.  24. 126.  33.]
 [ 42. 100.  89.  47. 356.]]

I - Local maximum validation set accuracy:  60.20

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 1.946 | Acc: 88.875% | Wgt Acc: 88.630%
	I - Batch: 100 | Loss: 1.965 | Acc: 88.375% | Wgt Acc: 88.700%
	I - Batch: 150 | Loss: 2.012 | Acc: 87.417% | Wgt Acc: 88.065%
	I - Batch: 200 | Loss: 2.033 | Acc: 86.594% | Wgt Acc: 87.495%
	I - Batch: 250 | Loss: 2.027 | Acc: 86.325% | Wgt Acc: 87.396%
	I - Batch: 300 | Loss: 2.033 | Acc: 86.625% | Wgt Acc: 87.570%
	I - Batch: 350 | Loss: 2.042 | Acc: 86.446% | Wgt Acc: 87.479%
I - num batch: 364
I - Train -- Loss: 2.048 | Acc: 86.311% | Wgt Acc: 87.268% | LR: 1.250000e-04 | Dur: 224.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 576.    3.   11.   30.  119.]
 [   3.  610.   11.    5.   50.]
 [  12.   16.  890.   11.  136.]
 [  31.    8.    8.  602.  117.]
 [  70.   31.   54.   70. 2341.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.832 | Acc: 55.125% | Wgt Acc: 49.969%
I - num batch: 87
I - Val -- Loss: 5.748 | Acc: 59.411% | Wgt Acc: 53.350% | Dur: 40.97s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   3.  13.  28.  15.]
 [  0. 118.  22.   2.   7.]
 [  2.  39. 113.  10.  18.]
 [ 36.  26.  37. 124.  44.]
 [ 36.  82. 105.  40. 347.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 1.965 | Acc: 87.125% | Wgt Acc: 88.981%
	I - Batch: 100 | Loss: 2.022 | Acc: 86.500% | Wgt Acc: 87.792%
	I - Batch: 150 | Loss: 1.996 | Acc: 87.458% | Wgt Acc: 88.702%
	I - Batch: 200 | Loss: 2.005 | Acc: 87.156% | Wgt Acc: 88.502%
	I - Batch: 250 | Loss: 1.998 | Acc: 87.375% | Wgt Acc: 88.497%
	I - Batch: 300 | Loss: 1.999 | Acc: 87.375% | Wgt Acc: 88.456%
	I - Batch: 350 | Loss: 2.012 | Acc: 86.982% | Wgt Acc: 88.142%
I - num batch: 364
I - Train -- Loss: 2.014 | Acc: 86.930% | Wgt Acc: 88.059% | LR: 1.250000e-04 | Dur: 224.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 569.    4.    9.   28.  121.]
 [   1.  624.    5.   11.   51.]
 [  10.   11.  902.   10.  125.]
 [  33.    8.    7.  609.  115.]
 [  79.   21.   51.   60. 2351.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.787 | Acc: 57.250% | Wgt Acc: 53.700%
I - num batch: 87
I - Val -- Loss: 5.733 | Acc: 59.339% | Wgt Acc: 54.921% | Dur: 40.95s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   4.  10.  29.  18.]
 [  0. 125.  34.   1.   6.]
 [  5.  44. 118.   6.  39.]
 [ 28.  30.  41. 132.  50.]
 [ 33.  65.  87.  36. 318.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 2.081 | Acc: 85.250% | Wgt Acc: 86.103%
	I - Batch: 100 | Loss: 2.018 | Acc: 86.375% | Wgt Acc: 87.256%
	I - Batch: 150 | Loss: 2.040 | Acc: 86.208% | Wgt Acc: 87.215%
	I - Batch: 200 | Loss: 2.041 | Acc: 86.125% | Wgt Acc: 87.220%
	I - Batch: 250 | Loss: 2.026 | Acc: 86.600% | Wgt Acc: 87.791%
	I - Batch: 300 | Loss: 2.011 | Acc: 86.792% | Wgt Acc: 87.931%
	I - Batch: 350 | Loss: 2.012 | Acc: 86.821% | Wgt Acc: 87.988%
I - num batch: 364
I - Train -- Loss: 2.013 | Acc: 86.879% | Wgt Acc: 87.998% | LR: 1.250000e-04 | Dur: 223.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 572.    5.    7.   29.  115.]
 [   6.  622.   13.    7.   48.]
 [   6.   13.  890.    8.  140.]
 [  29.    7.    9.  621.  113.]
 [  79.   21.   55.   53. 2347.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.795 | Acc: 56.000% | Wgt Acc: 51.403%
I - num batch: 87
I - Val -- Loss: 5.737 | Acc: 59.842% | Wgt Acc: 53.551% | Dur: 40.48s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   3.  13.  36.  14.]
 [  2. 116.  19.   1.  10.]
 [  2.  43. 122.   9.  15.]
 [ 30.  23.  30. 113.  38.]
 [ 37.  83. 106.  45. 354.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 1.874 | Acc: 89.375% | Wgt Acc: 90.351%
	I - Batch: 100 | Loss: 1.936 | Acc: 88.500% | Wgt Acc: 89.380%
	I - Batch: 150 | Loss: 1.952 | Acc: 88.792% | Wgt Acc: 89.371%
	I - Batch: 200 | Loss: 1.988 | Acc: 87.750% | Wgt Acc: 88.588%
	I - Batch: 250 | Loss: 1.988 | Acc: 87.600% | Wgt Acc: 88.356%
	I - Batch: 300 | Loss: 1.977 | Acc: 87.750% | Wgt Acc: 88.756%
	I - Batch: 350 | Loss: 1.986 | Acc: 87.786% | Wgt Acc: 88.688%
I - num batch: 364
I - Train -- Loss: 1.986 | Acc: 87.739% | Wgt Acc: 88.655% | LR: 1.250000e-04 | Dur: 222.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 585.    3.   10.   23.  105.]
 [   5.  621.    9.    7.   48.]
 [   6.   12.  896.   12.  131.]
 [  25.    7.    8.  618.   97.]
 [  71.   25.   51.   58. 2382.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.738 | Acc: 56.500% | Wgt Acc: 51.813%
I - num batch: 87
I - Val -- Loss: 5.708 | Acc: 60.201% | Wgt Acc: 54.809% | Dur: 40.47s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   2.  13.  25.  16.]
 [  2. 100.  24.   4.  14.]
 [  3.  68. 144.  14.  30.]
 [ 27.  21.  23. 125.  35.]
 [ 34.  77.  86.  36. 336.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 2.017 | Acc: 87.625% | Wgt Acc: 89.133%
	I - Batch: 100 | Loss: 1.974 | Acc: 88.375% | Wgt Acc: 89.407%
	I - Batch: 150 | Loss: 2.000 | Acc: 87.667% | Wgt Acc: 88.843%
	I - Batch: 200 | Loss: 2.002 | Acc: 87.406% | Wgt Acc: 88.695%
	I - Batch: 250 | Loss: 1.990 | Acc: 87.500% | Wgt Acc: 88.874%
	I - Batch: 300 | Loss: 1.964 | Acc: 88.000% | Wgt Acc: 89.380%
	I - Batch: 350 | Loss: 1.974 | Acc: 87.911% | Wgt Acc: 89.078%
I - num batch: 364
I - Train -- Loss: 1.975 | Acc: 87.807% | Wgt Acc: 89.020% | LR: 1.250000e-04 | Dur: 222.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 583.    4.    8.   24.  111.]
 [   6.  621.    3.    6.   49.]
 [   8.   15.  911.    8.  136.]
 [  20.    4.    7.  625.  101.]
 [  75.   24.   45.   55. 2366.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.691 | Acc: 58.625% | Wgt Acc: 55.924%
I - num batch: 87
I - Val -- Loss: 5.659 | Acc: 59.986% | Wgt Acc: 57.382% | Dur: 40.47s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   4.  10.  20.  12.]
 [  1. 143.  36.   7.  19.]
 [  2.  46. 146.  16.  53.]
 [ 42.  24.  31. 128.  50.]
 [ 33.  51.  67.  33. 297.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 1.866 | Acc: 89.500% | Wgt Acc: 90.520%
	I - Batch: 100 | Loss: 1.846 | Acc: 89.750% | Wgt Acc: 90.848%
	I - Batch: 150 | Loss: 1.887 | Acc: 89.208% | Wgt Acc: 90.319%
	I - Batch: 200 | Loss: 1.902 | Acc: 89.094% | Wgt Acc: 90.033%
	I - Batch: 250 | Loss: 1.930 | Acc: 88.625% | Wgt Acc: 89.514%
	I - Batch: 300 | Loss: 1.943 | Acc: 88.396% | Wgt Acc: 89.281%
	I - Batch: 350 | Loss: 1.942 | Acc: 88.429% | Wgt Acc: 89.235%
I - num batch: 364
I - Train -- Loss: 1.941 | Acc: 88.409% | Wgt Acc: 89.248% | LR: 1.250000e-04 | Dur: 222.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 581.    5.   10.   24.  118.]
 [   3.  629.    6.   10.   42.]
 [   7.    8.  905.    6.  102.]
 [  22.    1.    8.  618.   93.]
 [  79.   25.   45.   60. 2408.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.780 | Acc: 54.625% | Wgt Acc: 51.237%
I - num batch: 87
I - Val -- Loss: 5.722 | Acc: 57.543% | Wgt Acc: 52.696% | Dur: 40.39s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   0.   7.  18.   4.]
 [  0. 101.  19.   7.  10.]
 [  8.  86. 176.  24.  70.]
 [ 28.  12.  19.  93.  21.]
 [ 58.  69.  69.  62. 326.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 1.884 | Acc: 90.000% | Wgt Acc: 90.060%
	I - Batch: 100 | Loss: 1.970 | Acc: 88.688% | Wgt Acc: 88.558%
	I - Batch: 150 | Loss: 1.924 | Acc: 89.083% | Wgt Acc: 89.620%
	I - Batch: 200 | Loss: 1.937 | Acc: 88.656% | Wgt Acc: 89.129%
	I - Batch: 250 | Loss: 1.931 | Acc: 88.675% | Wgt Acc: 89.315%
	I - Batch: 300 | Loss: 1.941 | Acc: 88.542% | Wgt Acc: 89.137%
	I - Batch: 350 | Loss: 1.929 | Acc: 88.679% | Wgt Acc: 89.402%
I - num batch: 364
I - Train -- Loss: 1.927 | Acc: 88.684% | Wgt Acc: 89.404% | LR: 1.250000e-04 | Dur: 224.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 602.    7.    9.   19.  100.]
 [   3.  619.    7.    6.   42.]
 [   6.    8.  901.   10.  110.]
 [  14.    8.    8.  617.   93.]
 [  67.   26.   49.   66. 2418.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.807 | Acc: 55.250% | Wgt Acc: 50.662%
I - num batch: 87
I - Val -- Loss: 5.751 | Acc: 59.483% | Wgt Acc: 53.717% | Dur: 41.27s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   7.  23.  56.  26.]
 [  1. 107.  19.   2.   5.]
 [  4.  45. 130.  14.  26.]
 [ 16.  19.  19. 100.  33.]
 [ 28.  90.  99.  32. 341.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 1.803 | Acc: 91.375% | Wgt Acc: 91.966%
	I - Batch: 100 | Loss: 1.883 | Acc: 89.812% | Wgt Acc: 90.616%
	I - Batch: 150 | Loss: 1.920 | Acc: 88.792% | Wgt Acc: 89.734%
	I - Batch: 200 | Loss: 1.901 | Acc: 89.094% | Wgt Acc: 89.972%
	I - Batch: 250 | Loss: 1.892 | Acc: 89.300% | Wgt Acc: 90.150%
	I - Batch: 300 | Loss: 1.899 | Acc: 89.083% | Wgt Acc: 90.092%
	I - Batch: 350 | Loss: 1.915 | Acc: 88.875% | Wgt Acc: 89.761%
I - num batch: 364
I - Train -- Loss: 1.920 | Acc: 88.736% | Wgt Acc: 89.656% | LR: 1.250000e-04 | Dur: 225.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 595.    4.   10.   22.   97.]
 [   3.  622.    8.    8.   55.]
 [   4.   11.  905.    7.  105.]
 [  22.    3.    8.  631.   99.]
 [  68.   28.   43.   50. 2407.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.774 | Acc: 55.500% | Wgt Acc: 50.882%
I - num batch: 87
I - Val -- Loss: 5.713 | Acc: 60.057% | Wgt Acc: 54.306% | Dur: 41.24s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   1.  11.  24.  14.]
 [  0. 119.  20.   3.  10.]
 [  9.  46. 135.  21.  33.]
 [ 36.  19.  22. 118.  26.]
 [ 38.  83. 102.  38. 348.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 1.891 | Acc: 89.875% | Wgt Acc: 91.113%
	I - Batch: 100 | Loss: 1.879 | Acc: 89.750% | Wgt Acc: 90.852%
	I - Batch: 150 | Loss: 1.878 | Acc: 89.667% | Wgt Acc: 90.826%
	I - Batch: 200 | Loss: 1.860 | Acc: 89.781% | Wgt Acc: 90.992%
	I - Batch: 250 | Loss: 1.876 | Acc: 89.300% | Wgt Acc: 90.544%
	I - Batch: 300 | Loss: 1.881 | Acc: 89.333% | Wgt Acc: 90.428%
	I - Batch: 350 | Loss: 1.895 | Acc: 89.018% | Wgt Acc: 90.234%
I - num batch: 364
I - Train -- Loss: 1.897 | Acc: 88.960% | Wgt Acc: 90.201% | LR: 1.250000e-04 | Dur: 225.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 594.    6.   10.   17.  101.]
 [   2.  633.    6.    5.   39.]
 [   6.    5.  916.   10.  121.]
 [  20.    2.    5.  634.  106.]
 [  70.   22.   37.   52. 2396.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.790 | Acc: 58.750% | Wgt Acc: 54.258%
I - num batch: 87
I - Val -- Loss: 5.735 | Acc: 61.494% | Wgt Acc: 56.229% | Dur: 41.23s
I - Confusion Matrix: [row->prediction - col->label]
[[153.   5.  22.  45.  25.]
 [  0. 117.  21.   7.   6.]
 [  1.  41. 138.  10.  27.]
 [ 15.  19.  20. 106.  31.]
 [ 30.  86.  89.  36. 342.]]

I - Local maximum validation set accuracy:  61.49

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 1.853 | Acc: 90.250% | Wgt Acc: 90.413%
	I - Batch: 100 | Loss: 1.880 | Acc: 90.062% | Wgt Acc: 90.411%
	I - Batch: 150 | Loss: 1.859 | Acc: 90.708% | Wgt Acc: 90.971%
	I - Batch: 200 | Loss: 1.862 | Acc: 90.469% | Wgt Acc: 90.955%
	I - Batch: 250 | Loss: 1.857 | Acc: 90.550% | Wgt Acc: 91.136%
	I - Batch: 300 | Loss: 1.871 | Acc: 90.167% | Wgt Acc: 90.860%
	I - Batch: 350 | Loss: 1.889 | Acc: 89.857% | Wgt Acc: 90.545%
I - num batch: 364
I - Train -- Loss: 1.889 | Acc: 89.802% | Wgt Acc: 90.563% | LR: 1.250000e-04 | Dur: 225.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 601.    4.    9.   19.  100.]
 [   4.  625.    6.    7.   50.]
 [   6.   13.  919.    9.   88.]
 [  21.    4.    6.  630.   78.]
 [  60.   22.   34.   53. 2447.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.721 | Acc: 56.625% | Wgt Acc: 52.959%
I - num batch: 87
I - Val -- Loss: 5.673 | Acc: 60.201% | Wgt Acc: 54.863% | Dur: 41.28s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   3.   8.  19.  17.]
 [  1. 114.  23.   5.   5.]
 [ 10.  76. 147.  16.  44.]
 [ 38.  20.  18. 116.  24.]
 [ 30.  55.  94.  48. 341.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 1.887 | Acc: 90.625% | Wgt Acc: 90.878%
	I - Batch: 100 | Loss: 1.849 | Acc: 91.062% | Wgt Acc: 91.538%
	I - Batch: 150 | Loss: 1.852 | Acc: 90.333% | Wgt Acc: 91.315%
	I - Batch: 200 | Loss: 1.858 | Acc: 90.375% | Wgt Acc: 91.332%
	I - Batch: 250 | Loss: 1.855 | Acc: 90.425% | Wgt Acc: 91.308%
	I - Batch: 300 | Loss: 1.863 | Acc: 90.312% | Wgt Acc: 91.231%
	I - Batch: 350 | Loss: 1.855 | Acc: 90.464% | Wgt Acc: 91.321%
I - num batch: 364
I - Train -- Loss: 1.863 | Acc: 90.335% | Wgt Acc: 91.133% | LR: 1.250000e-04 | Dur: 225.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 609.    5.    9.   19.   98.]
 [   2.  627.    7.    4.   40.]
 [   4.   11.  922.    7.   88.]
 [  19.    6.    3.  637.   79.]
 [  58.   19.   33.   51. 2458.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.855 | Acc: 56.625% | Wgt Acc: 51.991%
I - num batch: 87
I - Val -- Loss: 5.763 | Acc: 59.914% | Wgt Acc: 53.648% | Dur: 41.27s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   5.  14.  37.  16.]
 [  0. 112.  17.   3.  10.]
 [  2.  34. 117.  10.  23.]
 [ 22.  18.  23. 115.  31.]
 [ 36.  99. 119.  39. 351.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 1.772 | Acc: 91.625% | Wgt Acc: 92.545%
	I - Batch: 100 | Loss: 1.856 | Acc: 90.438% | Wgt Acc: 91.299%
	I - Batch: 150 | Loss: 1.855 | Acc: 90.333% | Wgt Acc: 91.342%
	I - Batch: 200 | Loss: 1.856 | Acc: 90.375% | Wgt Acc: 91.257%
	I - Batch: 250 | Loss: 1.858 | Acc: 90.200% | Wgt Acc: 91.119%
	I - Batch: 300 | Loss: 1.853 | Acc: 90.125% | Wgt Acc: 91.115%
	I - Batch: 350 | Loss: 1.863 | Acc: 89.839% | Wgt Acc: 90.879%
I - num batch: 364
I - Train -- Loss: 1.872 | Acc: 89.716% | Wgt Acc: 90.799% | LR: 1.250000e-04 | Dur: 224.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 606.    5.    8.   20.   95.]
 [   5.  633.    1.    7.   52.]
 [   4.    9.  918.    9.  107.]
 [  19.    2.    7.  635.   84.]
 [  58.   19.   40.   47. 2425.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.704 | Acc: 58.125% | Wgt Acc: 56.653%
I - num batch: 87
I - Val -- Loss: 5.681 | Acc: 59.626% | Wgt Acc: 58.238% | Dur: 40.58s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   4.  14.  25.  20.]
 [  5. 152.  49.   7.  34.]
 [  5.  48. 140.  11.  55.]
 [ 46.  20.  43. 137.  48.]
 [ 16.  44.  44.  24. 274.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 1.777 | Acc: 91.875% | Wgt Acc: 92.531%
	I - Batch: 100 | Loss: 1.812 | Acc: 91.438% | Wgt Acc: 92.217%
	I - Batch: 150 | Loss: 1.820 | Acc: 90.958% | Wgt Acc: 91.814%
	I - Batch: 200 | Loss: 1.823 | Acc: 90.469% | Wgt Acc: 91.521%
	I - Batch: 250 | Loss: 1.827 | Acc: 90.550% | Wgt Acc: 91.513%
	I - Batch: 300 | Loss: 1.833 | Acc: 90.604% | Wgt Acc: 91.418%
	I - Batch: 350 | Loss: 1.840 | Acc: 90.536% | Wgt Acc: 91.372%
I - num batch: 364
I - Train -- Loss: 1.842 | Acc: 90.439% | Wgt Acc: 91.352% | LR: 1.250000e-04 | Dur: 222.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 615.    5.    8.   11.   94.]
 [   5.  626.    8.    5.   37.]
 [   5.    6.  923.    9.   95.]
 [  13.    3.    5.  643.   85.]
 [  54.   28.   30.   50. 2452.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.770 | Acc: 58.000% | Wgt Acc: 53.676%
I - num batch: 87
I - Val -- Loss: 5.716 | Acc: 61.997% | Wgt Acc: 56.488% | Dur: 40.71s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   3.  13.  23.  11.]
 [  0. 135.  19.   4.  12.]
 [  2.  51. 129.  15.  24.]
 [ 26.  17.  22. 118.  31.]
 [ 43.  62. 107.  44. 353.]]

I - Local maximum validation set accuracy:  62.00

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 1.710 | Acc: 93.375% | Wgt Acc: 94.008%
	I - Batch: 100 | Loss: 1.755 | Acc: 93.125% | Wgt Acc: 93.400%
	I - Batch: 150 | Loss: 1.764 | Acc: 92.500% | Wgt Acc: 93.019%
	I - Batch: 200 | Loss: 1.783 | Acc: 92.031% | Wgt Acc: 92.593%
	I - Batch: 250 | Loss: 1.782 | Acc: 91.975% | Wgt Acc: 92.608%
	I - Batch: 300 | Loss: 1.769 | Acc: 92.229% | Wgt Acc: 92.890%
	I - Batch: 350 | Loss: 1.779 | Acc: 91.911% | Wgt Acc: 92.609%
I - num batch: 364
I - Train -- Loss: 1.777 | Acc: 91.866% | Wgt Acc: 92.550% | LR: 1.250000e-04 | Dur: 226.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 617.    4.    7.   11.   80.]
 [   2.  631.    2.    4.   41.]
 [   5.    8.  937.    7.   70.]
 [  12.    2.    5.  651.   66.]
 [  56.   23.   23.   45. 2506.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.960 | Acc: 51.750% | Wgt Acc: 45.546%
I - num batch: 87
I - Val -- Loss: 5.854 | Acc: 57.615% | Wgt Acc: 49.418% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   3.  20.  59.  17.]
 [  0. 108.  23.   5.   3.]
 [  1.  32.  96.   4.  13.]
 [ 11.  17.  26.  80.  21.]
 [ 46. 108. 125.  56. 377.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 1.802 | Acc: 91.000% | Wgt Acc: 92.218%
	I - Batch: 100 | Loss: 1.812 | Acc: 91.250% | Wgt Acc: 92.075%
	I - Batch: 150 | Loss: 1.795 | Acc: 91.792% | Wgt Acc: 92.310%
	I - Batch: 200 | Loss: 1.797 | Acc: 91.625% | Wgt Acc: 92.214%
	I - Batch: 250 | Loss: 1.797 | Acc: 91.750% | Wgt Acc: 92.257%
	I - Batch: 300 | Loss: 1.795 | Acc: 91.562% | Wgt Acc: 92.125%
	I - Batch: 350 | Loss: 1.797 | Acc: 91.643% | Wgt Acc: 92.160%
I - num batch: 364
I - Train -- Loss: 1.796 | Acc: 91.625% | Wgt Acc: 92.167% | LR: 1.250000e-04 | Dur: 228.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 616.    4.    8.   20.   82.]
 [   3.  629.    2.    4.   38.]
 [   4.    5.  929.    5.   77.]
 [  15.    4.    5.  646.   58.]
 [  54.   26.   30.   43. 2508.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.827 | Acc: 52.875% | Wgt Acc: 48.952%
I - num batch: 87
I - Val -- Loss: 5.762 | Acc: 54.239% | Wgt Acc: 50.277% | Dur: 41.99s
I - Confusion Matrix: [row->prediction - col->label]
[[142.  11.  16.  40.  29.]
 [  0.  76.  13.   1.   3.]
 [  3.  58. 119.   9.  39.]
 [ 40.  52.  53. 141.  83.]
 [ 14.  71.  89.  13. 277.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 1.698 | Acc: 92.500% | Wgt Acc: 93.646%
	I - Batch: 100 | Loss: 1.754 | Acc: 92.000% | Wgt Acc: 92.779%
	I - Batch: 150 | Loss: 1.781 | Acc: 91.750% | Wgt Acc: 92.297%
	I - Batch: 200 | Loss: 1.782 | Acc: 91.844% | Wgt Acc: 92.382%
	I - Batch: 250 | Loss: 1.768 | Acc: 92.025% | Wgt Acc: 92.586%
	I - Batch: 300 | Loss: 1.765 | Acc: 91.979% | Wgt Acc: 92.593%
	I - Batch: 350 | Loss: 1.768 | Acc: 91.946% | Wgt Acc: 92.448%
I - num batch: 364
I - Train -- Loss: 1.762 | Acc: 92.021% | Wgt Acc: 92.544% | LR: 1.250000e-04 | Dur: 228.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 612.    5.    9.   15.   67.]
 [   2.  639.    3.    5.   34.]
 [   3.    5.  928.    3.   75.]
 [  12.    3.    7.  650.   65.]
 [  63.   16.   27.   45. 2522.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.902 | Acc: 53.375% | Wgt Acc: 47.923%
I - num batch: 87
I - Val -- Loss: 5.792 | Acc: 58.836% | Wgt Acc: 51.500% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   5.  15.   9.]
 [  1. 103.  22.   0.   3.]
 [  2.  47. 117.   4.  21.]
 [ 53.  13.  29. 134.  32.]
 [ 44. 104. 117.  51. 366.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 1.776 | Acc: 92.125% | Wgt Acc: 92.341%
	I - Batch: 100 | Loss: 1.764 | Acc: 91.625% | Wgt Acc: 92.225%
	I - Batch: 150 | Loss: 1.772 | Acc: 91.667% | Wgt Acc: 92.248%
	I - Batch: 200 | Loss: 1.766 | Acc: 91.656% | Wgt Acc: 92.261%
	I - Batch: 250 | Loss: 1.785 | Acc: 91.175% | Wgt Acc: 91.869%
	I - Batch: 300 | Loss: 1.771 | Acc: 91.521% | Wgt Acc: 92.234%
	I - Batch: 350 | Loss: 1.764 | Acc: 91.911% | Wgt Acc: 92.508%
I - num batch: 364
I - Train -- Loss: 1.765 | Acc: 91.849% | Wgt Acc: 92.463% | LR: 1.250000e-04 | Dur: 228.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 614.    6.    7.   12.   76.]
 [   2.  636.    5.    4.   39.]
 [   3.    8.  926.    6.   68.]
 [  14.    2.    7.  655.   70.]
 [  59.   16.   29.   41. 2510.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.780 | Acc: 52.750% | Wgt Acc: 47.838%
I - num batch: 87
I - Val -- Loss: 5.712 | Acc: 57.040% | Wgt Acc: 50.404% | Dur: 41.91s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   4.  15.  43.  14.]
 [  0.  88.  17.   5.   1.]
 [  8.  70. 162.  14.  57.]
 [  9.  10.   5.  67.   7.]
 [ 57.  96.  91.  75. 352.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 1.719 | Acc: 94.125% | Wgt Acc: 94.000%
	I - Batch: 100 | Loss: 1.735 | Acc: 93.750% | Wgt Acc: 93.637%
	I - Batch: 150 | Loss: 1.774 | Acc: 92.417% | Wgt Acc: 92.734%
	I - Batch: 200 | Loss: 1.753 | Acc: 92.500% | Wgt Acc: 92.945%
	I - Batch: 250 | Loss: 1.729 | Acc: 92.825% | Wgt Acc: 93.413%
	I - Batch: 300 | Loss: 1.726 | Acc: 92.938% | Wgt Acc: 93.389%
	I - Batch: 350 | Loss: 1.736 | Acc: 92.821% | Wgt Acc: 93.269%
I - num batch: 364
I - Train -- Loss: 1.736 | Acc: 92.777% | Wgt Acc: 93.297% | LR: 1.250000e-04 | Dur: 228.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 622.    6.    8.    9.   69.]
 [   2.  643.    3.    4.   36.]
 [   6.    3.  928.    6.   69.]
 [  14.    6.    6.  661.   48.]
 [  48.   10.   29.   38. 2541.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.862 | Acc: 53.375% | Wgt Acc: 47.733%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 58.405% | Wgt Acc: 50.753% | Dur: 42.01s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   1.   9.  35.   7.]
 [  1.  93.  19.   3.   8.]
 [  4.  65. 133.  20.  30.]
 [ 14.  12.  16.  87.  15.]
 [ 51.  97. 113.  59. 371.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 1.805 | Acc: 91.250% | Wgt Acc: 92.079%
	I - Batch: 100 | Loss: 1.774 | Acc: 92.125% | Wgt Acc: 92.748%
	I - Batch: 150 | Loss: 1.743 | Acc: 92.792% | Wgt Acc: 93.214%
	I - Batch: 200 | Loss: 1.744 | Acc: 92.594% | Wgt Acc: 93.149%
	I - Batch: 250 | Loss: 1.757 | Acc: 92.225% | Wgt Acc: 92.817%
	I - Batch: 300 | Loss: 1.748 | Acc: 92.542% | Wgt Acc: 92.976%
	I - Batch: 350 | Loss: 1.744 | Acc: 92.464% | Wgt Acc: 93.008%
I - num batch: 364
I - Train -- Loss: 1.747 | Acc: 92.468% | Wgt Acc: 92.958% | LR: 1.250000e-04 | Dur: 228.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 620.    4.    6.   11.   70.]
 [   2.  641.    8.    7.   34.]
 [   5.    5.  931.    8.   63.]
 [  17.    3.    6.  649.   60.]
 [  48.   15.   23.   43. 2536.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.976 | Acc: 49.750% | Wgt Acc: 43.788%
I - num batch: 87
I - Val -- Loss: 5.870 | Acc: 54.310% | Wgt Acc: 46.701% | Dur: 41.98s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   4.  19.  42.  22.]
 [  0.  98.  27.   1.   7.]
 [  1.  26.  62.   5.   9.]
 [ 25.  33.  42. 118.  48.]
 [ 40. 107. 140.  38. 345.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 1.719 | Acc: 92.875% | Wgt Acc: 93.812%
	I - Batch: 100 | Loss: 1.725 | Acc: 92.750% | Wgt Acc: 93.684%
	I - Batch: 150 | Loss: 1.720 | Acc: 92.833% | Wgt Acc: 93.761%
	I - Batch: 200 | Loss: 1.720 | Acc: 92.906% | Wgt Acc: 93.545%
	I - Batch: 250 | Loss: 1.746 | Acc: 92.525% | Wgt Acc: 93.049%
	I - Batch: 300 | Loss: 1.747 | Acc: 92.583% | Wgt Acc: 93.055%
	I - Batch: 350 | Loss: 1.748 | Acc: 92.625% | Wgt Acc: 93.067%
I - num batch: 364
I - Train -- Loss: 1.746 | Acc: 92.657% | Wgt Acc: 93.117% | LR: 1.250000e-04 | Dur: 228.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 616.    4.    7.   13.   59.]
 [   2.  640.    5.    3.   36.]
 [   4.    5.  935.    5.   60.]
 [   9.    2.    8.  654.   65.]
 [  61.   17.   19.   43. 2543.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.824 | Acc: 55.375% | Wgt Acc: 52.162%
I - num batch: 87
I - Val -- Loss: 5.766 | Acc: 58.477% | Wgt Acc: 54.433% | Dur: 41.97s
I - Confusion Matrix: [row->prediction - col->label]
[[149.   7.  25.  45.  42.]
 [  1. 140.  35.   5.  10.]
 [  1.  32.  96.   8.  20.]
 [ 28.  23.  38. 120.  50.]
 [ 20.  66.  96.  26. 309.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 1.602 | Acc: 95.875% | Wgt Acc: 95.945%
	I - Batch: 100 | Loss: 1.644 | Acc: 94.625% | Wgt Acc: 95.030%
	I - Batch: 150 | Loss: 1.663 | Acc: 94.333% | Wgt Acc: 94.750%
	I - Batch: 200 | Loss: 1.698 | Acc: 93.688% | Wgt Acc: 94.032%
	I - Batch: 250 | Loss: 1.702 | Acc: 93.500% | Wgt Acc: 93.942%
	I - Batch: 300 | Loss: 1.704 | Acc: 93.417% | Wgt Acc: 93.885%
	I - Batch: 350 | Loss: 1.700 | Acc: 93.304% | Wgt Acc: 93.907%
I - num batch: 364
I - Train -- Loss: 1.704 | Acc: 93.242% | Wgt Acc: 93.855% | LR: 1.250000e-04 | Dur: 228.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    4.    7.   11.   58.]
 [   3.  639.    3.    5.   39.]
 [   3.    4.  939.    4.   67.]
 [  13.    3.    7.  666.   53.]
 [  41.   18.   18.   32. 2546.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.901 | Acc: 52.000% | Wgt Acc: 45.271%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 57.328% | Wgt Acc: 48.299% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.  11.  20.  10.]
 [  1.  83.  10.   1.   3.]
 [  5.  58. 117.  14.  15.]
 [ 28.  18.  14.  99.  15.]
 [ 54. 108. 138.  70. 388.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 1.645 | Acc: 94.875% | Wgt Acc: 95.172%
	I - Batch: 100 | Loss: 1.644 | Acc: 94.625% | Wgt Acc: 95.023%
	I - Batch: 150 | Loss: 1.659 | Acc: 94.458% | Wgt Acc: 94.732%
	I - Batch: 200 | Loss: 1.687 | Acc: 94.000% | Wgt Acc: 94.217%
	I - Batch: 250 | Loss: 1.688 | Acc: 93.875% | Wgt Acc: 94.090%
	I - Batch: 300 | Loss: 1.698 | Acc: 93.521% | Wgt Acc: 93.802%
	I - Batch: 350 | Loss: 1.703 | Acc: 93.375% | Wgt Acc: 93.750%
I - num batch: 364
I - Train -- Loss: 1.704 | Acc: 93.379% | Wgt Acc: 93.768% | LR: 1.250000e-04 | Dur: 228.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 629.    5.    6.   11.   68.]
 [   4.  640.    4.    5.   27.]
 [   2.    6.  937.    4.   59.]
 [  14.    4.    4.  659.   44.]
 [  43.   13.   23.   39. 2565.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.882 | Acc: 53.250% | Wgt Acc: 47.170%
I - num batch: 87
I - Val -- Loss: 5.783 | Acc: 59.267% | Wgt Acc: 51.438% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   2.  11.  24.   8.]
 [  1. 109.  18.   7.   7.]
 [  5.  45. 116.  11.  23.]
 [ 20.   8.  13.  98.  14.]
 [ 50. 104. 132.  64. 379.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 1.674 | Acc: 94.125% | Wgt Acc: 94.315%
	I - Batch: 100 | Loss: 1.697 | Acc: 93.688% | Wgt Acc: 93.982%
	I - Batch: 150 | Loss: 1.739 | Acc: 92.833% | Wgt Acc: 93.057%
	I - Batch: 200 | Loss: 1.749 | Acc: 92.688% | Wgt Acc: 92.851%
	I - Batch: 250 | Loss: 1.734 | Acc: 92.775% | Wgt Acc: 93.000%
	I - Batch: 300 | Loss: 1.725 | Acc: 92.771% | Wgt Acc: 93.090%
	I - Batch: 350 | Loss: 1.720 | Acc: 92.857% | Wgt Acc: 93.247%
I - num batch: 364
I - Train -- Loss: 1.718 | Acc: 92.863% | Wgt Acc: 93.274% | LR: 1.250000e-04 | Dur: 228.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 626.    2.    8.   11.   61.]
 [   3.  636.    1.    5.   31.]
 [   3.    7.  932.    5.   68.]
 [   8.    3.    6.  657.   54.]
 [  52.   20.   27.   40. 2549.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.870 | Acc: 54.375% | Wgt Acc: 48.861%
I - num batch: 87
I - Val -- Loss: 5.798 | Acc: 58.261% | Wgt Acc: 51.136% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   9.  20.  43.  22.]
 [  0. 100.  25.   1.   3.]
 [  2.  30.  99.   8.  13.]
 [ 28.  26.  38. 115.  38.]
 [ 27. 103. 108.  37. 355.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 1.693 | Acc: 92.500% | Wgt Acc: 93.478%
	I - Batch: 100 | Loss: 1.742 | Acc: 92.250% | Wgt Acc: 92.625%
	I - Batch: 150 | Loss: 1.741 | Acc: 92.333% | Wgt Acc: 92.749%
	I - Batch: 200 | Loss: 1.721 | Acc: 92.938% | Wgt Acc: 93.355%
	I - Batch: 250 | Loss: 1.723 | Acc: 92.875% | Wgt Acc: 93.290%
	I - Batch: 300 | Loss: 1.716 | Acc: 92.958% | Wgt Acc: 93.373%
	I - Batch: 350 | Loss: 1.707 | Acc: 92.964% | Wgt Acc: 93.484%
I - num batch: 364
I - Train -- Loss: 1.710 | Acc: 92.863% | Wgt Acc: 93.440% | LR: 1.250000e-04 | Dur: 228.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    3.    6.   14.   75.]
 [   4.  640.    4.    4.   40.]
 [   1.    7.  942.    5.   45.]
 [  10.    1.    5.  645.   62.]
 [  45.   17.   17.   50. 2541.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.906 | Acc: 52.875% | Wgt Acc: 46.833%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 58.908% | Wgt Acc: 51.028% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   2.  11.  39.  21.]
 [  2. 125.  39.   5.   8.]
 [  2.  30.  89.   5.  10.]
 [ 19.  15.  18.  94.  13.]
 [ 43.  96. 133.  61. 379.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 1.736 | Acc: 93.500% | Wgt Acc: 93.442%
	I - Batch: 100 | Loss: 1.742 | Acc: 93.000% | Wgt Acc: 93.068%
	I - Batch: 150 | Loss: 1.717 | Acc: 93.333% | Wgt Acc: 93.523%
	I - Batch: 200 | Loss: 1.703 | Acc: 93.531% | Wgt Acc: 93.831%
	I - Batch: 250 | Loss: 1.694 | Acc: 93.625% | Wgt Acc: 93.920%
	I - Batch: 300 | Loss: 1.701 | Acc: 93.500% | Wgt Acc: 93.908%
	I - Batch: 350 | Loss: 1.707 | Acc: 93.304% | Wgt Acc: 93.748%
I - num batch: 364
I - Train -- Loss: 1.713 | Acc: 93.156% | Wgt Acc: 93.598% | LR: 1.250000e-04 | Dur: 228.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 631.    7.    8.   14.   66.]
 [   4.  642.    4.    7.   25.]
 [   1.    6.  929.    6.   65.]
 [  11.    2.   10.  660.   52.]
 [  45.   11.   23.   31. 2555.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.819 | Acc: 53.375% | Wgt Acc: 48.591%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 57.543% | Wgt Acc: 51.476% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   1.  12.  21.  12.]
 [  2. 110.  25.   1.  18.]
 [  4.  48. 121.  11.  36.]
 [ 37.  17.  26. 114.  24.]
 [ 41.  92. 106.  57. 341.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 1.674 | Acc: 93.875% | Wgt Acc: 94.410%
	I - Batch: 100 | Loss: 1.641 | Acc: 94.625% | Wgt Acc: 95.018%
	I - Batch: 150 | Loss: 1.691 | Acc: 93.833% | Wgt Acc: 94.121%
	I - Batch: 200 | Loss: 1.684 | Acc: 93.969% | Wgt Acc: 94.214%
	I - Batch: 250 | Loss: 1.677 | Acc: 94.200% | Wgt Acc: 94.364%
	I - Batch: 300 | Loss: 1.677 | Acc: 94.104% | Wgt Acc: 94.409%
	I - Batch: 350 | Loss: 1.676 | Acc: 94.286% | Wgt Acc: 94.534%
I - num batch: 364
I - Train -- Loss: 1.670 | Acc: 94.342% | Wgt Acc: 94.626% | LR: 1.250000e-04 | Dur: 229.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 645.    5.    8.    8.   59.]
 [   5.  639.    5.    4.   28.]
 [   2.    6.  941.    3.   40.]
 [   4.    2.    4.  666.   41.]
 [  36.   16.   16.   37. 2595.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.799 | Acc: 54.625% | Wgt Acc: 50.417%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 59.124% | Wgt Acc: 53.501% | Dur: 42.20s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   2.  11.  23.  16.]
 [  0. 134.  46.   7.  16.]
 [  3.  25.  97.   5.  15.]
 [ 34.  26.  32. 128.  44.]
 [ 38.  81. 104.  41. 340.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 1.661 | Acc: 93.750% | Wgt Acc: 93.890%
	I - Batch: 100 | Loss: 1.688 | Acc: 93.625% | Wgt Acc: 93.806%
	I - Batch: 150 | Loss: 1.686 | Acc: 93.792% | Wgt Acc: 93.933%
	I - Batch: 200 | Loss: 1.680 | Acc: 94.000% | Wgt Acc: 94.158%
	I - Batch: 250 | Loss: 1.674 | Acc: 94.000% | Wgt Acc: 94.117%
	I - Batch: 300 | Loss: 1.666 | Acc: 94.104% | Wgt Acc: 94.297%
	I - Batch: 350 | Loss: 1.682 | Acc: 93.750% | Wgt Acc: 94.020%
I - num batch: 364
I - Train -- Loss: 1.686 | Acc: 93.672% | Wgt Acc: 93.927% | LR: 1.250000e-04 | Dur: 229.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 630.    5.    6.   11.   56.]
 [   3.  635.    6.    3.   27.]
 [   4.    8.  936.    4.   62.]
 [  13.    1.    7.  667.   39.]
 [  42.   19.   19.   33. 2579.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.019 | Acc: 48.625% | Wgt Acc: 41.730%
I - num batch: 87
I - Val -- Loss: 5.875 | Acc: 56.250% | Wgt Acc: 46.712% | Dur: 41.73s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   1.  16.  40.  12.]
 [  0. 101.  19.   3.   3.]
 [  1.  17.  64.   4.   8.]
 [ 14.   9.  21.  89.  18.]
 [ 45. 140. 170.  68. 390.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 1.614 | Acc: 95.000% | Wgt Acc: 95.733%
	I - Batch: 100 | Loss: 1.664 | Acc: 94.188% | Wgt Acc: 94.419%
	I - Batch: 150 | Loss: 1.675 | Acc: 93.417% | Wgt Acc: 93.952%
	I - Batch: 200 | Loss: 1.696 | Acc: 93.469% | Wgt Acc: 93.744%
	I - Batch: 250 | Loss: 1.676 | Acc: 93.800% | Wgt Acc: 94.156%
	I - Batch: 300 | Loss: 1.672 | Acc: 93.750% | Wgt Acc: 94.155%
	I - Batch: 350 | Loss: 1.686 | Acc: 93.589% | Wgt Acc: 93.899%
I - num batch: 364
I - Train -- Loss: 1.683 | Acc: 93.620% | Wgt Acc: 93.961% | LR: 1.250000e-04 | Dur: 227.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    4.    8.   10.   65.]
 [   3.  638.    5.    5.   32.]
 [   3.    5.  932.    3.   42.]
 [   9.    3.    5.  670.   52.]
 [  45.   18.   24.   30. 2572.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.873 | Acc: 53.250% | Wgt Acc: 47.482%
I - num batch: 87
I - Val -- Loss: 5.783 | Acc: 59.195% | Wgt Acc: 51.736% | Dur: 41.91s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   5.  14.  32.  15.]
 [  1. 112.  18.   4.  10.]
 [  2.  38. 109.   8.  13.]
 [ 21.  18.  20. 107.  22.]
 [ 50.  95. 129.  53. 371.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 1.627 | Acc: 95.125% | Wgt Acc: 95.360%
	I - Batch: 100 | Loss: 1.631 | Acc: 94.875% | Wgt Acc: 95.261%
	I - Batch: 150 | Loss: 1.631 | Acc: 95.000% | Wgt Acc: 95.170%
	I - Batch: 200 | Loss: 1.630 | Acc: 95.000% | Wgt Acc: 95.189%
	I - Batch: 250 | Loss: 1.635 | Acc: 94.925% | Wgt Acc: 95.126%
	I - Batch: 300 | Loss: 1.630 | Acc: 95.062% | Wgt Acc: 95.222%
	I - Batch: 350 | Loss: 1.639 | Acc: 94.857% | Wgt Acc: 95.030%
I - num batch: 364
I - Train -- Loss: 1.636 | Acc: 94.824% | Wgt Acc: 95.030% | LR: 1.250000e-04 | Dur: 225.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 646.    5.    4.   10.   31.]
 [   3.  645.    4.    6.   27.]
 [   4.    5.  942.    5.   43.]
 [   4.    0.    5.  667.   48.]
 [  35.   13.   19.   30. 2614.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.798 | Acc: 55.000% | Wgt Acc: 50.398%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 59.555% | Wgt Acc: 53.272% | Dur: 41.09s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   7.  16.  35.  15.]
 [  0. 134.  42.   5.  22.]
 [  3.  38. 109.   9.  15.]
 [ 14.  15.  14.  99.  22.]
 [ 52.  74. 109.  56. 357.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 1.593 | Acc: 95.000% | Wgt Acc: 95.183%
	I - Batch: 100 | Loss: 1.621 | Acc: 94.750% | Wgt Acc: 94.702%
	I - Batch: 150 | Loss: 1.618 | Acc: 95.000% | Wgt Acc: 94.885%
	I - Batch: 200 | Loss: 1.608 | Acc: 95.094% | Wgt Acc: 95.126%
	I - Batch: 250 | Loss: 1.607 | Acc: 95.225% | Wgt Acc: 95.380%
	I - Batch: 300 | Loss: 1.627 | Acc: 94.750% | Wgt Acc: 94.988%
	I - Batch: 350 | Loss: 1.626 | Acc: 94.839% | Wgt Acc: 95.065%
I - num batch: 364
I - Train -- Loss: 1.626 | Acc: 94.893% | Wgt Acc: 95.086% | LR: 1.250000e-04 | Dur: 224.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    3.    8.   10.   40.]
 [   2.  645.    4.    3.   21.]
 [   0.    5.  940.    3.   50.]
 [   8.    0.    3.  673.   36.]
 [  38.   15.   19.   29. 2616.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.797 | Acc: 55.750% | Wgt Acc: 51.342%
I - num batch: 87
I - Val -- Loss: 5.734 | Acc: 59.626% | Wgt Acc: 53.868% | Dur: 41.18s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   5.  16.  28.  15.]
 [  1. 129.  27.   2.  13.]
 [  3.  22. 101.   7.  18.]
 [ 39.  24.  37. 129.  42.]
 [ 28.  88. 109.  38. 343.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 1.569 | Acc: 96.375% | Wgt Acc: 96.366%
	I - Batch: 100 | Loss: 1.593 | Acc: 96.000% | Wgt Acc: 96.023%
	I - Batch: 150 | Loss: 1.629 | Acc: 95.125% | Wgt Acc: 95.344%
	I - Batch: 200 | Loss: 1.643 | Acc: 95.000% | Wgt Acc: 95.200%
	I - Batch: 250 | Loss: 1.668 | Acc: 94.475% | Wgt Acc: 94.570%
	I - Batch: 300 | Loss: 1.669 | Acc: 94.354% | Wgt Acc: 94.556%
	I - Batch: 350 | Loss: 1.665 | Acc: 94.321% | Wgt Acc: 94.595%
I - num batch: 364
I - Train -- Loss: 1.670 | Acc: 94.273% | Wgt Acc: 94.514% | LR: 1.250000e-04 | Dur: 224.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 639.    3.    7.   13.   53.]
 [   1.  639.    8.    8.   27.]
 [   2.    7.  939.    1.   43.]
 [  11.    6.    8.  669.   44.]
 [  39.   13.   12.   27. 2596.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.866 | Acc: 53.750% | Wgt Acc: 48.107%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 58.908% | Wgt Acc: 51.964% | Dur: 40.62s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   8.  10.  19.  17.]
 [  0. 103.  23.   3.   6.]
 [  3.  39. 111.   9.  14.]
 [ 45.  15.  23. 130.  37.]
 [ 32. 103. 123.  43. 357.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 1.746 | Acc: 93.000% | Wgt Acc: 93.052%
	I - Batch: 100 | Loss: 1.723 | Acc: 93.125% | Wgt Acc: 93.659%
	I - Batch: 150 | Loss: 1.726 | Acc: 93.208% | Wgt Acc: 93.562%
	I - Batch: 200 | Loss: 1.688 | Acc: 93.969% | Wgt Acc: 94.313%
	I - Batch: 250 | Loss: 1.681 | Acc: 93.950% | Wgt Acc: 94.280%
	I - Batch: 300 | Loss: 1.679 | Acc: 94.021% | Wgt Acc: 94.347%
	I - Batch: 350 | Loss: 1.669 | Acc: 94.268% | Wgt Acc: 94.507%
I - num batch: 364
I - Train -- Loss: 1.670 | Acc: 94.187% | Wgt Acc: 94.468% | LR: 1.250000e-04 | Dur: 222.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 627.    6.    9.    9.   52.]
 [   2.  641.    5.    4.   18.]
 [   2.    4.  939.    4.   49.]
 [  22.    2.    5.  678.   52.]
 [  39.   15.   16.   23. 2592.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.795 | Acc: 55.625% | Wgt Acc: 52.077%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 60.273% | Wgt Acc: 55.389% | Dur: 40.60s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   5.  13.  41.  20.]
 [  0. 121.  20.   2.   6.]
 [  4.  42. 139.   9.  37.]
 [ 25.  26.  25. 110.  35.]
 [ 34.  74.  93.  42. 333.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 1.668 | Acc: 94.375% | Wgt Acc: 94.210%
	I - Batch: 100 | Loss: 1.629 | Acc: 94.750% | Wgt Acc: 94.813%
	I - Batch: 150 | Loss: 1.638 | Acc: 94.500% | Wgt Acc: 94.737%
	I - Batch: 200 | Loss: 1.631 | Acc: 94.594% | Wgt Acc: 94.940%
	I - Batch: 250 | Loss: 1.628 | Acc: 94.700% | Wgt Acc: 94.962%
	I - Batch: 300 | Loss: 1.632 | Acc: 94.771% | Wgt Acc: 95.052%
	I - Batch: 350 | Loss: 1.643 | Acc: 94.500% | Wgt Acc: 94.861%
I - num batch: 364
I - Train -- Loss: 1.637 | Acc: 94.583% | Wgt Acc: 94.939% | LR: 1.250000e-04 | Dur: 222.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 647.    7.    8.    8.   48.]
 [   0.  642.    3.    4.   24.]
 [   4.    5.  939.    6.   53.]
 [   3.    0.    4.  676.   42.]
 [  38.   14.   20.   24. 2596.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.737 | Acc: 60.125% | Wgt Acc: 56.910%
I - num batch: 87
I - Val -- Loss: 5.701 | Acc: 61.351% | Wgt Acc: 57.878% | Dur: 40.61s
I - Confusion Matrix: [row->prediction - col->label]
[[153.   7.  15.  47.  33.]
 [  0. 134.  22.   3.  10.]
 [  6.  40. 140.  11.  41.]
 [ 16.  22.  25. 114.  34.]
 [ 24.  65.  88.  29. 313.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 1.598 | Acc: 94.750% | Wgt Acc: 95.379%
	I - Batch: 100 | Loss: 1.630 | Acc: 94.375% | Wgt Acc: 94.722%
	I - Batch: 150 | Loss: 1.650 | Acc: 94.333% | Wgt Acc: 94.563%
	I - Batch: 200 | Loss: 1.632 | Acc: 94.656% | Wgt Acc: 94.986%
	I - Batch: 250 | Loss: 1.627 | Acc: 94.575% | Wgt Acc: 94.996%
	I - Batch: 300 | Loss: 1.634 | Acc: 94.667% | Wgt Acc: 95.005%
	I - Batch: 350 | Loss: 1.624 | Acc: 94.768% | Wgt Acc: 95.159%
I - num batch: 364
I - Train -- Loss: 1.624 | Acc: 94.824% | Wgt Acc: 95.189% | LR: 1.250000e-04 | Dur: 222.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 648.    3.    5.    7.   52.]
 [   2.  646.    4.    2.   24.]
 [   1.    3.  946.    3.   52.]
 [   5.    2.    3.  670.   31.]
 [  36.   14.   16.   36. 2604.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.735 | Acc: 57.125% | Wgt Acc: 54.349%
I - num batch: 87
I - Val -- Loss: 5.701 | Acc: 60.129% | Wgt Acc: 55.927% | Dur: 40.54s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   5.  12.  35.   9.]
 [  0. 108.  20.   3.   9.]
 [  6.  58. 169.  17.  56.]
 [ 19.  22.  21. 103.  36.]
 [ 38.  75.  68.  46. 321.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 1.621 | Acc: 95.375% | Wgt Acc: 95.722%
	I - Batch: 100 | Loss: 1.653 | Acc: 94.875% | Wgt Acc: 94.957%
	I - Batch: 150 | Loss: 1.646 | Acc: 94.792% | Wgt Acc: 94.962%
	I - Batch: 200 | Loss: 1.641 | Acc: 94.844% | Wgt Acc: 94.948%
	I - Batch: 250 | Loss: 1.621 | Acc: 95.150% | Wgt Acc: 95.300%
	I - Batch: 300 | Loss: 1.627 | Acc: 94.938% | Wgt Acc: 95.099%
	I - Batch: 350 | Loss: 1.635 | Acc: 94.804% | Wgt Acc: 94.927%
I - num batch: 364
I - Train -- Loss: 1.640 | Acc: 94.738% | Wgt Acc: 94.877% | LR: 1.250000e-04 | Dur: 223.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 641.    4.    7.   10.   41.]
 [   2.  636.    2.    3.   30.]
 [   1.    7.  949.    2.   40.]
 [  10.    2.    4.  668.   37.]
 [  38.   19.   12.   35. 2615.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.647 | Acc: 59.375% | Wgt Acc: 56.775%
I - num batch: 87
I - Val -- Loss: 5.624 | Acc: 61.135% | Wgt Acc: 58.265% | Dur: 40.95s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   3.  14.  20.  12.]
 [  5. 163.  41.  15.  34.]
 [  6.  50. 146.  16.  58.]
 [ 15.   8.  11.  98.  14.]
 [ 42.  44.  78.  55. 313.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 1.708 | Acc: 92.625% | Wgt Acc: 93.132%
	I - Batch: 100 | Loss: 1.669 | Acc: 94.312% | Wgt Acc: 94.129%
	I - Batch: 150 | Loss: 1.675 | Acc: 94.042% | Wgt Acc: 94.181%
	I - Batch: 200 | Loss: 1.662 | Acc: 94.375% | Wgt Acc: 94.472%
	I - Batch: 250 | Loss: 1.647 | Acc: 94.475% | Wgt Acc: 94.726%
	I - Batch: 300 | Loss: 1.635 | Acc: 94.771% | Wgt Acc: 95.088%
	I - Batch: 350 | Loss: 1.626 | Acc: 94.929% | Wgt Acc: 95.271%
I - num batch: 364
I - Train -- Loss: 1.623 | Acc: 94.996% | Wgt Acc: 95.351% | LR: 1.250000e-04 | Dur: 224.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 648.    7.    8.    6.   43.]
 [   1.  643.    5.    3.   23.]
 [   3.    6.  944.    5.   51.]
 [   6.    0.    4.  682.   39.]
 [  34.   12.   13.   22. 2607.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.761 | Acc: 54.125% | Wgt Acc: 50.441%
I - num batch: 87
I - Val -- Loss: 5.742 | Acc: 57.112% | Wgt Acc: 52.599% | Dur: 40.99s
I - Confusion Matrix: [row->prediction - col->label]
[[161.  14.  28.  79.  50.]
 [  2. 126.  36.   2.  16.]
 [  5.  52. 116.  13.  35.]
 [  6.  14.  19.  78.  16.]
 [ 25.  62.  91.  32. 314.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 1.531 | Acc: 96.000% | Wgt Acc: 96.683%
	I - Batch: 100 | Loss: 1.577 | Acc: 95.375% | Wgt Acc: 95.852%
	I - Batch: 150 | Loss: 1.582 | Acc: 95.542% | Wgt Acc: 95.996%
	I - Batch: 200 | Loss: 1.593 | Acc: 95.438% | Wgt Acc: 95.754%
	I - Batch: 250 | Loss: 1.595 | Acc: 95.425% | Wgt Acc: 95.672%
	I - Batch: 300 | Loss: 1.589 | Acc: 95.500% | Wgt Acc: 95.784%
	I - Batch: 350 | Loss: 1.589 | Acc: 95.446% | Wgt Acc: 95.694%
I - num batch: 364
I - Train -- Loss: 1.601 | Acc: 95.322% | Wgt Acc: 95.547% | LR: 1.250000e-04 | Dur: 224.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    5.    5.    9.   42.]
 [   2.  640.    2.    4.   22.]
 [   3.    4.  950.    4.   34.]
 [   3.    4.    5.  671.   41.]
 [  26.   15.   12.   30. 2624.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.925 | Acc: 53.500% | Wgt Acc: 47.580%
I - num batch: 87
I - Val -- Loss: 5.823 | Acc: 58.333% | Wgt Acc: 50.880% | Dur: 40.94s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   9.  21.  47.  30.]
 [  1.  97.  21.   0.   6.]
 [  3.  23. 101.   5.   7.]
 [ 10.  16.  23. 107.  27.]
 [ 39. 123. 124.  45. 361.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 1.598 | Acc: 95.250% | Wgt Acc: 95.498%
	I - Batch: 100 | Loss: 1.609 | Acc: 95.062% | Wgt Acc: 95.334%
	I - Batch: 150 | Loss: 1.642 | Acc: 94.375% | Wgt Acc: 94.624%
	I - Batch: 200 | Loss: 1.648 | Acc: 94.438% | Wgt Acc: 94.699%
	I - Batch: 250 | Loss: 1.653 | Acc: 94.625% | Wgt Acc: 94.796%
	I - Batch: 300 | Loss: 1.641 | Acc: 94.708% | Wgt Acc: 94.997%
	I - Batch: 350 | Loss: 1.647 | Acc: 94.607% | Wgt Acc: 94.934%
I - num batch: 364
I - Train -- Loss: 1.646 | Acc: 94.617% | Wgt Acc: 94.946% | LR: 1.250000e-04 | Dur: 224.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 641.    5.    6.    8.   47.]
 [   1.  641.    6.    2.   25.]
 [   3.    7.  946.    4.   51.]
 [   8.    3.    6.  674.   40.]
 [  39.   12.   10.   30. 2600.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.797 | Acc: 56.500% | Wgt Acc: 52.457%
I - num batch: 87
I - Val -- Loss: 5.762 | Acc: 59.842% | Wgt Acc: 54.770% | Dur: 40.94s
I - Confusion Matrix: [row->prediction - col->label]
[[151.   9.  17.  52.  24.]
 [  1. 123.  33.   8.  17.]
 [  3.  49. 133.   8.  30.]
 [  9.  10.  15.  91.  25.]
 [ 35.  77.  92.  45. 335.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 1.616 | Acc: 94.750% | Wgt Acc: 95.037%
	I - Batch: 100 | Loss: 1.578 | Acc: 95.062% | Wgt Acc: 95.400%
	I - Batch: 150 | Loss: 1.585 | Acc: 95.000% | Wgt Acc: 95.495%
	I - Batch: 200 | Loss: 1.589 | Acc: 95.094% | Wgt Acc: 95.543%
	I - Batch: 250 | Loss: 1.606 | Acc: 94.950% | Wgt Acc: 95.308%
	I - Batch: 300 | Loss: 1.606 | Acc: 95.000% | Wgt Acc: 95.271%
	I - Batch: 350 | Loss: 1.600 | Acc: 95.196% | Wgt Acc: 95.456%
I - num batch: 364
I - Train -- Loss: 1.596 | Acc: 95.288% | Wgt Acc: 95.540% | LR: 1.250000e-04 | Dur: 224.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 648.    5.    5.    8.   42.]
 [   2.  645.    4.    5.   31.]
 [   2.    2.  949.    5.   30.]
 [   6.    2.    3.  676.   37.]
 [  34.   14.   13.   24. 2623.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.759 | Acc: 55.500% | Wgt Acc: 51.801%
I - num batch: 87
I - Val -- Loss: 5.708 | Acc: 59.914% | Wgt Acc: 54.812% | Dur: 40.89s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   4.  18.  35.  20.]
 [  1. 138.  26.   6.  17.]
 [  2.  33. 109.  13.  18.]
 [ 20.  21.  17. 110.  40.]
 [ 35.  72. 120.  40. 336.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 1.546 | Acc: 95.875% | Wgt Acc: 96.407%
	I - Batch: 100 | Loss: 1.534 | Acc: 96.375% | Wgt Acc: 96.696%
	I - Batch: 150 | Loss: 1.556 | Acc: 95.875% | Wgt Acc: 96.252%
	I - Batch: 200 | Loss: 1.557 | Acc: 96.094% | Wgt Acc: 96.263%
	I - Batch: 250 | Loss: 1.552 | Acc: 96.100% | Wgt Acc: 96.349%
	I - Batch: 300 | Loss: 1.558 | Acc: 96.021% | Wgt Acc: 96.255%
	I - Batch: 350 | Loss: 1.570 | Acc: 95.839% | Wgt Acc: 96.050%
I - num batch: 364
I - Train -- Loss: 1.569 | Acc: 95.787% | Wgt Acc: 96.053% | LR: 1.250000e-04 | Dur: 224.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 653.    4.    5.    7.   40.]
 [   1.  649.    3.    2.   17.]
 [   5.    5.  954.    6.   28.]
 [   4.    1.    5.  678.   42.]
 [  29.    9.    7.   25. 2636.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.849 | Acc: 52.000% | Wgt Acc: 47.127%
I - num batch: 87
I - Val -- Loss: 5.768 | Acc: 57.902% | Wgt Acc: 51.391% | Dur: 41.01s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   1.   8.  30.  12.]
 [  0. 120.  25.   7.   9.]
 [  3.  40. 127.  12.  29.]
 [ 15.  11.  19.  90.  25.]
 [ 68.  96. 111.  65. 356.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 1.556 | Acc: 96.250% | Wgt Acc: 96.278%
	I - Batch: 100 | Loss: 1.542 | Acc: 96.500% | Wgt Acc: 96.589%
	I - Batch: 150 | Loss: 1.565 | Acc: 96.125% | Wgt Acc: 96.107%
	I - Batch: 200 | Loss: 1.561 | Acc: 96.156% | Wgt Acc: 96.226%
	I - Batch: 250 | Loss: 1.567 | Acc: 96.275% | Wgt Acc: 96.247%
	I - Batch: 300 | Loss: 1.566 | Acc: 96.271% | Wgt Acc: 96.302%
	I - Batch: 350 | Loss: 1.563 | Acc: 96.411% | Wgt Acc: 96.359%
I - num batch: 364
I - Train -- Loss: 1.565 | Acc: 96.406% | Wgt Acc: 96.350% | LR: 1.250000e-04 | Dur: 224.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    2.    7.    7.   30.]
 [   1.  648.    1.    2.   12.]
 [   2.    3.  951.    2.   24.]
 [   6.    2.    4.  677.   25.]
 [  25.   13.   11.   30. 2672.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.839 | Acc: 51.250% | Wgt Acc: 45.528%
I - num batch: 87
I - Val -- Loss: 5.765 | Acc: 57.184% | Wgt Acc: 49.994% | Dur: 40.94s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   4.  15.  25.  13.]
 [  0. 118.  30.   5.  15.]
 [  4.  35. 106.  12.  21.]
 [ 29.  11.  14.  92.  20.]
 [ 48. 100. 125.  70. 362.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 1.567 | Acc: 96.250% | Wgt Acc: 96.042%
	I - Batch: 100 | Loss: 1.562 | Acc: 96.500% | Wgt Acc: 96.129%
	I - Batch: 150 | Loss: 1.576 | Acc: 95.792% | Wgt Acc: 95.769%
	I - Batch: 200 | Loss: 1.577 | Acc: 95.812% | Wgt Acc: 95.836%
	I - Batch: 250 | Loss: 1.578 | Acc: 95.725% | Wgt Acc: 95.809%
	I - Batch: 300 | Loss: 1.599 | Acc: 95.396% | Wgt Acc: 95.419%
	I - Batch: 350 | Loss: 1.595 | Acc: 95.375% | Wgt Acc: 95.476%
I - num batch: 364
I - Train -- Loss: 1.599 | Acc: 95.340% | Wgt Acc: 95.431% | LR: 1.250000e-04 | Dur: 224.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 639.    5.    7.    9.   51.]
 [   0.  648.    4.    3.   18.]
 [   2.    4.  946.    2.   33.]
 [  12.    0.    4.  675.   25.]
 [  39.   11.   13.   29. 2636.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.866 | Acc: 52.625% | Wgt Acc: 47.023%
I - num batch: 87
I - Val -- Loss: 5.775 | Acc: 58.836% | Wgt Acc: 51.453% | Dur: 40.96s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   4.  11.  33.  14.]
 [  2. 107.  23.   3.   4.]
 [  5.  46. 128.  14.  27.]
 [ 14.   7.  16.  90.  15.]
 [ 55. 104. 112.  64. 371.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 1.577 | Acc: 95.875% | Wgt Acc: 95.936%
	I - Batch: 100 | Loss: 1.571 | Acc: 95.688% | Wgt Acc: 95.859%
	I - Batch: 150 | Loss: 1.578 | Acc: 95.833% | Wgt Acc: 95.898%
	I - Batch: 200 | Loss: 1.600 | Acc: 95.500% | Wgt Acc: 95.469%
	I - Batch: 250 | Loss: 1.601 | Acc: 95.600% | Wgt Acc: 95.549%
	I - Batch: 300 | Loss: 1.603 | Acc: 95.542% | Wgt Acc: 95.478%
	I - Batch: 350 | Loss: 1.608 | Acc: 95.321% | Wgt Acc: 95.428%
I - num batch: 364
I - Train -- Loss: 1.611 | Acc: 95.305% | Wgt Acc: 95.403% | LR: 1.250000e-04 | Dur: 224.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    5.    6.    9.   41.]
 [   3.  642.    5.    2.   19.]
 [   1.    8.  944.    6.   39.]
 [  11.    1.    3.  680.   32.]
 [  33.   12.   16.   21. 2632.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.841 | Acc: 53.250% | Wgt Acc: 49.375%
I - num batch: 87
I - Val -- Loss: 5.771 | Acc: 56.537% | Wgt Acc: 52.297% | Dur: 40.94s
I - Confusion Matrix: [row->prediction - col->label]
[[156.   5.  20.  54.  54.]
 [  0. 119.  27.   2.   7.]
 [  2.  33.  97.   4.  13.]
 [ 27.  30.  45. 115.  57.]
 [ 14.  81. 101.  29. 300.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 1.572 | Acc: 96.375% | Wgt Acc: 96.059%
	I - Batch: 100 | Loss: 1.615 | Acc: 95.438% | Wgt Acc: 95.412%
	I - Batch: 150 | Loss: 1.621 | Acc: 95.375% | Wgt Acc: 95.384%
	I - Batch: 200 | Loss: 1.609 | Acc: 95.406% | Wgt Acc: 95.451%
	I - Batch: 250 | Loss: 1.608 | Acc: 95.400% | Wgt Acc: 95.359%
	I - Batch: 300 | Loss: 1.621 | Acc: 95.083% | Wgt Acc: 95.130%
	I - Batch: 350 | Loss: 1.616 | Acc: 95.107% | Wgt Acc: 95.151%
I - num batch: 364
I - Train -- Loss: 1.612 | Acc: 95.202% | Wgt Acc: 95.242% | LR: 1.250000e-04 | Dur: 225.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 645.    6.    5.    8.   43.]
 [   0.  640.    2.    2.   18.]
 [   3.    8.  944.    4.   35.]
 [   6.    1.    5.  674.   34.]
 [  38.   13.   18.   30. 2633.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.864 | Acc: 53.000% | Wgt Acc: 47.347%
I - num batch: 87
I - Val -- Loss: 5.776 | Acc: 58.405% | Wgt Acc: 51.051% | Dur: 41.26s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   4.  10.  30.  16.]
 [  0. 102.  16.   3.   3.]
 [  4.  48. 109.   9.  21.]
 [ 26.  13.  33. 113.  28.]
 [ 43. 101. 122.  49. 363.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 1.587 | Acc: 95.750% | Wgt Acc: 95.899%
	I - Batch: 100 | Loss: 1.620 | Acc: 95.188% | Wgt Acc: 95.313%
	I - Batch: 150 | Loss: 1.598 | Acc: 95.500% | Wgt Acc: 95.725%
	I - Batch: 200 | Loss: 1.589 | Acc: 95.688% | Wgt Acc: 95.842%
	I - Batch: 250 | Loss: 1.580 | Acc: 95.775% | Wgt Acc: 95.987%
	I - Batch: 300 | Loss: 1.582 | Acc: 95.750% | Wgt Acc: 95.887%
	I - Batch: 350 | Loss: 1.572 | Acc: 95.875% | Wgt Acc: 96.057%
I - num batch: 364
I - Train -- Loss: 1.574 | Acc: 95.856% | Wgt Acc: 96.038% | LR: 1.250000e-04 | Dur: 225.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    3.    3.    7.   31.]
 [   3.  649.    5.    1.   19.]
 [   3.    1.  943.    1.   40.]
 [   6.    3.    6.  679.   32.]
 [  18.   12.   17.   30. 2641.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.839 | Acc: 53.625% | Wgt Acc: 48.628%
I - num batch: 87
I - Val -- Loss: 5.762 | Acc: 58.261% | Wgt Acc: 51.724% | Dur: 41.44s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   9.  20.  37.  37.]
 [  0. 107.  18.   2.   8.]
 [  5.  39. 112.   5.  15.]
 [ 20.  14.  22. 103.  22.]
 [ 34.  99. 118.  57. 349.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 1.591 | Acc: 95.375% | Wgt Acc: 95.806%
	I - Batch: 100 | Loss: 1.566 | Acc: 95.875% | Wgt Acc: 96.121%
	I - Batch: 150 | Loss: 1.553 | Acc: 96.292% | Wgt Acc: 96.499%
	I - Batch: 200 | Loss: 1.569 | Acc: 95.969% | Wgt Acc: 96.197%
	I - Batch: 250 | Loss: 1.560 | Acc: 96.175% | Wgt Acc: 96.316%
	I - Batch: 300 | Loss: 1.555 | Acc: 96.229% | Wgt Acc: 96.410%
	I - Batch: 350 | Loss: 1.563 | Acc: 96.000% | Wgt Acc: 96.201%
I - num batch: 364
I - Train -- Loss: 1.566 | Acc: 95.942% | Wgt Acc: 96.147% | LR: 1.250000e-04 | Dur: 225.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    3.    5.    6.   35.]
 [   1.  651.    3.    4.   26.]
 [   1.    2.  947.    3.   35.]
 [   3.    3.    6.  675.   24.]
 [  24.    9.   13.   30. 2643.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.826 | Acc: 55.375% | Wgt Acc: 50.809%
I - num batch: 87
I - Val -- Loss: 5.764 | Acc: 60.345% | Wgt Acc: 54.367% | Dur: 41.27s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   4.  21.  37.  29.]
 [  0. 107.  14.   1.   7.]
 [  2.  45. 128.  11.  19.]
 [ 24.  25.  34. 120.  29.]
 [ 35.  87.  93.  35. 347.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 1.577 | Acc: 96.250% | Wgt Acc: 96.165%
	I - Batch: 100 | Loss: 1.558 | Acc: 96.562% | Wgt Acc: 96.649%
	I - Batch: 150 | Loss: 1.551 | Acc: 96.542% | Wgt Acc: 96.621%
	I - Batch: 200 | Loss: 1.556 | Acc: 96.500% | Wgt Acc: 96.483%
	I - Batch: 250 | Loss: 1.562 | Acc: 96.325% | Wgt Acc: 96.403%
	I - Batch: 300 | Loss: 1.559 | Acc: 96.396% | Wgt Acc: 96.446%
	I - Batch: 350 | Loss: 1.559 | Acc: 96.375% | Wgt Acc: 96.494%
I - num batch: 364
I - Train -- Loss: 1.564 | Acc: 96.337% | Wgt Acc: 96.446% | LR: 1.250000e-04 | Dur: 225.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 657.    6.    5.   10.   25.]
 [   1.  649.    2.    3.   11.]
 [   3.    6.  955.    3.   36.]
 [   5.    0.    7.  681.   31.]
 [  26.    7.    5.   21. 2660.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.871 | Acc: 51.875% | Wgt Acc: 45.926%
I - num batch: 87
I - Val -- Loss: 5.792 | Acc: 57.040% | Wgt Acc: 49.766% | Dur: 41.32s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   5.  25.  43.  26.]
 [  0. 114.  30.   7.  12.]
 [  1.  32.  94.   6.  13.]
 [ 13.  11.  19.  90.  21.]
 [ 48. 106. 122.  58. 359.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 1.563 | Acc: 96.500% | Wgt Acc: 96.200%
	I - Batch: 100 | Loss: 1.553 | Acc: 96.812% | Wgt Acc: 96.536%
	I - Batch: 150 | Loss: 1.545 | Acc: 96.792% | Wgt Acc: 96.646%
	I - Batch: 200 | Loss: 1.558 | Acc: 96.406% | Wgt Acc: 96.384%
	I - Batch: 250 | Loss: 1.563 | Acc: 96.200% | Wgt Acc: 96.320%
	I - Batch: 300 | Loss: 1.558 | Acc: 96.146% | Wgt Acc: 96.322%
	I - Batch: 350 | Loss: 1.564 | Acc: 96.089% | Wgt Acc: 96.230%
I - num batch: 364
I - Train -- Loss: 1.568 | Acc: 95.976% | Wgt Acc: 96.136% | LR: 1.250000e-04 | Dur: 225.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    5.    3.    6.   36.]
 [   2.  640.    3.    7.   20.]
 [   1.    5.  952.    2.   29.]
 [   7.    6.    8.  683.   34.]
 [  20.   12.    8.   20. 2644.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.787 | Acc: 54.375% | Wgt Acc: 51.372%
I - num batch: 87
I - Val -- Loss: 5.738 | Acc: 57.830% | Wgt Acc: 54.038% | Dur: 41.34s
I - Confusion Matrix: [row->prediction - col->label]
[[129.  10.  16.  30.  25.]
 [  0. 104.  17.   4.   8.]
 [  3.  63. 146.  13.  45.]
 [ 40.  25.  37. 126.  53.]
 [ 27.  66.  74.  31. 300.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 1.755 | Acc: 93.000% | Wgt Acc: 92.319%
	I - Batch: 100 | Loss: 1.665 | Acc: 94.562% | Wgt Acc: 94.284%
	I - Batch: 150 | Loss: 1.650 | Acc: 95.000% | Wgt Acc: 94.640%
	I - Batch: 200 | Loss: 1.622 | Acc: 95.281% | Wgt Acc: 95.117%
	I - Batch: 250 | Loss: 1.604 | Acc: 95.550% | Wgt Acc: 95.470%
	I - Batch: 300 | Loss: 1.609 | Acc: 95.396% | Wgt Acc: 95.385%
	I - Batch: 350 | Loss: 1.605 | Acc: 95.518% | Wgt Acc: 95.513%
I - num batch: 364
I - Train -- Loss: 1.605 | Acc: 95.529% | Wgt Acc: 95.518% | LR: 1.250000e-04 | Dur: 223.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    4.    7.   10.   27.]
 [   3.  636.    4.    3.   28.]
 [   1.    9.  946.    5.   42.]
 [   7.    2.    3.  676.   23.]
 [  27.   17.   14.   24. 2643.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.809 | Acc: 52.125% | Wgt Acc: 47.213%
I - num batch: 87
I - Val -- Loss: 5.748 | Acc: 57.112% | Wgt Acc: 50.575% | Dur: 40.39s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   3.  14.  33.  22.]
 [  5. 130.  31.   9.  26.]
 [  5.  37. 104.  10.  14.]
 [ 16.  11.  13.  78.  16.]
 [ 43.  87. 128.  74. 353.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 1.533 | Acc: 97.000% | Wgt Acc: 97.082%
	I - Batch: 100 | Loss: 1.530 | Acc: 96.875% | Wgt Acc: 96.861%
	I - Batch: 150 | Loss: 1.532 | Acc: 96.917% | Wgt Acc: 96.875%
	I - Batch: 200 | Loss: 1.543 | Acc: 96.688% | Wgt Acc: 96.578%
	I - Batch: 250 | Loss: 1.546 | Acc: 96.625% | Wgt Acc: 96.498%
	I - Batch: 300 | Loss: 1.537 | Acc: 96.750% | Wgt Acc: 96.622%
	I - Batch: 350 | Loss: 1.536 | Acc: 96.750% | Wgt Acc: 96.622%
I - num batch: 364
I - Train -- Loss: 1.538 | Acc: 96.698% | Wgt Acc: 96.597% | LR: 1.250000e-04 | Dur: 221.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    4.    8.    7.   30.]
 [   3.  649.    1.    3.   16.]
 [   0.    5.  950.    5.   19.]
 [   1.    1.    5.  681.   16.]
 [  27.    9.   10.   22. 2682.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.794 | Acc: 51.125% | Wgt Acc: 46.490%
I - num batch: 87
I - Val -- Loss: 5.737 | Acc: 55.675% | Wgt Acc: 49.387% | Dur: 40.71s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   1.  15.  33.  19.]
 [  2.  85.  13.   4.   7.]
 [  7.  81. 143.  14.  45.]
 [ 18.  23.  20.  93.  24.]
 [ 54.  78.  99.  60. 336.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 1.528 | Acc: 97.000% | Wgt Acc: 97.168%
	I - Batch: 100 | Loss: 1.548 | Acc: 96.875% | Wgt Acc: 96.871%
	I - Batch: 150 | Loss: 1.546 | Acc: 96.833% | Wgt Acc: 96.926%
	I - Batch: 200 | Loss: 1.536 | Acc: 96.906% | Wgt Acc: 97.069%
	I - Batch: 250 | Loss: 1.533 | Acc: 96.925% | Wgt Acc: 97.044%
	I - Batch: 300 | Loss: 1.531 | Acc: 96.854% | Wgt Acc: 96.926%
	I - Batch: 350 | Loss: 1.535 | Acc: 96.839% | Wgt Acc: 96.854%
I - num batch: 364
I - Train -- Loss: 1.534 | Acc: 96.819% | Wgt Acc: 96.870% | LR: 1.250000e-04 | Dur: 223.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    3.    5.    4.   30.]
 [   0.  650.    2.    2.   14.]
 [   1.    7.  953.    3.   24.]
 [   2.    1.    4.  686.   20.]
 [  23.    7.   10.   23. 2675.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.946 | Acc: 50.750% | Wgt Acc: 44.407%
I - num batch: 87
I - Val -- Loss: 5.852 | Acc: 56.106% | Wgt Acc: 48.311% | Dur: 40.69s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   8.  19.  35.  29.]
 [  1.  98.  23.   2.   7.]
 [  2.  28.  82.   6.   9.]
 [ 23.  23.  20. 106.  28.]
 [ 36. 111. 146.  55. 358.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 1.530 | Acc: 96.625% | Wgt Acc: 96.481%
	I - Batch: 100 | Loss: 1.547 | Acc: 96.062% | Wgt Acc: 96.061%
	I - Batch: 150 | Loss: 1.559 | Acc: 95.833% | Wgt Acc: 96.017%
	I - Batch: 200 | Loss: 1.549 | Acc: 96.094% | Wgt Acc: 96.287%
	I - Batch: 250 | Loss: 1.554 | Acc: 96.150% | Wgt Acc: 96.337%
	I - Batch: 300 | Loss: 1.552 | Acc: 96.125% | Wgt Acc: 96.327%
	I - Batch: 350 | Loss: 1.550 | Acc: 96.196% | Wgt Acc: 96.382%
I - num batch: 364
I - Train -- Loss: 1.548 | Acc: 96.251% | Wgt Acc: 96.405% | LR: 1.250000e-04 | Dur: 223.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    4.    7.   12.   37.]
 [   1.  648.    3.    3.   18.]
 [   5.    3.  953.    4.   26.]
 [   3.    4.    2.  680.   28.]
 [  21.    9.    9.   19. 2654.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.913 | Acc: 49.375% | Wgt Acc: 42.765%
I - num batch: 87
I - Val -- Loss: 5.819 | Acc: 56.466% | Wgt Acc: 47.564% | Dur: 40.73s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   2.  14.  32.  20.]
 [  2. 123.  28.   8.   8.]
 [  3.  33.  84.   9.   6.]
 [ 13.   4.   6.  64.   6.]
 [ 57. 106. 158.  91. 391.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 1.512 | Acc: 97.375% | Wgt Acc: 97.212%
	I - Batch: 100 | Loss: 1.519 | Acc: 97.000% | Wgt Acc: 96.950%
	I - Batch: 150 | Loss: 1.522 | Acc: 97.000% | Wgt Acc: 96.952%
	I - Batch: 200 | Loss: 1.539 | Acc: 96.844% | Wgt Acc: 96.653%
	I - Batch: 250 | Loss: 1.530 | Acc: 96.825% | Wgt Acc: 96.801%
	I - Batch: 300 | Loss: 1.519 | Acc: 97.021% | Wgt Acc: 97.034%
	I - Batch: 350 | Loss: 1.520 | Acc: 96.946% | Wgt Acc: 97.011%
I - num batch: 364
I - Train -- Loss: 1.524 | Acc: 96.922% | Wgt Acc: 96.961% | LR: 1.250000e-04 | Dur: 223.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    3.    1.    8.   23.]
 [   1.  653.    2.    3.   18.]
 [   1.    4.  960.    2.   23.]
 [   2.    1.    5.  681.   18.]
 [  27.    7.    6.   24. 2681.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.843 | Acc: 50.875% | Wgt Acc: 45.026%
I - num batch: 87
I - Val -- Loss: 5.772 | Acc: 56.394% | Wgt Acc: 48.369% | Dur: 40.72s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   2.  12.  23.   7.]
 [  1. 105.  14.   9.   7.]
 [  4.  53. 121.  15.  23.]
 [ 17.   9.  19.  81.  19.]
 [ 74.  99. 124.  76. 375.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 1.499 | Acc: 96.375% | Wgt Acc: 96.720%
	I - Batch: 100 | Loss: 1.539 | Acc: 96.000% | Wgt Acc: 96.235%
	I - Batch: 150 | Loss: 1.516 | Acc: 96.667% | Wgt Acc: 96.784%
	I - Batch: 200 | Loss: 1.519 | Acc: 96.688% | Wgt Acc: 96.721%
	I - Batch: 250 | Loss: 1.535 | Acc: 96.350% | Wgt Acc: 96.496%
	I - Batch: 300 | Loss: 1.542 | Acc: 96.188% | Wgt Acc: 96.388%
	I - Batch: 350 | Loss: 1.540 | Acc: 96.286% | Wgt Acc: 96.397%
I - num batch: 364
I - Train -- Loss: 1.543 | Acc: 96.268% | Wgt Acc: 96.328% | LR: 1.250000e-04 | Dur: 223.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    3.    5.    9.   40.]
 [   0.  653.    1.    5.   16.]
 [   3.    3.  953.    2.   18.]
 [   5.    1.    4.  677.   26.]
 [  32.    8.   11.   25. 2663.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.857 | Acc: 50.250% | Wgt Acc: 44.156%
I - num batch: 87
I - Val -- Loss: 5.782 | Acc: 56.034% | Wgt Acc: 48.427% | Dur: 40.75s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   9.  23.  59.  38.]
 [  0. 105.  25.   2.   5.]
 [  1.  34.  83.   7.   7.]
 [ 12.  20.  28.  85.  24.]
 [ 36. 100. 131.  51. 357.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 1.523 | Acc: 96.625% | Wgt Acc: 96.718%
	I - Batch: 100 | Loss: 1.488 | Acc: 97.438% | Wgt Acc: 97.569%
	I - Batch: 150 | Loss: 1.504 | Acc: 97.125% | Wgt Acc: 97.185%
	I - Batch: 200 | Loss: 1.512 | Acc: 97.062% | Wgt Acc: 97.097%
	I - Batch: 250 | Loss: 1.532 | Acc: 96.775% | Wgt Acc: 96.733%
	I - Batch: 300 | Loss: 1.542 | Acc: 96.500% | Wgt Acc: 96.452%
	I - Batch: 350 | Loss: 1.541 | Acc: 96.554% | Wgt Acc: 96.482%
I - num batch: 364
I - Train -- Loss: 1.548 | Acc: 96.440% | Wgt Acc: 96.355% | LR: 1.250000e-04 | Dur: 229.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    4.    2.    7.   32.]
 [   2.  649.    4.    3.   16.]
 [   2.    4.  950.    1.   14.]
 [   4.    0.    4.  683.   26.]
 [  33.   11.   14.   24. 2675.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.881 | Acc: 53.000% | Wgt Acc: 46.974%
I - num batch: 87
I - Val -- Loss: 5.792 | Acc: 57.902% | Wgt Acc: 49.758% | Dur: 42.40s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.  15.  24.  12.]
 [  1. 113.  18.   5.   8.]
 [  4.  31. 102.   9.  11.]
 [ 17.  16.  16.  90.  20.]
 [ 56. 106. 139.  76. 380.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 1.593 | Acc: 96.625% | Wgt Acc: 96.188%
	I - Batch: 100 | Loss: 1.534 | Acc: 97.125% | Wgt Acc: 97.062%
	I - Batch: 150 | Loss: 1.507 | Acc: 97.500% | Wgt Acc: 97.537%
	I - Batch: 200 | Loss: 1.498 | Acc: 97.594% | Wgt Acc: 97.572%
	I - Batch: 250 | Loss: 1.499 | Acc: 97.550% | Wgt Acc: 97.479%
	I - Batch: 300 | Loss: 1.488 | Acc: 97.604% | Wgt Acc: 97.616%
	I - Batch: 350 | Loss: 1.496 | Acc: 97.393% | Wgt Acc: 97.408%
I - num batch: 364
I - Train -- Loss: 1.498 | Acc: 97.352% | Wgt Acc: 97.361% | LR: 1.250000e-04 | Dur: 229.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    2.    2.    5.   18.]
 [   1.  652.    1.    1.   18.]
 [   1.    3.  962.    2.   17.]
 [   5.    1.    5.  687.   17.]
 [  18.   10.    4.   23. 2693.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.760 | Acc: 56.375% | Wgt Acc: 53.106%
I - num batch: 87
I - Val -- Loss: 5.731 | Acc: 59.267% | Wgt Acc: 55.041% | Dur: 42.35s
I - Confusion Matrix: [row->prediction - col->label]
[[134.  10.  15.  38.  20.]
 [  4. 178.  79.   5.  37.]
 [  3.  12.  73.   5.   9.]
 [ 28.  15.  26. 116.  41.]
 [ 30.  53.  97.  40. 324.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 1.743 | Acc: 92.875% | Wgt Acc: 92.771%
	I - Batch: 100 | Loss: 1.652 | Acc: 94.312% | Wgt Acc: 94.364%
	I - Batch: 150 | Loss: 1.623 | Acc: 95.083% | Wgt Acc: 95.046%
	I - Batch: 200 | Loss: 1.613 | Acc: 95.375% | Wgt Acc: 95.315%
	I - Batch: 250 | Loss: 1.599 | Acc: 95.550% | Wgt Acc: 95.514%
	I - Batch: 300 | Loss: 1.592 | Acc: 95.604% | Wgt Acc: 95.645%
	I - Batch: 350 | Loss: 1.591 | Acc: 95.554% | Wgt Acc: 95.656%
I - num batch: 364
I - Train -- Loss: 1.588 | Acc: 95.615% | Wgt Acc: 95.736% | LR: 1.250000e-04 | Dur: 229.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    4.    4.    9.   30.]
 [   2.  639.   11.    4.   23.]
 [   3.   12.  943.    3.   37.]
 [   2.    2.    2.  675.   37.]
 [  18.   11.   14.   27. 2636.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.930 | Acc: 50.500% | Wgt Acc: 44.560%
I - num batch: 87
I - Val -- Loss: 5.825 | Acc: 55.747% | Wgt Acc: 48.802% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   6.  15.  25.  25.]
 [  0.  84.  15.   2.   4.]
 [  2.  41. 109.   7.  18.]
 [ 45.  25.  38. 123.  43.]
 [ 33. 112. 113.  47. 341.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 1.549 | Acc: 96.875% | Wgt Acc: 96.561%
	I - Batch: 100 | Loss: 1.539 | Acc: 96.688% | Wgt Acc: 96.596%
	I - Batch: 150 | Loss: 1.516 | Acc: 97.042% | Wgt Acc: 97.008%
	I - Batch: 200 | Loss: 1.512 | Acc: 96.938% | Wgt Acc: 97.049%
	I - Batch: 250 | Loss: 1.512 | Acc: 96.900% | Wgt Acc: 97.094%
	I - Batch: 300 | Loss: 1.516 | Acc: 96.854% | Wgt Acc: 97.020%
	I - Batch: 350 | Loss: 1.513 | Acc: 96.929% | Wgt Acc: 97.109%
I - num batch: 364
I - Train -- Loss: 1.512 | Acc: 96.922% | Wgt Acc: 97.104% | LR: 1.250000e-04 | Dur: 229.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    4.    3.    4.   29.]
 [   1.  652.    2.    3.   10.]
 [   2.    3.  958.    4.   27.]
 [   3.    0.    2.  694.   27.]
 [  24.    9.    9.   13. 2670.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.985 | Acc: 49.250% | Wgt Acc: 42.067%
I - num batch: 87
I - Val -- Loss: 5.866 | Acc: 55.891% | Wgt Acc: 47.061% | Dur: 42.34s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   7.  17.  27.  18.]
 [  1.  86.  16.   4.   6.]
 [  2.  27.  76.   1.   9.]
 [ 19.  19.  26. 110.  26.]
 [ 43. 129. 155.  62. 372.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 1.483 | Acc: 98.250% | Wgt Acc: 97.849%
	I - Batch: 100 | Loss: 1.469 | Acc: 98.125% | Wgt Acc: 97.991%
	I - Batch: 150 | Loss: 1.478 | Acc: 98.042% | Wgt Acc: 97.816%
	I - Batch: 200 | Loss: 1.473 | Acc: 98.094% | Wgt Acc: 97.980%
	I - Batch: 250 | Loss: 1.487 | Acc: 97.850% | Wgt Acc: 97.793%
	I - Batch: 300 | Loss: 1.492 | Acc: 97.604% | Wgt Acc: 97.636%
	I - Batch: 350 | Loss: 1.498 | Acc: 97.500% | Wgt Acc: 97.543%
I - num batch: 364
I - Train -- Loss: 1.496 | Acc: 97.506% | Wgt Acc: 97.547% | LR: 1.250000e-04 | Dur: 229.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    3.    3.    5.   17.]
 [   1.  655.    1.    3.   10.]
 [   2.    3.  960.    2.   18.]
 [   3.    0.    3.  689.   23.]
 [  15.    7.    7.   19. 2695.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.879 | Acc: 52.000% | Wgt Acc: 46.594%
I - num batch: 87
I - Val -- Loss: 5.792 | Acc: 57.974% | Wgt Acc: 51.368% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   9.  23.  52.  26.]
 [  0.  98.  11.   3.   4.]
 [  2.  45. 120.   8.  15.]
 [ 17.  28.  30.  97.  38.]
 [ 36.  88. 106.  44. 348.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 1.495 | Acc: 97.250% | Wgt Acc: 97.398%
	I - Batch: 100 | Loss: 1.531 | Acc: 97.000% | Wgt Acc: 96.806%
	I - Batch: 150 | Loss: 1.503 | Acc: 97.250% | Wgt Acc: 97.280%
	I - Batch: 200 | Loss: 1.503 | Acc: 97.250% | Wgt Acc: 97.226%
	I - Batch: 250 | Loss: 1.510 | Acc: 97.125% | Wgt Acc: 97.119%
	I - Batch: 300 | Loss: 1.503 | Acc: 97.188% | Wgt Acc: 97.210%
	I - Batch: 350 | Loss: 1.501 | Acc: 97.179% | Wgt Acc: 97.260%
I - num batch: 364
I - Train -- Loss: 1.501 | Acc: 97.197% | Wgt Acc: 97.258% | LR: 1.250000e-04 | Dur: 229.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    3.    4.    3.   24.]
 [   1.  651.    2.    1.   13.]
 [   1.    2.  956.    5.   21.]
 [   2.    2.    3.  695.   21.]
 [  22.   10.    9.   14. 2684.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.772 | Acc: 52.375% | Wgt Acc: 47.525%
I - num batch: 87
I - Val -- Loss: 5.725 | Acc: 57.830% | Wgt Acc: 51.891% | Dur: 42.38s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   9.  15.  34.  23.]
 [  4. 106.  32.   6.  10.]
 [  5.  56. 131.  19.  39.]
 [ 22.   8.  20.  96.  19.]
 [ 36.  89.  92.  49. 340.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 1.527 | Acc: 96.625% | Wgt Acc: 96.973%
	I - Batch: 100 | Loss: 1.542 | Acc: 96.625% | Wgt Acc: 96.686%
	I - Batch: 150 | Loss: 1.521 | Acc: 96.875% | Wgt Acc: 96.916%
	I - Batch: 200 | Loss: 1.518 | Acc: 96.969% | Wgt Acc: 96.936%
	I - Batch: 250 | Loss: 1.509 | Acc: 97.025% | Wgt Acc: 97.069%
	I - Batch: 300 | Loss: 1.504 | Acc: 97.083% | Wgt Acc: 97.140%
	I - Batch: 350 | Loss: 1.506 | Acc: 97.089% | Wgt Acc: 97.158%
I - num batch: 364
I - Train -- Loss: 1.507 | Acc: 97.025% | Wgt Acc: 97.130% | LR: 1.250000e-04 | Dur: 229.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    4.    2.    6.   24.]
 [   2.  652.    0.    5.   12.]
 [   2.    5.  963.    5.   26.]
 [   4.    0.    3.  681.   22.]
 [  17.    7.    6.   21. 2679.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.941 | Acc: 52.000% | Wgt Acc: 46.919%
I - num batch: 87
I - Val -- Loss: 5.837 | Acc: 57.687% | Wgt Acc: 50.892% | Dur: 42.28s
I - Confusion Matrix: [row->prediction - col->label]
[[152.  10.  19.  41.  31.]
 [  1. 131.  31.   4.   9.]
 [  1.   9.  65.   3.   6.]
 [ 17.  23.  27. 104.  34.]
 [ 28.  95. 148.  52. 351.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 1.539 | Acc: 96.000% | Wgt Acc: 95.911%
	I - Batch: 100 | Loss: 1.528 | Acc: 96.188% | Wgt Acc: 96.418%
	I - Batch: 150 | Loss: 1.552 | Acc: 96.125% | Wgt Acc: 96.139%
	I - Batch: 200 | Loss: 1.538 | Acc: 96.469% | Wgt Acc: 96.467%
	I - Batch: 250 | Loss: 1.533 | Acc: 96.575% | Wgt Acc: 96.519%
	I - Batch: 300 | Loss: 1.530 | Acc: 96.625% | Wgt Acc: 96.588%
	I - Batch: 350 | Loss: 1.529 | Acc: 96.571% | Wgt Acc: 96.555%
I - num batch: 364
I - Train -- Loss: 1.531 | Acc: 96.543% | Wgt Acc: 96.507% | LR: 1.250000e-04 | Dur: 229.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    5.    4.    7.   28.]
 [   3.  648.    2.    1.   13.]
 [   4.    5.  952.    3.   28.]
 [   7.    1.    4.  682.   20.]
 [  20.    9.   12.   25. 2674.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.856 | Acc: 51.750% | Wgt Acc: 46.386%
I - num batch: 87
I - Val -- Loss: 5.785 | Acc: 56.609% | Wgt Acc: 49.832% | Dur: 42.31s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   6.  12.  20.  23.]
 [  1. 123.  32.   2.   8.]
 [  1.  32.  79.   5.  12.]
 [ 49.  22.  37. 128.  40.]
 [ 38.  85. 130.  49. 348.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 98.375% | Wgt Acc: 98.651%
	I - Batch: 100 | Loss: 1.475 | Acc: 97.750% | Wgt Acc: 98.019%
	I - Batch: 150 | Loss: 1.486 | Acc: 97.625% | Wgt Acc: 97.772%
	I - Batch: 200 | Loss: 1.479 | Acc: 97.625% | Wgt Acc: 97.857%
	I - Batch: 250 | Loss: 1.488 | Acc: 97.525% | Wgt Acc: 97.559%
	I - Batch: 300 | Loss: 1.483 | Acc: 97.688% | Wgt Acc: 97.661%
	I - Batch: 350 | Loss: 1.480 | Acc: 97.750% | Wgt Acc: 97.687%
I - num batch: 364
I - Train -- Loss: 1.480 | Acc: 97.764% | Wgt Acc: 97.696% | LR: 1.250000e-04 | Dur: 229.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    3.    4.    4.   16.]
 [   1.  651.    2.    2.    8.]
 [   1.    4.  964.    2.   18.]
 [   1.    2.    0.  688.   13.]
 [  15.    8.    4.   22. 2708.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.876 | Acc: 51.500% | Wgt Acc: 45.399%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 56.537% | Wgt Acc: 48.814% | Dur: 42.22s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   7.  15.  34.  23.]
 [  0.  94.  24.   5.   5.]
 [  3.  35. 103.  11.  17.]
 [ 33.  17.  25. 104.  25.]
 [ 38. 115. 123.  50. 361.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 1.512 | Acc: 97.000% | Wgt Acc: 96.702%
	I - Batch: 100 | Loss: 1.492 | Acc: 97.375% | Wgt Acc: 97.234%
	I - Batch: 150 | Loss: 1.482 | Acc: 97.500% | Wgt Acc: 97.462%
	I - Batch: 200 | Loss: 1.492 | Acc: 97.438% | Wgt Acc: 97.363%
	I - Batch: 250 | Loss: 1.492 | Acc: 97.450% | Wgt Acc: 97.362%
	I - Batch: 300 | Loss: 1.498 | Acc: 97.229% | Wgt Acc: 97.253%
	I - Batch: 350 | Loss: 1.497 | Acc: 97.250% | Wgt Acc: 97.303%
I - num batch: 364
I - Train -- Loss: 1.505 | Acc: 97.145% | Wgt Acc: 97.172% | LR: 1.250000e-04 | Dur: 229.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    3.    3.    7.   25.]
 [   2.  649.    3.    1.   13.]
 [   0.    4.  958.    2.   23.]
 [   4.    3.    3.  689.   17.]
 [  18.    9.    7.   19. 2685.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.765 | Acc: 53.000% | Wgt Acc: 48.346%
I - num batch: 87
I - Val -- Loss: 5.715 | Acc: 56.322% | Wgt Acc: 51.089% | Dur: 42.26s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   6.  13.  26.  17.]
 [  0.  93.  18.   1.   1.]
 [  6.  71. 157.  18.  62.]
 [ 29.  16.  19.  95.  28.]
 [ 48.  82.  83.  64. 323.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 1.470 | Acc: 97.125% | Wgt Acc: 97.810%
	I - Batch: 100 | Loss: 1.496 | Acc: 96.812% | Wgt Acc: 97.213%
	I - Batch: 150 | Loss: 1.530 | Acc: 96.333% | Wgt Acc: 96.601%
	I - Batch: 200 | Loss: 1.543 | Acc: 96.031% | Wgt Acc: 96.327%
	I - Batch: 250 | Loss: 1.547 | Acc: 96.075% | Wgt Acc: 96.230%
	I - Batch: 300 | Loss: 1.547 | Acc: 96.208% | Wgt Acc: 96.326%
	I - Batch: 350 | Loss: 1.535 | Acc: 96.464% | Wgt Acc: 96.590%
I - num batch: 364
I - Train -- Loss: 1.537 | Acc: 96.406% | Wgt Acc: 96.567% | LR: 1.250000e-04 | Dur: 229.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    3.    1.    6.   31.]
 [   1.  652.    2.    2.   13.]
 [   0.    4.  955.    4.   33.]
 [   7.    1.    3.  678.   27.]
 [  22.    8.   13.   28. 2659.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.816 | Acc: 51.375% | Wgt Acc: 46.196%
I - num batch: 87
I - Val -- Loss: 5.750 | Acc: 56.753% | Wgt Acc: 49.901% | Dur: 42.18s
I - Confusion Matrix: [row->prediction - col->label]
[[155.   8.  23.  63.  34.]
 [  0. 105.  22.   8.   8.]
 [  2.  38. 101.   6.  17.]
 [ 12.  22.  25.  81.  24.]
 [ 30.  95. 119.  46. 348.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 1.444 | Acc: 98.250% | Wgt Acc: 97.993%
	I - Batch: 100 | Loss: 1.453 | Acc: 98.062% | Wgt Acc: 98.001%
	I - Batch: 150 | Loss: 1.471 | Acc: 97.792% | Wgt Acc: 97.804%
	I - Batch: 200 | Loss: 1.485 | Acc: 97.688% | Wgt Acc: 97.602%
	I - Batch: 250 | Loss: 1.483 | Acc: 97.775% | Wgt Acc: 97.696%
	I - Batch: 300 | Loss: 1.490 | Acc: 97.646% | Wgt Acc: 97.581%
	I - Batch: 350 | Loss: 1.489 | Acc: 97.643% | Wgt Acc: 97.594%
I - num batch: 364
I - Train -- Loss: 1.487 | Acc: 97.644% | Wgt Acc: 97.611% | LR: 1.250000e-04 | Dur: 229.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    4.    2.    5.   18.]
 [   1.  651.    1.    2.   11.]
 [   0.    5.  965.    2.   14.]
 [   2.    2.    1.  691.   17.]
 [  21.    6.    5.   18. 2703.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.808 | Acc: 52.500% | Wgt Acc: 47.978%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 57.615% | Wgt Acc: 52.161% | Dur: 42.26s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   5.  14.  28.  20.]
 [  1. 120.  35.   7.  19.]
 [  3.  27. 100.   9.  12.]
 [ 28.  35.  27. 121.  52.]
 [ 34.  81. 114.  39. 328.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 1.457 | Acc: 98.125% | Wgt Acc: 97.908%
	I - Batch: 100 | Loss: 1.456 | Acc: 97.875% | Wgt Acc: 97.874%
	I - Batch: 150 | Loss: 1.461 | Acc: 97.667% | Wgt Acc: 97.793%
	I - Batch: 200 | Loss: 1.457 | Acc: 97.719% | Wgt Acc: 97.886%
	I - Batch: 250 | Loss: 1.450 | Acc: 97.900% | Wgt Acc: 98.068%
	I - Batch: 300 | Loss: 1.452 | Acc: 97.854% | Wgt Acc: 97.963%
	I - Batch: 350 | Loss: 1.471 | Acc: 97.589% | Wgt Acc: 97.644%
I - num batch: 364
I - Train -- Loss: 1.476 | Acc: 97.541% | Wgt Acc: 97.559% | LR: 1.250000e-04 | Dur: 229.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    1.    5.   13.]
 [   1.  652.    2.    0.   19.]
 [   1.    2.  959.    4.   18.]
 [   0.    1.    4.  689.   17.]
 [  14.   11.    8.   20. 2696.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.754 | Acc: 54.125% | Wgt Acc: 50.864%
I - num batch: 87
I - Val -- Loss: 5.704 | Acc: 58.046% | Wgt Acc: 53.609% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   7.  17.  26.  23.]
 [  1. 154.  53.   7.  21.]
 [  6.  40. 100.  12.  39.]
 [ 18.  15.  27. 106.  26.]
 [ 48.  52.  93.  53. 322.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 1.437 | Acc: 98.375% | Wgt Acc: 98.438%
	I - Batch: 100 | Loss: 1.464 | Acc: 97.750% | Wgt Acc: 97.728%
	I - Batch: 150 | Loss: 1.485 | Acc: 97.625% | Wgt Acc: 97.502%
	I - Batch: 200 | Loss: 1.469 | Acc: 97.938% | Wgt Acc: 97.827%
	I - Batch: 250 | Loss: 1.477 | Acc: 97.750% | Wgt Acc: 97.691%
	I - Batch: 300 | Loss: 1.483 | Acc: 97.729% | Wgt Acc: 97.643%
	I - Batch: 350 | Loss: 1.485 | Acc: 97.714% | Wgt Acc: 97.613%
I - num batch: 364
I - Train -- Loss: 1.486 | Acc: 97.696% | Wgt Acc: 97.599% | LR: 1.250000e-04 | Dur: 229.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    3.    1.   10.   12.]
 [   0.  653.    1.    0.    8.]
 [   0.    5.  963.    2.   15.]
 [   2.    1.    5.  686.   19.]
 [  20.    6.    4.   20. 2709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.809 | Acc: 51.875% | Wgt Acc: 47.476%
I - num batch: 87
I - Val -- Loss: 5.745 | Acc: 56.106% | Wgt Acc: 51.213% | Dur: 42.22s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   4.  12.  22.  28.]
 [  0.  96.  22.   2.   9.]
 [  5.  46. 110.  10.  30.]
 [ 48.  51.  42. 144.  58.]
 [ 21.  71. 104.  26. 306.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 1.482 | Acc: 98.000% | Wgt Acc: 97.578%
	I - Batch: 100 | Loss: 1.474 | Acc: 97.688% | Wgt Acc: 97.604%
	I - Batch: 150 | Loss: 1.471 | Acc: 97.667% | Wgt Acc: 97.728%
	I - Batch: 200 | Loss: 1.473 | Acc: 97.656% | Wgt Acc: 97.745%
	I - Batch: 250 | Loss: 1.471 | Acc: 97.750% | Wgt Acc: 97.820%
	I - Batch: 300 | Loss: 1.473 | Acc: 97.812% | Wgt Acc: 97.814%
	I - Batch: 350 | Loss: 1.467 | Acc: 97.911% | Wgt Acc: 97.923%
I - num batch: 364
I - Train -- Loss: 1.466 | Acc: 97.954% | Wgt Acc: 97.950% | LR: 1.250000e-04 | Dur: 229.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    3.    3.    5.   16.]
 [   3.  655.    2.    1.   10.]
 [   0.    3.  963.    4.   16.]
 [   2.    3.    2.  696.   12.]
 [  14.    4.    4.   12. 2709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.826 | Acc: 53.625% | Wgt Acc: 49.173%
I - num batch: 87
I - Val -- Loss: 5.766 | Acc: 58.405% | Wgt Acc: 52.479% | Dur: 42.19s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   4.  19.  22.  17.]
 [  0. 132.  34.   7.  21.]
 [  4.  26.  91.   5.  12.]
 [ 42.  27.  34. 127.  39.]
 [ 32.  79. 112.  43. 342.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 1.536 | Acc: 96.750% | Wgt Acc: 96.521%
	I - Batch: 100 | Loss: 1.491 | Acc: 97.562% | Wgt Acc: 97.407%
	I - Batch: 150 | Loss: 1.499 | Acc: 97.458% | Wgt Acc: 97.302%
	I - Batch: 200 | Loss: 1.488 | Acc: 97.562% | Wgt Acc: 97.456%
	I - Batch: 250 | Loss: 1.485 | Acc: 97.575% | Wgt Acc: 97.489%
	I - Batch: 300 | Loss: 1.486 | Acc: 97.458% | Wgt Acc: 97.444%
	I - Batch: 350 | Loss: 1.485 | Acc: 97.518% | Wgt Acc: 97.477%
I - num batch: 364
I - Train -- Loss: 1.483 | Acc: 97.575% | Wgt Acc: 97.509% | LR: 1.250000e-04 | Dur: 229.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    3.    1.    4.   17.]
 [   0.  654.    1.    5.    4.]
 [   1.    3.  961.    1.   14.]
 [   2.    1.    5.  687.   24.]
 [  21.    7.    6.   21. 2704.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.020 | Acc: 47.625% | Wgt Acc: 40.070%
I - num batch: 87
I - Val -- Loss: 5.884 | Acc: 55.101% | Wgt Acc: 45.191% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   7.  18.  31.  21.]
 [  0.  77.  11.   2.   5.]
 [  2.  35.  85.  12.   5.]
 [ 14.  13.  11.  80.  10.]
 [ 48. 136. 165.  79. 390.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 1.531 | Acc: 97.000% | Wgt Acc: 96.732%
	I - Batch: 100 | Loss: 1.501 | Acc: 97.375% | Wgt Acc: 97.276%
	I - Batch: 150 | Loss: 1.503 | Acc: 97.292% | Wgt Acc: 97.146%
	I - Batch: 200 | Loss: 1.489 | Acc: 97.625% | Wgt Acc: 97.424%
	I - Batch: 250 | Loss: 1.481 | Acc: 97.675% | Wgt Acc: 97.517%
	I - Batch: 300 | Loss: 1.479 | Acc: 97.729% | Wgt Acc: 97.624%
	I - Batch: 350 | Loss: 1.472 | Acc: 97.786% | Wgt Acc: 97.747%
I - num batch: 364
I - Train -- Loss: 1.469 | Acc: 97.850% | Wgt Acc: 97.805% | LR: 1.250000e-04 | Dur: 229.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    3.    4.    5.   21.]
 [   0.  654.    0.    0.    2.]
 [   0.    5.  962.    1.   17.]
 [   2.    0.    2.  697.   14.]
 [  22.    6.    6.   15. 2709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.772 | Acc: 55.375% | Wgt Acc: 50.698%
I - num batch: 87
I - Val -- Loss: 5.728 | Acc: 58.405% | Wgt Acc: 53.052% | Dur: 42.25s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   9.  18.  36.  34.]
 [  1. 123.  34.   7.  12.]
 [  3.  38. 112.  10.  24.]
 [ 20.  13.  23. 104.  29.]
 [ 33.  85. 103.  47. 332.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 1.455 | Acc: 97.500% | Wgt Acc: 97.396%
	I - Batch: 100 | Loss: 1.488 | Acc: 96.750% | Wgt Acc: 97.041%
	I - Batch: 150 | Loss: 1.496 | Acc: 96.792% | Wgt Acc: 97.044%
	I - Batch: 200 | Loss: 1.492 | Acc: 96.969% | Wgt Acc: 97.185%
	I - Batch: 250 | Loss: 1.488 | Acc: 97.150% | Wgt Acc: 97.292%
	I - Batch: 300 | Loss: 1.488 | Acc: 97.271% | Wgt Acc: 97.350%
	I - Batch: 350 | Loss: 1.491 | Acc: 97.071% | Wgt Acc: 97.211%
I - num batch: 364
I - Train -- Loss: 1.491 | Acc: 97.094% | Wgt Acc: 97.227% | LR: 1.250000e-04 | Dur: 229.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    3.    3.    6.   25.]
 [   1.  655.    1.    1.    8.]
 [   0.    2.  960.    2.   24.]
 [   5.    1.    3.  694.   27.]
 [  28.    7.    7.   15. 2679.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.946 | Acc: 50.875% | Wgt Acc: 44.609%
I - num batch: 87
I - Val -- Loss: 5.836 | Acc: 56.897% | Wgt Acc: 48.520% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   4.  15.  36.  17.]
 [  0. 114.  23.   2.   8.]
 [  2.  27.  96.   6.  13.]
 [ 12.  11.   4.  75.  12.]
 [ 59. 112. 152.  85. 381.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 1.438 | Acc: 98.875% | Wgt Acc: 98.638%
	I - Batch: 100 | Loss: 1.433 | Acc: 98.625% | Wgt Acc: 98.571%
	I - Batch: 150 | Loss: 1.465 | Acc: 98.167% | Wgt Acc: 97.882%
	I - Batch: 200 | Loss: 1.481 | Acc: 97.844% | Wgt Acc: 97.663%
	I - Batch: 250 | Loss: 1.486 | Acc: 97.725% | Wgt Acc: 97.562%
	I - Batch: 300 | Loss: 1.494 | Acc: 97.542% | Wgt Acc: 97.463%
	I - Batch: 350 | Loss: 1.500 | Acc: 97.375% | Wgt Acc: 97.349%
I - num batch: 364
I - Train -- Loss: 1.499 | Acc: 97.317% | Wgt Acc: 97.357% | LR: 1.250000e-04 | Dur: 229.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    7.    1.    6.   22.]
 [   1.  653.    2.    2.   17.]
 [   2.    2.  960.    2.   13.]
 [   3.    0.    4.  686.   21.]
 [  16.    6.    7.   22. 2690.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.765 | Acc: 56.000% | Wgt Acc: 51.611%
I - num batch: 87
I - Val -- Loss: 5.721 | Acc: 58.908% | Wgt Acc: 53.659% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   1.  12.  24.  17.]
 [  1. 158.  63.   8.  36.]
 [  3.  22.  83.   5.  16.]
 [ 23.  18.  28. 117.  24.]
 [ 48.  69. 104.  50. 338.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 1.480 | Acc: 97.375% | Wgt Acc: 97.425%
	I - Batch: 100 | Loss: 1.502 | Acc: 97.062% | Wgt Acc: 97.153%
	I - Batch: 150 | Loss: 1.480 | Acc: 97.417% | Wgt Acc: 97.571%
	I - Batch: 200 | Loss: 1.487 | Acc: 97.438% | Wgt Acc: 97.479%
	I - Batch: 250 | Loss: 1.486 | Acc: 97.425% | Wgt Acc: 97.436%
	I - Batch: 300 | Loss: 1.485 | Acc: 97.375% | Wgt Acc: 97.465%
	I - Batch: 350 | Loss: 1.483 | Acc: 97.429% | Wgt Acc: 97.523%
I - num batch: 364
I - Train -- Loss: 1.482 | Acc: 97.472% | Wgt Acc: 97.537% | LR: 1.250000e-04 | Dur: 229.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    3.    2.    5.   23.]
 [   2.  655.    1.    3.   14.]
 [   2.    1.  958.    2.   19.]
 [   0.    2.    2.  691.   15.]
 [  16.    7.   11.   17. 2692.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.858 | Acc: 50.625% | Wgt Acc: 44.579%
I - num batch: 87
I - Val -- Loss: 5.774 | Acc: 56.609% | Wgt Acc: 48.845% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   6.  13.  13.  11.]
 [  2. 109.  27.   2.   5.]
 [  5.  32.  91.   9.  21.]
 [ 40.  32.  36. 119.  29.]
 [ 48.  89. 123.  61. 365.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 1.435 | Acc: 98.500% | Wgt Acc: 98.512%
	I - Batch: 100 | Loss: 1.461 | Acc: 98.250% | Wgt Acc: 98.169%
	I - Batch: 150 | Loss: 1.465 | Acc: 98.000% | Wgt Acc: 97.999%
	I - Batch: 200 | Loss: 1.468 | Acc: 97.938% | Wgt Acc: 97.865%
	I - Batch: 250 | Loss: 1.464 | Acc: 97.975% | Wgt Acc: 97.898%
	I - Batch: 300 | Loss: 1.463 | Acc: 98.021% | Wgt Acc: 97.937%
	I - Batch: 350 | Loss: 1.465 | Acc: 98.071% | Wgt Acc: 97.909%
I - num batch: 364
I - Train -- Loss: 1.463 | Acc: 98.108% | Wgt Acc: 97.954% | LR: 1.250000e-04 | Dur: 229.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    2.    3.    8.   13.]
 [   1.  656.    0.    0.    4.]
 [   0.    3.  960.    1.   12.]
 [   2.    2.    4.  693.   11.]
 [  16.    5.    7.   16. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.821 | Acc: 53.750% | Wgt Acc: 49.106%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 58.190% | Wgt Acc: 52.715% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   3.  15.  30.  22.]
 [  2. 118.  19.   4.  12.]
 [  1.  41. 108.   5.  18.]
 [ 45.  28.  36. 134.  48.]
 [ 32.  78. 112.  31. 331.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 1.509 | Acc: 96.750% | Wgt Acc: 96.708%
	I - Batch: 100 | Loss: 1.485 | Acc: 97.250% | Wgt Acc: 97.245%
	I - Batch: 150 | Loss: 1.474 | Acc: 97.583% | Wgt Acc: 97.608%
	I - Batch: 200 | Loss: 1.476 | Acc: 97.594% | Wgt Acc: 97.548%
	I - Batch: 250 | Loss: 1.470 | Acc: 97.675% | Wgt Acc: 97.662%
	I - Batch: 300 | Loss: 1.478 | Acc: 97.562% | Wgt Acc: 97.576%
	I - Batch: 350 | Loss: 1.478 | Acc: 97.554% | Wgt Acc: 97.537%
I - num batch: 364
I - Train -- Loss: 1.478 | Acc: 97.575% | Wgt Acc: 97.548% | LR: 1.250000e-04 | Dur: 229.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    5.    2.    4.   13.]
 [   4.  652.    1.    0.   11.]
 [   1.    4.  959.    1.   20.]
 [   2.    1.    3.  693.   19.]
 [  15.    6.    9.   20. 2700.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.814 | Acc: 51.750% | Wgt Acc: 46.808%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 56.681% | Wgt Acc: 50.451% | Dur: 42.26s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   8.  25.  64.  35.]
 [  3. 133.  43.   8.  13.]
 [  1.  37.  87.  11.  15.]
 [ 15.  15.  16.  76.  25.]
 [ 30.  75. 119.  45. 343.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 1.421 | Acc: 98.625% | Wgt Acc: 98.465%
	I - Batch: 100 | Loss: 1.444 | Acc: 98.500% | Wgt Acc: 98.346%
	I - Batch: 150 | Loss: 1.449 | Acc: 98.208% | Wgt Acc: 98.207%
	I - Batch: 200 | Loss: 1.459 | Acc: 98.062% | Wgt Acc: 98.076%
	I - Batch: 250 | Loss: 1.479 | Acc: 97.700% | Wgt Acc: 97.706%
	I - Batch: 300 | Loss: 1.485 | Acc: 97.458% | Wgt Acc: 97.567%
	I - Batch: 350 | Loss: 1.497 | Acc: 97.214% | Wgt Acc: 97.318%
I - num batch: 364
I - Train -- Loss: 1.497 | Acc: 97.214% | Wgt Acc: 97.304% | LR: 1.250000e-04 | Dur: 229.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    3.    2.    7.   22.]
 [   0.  650.    0.    2.   19.]
 [   1.    5.  956.    1.   22.]
 [   2.    1.    2.  691.   18.]
 [  15.    9.   14.   17. 2682.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.786 | Acc: 54.250% | Wgt Acc: 50.821%
I - num batch: 87
I - Val -- Loss: 5.730 | Acc: 57.759% | Wgt Acc: 53.322% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   4.   8.   6.  13.]
 [  0. 127.  34.   0.  16.]
 [  4.  40. 118.  17.  39.]
 [ 49.  22.  24. 140.  48.]
 [ 42.  75. 106.  41. 315.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 1.541 | Acc: 96.625% | Wgt Acc: 96.869%
	I - Batch: 100 | Loss: 1.516 | Acc: 97.000% | Wgt Acc: 97.410%
	I - Batch: 150 | Loss: 1.527 | Acc: 96.792% | Wgt Acc: 97.093%
	I - Batch: 200 | Loss: 1.525 | Acc: 96.625% | Wgt Acc: 96.988%
	I - Batch: 250 | Loss: 1.513 | Acc: 96.975% | Wgt Acc: 97.184%
	I - Batch: 300 | Loss: 1.506 | Acc: 97.083% | Wgt Acc: 97.208%
	I - Batch: 350 | Loss: 1.512 | Acc: 96.857% | Wgt Acc: 97.044%
I - num batch: 364
I - Train -- Loss: 1.512 | Acc: 96.887% | Wgt Acc: 97.061% | LR: 1.250000e-04 | Dur: 226.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    4.    1.    4.   24.]
 [   1.  646.    3.    2.   20.]
 [   0.    4.  956.    1.   31.]
 [   5.    1.    1.  693.   21.]
 [  14.   13.   13.   18. 2667.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.941 | Acc: 49.250% | Wgt Acc: 42.496%
I - num batch: 87
I - Val -- Loss: 5.843 | Acc: 54.885% | Wgt Acc: 45.938% | Dur: 41.34s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   2.  18.  39.  16.]
 [  0.  70.  16.   1.   3.]
 [  2.  40. 104.   9.  19.]
 [ 19.  33.  18.  88.  21.]
 [ 48. 123. 134.  67. 372.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 1.476 | Acc: 97.625% | Wgt Acc: 97.832%
	I - Batch: 100 | Loss: 1.512 | Acc: 97.000% | Wgt Acc: 96.925%
	I - Batch: 150 | Loss: 1.513 | Acc: 97.125% | Wgt Acc: 97.027%
	I - Batch: 200 | Loss: 1.507 | Acc: 97.188% | Wgt Acc: 97.148%
	I - Batch: 250 | Loss: 1.520 | Acc: 96.900% | Wgt Acc: 96.837%
	I - Batch: 300 | Loss: 1.514 | Acc: 97.125% | Wgt Acc: 96.977%
	I - Batch: 350 | Loss: 1.508 | Acc: 97.232% | Wgt Acc: 97.085%
I - num batch: 364
I - Train -- Loss: 1.508 | Acc: 97.266% | Wgt Acc: 97.125% | LR: 1.250000e-04 | Dur: 225.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    4.    2.    8.   24.]
 [   1.  650.    0.    1.   10.]
 [   3.    3.  958.    2.   16.]
 [   4.    2.    2.  690.   13.]
 [  26.    9.   12.   17. 2700.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.892 | Acc: 52.000% | Wgt Acc: 46.275%
I - num batch: 87
I - Val -- Loss: 5.802 | Acc: 57.256% | Wgt Acc: 49.777% | Dur: 41.45s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   5.  18.  25.  31.]
 [  1.  85.  14.   2.   1.]
 [  1.  39. 118.  11.  20.]
 [ 22.  11.  12.  96.  21.]
 [ 35. 128. 128.  70. 358.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 1.430 | Acc: 98.750% | Wgt Acc: 98.631%
	I - Batch: 100 | Loss: 1.450 | Acc: 98.188% | Wgt Acc: 98.188%
	I - Batch: 150 | Loss: 1.460 | Acc: 98.042% | Wgt Acc: 97.954%
	I - Batch: 200 | Loss: 1.473 | Acc: 97.812% | Wgt Acc: 97.596%
	I - Batch: 250 | Loss: 1.479 | Acc: 97.700% | Wgt Acc: 97.513%
	I - Batch: 300 | Loss: 1.475 | Acc: 97.812% | Wgt Acc: 97.638%
	I - Batch: 350 | Loss: 1.472 | Acc: 97.804% | Wgt Acc: 97.706%
I - num batch: 364
I - Train -- Loss: 1.468 | Acc: 97.850% | Wgt Acc: 97.773% | LR: 1.250000e-04 | Dur: 225.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    2.    8.   17.]
 [   0.  652.    0.    2.    4.]
 [   3.    2.  964.    3.   15.]
 [   2.    3.    3.  692.   16.]
 [  16.    9.    5.   13. 2711.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.942 | Acc: 51.625% | Wgt Acc: 45.755%
I - num batch: 87
I - Val -- Loss: 5.827 | Acc: 58.046% | Wgt Acc: 50.099% | Dur: 41.37s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   2.  14.  30.  16.]
 [  0. 139.  27.   5.  10.]
 [  0.  15.  74.   7.   4.]
 [ 16.  15.  19.  87.  21.]
 [ 55.  97. 156.  75. 380.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 1.513 | Acc: 97.625% | Wgt Acc: 97.258%
	I - Batch: 100 | Loss: 1.491 | Acc: 97.750% | Wgt Acc: 97.537%
	I - Batch: 150 | Loss: 1.499 | Acc: 97.708% | Wgt Acc: 97.321%
	I - Batch: 200 | Loss: 1.480 | Acc: 97.844% | Wgt Acc: 97.601%
	I - Batch: 250 | Loss: 1.475 | Acc: 97.875% | Wgt Acc: 97.710%
	I - Batch: 300 | Loss: 1.468 | Acc: 97.896% | Wgt Acc: 97.802%
	I - Batch: 350 | Loss: 1.471 | Acc: 97.911% | Wgt Acc: 97.758%
I - num batch: 364
I - Train -- Loss: 1.469 | Acc: 97.936% | Wgt Acc: 97.785% | LR: 1.250000e-04 | Dur: 225.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    4.    0.    6.   18.]
 [   0.  650.    2.    2.    4.]
 [   2.    3.  962.    1.   15.]
 [   3.    1.    3.  691.    9.]
 [  12.   10.    7.   18. 2717.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.902 | Acc: 51.750% | Wgt Acc: 45.540%
I - num batch: 87
I - Val -- Loss: 5.801 | Acc: 57.184% | Wgt Acc: 49.549% | Dur: 41.79s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   2.   8.  20.   9.]
 [  0. 112.  20.   4.   8.]
 [  5.  36. 108.  12.  24.]
 [ 25.  13.  18.  94.  21.]
 [ 56. 105. 136.  74. 369.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 1.447 | Acc: 98.500% | Wgt Acc: 98.204%
	I - Batch: 100 | Loss: 1.451 | Acc: 98.188% | Wgt Acc: 98.070%
	I - Batch: 150 | Loss: 1.462 | Acc: 97.792% | Wgt Acc: 97.809%
	I - Batch: 200 | Loss: 1.462 | Acc: 97.500% | Wgt Acc: 97.646%
	I - Batch: 250 | Loss: 1.483 | Acc: 97.225% | Wgt Acc: 97.292%
	I - Batch: 300 | Loss: 1.489 | Acc: 97.167% | Wgt Acc: 97.199%
	I - Batch: 350 | Loss: 1.492 | Acc: 97.161% | Wgt Acc: 97.170%
I - num batch: 364
I - Train -- Loss: 1.492 | Acc: 97.163% | Wgt Acc: 97.151% | LR: 1.250000e-04 | Dur: 227.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    4.    2.   10.   22.]
 [   2.  654.    2.    3.   11.]
 [   0.    1.  958.    1.   21.]
 [   3.    0.    5.  681.   19.]
 [  20.    9.    7.   23. 2690.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.870 | Acc: 51.375% | Wgt Acc: 45.865%
I - num batch: 87
I - Val -- Loss: 5.793 | Acc: 56.466% | Wgt Acc: 49.754% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   7.  20.  30.  22.]
 [  1. 102.  19.   1.   7.]
 [  2.  41. 104.   8.  21.]
 [ 42.  29.  38. 120.  37.]
 [ 38.  89. 109.  45. 344.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 1.491 | Acc: 97.625% | Wgt Acc: 97.955%
	I - Batch: 100 | Loss: 1.492 | Acc: 97.250% | Wgt Acc: 97.464%
	I - Batch: 150 | Loss: 1.494 | Acc: 97.083% | Wgt Acc: 97.203%
	I - Batch: 200 | Loss: 1.495 | Acc: 97.188% | Wgt Acc: 97.214%
	I - Batch: 250 | Loss: 1.509 | Acc: 97.050% | Wgt Acc: 97.035%
	I - Batch: 300 | Loss: 1.495 | Acc: 97.292% | Wgt Acc: 97.262%
	I - Batch: 350 | Loss: 1.486 | Acc: 97.393% | Wgt Acc: 97.389%
I - num batch: 364
I - Train -- Loss: 1.483 | Acc: 97.438% | Wgt Acc: 97.440% | LR: 1.250000e-04 | Dur: 227.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    3.    2.    3.   20.]
 [   1.  650.    1.    1.   12.]
 [   1.    3.  959.    3.   16.]
 [   3.    1.    1.  693.   21.]
 [  17.   11.   11.   18. 2694.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.831 | Acc: 53.375% | Wgt Acc: 48.217%
I - num batch: 87
I - Val -- Loss: 5.751 | Acc: 57.830% | Wgt Acc: 51.484% | Dur: 41.77s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   0.  20.  33.  18.]
 [  1. 120.  23.   3.  10.]
 [  4.  41. 116.   9.  33.]
 [ 22.  18.  18.  96.  20.]
 [ 49.  89. 113.  63. 350.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 1.443 | Acc: 97.500% | Wgt Acc: 97.935%
	I - Batch: 100 | Loss: 1.436 | Acc: 98.000% | Wgt Acc: 98.072%
	I - Batch: 150 | Loss: 1.459 | Acc: 97.667% | Wgt Acc: 97.704%
	I - Batch: 200 | Loss: 1.459 | Acc: 97.750% | Wgt Acc: 97.848%
	I - Batch: 250 | Loss: 1.462 | Acc: 97.700% | Wgt Acc: 97.787%
	I - Batch: 300 | Loss: 1.459 | Acc: 97.792% | Wgt Acc: 97.883%
	I - Batch: 350 | Loss: 1.462 | Acc: 97.732% | Wgt Acc: 97.822%
I - num batch: 364
I - Train -- Loss: 1.461 | Acc: 97.747% | Wgt Acc: 97.828% | LR: 1.250000e-04 | Dur: 227.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    3.    2.    4.   24.]
 [   1.  658.    2.    2.    9.]
 [   1.    3.  961.    1.   19.]
 [   2.    1.    5.  692.   12.]
 [  14.    3.    4.   19. 2699.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.795 | Acc: 52.500% | Wgt Acc: 47.838%
I - num batch: 87
I - Val -- Loss: 5.737 | Acc: 57.615% | Wgt Acc: 51.550% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   6.  19.  29.  30.]
 [  0. 123.  22.   7.  12.]
 [  1.  35. 103.  10.  22.]
 [ 23.  13.  20. 101.  25.]
 [ 42.  91. 126.  57. 342.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 98.500% | Wgt Acc: 98.121%
	I - Batch: 100 | Loss: 1.459 | Acc: 98.000% | Wgt Acc: 97.812%
	I - Batch: 150 | Loss: 1.473 | Acc: 97.667% | Wgt Acc: 97.513%
	I - Batch: 200 | Loss: 1.483 | Acc: 97.469% | Wgt Acc: 97.355%
	I - Batch: 250 | Loss: 1.464 | Acc: 97.750% | Wgt Acc: 97.702%
	I - Batch: 300 | Loss: 1.469 | Acc: 97.667% | Wgt Acc: 97.613%
	I - Batch: 350 | Loss: 1.458 | Acc: 97.804% | Wgt Acc: 97.806%
I - num batch: 364
I - Train -- Loss: 1.458 | Acc: 97.816% | Wgt Acc: 97.816% | LR: 1.250000e-04 | Dur: 227.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    4.    2.    4.   17.]
 [   0.  652.    1.    1.    8.]
 [   1.    3.  961.    1.   16.]
 [   2.    0.    4.  693.   18.]
 [  11.    9.    6.   19. 2704.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.848 | Acc: 52.375% | Wgt Acc: 46.729%
I - num batch: 87
I - Val -- Loss: 5.778 | Acc: 57.543% | Wgt Acc: 50.625% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   7.  22.  44.  26.]
 [  0. 110.  19.   5.   5.]
 [  4.  37. 104.  10.  14.]
 [ 17.  21.  31.  88.  32.]
 [ 33.  93. 114.  57. 354.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 98.625% | Wgt Acc: 98.552%
	I - Batch: 100 | Loss: 1.444 | Acc: 98.312% | Wgt Acc: 98.299%
	I - Batch: 150 | Loss: 1.443 | Acc: 98.333% | Wgt Acc: 98.257%
	I - Batch: 200 | Loss: 1.437 | Acc: 98.375% | Wgt Acc: 98.350%
	I - Batch: 250 | Loss: 1.441 | Acc: 98.325% | Wgt Acc: 98.238%
	I - Batch: 300 | Loss: 1.437 | Acc: 98.354% | Wgt Acc: 98.263%
	I - Batch: 350 | Loss: 1.440 | Acc: 98.375% | Wgt Acc: 98.254%
I - num batch: 364
I - Train -- Loss: 1.441 | Acc: 98.349% | Wgt Acc: 98.223% | LR: 1.250000e-04 | Dur: 227.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    3.    1.    5.   10.]
 [   2.  655.    0.    1.    3.]
 [   1.    5.  964.    1.   13.]
 [   2.    0.    2.  699.   10.]
 [  13.    5.    7.   12. 2727.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.839 | Acc: 52.125% | Wgt Acc: 46.900%
I - num batch: 87
I - Val -- Loss: 5.767 | Acc: 58.333% | Wgt Acc: 51.527% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   4.  14.  16.  12.]
 [  0. 137.  27.   4.  14.]
 [  5.  22. 103.   5.  14.]
 [ 36.  18.  21. 111.  27.]
 [ 61.  87. 125.  68. 364.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 1.424 | Acc: 98.375% | Wgt Acc: 98.188%
	I - Batch: 100 | Loss: 1.415 | Acc: 98.688% | Wgt Acc: 98.559%
	I - Batch: 150 | Loss: 1.415 | Acc: 98.542% | Wgt Acc: 98.465%
	I - Batch: 200 | Loss: 1.428 | Acc: 98.438% | Wgt Acc: 98.339%
	I - Batch: 250 | Loss: 1.439 | Acc: 98.350% | Wgt Acc: 98.167%
	I - Batch: 300 | Loss: 1.446 | Acc: 98.167% | Wgt Acc: 98.027%
	I - Batch: 350 | Loss: 1.458 | Acc: 97.946% | Wgt Acc: 97.850%
I - num batch: 364
I - Train -- Loss: 1.460 | Acc: 97.850% | Wgt Acc: 97.775% | LR: 1.250000e-04 | Dur: 227.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    4.    2.    6.   12.]
 [   1.  651.    1.    2.   14.]
 [   5.    2.  962.    1.   18.]
 [   3.    1.    3.  697.    9.]
 [  13.   10.    6.   12. 2710.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.844 | Acc: 54.625% | Wgt Acc: 49.975%
I - num batch: 87
I - Val -- Loss: 5.784 | Acc: 58.477% | Wgt Acc: 52.405% | Dur: 41.79s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   8.  17.  41.  24.]
 [  1. 119.  30.   4.   9.]
 [  3.  27. 108.   7.  27.]
 [ 23.  17.  27. 101.  27.]
 [ 30.  97. 108.  51. 344.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 1.479 | Acc: 96.875% | Wgt Acc: 96.971%
	I - Batch: 100 | Loss: 1.493 | Acc: 97.062% | Wgt Acc: 97.206%
	I - Batch: 150 | Loss: 1.491 | Acc: 97.000% | Wgt Acc: 97.238%
	I - Batch: 200 | Loss: 1.492 | Acc: 96.969% | Wgt Acc: 97.311%
	I - Batch: 250 | Loss: 1.502 | Acc: 97.025% | Wgt Acc: 97.220%
	I - Batch: 300 | Loss: 1.514 | Acc: 96.750% | Wgt Acc: 96.890%
	I - Batch: 350 | Loss: 1.523 | Acc: 96.571% | Wgt Acc: 96.754%
I - num batch: 364
I - Train -- Loss: 1.524 | Acc: 96.578% | Wgt Acc: 96.784% | LR: 1.250000e-04 | Dur: 227.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    2.    2.    7.   23.]
 [   4.  647.    3.    4.   21.]
 [   1.    4.  956.    2.   23.]
 [   5.    4.    3.  689.   38.]
 [  16.   11.   10.   16. 2658.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.925 | Acc: 51.750% | Wgt Acc: 45.773%
I - num batch: 87
I - Val -- Loss: 5.820 | Acc: 58.333% | Wgt Acc: 50.134% | Dur: 42.04s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   3.   8.  21.  11.]
 [  2. 120.  23.   6.   7.]
 [  2.  29. 111.   7.  14.]
 [ 26.   8.  12.  88.  12.]
 [ 63. 108. 136.  82. 387.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 1.545 | Acc: 95.875% | Wgt Acc: 96.190%
	I - Batch: 100 | Loss: 1.537 | Acc: 96.062% | Wgt Acc: 96.239%
	I - Batch: 150 | Loss: 1.572 | Acc: 95.375% | Wgt Acc: 95.551%
	I - Batch: 200 | Loss: 1.575 | Acc: 95.375% | Wgt Acc: 95.582%
	I - Batch: 250 | Loss: 1.554 | Acc: 95.900% | Wgt Acc: 96.103%
	I - Batch: 300 | Loss: 1.541 | Acc: 96.229% | Wgt Acc: 96.413%
	I - Batch: 350 | Loss: 1.538 | Acc: 96.321% | Wgt Acc: 96.504%
I - num batch: 364
I - Train -- Loss: 1.532 | Acc: 96.406% | Wgt Acc: 96.607% | LR: 1.250000e-04 | Dur: 228.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    2.    2.    7.   36.]
 [   3.  647.    4.    1.   22.]
 [   1.    5.  954.    3.   26.]
 [   4.    0.    3.  685.   25.]
 [  18.   14.   11.   22. 2654.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.910 | Acc: 52.000% | Wgt Acc: 46.190%
I - num batch: 87
I - Val -- Loss: 5.823 | Acc: 57.328% | Wgt Acc: 50.017% | Dur: 42.27s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   6.  23.  42.  29.]
 [  0.  95.  22.   4.   3.]
 [  1.  40. 102.   5.  18.]
 [ 21.  27.  27. 107.  26.]
 [ 38. 100. 116.  46. 355.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 1.454 | Acc: 98.375% | Wgt Acc: 98.331%
	I - Batch: 100 | Loss: 1.479 | Acc: 97.938% | Wgt Acc: 97.794%
	I - Batch: 150 | Loss: 1.482 | Acc: 97.833% | Wgt Acc: 97.774%
	I - Batch: 200 | Loss: 1.483 | Acc: 97.844% | Wgt Acc: 97.680%
	I - Batch: 250 | Loss: 1.476 | Acc: 97.900% | Wgt Acc: 97.769%
	I - Batch: 300 | Loss: 1.467 | Acc: 97.958% | Wgt Acc: 97.866%
	I - Batch: 350 | Loss: 1.465 | Acc: 98.036% | Wgt Acc: 97.926%
I - num batch: 364
I - Train -- Loss: 1.464 | Acc: 98.005% | Wgt Acc: 97.911% | LR: 1.250000e-04 | Dur: 229.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    3.    2.    3.   13.]
 [   2.  654.    1.    0.   11.]
 [   1.    2.  962.    3.   14.]
 [   1.    1.    2.  695.    9.]
 [  16.    8.    7.   17. 2716.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.851 | Acc: 51.500% | Wgt Acc: 45.975%
I - num batch: 87
I - Val -- Loss: 5.764 | Acc: 57.830% | Wgt Acc: 50.164% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   4.  12.  12.  16.]
 [  0. 140.  38.   3.  15.]
 [  2.  23.  86.   9.  11.]
 [ 41.  16.  16. 101.  12.]
 [ 55.  85. 138.  79. 377.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 1.405 | Acc: 98.625% | Wgt Acc: 98.797%
	I - Batch: 100 | Loss: 1.457 | Acc: 97.750% | Wgt Acc: 97.738%
	I - Batch: 150 | Loss: 1.463 | Acc: 97.750% | Wgt Acc: 97.706%
	I - Batch: 200 | Loss: 1.474 | Acc: 97.531% | Wgt Acc: 97.456%
	I - Batch: 250 | Loss: 1.475 | Acc: 97.575% | Wgt Acc: 97.513%
	I - Batch: 300 | Loss: 1.482 | Acc: 97.417% | Wgt Acc: 97.373%
	I - Batch: 350 | Loss: 1.479 | Acc: 97.321% | Wgt Acc: 97.358%
I - num batch: 364
I - Train -- Loss: 1.476 | Acc: 97.386% | Wgt Acc: 97.438% | LR: 1.250000e-04 | Dur: 229.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    2.    0.    6.   20.]
 [   1.  657.    1.    2.    9.]
 [   1.    3.  959.    1.   18.]
 [   6.    2.    4.  685.   24.]
 [  14.    4.   10.   24. 2692.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.939 | Acc: 48.375% | Wgt Acc: 42.067%
I - num batch: 87
I - Val -- Loss: 5.830 | Acc: 54.670% | Wgt Acc: 46.716% | Dur: 42.18s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   5.  17.  35.  23.]
 [  0.  96.  26.   4.   4.]
 [  6.  36.  75.   7.  10.]
 [ 24.  28.  40. 113.  39.]
 [ 47. 103. 132.  45. 355.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 1.534 | Acc: 96.250% | Wgt Acc: 96.050%
	I - Batch: 100 | Loss: 1.498 | Acc: 97.125% | Wgt Acc: 97.048%
	I - Batch: 150 | Loss: 1.486 | Acc: 97.417% | Wgt Acc: 97.359%
	I - Batch: 200 | Loss: 1.476 | Acc: 97.594% | Wgt Acc: 97.597%
	I - Batch: 250 | Loss: 1.473 | Acc: 97.675% | Wgt Acc: 97.700%
	I - Batch: 300 | Loss: 1.474 | Acc: 97.688% | Wgt Acc: 97.704%
	I - Batch: 350 | Loss: 1.472 | Acc: 97.679% | Wgt Acc: 97.719%
I - num batch: 364
I - Train -- Loss: 1.479 | Acc: 97.592% | Wgt Acc: 97.576% | LR: 1.250000e-04 | Dur: 229.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    2.    1.    6.   22.]
 [   1.  653.    1.    3.    5.]
 [   1.    3.  959.    2.   19.]
 [   3.    0.    2.  691.   17.]
 [  15.   10.   11.   16. 2700.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.800 | Acc: 51.250% | Wgt Acc: 46.735%
I - num batch: 87
I - Val -- Loss: 5.732 | Acc: 56.322% | Wgt Acc: 49.998% | Dur: 42.06s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   1.   8.  14.   6.]
 [  2. 101.  22.  12.  12.]
 [  8.  72. 145.  19.  54.]
 [ 30.   9.  15.  91.  14.]
 [ 57.  85. 100.  68. 345.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 1.455 | Acc: 98.000% | Wgt Acc: 98.181%
	I - Batch: 100 | Loss: 1.434 | Acc: 98.000% | Wgt Acc: 98.323%
	I - Batch: 150 | Loss: 1.454 | Acc: 97.792% | Wgt Acc: 97.999%
	I - Batch: 200 | Loss: 1.465 | Acc: 97.594% | Wgt Acc: 97.765%
	I - Batch: 250 | Loss: 1.466 | Acc: 97.550% | Wgt Acc: 97.710%
	I - Batch: 300 | Loss: 1.463 | Acc: 97.604% | Wgt Acc: 97.710%
	I - Batch: 350 | Loss: 1.465 | Acc: 97.607% | Wgt Acc: 97.707%
I - num batch: 364
I - Train -- Loss: 1.467 | Acc: 97.592% | Wgt Acc: 97.680% | LR: 1.250000e-04 | Dur: 228.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    3.    3.    4.   13.]
 [   0.  654.    1.    1.   12.]
 [   0.    3.  959.    1.   27.]
 [   4.    0.    4.  696.   18.]
 [  15.    8.    7.   16. 2693.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.758 | Acc: 55.125% | Wgt Acc: 51.048%
I - num batch: 87
I - Val -- Loss: 5.716 | Acc: 58.333% | Wgt Acc: 53.876% | Dur: 42.11s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   6.  19.  29.  27.]
 [  0. 111.  21.   1.   6.]
 [  5.  58. 132.  11.  42.]
 [ 38.  28.  33. 125.  42.]
 [ 26.  65.  85.  38. 314.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 1.424 | Acc: 98.375% | Wgt Acc: 98.560%
	I - Batch: 100 | Loss: 1.436 | Acc: 98.188% | Wgt Acc: 98.252%
	I - Batch: 150 | Loss: 1.424 | Acc: 98.542% | Wgt Acc: 98.523%
	I - Batch: 200 | Loss: 1.434 | Acc: 98.312% | Wgt Acc: 98.388%
	I - Batch: 250 | Loss: 1.450 | Acc: 98.125% | Wgt Acc: 98.152%
	I - Batch: 300 | Loss: 1.456 | Acc: 98.083% | Wgt Acc: 98.012%
	I - Batch: 350 | Loss: 1.455 | Acc: 98.089% | Wgt Acc: 98.003%
I - num batch: 364
I - Train -- Loss: 1.456 | Acc: 98.091% | Wgt Acc: 97.996% | LR: 1.250000e-04 | Dur: 228.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    2.    4.    4.   13.]
 [   2.  655.    2.    0.   12.]
 [   1.    3.  960.    2.   13.]
 [   0.    0.    3.  702.    7.]
 [  20.    8.    5.   10. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.803 | Acc: 52.625% | Wgt Acc: 47.880%
I - num batch: 87
I - Val -- Loss: 5.748 | Acc: 57.759% | Wgt Acc: 51.078% | Dur: 42.07s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   2.  14.  21.  17.]
 [  1. 134.  39.   5.  11.]
 [  4.  17.  95.   8.  20.]
 [ 31.  18.  19. 102.  26.]
 [ 47.  97. 123.  68. 357.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 1.466 | Acc: 97.125% | Wgt Acc: 97.705%
	I - Batch: 100 | Loss: 1.472 | Acc: 97.188% | Wgt Acc: 97.723%
	I - Batch: 150 | Loss: 1.449 | Acc: 97.833% | Wgt Acc: 98.205%
	I - Batch: 200 | Loss: 1.449 | Acc: 97.969% | Wgt Acc: 98.164%
	I - Batch: 250 | Loss: 1.444 | Acc: 98.125% | Wgt Acc: 98.234%
	I - Batch: 300 | Loss: 1.446 | Acc: 98.083% | Wgt Acc: 98.159%
	I - Batch: 350 | Loss: 1.446 | Acc: 98.143% | Wgt Acc: 98.181%
I - num batch: 364
I - Train -- Loss: 1.449 | Acc: 98.074% | Wgt Acc: 98.146% | LR: 1.250000e-04 | Dur: 228.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    2.    1.    3.   18.]
 [   0.  656.    3.    0.    9.]
 [   1.    2.  964.    1.    5.]
 [   6.    1.    1.  699.   24.]
 [   8.    7.    5.   15. 2707.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.817 | Acc: 50.875% | Wgt Acc: 44.983%
I - num batch: 87
I - Val -- Loss: 5.772 | Acc: 56.753% | Wgt Acc: 48.802% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   3.  14.  27.   8.]
 [  0.  94.  17.   1.   6.]
 [  5.  64. 133.  20.  25.]
 [ 14.  13.   9.  75.  19.]
 [ 65.  94. 117.  81. 373.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 1.524 | Acc: 97.250% | Wgt Acc: 97.184%
	I - Batch: 100 | Loss: 1.487 | Acc: 97.812% | Wgt Acc: 97.664%
	I - Batch: 150 | Loss: 1.481 | Acc: 97.917% | Wgt Acc: 97.708%
	I - Batch: 200 | Loss: 1.482 | Acc: 97.875% | Wgt Acc: 97.653%
	I - Batch: 250 | Loss: 1.477 | Acc: 97.925% | Wgt Acc: 97.715%
	I - Batch: 300 | Loss: 1.470 | Acc: 98.000% | Wgt Acc: 97.835%
	I - Batch: 350 | Loss: 1.464 | Acc: 98.018% | Wgt Acc: 97.932%
I - num batch: 364
I - Train -- Loss: 1.465 | Acc: 97.988% | Wgt Acc: 97.905% | LR: 1.250000e-04 | Dur: 228.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    2.    4.   12.]
 [   1.  655.    2.    1.   10.]
 [   1.    3.  961.    1.   17.]
 [   2.    0.    3.  696.    9.]
 [  17.    8.    6.   16. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.924 | Acc: 52.750% | Wgt Acc: 46.410%
I - num batch: 87
I - Val -- Loss: 5.825 | Acc: 57.256% | Wgt Acc: 49.085% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   2.  17.  24.  13.]
 [  1.  98.  19.   1.   7.]
 [  5.  33. 106.   7.  18.]
 [ 25.  18.  18. 101.  19.]
 [ 50. 117. 130.  71. 374.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 1.443 | Acc: 98.000% | Wgt Acc: 98.133%
	I - Batch: 100 | Loss: 1.479 | Acc: 97.500% | Wgt Acc: 97.513%
	I - Batch: 150 | Loss: 1.482 | Acc: 97.333% | Wgt Acc: 97.307%
	I - Batch: 200 | Loss: 1.504 | Acc: 96.812% | Wgt Acc: 96.920%
	I - Batch: 250 | Loss: 1.492 | Acc: 97.075% | Wgt Acc: 97.240%
	I - Batch: 300 | Loss: 1.491 | Acc: 97.167% | Wgt Acc: 97.324%
	I - Batch: 350 | Loss: 1.484 | Acc: 97.214% | Wgt Acc: 97.379%
I - num batch: 364
I - Train -- Loss: 1.486 | Acc: 97.214% | Wgt Acc: 97.363% | LR: 1.250000e-04 | Dur: 228.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    3.    6.    4.   24.]
 [   2.  645.    4.    3.   26.]
 [   1.    5.  961.    2.   19.]
 [   0.    4.    0.  695.   17.]
 [  14.   11.    3.   14. 2677.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.840 | Acc: 53.875% | Wgt Acc: 48.530%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 58.549% | Wgt Acc: 51.422% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   2.  14.  20.  12.]
 [  0. 106.  17.   7.   4.]
 [  3.  65. 129.  13.  36.]
 [ 30.  13.  15. 104.  14.]
 [ 55.  82. 115.  60. 365.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 1.481 | Acc: 97.750% | Wgt Acc: 97.593%
	I - Batch: 100 | Loss: 1.477 | Acc: 97.688% | Wgt Acc: 97.681%
	I - Batch: 150 | Loss: 1.452 | Acc: 98.083% | Wgt Acc: 98.093%
	I - Batch: 200 | Loss: 1.457 | Acc: 98.062% | Wgt Acc: 97.931%
	I - Batch: 250 | Loss: 1.458 | Acc: 98.000% | Wgt Acc: 97.881%
	I - Batch: 300 | Loss: 1.457 | Acc: 97.958% | Wgt Acc: 97.844%
	I - Batch: 350 | Loss: 1.454 | Acc: 98.071% | Wgt Acc: 97.949%
I - num batch: 364
I - Train -- Loss: 1.454 | Acc: 98.057% | Wgt Acc: 97.941% | LR: 1.250000e-04 | Dur: 229.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    1.    6.    9.]
 [   2.  654.    2.    0.   14.]
 [   1.    3.  963.    2.   10.]
 [   4.    0.    2.  695.   11.]
 [  14.    9.    6.   15. 2719.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.878 | Acc: 53.875% | Wgt Acc: 48.070%
I - num batch: 87
I - Val -- Loss: 5.799 | Acc: 58.190% | Wgt Acc: 50.946% | Dur: 42.35s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   5.  20.  22.  20.]
 [  0. 100.  15.   4.   3.]
 [  2.  38. 107.   7.  20.]
 [ 33.  24.  23. 117.  29.]
 [ 37. 101. 125.  54. 359.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 1.450 | Acc: 98.250% | Wgt Acc: 98.104%
	I - Batch: 100 | Loss: 1.474 | Acc: 97.688% | Wgt Acc: 97.719%
	I - Batch: 150 | Loss: 1.458 | Acc: 97.875% | Wgt Acc: 97.884%
	I - Batch: 200 | Loss: 1.449 | Acc: 98.062% | Wgt Acc: 98.050%
	I - Batch: 250 | Loss: 1.450 | Acc: 98.000% | Wgt Acc: 98.010%
	I - Batch: 300 | Loss: 1.454 | Acc: 97.979% | Wgt Acc: 97.944%
	I - Batch: 350 | Loss: 1.454 | Acc: 98.036% | Wgt Acc: 97.938%
I - num batch: 364
I - Train -- Loss: 1.455 | Acc: 98.005% | Wgt Acc: 97.949% | LR: 1.250000e-04 | Dur: 229.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    4.    2.   14.]
 [   1.  655.    0.    1.    7.]
 [   1.    5.  959.    3.   24.]
 [   3.    0.    2.  696.    5.]
 [  11.    6.    9.   16. 2713.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.934 | Acc: 50.125% | Wgt Acc: 44.419%
I - num batch: 87
I - Val -- Loss: 5.828 | Acc: 56.897% | Wgt Acc: 48.740% | Dur: 42.29s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   2.  15.  18.  10.]
 [  2. 130.  30.   8.  14.]
 [  4.  22.  84.   9.  11.]
 [ 15.  13.   8.  87.  16.]
 [ 67. 101. 153.  82. 380.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 1.460 | Acc: 98.250% | Wgt Acc: 98.216%
	I - Batch: 100 | Loss: 1.433 | Acc: 98.250% | Wgt Acc: 98.389%
	I - Batch: 150 | Loss: 1.418 | Acc: 98.417% | Wgt Acc: 98.637%
	I - Batch: 200 | Loss: 1.417 | Acc: 98.438% | Wgt Acc: 98.619%
	I - Batch: 250 | Loss: 1.418 | Acc: 98.500% | Wgt Acc: 98.586%
	I - Batch: 300 | Loss: 1.427 | Acc: 98.354% | Wgt Acc: 98.438%
	I - Batch: 350 | Loss: 1.436 | Acc: 98.232% | Wgt Acc: 98.272%
I - num batch: 364
I - Train -- Loss: 1.433 | Acc: 98.246% | Wgt Acc: 98.311% | LR: 1.250000e-04 | Dur: 229.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    2.    4.   18.]
 [   1.  660.    2.    0.    6.]
 [   1.    3.  964.    1.   13.]
 [   1.    0.    0.  700.   13.]
 [  13.    3.    6.   13. 2713.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.880 | Acc: 53.250% | Wgt Acc: 47.629%
I - num batch: 87
I - Val -- Loss: 5.800 | Acc: 58.693% | Wgt Acc: 51.740% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   3.  13.  22.  13.]
 [  2. 137.  33.  10.  19.]
 [  6.  21.  95.   7.   9.]
 [ 28.  15.  20. 111.  24.]
 [ 55.  92. 129.  54. 366.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 1.417 | Acc: 98.500% | Wgt Acc: 98.350%
	I - Batch: 100 | Loss: 1.446 | Acc: 98.188% | Wgt Acc: 98.107%
	I - Batch: 150 | Loss: 1.450 | Acc: 98.292% | Wgt Acc: 98.115%
	I - Batch: 200 | Loss: 1.452 | Acc: 98.219% | Wgt Acc: 98.054%
	I - Batch: 250 | Loss: 1.449 | Acc: 98.200% | Wgt Acc: 98.045%
	I - Batch: 300 | Loss: 1.442 | Acc: 98.271% | Wgt Acc: 98.176%
	I - Batch: 350 | Loss: 1.436 | Acc: 98.393% | Wgt Acc: 98.284%
I - num batch: 364
I - Train -- Loss: 1.439 | Acc: 98.332% | Wgt Acc: 98.229% | LR: 1.250000e-04 | Dur: 231.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    2.    0.    5.   15.]
 [   2.  657.    1.    3.    6.]
 [   0.    4.  961.    2.    8.]
 [   1.    1.    4.  698.    9.]
 [  12.    4.    8.   10. 2725.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.817 | Acc: 54.000% | Wgt Acc: 49.553%
I - num batch: 87
I - Val -- Loss: 5.762 | Acc: 57.328% | Wgt Acc: 51.829% | Dur: 42.65s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   6.  24.  26.  21.]
 [  0. 103.  19.   2.   9.]
 [  2.  43. 106.   8.  31.]
 [ 35.  37.  35. 132.  47.]
 [ 28.  79. 106.  36. 323.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 1.422 | Acc: 98.500% | Wgt Acc: 98.286%
	I - Batch: 100 | Loss: 1.442 | Acc: 98.062% | Wgt Acc: 97.938%
	I - Batch: 150 | Loss: 1.436 | Acc: 98.250% | Wgt Acc: 98.106%
	I - Batch: 200 | Loss: 1.440 | Acc: 98.062% | Wgt Acc: 97.984%
	I - Batch: 250 | Loss: 1.443 | Acc: 98.050% | Wgt Acc: 97.982%
	I - Batch: 300 | Loss: 1.447 | Acc: 98.000% | Wgt Acc: 97.992%
	I - Batch: 350 | Loss: 1.451 | Acc: 98.000% | Wgt Acc: 97.966%
I - num batch: 364
I - Train -- Loss: 1.452 | Acc: 97.971% | Wgt Acc: 97.962% | LR: 1.250000e-04 | Dur: 230.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    3.    0.    6.   13.]
 [   4.  658.    0.    0.    5.]
 [   1.    3.  959.    2.   23.]
 [   4.    0.    2.  696.   12.]
 [   9.    4.   13.   14. 2710.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.867 | Acc: 53.625% | Wgt Acc: 48.217%
I - num batch: 87
I - Val -- Loss: 5.787 | Acc: 58.046% | Wgt Acc: 51.391% | Dur: 42.66s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   5.  18.  25.  17.]
 [  0. 121.  28.   4.  10.]
 [  2.  19.  94.   6.  13.]
 [ 37.  21.  26. 117.  39.]
 [ 36. 102. 124.  52. 352.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 98.500% | Wgt Acc: 98.285%
	I - Batch: 100 | Loss: 1.430 | Acc: 98.562% | Wgt Acc: 98.355%
	I - Batch: 150 | Loss: 1.414 | Acc: 98.833% | Wgt Acc: 98.698%
	I - Batch: 200 | Loss: 1.409 | Acc: 98.812% | Wgt Acc: 98.724%
	I - Batch: 250 | Loss: 1.420 | Acc: 98.625% | Wgt Acc: 98.467%
	I - Batch: 300 | Loss: 1.424 | Acc: 98.604% | Wgt Acc: 98.428%
	I - Batch: 350 | Loss: 1.431 | Acc: 98.500% | Wgt Acc: 98.287%
I - num batch: 364
I - Train -- Loss: 1.431 | Acc: 98.504% | Wgt Acc: 98.307% | LR: 1.250000e-04 | Dur: 230.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    0.    3.   12.]
 [   1.  653.    3.    0.    4.]
 [   3.    5.  965.    1.    8.]
 [   0.    1.    3.  699.    4.]
 [  12.    7.    3.   15. 2735.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.857 | Acc: 50.125% | Wgt Acc: 44.554%
I - num batch: 87
I - Val -- Loss: 5.776 | Acc: 55.963% | Wgt Acc: 48.833% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   0.  14.  19.  11.]
 [  0.  98.  14.   4.   6.]
 [  4.  49. 128.  10.  39.]
 [ 18.  14.  18.  90.  20.]
 [ 69. 107. 116.  81. 355.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 1.417 | Acc: 98.875% | Wgt Acc: 98.770%
	I - Batch: 100 | Loss: 1.445 | Acc: 98.250% | Wgt Acc: 98.117%
	I - Batch: 150 | Loss: 1.439 | Acc: 98.417% | Wgt Acc: 98.249%
	I - Batch: 200 | Loss: 1.432 | Acc: 98.500% | Wgt Acc: 98.394%
	I - Batch: 250 | Loss: 1.435 | Acc: 98.400% | Wgt Acc: 98.277%
	I - Batch: 300 | Loss: 1.443 | Acc: 98.271% | Wgt Acc: 98.093%
	I - Batch: 350 | Loss: 1.443 | Acc: 98.250% | Wgt Acc: 98.126%
I - num batch: 364
I - Train -- Loss: 1.446 | Acc: 98.229% | Wgt Acc: 98.120% | LR: 1.250000e-04 | Dur: 230.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    2.    2.    6.   12.]
 [   3.  655.    0.    0.    9.]
 [   2.    2.  964.    3.    9.]
 [   1.    0.    2.  696.   10.]
 [  12.    9.    6.   13. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.919 | Acc: 49.875% | Wgt Acc: 43.200%
I - num batch: 87
I - Val -- Loss: 5.825 | Acc: 55.460% | Wgt Acc: 46.786% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   0.  12.   8.   8.]
 [  1.  92.  19.   2.   6.]
 [  2.  24. 106.   6.  20.]
 [ 30.  18.  16.  99.  20.]
 [ 68. 134. 137.  89. 377.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 1.553 | Acc: 96.250% | Wgt Acc: 96.330%
	I - Batch: 100 | Loss: 1.521 | Acc: 96.750% | Wgt Acc: 96.949%
	I - Batch: 150 | Loss: 1.521 | Acc: 96.875% | Wgt Acc: 96.957%
	I - Batch: 200 | Loss: 1.520 | Acc: 96.938% | Wgt Acc: 96.978%
	I - Batch: 250 | Loss: 1.507 | Acc: 97.100% | Wgt Acc: 97.219%
	I - Batch: 300 | Loss: 1.498 | Acc: 97.229% | Wgt Acc: 97.344%
	I - Batch: 350 | Loss: 1.491 | Acc: 97.286% | Wgt Acc: 97.383%
I - num batch: 364
I - Train -- Loss: 1.495 | Acc: 97.283% | Wgt Acc: 97.329% | LR: 1.250000e-04 | Dur: 230.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    3.    3.    7.   16.]
 [   2.  650.    3.    0.   19.]
 [   2.    6.  953.    0.   22.]
 [   3.    1.    3.  697.   20.]
 [  14.    8.   12.   14. 2686.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.773 | Acc: 54.750% | Wgt Acc: 50.901%
I - num batch: 87
I - Val -- Loss: 5.744 | Acc: 58.046% | Wgt Acc: 53.477% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[143.  12.  22.  40.  33.]
 [  0. 122.  35.   2.  15.]
 [  2.  45. 116.  11.  32.]
 [ 27.  19.  35. 111.  35.]
 [ 27.  70.  82.  40. 316.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 1.481 | Acc: 97.250% | Wgt Acc: 97.299%
	I - Batch: 100 | Loss: 1.479 | Acc: 97.500% | Wgt Acc: 97.557%
	I - Batch: 150 | Loss: 1.457 | Acc: 97.917% | Wgt Acc: 97.968%
	I - Batch: 200 | Loss: 1.445 | Acc: 98.031% | Wgt Acc: 98.111%
	I - Batch: 250 | Loss: 1.447 | Acc: 98.000% | Wgt Acc: 98.000%
	I - Batch: 300 | Loss: 1.445 | Acc: 98.021% | Wgt Acc: 98.065%
	I - Batch: 350 | Loss: 1.452 | Acc: 98.036% | Wgt Acc: 97.984%
I - num batch: 364
I - Train -- Loss: 1.450 | Acc: 98.057% | Wgt Acc: 97.999% | LR: 1.250000e-04 | Dur: 230.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    3.    3.    7.   15.]
 [   1.  655.    0.    0.   13.]
 [   0.    2.  962.    2.    8.]
 [   1.    1.    2.  694.   12.]
 [  14.    7.    7.   15. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.891 | Acc: 51.250% | Wgt Acc: 45.375%
I - num batch: 87
I - Val -- Loss: 5.802 | Acc: 57.040% | Wgt Acc: 49.305% | Dur: 42.65s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.  18.  36.  14.]
 [  0. 114.  24.   9.   4.]
 [  2.  23.  89.   6.   6.]
 [ 32.  30.  26. 103.  40.]
 [ 44.  99. 133.  50. 367.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 1.430 | Acc: 98.750% | Wgt Acc: 98.496%
	I - Batch: 100 | Loss: 1.419 | Acc: 99.000% | Wgt Acc: 98.714%
	I - Batch: 150 | Loss: 1.420 | Acc: 98.958% | Wgt Acc: 98.703%
	I - Batch: 200 | Loss: 1.418 | Acc: 98.906% | Wgt Acc: 98.682%
	I - Batch: 250 | Loss: 1.429 | Acc: 98.650% | Wgt Acc: 98.458%
	I - Batch: 300 | Loss: 1.433 | Acc: 98.604% | Wgt Acc: 98.395%
	I - Batch: 350 | Loss: 1.436 | Acc: 98.446% | Wgt Acc: 98.320%
I - num batch: 364
I - Train -- Loss: 1.441 | Acc: 98.315% | Wgt Acc: 98.229% | LR: 1.250000e-04 | Dur: 230.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    3.    4.    2.    7.]
 [   1.  656.    0.    2.    7.]
 [   1.    3.  961.    0.   18.]
 [   2.    0.    2.  704.    8.]
 [  15.    6.    7.   10. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.791 | Acc: 53.375% | Wgt Acc: 48.542%
I - num batch: 87
I - Val -- Loss: 5.746 | Acc: 57.399% | Wgt Acc: 51.774% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[155.  16.  29.  57.  51.]
 [  1. 111.  29.   8.   6.]
 [  8.  40. 120.  16.  26.]
 [ 17.  17.  11.  81.  16.]
 [ 18.  84. 101.  42. 332.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 1.519 | Acc: 97.000% | Wgt Acc: 97.033%
	I - Batch: 100 | Loss: 1.523 | Acc: 96.750% | Wgt Acc: 96.671%
	I - Batch: 150 | Loss: 1.504 | Acc: 97.000% | Wgt Acc: 97.075%
	I - Batch: 200 | Loss: 1.484 | Acc: 97.438% | Wgt Acc: 97.459%
	I - Batch: 250 | Loss: 1.484 | Acc: 97.500% | Wgt Acc: 97.494%
	I - Batch: 300 | Loss: 1.475 | Acc: 97.688% | Wgt Acc: 97.643%
	I - Batch: 350 | Loss: 1.476 | Acc: 97.661% | Wgt Acc: 97.581%
I - num batch: 364
I - Train -- Loss: 1.474 | Acc: 97.627% | Wgt Acc: 97.595% | LR: 1.250000e-04 | Dur: 230.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    2.    1.    4.   20.]
 [   1.  655.    2.    0.    5.]
 [   3.    4.  956.    5.   22.]
 [   4.    1.    3.  697.   14.]
 [  17.    6.   12.   12. 2702.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.994 | Acc: 47.250% | Wgt Acc: 40.462%
I - num batch: 87
I - Val -- Loss: 5.871 | Acc: 54.382% | Wgt Acc: 45.056% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   5.   9.  16.  16.]
 [  0.  83.  10.   3.   3.]
 [  2.  30.  90.   4.  11.]
 [ 33.  19.  26. 104.  21.]
 [ 64. 131. 155.  77. 380.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 1.412 | Acc: 98.500% | Wgt Acc: 98.472%
	I - Batch: 100 | Loss: 1.450 | Acc: 97.938% | Wgt Acc: 97.814%
	I - Batch: 150 | Loss: 1.456 | Acc: 97.875% | Wgt Acc: 97.763%
	I - Batch: 200 | Loss: 1.443 | Acc: 98.062% | Wgt Acc: 97.995%
	I - Batch: 250 | Loss: 1.443 | Acc: 98.025% | Wgt Acc: 97.993%
	I - Batch: 300 | Loss: 1.455 | Acc: 97.896% | Wgt Acc: 97.866%
	I - Batch: 350 | Loss: 1.458 | Acc: 97.929% | Wgt Acc: 97.820%
I - num batch: 364
I - Train -- Loss: 1.456 | Acc: 97.971% | Wgt Acc: 97.852% | LR: 1.250000e-04 | Dur: 230.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    2.    2.    7.   10.]
 [   0.  650.    0.    1.   13.]
 [   3.    4.  960.    1.   13.]
 [   5.    2.    3.  699.   12.]
 [  11.   10.    9.   10. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.964 | Acc: 50.375% | Wgt Acc: 43.727%
I - num batch: 87
I - Val -- Loss: 5.845 | Acc: 55.747% | Wgt Acc: 46.782% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.  19.  33.  18.]
 [  0.  88.  19.   1.   3.]
 [  3.  22.  93.   8.   9.]
 [ 17.  16.  16.  87.  22.]
 [ 50. 139. 143.  75. 379.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 1.437 | Acc: 98.625% | Wgt Acc: 98.420%
	I - Batch: 100 | Loss: 1.459 | Acc: 98.312% | Wgt Acc: 98.019%
	I - Batch: 150 | Loss: 1.449 | Acc: 98.458% | Wgt Acc: 98.206%
	I - Batch: 200 | Loss: 1.435 | Acc: 98.625% | Wgt Acc: 98.399%
	I - Batch: 250 | Loss: 1.436 | Acc: 98.550% | Wgt Acc: 98.311%
	I - Batch: 300 | Loss: 1.427 | Acc: 98.688% | Wgt Acc: 98.477%
	I - Batch: 350 | Loss: 1.423 | Acc: 98.732% | Wgt Acc: 98.547%
I - num batch: 364
I - Train -- Loss: 1.422 | Acc: 98.727% | Wgt Acc: 98.554% | LR: 1.250000e-04 | Dur: 230.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    4.    1.    2.    6.]
 [   1.  657.    1.    0.    4.]
 [   1.    0.  965.    0.    8.]
 [   3.    1.    4.  703.    5.]
 [  11.    6.    3.   13. 2740.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.922 | Acc: 50.750% | Wgt Acc: 44.468%
I - num batch: 87
I - Val -- Loss: 5.813 | Acc: 56.034% | Wgt Acc: 48.253% | Dur: 42.57s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   4.  23.  37.  26.]
 [  0. 107.  19.   5.   5.]
 [  3.  23.  82.   6.   9.]
 [ 21.  34.  29.  96.  30.]
 [ 41. 100. 137.  60. 361.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 1.461 | Acc: 98.000% | Wgt Acc: 97.727%
	I - Batch: 100 | Loss: 1.476 | Acc: 97.625% | Wgt Acc: 97.458%
	I - Batch: 150 | Loss: 1.456 | Acc: 97.875% | Wgt Acc: 97.773%
	I - Batch: 200 | Loss: 1.444 | Acc: 98.125% | Wgt Acc: 98.004%
	I - Batch: 250 | Loss: 1.431 | Acc: 98.350% | Wgt Acc: 98.279%
	I - Batch: 300 | Loss: 1.428 | Acc: 98.417% | Wgt Acc: 98.323%
	I - Batch: 350 | Loss: 1.422 | Acc: 98.536% | Wgt Acc: 98.425%
I - num batch: 364
I - Train -- Loss: 1.423 | Acc: 98.521% | Wgt Acc: 98.401% | LR: 1.250000e-04 | Dur: 230.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    2.    1.    2.   11.]
 [   1.  657.    1.    0.    6.]
 [   2.    3.  963.    3.    6.]
 [   3.    0.    2.  701.    9.]
 [   9.    6.    7.   12. 2731.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.894 | Acc: 49.750% | Wgt Acc: 43.690%
I - num batch: 87
I - Val -- Loss: 5.817 | Acc: 56.466% | Wgt Acc: 48.106% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   5.  12.  18.  21.]
 [  0.  78.  17.   2.   2.]
 [  3.  46. 106.   8.  14.]
 [ 23.  26.  25. 106.  26.]
 [ 45. 113. 130.  70. 368.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 1.453 | Acc: 97.875% | Wgt Acc: 97.782%
	I - Batch: 100 | Loss: 1.487 | Acc: 97.250% | Wgt Acc: 97.102%
	I - Batch: 150 | Loss: 1.458 | Acc: 97.667% | Wgt Acc: 97.640%
	I - Batch: 200 | Loss: 1.449 | Acc: 97.875% | Wgt Acc: 97.847%
	I - Batch: 250 | Loss: 1.445 | Acc: 98.025% | Wgt Acc: 97.991%
	I - Batch: 300 | Loss: 1.450 | Acc: 98.021% | Wgt Acc: 97.952%
	I - Batch: 350 | Loss: 1.443 | Acc: 98.143% | Wgt Acc: 98.085%
I - num batch: 364
I - Train -- Loss: 1.440 | Acc: 98.194% | Wgt Acc: 98.147% | LR: 1.250000e-04 | Dur: 227.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    3.    1.    6.   10.]
 [   2.  658.    0.    0.    5.]
 [   2.    2.  964.    0.   10.]
 [   3.    0.    4.  697.   19.]
 [  13.    5.    5.   15. 2719.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.841 | Acc: 52.750% | Wgt Acc: 48.315%
I - num batch: 87
I - Val -- Loss: 5.766 | Acc: 57.615% | Wgt Acc: 51.144% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   5.  14.  22.  29.]
 [  1. 131.  29.   7.  12.]
 [  1.  28.  98.   6.  21.]
 [ 21.  17.  26.  98.  17.]
 [ 53.  87. 123.  71. 352.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 1.393 | Acc: 98.750% | Wgt Acc: 98.877%
	I - Batch: 100 | Loss: 1.421 | Acc: 98.375% | Wgt Acc: 98.357%
	I - Batch: 150 | Loss: 1.428 | Acc: 98.375% | Wgt Acc: 98.305%
	I - Batch: 200 | Loss: 1.424 | Acc: 98.469% | Wgt Acc: 98.384%
	I - Batch: 250 | Loss: 1.430 | Acc: 98.300% | Wgt Acc: 98.270%
	I - Batch: 300 | Loss: 1.432 | Acc: 98.354% | Wgt Acc: 98.269%
	I - Batch: 350 | Loss: 1.438 | Acc: 98.196% | Wgt Acc: 98.156%
I - num batch: 364
I - Train -- Loss: 1.437 | Acc: 98.212% | Wgt Acc: 98.166% | LR: 1.250000e-04 | Dur: 227.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    3.    2.    4.   10.]
 [   1.  657.    1.    2.    3.]
 [   1.    1.  960.    0.   22.]
 [   1.    0.    3.  700.   10.]
 [  13.    7.    8.   12. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.871 | Acc: 52.875% | Wgt Acc: 47.182%
I - num batch: 87
I - Val -- Loss: 5.793 | Acc: 57.184% | Wgt Acc: 50.188% | Dur: 41.73s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   5.  21.  36.  23.]
 [  0.  91.  11.   3.  13.]
 [  5.  45. 120.  12.  25.]
 [ 13.  20.  22.  94.  19.]
 [ 41. 107. 116.  59. 351.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 1.421 | Acc: 98.500% | Wgt Acc: 98.286%
	I - Batch: 100 | Loss: 1.402 | Acc: 98.750% | Wgt Acc: 98.631%
	I - Batch: 150 | Loss: 1.412 | Acc: 98.750% | Wgt Acc: 98.600%
	I - Batch: 200 | Loss: 1.421 | Acc: 98.438% | Wgt Acc: 98.440%
	I - Batch: 250 | Loss: 1.427 | Acc: 98.425% | Wgt Acc: 98.382%
	I - Batch: 300 | Loss: 1.429 | Acc: 98.333% | Wgt Acc: 98.305%
	I - Batch: 350 | Loss: 1.435 | Acc: 98.250% | Wgt Acc: 98.225%
I - num batch: 364
I - Train -- Loss: 1.436 | Acc: 98.212% | Wgt Acc: 98.166% | LR: 1.250000e-04 | Dur: 226.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    3.    1.    5.   27.]
 [   3.  654.    0.    1.    5.]
 [   0.    3.  965.    1.    7.]
 [   1.    1.    2.  699.    6.]
 [  13.    7.    6.   12. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.815 | Acc: 53.875% | Wgt Acc: 49.467%
I - num batch: 87
I - Val -- Loss: 5.749 | Acc: 57.399% | Wgt Acc: 51.987% | Dur: 41.53s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   4.  20.  22.  24.]
 [  1. 136.  45.   4.  18.]
 [  3.  16.  75.   3.  10.]
 [ 40.  21.  39. 133.  52.]
 [ 27.  91. 111.  42. 327.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 1.492 | Acc: 97.000% | Wgt Acc: 97.147%
	I - Batch: 100 | Loss: 1.490 | Acc: 97.250% | Wgt Acc: 97.364%
	I - Batch: 150 | Loss: 1.469 | Acc: 97.667% | Wgt Acc: 97.761%
	I - Batch: 200 | Loss: 1.456 | Acc: 97.969% | Wgt Acc: 98.025%
	I - Batch: 250 | Loss: 1.462 | Acc: 97.875% | Wgt Acc: 97.856%
	I - Batch: 300 | Loss: 1.471 | Acc: 97.708% | Wgt Acc: 97.710%
	I - Batch: 350 | Loss: 1.472 | Acc: 97.732% | Wgt Acc: 97.720%
I - num batch: 364
I - Train -- Loss: 1.478 | Acc: 97.644% | Wgt Acc: 97.670% | LR: 1.250000e-04 | Dur: 227.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    1.    2.   16.]
 [   1.  654.    1.    8.   20.]
 [   2.    4.  961.    2.   16.]
 [   5.    2.    3.  693.   12.]
 [  13.    6.    8.   13. 2699.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.798 | Acc: 53.125% | Wgt Acc: 49.571%
I - num batch: 87
I - Val -- Loss: 5.744 | Acc: 57.543% | Wgt Acc: 53.183% | Dur: 41.66s
I - Confusion Matrix: [row->prediction - col->label]
[[145.  12.  19.  51.  34.]
 [  0. 138.  44.   4.  15.]
 [  3.  36. 100.   8.  29.]
 [ 26.  18.  37. 105.  40.]
 [ 25.  64.  90.  36. 313.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 1.479 | Acc: 98.250% | Wgt Acc: 97.934%
	I - Batch: 100 | Loss: 1.426 | Acc: 98.812% | Wgt Acc: 98.693%
	I - Batch: 150 | Loss: 1.429 | Acc: 98.583% | Wgt Acc: 98.520%
	I - Batch: 200 | Loss: 1.444 | Acc: 98.219% | Wgt Acc: 98.127%
	I - Batch: 250 | Loss: 1.439 | Acc: 98.350% | Wgt Acc: 98.231%
	I - Batch: 300 | Loss: 1.440 | Acc: 98.208% | Wgt Acc: 98.184%
	I - Batch: 350 | Loss: 1.438 | Acc: 98.232% | Wgt Acc: 98.210%
I - num batch: 364
I - Train -- Loss: 1.439 | Acc: 98.229% | Wgt Acc: 98.222% | LR: 1.250000e-04 | Dur: 226.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    2.    1.    4.   12.]
 [   4.  653.    2.    0.   10.]
 [   2.    2.  964.    1.   10.]
 [   2.    0.    2.  702.   16.]
 [   6.   11.    5.   11. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.991 | Acc: 49.125% | Wgt Acc: 42.251%
I - num batch: 87
I - Val -- Loss: 5.866 | Acc: 55.532% | Wgt Acc: 46.658% | Dur: 41.77s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   5.  16.  37.  21.]
 [  0.  94.  22.   1.   7.]
 [  3.  18.  89.   1.   5.]
 [ 16.  19.  16.  84.  20.]
 [ 52. 132. 147.  81. 378.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 1.469 | Acc: 97.625% | Wgt Acc: 97.473%
	I - Batch: 100 | Loss: 1.438 | Acc: 98.062% | Wgt Acc: 97.991%
	I - Batch: 150 | Loss: 1.433 | Acc: 98.208% | Wgt Acc: 98.196%
	I - Batch: 200 | Loss: 1.438 | Acc: 98.094% | Wgt Acc: 98.046%
	I - Batch: 250 | Loss: 1.436 | Acc: 98.125% | Wgt Acc: 98.097%
	I - Batch: 300 | Loss: 1.439 | Acc: 98.062% | Wgt Acc: 98.027%
	I - Batch: 350 | Loss: 1.433 | Acc: 98.179% | Wgt Acc: 98.165%
I - num batch: 364
I - Train -- Loss: 1.436 | Acc: 98.177% | Wgt Acc: 98.155% | LR: 1.250000e-04 | Dur: 227.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    2.    0.    1.   23.]
 [   0.  657.    0.    1.    9.]
 [   4.    4.  962.    0.    6.]
 [   1.    1.    2.  700.    9.]
 [  13.    4.   10.   16. 2716.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.844 | Acc: 54.500% | Wgt Acc: 49.069%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 59.411% | Wgt Acc: 52.413% | Dur: 41.84s
I - Confusion Matrix: [row->prediction - col->label]
[[143.  11.  19.  38.  28.]
 [  0. 109.  22.   3.   3.]
 [  2.  30. 108.   7.  12.]
 [ 23.  16.  18. 106.  27.]
 [ 31. 102. 123.  50. 361.]]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 1.412 | Acc: 98.625% | Wgt Acc: 98.625%
	I - Batch: 100 | Loss: 1.401 | Acc: 98.750% | Wgt Acc: 98.746%
	I - Batch: 150 | Loss: 1.403 | Acc: 98.708% | Wgt Acc: 98.774%
	I - Batch: 200 | Loss: 1.408 | Acc: 98.562% | Wgt Acc: 98.676%
	I - Batch: 250 | Loss: 1.410 | Acc: 98.575% | Wgt Acc: 98.634%
	I - Batch: 300 | Loss: 1.428 | Acc: 98.396% | Wgt Acc: 98.357%
	I - Batch: 350 | Loss: 1.431 | Acc: 98.304% | Wgt Acc: 98.290%
I - num batch: 364
I - Train -- Loss: 1.431 | Acc: 98.315% | Wgt Acc: 98.312% | LR: 1.250000e-04 | Dur: 229.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    3.    4.    2.    7.]
 [   1.  657.    1.    1.   12.]
 [   0.    3.  963.    3.   16.]
 [   2.    0.    3.  700.   10.]
 [  10.    5.    3.   12. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.840 | Acc: 53.125% | Wgt Acc: 47.697%
I - num batch: 87
I - Val -- Loss: 5.780 | Acc: 57.974% | Wgt Acc: 51.140% | Dur: 42.48s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   6.  27.  52.  31.]
 [  0. 111.  20.   3.   6.]
 [  3.  47.  96.   8.  14.]
 [ 23.  22.  25. 103.  28.]
 [ 28.  82. 122.  38. 352.]]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 1.454 | Acc: 98.250% | Wgt Acc: 98.088%
	I - Batch: 100 | Loss: 1.441 | Acc: 98.250% | Wgt Acc: 98.181%
	I - Batch: 150 | Loss: 1.425 | Acc: 98.458% | Wgt Acc: 98.362%
	I - Batch: 200 | Loss: 1.428 | Acc: 98.375% | Wgt Acc: 98.346%
	I - Batch: 250 | Loss: 1.434 | Acc: 98.250% | Wgt Acc: 98.278%
	I - Batch: 300 | Loss: 1.439 | Acc: 98.208% | Wgt Acc: 98.213%
	I - Batch: 350 | Loss: 1.432 | Acc: 98.304% | Wgt Acc: 98.354%
I - num batch: 364
I - Train -- Loss: 1.436 | Acc: 98.280% | Wgt Acc: 98.292% | LR: 1.250000e-04 | Dur: 227.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    3.    4.   19.]
 [   2.  656.    1.    0.   13.]
 [   2.    3.  964.    3.    9.]
 [   3.    1.    1.  703.    6.]
 [   9.    6.    5.    8. 2716.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.840 | Acc: 52.250% | Wgt Acc: 46.576%
I - num batch: 87
I - Val -- Loss: 5.769 | Acc: 57.759% | Wgt Acc: 51.082% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   4.  16.  30.  20.]
 [  1. 113.  24.   5.   6.]
 [  3.  35. 100.  13.  14.]
 [ 29.  22.  34. 109.  41.]
 [ 34.  94. 116.  47. 350.]]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 1.395 | Acc: 98.875% | Wgt Acc: 99.061%
	I - Batch: 100 | Loss: 1.389 | Acc: 98.938% | Wgt Acc: 98.999%
	I - Batch: 150 | Loss: 1.385 | Acc: 99.042% | Wgt Acc: 99.089%
	I - Batch: 200 | Loss: 1.394 | Acc: 98.844% | Wgt Acc: 98.864%
	I - Batch: 250 | Loss: 1.393 | Acc: 98.875% | Wgt Acc: 98.915%
	I - Batch: 300 | Loss: 1.408 | Acc: 98.750% | Wgt Acc: 98.730%
	I - Batch: 350 | Loss: 1.414 | Acc: 98.679% | Wgt Acc: 98.616%
I - num batch: 364
I - Train -- Loss: 1.419 | Acc: 98.624% | Wgt Acc: 98.556% | LR: 1.250000e-04 | Dur: 227.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    2.    4.   12.]
 [   1.  656.    0.    1.    7.]
 [   0.    1.  966.    1.    5.]
 [   3.    3.    4.  703.    9.]
 [   8.    6.    2.    9. 2730.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.908 | Acc: 51.000% | Wgt Acc: 45.222%
I - num batch: 87
I - Val -- Loss: 5.806 | Acc: 57.112% | Wgt Acc: 49.243% | Dur: 41.59s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   5.  20.  36.  28.]
 [  0. 108.  25.   4.   4.]
 [  0.  17.  78.   8.   4.]
 [ 24.  23.  31. 105.  30.]
 [ 36. 115. 136.  51. 365.]]

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 1.443 | Acc: 98.625% | Wgt Acc: 98.468%
	I - Batch: 100 | Loss: 1.463 | Acc: 98.188% | Wgt Acc: 97.927%
	I - Batch: 150 | Loss: 1.439 | Acc: 98.292% | Wgt Acc: 98.231%
	I - Batch: 200 | Loss: 1.439 | Acc: 98.344% | Wgt Acc: 98.229%
	I - Batch: 250 | Loss: 1.433 | Acc: 98.350% | Wgt Acc: 98.250%
	I - Batch: 300 | Loss: 1.436 | Acc: 98.354% | Wgt Acc: 98.209%
	I - Batch: 350 | Loss: 1.429 | Acc: 98.482% | Wgt Acc: 98.330%
I - num batch: 364
I - Train -- Loss: 1.427 | Acc: 98.487% | Wgt Acc: 98.352% | LR: 1.250000e-04 | Dur: 227.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    2.    5.   13.]
 [   1.  656.    2.    1.    8.]
 [   1.    2.  959.    0.    7.]
 [   0.    1.    4.  702.    5.]
 [  10.    7.    7.   10. 2730.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.863 | Acc: 51.250% | Wgt Acc: 45.326%
I - num batch: 87
I - Val -- Loss: 5.784 | Acc: 57.112% | Wgt Acc: 49.220% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   6.  23.  40.  19.]
 [  0. 108.  30.   5.   6.]
 [  2.  29.  89.  11.  14.]
 [ 18.  16.  18.  90.  24.]
 [ 39. 109. 130.  58. 368.]]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 1.386 | Acc: 99.375% | Wgt Acc: 99.453%
	I - Batch: 100 | Loss: 1.386 | Acc: 99.312% | Wgt Acc: 99.293%
	I - Batch: 150 | Loss: 1.401 | Acc: 99.125% | Wgt Acc: 99.041%
	I - Batch: 200 | Loss: 1.408 | Acc: 99.000% | Wgt Acc: 98.851%
	I - Batch: 250 | Loss: 1.411 | Acc: 98.875% | Wgt Acc: 98.715%
	I - Batch: 300 | Loss: 1.407 | Acc: 98.917% | Wgt Acc: 98.744%
	I - Batch: 350 | Loss: 1.409 | Acc: 98.911% | Wgt Acc: 98.748%
I - num batch: 364
I - Train -- Loss: 1.408 | Acc: 98.917% | Wgt Acc: 98.762% | LR: 1.250000e-04 | Dur: 228.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    3.    2.    3.    7.]
 [   2.  659.    0.    0.    2.]
 [   2.    0.  966.    2.    5.]
 [   2.    1.    1.  705.    5.]
 [   8.    5.    5.    8. 2744.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.811 | Acc: 54.375% | Wgt Acc: 49.001%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 59.195% | Wgt Acc: 52.622% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[145.  10.  18.  50.  26.]
 [  0. 115.  20.   3.   6.]
 [  5.  40. 111.  11.  24.]
 [ 21.  18.  17.  98.  20.]
 [ 28.  85. 124.  42. 355.]]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 1.400 | Acc: 98.750% | Wgt Acc: 98.767%
	I - Batch: 100 | Loss: 1.388 | Acc: 99.000% | Wgt Acc: 99.051%
	I - Batch: 150 | Loss: 1.394 | Acc: 99.000% | Wgt Acc: 98.904%
	I - Batch: 200 | Loss: 1.393 | Acc: 99.031% | Wgt Acc: 98.951%
	I - Batch: 250 | Loss: 1.387 | Acc: 99.125% | Wgt Acc: 99.017%
	I - Batch: 300 | Loss: 1.391 | Acc: 98.958% | Wgt Acc: 98.858%
	I - Batch: 350 | Loss: 1.394 | Acc: 98.929% | Wgt Acc: 98.824%
I - num batch: 364
I - Train -- Loss: 1.394 | Acc: 98.934% | Wgt Acc: 98.817% | LR: 1.250000e-04 | Dur: 229.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    2.    2.    3.    8.]
 [   1.  659.    0.    1.    5.]
 [   1.    2.  963.    1.    5.]
 [   1.    0.    3.  708.    4.]
 [   7.    5.    6.    5. 2741.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.871 | Acc: 49.500% | Wgt Acc: 43.727%
I - num batch: 87
I - Val -- Loss: 5.790 | Acc: 56.034% | Wgt Acc: 48.566% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   7.  17.  31.  28.]
 [  1. 101.  24.   5.   6.]
 [  2.  34.  93.  12.  19.]
 [ 32.  23.  32. 104.  23.]
 [ 37. 103. 124.  52. 355.]]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 1.419 | Acc: 98.375% | Wgt Acc: 98.480%
	I - Batch: 100 | Loss: 1.403 | Acc: 98.812% | Wgt Acc: 98.798%
	I - Batch: 150 | Loss: 1.390 | Acc: 99.083% | Wgt Acc: 99.037%
	I - Batch: 200 | Loss: 1.395 | Acc: 99.062% | Wgt Acc: 98.924%
	I - Batch: 250 | Loss: 1.402 | Acc: 99.000% | Wgt Acc: 98.831%
	I - Batch: 300 | Loss: 1.403 | Acc: 98.896% | Wgt Acc: 98.819%
	I - Batch: 350 | Loss: 1.412 | Acc: 98.696% | Wgt Acc: 98.626%
I - num batch: 364
I - Train -- Loss: 1.413 | Acc: 98.676% | Wgt Acc: 98.594% | LR: 1.250000e-04 | Dur: 228.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    4.    2.   10.]
 [   2.  655.    1.    0.    8.]
 [   1.    2.  967.    0.    4.]
 [   1.    0.    0.  703.    9.]
 [   7.    9.    2.   13. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.661 | Acc: 55.625% | Wgt Acc: 54.019%
I - num batch: 87
I - Val -- Loss: 5.659 | Acc: 58.405% | Wgt Acc: 56.763% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[142.  16.  22.  32.  38.]
 [  3. 162.  67.  16.  36.]
 [  3.  18. 111.   9.  23.]
 [ 37.  25.  20. 125.  61.]
 [ 14.  47.  70.  22. 273.]]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 1.492 | Acc: 97.250% | Wgt Acc: 96.941%
	I - Batch: 100 | Loss: 1.448 | Acc: 98.125% | Wgt Acc: 97.916%
	I - Batch: 150 | Loss: 1.440 | Acc: 98.375% | Wgt Acc: 98.219%
	I - Batch: 200 | Loss: 1.435 | Acc: 98.500% | Wgt Acc: 98.324%
	I - Batch: 250 | Loss: 1.431 | Acc: 98.500% | Wgt Acc: 98.367%
	I - Batch: 300 | Loss: 1.424 | Acc: 98.583% | Wgt Acc: 98.465%
	I - Batch: 350 | Loss: 1.424 | Acc: 98.554% | Wgt Acc: 98.459%
I - num batch: 364
I - Train -- Loss: 1.431 | Acc: 98.418% | Wgt Acc: 98.313% | LR: 1.250000e-04 | Dur: 228.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    4.    2.    3.    8.]
 [   2.  653.    0.    2.    6.]
 [   3.    1.  967.    1.    9.]
 [   3.    1.    3.  701.   13.]
 [   9.    9.    2.   11. 2727.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.948 | Acc: 49.500% | Wgt Acc: 43.752%
I - num batch: 87
I - Val -- Loss: 5.860 | Acc: 54.023% | Wgt Acc: 46.670% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[152.  19.  27.  63.  51.]
 [  1. 103.  25.   5.   9.]
 [  3.  25.  79.   2.  10.]
 [ 10.  14.  17.  73.  16.]
 [ 33. 107. 142.  61. 345.]]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 1.413 | Acc: 98.750% | Wgt Acc: 98.810%
	I - Batch: 100 | Loss: 1.423 | Acc: 98.625% | Wgt Acc: 98.646%
	I - Batch: 150 | Loss: 1.415 | Acc: 98.750% | Wgt Acc: 98.729%
	I - Batch: 200 | Loss: 1.407 | Acc: 98.812% | Wgt Acc: 98.819%
	I - Batch: 250 | Loss: 1.413 | Acc: 98.750% | Wgt Acc: 98.682%
	I - Batch: 300 | Loss: 1.418 | Acc: 98.667% | Wgt Acc: 98.553%
	I - Batch: 350 | Loss: 1.419 | Acc: 98.625% | Wgt Acc: 98.526%
I - num batch: 364
I - Train -- Loss: 1.422 | Acc: 98.590% | Wgt Acc: 98.483% | LR: 1.250000e-04 | Dur: 228.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    3.    2.    2.    8.]
 [   2.  656.    0.    1.    9.]
 [   4.    0.  966.    4.    9.]
 [   0.    3.    2.  703.    5.]
 [  10.    6.    4.    8. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.967 | Acc: 47.500% | Wgt Acc: 40.486%
I - num batch: 87
I - Val -- Loss: 5.848 | Acc: 55.244% | Wgt Acc: 46.496% | Dur: 42.02s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   9.  13.  30.  34.]
 [  0.  67.  12.   1.   2.]
 [  5.  35. 109.  10.  10.]
 [ 26.  13.  13.  92.  16.]
 [ 36. 144. 143.  71. 369.]]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 1.386 | Acc: 99.250% | Wgt Acc: 99.179%
	I - Batch: 100 | Loss: 1.393 | Acc: 99.125% | Wgt Acc: 99.064%
	I - Batch: 150 | Loss: 1.407 | Acc: 98.792% | Wgt Acc: 98.747%
	I - Batch: 200 | Loss: 1.416 | Acc: 98.562% | Wgt Acc: 98.587%
	I - Batch: 250 | Loss: 1.432 | Acc: 98.350% | Wgt Acc: 98.341%
	I - Batch: 300 | Loss: 1.427 | Acc: 98.438% | Wgt Acc: 98.439%
	I - Batch: 350 | Loss: 1.427 | Acc: 98.464% | Wgt Acc: 98.466%
I - num batch: 364
I - Train -- Loss: 1.426 | Acc: 98.452% | Wgt Acc: 98.465% | LR: 1.250000e-04 | Dur: 228.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    3.    3.    2.    8.]
 [   2.  659.    1.    0.    7.]
 [   3.    4.  964.    2.   13.]
 [   0.    0.    2.  705.   14.]
 [  11.    2.    4.    9. 2721.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.839 | Acc: 50.375% | Wgt Acc: 45.406%
I - num batch: 87
I - Val -- Loss: 5.773 | Acc: 55.460% | Wgt Acc: 48.872% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   6.  22.  56.  35.]
 [  1.  99.  21.   4.   5.]
 [  4.  49. 105.  14.  25.]
 [ 17.  23.  22.  85.  28.]
 [ 32.  91. 120.  45. 338.]]

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 1.466 | Acc: 97.875% | Wgt Acc: 97.808%
	I - Batch: 100 | Loss: 1.448 | Acc: 97.938% | Wgt Acc: 97.962%
	I - Batch: 150 | Loss: 1.447 | Acc: 98.000% | Wgt Acc: 97.996%
	I - Batch: 200 | Loss: 1.439 | Acc: 98.062% | Wgt Acc: 98.131%
	I - Batch: 250 | Loss: 1.440 | Acc: 98.075% | Wgt Acc: 98.134%
	I - Batch: 300 | Loss: 1.441 | Acc: 98.146% | Wgt Acc: 98.149%
	I - Batch: 350 | Loss: 1.438 | Acc: 98.214% | Wgt Acc: 98.190%
I - num batch: 364
I - Train -- Loss: 1.442 | Acc: 98.194% | Wgt Acc: 98.139% | LR: 1.250000e-04 | Dur: 228.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    4.    2.    4.   12.]
 [   1.  657.    1.    1.    8.]
 [   0.    3.  963.    3.   16.]
 [   2.    0.    2.  697.    8.]
 [  15.    4.    6.   13. 2719.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.913 | Acc: 51.250% | Wgt Acc: 46.398%
I - num batch: 87
I - Val -- Loss: 5.823 | Acc: 55.675% | Wgt Acc: 49.650% | Dur: 41.92s
I - Confusion Matrix: [row->prediction - col->label]
[[151.  13.  27.  49.  51.]
 [  0. 100.  18.   1.   6.]
 [  2.  22.  93.   6.  13.]
 [ 20.  30.  29. 106.  36.]
 [ 26. 103. 123.  42. 325.]]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 1.616 | Acc: 94.000% | Wgt Acc: 95.416%
	I - Batch: 100 | Loss: 1.560 | Acc: 95.625% | Wgt Acc: 96.336%
	I - Batch: 150 | Loss: 1.520 | Acc: 96.458% | Wgt Acc: 96.908%
	I - Batch: 200 | Loss: 1.503 | Acc: 96.906% | Wgt Acc: 97.143%
	I - Batch: 250 | Loss: 1.495 | Acc: 96.975% | Wgt Acc: 97.217%
	I - Batch: 300 | Loss: 1.491 | Acc: 97.062% | Wgt Acc: 97.243%
	I - Batch: 350 | Loss: 1.483 | Acc: 97.232% | Wgt Acc: 97.390%
I - num batch: 364
I - Train -- Loss: 1.482 | Acc: 97.266% | Wgt Acc: 97.419% | LR: 1.250000e-04 | Dur: 228.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    2.    2.    3.   14.]
 [   1.  649.    2.    0.   11.]
 [   3.    6.  955.    3.   43.]
 [   3.    1.    4.  702.   17.]
 [  13.   10.   11.   10. 2678.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.761 | Acc: 55.500% | Wgt Acc: 51.335%
I - num batch: 87
I - Val -- Loss: 5.721 | Acc: 59.626% | Wgt Acc: 54.991% | Dur: 41.98s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   4.  15.  16.  17.]
 [  1. 122.  27.   7.  13.]
 [  2.  38. 127.  11.  31.]
 [ 45.  23.  30. 139.  46.]
 [ 33.  81.  91.  31. 324.]]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 1.415 | Acc: 98.750% | Wgt Acc: 98.662%
	I - Batch: 100 | Loss: 1.427 | Acc: 98.625% | Wgt Acc: 98.504%
	I - Batch: 150 | Loss: 1.429 | Acc: 98.292% | Wgt Acc: 98.278%
	I - Batch: 200 | Loss: 1.436 | Acc: 98.156% | Wgt Acc: 98.119%
	I - Batch: 250 | Loss: 1.441 | Acc: 98.025% | Wgt Acc: 98.064%
	I - Batch: 300 | Loss: 1.445 | Acc: 97.979% | Wgt Acc: 98.005%
	I - Batch: 350 | Loss: 1.443 | Acc: 98.036% | Wgt Acc: 98.057%
I - num batch: 364
I - Train -- Loss: 1.440 | Acc: 98.091% | Wgt Acc: 98.101% | LR: 1.250000e-04 | Dur: 228.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    3.    2.    4.   15.]
 [   0.  655.    1.    0.    5.]
 [   3.    4.  962.    3.   20.]
 [   3.    1.    2.  704.   12.]
 [  14.    5.    7.    7. 2711.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.760 | Acc: 53.875% | Wgt Acc: 49.583%
I - num batch: 87
I - Val -- Loss: 5.719 | Acc: 58.908% | Wgt Acc: 53.268% | Dur: 41.97s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   9.  16.  26.  22.]
 [  2. 110.  28.   7.   9.]
 [  7.  49. 125.  13.  25.]
 [ 29.  14.  25. 117.  38.]
 [ 30.  86.  96.  41. 337.]]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 1.411 | Acc: 98.625% | Wgt Acc: 98.660%
	I - Batch: 100 | Loss: 1.406 | Acc: 98.562% | Wgt Acc: 98.523%
	I - Batch: 150 | Loss: 1.396 | Acc: 98.833% | Wgt Acc: 98.753%
	I - Batch: 200 | Loss: 1.390 | Acc: 98.938% | Wgt Acc: 98.892%
	I - Batch: 250 | Loss: 1.394 | Acc: 98.850% | Wgt Acc: 98.788%
	I - Batch: 300 | Loss: 1.391 | Acc: 98.917% | Wgt Acc: 98.872%
	I - Batch: 350 | Loss: 1.395 | Acc: 98.875% | Wgt Acc: 98.824%
I - num batch: 364
I - Train -- Loss: 1.396 | Acc: 98.882% | Wgt Acc: 98.837% | LR: 1.250000e-04 | Dur: 228.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    2.    2.    3.    5.]
 [   3.  658.    0.    1.    5.]
 [   2.    1.  966.    0.   10.]
 [   1.    1.    3.  708.    8.]
 [   3.    6.    3.    6. 2735.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.941 | Acc: 50.375% | Wgt Acc: 43.923%
I - num batch: 87
I - Val -- Loss: 5.822 | Acc: 56.753% | Wgt Acc: 48.315% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   3.  12.  19.  15.]
 [  0. 102.  23.   3.   9.]
 [  1.  23.  82.   6.   9.]
 [ 18.  21.  17.  99.  24.]
 [ 47. 119. 156.  77. 374.]]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 1.408 | Acc: 98.500% | Wgt Acc: 98.703%
	I - Batch: 100 | Loss: 1.432 | Acc: 98.562% | Wgt Acc: 98.384%
	I - Batch: 150 | Loss: 1.418 | Acc: 98.750% | Wgt Acc: 98.629%
	I - Batch: 200 | Loss: 1.416 | Acc: 98.719% | Wgt Acc: 98.624%
	I - Batch: 250 | Loss: 1.407 | Acc: 98.825% | Wgt Acc: 98.751%
	I - Batch: 300 | Loss: 1.409 | Acc: 98.750% | Wgt Acc: 98.669%
	I - Batch: 350 | Loss: 1.410 | Acc: 98.750% | Wgt Acc: 98.668%
I - num batch: 364
I - Train -- Loss: 1.412 | Acc: 98.710% | Wgt Acc: 98.644% | LR: 1.250000e-04 | Dur: 228.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    5.    3.    2.    6.]
 [   2.  657.    0.    0.    4.]
 [   1.    1.  965.    2.    9.]
 [   2.    0.    1.  705.   12.]
 [   6.    5.    5.    9. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.881 | Acc: 52.250% | Wgt Acc: 46.747%
I - num batch: 87
I - Val -- Loss: 5.785 | Acc: 58.908% | Wgt Acc: 51.933% | Dur: 41.99s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   7.  13.  17.  21.]
 [  2. 125.  26.   3.  11.]
 [  3.  25.  89.   5.   9.]
 [ 31.  18.  31. 123.  29.]
 [ 41.  93. 131.  56. 361.]]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 1.358 | Acc: 99.500% | Wgt Acc: 99.519%
	I - Batch: 100 | Loss: 1.382 | Acc: 99.312% | Wgt Acc: 99.152%
	I - Batch: 150 | Loss: 1.395 | Acc: 99.125% | Wgt Acc: 98.892%
	I - Batch: 200 | Loss: 1.397 | Acc: 99.031% | Wgt Acc: 98.819%
	I - Batch: 250 | Loss: 1.403 | Acc: 98.900% | Wgt Acc: 98.722%
	I - Batch: 300 | Loss: 1.406 | Acc: 98.854% | Wgt Acc: 98.718%
	I - Batch: 350 | Loss: 1.413 | Acc: 98.732% | Wgt Acc: 98.589%
I - num batch: 364
I - Train -- Loss: 1.413 | Acc: 98.693% | Wgt Acc: 98.565% | LR: 1.250000e-04 | Dur: 227.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    4.    1.    4.    6.]
 [   2.  657.    1.    0.    6.]
 [   1.    1.  965.    0.    6.]
 [   1.    0.    2.  703.    9.]
 [  10.    6.    5.   11. 2736.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.862 | Acc: 53.875% | Wgt Acc: 48.383%
I - num batch: 87
I - Val -- Loss: 5.780 | Acc: 58.261% | Wgt Acc: 51.883% | Dur: 41.65s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   6.  20.  32.  21.]
 [  0.  91.  17.   2.   6.]
 [  3.  40. 122.   6.  25.]
 [ 22.  32.  19. 120.  37.]
 [ 38.  99. 112.  44. 342.]]

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 1.381 | Acc: 99.125% | Wgt Acc: 99.016%
	I - Batch: 100 | Loss: 1.370 | Acc: 99.188% | Wgt Acc: 99.197%
	I - Batch: 150 | Loss: 1.385 | Acc: 98.958% | Wgt Acc: 98.921%
	I - Batch: 200 | Loss: 1.396 | Acc: 98.875% | Wgt Acc: 98.756%
	I - Batch: 250 | Loss: 1.400 | Acc: 98.800% | Wgt Acc: 98.700%
	I - Batch: 300 | Loss: 1.399 | Acc: 98.875% | Wgt Acc: 98.756%
	I - Batch: 350 | Loss: 1.397 | Acc: 98.911% | Wgt Acc: 98.831%
I - num batch: 364
I - Train -- Loss: 1.399 | Acc: 98.882% | Wgt Acc: 98.803% | LR: 1.250000e-04 | Dur: 227.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    3.    1.    7.]
 [   0.  660.    0.    1.    3.]
 [   2.    1.  965.    0.    6.]
 [   0.    0.    0.  707.    9.]
 [  10.    5.    6.    9. 2738.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.823 | Acc: 51.375% | Wgt Acc: 46.845%
I - num batch: 87
I - Val -- Loss: 5.750 | Acc: 56.322% | Wgt Acc: 50.497% | Dur: 41.74s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   8.  17.  39.  24.]
 [  0. 115.  41.   6.  10.]
 [  6.  43. 117.  12.  37.]
 [ 14.   9.  18.  81.  26.]
 [ 42.  93.  97.  66. 334.]]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 1.401 | Acc: 98.500% | Wgt Acc: 98.701%
	I - Batch: 100 | Loss: 1.402 | Acc: 98.625% | Wgt Acc: 98.642%
	I - Batch: 150 | Loss: 1.393 | Acc: 98.917% | Wgt Acc: 98.854%
	I - Batch: 200 | Loss: 1.404 | Acc: 98.750% | Wgt Acc: 98.676%
	I - Batch: 250 | Loss: 1.416 | Acc: 98.475% | Wgt Acc: 98.509%
	I - Batch: 300 | Loss: 1.420 | Acc: 98.312% | Wgt Acc: 98.418%
	I - Batch: 350 | Loss: 1.434 | Acc: 98.089% | Wgt Acc: 98.110%
I - num batch: 364
I - Train -- Loss: 1.433 | Acc: 98.126% | Wgt Acc: 98.146% | LR: 1.250000e-04 | Dur: 227.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    3.    3.    2.    9.]
 [   2.  652.    0.    0.    9.]
 [   0.    4.  967.    2.   19.]
 [   1.    0.    0.  703.   15.]
 [  16.    9.    4.   11. 2711.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.808 | Acc: 52.125% | Wgt Acc: 46.845%
I - num batch: 87
I - Val -- Loss: 5.740 | Acc: 56.897% | Wgt Acc: 50.675% | Dur: 41.64s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   2.  14.  29.  33.]
 [  1.  88.  14.   3.   9.]
 [  3.  61. 143.  14.  31.]
 [ 28.  20.  21. 100.  19.]
 [ 45.  97.  98.  58. 339.]]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 1.421 | Acc: 98.625% | Wgt Acc: 98.549%
	I - Batch: 100 | Loss: 1.430 | Acc: 98.562% | Wgt Acc: 98.432%
	I - Batch: 150 | Loss: 1.434 | Acc: 98.500% | Wgt Acc: 98.377%
	I - Batch: 200 | Loss: 1.446 | Acc: 98.094% | Wgt Acc: 98.130%
	I - Batch: 250 | Loss: 1.455 | Acc: 97.825% | Wgt Acc: 97.895%
	I - Batch: 300 | Loss: 1.456 | Acc: 97.833% | Wgt Acc: 97.882%
	I - Batch: 350 | Loss: 1.456 | Acc: 97.821% | Wgt Acc: 97.894%
I - num batch: 364
I - Train -- Loss: 1.455 | Acc: 97.850% | Wgt Acc: 97.915% | LR: 1.250000e-04 | Dur: 228.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    4.    2.    5.   13.]
 [   4.  654.    2.    1.   22.]
 [   1.    0.  961.    0.   14.]
 [   1.    2.    1.  698.   13.]
 [  10.    8.    8.   14. 2701.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.873 | Acc: 52.625% | Wgt Acc: 47.623%
I - num batch: 87
I - Val -- Loss: 5.799 | Acc: 57.256% | Wgt Acc: 50.726% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   2.  14.  20.  22.]
 [  1. 125.  31.   4.  12.]
 [  1.  25.  81.   7.  11.]
 [ 26.  28.  36. 120.  40.]
 [ 46.  88. 128.  53. 346.]]

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 1.509 | Acc: 96.625% | Wgt Acc: 97.104%
	I - Batch: 100 | Loss: 1.499 | Acc: 96.562% | Wgt Acc: 96.903%
	I - Batch: 150 | Loss: 1.488 | Acc: 97.083% | Wgt Acc: 97.225%
	I - Batch: 200 | Loss: 1.472 | Acc: 97.312% | Wgt Acc: 97.429%
	I - Batch: 250 | Loss: 1.468 | Acc: 97.500% | Wgt Acc: 97.584%
	I - Batch: 300 | Loss: 1.468 | Acc: 97.604% | Wgt Acc: 97.611%
	I - Batch: 350 | Loss: 1.466 | Acc: 97.679% | Wgt Acc: 97.678%
I - num batch: 364
I - Train -- Loss: 1.467 | Acc: 97.678% | Wgt Acc: 97.689% | LR: 1.250000e-04 | Dur: 228.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    3.    3.    9.   13.]
 [   1.  653.    0.    2.   13.]
 [   0.    2.  963.    0.   13.]
 [   6.    1.    2.  690.   23.]
 [  12.    9.    6.   17. 2701.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.872 | Acc: 51.000% | Wgt Acc: 45.577%
I - num batch: 87
I - Val -- Loss: 5.788 | Acc: 57.328% | Wgt Acc: 49.913% | Dur: 41.77s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   0.   8.  14.  11.]
 [  0. 107.  17.   4.   6.]
 [  4.  35. 125.  14.  27.]
 [ 30.  16.  13.  99.  20.]
 [ 65. 110. 127.  73. 367.]]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 1.439 | Acc: 98.625% | Wgt Acc: 98.307%
	I - Batch: 100 | Loss: 1.415 | Acc: 98.938% | Wgt Acc: 98.692%
	I - Batch: 150 | Loss: 1.413 | Acc: 98.917% | Wgt Acc: 98.775%
	I - Batch: 200 | Loss: 1.419 | Acc: 98.812% | Wgt Acc: 98.725%
	I - Batch: 250 | Loss: 1.426 | Acc: 98.575% | Wgt Acc: 98.505%
	I - Batch: 300 | Loss: 1.425 | Acc: 98.583% | Wgt Acc: 98.522%
	I - Batch: 350 | Loss: 1.429 | Acc: 98.518% | Wgt Acc: 98.424%
I - num batch: 364
I - Train -- Loss: 1.427 | Acc: 98.555% | Wgt Acc: 98.460% | LR: 1.250000e-04 | Dur: 227.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    4.    3.    3.    8.]
 [   1.  653.    1.    1.    2.]
 [   3.    5.  965.    3.   14.]
 [   0.    0.    1.  704.   10.]
 [   8.    6.    4.    7. 2729.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.880 | Acc: 52.750% | Wgt Acc: 46.551%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 58.405% | Wgt Acc: 50.083% | Dur: 41.67s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   4.  17.  24.  10.]
 [  1. 109.  26.   3.   7.]
 [  2.  22.  92.  10.  13.]
 [ 22.  19.  26. 103.  20.]
 [ 46. 114. 129.  64. 381.]]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 1.417 | Acc: 98.875% | Wgt Acc: 98.716%
	I - Batch: 100 | Loss: 1.402 | Acc: 99.062% | Wgt Acc: 98.913%
	I - Batch: 150 | Loss: 1.410 | Acc: 98.792% | Wgt Acc: 98.756%
	I - Batch: 200 | Loss: 1.409 | Acc: 98.844% | Wgt Acc: 98.784%
	I - Batch: 250 | Loss: 1.414 | Acc: 98.750% | Wgt Acc: 98.711%
	I - Batch: 300 | Loss: 1.413 | Acc: 98.708% | Wgt Acc: 98.666%
	I - Batch: 350 | Loss: 1.422 | Acc: 98.536% | Wgt Acc: 98.470%
I - num batch: 364
I - Train -- Loss: 1.423 | Acc: 98.469% | Wgt Acc: 98.459% | LR: 1.250000e-04 | Dur: 226.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    3.    4.    5.   17.]
 [   2.  657.    1.    1.    5.]
 [   1.    2.  967.    1.    6.]
 [   2.    0.    1.  702.   12.]
 [  10.    6.    1.    9. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.887 | Acc: 52.625% | Wgt Acc: 46.422%
I - num batch: 87
I - Val -- Loss: 5.816 | Acc: 57.687% | Wgt Acc: 49.719% | Dur: 41.63s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   1.  19.  39.  24.]
 [  1. 104.  22.   3.   7.]
 [  3.  40. 100.   9.  10.]
 [ 17.  11.  20.  91.  18.]
 [ 42. 112. 129.  62. 372.]]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 1.508 | Acc: 97.125% | Wgt Acc: 96.637%
	I - Batch: 100 | Loss: 1.445 | Acc: 98.125% | Wgt Acc: 97.915%
	I - Batch: 150 | Loss: 1.452 | Acc: 97.792% | Wgt Acc: 97.819%
	I - Batch: 200 | Loss: 1.440 | Acc: 97.812% | Wgt Acc: 97.980%
	I - Batch: 250 | Loss: 1.436 | Acc: 97.925% | Wgt Acc: 98.017%
	I - Batch: 300 | Loss: 1.438 | Acc: 97.958% | Wgt Acc: 98.029%
	I - Batch: 350 | Loss: 1.436 | Acc: 98.018% | Wgt Acc: 98.090%
I - num batch: 364
I - Train -- Loss: 1.441 | Acc: 97.988% | Wgt Acc: 98.048% | LR: 1.250000e-04 | Dur: 227.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    2.    3.    1.   17.]
 [   1.  656.    3.    0.    8.]
 [   4.    4.  960.    2.   19.]
 [   2.    0.    1.  703.   14.]
 [  11.    6.    7.   12. 2705.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.950 | Acc: 50.000% | Wgt Acc: 44.046%
I - num batch: 87
I - Val -- Loss: 5.845 | Acc: 55.963% | Wgt Acc: 48.485% | Dur: 41.60s
I - Confusion Matrix: [row->prediction - col->label]
[[158.   7.  27.  69.  42.]
 [  0.  95.  13.   5.   2.]
 [  2.  33. 103.  10.  22.]
 [ 10.  13.  16.  68.  10.]
 [ 29. 120. 131.  52. 355.]]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 1.451 | Acc: 97.875% | Wgt Acc: 97.508%
	I - Batch: 100 | Loss: 1.438 | Acc: 98.062% | Wgt Acc: 97.925%
	I - Batch: 150 | Loss: 1.437 | Acc: 98.083% | Wgt Acc: 97.992%
	I - Batch: 200 | Loss: 1.444 | Acc: 97.938% | Wgt Acc: 97.864%
	I - Batch: 250 | Loss: 1.434 | Acc: 98.100% | Wgt Acc: 98.087%
	I - Batch: 300 | Loss: 1.436 | Acc: 98.062% | Wgt Acc: 98.073%
	I - Batch: 350 | Loss: 1.439 | Acc: 98.036% | Wgt Acc: 98.002%
I - num batch: 364
I - Train -- Loss: 1.438 | Acc: 98.057% | Wgt Acc: 98.038% | LR: 1.250000e-04 | Dur: 227.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    3.    4.   15.]
 [   2.  657.    0.    0.    5.]
 [   2.    2.  962.    2.   18.]
 [   2.    0.    3.  699.   12.]
 [  15.    7.    6.   13. 2713.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.759 | Acc: 51.875% | Wgt Acc: 47.023%
I - num batch: 87
I - Val -- Loss: 5.701 | Acc: 56.968% | Wgt Acc: 50.478% | Dur: 41.67s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.  16.  20.  12.]
 [  4. 116.  26.  10.  16.]
 [  7.  54. 133.  18.  35.]
 [ 17.   7.  14.  80.  15.]
 [ 60.  90. 101.  76. 353.]]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 1.461 | Acc: 97.750% | Wgt Acc: 97.579%
	I - Batch: 100 | Loss: 1.452 | Acc: 97.750% | Wgt Acc: 97.823%
	I - Batch: 150 | Loss: 1.443 | Acc: 97.875% | Wgt Acc: 97.927%
	I - Batch: 200 | Loss: 1.436 | Acc: 98.094% | Wgt Acc: 98.152%
	I - Batch: 250 | Loss: 1.433 | Acc: 98.150% | Wgt Acc: 98.173%
	I - Batch: 300 | Loss: 1.427 | Acc: 98.271% | Wgt Acc: 98.305%
	I - Batch: 350 | Loss: 1.426 | Acc: 98.286% | Wgt Acc: 98.325%
I - num batch: 364
I - Train -- Loss: 1.429 | Acc: 98.212% | Wgt Acc: 98.273% | LR: 1.250000e-04 | Dur: 226.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    3.    2.    5.   10.]
 [   1.  657.    1.    0.   10.]
 [   2.    0.  967.    1.   12.]
 [   4.    3.    1.  700.   19.]
 [  10.    5.    3.   12. 2712.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.771 | Acc: 54.000% | Wgt Acc: 49.504%
I - num batch: 87
I - Val -- Loss: 5.723 | Acc: 58.405% | Wgt Acc: 52.367% | Dur: 41.29s
I - Confusion Matrix: [row->prediction - col->label]
[[137.  20.  28.  30.  24.]
 [  0. 113.  23.   2.   8.]
 [  2.  31. 113.   9.  24.]
 [ 24.  25.  25. 108.  33.]
 [ 36.  79. 101.  55. 342.]]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 1.412 | Acc: 98.875% | Wgt Acc: 98.956%
	I - Batch: 100 | Loss: 1.415 | Acc: 98.750% | Wgt Acc: 98.731%
	I - Batch: 150 | Loss: 1.404 | Acc: 98.833% | Wgt Acc: 98.869%
	I - Batch: 200 | Loss: 1.407 | Acc: 98.719% | Wgt Acc: 98.751%
	I - Batch: 250 | Loss: 1.419 | Acc: 98.525% | Wgt Acc: 98.548%
	I - Batch: 300 | Loss: 1.419 | Acc: 98.500% | Wgt Acc: 98.521%
	I - Batch: 350 | Loss: 1.424 | Acc: 98.446% | Wgt Acc: 98.441%
I - num batch: 364
I - Train -- Loss: 1.423 | Acc: 98.435% | Wgt Acc: 98.449% | LR: 1.250000e-04 | Dur: 225.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    2.    1.    4.   18.]
 [   3.  657.    0.    0.    4.]
 [   1.    1.  965.    2.   15.]
 [   2.    1.    3.  705.    6.]
 [   9.    7.    5.    7. 2720.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.872 | Acc: 52.375% | Wgt Acc: 46.704%
I - num batch: 87
I - Val -- Loss: 5.790 | Acc: 57.830% | Wgt Acc: 50.164% | Dur: 41.18s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   3.  14.  32.  19.]
 [  0.  96.   8.   5.   4.]
 [  2.  36. 116.  14.  23.]
 [ 16.  12.  11.  85.  18.]
 [ 40. 121. 141.  68. 367.]]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 1.432 | Acc: 98.625% | Wgt Acc: 98.374%
	I - Batch: 100 | Loss: 1.395 | Acc: 98.938% | Wgt Acc: 98.950%
	I - Batch: 150 | Loss: 1.397 | Acc: 98.958% | Wgt Acc: 98.963%
	I - Batch: 200 | Loss: 1.389 | Acc: 99.000% | Wgt Acc: 99.086%
	I - Batch: 250 | Loss: 1.384 | Acc: 99.000% | Wgt Acc: 99.095%
	I - Batch: 300 | Loss: 1.398 | Acc: 98.833% | Wgt Acc: 98.868%
	I - Batch: 350 | Loss: 1.398 | Acc: 98.768% | Wgt Acc: 98.837%
I - num batch: 364
I - Train -- Loss: 1.399 | Acc: 98.727% | Wgt Acc: 98.835% | LR: 1.250000e-04 | Dur: 225.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    2.    3.    2.   12.]
 [   1.  661.    0.    1.    5.]
 [   0.    0.  967.    2.   15.]
 [   0.    2.    0.  708.    9.]
 [   8.    3.    4.    5. 2722.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.980 | Acc: 46.250% | Wgt Acc: 39.365%
I - num batch: 87
I - Val -- Loss: 5.856 | Acc: 53.448% | Wgt Acc: 44.715% | Dur: 41.20s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   4.  14.  26.  17.]
 [  0.  74.  10.   0.   3.]
 [  2.  27.  80.   2.  10.]
 [ 39.  25.  32. 111.  41.]
 [ 39. 138. 154.  65. 360.]]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 1.462 | Acc: 98.375% | Wgt Acc: 97.796%
	I - Batch: 100 | Loss: 1.432 | Acc: 98.688% | Wgt Acc: 98.375%
	I - Batch: 150 | Loss: 1.424 | Acc: 98.667% | Wgt Acc: 98.363%
	I - Batch: 200 | Loss: 1.442 | Acc: 98.344% | Wgt Acc: 98.059%
	I - Batch: 250 | Loss: 1.436 | Acc: 98.375% | Wgt Acc: 98.177%
	I - Batch: 300 | Loss: 1.436 | Acc: 98.354% | Wgt Acc: 98.209%
	I - Batch: 350 | Loss: 1.430 | Acc: 98.464% | Wgt Acc: 98.333%
I - num batch: 364
I - Train -- Loss: 1.430 | Acc: 98.487% | Wgt Acc: 98.339% | LR: 1.250000e-04 | Dur: 225.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    3.    5.    8.]
 [   5.  654.    0.    1.    1.]
 [   3.    0.  967.    2.   14.]
 [   2.    2.    1.  698.    8.]
 [   6.   10.    3.   12. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.863 | Acc: 52.375% | Wgt Acc: 46.478%
I - num batch: 87
I - Val -- Loss: 5.785 | Acc: 59.339% | Wgt Acc: 51.349% | Dur: 41.21s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   2.  15.  15.  12.]
 [  1. 132.  31.   8.   6.]
 [  4.  16.  89.  11.  12.]
 [ 21.  12.  13.  97.  16.]
 [ 50. 106. 142.  73. 385.]]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 1.440 | Acc: 97.625% | Wgt Acc: 97.921%
	I - Batch: 100 | Loss: 1.423 | Acc: 98.125% | Wgt Acc: 98.263%
	I - Batch: 150 | Loss: 1.425 | Acc: 98.333% | Wgt Acc: 98.343%
	I - Batch: 200 | Loss: 1.421 | Acc: 98.438% | Wgt Acc: 98.378%
	I - Batch: 250 | Loss: 1.420 | Acc: 98.500% | Wgt Acc: 98.441%
	I - Batch: 300 | Loss: 1.410 | Acc: 98.646% | Wgt Acc: 98.604%
	I - Batch: 350 | Loss: 1.408 | Acc: 98.661% | Wgt Acc: 98.635%
I - num batch: 364
I - Train -- Loss: 1.413 | Acc: 98.607% | Wgt Acc: 98.549% | LR: 1.250000e-04 | Dur: 225.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    3.    1.    2.    9.]
 [   3.  658.    0.    1.    2.]
 [   1.    0.  963.    1.   14.]
 [   1.    2.    3.  707.    9.]
 [  10.    5.    7.    7. 2729.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.828 | Acc: 53.000% | Wgt Acc: 47.452%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 57.615% | Wgt Acc: 51.058% | Dur: 41.28s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   7.  20.  27.  27.]
 [  1. 112.  18.   4.   5.]
 [  2.  46.  92.  11.  15.]
 [ 34.  23.  30. 117.  39.]
 [ 26.  80. 130.  45. 345.]]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 1.477 | Acc: 97.750% | Wgt Acc: 97.610%
	I - Batch: 100 | Loss: 1.443 | Acc: 98.250% | Wgt Acc: 98.153%
	I - Batch: 150 | Loss: 1.430 | Acc: 98.417% | Wgt Acc: 98.354%
	I - Batch: 200 | Loss: 1.424 | Acc: 98.438% | Wgt Acc: 98.346%
	I - Batch: 250 | Loss: 1.421 | Acc: 98.450% | Wgt Acc: 98.407%
	I - Batch: 300 | Loss: 1.422 | Acc: 98.375% | Wgt Acc: 98.387%
	I - Batch: 350 | Loss: 1.424 | Acc: 98.339% | Wgt Acc: 98.373%
I - num batch: 364
I - Train -- Loss: 1.424 | Acc: 98.332% | Wgt Acc: 98.367% | LR: 1.250000e-04 | Dur: 224.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    2.    1.    5.   13.]
 [   0.  658.    0.    0.    8.]
 [   1.    2.  967.    0.    9.]
 [   6.    1.    2.  703.   16.]
 [  12.    5.    4.   10. 2717.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.856 | Acc: 52.625% | Wgt Acc: 47.292%
I - num batch: 87
I - Val -- Loss: 5.784 | Acc: 57.040% | Wgt Acc: 50.246% | Dur: 41.14s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   9.  14.  27.  28.]
 [  0.  90.  16.   3.   2.]
 [  2.  47. 119.  11.  19.]
 [ 34.  15.  29. 112.  36.]
 [ 36. 107. 112.  51. 346.]]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 1.440 | Acc: 98.375% | Wgt Acc: 97.904%
	I - Batch: 100 | Loss: 1.398 | Acc: 99.000% | Wgt Acc: 98.849%
	I - Batch: 150 | Loss: 1.405 | Acc: 98.917% | Wgt Acc: 98.756%
	I - Batch: 200 | Loss: 1.392 | Acc: 99.031% | Wgt Acc: 98.954%
	I - Batch: 250 | Loss: 1.396 | Acc: 99.000% | Wgt Acc: 98.864%
	I - Batch: 300 | Loss: 1.390 | Acc: 99.104% | Wgt Acc: 98.981%
	I - Batch: 350 | Loss: 1.392 | Acc: 99.071% | Wgt Acc: 98.935%
I - num batch: 364
I - Train -- Loss: 1.398 | Acc: 99.020% | Wgt Acc: 98.884% | LR: 1.250000e-04 | Dur: 225.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    2.    2.    3.    4.]
 [   1.  661.    0.    0.    4.]
 [   1.    1.  967.    1.    5.]
 [   4.    1.    1.  706.    4.]
 [   8.    3.    4.    8. 2746.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.863 | Acc: 51.125% | Wgt Acc: 45.889%
I - num batch: 87
I - Val -- Loss: 5.789 | Acc: 55.244% | Wgt Acc: 48.644% | Dur: 41.21s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   9.  21.  41.  34.]
 [  0.  86.  16.   2.   3.]
 [  3.  44. 102.  13.  20.]
 [ 26.  22.  20. 108.  42.]
 [ 29. 107. 131.  40. 332.]]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 1.380 | Acc: 99.500% | Wgt Acc: 99.283%
	I - Batch: 100 | Loss: 1.369 | Acc: 99.438% | Wgt Acc: 99.373%
	I - Batch: 150 | Loss: 1.395 | Acc: 99.083% | Wgt Acc: 98.870%
	I - Batch: 200 | Loss: 1.396 | Acc: 99.000% | Wgt Acc: 98.839%
	I - Batch: 250 | Loss: 1.393 | Acc: 99.025% | Wgt Acc: 98.922%
	I - Batch: 300 | Loss: 1.393 | Acc: 99.042% | Wgt Acc: 98.922%
	I - Batch: 350 | Loss: 1.396 | Acc: 98.982% | Wgt Acc: 98.847%
I - num batch: 364
I - Train -- Loss: 1.398 | Acc: 98.951% | Wgt Acc: 98.793% | LR: 1.250000e-04 | Dur: 224.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    2.    3.    3.    1.]
 [   3.  659.    1.    2.    4.]
 [   1.    1.  966.    0.    8.]
 [   1.    1.    1.  705.    5.]
 [   8.    5.    3.    8. 2745.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.820 | Acc: 50.625% | Wgt Acc: 45.062%
I - num batch: 87
I - Val -- Loss: 5.753 | Acc: 56.394% | Wgt Acc: 49.553% | Dur: 40.94s
I - Confusion Matrix: [row->prediction - col->label]
[[147.  24.  29.  49.  37.]
 [  0. 108.  27.   3.   9.]
 [  4.  25.  88.   5.   9.]
 [ 13.  20.  26.  97.  31.]
 [ 35.  91. 120.  50. 345.]]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 1.425 | Acc: 98.750% | Wgt Acc: 98.415%
	I - Batch: 100 | Loss: 1.433 | Acc: 98.625% | Wgt Acc: 98.260%
	I - Batch: 150 | Loss: 1.415 | Acc: 98.792% | Wgt Acc: 98.536%
	I - Batch: 200 | Loss: 1.418 | Acc: 98.719% | Wgt Acc: 98.495%
	I - Batch: 250 | Loss: 1.420 | Acc: 98.625% | Wgt Acc: 98.529%
	I - Batch: 300 | Loss: 1.412 | Acc: 98.812% | Wgt Acc: 98.703%
	I - Batch: 350 | Loss: 1.407 | Acc: 98.857% | Wgt Acc: 98.787%
I - num batch: 364
I - Train -- Loss: 1.405 | Acc: 98.882% | Wgt Acc: 98.821% | LR: 1.250000e-04 | Dur: 223.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    2.    3.   12.]
 [   3.  657.    0.    0.    6.]
 [   1.    1.  967.    0.    8.]
 [   2.    2.    2.  710.    1.]
 [   6.    6.    3.    5. 2736.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.752 | Acc: 55.625% | Wgt Acc: 51.636%
I - num batch: 87
I - Val -- Loss: 5.709 | Acc: 59.770% | Wgt Acc: 54.685% | Dur: 40.89s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   9.  21.  39.  26.]
 [  2. 132.  39.   4.  11.]
 [  5.  34. 109.  10.  24.]
 [ 27.  20.  37. 116.  37.]
 [ 23.  73.  84.  35. 333.]]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 1.371 | Acc: 99.250% | Wgt Acc: 98.882%
	I - Batch: 100 | Loss: 1.417 | Acc: 98.250% | Wgt Acc: 98.351%
	I - Batch: 150 | Loss: 1.419 | Acc: 98.333% | Wgt Acc: 98.319%
	I - Batch: 200 | Loss: 1.416 | Acc: 98.406% | Wgt Acc: 98.376%
	I - Batch: 250 | Loss: 1.415 | Acc: 98.550% | Wgt Acc: 98.509%
	I - Batch: 300 | Loss: 1.419 | Acc: 98.417% | Wgt Acc: 98.402%
	I - Batch: 350 | Loss: 1.414 | Acc: 98.536% | Wgt Acc: 98.536%
I - num batch: 364
I - Train -- Loss: 1.413 | Acc: 98.555% | Wgt Acc: 98.550% | LR: 1.250000e-04 | Dur: 224.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    2.    3.   10.]
 [   3.  658.    0.    1.    7.]
 [   1.    0.  967.    1.   10.]
 [   2.    2.    1.  701.   11.]
 [   6.    6.    4.   12. 2725.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.825 | Acc: 53.750% | Wgt Acc: 49.075%
I - num batch: 87
I - Val -- Loss: 5.760 | Acc: 58.549% | Wgt Acc: 52.432% | Dur: 40.90s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   9.  15.  34.  22.]
 [  2. 156.  55.   7.  26.]
 [  2.  15.  85.  12.  14.]
 [ 15.  12.  10.  86.  15.]
 [ 46.  76. 125.  65. 354.]]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 1.405 | Acc: 98.750% | Wgt Acc: 98.679%
	I - Batch: 100 | Loss: 1.418 | Acc: 98.562% | Wgt Acc: 98.582%
	I - Batch: 150 | Loss: 1.419 | Acc: 98.667% | Wgt Acc: 98.613%
	I - Batch: 200 | Loss: 1.427 | Acc: 98.469% | Wgt Acc: 98.427%
	I - Batch: 250 | Loss: 1.426 | Acc: 98.550% | Wgt Acc: 98.437%
	I - Batch: 300 | Loss: 1.424 | Acc: 98.562% | Wgt Acc: 98.446%
	I - Batch: 350 | Loss: 1.413 | Acc: 98.696% | Wgt Acc: 98.613%
I - num batch: 364
I - Train -- Loss: 1.413 | Acc: 98.710% | Wgt Acc: 98.634% | LR: 1.250000e-04 | Dur: 224.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    2.    3.    7.]
 [   1.  659.    0.    1.    5.]
 [   4.    2.  963.    0.    9.]
 [   0.    1.    1.  704.    9.]
 [   6.    4.    8.   10. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.895 | Acc: 51.750% | Wgt Acc: 45.730%
I - num batch: 87
I - Val -- Loss: 5.801 | Acc: 57.902% | Wgt Acc: 50.544% | Dur: 40.92s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   6.  24.  21.  21.]
 [  0.  97.  18.   3.   2.]
 [  2.  28. 101.  12.  15.]
 [ 31.  31.  26. 118.  35.]
 [ 34. 106. 121.  50. 358.]]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 1.390 | Acc: 98.875% | Wgt Acc: 98.867%
	I - Batch: 100 | Loss: 1.429 | Acc: 98.000% | Wgt Acc: 98.354%
	I - Batch: 150 | Loss: 1.415 | Acc: 98.333% | Wgt Acc: 98.587%
	I - Batch: 200 | Loss: 1.415 | Acc: 98.344% | Wgt Acc: 98.516%
	I - Batch: 250 | Loss: 1.416 | Acc: 98.375% | Wgt Acc: 98.465%
	I - Batch: 300 | Loss: 1.414 | Acc: 98.438% | Wgt Acc: 98.483%
	I - Batch: 350 | Loss: 1.409 | Acc: 98.589% | Wgt Acc: 98.600%
I - num batch: 364
I - Train -- Loss: 1.408 | Acc: 98.624% | Wgt Acc: 98.631% | LR: 1.250000e-04 | Dur: 223.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    3.    3.    3.    7.]
 [   1.  660.    1.    0.    4.]
 [   1.    1.  965.    3.   19.]
 [   0.    1.    0.  704.    7.]
 [  10.    3.    5.    8. 2726.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.771 | Acc: 55.750% | Wgt Acc: 51.954%
I - num batch: 87
I - Val -- Loss: 5.722 | Acc: 60.201% | Wgt Acc: 55.126% | Dur: 40.83s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   8.  18.  24.  16.]
 [  0. 114.  22.   2.  10.]
 [  4.  42. 122.  11.  21.]
 [ 34.  28.  43. 134.  54.]
 [ 23.  76.  85.  33. 330.]]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 1.348 | Acc: 99.625% | Wgt Acc: 99.568%
	I - Batch: 100 | Loss: 1.388 | Acc: 99.125% | Wgt Acc: 98.957%
	I - Batch: 150 | Loss: 1.381 | Acc: 99.250% | Wgt Acc: 99.167%
	I - Batch: 200 | Loss: 1.388 | Acc: 99.125% | Wgt Acc: 99.016%
	I - Batch: 250 | Loss: 1.396 | Acc: 98.975% | Wgt Acc: 98.816%
	I - Batch: 300 | Loss: 1.398 | Acc: 98.958% | Wgt Acc: 98.779%
	I - Batch: 350 | Loss: 1.393 | Acc: 99.018% | Wgt Acc: 98.841%
I - num batch: 364
I - Train -- Loss: 1.391 | Acc: 99.037% | Wgt Acc: 98.878% | LR: 1.250000e-04 | Dur: 225.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    3.    3.    1.]
 [   2.  659.    0.    0.    1.]
 [   1.    0.  966.    1.    7.]
 [   1.    2.    1.  706.    7.]
 [   7.    5.    4.    8. 2747.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.928 | Acc: 50.875% | Wgt Acc: 44.376%
I - num batch: 87
I - Val -- Loss: 5.818 | Acc: 56.681% | Wgt Acc: 48.098% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   6.  16.  20.  18.]
 [  0.  99.  17.   1.   6.]
 [  3.  30.  97.   6.  10.]
 [ 16.   8.  16.  90.  18.]
 [ 56. 125. 144.  87. 379.]]

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 1.360 | Acc: 99.500% | Wgt Acc: 99.514%
	I - Batch: 100 | Loss: 1.365 | Acc: 99.375% | Wgt Acc: 99.419%
	I - Batch: 150 | Loss: 1.371 | Acc: 99.292% | Wgt Acc: 99.313%
	I - Batch: 200 | Loss: 1.382 | Acc: 99.156% | Wgt Acc: 99.100%
	I - Batch: 250 | Loss: 1.375 | Acc: 99.250% | Wgt Acc: 99.192%
	I - Batch: 300 | Loss: 1.376 | Acc: 99.250% | Wgt Acc: 99.162%
	I - Batch: 350 | Loss: 1.376 | Acc: 99.268% | Wgt Acc: 99.157%
I - num batch: 364
I - Train -- Loss: 1.377 | Acc: 99.261% | Wgt Acc: 99.140% | LR: 1.250000e-04 | Dur: 228.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    3.    4.    4.    4.]
 [   2.  662.    0.    0.    1.]
 [   1.    0.  968.    0.    5.]
 [   0.    1.    1.  707.    2.]
 [   5.    2.    1.    7. 2751.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.875 | Acc: 53.500% | Wgt Acc: 47.329%
I - num batch: 87
I - Val -- Loss: 5.790 | Acc: 59.052% | Wgt Acc: 51.190% | Dur: 41.86s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   8.  17.  29.  22.]
 [  0. 107.  19.   3.   5.]
 [  2.  31.  93.   4.   9.]
 [ 13.  16.  11. 105.  22.]
 [ 40. 106. 150.  63. 373.]]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 1.368 | Acc: 99.375% | Wgt Acc: 99.205%
	I - Batch: 100 | Loss: 1.386 | Acc: 99.125% | Wgt Acc: 98.993%
	I - Batch: 150 | Loss: 1.388 | Acc: 99.042% | Wgt Acc: 98.864%
	I - Batch: 200 | Loss: 1.389 | Acc: 99.000% | Wgt Acc: 98.860%
	I - Batch: 250 | Loss: 1.396 | Acc: 98.900% | Wgt Acc: 98.782%
	I - Batch: 300 | Loss: 1.390 | Acc: 99.000% | Wgt Acc: 98.921%
	I - Batch: 350 | Loss: 1.394 | Acc: 98.964% | Wgt Acc: 98.883%
I - num batch: 364
I - Train -- Loss: 1.394 | Acc: 98.968% | Wgt Acc: 98.876% | LR: 1.250000e-04 | Dur: 227.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    3.    0.    4.    3.]
 [   2.  658.    1.    1.    4.]
 [   3.    2.  969.    0.    8.]
 [   0.    1.    3.  703.    7.]
 [   3.    4.    1.   10. 2741.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.900 | Acc: 52.000% | Wgt Acc: 46.545%
I - num batch: 87
I - Val -- Loss: 5.799 | Acc: 57.687% | Wgt Acc: 50.764% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   5.  13.  27.  19.]
 [  0. 113.  21.   1.   3.]
 [  2.  23.  84.  10.  10.]
 [ 41.  30.  40. 129.  48.]
 [ 30.  97. 132.  37. 351.]]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 1.383 | Acc: 99.000% | Wgt Acc: 99.117%
	I - Batch: 100 | Loss: 1.369 | Acc: 99.250% | Wgt Acc: 99.385%
	I - Batch: 150 | Loss: 1.368 | Acc: 99.333% | Wgt Acc: 99.387%
	I - Batch: 200 | Loss: 1.385 | Acc: 99.031% | Wgt Acc: 99.099%
	I - Batch: 250 | Loss: 1.387 | Acc: 99.025% | Wgt Acc: 99.056%
	I - Batch: 300 | Loss: 1.393 | Acc: 98.958% | Wgt Acc: 98.892%
	I - Batch: 350 | Loss: 1.389 | Acc: 99.018% | Wgt Acc: 98.982%
I - num batch: 364
I - Train -- Loss: 1.388 | Acc: 99.020% | Wgt Acc: 98.989% | LR: 1.250000e-04 | Dur: 228.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    2.    1.    1.    8.]
 [   3.  659.    0.    0.    2.]
 [   2.    1.  968.    2.   13.]
 [   0.    1.    1.  710.    2.]
 [   4.    5.    4.    5. 2738.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.794 | Acc: 52.625% | Wgt Acc: 47.017%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 57.974% | Wgt Acc: 50.811% | Dur: 41.99s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   2.  16.  21.  14.]
 [  0. 109.  19.   3.   9.]
 [  7.  53. 123.  16.  24.]
 [ 18.  13.  14.  96.  20.]
 [ 59.  91. 118.  68. 364.]]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 1.399 | Acc: 98.625% | Wgt Acc: 98.831%
	I - Batch: 100 | Loss: 1.399 | Acc: 98.625% | Wgt Acc: 98.835%
	I - Batch: 150 | Loss: 1.407 | Acc: 98.583% | Wgt Acc: 98.707%
	I - Batch: 200 | Loss: 1.416 | Acc: 98.594% | Wgt Acc: 98.644%
	I - Batch: 250 | Loss: 1.421 | Acc: 98.450% | Wgt Acc: 98.541%
	I - Batch: 300 | Loss: 1.417 | Acc: 98.562% | Wgt Acc: 98.655%
	I - Batch: 350 | Loss: 1.422 | Acc: 98.518% | Wgt Acc: 98.576%
I - num batch: 364
I - Train -- Loss: 1.423 | Acc: 98.521% | Wgt Acc: 98.569% | LR: 1.250000e-04 | Dur: 228.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    2.    2.    5.    9.]
 [   2.  655.    0.    1.   13.]
 [   0.    3.  966.    1.   15.]
 [   1.    0.    5.  707.    7.]
 [   7.    8.    1.    4. 2719.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.860 | Acc: 52.125% | Wgt Acc: 46.576%
I - num batch: 87
I - Val -- Loss: 5.779 | Acc: 57.687% | Wgt Acc: 50.671% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.  19.  19.  16.]
 [  2. 108.  20.   2.   7.]
 [  2.  30.  93.   9.  17.]
 [ 30.  21.  24. 120.  38.]
 [ 36. 106. 134.  54. 353.]]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 1.394 | Acc: 98.750% | Wgt Acc: 99.056%
	I - Batch: 100 | Loss: 1.464 | Acc: 97.438% | Wgt Acc: 97.501%
	I - Batch: 150 | Loss: 1.457 | Acc: 97.625% | Wgt Acc: 97.575%
	I - Batch: 200 | Loss: 1.463 | Acc: 97.500% | Wgt Acc: 97.640%
	I - Batch: 250 | Loss: 1.471 | Acc: 97.425% | Wgt Acc: 97.533%
	I - Batch: 300 | Loss: 1.481 | Acc: 97.250% | Wgt Acc: 97.373%
	I - Batch: 350 | Loss: 1.478 | Acc: 97.304% | Wgt Acc: 97.427%
I - num batch: 364
I - Train -- Loss: 1.478 | Acc: 97.317% | Wgt Acc: 97.441% | LR: 1.250000e-04 | Dur: 228.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    2.    4.   10.   26.]
 [   4.  657.    1.    2.   11.]
 [   1.    3.  962.    2.   20.]
 [   9.    1.    0.  691.   20.]
 [  15.    5.    7.   13. 2686.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.753 | Acc: 56.875% | Wgt Acc: 52.371%
I - num batch: 87
I - Val -- Loss: 5.719 | Acc: 59.267% | Wgt Acc: 53.969% | Dur: 41.93s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   9.  19.  30.  22.]
 [  1. 120.  23.   4.  10.]
 [  3.  29. 112.  11.  17.]
 [ 36.  21.  35. 130.  50.]
 [ 28.  89. 101.  29. 332.]]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 1.423 | Acc: 98.750% | Wgt Acc: 98.856%
	I - Batch: 100 | Loss: 1.447 | Acc: 98.375% | Wgt Acc: 98.303%
	I - Batch: 150 | Loss: 1.441 | Acc: 98.375% | Wgt Acc: 98.272%
	I - Batch: 200 | Loss: 1.451 | Acc: 97.969% | Wgt Acc: 97.927%
	I - Batch: 250 | Loss: 1.471 | Acc: 97.400% | Wgt Acc: 97.608%
	I - Batch: 300 | Loss: 1.470 | Acc: 97.458% | Wgt Acc: 97.624%
	I - Batch: 350 | Loss: 1.468 | Acc: 97.518% | Wgt Acc: 97.636%
I - num batch: 364
I - Train -- Loss: 1.466 | Acc: 97.558% | Wgt Acc: 97.680% | LR: 1.250000e-04 | Dur: 228.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    2.    4.    6.   17.]
 [   1.  656.    1.    1.   18.]
 [   1.    1.  961.    2.   20.]
 [   6.    3.    3.  696.   17.]
 [  15.    6.    5.   13. 2691.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.833 | Acc: 53.875% | Wgt Acc: 48.193%
I - num batch: 87
I - Val -- Loss: 5.759 | Acc: 58.621% | Wgt Acc: 51.705% | Dur: 41.89s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   5.  21.  38.  27.]
 [  0. 111.  16.   4.   3.]
 [  3.  34. 112.  11.  12.]
 [ 24.  16.  15. 100.  30.]
 [ 38. 102. 126.  51. 359.]]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 1.371 | Acc: 99.625% | Wgt Acc: 99.676%
	I - Batch: 100 | Loss: 1.382 | Acc: 99.312% | Wgt Acc: 99.288%
	I - Batch: 150 | Loss: 1.406 | Acc: 98.833% | Wgt Acc: 98.760%
	I - Batch: 200 | Loss: 1.408 | Acc: 98.719% | Wgt Acc: 98.706%
	I - Batch: 250 | Loss: 1.414 | Acc: 98.700% | Wgt Acc: 98.659%
	I - Batch: 300 | Loss: 1.417 | Acc: 98.667% | Wgt Acc: 98.583%
	I - Batch: 350 | Loss: 1.419 | Acc: 98.500% | Wgt Acc: 98.508%
I - num batch: 364
I - Train -- Loss: 1.420 | Acc: 98.452% | Wgt Acc: 98.483% | LR: 1.250000e-04 | Dur: 228.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    3.    5.   13.]
 [   2.  659.    0.    2.    5.]
 [   3.    1.  965.    0.   12.]
 [   1.    0.    3.  700.   13.]
 [   5.    6.    3.   11. 2720.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.860 | Acc: 53.625% | Wgt Acc: 47.862%
I - num batch: 87
I - Val -- Loss: 5.777 | Acc: 58.477% | Wgt Acc: 50.873% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   4.  14.  25.  18.]
 [  1.  99.  17.   2.   6.]
 [  6.  45. 122.   8.  24.]
 [ 21.   8.   8.  99.  13.]
 [ 47. 112. 129.  70. 370.]]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 1.391 | Acc: 99.000% | Wgt Acc: 98.990%
	I - Batch: 100 | Loss: 1.390 | Acc: 98.875% | Wgt Acc: 99.002%
	I - Batch: 150 | Loss: 1.396 | Acc: 98.875% | Wgt Acc: 98.911%
	I - Batch: 200 | Loss: 1.399 | Acc: 98.844% | Wgt Acc: 98.808%
	I - Batch: 250 | Loss: 1.396 | Acc: 98.900% | Wgt Acc: 98.846%
	I - Batch: 300 | Loss: 1.396 | Acc: 98.979% | Wgt Acc: 98.888%
	I - Batch: 350 | Loss: 1.408 | Acc: 98.696% | Wgt Acc: 98.618%
I - num batch: 364
I - Train -- Loss: 1.412 | Acc: 98.641% | Wgt Acc: 98.557% | LR: 1.250000e-04 | Dur: 228.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    2.    1.    3.    8.]
 [   0.  661.    0.    1.    2.]
 [   2.    0.  964.    2.   12.]
 [   0.    1.    4.  699.    8.]
 [  11.    4.    5.   13. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.804 | Acc: 53.250% | Wgt Acc: 47.752%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 58.190% | Wgt Acc: 51.244% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.  13.  27.  12.]
 [  1. 101.  17.   6.   3.]
 [  2.  42. 118.   8.  18.]
 [ 33.  28.  27. 118.  42.]
 [ 46.  95. 115.  45. 356.]]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 1.370 | Acc: 98.875% | Wgt Acc: 98.824%
	I - Batch: 100 | Loss: 1.392 | Acc: 98.875% | Wgt Acc: 98.765%
	I - Batch: 150 | Loss: 1.407 | Acc: 98.833% | Wgt Acc: 98.662%
	I - Batch: 200 | Loss: 1.406 | Acc: 98.875% | Wgt Acc: 98.725%
	I - Batch: 250 | Loss: 1.401 | Acc: 98.925% | Wgt Acc: 98.826%
	I - Batch: 300 | Loss: 1.396 | Acc: 98.938% | Wgt Acc: 98.866%
	I - Batch: 350 | Loss: 1.399 | Acc: 98.875% | Wgt Acc: 98.820%
I - num batch: 364
I - Train -- Loss: 1.401 | Acc: 98.865% | Wgt Acc: 98.810% | LR: 1.250000e-04 | Dur: 231.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    3.    1.    2.    4.]
 [   3.  658.    0.    0.    1.]
 [   1.    2.  969.    1.    7.]
 [   2.    1.    3.  705.   15.]
 [   5.    4.    1.   10. 2736.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.814 | Acc: 52.375% | Wgt Acc: 46.937%
I - num batch: 87
I - Val -- Loss: 5.759 | Acc: 57.399% | Wgt Acc: 50.459% | Dur: 43.13s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   7.  30.  59.  37.]
 [  0. 104.  16.   4.   5.]
 [  3.  33. 105.  14.  16.]
 [ 15.  18.  25.  88.  21.]
 [ 31. 106. 114.  39. 352.]]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 1.415 | Acc: 98.875% | Wgt Acc: 98.781%
	I - Batch: 100 | Loss: 1.394 | Acc: 99.000% | Wgt Acc: 99.047%
	I - Batch: 150 | Loss: 1.399 | Acc: 98.792% | Wgt Acc: 98.914%
	I - Batch: 200 | Loss: 1.402 | Acc: 98.781% | Wgt Acc: 98.822%
	I - Batch: 250 | Loss: 1.409 | Acc: 98.550% | Wgt Acc: 98.657%
	I - Batch: 300 | Loss: 1.418 | Acc: 98.375% | Wgt Acc: 98.473%
	I - Batch: 350 | Loss: 1.417 | Acc: 98.411% | Wgt Acc: 98.473%
I - num batch: 364
I - Train -- Loss: 1.421 | Acc: 98.332% | Wgt Acc: 98.411% | LR: 1.250000e-04 | Dur: 233.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    2.    4.   10.]
 [   1.  659.    1.    0.    8.]
 [   1.    0.  966.    0.   23.]
 [   2.    0.    0.  703.    8.]
 [  12.    7.    5.   11. 2714.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.949 | Acc: 49.750% | Wgt Acc: 43.010%
I - num batch: 87
I - Val -- Loss: 5.848 | Acc: 55.603% | Wgt Acc: 47.010% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   2.  14.  50.  28.]
 [  0.  79.   9.   1.   1.]
 [  3.  34. 107.   5.  14.]
 [ 14.  11.  14.  77.  17.]
 [ 42. 142. 146.  71. 371.]]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 1.393 | Acc: 99.250% | Wgt Acc: 99.016%
	I - Batch: 100 | Loss: 1.402 | Acc: 99.000% | Wgt Acc: 98.793%
	I - Batch: 150 | Loss: 1.401 | Acc: 99.000% | Wgt Acc: 98.821%
	I - Batch: 200 | Loss: 1.401 | Acc: 98.906% | Wgt Acc: 98.798%
	I - Batch: 250 | Loss: 1.391 | Acc: 99.075% | Wgt Acc: 98.974%
	I - Batch: 300 | Loss: 1.389 | Acc: 99.042% | Wgt Acc: 98.945%
	I - Batch: 350 | Loss: 1.397 | Acc: 98.911% | Wgt Acc: 98.823%
I - num batch: 364
I - Train -- Loss: 1.404 | Acc: 98.641% | Wgt Acc: 98.680% | LR: 1.250000e-04 | Dur: 231.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    1.    1.    6.]
 [   2.  661.    0.    0.    3.]
 [   0.    0.  963.    1.   26.]
 [   1.    0.    4.  707.    4.]
 [   8.    5.    6.    9. 2724.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.842 | Acc: 54.000% | Wgt Acc: 48.824%
I - num batch: 87
I - Val -- Loss: 5.781 | Acc: 58.693% | Wgt Acc: 52.185% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   8.  19.  46.  26.]
 [  0. 104.  10.   2.   6.]
 [  4.  52. 119.  13.  15.]
 [ 18.  18.  36.  98.  34.]
 [ 31.  86. 106.  45. 350.]]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 1.503 | Acc: 96.750% | Wgt Acc: 96.770%
	I - Batch: 100 | Loss: 1.504 | Acc: 96.562% | Wgt Acc: 96.833%
	I - Batch: 150 | Loss: 1.520 | Acc: 96.250% | Wgt Acc: 96.475%
	I - Batch: 200 | Loss: 1.509 | Acc: 96.625% | Wgt Acc: 96.816%
	I - Batch: 250 | Loss: 1.501 | Acc: 96.750% | Wgt Acc: 96.898%
	I - Batch: 300 | Loss: 1.497 | Acc: 96.896% | Wgt Acc: 97.078%
	I - Batch: 350 | Loss: 1.497 | Acc: 96.875% | Wgt Acc: 97.130%
I - num batch: 364
I - Train -- Loss: 1.495 | Acc: 96.853% | Wgt Acc: 97.100% | LR: 1.250000e-04 | Dur: 231.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    3.    4.    4.   24.]
 [   1.  652.    1.    0.   18.]
 [   5.    3.  946.    0.   41.]
 [   2.    0.    2.  698.   19.]
 [   9.   10.   21.   16. 2661.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.903 | Acc: 48.875% | Wgt Acc: 43.684%
I - num batch: 87
I - Val -- Loss: 5.798 | Acc: 53.879% | Wgt Acc: 47.169% | Dur: 42.88s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   3.  17.  48.  21.]
 [  0.  85.  20.   0.   4.]
 [  1.  39. 101.   4.  35.]
 [ 18.  38.  34.  99.  41.]
 [ 45. 103. 118.  53. 330.]]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 1.435 | Acc: 98.000% | Wgt Acc: 98.803%
	I - Batch: 100 | Loss: 1.431 | Acc: 98.188% | Wgt Acc: 98.606%
	I - Batch: 150 | Loss: 1.433 | Acc: 98.333% | Wgt Acc: 98.554%
	I - Batch: 200 | Loss: 1.440 | Acc: 98.250% | Wgt Acc: 98.400%
	I - Batch: 250 | Loss: 1.429 | Acc: 98.400% | Wgt Acc: 98.518%
	I - Batch: 300 | Loss: 1.423 | Acc: 98.521% | Wgt Acc: 98.586%
	I - Batch: 350 | Loss: 1.422 | Acc: 98.500% | Wgt Acc: 98.577%
I - num batch: 364
I - Train -- Loss: 1.421 | Acc: 98.521% | Wgt Acc: 98.584% | LR: 1.250000e-04 | Dur: 232.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    2.    2.    4.   15.]
 [   2.  661.    2.    0.    8.]
 [   1.    0.  965.    0.   15.]
 [   3.    1.    1.  705.    5.]
 [   8.    4.    4.    9. 2720.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.925 | Acc: 49.875% | Wgt Acc: 43.004%
I - num batch: 87
I - Val -- Loss: 5.823 | Acc: 55.316% | Wgt Acc: 46.271% | Dur: 42.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 85.   2.   7.   8.   7.]
 [  0.  92.  15.   2.   7.]
 [  5.  34.  93.  10.   7.]
 [ 49.  25.  38. 119.  29.]
 [ 60. 115. 137.  65. 381.]]

I - Epoch: 200
I - Training: 
	I - Batch: 50 | Loss: 1.381 | Acc: 99.000% | Wgt Acc: 99.091%
	I - Batch: 100 | Loss: 1.418 | Acc: 98.750% | Wgt Acc: 98.580%
	I - Batch: 150 | Loss: 1.410 | Acc: 98.833% | Wgt Acc: 98.732%
	I - Batch: 200 | Loss: 1.407 | Acc: 98.906% | Wgt Acc: 98.800%
	I - Batch: 250 | Loss: 1.408 | Acc: 98.850% | Wgt Acc: 98.697%
	I - Batch: 300 | Loss: 1.402 | Acc: 98.938% | Wgt Acc: 98.800%
	I - Batch: 350 | Loss: 1.402 | Acc: 98.875% | Wgt Acc: 98.747%
I - num batch: 364
I - Train -- Loss: 1.405 | Acc: 98.831% | Wgt Acc: 98.704% | LR: 1.250000e-04 | Dur: 232.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    4.    3.    3.]
 [   1.  659.    0.    0.    7.]
 [   1.    0.  966.    0.    7.]
 [   1.    0.    0.  706.    6.]
 [  13.    7.    4.    9. 2740.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.004 | Acc: 49.125% | Wgt Acc: 41.650%
I - num batch: 87
I - Val -- Loss: 5.874 | Acc: 55.388% | Wgt Acc: 45.725% | Dur: 42.84s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   0.  11.  22.  14.]
 [  0.  79.  12.   1.   5.]
 [  2.  33.  91.   7.   8.]
 [ 20.  16.  23.  90.  16.]
 [ 54. 140. 153.  84. 388.]]

I - Epoch: 201
I - Training: 
	I - Batch: 50 | Loss: 1.375 | Acc: 99.000% | Wgt Acc: 99.492%
	I - Batch: 100 | Loss: 1.382 | Acc: 98.875% | Wgt Acc: 99.182%
	I - Batch: 150 | Loss: 1.385 | Acc: 98.958% | Wgt Acc: 99.132%
	I - Batch: 200 | Loss: 1.394 | Acc: 98.719% | Wgt Acc: 98.915%
	I - Batch: 250 | Loss: 1.393 | Acc: 98.825% | Wgt Acc: 98.995%
	I - Batch: 300 | Loss: 1.393 | Acc: 98.875% | Wgt Acc: 98.989%
	I - Batch: 350 | Loss: 1.393 | Acc: 98.875% | Wgt Acc: 98.962%
I - num batch: 364
I - Train -- Loss: 1.397 | Acc: 98.848% | Wgt Acc: 98.918% | LR: 1.250000e-04 | Dur: 231.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    2.    3.    3.   18.]
 [   1.  662.    0.    0.    3.]
 [   1.    0.  968.    1.    4.]
 [   2.    0.    3.  706.   10.]
 [   4.    4.    0.    8. 2728.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.863 | Acc: 52.875% | Wgt Acc: 47.047%
I - num batch: 87
I - Val -- Loss: 5.781 | Acc: 58.046% | Wgt Acc: 50.548% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   7.  13.  23.  16.]
 [  2. 106.  13.   3.  10.]
 [  3.  30. 107.  10.  19.]
 [ 24.  15.  26. 108.  20.]
 [ 49. 110. 131.  60. 366.]]

I - Epoch: 202
I - Training: 
	I - Batch: 50 | Loss: 1.368 | Acc: 99.500% | Wgt Acc: 99.377%
	I - Batch: 100 | Loss: 1.390 | Acc: 99.000% | Wgt Acc: 98.915%
	I - Batch: 150 | Loss: 1.393 | Acc: 99.083% | Wgt Acc: 98.912%
	I - Batch: 200 | Loss: 1.392 | Acc: 99.000% | Wgt Acc: 98.926%
	I - Batch: 250 | Loss: 1.391 | Acc: 98.975% | Wgt Acc: 98.885%
	I - Batch: 300 | Loss: 1.389 | Acc: 99.021% | Wgt Acc: 98.931%
	I - Batch: 350 | Loss: 1.388 | Acc: 99.054% | Wgt Acc: 98.970%
I - num batch: 364
I - Train -- Loss: 1.390 | Acc: 99.054% | Wgt Acc: 98.961% | LR: 1.250000e-04 | Dur: 231.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    0.    2.   11.]
 [   1.  661.    0.    0.    3.]
 [   2.    0.  968.    0.    3.]
 [   1.    0.    3.  706.    2.]
 [   7.    5.    3.   10. 2744.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.963 | Acc: 48.750% | Wgt Acc: 41.558%
I - num batch: 87
I - Val -- Loss: 5.858 | Acc: 54.598% | Wgt Acc: 45.029% | Dur: 42.76s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   9.  14.  29.  21.]
 [  0.  71.   7.   0.   2.]
 [  2.  38. 104.   7.  12.]
 [ 14.  11.  11.  71.  12.]
 [ 53. 139. 154.  97. 384.]]

I - Epoch: 203
I - Training: 
	I - Batch: 50 | Loss: 1.395 | Acc: 98.875% | Wgt Acc: 98.538%
	I - Batch: 100 | Loss: 1.395 | Acc: 98.875% | Wgt Acc: 98.733%
	I - Batch: 150 | Loss: 1.386 | Acc: 98.958% | Wgt Acc: 98.914%
	I - Batch: 200 | Loss: 1.388 | Acc: 98.812% | Wgt Acc: 98.841%
	I - Batch: 250 | Loss: 1.405 | Acc: 98.625% | Wgt Acc: 98.637%
	I - Batch: 300 | Loss: 1.412 | Acc: 98.500% | Wgt Acc: 98.470%
	I - Batch: 350 | Loss: 1.421 | Acc: 98.393% | Wgt Acc: 98.391%
I - num batch: 364
I - Train -- Loss: 1.422 | Acc: 98.349% | Wgt Acc: 98.380% | LR: 1.250000e-04 | Dur: 228.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    3.    4.    4.   12.]
 [   1.  656.    1.    1.   16.]
 [   1.    0.  963.    0.    7.]
 [   0.    0.    2.  705.   12.]
 [  11.    9.    4.    8. 2716.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.902 | Acc: 51.750% | Wgt Acc: 46.759%
I - num batch: 87
I - Val -- Loss: 5.807 | Acc: 57.184% | Wgt Acc: 49.894% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   2.  20.  25.  13.]
 [  1. 119.  21.   3.   4.]
 [  2.  28. 100.   4.  27.]
 [ 26.  21.  21. 103.  24.]
 [ 59.  98. 128.  69. 363.]]

I - Epoch: 204
I - Training: 
	I - Batch: 50 | Loss: 1.468 | Acc: 98.000% | Wgt Acc: 97.604%
	I - Batch: 100 | Loss: 1.505 | Acc: 97.062% | Wgt Acc: 97.070%
	I - Batch: 150 | Loss: 1.471 | Acc: 97.583% | Wgt Acc: 97.623%
	I - Batch: 200 | Loss: 1.459 | Acc: 97.781% | Wgt Acc: 97.841%
	I - Batch: 250 | Loss: 1.458 | Acc: 97.800% | Wgt Acc: 97.799%
	I - Batch: 300 | Loss: 1.450 | Acc: 97.917% | Wgt Acc: 97.940%
	I - Batch: 350 | Loss: 1.438 | Acc: 98.071% | Wgt Acc: 98.137%
I - num batch: 364
I - Train -- Loss: 1.436 | Acc: 98.108% | Wgt Acc: 98.168% | LR: 1.250000e-04 | Dur: 229.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    2.    1.    3.    7.]
 [   2.  658.    2.    1.   19.]
 [   0.    0.  962.    1.   13.]
 [   4.    1.    2.  701.   15.]
 [  11.    7.    7.   12. 2709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.836 | Acc: 53.625% | Wgt Acc: 48.401%
I - num batch: 87
I - Val -- Loss: 5.755 | Acc: 58.621% | Wgt Acc: 51.937% | Dur: 42.31s
I - Confusion Matrix: [row->prediction - col->label]
[[132.  13.  17.  29.  25.]
 [  0. 103.  15.   6.   9.]
 [  4.  41. 115.  11.  14.]
 [ 31.  22.  28. 114.  31.]
 [ 32.  89. 115.  44. 352.]]

I - Epoch: 205
I - Training: 
	I - Batch: 50 | Loss: 1.386 | Acc: 99.000% | Wgt Acc: 99.191%
	I - Batch: 100 | Loss: 1.392 | Acc: 99.062% | Wgt Acc: 99.121%
	I - Batch: 150 | Loss: 1.387 | Acc: 99.000% | Wgt Acc: 99.054%
	I - Batch: 200 | Loss: 1.382 | Acc: 99.094% | Wgt Acc: 99.121%
	I - Batch: 250 | Loss: 1.391 | Acc: 98.875% | Wgt Acc: 98.953%
	I - Batch: 300 | Loss: 1.396 | Acc: 98.833% | Wgt Acc: 98.865%
	I - Batch: 350 | Loss: 1.403 | Acc: 98.732% | Wgt Acc: 98.748%
I - num batch: 364
I - Train -- Loss: 1.401 | Acc: 98.779% | Wgt Acc: 98.795% | LR: 1.250000e-04 | Dur: 230.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    2.    3.    3.    7.]
 [   1.  661.    0.    0.    7.]
 [   2.    1.  964.    1.   13.]
 [   0.    0.    5.  706.    7.]
 [   5.    4.    2.    8. 2729.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.861 | Acc: 51.125% | Wgt Acc: 45.546%
I - num batch: 87
I - Val -- Loss: 5.777 | Acc: 57.328% | Wgt Acc: 49.483% | Dur: 42.34s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   1.   8.  17.  15.]
 [  2. 111.  11.   5.   8.]
 [  5.  39. 116.  15.  20.]
 [ 18.  13.   6.  84.  13.]
 [ 62. 104. 149.  83. 375.]]

I - Epoch: 206
I - Training: 
	I - Batch: 50 | Loss: 1.429 | Acc: 98.625% | Wgt Acc: 98.425%
	I - Batch: 100 | Loss: 1.411 | Acc: 98.875% | Wgt Acc: 98.851%
	I - Batch: 150 | Loss: 1.413 | Acc: 98.833% | Wgt Acc: 98.815%
	I - Batch: 200 | Loss: 1.460 | Acc: 97.688% | Wgt Acc: 97.866%
	I - Batch: 250 | Loss: 1.453 | Acc: 97.775% | Wgt Acc: 97.993%
	I - Batch: 300 | Loss: 1.451 | Acc: 97.792% | Wgt Acc: 98.009%
	I - Batch: 350 | Loss: 1.451 | Acc: 97.804% | Wgt Acc: 97.976%
I - num batch: 364
I - Train -- Loss: 1.453 | Acc: 97.799% | Wgt Acc: 97.933% | LR: 1.250000e-04 | Dur: 229.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    2.    2.    6.    9.]
 [   0.  655.    2.    2.   27.]
 [   2.    0.  960.    1.   21.]
 [   4.    1.    5.  701.   11.]
 [  10.   10.    5.    8. 2695.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.859 | Acc: 51.125% | Wgt Acc: 46.043%
I - num batch: 87
I - Val -- Loss: 5.776 | Acc: 57.112% | Wgt Acc: 50.551% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   4.  18.  28.  20.]
 [  0.  98.  12.   1.   6.]
 [  4.  41. 112.   4.  18.]
 [ 38.  29.  32. 126.  44.]
 [ 41.  96. 116.  45. 343.]]

I - Epoch: 207
I - Training: 
	I - Batch: 50 | Loss: 1.421 | Acc: 98.875% | Wgt Acc: 98.815%
	I - Batch: 100 | Loss: 1.418 | Acc: 98.438% | Wgt Acc: 98.687%
	I - Batch: 150 | Loss: 1.413 | Acc: 98.667% | Wgt Acc: 98.819%
	I - Batch: 200 | Loss: 1.410 | Acc: 98.688% | Wgt Acc: 98.808%
	I - Batch: 250 | Loss: 1.413 | Acc: 98.675% | Wgt Acc: 98.748%
	I - Batch: 300 | Loss: 1.403 | Acc: 98.833% | Wgt Acc: 98.891%
	I - Batch: 350 | Loss: 1.400 | Acc: 98.893% | Wgt Acc: 98.946%
I - num batch: 364
I - Train -- Loss: 1.401 | Acc: 98.899% | Wgt Acc: 98.936% | LR: 1.250000e-04 | Dur: 228.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    2.    2.    3.    5.]
 [   1.  663.    0.    2.    5.]
 [   0.    0.  968.    0.   11.]
 [   2.    0.    2.  703.   10.]
 [   4.    3.    2.   10. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.886 | Acc: 52.875% | Wgt Acc: 46.870%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 57.902% | Wgt Acc: 50.103% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[129.  10.  18.  33.  17.]
 [  3. 125.  32.   7.  12.]
 [  3.  19.  77.   3.   8.]
 [ 20.  20.  21. 103.  22.]
 [ 44.  94. 142.  58. 372.]]

I - Epoch: 208
I - Training: 
	I - Batch: 50 | Loss: 1.366 | Acc: 99.375% | Wgt Acc: 99.226%
	I - Batch: 100 | Loss: 1.380 | Acc: 99.062% | Wgt Acc: 98.938%
	I - Batch: 150 | Loss: 1.381 | Acc: 99.125% | Wgt Acc: 99.022%
	I - Batch: 200 | Loss: 1.376 | Acc: 99.250% | Wgt Acc: 99.162%
	I - Batch: 250 | Loss: 1.377 | Acc: 99.175% | Wgt Acc: 99.141%
	I - Batch: 300 | Loss: 1.378 | Acc: 99.167% | Wgt Acc: 99.103%
	I - Batch: 350 | Loss: 1.383 | Acc: 99.054% | Wgt Acc: 99.024%
I - num batch: 364
I - Train -- Loss: 1.385 | Acc: 99.054% | Wgt Acc: 99.005% | LR: 1.250000e-04 | Dur: 229.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    2.    3.    3.    8.]
 [   1.  662.    0.    0.    2.]
 [   1.    0.  967.    2.    7.]
 [   2.    0.    1.  707.    5.]
 [   5.    4.    3.    6. 2741.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.905 | Acc: 51.625% | Wgt Acc: 46.380%
I - num batch: 87
I - Val -- Loss: 5.802 | Acc: 57.902% | Wgt Acc: 50.861% | Dur: 42.47s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   3.  18.  31.  24.]
 [  0. 126.  24.   5.  11.]
 [  2.  22.  93.  10.   9.]
 [ 28.  15.  21. 102.  26.]
 [ 45. 102. 134.  56. 361.]]

I - Epoch: 209
I - Training: 
	I - Batch: 50 | Loss: 1.392 | Acc: 99.125% | Wgt Acc: 98.823%
	I - Batch: 100 | Loss: 1.381 | Acc: 99.250% | Wgt Acc: 99.107%
	I - Batch: 150 | Loss: 1.384 | Acc: 99.250% | Wgt Acc: 99.109%
	I - Batch: 200 | Loss: 1.379 | Acc: 99.219% | Wgt Acc: 99.140%
	I - Batch: 250 | Loss: 1.375 | Acc: 99.300% | Wgt Acc: 99.203%
	I - Batch: 300 | Loss: 1.375 | Acc: 99.292% | Wgt Acc: 99.181%
	I - Batch: 350 | Loss: 1.373 | Acc: 99.304% | Wgt Acc: 99.200%
I - num batch: 364
I - Train -- Loss: 1.373 | Acc: 99.295% | Wgt Acc: 99.183% | LR: 1.250000e-04 | Dur: 230.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    2.    1.    3.    2.]
 [   2.  663.    0.    0.    2.]
 [   1.    0.  970.    2.    3.]
 [   2.    0.    3.  710.    4.]
 [   8.    3.    0.    3. 2752.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.946 | Acc: 51.000% | Wgt Acc: 44.805%
I - num batch: 87
I - Val -- Loss: 5.838 | Acc: 57.040% | Wgt Acc: 49.456% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   9.  25.  32.  27.]
 [  0.  94.  12.   1.   5.]
 [  2.  21.  92.   5.  13.]
 [ 21.  22.  19. 113.  29.]
 [ 38. 122. 142.  53. 357.]]

I - Epoch: 210
I - Training: 
	I - Batch: 50 | Loss: 1.419 | Acc: 98.375% | Wgt Acc: 98.417%
	I - Batch: 100 | Loss: 1.393 | Acc: 98.938% | Wgt Acc: 98.848%
	I - Batch: 150 | Loss: 1.388 | Acc: 99.042% | Wgt Acc: 98.929%
	I - Batch: 200 | Loss: 1.390 | Acc: 98.938% | Wgt Acc: 98.910%
	I - Batch: 250 | Loss: 1.386 | Acc: 99.025% | Wgt Acc: 98.993%
	I - Batch: 300 | Loss: 1.386 | Acc: 99.062% | Wgt Acc: 99.001%
	I - Batch: 350 | Loss: 1.383 | Acc: 99.107% | Wgt Acc: 99.049%
I - num batch: 364
I - Train -- Loss: 1.381 | Acc: 99.140% | Wgt Acc: 99.082% | LR: 1.250000e-04 | Dur: 230.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    2.    2.    3.    3.]
 [   1.  663.    0.    1.    4.]
 [   2.    0.  967.    0.   11.]
 [   1.    0.    1.  707.    1.]
 [   4.    3.    4.    7. 2744.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.905 | Acc: 50.000% | Wgt Acc: 44.235%
I - num batch: 87
I - Val -- Loss: 5.810 | Acc: 56.178% | Wgt Acc: 48.307% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   1.  20.  31.  25.]
 [  0. 115.  18.   1.   6.]
 [  2.  17.  81.   7.   8.]
 [ 32.  21.  22. 100.  26.]
 [ 45. 114. 149.  65. 366.]]

I - Epoch: 211
I - Training: 
	I - Batch: 50 | Loss: 1.349 | Acc: 99.750% | Wgt Acc: 99.624%
	I - Batch: 100 | Loss: 1.375 | Acc: 99.375% | Wgt Acc: 99.127%
	I - Batch: 150 | Loss: 1.376 | Acc: 99.375% | Wgt Acc: 99.124%
	I - Batch: 200 | Loss: 1.383 | Acc: 99.281% | Wgt Acc: 99.052%
	I - Batch: 250 | Loss: 1.375 | Acc: 99.375% | Wgt Acc: 99.198%
	I - Batch: 300 | Loss: 1.371 | Acc: 99.417% | Wgt Acc: 99.267%
	I - Batch: 350 | Loss: 1.381 | Acc: 99.196% | Wgt Acc: 99.060%
I - num batch: 364
I - Train -- Loss: 1.383 | Acc: 99.192% | Wgt Acc: 99.044% | LR: 1.250000e-04 | Dur: 230.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    2.    1.    2.    5.]
 [   1.  661.    0.    1.    4.]
 [   0.    0.  968.    0.    2.]
 [   3.    0.    1.  709.    1.]
 [   9.    5.    4.    6. 2751.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.796 | Acc: 54.500% | Wgt Acc: 50.239%
I - num batch: 87
I - Val -- Loss: 5.758 | Acc: 56.753% | Wgt Acc: 51.264% | Dur: 42.72s
I - Confusion Matrix: [row->prediction - col->label]
[[150.  14.  25.  53.  47.]
 [  2. 124.  28.   6.   8.]
 [  4.  25. 100.  14.  27.]
 [ 17.  15.  19.  88.  21.]
 [ 26.  90. 118.  43. 328.]]

I - Epoch: 212
I - Training: 
	I - Batch: 50 | Loss: 1.392 | Acc: 98.750% | Wgt Acc: 98.652%
	I - Batch: 100 | Loss: 1.422 | Acc: 98.438% | Wgt Acc: 98.350%
	I - Batch: 150 | Loss: 1.409 | Acc: 98.750% | Wgt Acc: 98.619%
	I - Batch: 200 | Loss: 1.411 | Acc: 98.750% | Wgt Acc: 98.604%
	I - Batch: 250 | Loss: 1.426 | Acc: 98.475% | Wgt Acc: 98.328%
	I - Batch: 300 | Loss: 1.422 | Acc: 98.438% | Wgt Acc: 98.378%
	I - Batch: 350 | Loss: 1.421 | Acc: 98.482% | Wgt Acc: 98.374%
I - num batch: 364
I - Train -- Loss: 1.418 | Acc: 98.538% | Wgt Acc: 98.435% | LR: 1.250000e-04 | Dur: 230.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    2.    2.    5.   11.]
 [   4.  657.    2.    2.    7.]
 [   0.    0.  962.    0.    8.]
 [   2.    3.    4.  704.    7.]
 [   9.    6.    4.    7. 2730.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.826 | Acc: 51.625% | Wgt Acc: 46.925%
I - num batch: 87
I - Val -- Loss: 5.771 | Acc: 56.394% | Wgt Acc: 50.385% | Dur: 42.58s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   6.  19.  47.  23.]
 [  1. 100.  14.   1.   6.]
 [  6.  48. 121.  16.  29.]
 [ 25.  24.  29.  97.  40.]
 [ 33.  90. 107.  43. 333.]]

I - Epoch: 213
I - Training: 
	I - Batch: 50 | Loss: 1.420 | Acc: 98.375% | Wgt Acc: 98.401%
	I - Batch: 100 | Loss: 1.422 | Acc: 98.188% | Wgt Acc: 98.286%
	I - Batch: 150 | Loss: 1.417 | Acc: 98.292% | Wgt Acc: 98.362%
	I - Batch: 200 | Loss: 1.408 | Acc: 98.562% | Wgt Acc: 98.579%
	I - Batch: 250 | Loss: 1.415 | Acc: 98.375% | Wgt Acc: 98.388%
	I - Batch: 300 | Loss: 1.411 | Acc: 98.458% | Wgt Acc: 98.487%
	I - Batch: 350 | Loss: 1.416 | Acc: 98.411% | Wgt Acc: 98.438%
I - num batch: 364
I - Train -- Loss: 1.414 | Acc: 98.418% | Wgt Acc: 98.470% | LR: 1.250000e-04 | Dur: 230.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    2.    3.    9.   14.]
 [   2.  661.    0.    0.    5.]
 [   1.    0.  963.    0.   13.]
 [   3.    1.    1.  699.   13.]
 [   4.    4.    7.   10. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.831 | Acc: 52.625% | Wgt Acc: 47.427%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 57.184% | Wgt Acc: 50.730% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   5.  25.  27.  31.]
 [  1. 105.  22.   4.   6.]
 [  3.  39. 100.   9.  21.]
 [ 23.  28.  23. 111.  32.]
 [ 33.  91. 120.  53. 341.]]

I - Epoch: 214
I - Training: 
	I - Batch: 50 | Loss: 1.443 | Acc: 98.000% | Wgt Acc: 97.828%
	I - Batch: 100 | Loss: 1.438 | Acc: 98.375% | Wgt Acc: 98.205%
	I - Batch: 150 | Loss: 1.418 | Acc: 98.708% | Wgt Acc: 98.622%
	I - Batch: 200 | Loss: 1.402 | Acc: 98.938% | Wgt Acc: 98.869%
	I - Batch: 250 | Loss: 1.397 | Acc: 98.950% | Wgt Acc: 98.910%
	I - Batch: 300 | Loss: 1.400 | Acc: 98.896% | Wgt Acc: 98.822%
	I - Batch: 350 | Loss: 1.403 | Acc: 98.821% | Wgt Acc: 98.768%
I - num batch: 364
I - Train -- Loss: 1.407 | Acc: 98.779% | Wgt Acc: 98.689% | LR: 1.250000e-04 | Dur: 230.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    4.    2.    4.   11.]
 [   1.  659.    0.    0.    3.]
 [   1.    0.  965.    0.    3.]
 [   2.    0.    2.  701.   10.]
 [   5.    5.    5.   13. 2736.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.896 | Acc: 50.000% | Wgt Acc: 44.082%
I - num batch: 87
I - Val -- Loss: 5.793 | Acc: 55.819% | Wgt Acc: 48.442% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   9.  20.  21.  27.]
 [  3. 112.  30.   7.   9.]
 [  2.  27.  72.   6.   9.]
 [ 31.  17.  30. 116.  34.]
 [ 38. 103. 138.  54. 352.]]

I - Epoch: 215
I - Training: 
	I - Batch: 50 | Loss: 1.389 | Acc: 98.625% | Wgt Acc: 98.759%
	I - Batch: 100 | Loss: 1.369 | Acc: 99.062% | Wgt Acc: 99.201%
	I - Batch: 150 | Loss: 1.383 | Acc: 98.875% | Wgt Acc: 98.916%
	I - Batch: 200 | Loss: 1.389 | Acc: 98.844% | Wgt Acc: 98.761%
	I - Batch: 250 | Loss: 1.399 | Acc: 98.750% | Wgt Acc: 98.576%
	I - Batch: 300 | Loss: 1.390 | Acc: 98.896% | Wgt Acc: 98.742%
	I - Batch: 350 | Loss: 1.388 | Acc: 98.946% | Wgt Acc: 98.789%
I - num batch: 364
I - Train -- Loss: 1.390 | Acc: 98.899% | Wgt Acc: 98.772% | LR: 1.250000e-04 | Dur: 230.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    1.    1.    2.   12.]
 [   2.  660.    0.    0.    1.]
 [   2.    0.  966.    1.    1.]
 [   1.    0.    2.  703.    7.]
 [   7.    7.    5.   12. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.919 | Acc: 47.500% | Wgt Acc: 42.557%
I - num batch: 87
I - Val -- Loss: 5.849 | Acc: 52.371% | Wgt Acc: 46.290% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[155.  29.  44.  63.  91.]
 [  0.  88.  12.   4.   3.]
 [  3.  27.  85.   9.   2.]
 [ 25.  15.  22.  90.  24.]
 [ 16. 109. 127.  38. 311.]]

I - Epoch: 216
I - Training: 
	I - Batch: 50 | Loss: 1.435 | Acc: 97.875% | Wgt Acc: 97.907%
	I - Batch: 100 | Loss: 1.427 | Acc: 98.188% | Wgt Acc: 98.124%
	I - Batch: 150 | Loss: 1.422 | Acc: 98.375% | Wgt Acc: 98.265%
	I - Batch: 200 | Loss: 1.423 | Acc: 98.250% | Wgt Acc: 98.217%
	I - Batch: 250 | Loss: 1.421 | Acc: 98.300% | Wgt Acc: 98.297%
	I - Batch: 300 | Loss: 1.422 | Acc: 98.292% | Wgt Acc: 98.283%
	I - Batch: 350 | Loss: 1.418 | Acc: 98.304% | Wgt Acc: 98.351%
I - num batch: 364
I - Train -- Loss: 1.419 | Acc: 98.298% | Wgt Acc: 98.337% | LR: 1.250000e-04 | Dur: 230.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    1.    3.    5.   14.]
 [   2.  660.    0.    2.    4.]
 [   1.    1.  964.    2.   18.]
 [   1.    0.    2.  695.   11.]
 [   7.    6.    5.   14. 2716.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.864 | Acc: 51.750% | Wgt Acc: 47.121%
I - num batch: 87
I - Val -- Loss: 5.782 | Acc: 55.675% | Wgt Acc: 49.894% | Dur: 42.58s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   4.  14.  15.  19.]
 [  1.  79.  15.   2.   5.]
 [  3.  68. 123.   7.  41.]
 [ 44.  23.  36. 137.  47.]
 [ 34.  94. 102.  43. 319.]]

I - Epoch: 217
I - Training: 
	I - Batch: 50 | Loss: 1.426 | Acc: 98.500% | Wgt Acc: 98.273%
	I - Batch: 100 | Loss: 1.430 | Acc: 98.312% | Wgt Acc: 98.180%
	I - Batch: 150 | Loss: 1.409 | Acc: 98.667% | Wgt Acc: 98.647%
	I - Batch: 200 | Loss: 1.397 | Acc: 98.844% | Wgt Acc: 98.909%
	I - Batch: 250 | Loss: 1.406 | Acc: 98.725% | Wgt Acc: 98.769%
	I - Batch: 300 | Loss: 1.414 | Acc: 98.542% | Wgt Acc: 98.613%
	I - Batch: 350 | Loss: 1.409 | Acc: 98.607% | Wgt Acc: 98.675%
I - num batch: 364
I - Train -- Loss: 1.407 | Acc: 98.641% | Wgt Acc: 98.715% | LR: 1.250000e-04 | Dur: 230.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    2.    4.   12.]
 [   1.  661.    0.    0.    9.]
 [   0.    0.  965.    1.   12.]
 [   3.    0.    2.  707.    8.]
 [   7.    5.    5.    6. 2722.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.825 | Acc: 53.750% | Wgt Acc: 48.315%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 58.477% | Wgt Acc: 51.891% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   8.  21.  36.  29.]
 [  0. 114.  22.   3.   9.]
 [  5.  29.  98.  11.  13.]
 [ 25.  22.  28. 111.  30.]
 [ 28.  95. 121.  43. 350.]]

I - Epoch: 218
I - Training: 
	I - Batch: 50 | Loss: 1.378 | Acc: 99.125% | Wgt Acc: 98.903%
	I - Batch: 100 | Loss: 1.386 | Acc: 99.000% | Wgt Acc: 98.887%
	I - Batch: 150 | Loss: 1.389 | Acc: 98.917% | Wgt Acc: 98.893%
	I - Batch: 200 | Loss: 1.402 | Acc: 98.688% | Wgt Acc: 98.597%
	I - Batch: 250 | Loss: 1.395 | Acc: 98.775% | Wgt Acc: 98.726%
	I - Batch: 300 | Loss: 1.397 | Acc: 98.688% | Wgt Acc: 98.705%
	I - Batch: 350 | Loss: 1.404 | Acc: 98.571% | Wgt Acc: 98.569%
I - num batch: 364
I - Train -- Loss: 1.405 | Acc: 98.555% | Wgt Acc: 98.549% | LR: 1.250000e-04 | Dur: 231.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    2.    1.    4.   14.]
 [   0.  657.    0.    2.    4.]
 [   0.    1.  964.    1.    9.]
 [   2.    1.    2.  701.   12.]
 [   5.    7.    7.   10. 2724.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.813 | Acc: 50.000% | Wgt Acc: 45.877%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 55.460% | Wgt Acc: 49.959% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[156.  22.  40.  77.  47.]
 [  1. 126.  33.   5.  13.]
 [  2.  24.  93.   2.  14.]
 [ 17.  15.  29.  73.  33.]
 [ 23.  81.  95.  47. 324.]]

I - Epoch: 219
I - Training: 
	I - Batch: 50 | Loss: 1.391 | Acc: 99.125% | Wgt Acc: 99.020%
	I - Batch: 100 | Loss: 1.401 | Acc: 98.812% | Wgt Acc: 98.738%
	I - Batch: 150 | Loss: 1.396 | Acc: 98.958% | Wgt Acc: 98.837%
	I - Batch: 200 | Loss: 1.387 | Acc: 99.031% | Wgt Acc: 98.910%
	I - Batch: 250 | Loss: 1.394 | Acc: 98.975% | Wgt Acc: 98.842%
	I - Batch: 300 | Loss: 1.388 | Acc: 99.042% | Wgt Acc: 98.926%
	I - Batch: 350 | Loss: 1.386 | Acc: 99.071% | Wgt Acc: 98.955%
I - num batch: 364
I - Train -- Loss: 1.385 | Acc: 99.054% | Wgt Acc: 98.967% | LR: 1.250000e-04 | Dur: 228.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    1.    1.    4.    6.]
 [   1.  659.    0.    0.    6.]
 [   1.    0.  969.    0.    7.]
 [   1.    1.    0.  705.    1.]
 [   5.    7.    4.    9. 2743.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.865 | Acc: 51.875% | Wgt Acc: 46.245%
I - num batch: 87
I - Val -- Loss: 5.786 | Acc: 56.394% | Wgt Acc: 49.491% | Dur: 41.23s
I - Confusion Matrix: [row->prediction - col->label]
[[125.  14.  27.  33.  27.]
 [  2. 120.  23.   8.  22.]
 [  2.  27.  93.   5.   8.]
 [ 21.  13.  19.  95.  22.]
 [ 49.  94. 128.  63. 352.]]

I - Epoch: 220
I - Training: 
	I - Batch: 50 | Loss: 1.390 | Acc: 98.875% | Wgt Acc: 98.686%
	I - Batch: 100 | Loss: 1.383 | Acc: 99.000% | Wgt Acc: 98.911%
	I - Batch: 150 | Loss: 1.375 | Acc: 99.125% | Wgt Acc: 99.055%
	I - Batch: 200 | Loss: 1.372 | Acc: 99.188% | Wgt Acc: 99.100%
	I - Batch: 250 | Loss: 1.373 | Acc: 99.150% | Wgt Acc: 99.069%
	I - Batch: 300 | Loss: 1.374 | Acc: 99.167% | Wgt Acc: 99.074%
	I - Batch: 350 | Loss: 1.375 | Acc: 99.196% | Wgt Acc: 99.078%
I - num batch: 364
I - Train -- Loss: 1.373 | Acc: 99.226% | Wgt Acc: 99.111% | LR: 1.250000e-04 | Dur: 225.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    1.    1.    2.    5.]
 [   0.  663.    0.    0.    2.]
 [   3.    0.  967.    0.    3.]
 [   0.    0.    1.  709.    3.]
 [   8.    4.    5.    7. 2750.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.871 | Acc: 52.000% | Wgt Acc: 46.349%
I - num batch: 87
I - Val -- Loss: 5.789 | Acc: 56.537% | Wgt Acc: 49.116% | Dur: 41.04s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   8.  19.  22.  18.]
 [  2. 123.  29.   9.  11.]
 [  2.  31.  85.  10.  13.]
 [ 18.  13.  13.  96.  27.]
 [ 56.  93. 144.  67. 362.]]

I - Epoch: 221
I - Training: 
	I - Batch: 50 | Loss: 1.372 | Acc: 99.375% | Wgt Acc: 99.329%
	I - Batch: 100 | Loss: 1.358 | Acc: 99.562% | Wgt Acc: 99.480%
	I - Batch: 150 | Loss: 1.356 | Acc: 99.458% | Wgt Acc: 99.449%
	I - Batch: 200 | Loss: 1.367 | Acc: 99.312% | Wgt Acc: 99.243%
	I - Batch: 250 | Loss: 1.366 | Acc: 99.375% | Wgt Acc: 99.285%
	I - Batch: 300 | Loss: 1.370 | Acc: 99.375% | Wgt Acc: 99.266%
	I - Batch: 350 | Loss: 1.368 | Acc: 99.393% | Wgt Acc: 99.301%
I - num batch: 364
I - Train -- Loss: 1.368 | Acc: 99.381% | Wgt Acc: 99.296% | LR: 1.250000e-04 | Dur: 224.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    1.    4.    2.    0.]
 [   0.  664.    0.    0.    2.]
 [   2.    0.  968.    1.    7.]
 [   1.    1.    0.  709.    2.]
 [   3.    2.    2.    6. 2752.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.979 | Acc: 48.875% | Wgt Acc: 41.895%
I - num batch: 87
I - Val -- Loss: 5.851 | Acc: 55.244% | Wgt Acc: 46.089% | Dur: 40.87s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   7.  19.  25.  14.]
 [  1. 102.  22.  10.   4.]
 [  3.  14.  59.   5.   7.]
 [ 20.  13.  19.  94.  27.]
 [ 40. 132. 171.  70. 379.]]

I - Epoch: 222
I - Training: 
	I - Batch: 50 | Loss: 1.388 | Acc: 99.250% | Wgt Acc: 99.064%
	I - Batch: 100 | Loss: 1.388 | Acc: 99.188% | Wgt Acc: 99.024%
	I - Batch: 150 | Loss: 1.386 | Acc: 99.167% | Wgt Acc: 99.099%
	I - Batch: 200 | Loss: 1.391 | Acc: 99.000% | Wgt Acc: 98.943%
	I - Batch: 250 | Loss: 1.385 | Acc: 99.075% | Wgt Acc: 99.036%
	I - Batch: 300 | Loss: 1.381 | Acc: 99.167% | Wgt Acc: 99.099%
	I - Batch: 350 | Loss: 1.384 | Acc: 99.125% | Wgt Acc: 99.032%
I - num batch: 364
I - Train -- Loss: 1.384 | Acc: 99.106% | Wgt Acc: 99.028% | LR: 1.250000e-04 | Dur: 224.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    2.    2.    2.    4.]
 [   3.  662.    0.    1.    3.]
 [   1.    1.  966.    1.    2.]
 [   2.    0.    2.  706.   10.]
 [   1.    3.    4.    8. 2744.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.019 | Acc: 47.000% | Wgt Acc: 39.868%
I - num batch: 87
I - Val -- Loss: 5.889 | Acc: 53.951% | Wgt Acc: 44.274% | Dur: 40.87s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   3.  15.  27.  17.]
 [  1.  86.  14.   5.   3.]
 [  5.  24.  77.   4.  10.]
 [ 14.  15.  14.  80.  17.]
 [ 55. 140. 170.  88. 384.]]

I - Epoch: 223
I - Training: 
	I - Batch: 50 | Loss: 1.376 | Acc: 99.250% | Wgt Acc: 99.084%
	I - Batch: 100 | Loss: 1.368 | Acc: 99.375% | Wgt Acc: 99.254%
	I - Batch: 150 | Loss: 1.371 | Acc: 99.375% | Wgt Acc: 99.223%
	I - Batch: 200 | Loss: 1.366 | Acc: 99.500% | Wgt Acc: 99.376%
	I - Batch: 250 | Loss: 1.366 | Acc: 99.425% | Wgt Acc: 99.347%
	I - Batch: 300 | Loss: 1.365 | Acc: 99.438% | Wgt Acc: 99.360%
	I - Batch: 350 | Loss: 1.368 | Acc: 99.339% | Wgt Acc: 99.284%
I - num batch: 364
I - Train -- Loss: 1.369 | Acc: 99.312% | Wgt Acc: 99.266% | LR: 1.250000e-04 | Dur: 223.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    1.    1.    3.    7.]
 [   0.  663.    0.    1.    1.]
 [   2.    1.  971.    1.    5.]
 [   1.    1.    1.  709.    2.]
 [   5.    2.    1.    4. 2748.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.885 | Acc: 52.000% | Wgt Acc: 45.877%
I - num batch: 87
I - Val -- Loss: 5.799 | Acc: 57.543% | Wgt Acc: 50.273% | Dur: 40.88s
I - Confusion Matrix: [row->prediction - col->label]
[[139.  12.  24.  33.  34.]
 [  0. 111.  18.   8.   1.]
 [  1.  32.  85.   8.   9.]
 [ 32.  12.  26. 109.  30.]
 [ 27. 101. 137.  46. 357.]]

I - Epoch: 224
I - Training: 
	I - Batch: 50 | Loss: 1.368 | Acc: 99.250% | Wgt Acc: 99.209%
	I - Batch: 100 | Loss: 1.366 | Acc: 99.438% | Wgt Acc: 99.368%
	I - Batch: 150 | Loss: 1.384 | Acc: 99.208% | Wgt Acc: 99.042%
	I - Batch: 200 | Loss: 1.382 | Acc: 99.250% | Wgt Acc: 99.076%
	I - Batch: 250 | Loss: 1.384 | Acc: 99.200% | Wgt Acc: 99.057%
	I - Batch: 300 | Loss: 1.384 | Acc: 99.188% | Wgt Acc: 99.033%
	I - Batch: 350 | Loss: 1.385 | Acc: 99.143% | Wgt Acc: 99.025%
I - num batch: 364
I - Train -- Loss: 1.386 | Acc: 99.123% | Wgt Acc: 98.988% | LR: 1.250000e-04 | Dur: 223.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    1.    4.    3.    4.]
 [   1.  659.    0.    1.    5.]
 [   2.    0.  969.    0.    1.]
 [   1.    1.    0.  707.    5.]
 [   7.    7.    1.    7. 2748.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.899 | Acc: 50.000% | Wgt Acc: 43.396%
I - num batch: 87
I - Val -- Loss: 5.817 | Acc: 55.675% | Wgt Acc: 47.641% | Dur: 40.92s
I - Confusion Matrix: [row->prediction - col->label]
[[128.  10.  19.  24.  19.]
 [  0.  82.  11.   3.   2.]
 [  3.  31.  80.   7.   6.]
 [ 38.  41.  51. 130.  49.]
 [ 30. 104. 129.  40. 355.]]

I - Epoch: 225
I - Training: 
	I - Batch: 50 | Loss: 1.378 | Acc: 99.125% | Wgt Acc: 99.060%
	I - Batch: 100 | Loss: 1.380 | Acc: 99.250% | Wgt Acc: 99.144%
	I - Batch: 150 | Loss: 1.385 | Acc: 99.042% | Wgt Acc: 99.009%
	I - Batch: 200 | Loss: 1.400 | Acc: 98.844% | Wgt Acc: 98.743%
	I - Batch: 250 | Loss: 1.392 | Acc: 98.925% | Wgt Acc: 98.842%
	I - Batch: 300 | Loss: 1.385 | Acc: 99.062% | Wgt Acc: 98.993%
	I - Batch: 350 | Loss: 1.382 | Acc: 99.125% | Wgt Acc: 99.050%
I - num batch: 364
I - Train -- Loss: 1.380 | Acc: 99.157% | Wgt Acc: 99.086% | LR: 1.250000e-04 | Dur: 225.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    2.    0.    4.    3.]
 [   0.  661.    0.    0.    5.]
 [   2.    1.  969.    0.    5.]
 [   1.    0.    1.  707.    5.]
 [   5.    4.    4.    7. 2745.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.854 | Acc: 52.000% | Wgt Acc: 46.196%
I - num batch: 87
I - Val -- Loss: 5.780 | Acc: 57.471% | Wgt Acc: 50.602% | Dur: 41.59s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   4.  17.  27.  20.]
 [  0.  88.  11.   4.   5.]
 [  9.  56. 124.  25.  22.]
 [ 20.  14.  19. 104.  35.]
 [ 35. 106. 119.  44. 349.]]

I - Epoch: 226
I - Training: 
	I - Batch: 50 | Loss: 1.376 | Acc: 98.875% | Wgt Acc: 98.927%
	I - Batch: 100 | Loss: 1.370 | Acc: 99.188% | Wgt Acc: 99.119%
	I - Batch: 150 | Loss: 1.362 | Acc: 99.250% | Wgt Acc: 99.242%
	I - Batch: 200 | Loss: 1.356 | Acc: 99.406% | Wgt Acc: 99.391%
	I - Batch: 250 | Loss: 1.354 | Acc: 99.500% | Wgt Acc: 99.482%
	I - Batch: 300 | Loss: 1.354 | Acc: 99.521% | Wgt Acc: 99.504%
	I - Batch: 350 | Loss: 1.363 | Acc: 99.446% | Wgt Acc: 99.378%
I - num batch: 364
I - Train -- Loss: 1.363 | Acc: 99.450% | Wgt Acc: 99.377% | LR: 1.250000e-04 | Dur: 226.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    2.    1.    2.    4.]
 [   0.  663.    0.    0.    0.]
 [   2.    0.  971.    1.    3.]
 [   0.    0.    1.  710.    3.]
 [   4.    3.    1.    5. 2753.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.802 | Acc: 51.375% | Wgt Acc: 47.433%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 56.106% | Wgt Acc: 51.360% | Dur: 41.59s
I - Confusion Matrix: [row->prediction - col->label]
[[151.  24.  30.  48.  47.]
 [  0.  90.  14.   3.   3.]
 [  3.  57. 124.  13.  25.]
 [ 28.  29.  32. 112.  52.]
 [ 17.  68.  90.  28. 304.]]

I - Epoch: 227
I - Training: 
	I - Batch: 50 | Loss: 1.362 | Acc: 99.500% | Wgt Acc: 99.422%
	I - Batch: 100 | Loss: 1.347 | Acc: 99.688% | Wgt Acc: 99.607%
	I - Batch: 150 | Loss: 1.349 | Acc: 99.667% | Wgt Acc: 99.594%
	I - Batch: 200 | Loss: 1.356 | Acc: 99.531% | Wgt Acc: 99.445%
	I - Batch: 250 | Loss: 1.365 | Acc: 99.400% | Wgt Acc: 99.305%
	I - Batch: 300 | Loss: 1.364 | Acc: 99.396% | Wgt Acc: 99.329%
	I - Batch: 350 | Loss: 1.368 | Acc: 99.339% | Wgt Acc: 99.261%
I - num batch: 364
I - Train -- Loss: 1.367 | Acc: 99.347% | Wgt Acc: 99.266% | LR: 1.250000e-04 | Dur: 226.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    1.    0.    3.    6.]
 [   1.  663.    0.    0.    0.]
 [   1.    1.  970.    2.    1.]
 [   1.    1.    3.  708.    5.]
 [   4.    2.    1.    5. 2751.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.817 | Acc: 55.000% | Wgt Acc: 49.822%
I - num batch: 87
I - Val -- Loss: 5.761 | Acc: 60.489% | Wgt Acc: 53.667% | Dur: 41.62s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   4.  12.  35.  22.]
 [  1. 120.  20.   4.   7.]
 [  4.  35. 123.  10.  14.]
 [ 21.  11.  14.  96.  20.]
 [ 38.  98. 121.  59. 368.]]

I - Epoch: 228
I - Training: 
	I - Batch: 50 | Loss: 1.359 | Acc: 99.250% | Wgt Acc: 99.529%
	I - Batch: 100 | Loss: 1.374 | Acc: 99.188% | Wgt Acc: 99.276%
	I - Batch: 150 | Loss: 1.368 | Acc: 99.333% | Wgt Acc: 99.378%
	I - Batch: 200 | Loss: 1.375 | Acc: 99.250% | Wgt Acc: 99.252%
	I - Batch: 250 | Loss: 1.383 | Acc: 99.175% | Wgt Acc: 99.156%
	I - Batch: 300 | Loss: 1.383 | Acc: 99.146% | Wgt Acc: 99.125%
	I - Batch: 350 | Loss: 1.380 | Acc: 99.214% | Wgt Acc: 99.193%
I - num batch: 364
I - Train -- Loss: 1.378 | Acc: 99.226% | Wgt Acc: 99.215% | LR: 1.250000e-04 | Dur: 226.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    1.    1.    2.    5.]
 [   2.  661.    0.    0.    6.]
 [   0.    1.  972.    1.    7.]
 [   2.    0.    0.  709.    2.]
 [   3.    5.    1.    6. 2743.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.914 | Acc: 49.750% | Wgt Acc: 43.782%
I - num batch: 87
I - Val -- Loss: 5.821 | Acc: 55.675% | Wgt Acc: 48.086% | Dur: 41.43s
I - Confusion Matrix: [row->prediction - col->label]
[[145.  22.  31.  45.  30.]
 [  0.  94.  19.   2.   9.]
 [  1.  39.  81.   9.  11.]
 [ 25.  18.  31. 104.  30.]
 [ 28.  95. 128.  44. 351.]]

I - Epoch: 229
I - Training: 
	I - Batch: 50 | Loss: 1.366 | Acc: 99.375% | Wgt Acc: 99.312%
	I - Batch: 100 | Loss: 1.362 | Acc: 99.312% | Wgt Acc: 99.235%
	I - Batch: 150 | Loss: 1.362 | Acc: 99.208% | Wgt Acc: 99.214%
	I - Batch: 200 | Loss: 1.357 | Acc: 99.344% | Wgt Acc: 99.358%
	I - Batch: 250 | Loss: 1.363 | Acc: 99.275% | Wgt Acc: 99.288%
	I - Batch: 300 | Loss: 1.364 | Acc: 99.271% | Wgt Acc: 99.277%
	I - Batch: 350 | Loss: 1.364 | Acc: 99.286% | Wgt Acc: 99.267%
I - num batch: 364
I - Train -- Loss: 1.366 | Acc: 99.278% | Wgt Acc: 99.262% | LR: 1.250000e-04 | Dur: 226.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    2.    0.    3.    3.]
 [   1.  663.    0.    0.    1.]
 [   0.    0.  971.    0.    5.]
 [   1.    0.    0.  709.    9.]
 [   5.    3.    3.    6. 2745.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.866 | Acc: 49.000% | Wgt Acc: 43.219%
I - num batch: 87
I - Val -- Loss: 5.788 | Acc: 55.388% | Wgt Acc: 47.730% | Dur: 41.53s
I - Confusion Matrix: [row->prediction - col->label]
[[132.  13.  23.  34.  31.]
 [  1.  99.  19.   3.   7.]
 [  1.  33.  83.   4.   9.]
 [ 27.  27.  30. 103.  30.]
 [ 38.  96. 135.  60. 354.]]

I - Epoch: 230
I - Training: 
	I - Batch: 50 | Loss: 1.377 | Acc: 99.250% | Wgt Acc: 99.091%
	I - Batch: 100 | Loss: 1.368 | Acc: 99.375% | Wgt Acc: 99.234%
