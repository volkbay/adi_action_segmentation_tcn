Tue Oct 18 23:13:59 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.2, 0.25, 0.2, 0.25, 0.08], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': True, 'tossFirstLastFrames': True}, 'dataPath': '/data/processed/Kinetics/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat'], 'lastLayerInitUniform': True, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 70.33639143730886, 'maxValidationTrainNo': 39, 'modelVersion': 10, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 43, 'validationAccThr': 70, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Train set length:  7641
I - Label distribution: [2091. 1734. 2202. 1614.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/test
I - Test set length:  981
I - Label distribution: [264. 234. 225. 258.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(3) data number in dataset:  tensor([187413,  72346, 133086,  85680, 117023,  70469, 116865, 170833,  33440,
         19871, 147370, 197692,  42251,   7928,  12887, 204021])
I - Initializing model TCNv10
I - Number of Model Parameters: 169868
I - Model output shape:  torch.Size([16, 4])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv10                                   [16, 4]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          --
│    └─ReLU: 2-1673                      [16, 64, 64, 64]          --
│    └─Conv2d: 2-2                       --                        3,136
│    └─BatchNorm2d: 2-1671               [16, 64, 64, 64]          --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-1672                    [16, 64, 64, 64]          --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [64, 48, 1, 1]            --
│    └─Empty: 2-9                        [64, 48, 1, 1]            --
│    └─Empty: 2-10                       [64]                      --
│    └─Empty: 2-11                       [64]                      --
│    └─BatchNorm2d: 2-12                 [16, 64, 64, 64]          --
│    └─Scaler: 2-13                      [16, 64, 64, 64]          --
│    └─Empty: 2-14                       --                        --
│    └─Empty: 2-15                       --                        --
│    └─ReLU: 2-16                        [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1685                      [16, 64, 64, 64]          --
│    └─Conv2d: 2-18                      --                        36,928
│    └─BatchNorm2d: 2-1683               [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-20                       [16, 64, 64, 64]          --
│    └─Clamp: 2-21                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1684                    [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-23          --                        --
│    └─One: 2-24                         [1]                       --
│    └─OutputScale: 2-25                 --                        --
│    └─Empty: 2-26                       [64, 64, 3, 3]            --
│    └─Empty: 2-27                       [64, 64, 3, 3]            --
│    └─Empty: 2-28                       [64]                      --
│    └─Empty: 2-29                       [64]                      --
│    └─BatchNorm2d: 2-30                 [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-127        [16, 64, 32, 32]          (recursive)
│    └─ReLU: 2-1700                      [16, 64, 32, 32]          --
│    └─MaxPool2d: 2-1688                 [16, 64, 32, 32]          --
│    └─Conv2d: 2-33                      --                        36,928
│    └─BatchNorm2d: 2-1698               [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-35                      [16, 64, 64, 64]          --
│    └─ReLU: 2-36                        [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1699                    [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-38                       [16, 64, 64, 64]          --
│    └─Clamp: 2-39                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-4          [16, 64, 32, 32]          32,774
│    └─MaxPool2d: 2-40                   [16, 64, 32, 32]          --
│    └─Empty: 2-41                       [16, 64, 32, 32]          --
│    └─Empty: 2-42                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-43          --                        --
│    └─Empty: 2-1689                     [16, 64, 32, 32]          --
│    └─Empty: 2-1690                     [16, 64, 32, 32]          --
│    └─One: 2-46                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1712                      [16, 64, 32, 32]          --
│    └─Conv2d: 2-48                      --                        4,160
│    └─BatchNorm2d: 2-1710               [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-50                 --                        --
│    └─Empty: 2-51                       [64, 64, 3, 3]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1711                    [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-53                       [64, 64, 3, 3]            --
│    └─Empty: 2-54                       [64]                      --
│    └─Empty: 2-55                       [64]                      --
│    └─BatchNorm2d: 2-56                 [16, 64, 32, 32]          --
│    └─Scaler: 2-57                      [16, 64, 32, 32]          --
│    └─ReLU: 2-58                        [16, 64, 32, 32]          --
│    └─Empty: 2-59                       [16, 64, 32, 32]          --
│    └─Clamp: 2-60                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-5                 [16, 64, 32, 32]          4,166
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 64, 32, 32]          (recursive)
│    └─ReLU: 2-1727                      [16, 64, 32, 32]          --
│    └─MaxPool2d: 2-1715                 [16, 64, 32, 32]          --
│    └─Conv2d: 2-63                      --                        36,928
│    └─BatchNorm2d: 2-1725               [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1726                    [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-68                 --                        --
│    └─Empty: 2-69                       [64, 64, 1, 1]            --
│    └─Empty: 2-70                       [64, 64, 1, 1]            --
│    └─Empty: 2-71                       [64]                      --
│    └─Empty: 2-72                       [64]                      --
│    └─BatchNorm2d: 2-73                 [16, 64, 32, 32]          --
│    └─Scaler: 2-74                      [16, 64, 32, 32]          --
│    └─ReLU: 2-75                        [16, 64, 32, 32]          --
│    └─Empty: 2-76                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 16, 16]          (recursive)
│    └─ReLU: 2-1742                      [16, 64, 16, 16]          --
│    └─MaxPool2d: 2-1730                 [16, 64, 16, 16]          --
│    └─Conv2d: 2-79                      --                        36,928
│    └─BatchNorm2d: 2-1740               [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-81                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-8          [16, 64, 32, 32]          36,674
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1741                    [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─MaxPool2d: 2-83                   [16, 64, 32, 32]          --
│    └─Empty: 2-84                       [16, 64, 32, 32]          --
│    └─Empty: 2-85                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-86          --                        --
│    └─One: 2-87                         [1]                       --
│    └─OutputScale: 2-88                 --                        --
│    └─Empty: 2-89                       [64, 64, 3, 3]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1731                     [16, 64, 16, 16]          --
│    └─Empty: 2-1732                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-92                       [64, 64, 3, 3]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1754                      [16, 4, 16, 16]           --
│    └─Conv2d: 2-94                      --                        260
│    └─BatchNorm2d: 2-1752               [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-96                       [64]                      --
│    └─Empty: 2-97                       [64]                      --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1753                    [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─BatchNorm2d: 2-99                 [16, 64, 32, 32]          --
│    └─Scaler: 2-100                     [16, 64, 32, 32]          --
│    └─ReLU: 2-101                       [16, 64, 32, 32]          --
│    └─Empty: 2-102                      [16, 64, 32, 32]          --
│    └─Clamp: 2-103                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-104                  [16, 64, 16, 16]          --
│    └─Empty: 2-105                      [16, 64, 16, 16]          --
│    └─Empty: 2-106                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 4, 16, 16]           (recursive)
│    └─ReLU: 2-1769                      [16, 4, 16, 16]           --
│    └─MaxPool2d: 2-1757                 [16, 64, 16, 16]          --
│    └─Conv2d: 2-109                     --                        2,308
│    └─BatchNorm2d: 2-1767               [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputShiftSqueeze: 2-111         --                        --
│    └─One: 2-112                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1768                    [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-114                --                        --
│    └─Empty: 2-115                      [64, 64, 3, 3]            --
│    └─Empty: 2-116                      [64, 64, 3, 3]            --
│    └─Empty: 2-117                      [64]                      --
│    └─Empty: 2-118                      [64]                      --
│    └─BatchNorm2d: 2-119                [16, 64, 16, 16]          --
│    └─Scaler: 2-120                     [16, 64, 16, 16]          --
│    └─ReLU: 2-121                       [16, 64, 16, 16]          --
│    └─Empty: 2-122                      [16, 64, 16, 16]          --
│    └─Clamp: 2-123                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-11                [16, 4, 16, 16]           266
│    └─OutputShiftSqueeze: 2-124         --                        --
│    └─One: 2-125                        [1]                       --
│    └─OutputScale: 2-126                --                        --
├─Conv1d: 1                              --                        --
│    └─Scaler: 2-1779                    [16, 4, 14]               --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-128                      [4, 64, 1, 1]             --
│    └─Empty: 2-129                      [4, 64, 1, 1]             --
│    └─Empty: 2-130                      [4]                       --
│    └─Empty: 2-131                      [4]                       --
│    └─BatchNorm2d: 2-132                [16, 4, 16, 16]           --
│    └─Scaler: 2-133                     [16, 4, 16, 16]           --
│    └─ReLU: 2-134                       [16, 4, 16, 16]           --
│    └─Empty: 2-135                      [16, 4, 16, 16]           --
│    └─Clamp: 2-136                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 4, 16, 16]           2,314
│    └─MaxPool2d: 2-137                  [16, 64, 16, 16]          --
│    └─Empty: 2-138                      [16, 64, 16, 16]          --
│    └─Empty: 2-139                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-140         --                        --
│    └─One: 2-141                        [1]                       --
│    └─OutputScale: 2-142                --                        --
│    └─Empty: 2-143                      [4, 64, 3, 3]             --
│    └─Empty: 2-144                      [4, 64, 3, 3]             --
│    └─Empty: 2-145                      [4]                       --
│    └─Empty: 2-146                      [4]                       --
│    └─BatchNorm2d: 2-147                [16, 4, 16, 16]           --
│    └─Scaler: 2-148                     [16, 4, 16, 16]           --
│    └─ReLU: 2-149                       [16, 4, 16, 16]           --
│    └─Empty: 2-150                      [16, 4, 16, 16]           --
│    └─Clamp: 2-151                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-13                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-152         --                        --
│    └─One: 2-153                        [1]                       --
│    └─OutputScale: 2-154                --                        --
│    └─Empty: 2-155                      [64, 48, 1, 1]            --
│    └─Empty: 2-156                      [64, 48, 1, 1]            --
│    └─Empty: 2-157                      [64]                      --
│    └─Empty: 2-158                      [64]                      --
│    └─BatchNorm2d: 2-159                [16, 64, 64, 64]          --
│    └─Scaler: 2-160                     [16, 64, 64, 64]          --
│    └─ReLU: 2-161                       [16, 64, 64, 64]          --
│    └─Empty: 2-162                      [16, 64, 64, 64]          --
│    └─Clamp: 2-163                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-14                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-164         --                        --
│    └─One: 2-165                        [1]                       --
│    └─OutputScale: 2-166                --                        --
│    └─Empty: 2-167                      [64, 64, 3, 3]            --
│    └─Empty: 2-168                      [64, 64, 3, 3]            --
│    └─Empty: 2-169                      [64]                      --
│    └─Empty: 2-170                      [64]                      --
│    └─BatchNorm2d: 2-171                [16, 64, 64, 64]          --
│    └─Scaler: 2-172                     [16, 64, 64, 64]          --
│    └─ReLU: 2-173                       [16, 64, 64, 64]          --
│    └─Empty: 2-174                      [16, 64, 64, 64]          --
│    └─Clamp: 2-175                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-176                  [16, 64, 32, 32]          --
│    └─Empty: 2-177                      [16, 64, 32, 32]          --
│    └─Empty: 2-178                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-179         --                        --
│    └─One: 2-180                        [1]                       --
│    └─OutputScale: 2-181                --                        --
│    └─Empty: 2-182                      [64, 64, 3, 3]            --
│    └─Empty: 2-183                      [64, 64, 3, 3]            --
│    └─Empty: 2-184                      [64]                      --
│    └─Empty: 2-185                      [64]                      --
│    └─BatchNorm2d: 2-186                [16, 64, 32, 32]          --
│    └─Scaler: 2-187                     [16, 64, 32, 32]          --
│    └─ReLU: 2-188                       [16, 64, 32, 32]          --
│    └─Empty: 2-189                      [16, 64, 32, 32]          --
│    └─Clamp: 2-190                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-16                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-191         --                        --
│    └─One: 2-192                        [1]                       --
│    └─OutputScale: 2-193                --                        --
│    └─Empty: 2-194                      [64, 64, 1, 1]            --
│    └─Empty: 2-195                      [64, 64, 1, 1]            --
│    └─Empty: 2-196                      [64]                      --
│    └─Empty: 2-197                      [64]                      --
│    └─BatchNorm2d: 2-198                [16, 64, 32, 32]          --
│    └─Scaler: 2-199                     [16, 64, 32, 32]          --
│    └─ReLU: 2-200                       [16, 64, 32, 32]          --
│    └─Empty: 2-201                      [16, 64, 32, 32]          --
│    └─Clamp: 2-202                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-203                  [16, 64, 32, 32]          --
│    └─Empty: 2-204                      [16, 64, 32, 32]          --
│    └─Empty: 2-205                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-206         --                        --
│    └─One: 2-207                        [1]                       --
│    └─OutputScale: 2-208                --                        --
│    └─Empty: 2-209                      [64, 64, 3, 3]            --
│    └─Empty: 2-210                      [64, 64, 3, 3]            --
│    └─Empty: 2-211                      [64]                      --
│    └─Empty: 2-212                      [64]                      --
│    └─BatchNorm2d: 2-213                [16, 64, 32, 32]          --
│    └─Scaler: 2-214                     [16, 64, 32, 32]          --
│    └─ReLU: 2-215                       [16, 64, 32, 32]          --
│    └─Empty: 2-216                      [16, 64, 32, 32]          --
│    └─Clamp: 2-217                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-18         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-218                  [16, 64, 16, 16]          --
│    └─Empty: 2-219                      [16, 64, 16, 16]          --
│    └─Empty: 2-220                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-221         --                        --
│    └─One: 2-222                        [1]                       --
│    └─OutputScale: 2-223                --                        --
│    └─Empty: 2-224                      [64, 64, 3, 3]            --
│    └─Empty: 2-225                      [64, 64, 3, 3]            --
│    └─Empty: 2-226                      [64]                      --
│    └─Empty: 2-227                      [64]                      --
│    └─BatchNorm2d: 2-228                [16, 64, 16, 16]          --
│    └─Scaler: 2-229                     [16, 64, 16, 16]          --
│    └─ReLU: 2-230                       [16, 64, 16, 16]          --
│    └─Empty: 2-231                      [16, 64, 16, 16]          --
│    └─Clamp: 2-232                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-19                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-233         --                        --
│    └─One: 2-234                        [1]                       --
│    └─OutputScale: 2-235                --                        --
│    └─Empty: 2-236                      [4, 64, 1, 1]             --
│    └─Empty: 2-237                      [4, 64, 1, 1]             --
│    └─Empty: 2-238                      [4]                       --
│    └─Empty: 2-239                      [4]                       --
│    └─BatchNorm2d: 2-240                [16, 4, 16, 16]           --
│    └─Scaler: 2-241                     [16, 4, 16, 16]           --
│    └─ReLU: 2-242                       [16, 4, 16, 16]           --
│    └─Empty: 2-243                      [16, 4, 16, 16]           --
│    └─Clamp: 2-244                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-20         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-245                  [16, 64, 16, 16]          --
│    └─Empty: 2-246                      [16, 64, 16, 16]          --
│    └─Empty: 2-247                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-248         --                        --
│    └─One: 2-249                        [1]                       --
│    └─OutputScale: 2-250                --                        --
│    └─Empty: 2-251                      [4, 64, 3, 3]             --
│    └─Empty: 2-252                      [4, 64, 3, 3]             --
│    └─Empty: 2-253                      [4]                       --
│    └─Empty: 2-254                      [4]                       --
│    └─BatchNorm2d: 2-255                [16, 4, 16, 16]           --
│    └─Scaler: 2-256                     [16, 4, 16, 16]           --
│    └─ReLU: 2-257                       [16, 4, 16, 16]           --
│    └─Empty: 2-258                      [16, 4, 16, 16]           --
│    └─Clamp: 2-259                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-260         --                        --
│    └─One: 2-261                        [1]                       --
│    └─OutputScale: 2-262                --                        --
│    └─Empty: 2-263                      [64, 48, 1, 1]            --
│    └─Empty: 2-264                      [64, 48, 1, 1]            --
│    └─Empty: 2-265                      [64]                      --
│    └─Empty: 2-266                      [64]                      --
│    └─BatchNorm2d: 2-267                [16, 64, 64, 64]          --
│    └─Scaler: 2-268                     [16, 64, 64, 64]          --
│    └─ReLU: 2-269                       [16, 64, 64, 64]          --
│    └─Empty: 2-270                      [16, 64, 64, 64]          --
│    └─Clamp: 2-271                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-22                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-272         --                        --
│    └─One: 2-273                        [1]                       --
│    └─OutputScale: 2-274                --                        --
│    └─Empty: 2-275                      [64, 64, 3, 3]            --
│    └─Empty: 2-276                      [64, 64, 3, 3]            --
│    └─Empty: 2-277                      [64]                      --
│    └─Empty: 2-278                      [64]                      --
│    └─BatchNorm2d: 2-279                [16, 64, 64, 64]          --
│    └─Scaler: 2-280                     [16, 64, 64, 64]          --
│    └─ReLU: 2-281                       [16, 64, 64, 64]          --
│    └─Empty: 2-282                      [16, 64, 64, 64]          --
│    └─Clamp: 2-283                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-284                  [16, 64, 32, 32]          --
│    └─Empty: 2-285                      [16, 64, 32, 32]          --
│    └─Empty: 2-286                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-287         --                        --
│    └─One: 2-288                        [1]                       --
│    └─OutputScale: 2-289                --                        --
│    └─Empty: 2-290                      [64, 64, 3, 3]            --
│    └─Empty: 2-291                      [64, 64, 3, 3]            --
│    └─Empty: 2-292                      [64]                      --
│    └─Empty: 2-293                      [64]                      --
│    └─BatchNorm2d: 2-294                [16, 64, 32, 32]          --
│    └─Scaler: 2-295                     [16, 64, 32, 32]          --
│    └─ReLU: 2-296                       [16, 64, 32, 32]          --
│    └─Empty: 2-297                      [16, 64, 32, 32]          --
│    └─Clamp: 2-298                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-24                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-299         --                        --
│    └─One: 2-300                        [1]                       --
│    └─OutputScale: 2-301                --                        --
│    └─Empty: 2-302                      [64, 64, 1, 1]            --
│    └─Empty: 2-303                      [64, 64, 1, 1]            --
│    └─Empty: 2-304                      [64]                      --
│    └─Empty: 2-305                      [64]                      --
│    └─BatchNorm2d: 2-306                [16, 64, 32, 32]          --
│    └─Scaler: 2-307                     [16, 64, 32, 32]          --
│    └─ReLU: 2-308                       [16, 64, 32, 32]          --
│    └─Empty: 2-309                      [16, 64, 32, 32]          --
│    └─Clamp: 2-310                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-311                  [16, 64, 32, 32]          --
│    └─Empty: 2-312                      [16, 64, 32, 32]          --
│    └─Empty: 2-313                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-314         --                        --
│    └─One: 2-315                        [1]                       --
│    └─OutputScale: 2-316                --                        --
│    └─Empty: 2-317                      [64, 64, 3, 3]            --
│    └─Empty: 2-318                      [64, 64, 3, 3]            --
│    └─Empty: 2-319                      [64]                      --
│    └─Empty: 2-320                      [64]                      --
│    └─BatchNorm2d: 2-321                [16, 64, 32, 32]          --
│    └─Scaler: 2-322                     [16, 64, 32, 32]          --
│    └─ReLU: 2-323                       [16, 64, 32, 32]          --
│    └─Empty: 2-324                      [16, 64, 32, 32]          --
│    └─Clamp: 2-325                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-326                  [16, 64, 16, 16]          --
│    └─Empty: 2-327                      [16, 64, 16, 16]          --
│    └─Empty: 2-328                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-329         --                        --
│    └─One: 2-330                        [1]                       --
│    └─OutputScale: 2-331                --                        --
│    └─Empty: 2-332                      [64, 64, 3, 3]            --
│    └─Empty: 2-333                      [64, 64, 3, 3]            --
│    └─Empty: 2-334                      [64]                      --
│    └─Empty: 2-335                      [64]                      --
│    └─BatchNorm2d: 2-336                [16, 64, 16, 16]          --
│    └─Scaler: 2-337                     [16, 64, 16, 16]          --
│    └─ReLU: 2-338                       [16, 64, 16, 16]          --
│    └─Empty: 2-339                      [16, 64, 16, 16]          --
│    └─Clamp: 2-340                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-27                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-341         --                        --
│    └─One: 2-342                        [1]                       --
│    └─OutputScale: 2-343                --                        --
│    └─Empty: 2-344                      [4, 64, 1, 1]             --
│    └─Empty: 2-345                      [4, 64, 1, 1]             --
│    └─Empty: 2-346                      [4]                       --
│    └─Empty: 2-347                      [4]                       --
│    └─BatchNorm2d: 2-348                [16, 4, 16, 16]           --
│    └─Scaler: 2-349                     [16, 4, 16, 16]           --
│    └─ReLU: 2-350                       [16, 4, 16, 16]           --
│    └─Empty: 2-351                      [16, 4, 16, 16]           --
│    └─Clamp: 2-352                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-353                  [16, 64, 16, 16]          --
│    └─Empty: 2-354                      [16, 64, 16, 16]          --
│    └─Empty: 2-355                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-356         --                        --
│    └─One: 2-357                        [1]                       --
│    └─OutputScale: 2-358                --                        --
│    └─Empty: 2-359                      [4, 64, 3, 3]             --
│    └─Empty: 2-360                      [4, 64, 3, 3]             --
│    └─Empty: 2-361                      [4]                       --
│    └─Empty: 2-362                      [4]                       --
│    └─BatchNorm2d: 2-363                [16, 4, 16, 16]           --
│    └─Scaler: 2-364                     [16, 4, 16, 16]           --
│    └─ReLU: 2-365                       [16, 4, 16, 16]           --
│    └─Empty: 2-366                      [16, 4, 16, 16]           --
│    └─Clamp: 2-367                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-29                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-368         --                        --
│    └─One: 2-369                        [1]                       --
│    └─OutputScale: 2-370                --                        --
│    └─Empty: 2-371                      [64, 48, 1, 1]            --
│    └─Empty: 2-372                      [64, 48, 1, 1]            --
│    └─Empty: 2-373                      [64]                      --
│    └─Empty: 2-374                      [64]                      --
│    └─BatchNorm2d: 2-375                [16, 64, 64, 64]          --
│    └─Scaler: 2-376                     [16, 64, 64, 64]          --
│    └─ReLU: 2-377                       [16, 64, 64, 64]          --
│    └─Empty: 2-378                      [16, 64, 64, 64]          --
│    └─Clamp: 2-379                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-30                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-380         --                        --
│    └─One: 2-381                        [1]                       --
│    └─OutputScale: 2-382                --                        --
│    └─Empty: 2-383                      [64, 64, 3, 3]            --
│    └─Empty: 2-384                      [64, 64, 3, 3]            --
│    └─Empty: 2-385                      [64]                      --
│    └─Empty: 2-386                      [64]                      --
│    └─BatchNorm2d: 2-387                [16, 64, 64, 64]          --
│    └─Scaler: 2-388                     [16, 64, 64, 64]          --
│    └─ReLU: 2-389                       [16, 64, 64, 64]          --
│    └─Empty: 2-390                      [16, 64, 64, 64]          --
│    └─Clamp: 2-391                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-392                  [16, 64, 32, 32]          --
│    └─Empty: 2-393                      [16, 64, 32, 32]          --
│    └─Empty: 2-394                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-395         --                        --
│    └─One: 2-396                        [1]                       --
│    └─OutputScale: 2-397                --                        --
│    └─Empty: 2-398                      [64, 64, 3, 3]            --
│    └─Empty: 2-399                      [64, 64, 3, 3]            --
│    └─Empty: 2-400                      [64]                      --
│    └─Empty: 2-401                      [64]                      --
│    └─BatchNorm2d: 2-402                [16, 64, 32, 32]          --
│    └─Scaler: 2-403                     [16, 64, 32, 32]          --
│    └─ReLU: 2-404                       [16, 64, 32, 32]          --
│    └─Empty: 2-405                      [16, 64, 32, 32]          --
│    └─Clamp: 2-406                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-32                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-407         --                        --
│    └─One: 2-408                        [1]                       --
│    └─OutputScale: 2-409                --                        --
│    └─Empty: 2-410                      [64, 64, 1, 1]            --
│    └─Empty: 2-411                      [64, 64, 1, 1]            --
│    └─Empty: 2-412                      [64]                      --
│    └─Empty: 2-413                      [64]                      --
│    └─BatchNorm2d: 2-414                [16, 64, 32, 32]          --
│    └─Scaler: 2-415                     [16, 64, 32, 32]          --
│    └─ReLU: 2-416                       [16, 64, 32, 32]          --
│    └─Empty: 2-417                      [16, 64, 32, 32]          --
│    └─Clamp: 2-418                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-419                  [16, 64, 32, 32]          --
│    └─Empty: 2-420                      [16, 64, 32, 32]          --
│    └─Empty: 2-421                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-422         --                        --
│    └─One: 2-423                        [1]                       --
│    └─OutputScale: 2-424                --                        --
│    └─Empty: 2-425                      [64, 64, 3, 3]            --
│    └─Empty: 2-426                      [64, 64, 3, 3]            --
│    └─Empty: 2-427                      [64]                      --
│    └─Empty: 2-428                      [64]                      --
│    └─BatchNorm2d: 2-429                [16, 64, 32, 32]          --
│    └─Scaler: 2-430                     [16, 64, 32, 32]          --
│    └─ReLU: 2-431                       [16, 64, 32, 32]          --
│    └─Empty: 2-432                      [16, 64, 32, 32]          --
│    └─Clamp: 2-433                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-434                  [16, 64, 16, 16]          --
│    └─Empty: 2-435                      [16, 64, 16, 16]          --
│    └─Empty: 2-436                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-437         --                        --
│    └─One: 2-438                        [1]                       --
│    └─OutputScale: 2-439                --                        --
│    └─Empty: 2-440                      [64, 64, 3, 3]            --
│    └─Empty: 2-441                      [64, 64, 3, 3]            --
│    └─Empty: 2-442                      [64]                      --
│    └─Empty: 2-443                      [64]                      --
│    └─BatchNorm2d: 2-444                [16, 64, 16, 16]          --
│    └─Scaler: 2-445                     [16, 64, 16, 16]          --
│    └─ReLU: 2-446                       [16, 64, 16, 16]          --
│    └─Empty: 2-447                      [16, 64, 16, 16]          --
│    └─Clamp: 2-448                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-35                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-449         --                        --
│    └─One: 2-450                        [1]                       --
│    └─OutputScale: 2-451                --                        --
│    └─Empty: 2-452                      [4, 64, 1, 1]             --
│    └─Empty: 2-453                      [4, 64, 1, 1]             --
│    └─Empty: 2-454                      [4]                       --
│    └─Empty: 2-455                      [4]                       --
│    └─BatchNorm2d: 2-456                [16, 4, 16, 16]           --
│    └─Scaler: 2-457                     [16, 4, 16, 16]           --
│    └─ReLU: 2-458                       [16, 4, 16, 16]           --
│    └─Empty: 2-459                      [16, 4, 16, 16]           --
│    └─Clamp: 2-460                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-36         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-461                  [16, 64, 16, 16]          --
│    └─Empty: 2-462                      [16, 64, 16, 16]          --
│    └─Empty: 2-463                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-464         --                        --
│    └─One: 2-465                        [1]                       --
│    └─OutputScale: 2-466                --                        --
│    └─Empty: 2-467                      [4, 64, 3, 3]             --
│    └─Empty: 2-468                      [4, 64, 3, 3]             --
│    └─Empty: 2-469                      [4]                       --
│    └─Empty: 2-470                      [4]                       --
│    └─BatchNorm2d: 2-471                [16, 4, 16, 16]           --
│    └─Scaler: 2-472                     [16, 4, 16, 16]           --
│    └─ReLU: 2-473                       [16, 4, 16, 16]           --
│    └─Empty: 2-474                      [16, 4, 16, 16]           --
│    └─Clamp: 2-475                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-476         --                        --
│    └─One: 2-477                        [1]                       --
│    └─OutputScale: 2-478                --                        --
│    └─Empty: 2-479                      [64, 48, 1, 1]            --
│    └─Empty: 2-480                      [64, 48, 1, 1]            --
│    └─Empty: 2-481                      [64]                      --
│    └─Empty: 2-482                      [64]                      --
│    └─BatchNorm2d: 2-483                [16, 64, 64, 64]          --
│    └─Scaler: 2-484                     [16, 64, 64, 64]          --
│    └─ReLU: 2-485                       [16, 64, 64, 64]          --
│    └─Empty: 2-486                      [16, 64, 64, 64]          --
│    └─Clamp: 2-487                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-488         --                        --
│    └─One: 2-489                        [1]                       --
│    └─OutputScale: 2-490                --                        --
│    └─Empty: 2-491                      [64, 64, 3, 3]            --
│    └─Empty: 2-492                      [64, 64, 3, 3]            --
│    └─Empty: 2-493                      [64]                      --
│    └─Empty: 2-494                      [64]                      --
│    └─BatchNorm2d: 2-495                [16, 64, 64, 64]          --
│    └─Scaler: 2-496                     [16, 64, 64, 64]          --
│    └─ReLU: 2-497                       [16, 64, 64, 64]          --
│    └─Empty: 2-498                      [16, 64, 64, 64]          --
│    └─Clamp: 2-499                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-500                  [16, 64, 32, 32]          --
│    └─Empty: 2-501                      [16, 64, 32, 32]          --
│    └─Empty: 2-502                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-503         --                        --
│    └─One: 2-504                        [1]                       --
│    └─OutputScale: 2-505                --                        --
│    └─Empty: 2-506                      [64, 64, 3, 3]            --
│    └─Empty: 2-507                      [64, 64, 3, 3]            --
│    └─Empty: 2-508                      [64]                      --
│    └─Empty: 2-509                      [64]                      --
│    └─BatchNorm2d: 2-510                [16, 64, 32, 32]          --
│    └─Scaler: 2-511                     [16, 64, 32, 32]          --
│    └─ReLU: 2-512                       [16, 64, 32, 32]          --
│    └─Empty: 2-513                      [16, 64, 32, 32]          --
│    └─Clamp: 2-514                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-515         --                        --
│    └─One: 2-516                        [1]                       --
│    └─OutputScale: 2-517                --                        --
│    └─Empty: 2-518                      [64, 64, 1, 1]            --
│    └─Empty: 2-519                      [64, 64, 1, 1]            --
│    └─Empty: 2-520                      [64]                      --
│    └─Empty: 2-521                      [64]                      --
│    └─BatchNorm2d: 2-522                [16, 64, 32, 32]          --
│    └─Scaler: 2-523                     [16, 64, 32, 32]          --
│    └─ReLU: 2-524                       [16, 64, 32, 32]          --
│    └─Empty: 2-525                      [16, 64, 32, 32]          --
│    └─Clamp: 2-526                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-527                  [16, 64, 32, 32]          --
│    └─Empty: 2-528                      [16, 64, 32, 32]          --
│    └─Empty: 2-529                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-530         --                        --
│    └─One: 2-531                        [1]                       --
│    └─OutputScale: 2-532                --                        --
│    └─Empty: 2-533                      [64, 64, 3, 3]            --
│    └─Empty: 2-534                      [64, 64, 3, 3]            --
│    └─Empty: 2-535                      [64]                      --
│    └─Empty: 2-536                      [64]                      --
│    └─BatchNorm2d: 2-537                [16, 64, 32, 32]          --
│    └─Scaler: 2-538                     [16, 64, 32, 32]          --
│    └─ReLU: 2-539                       [16, 64, 32, 32]          --
│    └─Empty: 2-540                      [16, 64, 32, 32]          --
│    └─Clamp: 2-541                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-42         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-542                  [16, 64, 16, 16]          --
│    └─Empty: 2-543                      [16, 64, 16, 16]          --
│    └─Empty: 2-544                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-545         --                        --
│    └─One: 2-546                        [1]                       --
│    └─OutputScale: 2-547                --                        --
│    └─Empty: 2-548                      [64, 64, 3, 3]            --
│    └─Empty: 2-549                      [64, 64, 3, 3]            --
│    └─Empty: 2-550                      [64]                      --
│    └─Empty: 2-551                      [64]                      --
│    └─BatchNorm2d: 2-552                [16, 64, 16, 16]          --
│    └─Scaler: 2-553                     [16, 64, 16, 16]          --
│    └─ReLU: 2-554                       [16, 64, 16, 16]          --
│    └─Empty: 2-555                      [16, 64, 16, 16]          --
│    └─Clamp: 2-556                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-43                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-557         --                        --
│    └─One: 2-558                        [1]                       --
│    └─OutputScale: 2-559                --                        --
│    └─Empty: 2-560                      [4, 64, 1, 1]             --
│    └─Empty: 2-561                      [4, 64, 1, 1]             --
│    └─Empty: 2-562                      [4]                       --
│    └─Empty: 2-563                      [4]                       --
│    └─BatchNorm2d: 2-564                [16, 4, 16, 16]           --
│    └─Scaler: 2-565                     [16, 4, 16, 16]           --
│    └─ReLU: 2-566                       [16, 4, 16, 16]           --
│    └─Empty: 2-567                      [16, 4, 16, 16]           --
│    └─Clamp: 2-568                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-44         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-569                  [16, 64, 16, 16]          --
│    └─Empty: 2-570                      [16, 64, 16, 16]          --
│    └─Empty: 2-571                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-572         --                        --
│    └─One: 2-573                        [1]                       --
│    └─OutputScale: 2-574                --                        --
│    └─Empty: 2-575                      [4, 64, 3, 3]             --
│    └─Empty: 2-576                      [4, 64, 3, 3]             --
│    └─Empty: 2-577                      [4]                       --
│    └─Empty: 2-578                      [4]                       --
│    └─BatchNorm2d: 2-579                [16, 4, 16, 16]           --
│    └─Scaler: 2-580                     [16, 4, 16, 16]           --
│    └─ReLU: 2-581                       [16, 4, 16, 16]           --
│    └─Empty: 2-582                      [16, 4, 16, 16]           --
│    └─Clamp: 2-583                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-45                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-584         --                        --
│    └─One: 2-585                        [1]                       --
│    └─OutputScale: 2-586                --                        --
│    └─Empty: 2-587                      [64, 48, 1, 1]            --
│    └─Empty: 2-588                      [64, 48, 1, 1]            --
│    └─Empty: 2-589                      [64]                      --
│    └─Empty: 2-590                      [64]                      --
│    └─BatchNorm2d: 2-591                [16, 64, 64, 64]          --
│    └─Scaler: 2-592                     [16, 64, 64, 64]          --
│    └─ReLU: 2-593                       [16, 64, 64, 64]          --
│    └─Empty: 2-594                      [16, 64, 64, 64]          --
│    └─Clamp: 2-595                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-46                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-596         --                        --
│    └─One: 2-597                        [1]                       --
│    └─OutputScale: 2-598                --                        --
│    └─Empty: 2-599                      [64, 64, 3, 3]            --
│    └─Empty: 2-600                      [64, 64, 3, 3]            --
│    └─Empty: 2-601                      [64]                      --
│    └─Empty: 2-602                      [64]                      --
│    └─BatchNorm2d: 2-603                [16, 64, 64, 64]          --
│    └─Scaler: 2-604                     [16, 64, 64, 64]          --
│    └─ReLU: 2-605                       [16, 64, 64, 64]          --
│    └─Empty: 2-606                      [16, 64, 64, 64]          --
│    └─Clamp: 2-607                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-608                  [16, 64, 32, 32]          --
│    └─Empty: 2-609                      [16, 64, 32, 32]          --
│    └─Empty: 2-610                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-611         --                        --
│    └─One: 2-612                        [1]                       --
│    └─OutputScale: 2-613                --                        --
│    └─Empty: 2-614                      [64, 64, 3, 3]            --
│    └─Empty: 2-615                      [64, 64, 3, 3]            --
│    └─Empty: 2-616                      [64]                      --
│    └─Empty: 2-617                      [64]                      --
│    └─BatchNorm2d: 2-618                [16, 64, 32, 32]          --
│    └─Scaler: 2-619                     [16, 64, 32, 32]          --
│    └─ReLU: 2-620                       [16, 64, 32, 32]          --
│    └─Empty: 2-621                      [16, 64, 32, 32]          --
│    └─Clamp: 2-622                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-48                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-623         --                        --
│    └─One: 2-624                        [1]                       --
│    └─OutputScale: 2-625                --                        --
│    └─Empty: 2-626                      [64, 64, 1, 1]            --
│    └─Empty: 2-627                      [64, 64, 1, 1]            --
│    └─Empty: 2-628                      [64]                      --
│    └─Empty: 2-629                      [64]                      --
│    └─BatchNorm2d: 2-630                [16, 64, 32, 32]          --
│    └─Scaler: 2-631                     [16, 64, 32, 32]          --
│    └─ReLU: 2-632                       [16, 64, 32, 32]          --
│    └─Empty: 2-633                      [16, 64, 32, 32]          --
│    └─Clamp: 2-634                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-635                  [16, 64, 32, 32]          --
│    └─Empty: 2-636                      [16, 64, 32, 32]          --
│    └─Empty: 2-637                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-638         --                        --
│    └─One: 2-639                        [1]                       --
│    └─OutputScale: 2-640                --                        --
│    └─Empty: 2-641                      [64, 64, 3, 3]            --
│    └─Empty: 2-642                      [64, 64, 3, 3]            --
│    └─Empty: 2-643                      [64]                      --
│    └─Empty: 2-644                      [64]                      --
│    └─BatchNorm2d: 2-645                [16, 64, 32, 32]          --
│    └─Scaler: 2-646                     [16, 64, 32, 32]          --
│    └─ReLU: 2-647                       [16, 64, 32, 32]          --
│    └─Empty: 2-648                      [16, 64, 32, 32]          --
│    └─Clamp: 2-649                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-50         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-650                  [16, 64, 16, 16]          --
│    └─Empty: 2-651                      [16, 64, 16, 16]          --
│    └─Empty: 2-652                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-653         --                        --
│    └─One: 2-654                        [1]                       --
│    └─OutputScale: 2-655                --                        --
│    └─Empty: 2-656                      [64, 64, 3, 3]            --
│    └─Empty: 2-657                      [64, 64, 3, 3]            --
│    └─Empty: 2-658                      [64]                      --
│    └─Empty: 2-659                      [64]                      --
│    └─BatchNorm2d: 2-660                [16, 64, 16, 16]          --
│    └─Scaler: 2-661                     [16, 64, 16, 16]          --
│    └─ReLU: 2-662                       [16, 64, 16, 16]          --
│    └─Empty: 2-663                      [16, 64, 16, 16]          --
│    └─Clamp: 2-664                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-51                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-665         --                        --
│    └─One: 2-666                        [1]                       --
│    └─OutputScale: 2-667                --                        --
│    └─Empty: 2-668                      [4, 64, 1, 1]             --
│    └─Empty: 2-669                      [4, 64, 1, 1]             --
│    └─Empty: 2-670                      [4]                       --
│    └─Empty: 2-671                      [4]                       --
│    └─BatchNorm2d: 2-672                [16, 4, 16, 16]           --
│    └─Scaler: 2-673                     [16, 4, 16, 16]           --
│    └─ReLU: 2-674                       [16, 4, 16, 16]           --
│    └─Empty: 2-675                      [16, 4, 16, 16]           --
│    └─Clamp: 2-676                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-52         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-677                  [16, 64, 16, 16]          --
│    └─Empty: 2-678                      [16, 64, 16, 16]          --
│    └─Empty: 2-679                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-680         --                        --
│    └─One: 2-681                        [1]                       --
│    └─OutputScale: 2-682                --                        --
│    └─Empty: 2-683                      [4, 64, 3, 3]             --
│    └─Empty: 2-684                      [4, 64, 3, 3]             --
│    └─Empty: 2-685                      [4]                       --
│    └─Empty: 2-686                      [4]                       --
│    └─BatchNorm2d: 2-687                [16, 4, 16, 16]           --
│    └─Scaler: 2-688                     [16, 4, 16, 16]           --
│    └─ReLU: 2-689                       [16, 4, 16, 16]           --
│    └─Empty: 2-690                      [16, 4, 16, 16]           --
│    └─Clamp: 2-691                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-692         --                        --
│    └─One: 2-693                        [1]                       --
│    └─OutputScale: 2-694                --                        --
│    └─Empty: 2-695                      [64, 48, 1, 1]            --
│    └─Empty: 2-696                      [64, 48, 1, 1]            --
│    └─Empty: 2-697                      [64]                      --
│    └─Empty: 2-698                      [64]                      --
│    └─BatchNorm2d: 2-699                [16, 64, 64, 64]          --
│    └─Scaler: 2-700                     [16, 64, 64, 64]          --
│    └─ReLU: 2-701                       [16, 64, 64, 64]          --
│    └─Empty: 2-702                      [16, 64, 64, 64]          --
│    └─Clamp: 2-703                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-704         --                        --
│    └─One: 2-705                        [1]                       --
│    └─OutputScale: 2-706                --                        --
│    └─Empty: 2-707                      [64, 64, 3, 3]            --
│    └─Empty: 2-708                      [64, 64, 3, 3]            --
│    └─Empty: 2-709                      [64]                      --
│    └─Empty: 2-710                      [64]                      --
│    └─BatchNorm2d: 2-711                [16, 64, 64, 64]          --
│    └─Scaler: 2-712                     [16, 64, 64, 64]          --
│    └─ReLU: 2-713                       [16, 64, 64, 64]          --
│    └─Empty: 2-714                      [16, 64, 64, 64]          --
│    └─Clamp: 2-715                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-716                  [16, 64, 32, 32]          --
│    └─Empty: 2-717                      [16, 64, 32, 32]          --
│    └─Empty: 2-718                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-719         --                        --
│    └─One: 2-720                        [1]                       --
│    └─OutputScale: 2-721                --                        --
│    └─Empty: 2-722                      [64, 64, 3, 3]            --
│    └─Empty: 2-723                      [64, 64, 3, 3]            --
│    └─Empty: 2-724                      [64]                      --
│    └─Empty: 2-725                      [64]                      --
│    └─BatchNorm2d: 2-726                [16, 64, 32, 32]          --
│    └─Scaler: 2-727                     [16, 64, 32, 32]          --
│    └─ReLU: 2-728                       [16, 64, 32, 32]          --
│    └─Empty: 2-729                      [16, 64, 32, 32]          --
│    └─Clamp: 2-730                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-56                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-731         --                        --
│    └─One: 2-732                        [1]                       --
│    └─OutputScale: 2-733                --                        --
│    └─Empty: 2-734                      [64, 64, 1, 1]            --
│    └─Empty: 2-735                      [64, 64, 1, 1]            --
│    └─Empty: 2-736                      [64]                      --
│    └─Empty: 2-737                      [64]                      --
│    └─BatchNorm2d: 2-738                [16, 64, 32, 32]          --
│    └─Scaler: 2-739                     [16, 64, 32, 32]          --
│    └─ReLU: 2-740                       [16, 64, 32, 32]          --
│    └─Empty: 2-741                      [16, 64, 32, 32]          --
│    └─Clamp: 2-742                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-57         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-743                  [16, 64, 32, 32]          --
│    └─Empty: 2-744                      [16, 64, 32, 32]          --
│    └─Empty: 2-745                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-746         --                        --
│    └─One: 2-747                        [1]                       --
│    └─OutputScale: 2-748                --                        --
│    └─Empty: 2-749                      [64, 64, 3, 3]            --
│    └─Empty: 2-750                      [64, 64, 3, 3]            --
│    └─Empty: 2-751                      [64]                      --
│    └─Empty: 2-752                      [64]                      --
│    └─BatchNorm2d: 2-753                [16, 64, 32, 32]          --
│    └─Scaler: 2-754                     [16, 64, 32, 32]          --
│    └─ReLU: 2-755                       [16, 64, 32, 32]          --
│    └─Empty: 2-756                      [16, 64, 32, 32]          --
│    └─Clamp: 2-757                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-758                  [16, 64, 16, 16]          --
│    └─Empty: 2-759                      [16, 64, 16, 16]          --
│    └─Empty: 2-760                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-761         --                        --
│    └─One: 2-762                        [1]                       --
│    └─OutputScale: 2-763                --                        --
│    └─Empty: 2-764                      [64, 64, 3, 3]            --
│    └─Empty: 2-765                      [64, 64, 3, 3]            --
│    └─Empty: 2-766                      [64]                      --
│    └─Empty: 2-767                      [64]                      --
│    └─BatchNorm2d: 2-768                [16, 64, 16, 16]          --
│    └─Scaler: 2-769                     [16, 64, 16, 16]          --
│    └─ReLU: 2-770                       [16, 64, 16, 16]          --
│    └─Empty: 2-771                      [16, 64, 16, 16]          --
│    └─Clamp: 2-772                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-773         --                        --
│    └─One: 2-774                        [1]                       --
│    └─OutputScale: 2-775                --                        --
│    └─Empty: 2-776                      [4, 64, 1, 1]             --
│    └─Empty: 2-777                      [4, 64, 1, 1]             --
│    └─Empty: 2-778                      [4]                       --
│    └─Empty: 2-779                      [4]                       --
│    └─BatchNorm2d: 2-780                [16, 4, 16, 16]           --
│    └─Scaler: 2-781                     [16, 4, 16, 16]           --
│    └─ReLU: 2-782                       [16, 4, 16, 16]           --
│    └─Empty: 2-783                      [16, 4, 16, 16]           --
│    └─Clamp: 2-784                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-785                  [16, 64, 16, 16]          --
│    └─Empty: 2-786                      [16, 64, 16, 16]          --
│    └─Empty: 2-787                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-788         --                        --
│    └─One: 2-789                        [1]                       --
│    └─OutputScale: 2-790                --                        --
│    └─Empty: 2-791                      [4, 64, 3, 3]             --
│    └─Empty: 2-792                      [4, 64, 3, 3]             --
│    └─Empty: 2-793                      [4]                       --
│    └─Empty: 2-794                      [4]                       --
│    └─BatchNorm2d: 2-795                [16, 4, 16, 16]           --
│    └─Scaler: 2-796                     [16, 4, 16, 16]           --
│    └─ReLU: 2-797                       [16, 4, 16, 16]           --
│    └─Empty: 2-798                      [16, 4, 16, 16]           --
│    └─Clamp: 2-799                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-61                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-800         --                        --
│    └─One: 2-801                        [1]                       --
│    └─OutputScale: 2-802                --                        --
│    └─Empty: 2-803                      [64, 48, 1, 1]            --
│    └─Empty: 2-804                      [64, 48, 1, 1]            --
│    └─Empty: 2-805                      [64]                      --
│    └─Empty: 2-806                      [64]                      --
│    └─BatchNorm2d: 2-807                [16, 64, 64, 64]          --
│    └─Scaler: 2-808                     [16, 64, 64, 64]          --
│    └─ReLU: 2-809                       [16, 64, 64, 64]          --
│    └─Empty: 2-810                      [16, 64, 64, 64]          --
│    └─Clamp: 2-811                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-62                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-812         --                        --
│    └─One: 2-813                        [1]                       --
│    └─OutputScale: 2-814                --                        --
│    └─Empty: 2-815                      [64, 64, 3, 3]            --
│    └─Empty: 2-816                      [64, 64, 3, 3]            --
│    └─Empty: 2-817                      [64]                      --
│    └─Empty: 2-818                      [64]                      --
│    └─BatchNorm2d: 2-819                [16, 64, 64, 64]          --
│    └─Scaler: 2-820                     [16, 64, 64, 64]          --
│    └─ReLU: 2-821                       [16, 64, 64, 64]          --
│    └─Empty: 2-822                      [16, 64, 64, 64]          --
│    └─Clamp: 2-823                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-824                  [16, 64, 32, 32]          --
│    └─Empty: 2-825                      [16, 64, 32, 32]          --
│    └─Empty: 2-826                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-827         --                        --
│    └─One: 2-828                        [1]                       --
│    └─OutputScale: 2-829                --                        --
│    └─Empty: 2-830                      [64, 64, 3, 3]            --
│    └─Empty: 2-831                      [64, 64, 3, 3]            --
│    └─Empty: 2-832                      [64]                      --
│    └─Empty: 2-833                      [64]                      --
│    └─BatchNorm2d: 2-834                [16, 64, 32, 32]          --
│    └─Scaler: 2-835                     [16, 64, 32, 32]          --
│    └─ReLU: 2-836                       [16, 64, 32, 32]          --
│    └─Empty: 2-837                      [16, 64, 32, 32]          --
│    └─Clamp: 2-838                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-64                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-839         --                        --
│    └─One: 2-840                        [1]                       --
│    └─OutputScale: 2-841                --                        --
│    └─Empty: 2-842                      [64, 64, 1, 1]            --
│    └─Empty: 2-843                      [64, 64, 1, 1]            --
│    └─Empty: 2-844                      [64]                      --
│    └─Empty: 2-845                      [64]                      --
│    └─BatchNorm2d: 2-846                [16, 64, 32, 32]          --
│    └─Scaler: 2-847                     [16, 64, 32, 32]          --
│    └─ReLU: 2-848                       [16, 64, 32, 32]          --
│    └─Empty: 2-849                      [16, 64, 32, 32]          --
│    └─Clamp: 2-850                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-851                  [16, 64, 32, 32]          --
│    └─Empty: 2-852                      [16, 64, 32, 32]          --
│    └─Empty: 2-853                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-854         --                        --
│    └─One: 2-855                        [1]                       --
│    └─OutputScale: 2-856                --                        --
│    └─Empty: 2-857                      [64, 64, 3, 3]            --
│    └─Empty: 2-858                      [64, 64, 3, 3]            --
│    └─Empty: 2-859                      [64]                      --
│    └─Empty: 2-860                      [64]                      --
│    └─BatchNorm2d: 2-861                [16, 64, 32, 32]          --
│    └─Scaler: 2-862                     [16, 64, 32, 32]          --
│    └─ReLU: 2-863                       [16, 64, 32, 32]          --
│    └─Empty: 2-864                      [16, 64, 32, 32]          --
│    └─Clamp: 2-865                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-866                  [16, 64, 16, 16]          --
│    └─Empty: 2-867                      [16, 64, 16, 16]          --
│    └─Empty: 2-868                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-869         --                        --
│    └─One: 2-870                        [1]                       --
│    └─OutputScale: 2-871                --                        --
│    └─Empty: 2-872                      [64, 64, 3, 3]            --
│    └─Empty: 2-873                      [64, 64, 3, 3]            --
│    └─Empty: 2-874                      [64]                      --
│    └─Empty: 2-875                      [64]                      --
│    └─BatchNorm2d: 2-876                [16, 64, 16, 16]          --
│    └─Scaler: 2-877                     [16, 64, 16, 16]          --
│    └─ReLU: 2-878                       [16, 64, 16, 16]          --
│    └─Empty: 2-879                      [16, 64, 16, 16]          --
│    └─Clamp: 2-880                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-67                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-881         --                        --
│    └─One: 2-882                        [1]                       --
│    └─OutputScale: 2-883                --                        --
│    └─Empty: 2-884                      [4, 64, 1, 1]             --
│    └─Empty: 2-885                      [4, 64, 1, 1]             --
│    └─Empty: 2-886                      [4]                       --
│    └─Empty: 2-887                      [4]                       --
│    └─BatchNorm2d: 2-888                [16, 4, 16, 16]           --
│    └─Scaler: 2-889                     [16, 4, 16, 16]           --
│    └─ReLU: 2-890                       [16, 4, 16, 16]           --
│    └─Empty: 2-891                      [16, 4, 16, 16]           --
│    └─Clamp: 2-892                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-893                  [16, 64, 16, 16]          --
│    └─Empty: 2-894                      [16, 64, 16, 16]          --
│    └─Empty: 2-895                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-896         --                        --
│    └─One: 2-897                        [1]                       --
│    └─OutputScale: 2-898                --                        --
│    └─Empty: 2-899                      [4, 64, 3, 3]             --
│    └─Empty: 2-900                      [4, 64, 3, 3]             --
│    └─Empty: 2-901                      [4]                       --
│    └─Empty: 2-902                      [4]                       --
│    └─BatchNorm2d: 2-903                [16, 4, 16, 16]           --
│    └─Scaler: 2-904                     [16, 4, 16, 16]           --
│    └─ReLU: 2-905                       [16, 4, 16, 16]           --
│    └─Empty: 2-906                      [16, 4, 16, 16]           --
│    └─Clamp: 2-907                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-908         --                        --
│    └─One: 2-909                        [1]                       --
│    └─OutputScale: 2-910                --                        --
│    └─Empty: 2-911                      [64, 48, 1, 1]            --
│    └─Empty: 2-912                      [64, 48, 1, 1]            --
│    └─Empty: 2-913                      [64]                      --
│    └─Empty: 2-914                      [64]                      --
│    └─BatchNorm2d: 2-915                [16, 64, 64, 64]          --
│    └─Scaler: 2-916                     [16, 64, 64, 64]          --
│    └─ReLU: 2-917                       [16, 64, 64, 64]          --
│    └─Empty: 2-918                      [16, 64, 64, 64]          --
│    └─Clamp: 2-919                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-920         --                        --
│    └─One: 2-921                        [1]                       --
│    └─OutputScale: 2-922                --                        --
│    └─Empty: 2-923                      [64, 64, 3, 3]            --
│    └─Empty: 2-924                      [64, 64, 3, 3]            --
│    └─Empty: 2-925                      [64]                      --
│    └─Empty: 2-926                      [64]                      --
│    └─BatchNorm2d: 2-927                [16, 64, 64, 64]          --
│    └─Scaler: 2-928                     [16, 64, 64, 64]          --
│    └─ReLU: 2-929                       [16, 64, 64, 64]          --
│    └─Empty: 2-930                      [16, 64, 64, 64]          --
│    └─Clamp: 2-931                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-71         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-932                  [16, 64, 32, 32]          --
│    └─Empty: 2-933                      [16, 64, 32, 32]          --
│    └─Empty: 2-934                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-935         --                        --
│    └─One: 2-936                        [1]                       --
│    └─OutputScale: 2-937                --                        --
│    └─Empty: 2-938                      [64, 64, 3, 3]            --
│    └─Empty: 2-939                      [64, 64, 3, 3]            --
│    └─Empty: 2-940                      [64]                      --
│    └─Empty: 2-941                      [64]                      --
│    └─BatchNorm2d: 2-942                [16, 64, 32, 32]          --
│    └─Scaler: 2-943                     [16, 64, 32, 32]          --
│    └─ReLU: 2-944                       [16, 64, 32, 32]          --
│    └─Empty: 2-945                      [16, 64, 32, 32]          --
│    └─Clamp: 2-946                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-947         --                        --
│    └─One: 2-948                        [1]                       --
│    └─OutputScale: 2-949                --                        --
│    └─Empty: 2-950                      [64, 64, 1, 1]            --
│    └─Empty: 2-951                      [64, 64, 1, 1]            --
│    └─Empty: 2-952                      [64]                      --
│    └─Empty: 2-953                      [64]                      --
│    └─BatchNorm2d: 2-954                [16, 64, 32, 32]          --
│    └─Scaler: 2-955                     [16, 64, 32, 32]          --
│    └─ReLU: 2-956                       [16, 64, 32, 32]          --
│    └─Empty: 2-957                      [16, 64, 32, 32]          --
│    └─Clamp: 2-958                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-959                  [16, 64, 32, 32]          --
│    └─Empty: 2-960                      [16, 64, 32, 32]          --
│    └─Empty: 2-961                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-962         --                        --
│    └─One: 2-963                        [1]                       --
│    └─OutputScale: 2-964                --                        --
│    └─Empty: 2-965                      [64, 64, 3, 3]            --
│    └─Empty: 2-966                      [64, 64, 3, 3]            --
│    └─Empty: 2-967                      [64]                      --
│    └─Empty: 2-968                      [64]                      --
│    └─BatchNorm2d: 2-969                [16, 64, 32, 32]          --
│    └─Scaler: 2-970                     [16, 64, 32, 32]          --
│    └─ReLU: 2-971                       [16, 64, 32, 32]          --
│    └─Empty: 2-972                      [16, 64, 32, 32]          --
│    └─Clamp: 2-973                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-74         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-974                  [16, 64, 16, 16]          --
│    └─Empty: 2-975                      [16, 64, 16, 16]          --
│    └─Empty: 2-976                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-977         --                        --
│    └─One: 2-978                        [1]                       --
│    └─OutputScale: 2-979                --                        --
│    └─Empty: 2-980                      [64, 64, 3, 3]            --
│    └─Empty: 2-981                      [64, 64, 3, 3]            --
│    └─Empty: 2-982                      [64]                      --
│    └─Empty: 2-983                      [64]                      --
│    └─BatchNorm2d: 2-984                [16, 64, 16, 16]          --
│    └─Scaler: 2-985                     [16, 64, 16, 16]          --
│    └─ReLU: 2-986                       [16, 64, 16, 16]          --
│    └─Empty: 2-987                      [16, 64, 16, 16]          --
│    └─Clamp: 2-988                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-75                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-989         --                        --
│    └─One: 2-990                        [1]                       --
│    └─OutputScale: 2-991                --                        --
│    └─Empty: 2-992                      [4, 64, 1, 1]             --
│    └─Empty: 2-993                      [4, 64, 1, 1]             --
│    └─Empty: 2-994                      [4]                       --
│    └─Empty: 2-995                      [4]                       --
│    └─BatchNorm2d: 2-996                [16, 4, 16, 16]           --
│    └─Scaler: 2-997                     [16, 4, 16, 16]           --
│    └─ReLU: 2-998                       [16, 4, 16, 16]           --
│    └─Empty: 2-999                      [16, 4, 16, 16]           --
│    └─Clamp: 2-1000                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-76         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1001                 [16, 64, 16, 16]          --
│    └─Empty: 2-1002                     [16, 64, 16, 16]          --
│    └─Empty: 2-1003                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1004        --                        --
│    └─One: 2-1005                       [1]                       --
│    └─OutputScale: 2-1006               --                        --
│    └─Empty: 2-1007                     [4, 64, 3, 3]             --
│    └─Empty: 2-1008                     [4, 64, 3, 3]             --
│    └─Empty: 2-1009                     [4]                       --
│    └─Empty: 2-1010                     [4]                       --
│    └─BatchNorm2d: 2-1011               [16, 4, 16, 16]           --
│    └─Scaler: 2-1012                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1013                      [16, 4, 16, 16]           --
│    └─Empty: 2-1014                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1015                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-77                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1016        --                        --
│    └─One: 2-1017                       [1]                       --
│    └─OutputScale: 2-1018               --                        --
│    └─Empty: 2-1019                     [64, 48, 1, 1]            --
│    └─Empty: 2-1020                     [64, 48, 1, 1]            --
│    └─Empty: 2-1021                     [64]                      --
│    └─Empty: 2-1022                     [64]                      --
│    └─BatchNorm2d: 2-1023               [16, 64, 64, 64]          --
│    └─Scaler: 2-1024                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1025                      [16, 64, 64, 64]          --
│    └─Empty: 2-1026                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1027                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-78                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1028        --                        --
│    └─One: 2-1029                       [1]                       --
│    └─OutputScale: 2-1030               --                        --
│    └─Empty: 2-1031                     [64, 64, 3, 3]            --
│    └─Empty: 2-1032                     [64, 64, 3, 3]            --
│    └─Empty: 2-1033                     [64]                      --
│    └─Empty: 2-1034                     [64]                      --
│    └─BatchNorm2d: 2-1035               [16, 64, 64, 64]          --
│    └─Scaler: 2-1036                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1037                      [16, 64, 64, 64]          --
│    └─Empty: 2-1038                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1039                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1040                 [16, 64, 32, 32]          --
│    └─Empty: 2-1041                     [16, 64, 32, 32]          --
│    └─Empty: 2-1042                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1043        --                        --
│    └─One: 2-1044                       [1]                       --
│    └─OutputScale: 2-1045               --                        --
│    └─Empty: 2-1046                     [64, 64, 3, 3]            --
│    └─Empty: 2-1047                     [64, 64, 3, 3]            --
│    └─Empty: 2-1048                     [64]                      --
│    └─Empty: 2-1049                     [64]                      --
│    └─BatchNorm2d: 2-1050               [16, 64, 32, 32]          --
│    └─Scaler: 2-1051                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1052                      [16, 64, 32, 32]          --
│    └─Empty: 2-1053                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1054                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-80                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1055        --                        --
│    └─One: 2-1056                       [1]                       --
│    └─OutputScale: 2-1057               --                        --
│    └─Empty: 2-1058                     [64, 64, 1, 1]            --
│    └─Empty: 2-1059                     [64, 64, 1, 1]            --
│    └─Empty: 2-1060                     [64]                      --
│    └─Empty: 2-1061                     [64]                      --
│    └─BatchNorm2d: 2-1062               [16, 64, 32, 32]          --
│    └─Scaler: 2-1063                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1064                      [16, 64, 32, 32]          --
│    └─Empty: 2-1065                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1066                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1067                 [16, 64, 32, 32]          --
│    └─Empty: 2-1068                     [16, 64, 32, 32]          --
│    └─Empty: 2-1069                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1070        --                        --
│    └─One: 2-1071                       [1]                       --
│    └─OutputScale: 2-1072               --                        --
│    └─Empty: 2-1073                     [64, 64, 3, 3]            --
│    └─Empty: 2-1074                     [64, 64, 3, 3]            --
│    └─Empty: 2-1075                     [64]                      --
│    └─Empty: 2-1076                     [64]                      --
│    └─BatchNorm2d: 2-1077               [16, 64, 32, 32]          --
│    └─Scaler: 2-1078                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1079                      [16, 64, 32, 32]          --
│    └─Empty: 2-1080                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1081                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1082                 [16, 64, 16, 16]          --
│    └─Empty: 2-1083                     [16, 64, 16, 16]          --
│    └─Empty: 2-1084                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1085        --                        --
│    └─One: 2-1086                       [1]                       --
│    └─OutputScale: 2-1087               --                        --
│    └─Empty: 2-1088                     [64, 64, 3, 3]            --
│    └─Empty: 2-1089                     [64, 64, 3, 3]            --
│    └─Empty: 2-1090                     [64]                      --
│    └─Empty: 2-1091                     [64]                      --
│    └─BatchNorm2d: 2-1092               [16, 64, 16, 16]          --
│    └─Scaler: 2-1093                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1094                      [16, 64, 16, 16]          --
│    └─Empty: 2-1095                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1096                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-83                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1097        --                        --
│    └─One: 2-1098                       [1]                       --
│    └─OutputScale: 2-1099               --                        --
│    └─Empty: 2-1100                     [4, 64, 1, 1]             --
│    └─Empty: 2-1101                     [4, 64, 1, 1]             --
│    └─Empty: 2-1102                     [4]                       --
│    └─Empty: 2-1103                     [4]                       --
│    └─BatchNorm2d: 2-1104               [16, 4, 16, 16]           --
│    └─Scaler: 2-1105                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1106                      [16, 4, 16, 16]           --
│    └─Empty: 2-1107                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1108                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-84         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1109                 [16, 64, 16, 16]          --
│    └─Empty: 2-1110                     [16, 64, 16, 16]          --
│    └─Empty: 2-1111                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1112        --                        --
│    └─One: 2-1113                       [1]                       --
│    └─OutputScale: 2-1114               --                        --
│    └─Empty: 2-1115                     [4, 64, 3, 3]             --
│    └─Empty: 2-1116                     [4, 64, 3, 3]             --
│    └─Empty: 2-1117                     [4]                       --
│    └─Empty: 2-1118                     [4]                       --
│    └─BatchNorm2d: 2-1119               [16, 4, 16, 16]           --
│    └─Scaler: 2-1120                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1121                      [16, 4, 16, 16]           --
│    └─Empty: 2-1122                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1123                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-85                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1124        --                        --
│    └─One: 2-1125                       [1]                       --
│    └─OutputScale: 2-1126               --                        --
│    └─Empty: 2-1127                     [64, 48, 1, 1]            --
│    └─Empty: 2-1128                     [64, 48, 1, 1]            --
│    └─Empty: 2-1129                     [64]                      --
│    └─Empty: 2-1130                     [64]                      --
│    └─BatchNorm2d: 2-1131               [16, 64, 64, 64]          --
│    └─Scaler: 2-1132                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1133                      [16, 64, 64, 64]          --
│    └─Empty: 2-1134                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1135                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1136        --                        --
│    └─One: 2-1137                       [1]                       --
│    └─OutputScale: 2-1138               --                        --
│    └─Empty: 2-1139                     [64, 64, 3, 3]            --
│    └─Empty: 2-1140                     [64, 64, 3, 3]            --
│    └─Empty: 2-1141                     [64]                      --
│    └─Empty: 2-1142                     [64]                      --
│    └─BatchNorm2d: 2-1143               [16, 64, 64, 64]          --
│    └─Scaler: 2-1144                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1145                      [16, 64, 64, 64]          --
│    └─Empty: 2-1146                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1147                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-87         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1148                 [16, 64, 32, 32]          --
│    └─Empty: 2-1149                     [16, 64, 32, 32]          --
│    └─Empty: 2-1150                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1151        --                        --
│    └─One: 2-1152                       [1]                       --
│    └─OutputScale: 2-1153               --                        --
│    └─Empty: 2-1154                     [64, 64, 3, 3]            --
│    └─Empty: 2-1155                     [64, 64, 3, 3]            --
│    └─Empty: 2-1156                     [64]                      --
│    └─Empty: 2-1157                     [64]                      --
│    └─BatchNorm2d: 2-1158               [16, 64, 32, 32]          --
│    └─Scaler: 2-1159                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1160                      [16, 64, 32, 32]          --
│    └─Empty: 2-1161                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1162                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1163        --                        --
│    └─One: 2-1164                       [1]                       --
│    └─OutputScale: 2-1165               --                        --
│    └─Empty: 2-1166                     [64, 64, 1, 1]            --
│    └─Empty: 2-1167                     [64, 64, 1, 1]            --
│    └─Empty: 2-1168                     [64]                      --
│    └─Empty: 2-1169                     [64]                      --
│    └─BatchNorm2d: 2-1170               [16, 64, 32, 32]          --
│    └─Scaler: 2-1171                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1172                      [16, 64, 32, 32]          --
│    └─Empty: 2-1173                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1174                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1175                 [16, 64, 32, 32]          --
│    └─Empty: 2-1176                     [16, 64, 32, 32]          --
│    └─Empty: 2-1177                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1178        --                        --
│    └─One: 2-1179                       [1]                       --
│    └─OutputScale: 2-1180               --                        --
│    └─Empty: 2-1181                     [64, 64, 3, 3]            --
│    └─Empty: 2-1182                     [64, 64, 3, 3]            --
│    └─Empty: 2-1183                     [64]                      --
│    └─Empty: 2-1184                     [64]                      --
│    └─BatchNorm2d: 2-1185               [16, 64, 32, 32]          --
│    └─Scaler: 2-1186                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1187                      [16, 64, 32, 32]          --
│    └─Empty: 2-1188                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1189                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1190                 [16, 64, 16, 16]          --
│    └─Empty: 2-1191                     [16, 64, 16, 16]          --
│    └─Empty: 2-1192                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1193        --                        --
│    └─One: 2-1194                       [1]                       --
│    └─OutputScale: 2-1195               --                        --
│    └─Empty: 2-1196                     [64, 64, 3, 3]            --
│    └─Empty: 2-1197                     [64, 64, 3, 3]            --
│    └─Empty: 2-1198                     [64]                      --
│    └─Empty: 2-1199                     [64]                      --
│    └─BatchNorm2d: 2-1200               [16, 64, 16, 16]          --
│    └─Scaler: 2-1201                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1202                      [16, 64, 16, 16]          --
│    └─Empty: 2-1203                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1204                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-91                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1205        --                        --
│    └─One: 2-1206                       [1]                       --
│    └─OutputScale: 2-1207               --                        --
│    └─Empty: 2-1208                     [4, 64, 1, 1]             --
│    └─Empty: 2-1209                     [4, 64, 1, 1]             --
│    └─Empty: 2-1210                     [4]                       --
│    └─Empty: 2-1211                     [4]                       --
│    └─BatchNorm2d: 2-1212               [16, 4, 16, 16]           --
│    └─Scaler: 2-1213                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1214                      [16, 4, 16, 16]           --
│    └─Empty: 2-1215                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1216                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1217                 [16, 64, 16, 16]          --
│    └─Empty: 2-1218                     [16, 64, 16, 16]          --
│    └─Empty: 2-1219                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1220        --                        --
│    └─One: 2-1221                       [1]                       --
│    └─OutputScale: 2-1222               --                        --
│    └─Empty: 2-1223                     [4, 64, 3, 3]             --
│    └─Empty: 2-1224                     [4, 64, 3, 3]             --
│    └─Empty: 2-1225                     [4]                       --
│    └─Empty: 2-1226                     [4]                       --
│    └─BatchNorm2d: 2-1227               [16, 4, 16, 16]           --
│    └─Scaler: 2-1228                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1229                      [16, 4, 16, 16]           --
│    └─Empty: 2-1230                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1231                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-93                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1232        --                        --
│    └─One: 2-1233                       [1]                       --
│    └─OutputScale: 2-1234               --                        --
│    └─Empty: 2-1235                     [64, 48, 1, 1]            --
│    └─Empty: 2-1236                     [64, 48, 1, 1]            --
│    └─Empty: 2-1237                     [64]                      --
│    └─Empty: 2-1238                     [64]                      --
│    └─BatchNorm2d: 2-1239               [16, 64, 64, 64]          --
│    └─Scaler: 2-1240                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1241                      [16, 64, 64, 64]          --
│    └─Empty: 2-1242                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1243                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-94                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1244        --                        --
│    └─One: 2-1245                       [1]                       --
│    └─OutputScale: 2-1246               --                        --
│    └─Empty: 2-1247                     [64, 64, 3, 3]            --
│    └─Empty: 2-1248                     [64, 64, 3, 3]            --
│    └─Empty: 2-1249                     [64]                      --
│    └─Empty: 2-1250                     [64]                      --
│    └─BatchNorm2d: 2-1251               [16, 64, 64, 64]          --
│    └─Scaler: 2-1252                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1253                      [16, 64, 64, 64]          --
│    └─Empty: 2-1254                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1255                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1256                 [16, 64, 32, 32]          --
│    └─Empty: 2-1257                     [16, 64, 32, 32]          --
│    └─Empty: 2-1258                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1259        --                        --
│    └─One: 2-1260                       [1]                       --
│    └─OutputScale: 2-1261               --                        --
│    └─Empty: 2-1262                     [64, 64, 3, 3]            --
│    └─Empty: 2-1263                     [64, 64, 3, 3]            --
│    └─Empty: 2-1264                     [64]                      --
│    └─Empty: 2-1265                     [64]                      --
│    └─BatchNorm2d: 2-1266               [16, 64, 32, 32]          --
│    └─Scaler: 2-1267                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1268                      [16, 64, 32, 32]          --
│    └─Empty: 2-1269                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1270                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-96                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1271        --                        --
│    └─One: 2-1272                       [1]                       --
│    └─OutputScale: 2-1273               --                        --
│    └─Empty: 2-1274                     [64, 64, 1, 1]            --
│    └─Empty: 2-1275                     [64, 64, 1, 1]            --
│    └─Empty: 2-1276                     [64]                      --
│    └─Empty: 2-1277                     [64]                      --
│    └─BatchNorm2d: 2-1278               [16, 64, 32, 32]          --
│    └─Scaler: 2-1279                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1280                      [16, 64, 32, 32]          --
│    └─Empty: 2-1281                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1282                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1283                 [16, 64, 32, 32]          --
│    └─Empty: 2-1284                     [16, 64, 32, 32]          --
│    └─Empty: 2-1285                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1286        --                        --
│    └─One: 2-1287                       [1]                       --
│    └─OutputScale: 2-1288               --                        --
│    └─Empty: 2-1289                     [64, 64, 3, 3]            --
│    └─Empty: 2-1290                     [64, 64, 3, 3]            --
│    └─Empty: 2-1291                     [64]                      --
│    └─Empty: 2-1292                     [64]                      --
│    └─BatchNorm2d: 2-1293               [16, 64, 32, 32]          --
│    └─Scaler: 2-1294                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1295                      [16, 64, 32, 32]          --
│    └─Empty: 2-1296                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1297                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-98         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1298                 [16, 64, 16, 16]          --
│    └─Empty: 2-1299                     [16, 64, 16, 16]          --
│    └─Empty: 2-1300                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1301        --                        --
│    └─One: 2-1302                       [1]                       --
│    └─OutputScale: 2-1303               --                        --
│    └─Empty: 2-1304                     [64, 64, 3, 3]            --
│    └─Empty: 2-1305                     [64, 64, 3, 3]            --
│    └─Empty: 2-1306                     [64]                      --
│    └─Empty: 2-1307                     [64]                      --
│    └─BatchNorm2d: 2-1308               [16, 64, 16, 16]          --
│    └─Scaler: 2-1309                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1310                      [16, 64, 16, 16]          --
│    └─Empty: 2-1311                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1312                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-99                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1313        --                        --
│    └─One: 2-1314                       [1]                       --
│    └─OutputScale: 2-1315               --                        --
│    └─Empty: 2-1316                     [4, 64, 1, 1]             --
│    └─Empty: 2-1317                     [4, 64, 1, 1]             --
│    └─Empty: 2-1318                     [4]                       --
│    └─Empty: 2-1319                     [4]                       --
│    └─BatchNorm2d: 2-1320               [16, 4, 16, 16]           --
│    └─Scaler: 2-1321                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1322                      [16, 4, 16, 16]           --
│    └─Empty: 2-1323                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1324                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1325                 [16, 64, 16, 16]          --
│    └─Empty: 2-1326                     [16, 64, 16, 16]          --
│    └─Empty: 2-1327                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1328        --                        --
│    └─One: 2-1329                       [1]                       --
│    └─OutputScale: 2-1330               --                        --
│    └─Empty: 2-1331                     [4, 64, 3, 3]             --
│    └─Empty: 2-1332                     [4, 64, 3, 3]             --
│    └─Empty: 2-1333                     [4]                       --
│    └─Empty: 2-1334                     [4]                       --
│    └─BatchNorm2d: 2-1335               [16, 4, 16, 16]           --
│    └─Scaler: 2-1336                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1337                      [16, 4, 16, 16]           --
│    └─Empty: 2-1338                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1339                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-101               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1340        --                        --
│    └─One: 2-1341                       [1]                       --
│    └─OutputScale: 2-1342               --                        --
│    └─Empty: 2-1343                     [64, 48, 1, 1]            --
│    └─Empty: 2-1344                     [64, 48, 1, 1]            --
│    └─Empty: 2-1345                     [64]                      --
│    └─Empty: 2-1346                     [64]                      --
│    └─BatchNorm2d: 2-1347               [16, 64, 64, 64]          --
│    └─Scaler: 2-1348                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1349                      [16, 64, 64, 64]          --
│    └─Empty: 2-1350                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1351                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-102               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1352        --                        --
│    └─One: 2-1353                       [1]                       --
│    └─OutputScale: 2-1354               --                        --
│    └─Empty: 2-1355                     [64, 64, 3, 3]            --
│    └─Empty: 2-1356                     [64, 64, 3, 3]            --
│    └─Empty: 2-1357                     [64]                      --
│    └─Empty: 2-1358                     [64]                      --
│    └─BatchNorm2d: 2-1359               [16, 64, 64, 64]          --
│    └─Scaler: 2-1360                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1361                      [16, 64, 64, 64]          --
│    └─Empty: 2-1362                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1363                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1364                 [16, 64, 32, 32]          --
│    └─Empty: 2-1365                     [16, 64, 32, 32]          --
│    └─Empty: 2-1366                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1367        --                        --
│    └─One: 2-1368                       [1]                       --
│    └─OutputScale: 2-1369               --                        --
│    └─Empty: 2-1370                     [64, 64, 3, 3]            --
│    └─Empty: 2-1371                     [64, 64, 3, 3]            --
│    └─Empty: 2-1372                     [64]                      --
│    └─Empty: 2-1373                     [64]                      --
│    └─BatchNorm2d: 2-1374               [16, 64, 32, 32]          --
│    └─Scaler: 2-1375                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1376                      [16, 64, 32, 32]          --
│    └─Empty: 2-1377                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1378                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1379        --                        --
│    └─One: 2-1380                       [1]                       --
│    └─OutputScale: 2-1381               --                        --
│    └─Empty: 2-1382                     [64, 64, 1, 1]            --
│    └─Empty: 2-1383                     [64, 64, 1, 1]            --
│    └─Empty: 2-1384                     [64]                      --
│    └─Empty: 2-1385                     [64]                      --
│    └─BatchNorm2d: 2-1386               [16, 64, 32, 32]          --
│    └─Scaler: 2-1387                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1388                      [16, 64, 32, 32]          --
│    └─Empty: 2-1389                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1390                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-105        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1391                 [16, 64, 32, 32]          --
│    └─Empty: 2-1392                     [16, 64, 32, 32]          --
│    └─Empty: 2-1393                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1394        --                        --
│    └─One: 2-1395                       [1]                       --
│    └─OutputScale: 2-1396               --                        --
│    └─Empty: 2-1397                     [64, 64, 3, 3]            --
│    └─Empty: 2-1398                     [64, 64, 3, 3]            --
│    └─Empty: 2-1399                     [64]                      --
│    └─Empty: 2-1400                     [64]                      --
│    └─BatchNorm2d: 2-1401               [16, 64, 32, 32]          --
│    └─Scaler: 2-1402                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1403                      [16, 64, 32, 32]          --
│    └─Empty: 2-1404                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1405                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-106        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1406                 [16, 64, 16, 16]          --
│    └─Empty: 2-1407                     [16, 64, 16, 16]          --
│    └─Empty: 2-1408                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1409        --                        --
│    └─One: 2-1410                       [1]                       --
│    └─OutputScale: 2-1411               --                        --
│    └─Empty: 2-1412                     [64, 64, 3, 3]            --
│    └─Empty: 2-1413                     [64, 64, 3, 3]            --
│    └─Empty: 2-1414                     [64]                      --
│    └─Empty: 2-1415                     [64]                      --
│    └─BatchNorm2d: 2-1416               [16, 64, 16, 16]          --
│    └─Scaler: 2-1417                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1418                      [16, 64, 16, 16]          --
│    └─Empty: 2-1419                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1420                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-107               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1421        --                        --
│    └─One: 2-1422                       [1]                       --
│    └─OutputScale: 2-1423               --                        --
│    └─Empty: 2-1424                     [4, 64, 1, 1]             --
│    └─Empty: 2-1425                     [4, 64, 1, 1]             --
│    └─Empty: 2-1426                     [4]                       --
│    └─Empty: 2-1427                     [4]                       --
│    └─BatchNorm2d: 2-1428               [16, 4, 16, 16]           --
│    └─Scaler: 2-1429                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1430                      [16, 4, 16, 16]           --
│    └─Empty: 2-1431                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1432                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-108        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1433                 [16, 64, 16, 16]          --
│    └─Empty: 2-1434                     [16, 64, 16, 16]          --
│    └─Empty: 2-1435                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1436        --                        --
│    └─One: 2-1437                       [1]                       --
│    └─OutputScale: 2-1438               --                        --
│    └─Empty: 2-1439                     [4, 64, 3, 3]             --
│    └─Empty: 2-1440                     [4, 64, 3, 3]             --
│    └─Empty: 2-1441                     [4]                       --
│    └─Empty: 2-1442                     [4]                       --
│    └─BatchNorm2d: 2-1443               [16, 4, 16, 16]           --
│    └─Scaler: 2-1444                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1445                      [16, 4, 16, 16]           --
│    └─Empty: 2-1446                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1447                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-109               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1448        --                        --
│    └─One: 2-1449                       [1]                       --
│    └─OutputScale: 2-1450               --                        --
│    └─Empty: 2-1451                     [64, 48, 1, 1]            --
│    └─Empty: 2-1452                     [64, 48, 1, 1]            --
│    └─Empty: 2-1453                     [64]                      --
│    └─Empty: 2-1454                     [64]                      --
│    └─BatchNorm2d: 2-1455               [16, 64, 64, 64]          --
│    └─Scaler: 2-1456                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1457                      [16, 64, 64, 64]          --
│    └─Empty: 2-1458                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1459                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1460        --                        --
│    └─One: 2-1461                       [1]                       --
│    └─OutputScale: 2-1462               --                        --
│    └─Empty: 2-1463                     [64, 64, 3, 3]            --
│    └─Empty: 2-1464                     [64, 64, 3, 3]            --
│    └─Empty: 2-1465                     [64]                      --
│    └─Empty: 2-1466                     [64]                      --
│    └─BatchNorm2d: 2-1467               [16, 64, 64, 64]          --
│    └─Scaler: 2-1468                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1469                      [16, 64, 64, 64]          --
│    └─Empty: 2-1470                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1471                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1472                 [16, 64, 32, 32]          --
│    └─Empty: 2-1473                     [16, 64, 32, 32]          --
│    └─Empty: 2-1474                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1475        --                        --
│    └─One: 2-1476                       [1]                       --
│    └─OutputScale: 2-1477               --                        --
│    └─Empty: 2-1478                     [64, 64, 3, 3]            --
│    └─Empty: 2-1479                     [64, 64, 3, 3]            --
│    └─Empty: 2-1480                     [64]                      --
│    └─Empty: 2-1481                     [64]                      --
│    └─BatchNorm2d: 2-1482               [16, 64, 32, 32]          --
│    └─Scaler: 2-1483                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1484                      [16, 64, 32, 32]          --
│    └─Empty: 2-1485                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1486                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-112               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1487        --                        --
│    └─One: 2-1488                       [1]                       --
│    └─OutputScale: 2-1489               --                        --
│    └─Empty: 2-1490                     [64, 64, 1, 1]            --
│    └─Empty: 2-1491                     [64, 64, 1, 1]            --
│    └─Empty: 2-1492                     [64]                      --
│    └─Empty: 2-1493                     [64]                      --
│    └─BatchNorm2d: 2-1494               [16, 64, 32, 32]          --
│    └─Scaler: 2-1495                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1496                      [16, 64, 32, 32]          --
│    └─Empty: 2-1497                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1498                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1499                 [16, 64, 32, 32]          --
│    └─Empty: 2-1500                     [16, 64, 32, 32]          --
│    └─Empty: 2-1501                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1502        --                        --
│    └─One: 2-1503                       [1]                       --
│    └─OutputScale: 2-1504               --                        --
│    └─Empty: 2-1505                     [64, 64, 3, 3]            --
│    └─Empty: 2-1506                     [64, 64, 3, 3]            --
│    └─Empty: 2-1507                     [64]                      --
│    └─Empty: 2-1508                     [64]                      --
│    └─BatchNorm2d: 2-1509               [16, 64, 32, 32]          --
│    └─Scaler: 2-1510                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1511                      [16, 64, 32, 32]          --
│    └─Empty: 2-1512                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1513                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1514                 [16, 64, 16, 16]          --
│    └─Empty: 2-1515                     [16, 64, 16, 16]          --
│    └─Empty: 2-1516                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1517        --                        --
│    └─One: 2-1518                       [1]                       --
│    └─OutputScale: 2-1519               --                        --
│    └─Empty: 2-1520                     [64, 64, 3, 3]            --
│    └─Empty: 2-1521                     [64, 64, 3, 3]            --
│    └─Empty: 2-1522                     [64]                      --
│    └─Empty: 2-1523                     [64]                      --
│    └─BatchNorm2d: 2-1524               [16, 64, 16, 16]          --
│    └─Scaler: 2-1525                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1526                      [16, 64, 16, 16]          --
│    └─Empty: 2-1527                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1528                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-115               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1529        --                        --
│    └─One: 2-1530                       [1]                       --
│    └─OutputScale: 2-1531               --                        --
│    └─Empty: 2-1532                     [4, 64, 1, 1]             --
│    └─Empty: 2-1533                     [4, 64, 1, 1]             --
│    └─Empty: 2-1534                     [4]                       --
│    └─Empty: 2-1535                     [4]                       --
│    └─BatchNorm2d: 2-1536               [16, 4, 16, 16]           --
│    └─Scaler: 2-1537                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1538                      [16, 4, 16, 16]           --
│    └─Empty: 2-1539                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1540                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1541                 [16, 64, 16, 16]          --
│    └─Empty: 2-1542                     [16, 64, 16, 16]          --
│    └─Empty: 2-1543                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1544        --                        --
│    └─One: 2-1545                       [1]                       --
│    └─OutputScale: 2-1546               --                        --
│    └─Empty: 2-1547                     [4, 64, 3, 3]             --
│    └─Empty: 2-1548                     [4, 64, 3, 3]             --
│    └─Empty: 2-1549                     [4]                       --
│    └─Empty: 2-1550                     [4]                       --
│    └─BatchNorm2d: 2-1551               [16, 4, 16, 16]           --
│    └─Scaler: 2-1552                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1553                      [16, 4, 16, 16]           --
│    └─Empty: 2-1554                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1555                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-117               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1556        --                        --
│    └─One: 2-1557                       [1]                       --
│    └─OutputScale: 2-1558               --                        --
│    └─Empty: 2-1559                     [64, 48, 1, 1]            --
│    └─Empty: 2-1560                     [64, 48, 1, 1]            --
│    └─Empty: 2-1561                     [64]                      --
│    └─Empty: 2-1562                     [64]                      --
│    └─BatchNorm2d: 2-1563               [16, 64, 64, 64]          --
│    └─Scaler: 2-1564                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1565                      [16, 64, 64, 64]          --
│    └─Empty: 2-1566                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1567                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-118               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1568        --                        --
│    └─One: 2-1569                       [1]                       --
│    └─OutputScale: 2-1570               --                        --
│    └─Empty: 2-1571                     [64, 64, 3, 3]            --
│    └─Empty: 2-1572                     [64, 64, 3, 3]            --
│    └─Empty: 2-1573                     [64]                      --
│    └─Empty: 2-1574                     [64]                      --
│    └─BatchNorm2d: 2-1575               [16, 64, 64, 64]          --
│    └─Scaler: 2-1576                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1577                      [16, 64, 64, 64]          --
│    └─Empty: 2-1578                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1579                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1580                 [16, 64, 32, 32]          --
│    └─Empty: 2-1581                     [16, 64, 32, 32]          --
│    └─Empty: 2-1582                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1583        --                        --
│    └─One: 2-1584                       [1]                       --
│    └─OutputScale: 2-1585               --                        --
│    └─Empty: 2-1586                     [64, 64, 3, 3]            --
│    └─Empty: 2-1587                     [64, 64, 3, 3]            --
│    └─Empty: 2-1588                     [64]                      --
│    └─Empty: 2-1589                     [64]                      --
│    └─BatchNorm2d: 2-1590               [16, 64, 32, 32]          --
│    └─Scaler: 2-1591                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1592                      [16, 64, 32, 32]          --
│    └─Empty: 2-1593                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1594                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-120               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1595        --                        --
│    └─One: 2-1596                       [1]                       --
│    └─OutputScale: 2-1597               --                        --
│    └─Empty: 2-1598                     [64, 64, 1, 1]            --
│    └─Empty: 2-1599                     [64, 64, 1, 1]            --
│    └─Empty: 2-1600                     [64]                      --
│    └─Empty: 2-1601                     [64]                      --
│    └─BatchNorm2d: 2-1602               [16, 64, 32, 32]          --
│    └─Scaler: 2-1603                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1604                      [16, 64, 32, 32]          --
│    └─Empty: 2-1605                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1606                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1607                 [16, 64, 32, 32]          --
│    └─Empty: 2-1608                     [16, 64, 32, 32]          --
│    └─Empty: 2-1609                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1610        --                        --
│    └─One: 2-1611                       [1]                       --
│    └─OutputScale: 2-1612               --                        --
│    └─Empty: 2-1613                     [64, 64, 3, 3]            --
│    └─Empty: 2-1614                     [64, 64, 3, 3]            --
│    └─Empty: 2-1615                     [64]                      --
│    └─Empty: 2-1616                     [64]                      --
│    └─BatchNorm2d: 2-1617               [16, 64, 32, 32]          --
│    └─Scaler: 2-1618                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1619                      [16, 64, 32, 32]          --
│    └─Empty: 2-1620                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1621                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-122        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1622                 [16, 64, 16, 16]          --
│    └─Empty: 2-1623                     [16, 64, 16, 16]          --
│    └─Empty: 2-1624                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1625        --                        --
│    └─One: 2-1626                       [1]                       --
│    └─OutputScale: 2-1627               --                        --
│    └─Empty: 2-1628                     [64, 64, 3, 3]            --
│    └─Empty: 2-1629                     [64, 64, 3, 3]            --
│    └─Empty: 2-1630                     [64]                      --
│    └─Empty: 2-1631                     [64]                      --
│    └─BatchNorm2d: 2-1632               [16, 64, 16, 16]          --
│    └─Scaler: 2-1633                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1634                      [16, 64, 16, 16]          --
│    └─Empty: 2-1635                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1636                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-123               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1637        --                        --
│    └─One: 2-1638                       [1]                       --
│    └─OutputScale: 2-1639               --                        --
│    └─Empty: 2-1640                     [4, 64, 1, 1]             --
│    └─Empty: 2-1641                     [4, 64, 1, 1]             --
│    └─Empty: 2-1642                     [4]                       --
│    └─Empty: 2-1643                     [4]                       --
│    └─BatchNorm2d: 2-1644               [16, 4, 16, 16]           --
│    └─Scaler: 2-1645                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1646                      [16, 4, 16, 16]           --
│    └─Empty: 2-1647                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1648                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1649                 [16, 64, 16, 16]          --
│    └─Empty: 2-1650                     [16, 64, 16, 16]          --
│    └─Empty: 2-1651                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1652        --                        --
│    └─One: 2-1653                       [1]                       --
│    └─OutputScale: 2-1654               --                        --
│    └─Empty: 2-1655                     [4, 64, 3, 3]             --
│    └─Empty: 2-1656                     [4, 64, 3, 3]             --
│    └─Empty: 2-1657                     [4]                       --
│    └─Empty: 2-1658                     [4]                       --
│    └─BatchNorm2d: 2-1659               [16, 4, 16, 16]           --
│    └─Scaler: 2-1660                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1661                      [16, 4, 16, 16]           --
│    └─Empty: 2-1662                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1663                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-125               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1664        --                        --
│    └─One: 2-1665                       [1]                       --
│    └─OutputScale: 2-1666               --                        --
│    └─Empty: 2-1667                     [64, 48, 1, 1]            --
│    └─Empty: 2-1668                     [64, 48, 1, 1]            --
│    └─Empty: 2-1669                     [64]                      --
│    └─Empty: 2-1670                     [64]                      --
│    └─BatchNorm2d: 2-1671               [16, 64, 64, 64]          --
│    └─Scaler: 2-1672                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1673                      [16, 64, 64, 64]          --
│    └─Empty: 2-1674                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1675                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-126               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1676        --                        --
│    └─One: 2-1677                       [1]                       --
│    └─OutputScale: 2-1678               --                        --
│    └─Empty: 2-1679                     [64, 64, 3, 3]            --
│    └─Empty: 2-1680                     [64, 64, 3, 3]            --
│    └─Empty: 2-1681                     [64]                      --
│    └─Empty: 2-1682                     [64]                      --
│    └─BatchNorm2d: 2-1683               [16, 64, 64, 64]          --
│    └─Scaler: 2-1684                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1685                      [16, 64, 64, 64]          --
│    └─Empty: 2-1686                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1687                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-127        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1688                 [16, 64, 32, 32]          --
│    └─Empty: 2-1689                     [16, 64, 32, 32]          --
│    └─Empty: 2-1690                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1691        --                        --
│    └─One: 2-1692                       [1]                       --
│    └─OutputScale: 2-1693               --                        --
│    └─Empty: 2-1694                     [64, 64, 3, 3]            --
│    └─Empty: 2-1695                     [64, 64, 3, 3]            --
│    └─Empty: 2-1696                     [64]                      --
│    └─Empty: 2-1697                     [64]                      --
│    └─BatchNorm2d: 2-1698               [16, 64, 32, 32]          --
│    └─Scaler: 2-1699                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1700                      [16, 64, 32, 32]          --
│    └─Empty: 2-1701                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1702                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-128               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1703        --                        --
│    └─One: 2-1704                       [1]                       --
│    └─OutputScale: 2-1705               --                        --
│    └─Empty: 2-1706                     [64, 64, 1, 1]            --
│    └─Empty: 2-1707                     [64, 64, 1, 1]            --
│    └─Empty: 2-1708                     [64]                      --
│    └─Empty: 2-1709                     [64]                      --
│    └─BatchNorm2d: 2-1710               [16, 64, 32, 32]          --
│    └─Scaler: 2-1711                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1712                      [16, 64, 32, 32]          --
│    └─Empty: 2-1713                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1714                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1715                 [16, 64, 32, 32]          --
│    └─Empty: 2-1716                     [16, 64, 32, 32]          --
│    └─Empty: 2-1717                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1718        --                        --
│    └─One: 2-1719                       [1]                       --
│    └─OutputScale: 2-1720               --                        --
│    └─Empty: 2-1721                     [64, 64, 3, 3]            --
│    └─Empty: 2-1722                     [64, 64, 3, 3]            --
│    └─Empty: 2-1723                     [64]                      --
│    └─Empty: 2-1724                     [64]                      --
│    └─BatchNorm2d: 2-1725               [16, 64, 32, 32]          --
│    └─Scaler: 2-1726                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1727                      [16, 64, 32, 32]          --
│    └─Empty: 2-1728                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1729                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1730                 [16, 64, 16, 16]          --
│    └─Empty: 2-1731                     [16, 64, 16, 16]          --
│    └─Empty: 2-1732                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1733        --                        --
│    └─One: 2-1734                       [1]                       --
│    └─OutputScale: 2-1735               --                        --
│    └─Empty: 2-1736                     [64, 64, 3, 3]            --
│    └─Empty: 2-1737                     [64, 64, 3, 3]            --
│    └─Empty: 2-1738                     [64]                      --
│    └─Empty: 2-1739                     [64]                      --
│    └─BatchNorm2d: 2-1740               [16, 64, 16, 16]          --
│    └─Scaler: 2-1741                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1742                      [16, 64, 16, 16]          --
│    └─Empty: 2-1743                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1744                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-131               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1745        --                        --
│    └─One: 2-1746                       [1]                       --
│    └─OutputScale: 2-1747               --                        --
│    └─Empty: 2-1748                     [4, 64, 1, 1]             --
│    └─Empty: 2-1749                     [4, 64, 1, 1]             --
│    └─Empty: 2-1750                     [4]                       --
│    └─Empty: 2-1751                     [4]                       --
│    └─BatchNorm2d: 2-1752               [16, 4, 16, 16]           --
│    └─Scaler: 2-1753                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1754                      [16, 4, 16, 16]           --
│    └─Empty: 2-1755                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1756                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1757                 [16, 64, 16, 16]          --
│    └─Empty: 2-1758                     [16, 64, 16, 16]          --
│    └─Empty: 2-1759                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1760        --                        --
│    └─One: 2-1761                       [1]                       --
│    └─OutputScale: 2-1762               --                        --
│    └─Empty: 2-1763                     [4, 64, 3, 3]             --
│    └─Empty: 2-1764                     [4, 64, 3, 3]             --
│    └─Empty: 2-1765                     [4]                       --
│    └─Empty: 2-1766                     [4]                       --
│    └─BatchNorm2d: 2-1767               [16, 4, 16, 16]           --
│    └─Scaler: 2-1768                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1769                      [16, 4, 16, 16]           --
│    └─Empty: 2-1770                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1771                     [16, 4, 16, 16]           --
├─Conv1d: 1-133                          [16, 4, 14]               12,298
│    └─OutputShiftSqueeze: 2-1772        --                        --
│    └─One: 2-1773                       [1]                       --
│    └─OutputScale: 2-1774               --                        --
│    └─Empty: 2-1775                     [4, 1024, 3]              --
│    └─Empty: 2-1776                     [4, 1024, 3]              --
│    └─Empty: 2-1777                     [4]                       --
│    └─Empty: 2-1778                     [4]                       --
│    └─Scaler: 2-1779                    [16, 4, 14]               --
│    └─Empty: 2-1780                     [16, 4, 14]               --
│    └─Empty: 2-1781                     [16, 4, 14]               --
│    └─Clamp: 2-1782                     [16, 4, 14]               --
==========================================================================================
Total params: 169,922
Trainable params: 169,868
Non-trainable params: 54
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.63
Estimated Total Size (MB): 201.96
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.250 | Acc: 35.500% | Wgt Acc: 36.203%
	I - Batch: 100 | Loss: 1.192 | Acc: 41.625% | Wgt Acc: 41.968%
	I - Batch: 150 | Loss: 1.154 | Acc: 42.958% | Wgt Acc: 43.494%
	I - Batch: 200 | Loss: 1.121 | Acc: 46.031% | Wgt Acc: 46.616%
	I - Batch: 250 | Loss: 1.115 | Acc: 46.650% | Wgt Acc: 47.003%
	I - Batch: 300 | Loss: 1.109 | Acc: 47.333% | Wgt Acc: 47.528%
	I - Batch: 350 | Loss: 1.093 | Acc: 48.679% | Wgt Acc: 48.819%
	I - Batch: 400 | Loss: 1.084 | Acc: 49.234% | Wgt Acc: 49.322%
	I - Batch: 450 | Loss: 1.078 | Acc: 49.764% | Wgt Acc: 49.886%
I - num batch: 478
I - Train -- Loss: 1.072 | Acc: 50.517% | Wgt Acc: 50.634% | LR: 1.000000e-03 | Dur: 320.53s
I - Confusion Matrix: [row->prediction - col->label]
[[1245.   90.  159.  590.]
 [ 202. 1088.  949.  192.]
 [ 215.  418.  884.  189.]
 [ 429.  138.  210.  643.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.155 | Acc: 49.500% | Wgt Acc: 48.695%
I - num batch: 62
I - Val -- Loss: 1.164 | Acc: 48.114% | Wgt Acc: 47.351% | Dur: 35.17s
I - Confusion Matrix: [row->prediction - col->label]
[[155.  11.  14.  77.]
 [ 35. 125.  92.  60.]
 [ 35.  97. 114.  43.]
 [ 39.   1.   5.  78.]]

I - Local maximum validation set accuracy:  48.11

I - Validation set results: 
[14-1-2-0.99][14-1-2-0.97][14-1-2-0.85][50-3-1-0.21][50-3-1-0.99][50-3-1-0.99][124-2-2-0.36][124-2-2-0.91][124-2-2-0.75][127-0-0-0.99]
[127-0-0-0.98][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.97][567-0-0-0.80][573-1-1-0.12][573-1-1-0.34]
[573-1-1-0.52][615-0-3-0.99][615-0-3-0.87][615-0-3-0.99][695-1-2-0.99][695-1-2-0.99][695-1-2-0.99][722-3-0-0.99][722-3-3-0.38][722-3-0-0.70]
[826-0-3-0.56][826-0-0-0.92][826-0-0-0.70][878-0-0-0.89][878-0-0-0.99][878-0-0-0.95][1103-0-1--0.31][1103-0-1--0.15][1103-0-0--0.12][1212-3-3-0.03]
[1212-3-3--0.28][1212-3-0--0.51][1368-0-0-0.25][1368-0-0-0.29][1368-0-0-0.16][2181-2-0-0.43][2181-2-0-0.52][2181-2-0-0.53][2476-2-1-0.99][2476-2-1-0.99]
[2476-2-1-0.99][2721-2-2-0.99][2721-2-2-0.99][2721-2-2-0.99][2818-1-2-0.98][2818-1-1-0.88][2818-1-1-0.94][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-1-0.99][3231-2-1-0.99][3231-2-1-0.99][3333-2-1-0.57][3333-2-1-0.66][3333-2-1-0.65][3482-2-2-0.99][3482-2-2-0.99][3482-2-2-0.99][3536-3-1-0.99]
[3536-3-1-0.77][3536-3-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3909-0-0--0.37][3909-0-0--0.48][3909-0-0--0.54][4035-0-3-0.70][4035-0-0-0.76]
[4035-0-0-0.50][4140-0-0-0.99][4140-0-0-0.75][4140-0-0-0.98][4214-1-0-0.54][4214-1-1-0.14][4214-1-1-0.96][4346-1-2-0.01][4346-1-0-0.99][4346-1-0-0.99]
[4581-2-2-0.99][4581-2-2-0.99][4581-2-2-0.99][4708-3-2-0.94][4708-3-1-0.95][4708-3-1-0.91][4838-3-1--0.19][4838-3-1-0.43][4838-3-1-0.95][4845-1-2-0.35]
[4845-1-2-0.21][4845-1-2-0.25][4868-0-0-0.57][4868-0-0-0.99][4868-0-0-0.99][4939-0-2-0.25][4939-0-2-0.99][4939-0-2-0.99][4984-2-0-0.44][4984-2-0-0.30]
[4984-2-0-0.48][5078-1-2-0.37][5078-1-2-0.48][5078-1-2-0.20][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-1-0.98][5479-1-1-0.99][5479-1-1-0.99]
[5717-0-0--0.25][5717-0-0-0.91][5717-0-1-0.57][5843-1-1-0.99][5843-1-1-0.52][5843-1-1-0.99][5949-3-3-0.36][5949-3-3-0.99][5949-3-3-0.99][5987-2-1-0.90]
[5987-2-1-0.99][5987-2-1-0.99][6014-3-1-0.27][6014-3-3-0.28][6014-3-3-0.45][6033-3-0-0.98][6033-3-0-0.11][6033-3-0-0.95][6313-0-0-0.99][6313-0-0-0.94]
[6313-0-0-0.37][6421-3-3-0.99][6421-3-3-0.81][6421-3-3-0.99][6500-1-1-0.99][6500-1-1-0.99][6500-1-1-0.99][6583-3-3-0.65][6583-3-3-0.83][6583-3-3-0.87]
[6683-3-1-0.76][6683-3-1-0.27][6683-3-1-0.15][6825-2-1--0.13][6825-2-1--0.50][6825-2-1--0.18][6998-3-1--0.03][6998-3-3--0.65][6998-3-1--0.22][7049-3-2-0.52]
[7049-3-2-0.45][7049-3-3-0.02][7517-1-1-0.99][7517-1-1-0.99][7517-1-1-0.99][7521-1-1-0.99][7521-1-1-0.99][7521-1-1-0.99][7528-1-1-0.11][7528-1-2-0.17]
[7528-1-2-0.43][7949-1-2-0.99][7949-1-2-0.99][7949-1-2-0.99][8135-1-0-0.01][8135-1-2--0.03][8135-1-0--0.40][8185-3-0-0.99][8185-3-0-0.61][8185-3-0-0.99]
[8269-3-2-0.92][8269-3-2-0.98][8269-3-2-0.99][8273-3-0--1.00][8273-3-0--1.00][8273-3-3--0.48][8543-3-0-0.99][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.89]
[8666-1-1-0.99][8666-1-1-0.99][8672-0-0-0.99][8672-0-0-0.99][8672-0-0-0.37][8903-1-1-0.84][8903-1-2-0.93][8903-1-2-0.99][9001-2-2-0.99][9001-2-1-0.99]
[9001-2-1-0.99][9036-2-2-0.99][9036-2-2-0.99][9036-2-2-0.99][9281-3-1-0.67][9281-3-1-0.42][9281-3-1-0.86][9300-2-1-0.99][9300-2-1-0.99][9300-2-1-0.99]
[9571-0-3-0.69][9571-0-0--0.19][9571-0-0-0.07][9617-1-1-0.99][9617-1-1-0.33][9617-1-1-0.99][9644-2-2-0.99][9644-2-2-0.99][9644-2-2-0.99][9705-2-2-0.55]
[9705-2-2-0.49][9705-2-2-0.62][9801-0-3-0.86][9801-0-1-0.22][9801-0-3-0.85][9803-3-3-0.89][9803-3-1-0.06][9803-3-1-0.47][9865-3-0-0.99][9865-3-0-0.99]
[9865-3-0-0.99][9896-2-2-0.99][9896-2-2-0.99][9896-2-2-0.99][10314-1-1-0.99][10314-1-1-0.99][10314-1-1-0.99][10337-3-3-0.99][10337-3-3-0.99][10337-3-3-0.99]
[10403-0-2-0.65][10403-0-2-0.69][10403-0-2-0.48][10653-2-1-0.99][10653-2-1-0.80][10653-2-2-0.52][10704-2-1-0.99][10704-2-1-0.99][10704-2-1-0.96][10719-1-2-0.94]
[10719-1-1-0.99][10719-1-1-0.89][10727-1-1-0.81][10727-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-1--0.27][10969-2-2--0.13]
[10969-2-3--0.37][11042-0-0-0.90][11042-0-0-0.14][11042-0-0-0.38][11088-1-2-0.99][11088-1-2-0.99][11088-1-2-0.90][11322-0-0-0.99][11322-0-0-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11398-2-2-0.99][11398-2-2-0.99][11499-0-0--0.05][11499-0-0--0.40][11499-0-1--0.55][11502-3-2-0.10][11502-3-2-0.61][11502-3-2-0.49][11512-3-1-0.33]
[11512-3-1-0.27][11512-3-1-0.52][11608-1-1-0.99][11608-1-1-0.99][11608-1-1-0.99][11610-0-3-0.83][11610-0-3-0.99][11610-0-3-0.43][11692-0-0-0.99][11692-0-0-0.96]
[11692-0-0-0.81][11905-0-0-0.99][11905-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][11993-1-1-0.99][11993-1-1-0.99][12002-2-3-0.99][12002-2-3--0.02][12002-2-3-0.68]
[12052-0-2--0.31][12052-0-0-0.99][12052-0-0-0.30][12201-0-0-0.99][12201-0-3-0.99][12201-0-3-0.99][12235-2-1-0.99][12235-2-1-0.99][12235-2-2-0.99][12320-1-2-0.85]
[12320-1-2-0.88][12320-1-2-0.06][12377-2-1-0.79][12377-2-2-0.83][12377-2-1-0.99][12398-2-2--0.37][12398-2-1-0.10][12398-2-1-0.58][12503-1-2-0.05][12503-1-2-0.25]
[12503-1-1-0.99][12617-0-1-0.99][12617-0-1-0.99][12617-0-1-0.99][12685-3-1-0.57][12685-3-1-0.26][12685-3-2--0.33][12738-2-2-0.99][12738-2-2-0.92][12738-2-2-0.48]
[12742-2-2-0.99][12742-2-2-0.99][12742-2-2-0.99][12823-0-3-0.91][12823-0-3-0.90][12823-0-0-0.99][13110-1-1-0.99][13110-1-1-0.99][13110-1-1-0.99][13240-3-3-0.99]
[13240-3-3-0.98][13240-3-3-0.97][13253-1-2-0.98][13253-1-2-0.99][13253-1-2-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-1-0.99][13634-1-1-0.99]
[13634-1-1-0.99][13763-2-1-0.84][13763-2-2-0.91][13763-2-1-0.93][13905-3-2-0.43][13905-3-2-0.50][13905-3-2-0.48][14060-2-1-0.99][14060-2-1-0.99][14060-2-1-0.99]
[14065-3-3-0.96][14065-3-0-0.99][14065-3-3-0.40][14147-3-0--0.30][14147-3-2-0.00][14147-3-0-0.57][14595-2-2-0.99][14595-2-2-0.99][14595-2-2-0.99][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.99][14788-2-1-0.99][14788-2-2-0.99][14788-2-1-0.99][14869-1-1-0.67][14869-1-1-0.56][14869-1-1-0.57][14872-3-0-0.08][14872-3-0--0.06]
[14872-3-2--0.24][14877-1-1-0.32][14877-1-1-0.36][14877-1-1-0.58][14927-0-3-0.99][14927-0-3-0.99][14927-0-3-0.99][15066-0-0-0.99][15066-0-0-0.99][15066-0-0-0.99]
[15175-1-2-0.83][15175-1-2-0.81][15175-1-2-0.81][15178-2-0--0.60][15178-2-0--0.89][15178-2-0--0.84][15375-3-3-0.96][15375-3-0-0.38][15375-3-0--0.25][15389-3-3-0.56]
[15389-3-3-0.92][15389-3-3-0.99][15568-2-1-0.96][15568-2-1-0.99][15568-2-1-0.99][15675-3-1-0.56][15675-3-1--0.31][15675-3-1--0.18][15869-1-2-0.13][15869-1-2-0.95]
[15869-1-2-0.64][16207-3-0-0.69][16207-3-0-0.58][16207-3-0-0.62][16236-0-2-0.37][16236-0-2-0.10][16236-0-0--0.35][16302-3-0-0.61][16302-3-0-0.67][16302-3-0-0.65]
[16331-2-2-0.99][16331-2-2-0.99][16331-2-2-0.99][16381-0-2-0.23][16381-0-2--0.21][16381-0-1--0.52][16488-1-1-0.99][16488-1-1-0.99][16488-1-2-0.99][16495-0-2--0.37]
[16495-0-0-0.45][16495-0-0-0.64][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-1-0.98][16719-1-1-0.99][16719-1-1-0.99][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.11][16828-0-0-0.15][16828-0-0--0.00][17137-3-0-0.98][17137-3-0-0.41][17137-3-0-0.65][17245-1-2-0.37][17245-1-2-0.31][17245-1-1--0.47]
[17278-3-1--0.38][17278-3-1--0.04][17278-3-1-0.26][17282-0-1-0.74][17282-0-1-0.35][17282-0-1-0.24][17311-2-2-0.99][17311-2-2-0.99][17311-2-2-0.99][17336-2-1-0.47]
[17336-2-2-0.87][17336-2-1-0.97][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-1-0.89][17627-0-1-0.64][17627-0-1-0.26][17877-3-1-0.99][17877-3-1-0.91]
[17877-3-1-0.51][17924-1-2--0.01][17924-1-0-0.35][17924-1-2-0.04][17984-3-0-0.99][17984-3-3-0.80][17984-3-0-0.99][18211-0-1-0.81][18211-0-1-0.90][18211-0-1-0.88]
[18276-3-0-0.99][18276-3-0-0.99][18276-3-0-0.99][18287-1-1-0.30][18287-1-1-0.47][18287-1-1-0.48][18394-0-0-0.99][18394-0-0-0.86][18394-0-0-0.99][18428-0-1-0.48]
[18428-0-0-0.17][18428-0-0-0.99][18442-0-3-0.99][18442-0-3-0.87][18442-0-3-0.82][18478-3-0--0.06][18478-3-0--0.08][18478-3-0--0.20][18607-0-2--0.78][18607-0-2--0.19]
[18607-0-2--0.20][18616-0-1-0.71][18616-0-1-0.38][18616-0-1--0.09][18663-0-0-0.11][18663-0-0--0.38][18663-0-0-0.38][18718-0-0-0.99][18718-0-0-0.99][18718-0-0-0.99]
[18766-2-1-0.99][18766-2-1-0.99][18766-2-1-0.99][18824-2-2-0.99][18824-2-1-0.99][18824-2-1-0.99][18890-3-2-0.99][18890-3-2-0.99][18890-3-2-0.85][18930-3-2-0.99]
[18930-3-2-0.98][18930-3-2-0.99][18938-3-0-0.52][18938-3-0-0.74][18938-3-0-0.68][19817-1-2-0.99][19817-1-2-0.99][19817-1-2-0.99][19839-0-2-0.80][19839-0-2-0.90]
[19839-0-2-0.99][19930-3-1--0.09][19930-3-1--0.34][19930-3-3--0.02][19944-0-0-0.38][19944-0-2-0.99][19944-0-2-0.99][20036-2-2-0.99][20036-2-2-0.99][20036-2-2-0.99]
[20101-3-1--0.28][20101-3-3-0.25][20101-3-0-0.22][20474-1-2-0.99][20474-1-2-0.99][20474-1-2-0.99][20547-3-1-0.47][20547-3-2--0.51][20547-3-0--0.21][20929-2-2-0.79]
[20929-2-2-0.99][20929-2-2-0.99][21245-1-1-0.99][21245-1-1-0.99][21245-1-1-0.99][21257-3-1--0.35][21257-3-1-0.41][21257-3-1-0.22][21293-1-1-0.99][21293-1-1-0.99]
[21293-1-1-0.99][21316-1-1-0.99][21316-1-1-0.99][21316-1-2--0.04][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1-0.99][21448-1-1-0.99][21448-1-1-0.95]
[21483-0-0-0.99][21483-0-0-0.98][21483-0-0-0.99][21487-2-2-0.93][21487-2-2-0.94][21487-2-2-0.98][21714-0-2-0.36][21714-0-2-0.45][21714-0-0-0.23][21943-3-2-0.99]
[21943-3-2-0.99][21943-3-2-0.99][21947-0-0-0.92][21947-0-0-0.56][21947-0-0-0.37][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21965-2-2-0.99]
[21965-2-2-0.92][21998-1-2-0.99][21998-1-2-0.73][21998-1-2-0.80][22025-0-1-0.33][22025-0-3-0.04][22025-0-1-0.22][22228-3-0-0.97][22228-3-0-0.93][22228-3-0-0.98]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-0-0.99][22494-3-0-0.99][22494-3-0-0.99][22757-0-3-0.74][22757-0-0-0.99][22757-0-0-0.99][22811-3-2-0.51]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-1-0.91][22976-3-1-0.89][22976-3-1-0.99][22985-3-3-0.99][22985-3-3-0.98][22985-3-3-0.87][23014-0-3-0.99][23014-0-3-0.99]
[23014-0-3-0.99][23112-1-1-0.98][23112-1-2-0.99][23112-1-2-0.99][23144-3-0-0.97][23144-3-0-0.99][23144-3-0-0.99][23168-2-1-0.48][23168-2-1-0.63][23168-2-1-0.99]
[23219-0-2--0.19][23219-0-3-0.32][23219-0-0--0.02][23363-3-3-0.46][23363-3-3-0.84][23363-3-3-0.72][23470-0-2-0.31][23470-0-2-0.30][23470-0-2-0.16][23486-2-1-0.51]
[23486-2-1-0.87][23486-2-1-0.43][23497-0-0-0.99][23497-0-3-0.99][23497-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-1-0.12][23690-1-1-0.98]
[23690-1-1-0.99][23921-2-1-0.84][23921-2-2-0.74][23921-2-2-0.94][23936-1-2-0.97][23936-1-2-0.87][23936-1-2-0.79][24040-3-2-0.90][24040-3-2-0.84][24040-3-2-0.91]
[24111-1-1-0.99][24111-1-1-0.99][24111-1-1-0.99][24182-0-0-0.99][24182-0-3-0.99][24182-0-0-0.99][24238-3-3-0.99][24238-3-3-0.99][24238-3-3-0.99][24290-2-0-0.99]
[24290-2-0-0.99][24290-2-0-0.99][24345-0-0-0.85][24345-0-0-0.60][24345-0-2-0.82][24364-1-0--0.57][24364-1-2-0.84][24364-1-2-0.53][24427-3-2--0.50][24427-3-0--0.58]
[24427-3-0--0.36][24477-2-2-0.99][24477-2-2-0.99][24477-2-2-0.98][24495-2-1-0.99][24495-2-1-0.93][24495-2-1-0.75][24893-2-2-0.99][24893-2-2-0.99][24893-2-2-0.99]
[25012-1-2-0.96][25012-1-1-0.93][25012-1-1-0.42][25121-2-2-0.95][25121-2-2-0.91][25121-2-2-0.99][25165-3-1--0.42][25165-3-1--0.45][25165-3-1--0.48][25183-0-1-0.35]
[25183-0-1--0.09][25183-0-0--0.02][25297-3-1-0.30][25297-3-3-0.33][25297-3-3-0.57][25398-0-0-0.33][25398-0-0-0.73][25398-0-0-0.83][25574-2-1-0.99][25574-2-1-0.86]
[25574-2-1-0.95][25644-1-1-0.99][25644-1-1-0.99][25644-1-2-0.98][25718-1-1-0.94][25718-1-2-0.32][25718-1-0--0.59][25774-2-2-0.99][25774-2-2-0.70][25774-2-2-0.75]
[26032-3-3-0.88][26032-3-3-0.76][26032-3-3-0.50][26051-3-3-0.99][26051-3-3-0.99][26051-3-3-0.96][26120-0-1-0.79][26120-0-0-0.05][26120-0-0-0.99][26321-1-1--0.15]
[26321-1-1-0.11][26321-1-2-0.87][26732-1-2-0.73][26732-1-2-0.71][26732-1-2-0.80][26784-3-3-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-3-0.22][26827-3-3-0.24]
[26827-3-1-0.41][26833-0-3-0.99][26833-0-3-0.99][26833-0-3-0.99][26838-2-2-0.91][26838-2-2-0.99][26838-2-2-0.69][26860-1-2-0.96][26860-1-2-0.99][26860-1-2-0.99]
[26948-0-0--0.23][26948-0-0--0.21][26948-0-0--0.37][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-1-0.71][27098-1-1--0.14][27098-1-0--0.37][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.24][27639-3-3-0.49][27639-3-3-0.50][27639-3-3-0.71][27698-3-3-0.67][27698-3-0-0.81][27698-3-3-0.77][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-3-0.56][27890-1-1-0.91][27890-1-1-0.82][27890-1-1-0.70][28040-0-0-0.07][28040-0-0-0.05][28040-0-0-0.42][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28577-1-1-0.99][28577-1-1-0.99][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-2-0.32][29198-3-1-0.17][29198-3-2-0.25][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-1-0.99][29877-2-1-0.80][29877-2-1-0.97][30035-1-2-0.99][30035-1-2-0.99][30035-1-2-0.99][30098-0-0--0.02][30098-0-0-0.39]
[30098-0-0-0.15][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.98][30572-2-2-0.84][30572-2-2-0.99][30716-0-1-0.99][30716-0-1-0.99][30716-0-1-0.99]
[30806-2-1--0.01][30806-2-1--0.19][30806-2-1-0.02][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.99][31007-0-0-0.55][31007-0-0-0.69][31007-0-2-0.91][31181-3-0-0.86]
[31181-3-0-0.40][31181-3-2-0.99][31238-0-0-0.99][31238-0-0-0.21][31238-0-0-0.56][31347-0-3-0.99][31347-0-3-0.99][31347-0-3-0.99][31422-2-1-0.99][31422-2-1-0.99]
[31422-2-2-0.98][31429-3-2--0.22][31429-3-2--0.09][31429-3-0--0.34][31431-0-0-0.99][31431-0-0-0.29][31431-0-0--0.38][31432-1-1-0.55][31432-1-1-0.99][31432-1-1-0.99]
[31477-0-0-0.99][31477-0-0-0.99][31477-0-0-0.99][31524-1-2-0.89][31524-1-2-0.43][31524-1-2--0.03][31597-1-2-0.99][31597-1-2-0.99][31597-1-2-0.79][31619-1-2-0.41]
[31619-1-0-0.88][31619-1-0-0.76][31701-0-0-0.99][31701-0-0-0.99][31701-0-0-0.99][31755-0-3-0.56][31755-0-3-0.50][31755-0-3-0.62][31854-3-0-0.88][31854-3-3-0.53]
[31854-3-3-0.17][32074-1-2-0.70][32074-1-2-0.27][32074-1-3-0.05][32078-3-3-0.87][32078-3-3-0.94][32078-3-3-0.92][32111-1-1-0.99][32111-1-2-0.99][32111-1-1-0.99]
[32127-1-2-0.99][32127-1-2-0.99][32127-1-2-0.84][32140-3-2--0.43][32140-3-2--0.35][32140-3-2--0.24][32263-2-2-0.72][32263-2-2-0.98][32263-2-2-0.92][32365-0-2-0.63]
[32365-0-1-0.84][32365-0-2--0.29][32411-2-0-0.99][32411-2-3-0.99][32411-2-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32473-3-3--0.14][32473-3-3--0.30]
[32473-3-3--0.36][32574-3-0-0.99][32574-3-0-0.99][32574-3-0-0.99][32584-0-2-0.78][32584-0-2-0.81][32584-0-2-0.82][32622-0-2-0.42][32622-0-2-0.79][32622-0-1-0.75]
[32858-3-0-0.99][32858-3-0-0.99][32858-3-0-0.99][32969-3-0-0.82][32969-3-0-0.72][32969-3-0-0.86][33016-2-1-0.99][33016-2-1-0.99][33016-2-1-0.99][33031-1-1--0.71]
[33031-1-1-0.11][33031-1-1-0.38][33035-2-2-0.99][33035-2-2-0.99][33035-2-2-0.99][33133-2-1-0.99][33133-2-1-0.99][33133-2-1-0.99][33173-2-1-0.62][33173-2-1-0.99]
[33173-2-1-0.99][33175-3-1-0.99][33175-3-1-0.99][33175-3-1-0.99][33306-3-1-0.72][33306-3-1-0.66][33306-3-1-0.67][33309-2-2-0.87][33309-2-2-0.87][33309-2-1-0.61]
[33474-0-1-0.43][33474-0-1-0.41][33474-0-1--0.64][33478-2-2-0.43][33478-2-2-0.96][33478-2-2-0.53][33618-1-1-0.84][33618-1-1-0.92][33618-1-1-0.91][33712-0-0-0.16]
[33712-0-0--0.20][33712-0-0--0.07][33782-2-2-0.97][33782-2-2-0.88][33782-2-2-0.91][33914-3-1-0.99][33914-3-1-0.04][33914-3-3--0.12][34076-3-2-0.54][34076-3-2-0.62]
[34076-3-3-0.57][34112-2-1-0.99][34112-2-1-0.99][34112-2-1-0.99][34138-2-2-0.99][34138-2-2-0.99][34138-2-2-0.99][34239-1-2-0.74][34239-1-2-0.81][34239-1-2-0.65]
[34364-2-1-0.99][34364-2-1-0.99][34364-2-2-0.99][34617-1-1-0.70][34617-1-1-0.99][34617-1-2-0.99][34751-3-3-0.99][34751-3-3-0.99][34751-3-3-0.99][34783-2-1-0.99]
[34783-2-1-0.99][34783-2-2-0.98][35015-3-2-0.99][35015-3-2-0.30][35015-3-2-0.99][35018-1-2-0.99][35018-1-1-0.99][35018-1-2-0.99][35288-2-2-0.48][35288-2-2-0.20]
[35288-2-1--0.15]
---------------------------
I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 0.962 | Acc: 57.750% | Wgt Acc: 57.608%
	I - Batch: 100 | Loss: 0.980 | Acc: 58.938% | Wgt Acc: 58.759%
	I - Batch: 150 | Loss: 0.986 | Acc: 57.250% | Wgt Acc: 57.183%
	I - Batch: 200 | Loss: 0.970 | Acc: 58.312% | Wgt Acc: 58.251%
	I - Batch: 250 | Loss: 0.956 | Acc: 59.675% | Wgt Acc: 59.642%
	I - Batch: 300 | Loss: 0.947 | Acc: 60.479% | Wgt Acc: 60.424%
	I - Batch: 350 | Loss: 0.943 | Acc: 60.875% | Wgt Acc: 60.787%
	I - Batch: 400 | Loss: 0.933 | Acc: 61.781% | Wgt Acc: 61.733%
	I - Batch: 450 | Loss: 0.931 | Acc: 61.792% | Wgt Acc: 61.760%
I - num batch: 478
I - Train -- Loss: 0.929 | Acc: 61.837% | Wgt Acc: 61.851% | LR: 1.000000e-03 | Dur: 314.64s
I - Confusion Matrix: [row->prediction - col->label]
[[1470.   71.  115.  500.]
 [ 134. 1256.  781.  145.]
 [ 140.  310. 1180.  150.]
 [ 347.   97.  126.  819.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.083 | Acc: 56.625% | Wgt Acc: 55.969%
I - num batch: 62
I - Val -- Loss: 1.069 | Acc: 56.983% | Wgt Acc: 56.409% | Dur: 32.81s
I - Confusion Matrix: [row->prediction - col->label]
[[203.  21.  27.  96.]
 [ 19. 141.  74.  33.]
 [ 11.  61. 101.  15.]
 [ 31.  11.  23. 114.]]

I - Local maximum validation set accuracy:  56.98

I - Validation set results: 
[14-1-2-0.99][14-1-2-0.93][14-1-1-0.90][50-3-1-0.72][50-3-1-0.99][50-3-1-0.98][124-2-3-0.32][124-2-2-0.71][124-2-2-0.83][127-0-0-0.99]
[127-0-0-0.99][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.99][567-0-0-0.76][573-1-0-0.48][573-1-1-0.87]
[573-1-1-0.99][615-0-3-0.99][615-0-3-0.99][615-0-3-0.99][695-1-2-0.60][695-1-2-0.54][695-1-2-0.75][722-3-0-0.99][722-3-3-0.99][722-3-0-0.99]
[826-0-0-0.99][826-0-0-0.99][826-0-0-0.99][878-0-0-0.99][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.67][1103-0-0-0.40][1103-0-0-0.19][1212-3-3-0.80]
[1212-3-3-0.66][1212-3-3-0.29][1368-0-0-0.99][1368-0-0-0.99][1368-0-0-0.99][2181-2-0-0.99][2181-2-0-0.99][2181-2-0-0.99][2476-2-2-0.76][2476-2-2-0.72]
[2476-2-2-0.76][2721-2-2-0.99][2721-2-2-0.99][2721-2-2-0.99][2818-1-1-0.72][2818-1-1-0.99][2818-1-1-0.99][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-1-0.99][3231-2-1-0.99][3231-2-1-0.99][3333-2-2-0.59][3333-2-2-0.67][3333-2-2-0.71][3482-2-2-0.99][3482-2-2-0.99][3482-2-2-0.99][3536-3-3-0.79]
[3536-3-3-0.83][3536-3-3-0.99][3625-1-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3909-0-0-0.74][3909-0-0-0.99][3909-0-0-0.99][4035-0-0-0.99][4035-0-0-0.99]
[4035-0-0-0.99][4140-0-0-0.99][4140-0-0-0.95][4140-0-0-0.99][4214-1-0-0.98][4214-1-3-0.11][4214-1-2-0.66][4346-1-0-0.99][4346-1-0-0.99][4346-1-0-0.99]
[4581-2-2-0.99][4581-2-2-0.99][4581-2-2-0.93][4708-3-2-0.97][4708-3-2-0.99][4708-3-2-0.99][4838-3-1-0.66][4838-3-1-0.95][4838-3-1-0.88][4845-1-2-0.70]
[4845-1-2-0.52][4845-1-2-0.46][4868-0-0-0.99][4868-0-0-0.99][4868-0-0-0.99][4939-0-2-0.22][4939-0-1-0.99][4939-0-2-0.99][4984-2-0-0.97][4984-2-0-0.99]
[4984-2-0-0.99][5078-1-1-0.81][5078-1-1-0.96][5078-1-0-0.27][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-1-0.82][5479-1-1-0.98][5479-1-1-0.82]
[5717-0-0-0.73][5717-0-0-0.99][5717-0-1-0.72][5843-1-1-0.99][5843-1-1-0.99][5843-1-1-0.99][5949-3-0-0.77][5949-3-3-0.99][5949-3-0-0.99][5987-2-1-0.99]
[5987-2-1-0.99][5987-2-1-0.99][6014-3-1-0.64][6014-3-3-0.69][6014-3-3-0.63][6033-3-0-0.99][6033-3-3-0.31][6033-3-0-0.97][6313-0-0-0.99][6313-0-3-0.99]
[6313-0-3-0.99][6421-3-3-0.99][6421-3-3-0.99][6421-3-3-0.99][6500-1-0-0.95][6500-1-0-0.96][6500-1-0-0.98][6583-3-3-0.97][6583-3-3-0.97][6583-3-3-0.76]
[6683-3-3-0.48][6683-3-3-0.46][6683-3-3-0.99][6825-2-3-0.98][6825-2-3-0.99][6825-2-3-0.99][6998-3-2-0.40][6998-3-3-0.64][6998-3-2-0.06][7049-3-3-0.99]
[7049-3-3-0.84][7049-3-3-0.98][7517-1-1-0.99][7517-1-1-0.99][7517-1-1-0.99][7521-1-3-0.86][7521-1-3-0.90][7521-1-3-0.99][7528-1-0-0.21][7528-1-1-0.69]
[7528-1-1-0.69][7949-1-2-0.99][7949-1-2-0.99][7949-1-2-0.96][8135-1-0-0.99][8135-1-0-0.99][8135-1-0-0.99][8185-3-0-0.99][8185-3-0-0.99][8185-3-0-0.99]
[8269-3-1-0.99][8269-3-1-0.99][8269-3-1-0.99][8273-3-0-0.99][8273-3-0-0.99][8273-3-0-0.99][8543-3-0-0.99][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.82]
[8666-1-1-0.99][8666-1-1-0.99][8672-0-0-0.99][8672-0-0-0.99][8672-0-3-0.99][8903-1-2--0.05][8903-1-2-0.74][8903-1-2-0.99][9001-2-0-0.92][9001-2-1-0.99]
[9001-2-1-0.99][9036-2-2-0.99][9036-2-2-0.96][9036-2-1-0.99][9281-3-1-0.97][9281-3-1-0.84][9281-3-1-0.99][9300-2-1-0.99][9300-2-2-0.99][9300-2-2-0.99]
[9571-0-3-0.99][9571-0-3-0.80][9571-0-3-0.86][9617-1-1-0.99][9617-1-1-0.65][9617-1-1-0.94][9644-2-2-0.99][9644-2-2-0.99][9644-2-2-0.99][9705-2-3-0.90]
[9705-2-3-0.99][9705-2-3-0.99][9801-0-3-0.99][9801-0-3-0.99][9801-0-3-0.99][9803-3-3-0.99][9803-3-3-0.87][9803-3-3-0.99][9865-3-0-0.99][9865-3-0-0.99]
[9865-3-0-0.99][9896-2-2-0.99][9896-2-2-0.99][9896-2-2-0.99][10314-1-1-0.99][10314-1-2-0.90][10314-1-2-0.64][10337-3-3-0.99][10337-3-0-0.99][10337-3-3-0.99]
[10403-0-0-0.81][10403-0-0-0.89][10403-0-0-0.79][10653-2-1-0.99][10653-2-1-0.99][10653-2-1-0.85][10704-2-1-0.99][10704-2-1-0.99][10704-2-1-0.99][10719-1-1-0.78]
[10719-1-1-0.98][10719-1-1-0.91][10727-1-1-0.99][10727-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-3-0.99][10969-2-3-0.99]
[10969-2-3-0.99][11042-0-0-0.99][11042-0-0-0.99][11042-0-0-0.99][11088-1-2-0.99][11088-1-1-0.82][11088-1-1-0.68][11322-0-0-0.99][11322-0-0-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11398-2-2-0.98][11398-2-2-0.74][11499-0-0-0.90][11499-0-0-0.94][11499-0-0-0.66][11502-3-3-0.99][11502-3-3-0.99][11502-3-3-0.99][11512-3-3-0.81]
[11512-3-3-0.69][11512-3-3-0.55][11608-1-1-0.99][11608-1-1-0.99][11608-1-1-0.99][11610-0-0-0.69][11610-0-0-0.99][11610-0-3-0.76][11692-0-0-0.99][11692-0-0-0.99]
[11692-0-0-0.99][11905-0-0-0.99][11905-0-0-0.99][11905-0-0-0.99][11993-1-2-0.99][11993-1-2-0.99][11993-1-2-0.99][12002-2-0-0.99][12002-2-0-0.52][12002-2-3-0.81]
[12052-0-0-0.62][12052-0-0-0.99][12052-0-0-0.99][12201-0-0-0.99][12201-0-0-0.99][12201-0-0-0.99][12235-2-1-0.99][12235-2-1-0.99][12235-2-1-0.99][12320-1-2-0.82]
[12320-1-2-0.95][12320-1-0-0.79][12377-2-1-0.98][12377-2-1-0.94][12377-2-1-0.99][12398-2-0-0.93][12398-2-0-0.92][12398-2-1-0.99][12503-1-2-0.99][12503-1-2-0.98]
[12503-1-1-0.99][12617-0-1-0.99][12617-0-1-0.99][12617-0-1-0.99][12685-3-1-0.53][12685-3-1-0.71][12685-3-3-0.82][12738-2-2-0.98][12738-2-3-0.69][12738-2-3-0.43]
[12742-2-2-0.96][12742-2-2-0.89][12742-2-2-0.99][12823-0-0-0.99][12823-0-0-0.99][12823-0-0-0.99][13110-1-1-0.99][13110-1-1-0.99][13110-1-1-0.99][13240-3-0-0.99]
[13240-3-0-0.99][13240-3-3-0.99][13253-1-1-0.99][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-1-0.99][13634-1-1-0.99]
[13634-1-1-0.99][13763-2-1-0.77][13763-2-2-0.95][13763-2-1-0.89][13905-3-0-0.99][13905-3-0-0.99][13905-3-0-0.88][14060-2-1-0.99][14060-2-1-0.99][14060-2-1-0.99]
[14065-3-3-0.99][14065-3-0-0.99][14065-3-3-0.89][14147-3-3-0.99][14147-3-3-0.99][14147-3-0-0.99][14595-2-2-0.99][14595-2-2-0.99][14595-2-2-0.99][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.99][14788-2-2-0.99][14788-2-2-0.95][14788-2-2-0.99][14869-1-1-0.93][14869-1-1-0.97][14869-1-1-0.99][14872-3-0-0.83][14872-3-0-0.99]
[14872-3-0-0.85][14877-1-1-0.29][14877-1-1-0.30][14877-1-1-0.46][14927-0-3-0.99][14927-0-3-0.99][14927-0-3-0.99][15066-0-0-0.99][15066-0-0-0.99][15066-0-0-0.99]
[15175-1-1-0.99][15175-1-1-0.99][15175-1-1-0.99][15178-2-0-0.61][15178-2-0--0.03][15178-2-0--0.11][15375-3-0-0.99][15375-3-3-0.85][15375-3-3-0.22][15389-3-0-0.99]
[15389-3-3-0.99][15389-3-0-0.99][15568-2-1-0.99][15568-2-1-0.99][15568-2-1-0.99][15675-3-3-0.97][15675-3-3-0.62][15675-3-3-0.16][15869-1-1-0.41][15869-1-2-0.86]
[15869-1-2-0.96][16207-3-0-0.99][16207-3-0-0.99][16207-3-0-0.99][16236-0-3-0.38][16236-0-3-0.45][16236-0-0-0.67][16302-3-0-0.99][16302-3-0-0.99][16302-3-0-0.99]
[16331-2-2-0.99][16331-2-2-0.99][16331-2-2-0.99][16381-0-0-0.60][16381-0-3-0.68][16381-0-3-0.98][16488-1-1-0.82][16488-1-1-0.99][16488-1-1-0.40][16495-0-1--0.14]
[16495-0-0-0.99][16495-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-1-0.99][16719-1-1-0.99][16719-1-1-0.99][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.60][16828-0-0-0.95][16828-0-3-0.89][17137-3-3-0.99][17137-3-3-0.98][17137-3-3-0.99][17245-1-2-0.16][17245-1-2-0.54][17245-1-3-0.02]
[17278-3-0-0.56][17278-3-1-0.48][17278-3-1-0.94][17282-0-0-0.99][17282-0-0-0.96][17282-0-1-0.36][17311-2-2-0.99][17311-2-2-0.99][17311-2-2-0.99][17336-2-3-0.10]
[17336-2-2-0.89][17336-2-2-0.57][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-3-0.99][17627-0-2--0.01][17627-0-3-0.41][17877-3-1-0.99][17877-3-1-0.59]
[17877-3-0-0.56][17924-1-3-0.39][17924-1-3-0.95][17924-1-3-0.33][17984-3-3-0.99][17984-3-3-0.99][17984-3-3-0.99][18211-0-1-0.37][18211-0-3-0.70][18211-0-3-0.41]
[18276-3-0-0.99][18276-3-0-0.99][18276-3-0-0.99][18287-1-1-0.71][18287-1-1-0.90][18287-1-1-0.99][18394-0-0-0.99][18394-0-0-0.99][18394-0-0-0.99][18428-0-0-0.72]
[18428-0-0-0.78][18428-0-0-0.99][18442-0-0-0.99][18442-0-0-0.99][18442-0-0-0.99][18478-3-0-0.69][18478-3-0-0.77][18478-3-3-0.80][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-1-0.89][18616-0-1-0.67][18616-0-0-0.87][18663-0-0-0.33][18663-0-0-0.50][18663-0-0-0.58][18718-0-0-0.99][18718-0-0-0.99][18718-0-0-0.99]
[18766-2-3-0.99][18766-2-3-0.98][18766-2-3-0.96][18824-2-1-0.99][18824-2-1-0.99][18824-2-1-0.99][18890-3-2-0.72][18890-3-2-0.58][18890-3-2-0.32][18930-3-2-0.94]
[18930-3-2-0.88][18930-3-2-0.84][18938-3-0-0.99][18938-3-0-0.99][18938-3-0-0.99][19817-1-2-0.99][19817-1-2-0.99][19817-1-2-0.99][19839-0-2-0.81][19839-0-2-0.83]
[19839-0-2-0.98][19930-3-0-0.62][19930-3-3-0.69][19930-3-3-0.93][19944-0-0-0.78][19944-0-2-0.99][19944-0-2-0.99][20036-2-2-0.99][20036-2-2-0.99][20036-2-1-0.99]
[20101-3-0-0.26][20101-3-3-0.99][20101-3-3-0.99][20474-1-2-0.94][20474-1-2-0.94][20474-1-2-0.91][20547-3-0-0.99][20547-3-0-0.67][20547-3-0-0.99][20929-2-2-0.67]
[20929-2-1-0.99][20929-2-1-0.99][21245-1-1-0.99][21245-1-1-0.99][21245-1-1-0.99][21257-3-0-0.83][21257-3-1-0.76][21257-3-1-0.99][21293-1-1-0.99][21293-1-1-0.99]
[21293-1-1-0.99][21316-1-1-0.96][21316-1-1-0.99][21316-1-3-0.86][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1-0.99][21448-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-1-0.63][21487-2-2-0.98][21487-2-2-0.93][21714-0-0-0.88][21714-0-0-0.81][21714-0-0-0.91][21943-3-1-0.92]
[21943-3-1-0.66][21943-3-2-0.98][21947-0-0-0.95][21947-0-0-0.87][21947-0-0-0.89][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21965-2-1-0.99]
[21965-2-1-0.99][21998-1-2-0.85][21998-1-2--0.03][21998-1-2-0.48][22025-0-2-0.47][22025-0-2-0.08][22025-0-1-0.59][22228-3-0-0.99][22228-3-0-0.99][22228-3-0-0.99]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-0-0.99][22494-3-0-0.99][22494-3-0-0.99][22757-0-0-0.99][22757-0-0-0.99][22757-0-0-0.99][22811-3-0-0.60]
[22811-3-0-0.99][22811-3-0-0.99][22976-3-2-0.48][22976-3-1-0.75][22976-3-1-0.99][22985-3-0-0.99][22985-3-0-0.99][22985-3-3-0.99][23014-0-0-0.99][23014-0-0-0.99]
[23014-0-0-0.99][23112-1-1-0.99][23112-1-1-0.99][23112-1-1-0.99][23144-3-0-0.99][23144-3-0-0.99][23144-3-0-0.99][23168-2-0-0.88][23168-2-1-0.78][23168-2-1-0.99]
[23219-0-0-0.35][23219-0-3-0.99][23219-0-3-0.99][23363-3-3-0.99][23363-3-3-0.99][23363-3-3-0.99][23470-0-0-0.51][23470-0-0-0.27][23470-0-1--0.05][23486-2-1-0.27]
[23486-2-3-0.40][23486-2-2-0.18][23497-0-0-0.99][23497-0-0-0.99][23497-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-2-0.23][23690-1-1-0.82]
[23690-1-1-0.99][23921-2-1-0.70][23921-2-2-0.61][23921-2-2-0.86][23936-1-2-0.99][23936-1-2-0.99][23936-1-2-0.99][24040-3-0-0.47][24040-3-0-0.65][24040-3-0-0.45]
[24111-1-1-0.99][24111-1-1-0.99][24111-1-1-0.99][24182-0-0-0.99][24182-0-0-0.99][24182-0-0-0.99][24238-3-3-0.99][24238-3-3-0.99][24238-3-3-0.99][24290-2-0-0.99]
[24290-2-0-0.99][24290-2-0-0.99][24345-0-0-0.99][24345-0-0-0.99][24345-0-2-0.76][24364-1-2--0.19][24364-1-2-0.94][24364-1-2-0.72][24427-3-3-0.78][24427-3-3-0.99]
[24427-3-0-0.99][24477-2-2-0.99][24477-2-2-0.99][24477-2-2-0.99][24495-2-1-0.99][24495-2-1-0.96][24495-2-1-0.99][24893-2-1-0.99][24893-2-1-0.99][24893-2-1-0.99]
[25012-1-1-0.88][25012-1-1-0.98][25012-1-1-0.94][25121-2-0-0.94][25121-2-0-0.97][25121-2-0-0.78][25165-3-3-0.87][25165-3-3-0.91][25165-3-3-0.87][25183-0-0-0.99]
[25183-0-0-0.99][25183-0-0-0.99][25297-3-3-0.99][25297-3-3-0.99][25297-3-3-0.99][25398-0-0-0.61][25398-0-0-0.99][25398-0-0-0.99][25574-2-1-0.88][25574-2-2-0.47]
[25574-2-2-0.28][25644-1-1-0.99][25644-1-1-0.99][25644-1-2-0.26][25718-1-1-0.99][25718-1-1-0.99][25718-1-0-0.82][25774-2-2-0.87][25774-2-2-0.24][25774-2-2-0.49]
[26032-3-0-0.99][26032-3-3-0.99][26032-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26120-0-0-0.50][26120-0-0-0.99][26120-0-0-0.99][26321-1-1-0.85]
[26321-1-1-0.92][26321-1-2-0.50][26732-1-1-0.99][26732-1-1-0.99][26732-1-1-0.99][26784-3-0-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-3-0.99][26827-3-3-0.99]
[26827-3-3-0.91][26833-0-3-0.99][26833-0-0-0.99][26833-0-0-0.99][26838-2-1-0.77][26838-2-2-0.72][26838-2-2-0.61][26860-1-2-0.99][26860-1-2-0.99][26860-1-2-0.66]
[26948-0-0-0.99][26948-0-0-0.99][26948-0-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-0-0.51][27098-1-0-0.71][27098-1-0-0.99][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.55][27639-3-3-0.99][27639-3-3-0.99][27639-3-3-0.99][27698-3-3-0.99][27698-3-3-0.99][27698-3-3-0.99][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0-0.95][27890-1-1-0.99][27890-1-1-0.99][27890-1-1-0.99][28040-0-0-0.42][28040-0-0-0.49][28040-0-0-0.72][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28577-1-1-0.99][28577-1-1-0.99][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-1-0.88][29198-3-1-0.95][29198-3-1-0.98][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-1-0.83][29877-2-1-0.70][29877-2-2-0.65][30035-1-1-0.99][30035-1-1-0.99][30035-1-1-0.99][30098-0-3-0.99][30098-0-0-0.99]
[30098-0-0-0.99][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.99][30572-2-2-0.92][30572-2-2-0.99][30716-0-1-0.99][30716-0-1-0.99][30716-0-1-0.99]
[30806-2-2--0.36][30806-2-2--0.54][30806-2-2--0.63][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.99][31007-0-0-0.76][31007-0-0-0.95][31007-0-0-0.82][31181-3-0-0.99]
[31181-3-0-0.99][31181-3-0-0.99][31238-0-0-0.99][31238-0-0-0.99][31238-0-0-0.99][31347-0-0-0.99][31347-0-3-0.99][31347-0-0-0.99][31422-2-2-0.72][31422-2-1-0.87]
[31422-2-2-0.67][31429-3-0-0.79][31429-3-0-0.79][31429-3-0-0.93][31431-0-0-0.99][31431-0-0-0.98][31431-0-3-0.46][31432-1-1-0.66][31432-1-1-0.99][31432-1-1-0.99]
[31477-0-0-0.99][31477-0-0-0.99][31477-0-0-0.99][31524-1-3-0.99][31524-1-2-0.47][31524-1-2--0.05][31597-1-2-0.91][31597-1-2-0.98][31597-1-1-0.70][31619-1-0-0.97]
[31619-1-0-0.99][31619-1-0-0.99][31701-0-0-0.99][31701-0-0-0.99][31701-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][31854-3-3-0.99]
[31854-3-3-0.99][32074-1-1-0.53][32074-1-1-0.64][32074-1-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32111-1-1-0.99][32111-1-1-0.99][32111-1-1-0.99]
[32127-1-2-0.99][32127-1-2-0.99][32127-1-2-0.90][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-1-0.88][32263-2-1-0.68][32263-2-2-0.93][32365-0-0-0.54]
[32365-0-0-0.70][32365-0-0-0.92][32411-2-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32473-3-3-0.86][32473-3-3-0.65]
[32473-3-0-0.66][32574-3-0-0.99][32574-3-0-0.99][32574-3-0-0.99][32584-0-0-0.83][32584-0-0-0.79][32584-0-0-0.82][32622-0-1-0.57][32622-0-1-0.19][32622-0-1-0.96]
[32858-3-0-0.99][32858-3-0-0.99][32858-3-0-0.99][32969-3-0-0.99][32969-3-0-0.99][32969-3-0-0.99][33016-2-1-0.99][33016-2-1-0.99][33016-2-1-0.99][33031-1-1-0.33]
[33031-1-1-0.83][33031-1-1-0.79][33035-2-2-0.99][33035-2-2-0.99][33035-2-2-0.99][33133-2-2-0.99][33133-2-2-0.99][33133-2-2-0.99][33173-2-1-0.22][33173-2-1-0.99]
[33173-2-1-0.99][33175-3-1-0.99][33175-3-1-0.99][33175-3-2-0.99][33306-3-1-0.99][33306-3-1-0.99][33306-3-1-0.99][33309-2-1--0.74][33309-2-3--0.63][33309-2-3--0.63]
[33474-0-1-0.99][33474-0-0-0.99][33474-0-0-0.99][33478-2-0-0.99][33478-2-0-0.99][33478-2-0-0.99][33618-1-1-0.99][33618-1-1-0.99][33618-1-1-0.99][33712-0-0-0.99]
[33712-0-0-0.99][33712-0-0-0.99][33782-2-2-0.99][33782-2-2-0.99][33782-2-2-0.99][33914-3-3-0.96][33914-3-3-0.99][33914-3-3-0.99][34076-3-3-0.99][34076-3-3-0.99]
[34076-3-3-0.99][34112-2-1-0.99][34112-2-1-0.99][34112-2-1-0.99][34138-2-3-0.99][34138-2-3-0.99][34138-2-3-0.99][34239-1-1-0.17][34239-1-1-0.06][34239-1-1-0.87]
[34364-2-1-0.99][34364-2-2-0.99][34364-2-2-0.99][34617-1-1-0.99][34617-1-1-0.99][34617-1-1-0.99][34751-3-3-0.99][34751-3-3-0.99][34751-3-3-0.99][34783-2-1-0.99]
[34783-2-1-0.99][34783-2-2-0.59][35015-3-2-0.99][35015-3-3-0.95][35015-3-3-0.90][35018-1-2-0.99][35018-1-1-0.99][35018-1-1-0.99][35288-2-2-0.99][35288-2-2-0.57]
[35288-2-2-0.51]
---------------------------
I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.857 | Acc: 67.625% | Wgt Acc: 67.115%
	I - Batch: 100 | Loss: 0.855 | Acc: 67.438% | Wgt Acc: 67.146%
	I - Batch: 150 | Loss: 0.862 | Acc: 67.542% | Wgt Acc: 67.203%
	I - Batch: 200 | Loss: 0.863 | Acc: 67.469% | Wgt Acc: 67.207%
	I - Batch: 250 | Loss: 0.864 | Acc: 67.675% | Wgt Acc: 67.427%
	I - Batch: 300 | Loss: 0.856 | Acc: 67.979% | Wgt Acc: 67.851%
	I - Batch: 350 | Loss: 0.857 | Acc: 67.625% | Wgt Acc: 67.544%
	I - Batch: 400 | Loss: 0.857 | Acc: 67.672% | Wgt Acc: 67.553%
	I - Batch: 450 | Loss: 0.851 | Acc: 68.014% | Wgt Acc: 67.912%
I - num batch: 478
I - Train -- Loss: 0.848 | Acc: 68.224% | Wgt Acc: 68.153% | LR: 1.000000e-03 | Dur: 320.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1580.   67.   94.  400.]
 [ 103. 1293.  631.  111.]
 [ 108.  298. 1373.  136.]
 [ 300.   76.  104.  967.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.068 | Acc: 57.000% | Wgt Acc: 56.774%
I - num batch: 62
I - Val -- Loss: 1.064 | Acc: 56.371% | Wgt Acc: 56.182% | Dur: 36.42s
I - Confusion Matrix: [row->prediction - col->label]
[[172.   9.  16.  75.]
 [ 33. 157.  88.  35.]
 [ 28.  63. 112.  36.]
 [ 31.   5.   9. 112.]]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.791 | Acc: 71.250% | Wgt Acc: 71.019%
	I - Batch: 100 | Loss: 0.789 | Acc: 71.938% | Wgt Acc: 71.881%
	I - Batch: 150 | Loss: 0.789 | Acc: 72.625% | Wgt Acc: 72.592%
	I - Batch: 200 | Loss: 0.791 | Acc: 72.375% | Wgt Acc: 72.275%
	I - Batch: 250 | Loss: 0.789 | Acc: 72.750% | Wgt Acc: 72.646%
	I - Batch: 300 | Loss: 0.793 | Acc: 72.896% | Wgt Acc: 72.756%
	I - Batch: 350 | Loss: 0.792 | Acc: 73.036% | Wgt Acc: 72.901%
	I - Batch: 400 | Loss: 0.788 | Acc: 73.391% | Wgt Acc: 73.211%
	I - Batch: 450 | Loss: 0.786 | Acc: 73.667% | Wgt Acc: 73.520%
I - num batch: 478
I - Train -- Loss: 0.789 | Acc: 73.380% | Wgt Acc: 73.219% | LR: 1.000000e-03 | Dur: 321.73s
I - Confusion Matrix: [row->prediction - col->label]
[[1642.   47.   65.  337.]
 [  96. 1373.  477.  124.]
 [  93.  243. 1563.  124.]
 [ 260.   71.   97. 1029.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.053 | Acc: 59.250% | Wgt Acc: 57.773%
I - num batch: 62
I - Val -- Loss: 1.062 | Acc: 58.206% | Wgt Acc: 56.748% | Dur: 34.63s
I - Confusion Matrix: [row->prediction - col->label]
[[229.  34.  38. 127.]
 [  3. 130.  43.  19.]
 [ 15.  51. 120.  20.]
 [ 17.  19.  24.  92.]]

I - Local maximum validation set accuracy:  58.21

I - Validation set results: 
[14-1-0-0.20][14-1-2--0.07][14-1-1--0.08][50-3-1-0.12][50-3-3--0.11][50-3-3--0.22][124-2-3-0.37][124-2-2-0.03][124-2-2-0.64][127-0-0-0.99]
[127-0-0-0.99][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.99][567-0-0-0.81][573-1-2-0.01][573-1-1-0.53]
[573-1-1-0.48][615-0-3-0.70][615-0-3-0.91][615-0-3-0.88][695-1-0-0.78][695-1-0-0.54][695-1-0-0.75][722-3-0-0.99][722-3-3-0.99][722-3-3-0.99]
[826-0-0-0.99][826-0-0-0.99][826-0-0-0.99][878-0-0-0.99][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.99][1103-0-0-0.32][1103-0-0-0.45][1212-3-3-0.50]
[1212-3-3--0.20][1212-3-3--0.63][1368-0-0-0.99][1368-0-0-0.99][1368-0-0-0.99][2181-2-0--0.16][2181-2-0-0.02][2181-2-0--0.08][2476-2-2-0.58][2476-2-2-0.65]
[2476-2-2-0.53][2721-2-2-0.77][2721-2-2-0.99][2721-2-2-0.99][2818-1-1-0.11][2818-1-1-0.32][2818-1-1--0.07][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-1-0.99][3231-2-1-0.99][3231-2-1-0.99][3333-2-1-0.74][3333-2-1-0.81][3333-2-3-0.63][3482-2-2--0.38][3482-2-2--0.38][3482-2-2--0.16][3536-3-3-0.33]
[3536-3-3-0.17][3536-3-3-0.87][3625-1-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3909-0-0-0.99][3909-0-0-0.99][3909-0-0-0.99][4035-0-0-0.43][4035-0-0-0.67]
[4035-0-0-0.60][4140-0-0-0.99][4140-0-0-0.99][4140-0-0-0.99][4214-1-3-0.84][4214-1-3--0.26][4214-1-1--0.04][4346-1-0-0.99][4346-1-0-0.99][4346-1-0-0.99]
[4581-2-1-0.96][4581-2-1-0.97][4581-2-2-0.65][4708-3-2-0.99][4708-3-2-0.99][4708-3-2-0.99][4838-3-0--0.17][4838-3-0--0.06][4838-3-0-0.26][4845-1-2--0.30]
[4845-1-3--0.42][4845-1-3--0.43][4868-0-0-0.99][4868-0-0-0.99][4868-0-0-0.99][4939-0-0-0.16][4939-0-3--0.70][4939-0-2--0.40][4984-2-2-0.72][4984-2-2-0.98]
[4984-2-2-0.99][5078-1-2-0.43][5078-1-2-0.91][5078-1-2-0.65][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-2--0.41][5479-1-2--0.42][5479-1-2--0.55]
[5717-0-0-0.59][5717-0-0-0.99][5717-0-0-0.51][5843-1-1-0.82][5843-1-2-0.98][5843-1-2-0.99][5949-3-0-0.90][5949-3-0-0.99][5949-3-0-0.99][5987-2-2-0.84]
[5987-2-2-0.98][5987-2-2-0.99][6014-3-3-0.36][6014-3-3-0.48][6014-3-3-0.66][6033-3-0-0.99][6033-3-0-0.27][6033-3-0-0.97][6313-0-3-0.86][6313-0-0-0.85]
[6313-0-0-0.97][6421-3-3-0.99][6421-3-3-0.92][6421-3-3-0.96][6500-1-0-0.11][6500-1-0-0.17][6500-1-0-0.32][6583-3-3-0.98][6583-3-3-0.96][6583-3-3-0.62]
[6683-3-3-0.83][6683-3-3-0.99][6683-3-3-0.99][6825-2-3-0.86][6825-2-3-0.99][6825-2-3-0.99][6998-3-3-0.02][6998-3-3-0.99][6998-3-3-0.41][7049-3-3-0.65]
[7049-3-3-0.24][7049-3-0-0.99][7517-1-1-0.99][7517-1-1-0.99][7517-1-1-0.99][7521-1-1-0.35][7521-1-1-0.83][7521-1-1-0.99][7528-1-0--0.08][7528-1-3-0.04]
[7528-1-3-0.02][7949-1-1-0.97][7949-1-1-0.98][7949-1-1-0.49][8135-1-0-0.99][8135-1-0-0.99][8135-1-0-0.99][8185-3-0-0.99][8185-3-0-0.99][8185-3-0-0.99]
[8269-3-2-0.38][8269-3-1-0.04][8269-3-1-0.99][8273-3-3-0.99][8273-3-3-0.99][8273-3-3-0.99][8543-3-0-0.99][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.48]
[8666-1-1-0.95][8666-1-1-0.98][8672-0-0-0.99][8672-0-0-0.99][8672-0-0-0.99][8903-1-1-0.16][8903-1-1--0.30][8903-1-2--0.39][9001-2-0-0.83][9001-2-2-0.99]
[9001-2-2-0.99][9036-2-2-0.99][9036-2-2-0.99][9036-2-2-0.99][9281-3-2--0.49][9281-3-2--0.71][9281-3-2--0.46][9300-2-2-0.87][9300-2-2-0.99][9300-2-2-0.31]
[9571-0-3-0.39][9571-0-3-0.18][9571-0-3-0.36][9617-1-1-0.91][9617-1-0-0.33][9617-1-1-0.38][9644-2-2-0.95][9644-2-2-0.99][9644-2-2-0.99][9705-2-0-0.91]
[9705-2-0-0.99][9705-2-0-0.97][9801-0-3-0.60][9801-0-0-0.59][9801-0-0-0.66][9803-3-0-0.99][9803-3-3-0.64][9803-3-3-0.99][9865-3-0-0.99][9865-3-0-0.90]
[9865-3-0-0.99][9896-2-2-0.99][9896-2-2-0.91][9896-2-2-0.97][10314-1-1-0.88][10314-1-1-0.51][10314-1-0-0.17][10337-3-3-0.99][10337-3-3-0.99][10337-3-3-0.99]
[10403-0-0-0.94][10403-0-0-0.56][10403-0-0-0.99][10653-2-1-0.87][10653-2-2-0.25][10653-2-1-0.62][10704-2-1-0.99][10704-2-1-0.98][10704-2-1-0.99][10719-1-1-0.80]
[10719-1-1-0.92][10719-1-1-0.93][10727-1-1-0.30][10727-1-1-0.97][10727-1-1-0.71][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-0-0.99][10969-2-0-0.99]
[10969-2-0-0.99][11042-0-0-0.99][11042-0-0-0.98][11042-0-0-0.99][11088-1-1-0.99][11088-1-1-0.99][11088-1-1-0.99][11322-0-0-0.99][11322-0-0-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11398-2-2-0.99][11398-2-2-0.93][11499-0-0-0.96][11499-0-0-0.98][11499-0-0-0.87][11502-3-0-0.96][11502-3-0-0.14][11502-3-0-0.99][11512-3-3-0.99]
[11512-3-3-0.87][11512-3-3-0.01][11608-1-1-0.99][11608-1-1-0.98][11608-1-1-0.99][11610-0-0-0.93][11610-0-0-0.99][11610-0-0-0.89][11692-0-0-0.99][11692-0-0-0.99]
[11692-0-0-0.99][11905-0-0-0.99][11905-0-0-0.86][11905-0-0-0.99][11993-1-1-0.99][11993-1-1-0.99][11993-1-1-0.99][12002-2-3-0.99][12002-2-0-0.78][12002-2-3-0.67]
[12052-0-0-0.47][12052-0-0-0.99][12052-0-0-0.99][12201-0-0-0.99][12201-0-0-0.99][12201-0-0-0.99][12235-2-1-0.92][12235-2-1-0.86][12235-2-2-0.40][12320-1-0-0.97]
[12320-1-0-0.99][12320-1-0-0.99][12377-2-1-0.15][12377-2-2-0.46][12377-2-2-0.58][12398-2-0-0.98][12398-2-0-0.99][12398-2-0-0.99][12503-1-2-0.99][12503-1-2-0.99]
[12503-1-1-0.99][12617-0-2-0.71][12617-0-2-0.98][12617-0-2-0.41][12685-3-0--0.25][12685-3-3-0.12][12685-3-3-0.79][12738-2-3-0.15][12738-2-3-0.73][12738-2-3--0.06]
[12742-2-2-0.94][12742-2-2-0.53][12742-2-2-0.99][12823-0-0-0.99][12823-0-0-0.99][12823-0-0-0.99][13110-1-1-0.99][13110-1-1-0.76][13110-1-1-0.52][13240-3-0-0.99]
[13240-3-0-0.99][13240-3-0-0.99][13253-1-1-0.99][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-2-0.19][13634-1-2-0.15]
[13634-1-2-0.14][13763-2-3-0.38][13763-2-2-0.94][13763-2-3-0.56][13905-3-0-0.98][13905-3-0-0.52][13905-3-0--0.17][14060-2-1-0.99][14060-2-1-0.96][14060-2-1-0.99]
[14065-3-3-0.36][14065-3-0-0.94][14065-3-3-0.32][14147-3-0-0.86][14147-3-3-0.92][14147-3-0-0.99][14595-2-2-0.96][14595-2-2-0.90][14595-2-2-0.89][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.93][14788-2-2-0.99][14788-2-2-0.99][14788-2-2-0.98][14869-1-1-0.88][14869-1-1-0.98][14869-1-1-0.99][14872-3-0-0.92][14872-3-0-0.99]
[14872-3-0-0.43][14877-1-1-0.80][14877-1-1-0.95][14877-1-1-0.98][14927-0-2--0.13][14927-0-2--0.08][14927-0-2--0.11][15066-0-0-0.99][15066-0-0-0.99][15066-0-0-0.99]
[15175-1-1-0.61][15175-1-1-0.61][15175-1-1-0.07][15178-2-0-0.27][15178-2-3--0.60][15178-2-3--0.63][15375-3-0-0.99][15375-3-0-0.39][15375-3-0-0.71][15389-3-0-0.98]
[15389-3-3-0.17][15389-3-0-0.99][15568-2-1-0.45][15568-2-1-0.97][15568-2-1-0.99][15675-3-3-0.99][15675-3-3-0.99][15675-3-0-0.38][15869-1-1--0.78][15869-1-2-0.06]
[15869-1-3-0.57][16207-3-0-0.99][16207-3-0-0.99][16207-3-0-0.99][16236-0-0--0.21][16236-0-0-0.13][16236-0-0--0.22][16302-3-0-0.99][16302-3-0-0.99][16302-3-0-0.99]
[16331-2-2-0.99][16331-2-2-0.99][16331-2-2-0.99][16381-0-0-0.99][16381-0-0-0.97][16381-0-0-0.98][16488-1-1-0.80][16488-1-1-0.94][16488-1-1-0.41][16495-0-0-0.13]
[16495-0-0-0.99][16495-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-1-0.83][16719-1-2-0.99][16719-1-2-0.24][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.37][16828-0-0-0.95][16828-0-0-0.86][17137-3-0-0.99][17137-3-3-0.72][17137-3-0-0.99][17245-1-3-0.26][17245-1-3--0.10][17245-1-3-0.51]
[17278-3-0-0.36][17278-3-0-0.05][17278-3-0--0.08][17282-0-0-0.99][17282-0-0-0.99][17282-0-0-0.46][17311-2-2-0.99][17311-2-2-0.99][17311-2-2-0.99][17336-2-3-0.19]
[17336-2-2-0.64][17336-2-2-0.35][17608-3-0-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-0-0.71][17627-0-0--0.19][17627-0-0-0.54][17877-3-1-0.99][17877-3-1-0.19]
[17877-3-0-0.42][17924-1-0--0.80][17924-1-0--0.33][17924-1-0--0.68][17984-3-0-0.99][17984-3-0-0.99][17984-3-0-0.99][18211-0-3--0.40][18211-0-3-0.13][18211-0-3-0.20]
[18276-3-0-0.99][18276-3-0-0.99][18276-3-0-0.99][18287-1-1--0.04][18287-1-1-0.99][18287-1-1-0.99][18394-0-0-0.99][18394-0-0-0.96][18394-0-0-0.99][18428-0-0-0.99]
[18428-0-0-0.99][18428-0-0-0.99][18442-0-0-0.99][18442-0-0-0.99][18442-0-0-0.99][18478-3-0-0.95][18478-3-0-0.85][18478-3-0-0.91][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-0-0.18][18616-0-0--0.01][18616-0-0-0.37][18663-0-0-0.93][18663-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99][18718-0-0-0.99][18718-0-0-0.99]
[18766-2-3-0.92][18766-2-3-0.99][18766-2-3-0.99][18824-2-2-0.99][18824-2-2-0.99][18824-2-1-0.91][18890-3-1--0.36][18890-3-2--0.32][18890-3-2--0.49][18930-3-2--0.17]
[18930-3-0--0.16][18930-3-2--0.01][18938-3-0-0.77][18938-3-0-0.93][18938-3-0-0.99][19817-1-2-0.86][19817-1-2-0.99][19817-1-2-0.99][19839-0-0-0.99][19839-0-0-0.99]
[19839-0-0-0.99][19930-3-0-0.99][19930-3-3-0.73][19930-3-3-0.99][19944-0-0-0.42][19944-0-2-0.99][19944-0-2-0.99][20036-2-2-0.99][20036-2-2-0.99][20036-2-2-0.99]
[20101-3-0-0.79][20101-3-0-0.93][20101-3-0-0.94][20474-1-1-0.99][20474-1-1-0.97][20474-1-1-0.95][20547-3-0-0.85][20547-3-3-0.68][20547-3-0-0.84][20929-2-2-0.87]
[20929-2-2-0.99][20929-2-2-0.97][21245-1-1-0.99][21245-1-1-0.99][21245-1-1-0.99][21257-3-0-0.55][21257-3-0-0.10][21257-3-3-0.99][21293-1-1-0.99][21293-1-1-0.99]
[21293-1-1-0.99][21316-1-1-0.99][21316-1-1-0.99][21316-1-3-0.62][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1-0.10][21448-1-1-0.66][21448-1-1-0.30]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-2-0.93][21487-2-2-0.94][21487-2-2-0.91][21714-0-0-0.58][21714-0-0-0.80][21714-0-0-0.65][21943-3-1-0.68]
[21943-3-1-0.65][21943-3-1-0.53][21947-0-0-0.99][21947-0-0-0.99][21947-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21965-2-2-0.99]
[21965-2-2-0.14][21998-1-2-0.02][21998-1-1--0.20][21998-1-2-0.20][22025-0-2-0.67][22025-0-2-0.45][22025-0-2-0.70][22228-3-0-0.99][22228-3-0-0.99][22228-3-0-0.99]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-3-0.98][22494-3-3-0.90][22494-3-3-0.99][22757-0-0-0.99][22757-0-0-0.99][22757-0-0-0.99][22811-3-3-0.14]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-2--0.15][22976-3-2-0.36][22976-3-1-0.99][22985-3-0-0.99][22985-3-0-0.95][22985-3-3-0.80][23014-0-0-0.99][23014-0-0-0.99]
[23014-0-0-0.99][23112-1-1-0.96][23112-1-1-0.99][23112-1-1-0.99][23144-3-0-0.99][23144-3-0-0.93][23144-3-0-0.99][23168-2-0-0.99][23168-2-0-0.96][23168-2-0-0.99]
[23219-0-0-0.28][23219-0-0-0.83][23219-0-3-0.99][23363-3-0--0.39][23363-3-0--0.55][23363-3-0-0.18][23470-0-0-0.96][23470-0-0-0.67][23470-0-0-0.42][23486-2-3-0.14]
[23486-2-3-0.38][23486-2-3-0.08][23497-0-0-0.99][23497-0-3-0.99][23497-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-2--0.70][23690-1-2-0.99]
[23690-1-1-0.99][23921-2-1--0.44][23921-2-2-0.13][23921-2-2-0.74][23936-1-3-0.94][23936-1-3-0.99][23936-1-3-0.99][24040-3-0-0.98][24040-3-0-0.84][24040-3-0-0.64]
[24111-1-1-0.99][24111-1-1-0.99][24111-1-1-0.99][24182-0-0-0.99][24182-0-0-0.99][24182-0-0-0.99][24238-3-3-0.99][24238-3-3-0.95][24238-3-3-0.99][24290-2-0-0.99]
[24290-2-0-0.99][24290-2-0-0.99][24345-0-0-0.99][24345-0-0-0.99][24345-0-2-0.59][24364-1-1--0.85][24364-1-2-0.79][24364-1-2-0.41][24427-3-0-0.99][24427-3-0-0.99]
[24427-3-0-0.99][24477-2-2-0.87][24477-2-2-0.99][24477-2-2-0.89][24495-2-1-0.84][24495-2-1-0.45][24495-2-0-0.50][24893-2-1-0.99][24893-2-1-0.99][24893-2-1-0.99]
[25012-1-1-0.10][25012-1-1-0.18][25012-1-2-0.11][25121-2-2-0.99][25121-2-2-0.99][25121-2-2-0.99][25165-3-1--0.29][25165-3-1--0.32][25165-3-1--0.50][25183-0-0-0.99]
[25183-0-0-0.99][25183-0-0-0.99][25297-3-3-0.99][25297-3-3-0.99][25297-3-3-0.99][25398-0-0-0.60][25398-0-0-0.99][25398-0-0-0.99][25574-2-2-0.69][25574-2-2-0.40]
[25574-2-2-0.38][25644-1-1-0.99][25644-1-1-0.99][25644-1-1-0.51][25718-1-1-0.72][25718-1-1-0.08][25718-1-0--0.40][25774-2-2-0.30][25774-2-2-0.32][25774-2-2-0.67]
[26032-3-0-0.99][26032-3-0-0.73][26032-3-3-0.70][26051-3-3-0.82][26051-3-3-0.99][26051-3-3-0.99][26120-0-0-0.38][26120-0-0-0.77][26120-0-0-0.99][26321-1-1-0.97]
[26321-1-1-0.99][26321-1-2-0.29][26732-1-1-0.96][26732-1-1-0.99][26732-1-1-0.90][26784-3-3-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-0-0.99][26827-3-0-0.99]
[26827-3-2--0.20][26833-0-3-0.99][26833-0-3-0.99][26833-0-3-0.99][26838-2-1-0.58][26838-2-2--0.54][26838-2-0-0.04][26860-1-2-0.55][26860-1-2-0.24][26860-1-2-0.99]
[26948-0-0-0.99][26948-0-0-0.99][26948-0-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-0-0.27][27098-1-0-0.50][27098-1-0-0.95][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.52][27639-3-1-0.75][27639-3-1-0.86][27639-3-1-0.83][27698-3-3-0.99][27698-3-3-0.99][27698-3-3-0.99][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0-0.99][27890-1-3-0.14][27890-1-3-0.21][27890-1-3-0.26][28040-0-2-0.49][28040-0-0-0.51][28040-0-0-0.98][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-2-0.99][28577-1-2-0.97][28577-1-2-0.98][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-0--0.24][29198-3-0--0.06][29198-3-0--0.30][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-2-0.35][29877-2-2--0.30][29877-2-1-0.15][30035-1-1-0.99][30035-1-1-0.97][30035-1-1-0.99][30098-0-0-0.99][30098-0-0-0.99]
[30098-0-0-0.99][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.95][30572-2-2-0.49][30572-2-2-0.99][30716-0-1-0.75][30716-0-1-0.83][30716-0-1-0.89]
[30806-2-3--0.21][30806-2-0--0.13][30806-2-0--0.42][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.99][31007-0-0-0.99][31007-0-0-0.99][31007-0-2-0.67][31181-3-0-0.91]
[31181-3-0-0.96][31181-3-0-0.99][31238-0-0-0.99][31238-0-0-0.99][31238-0-0-0.99][31347-0-0-0.99][31347-0-0-0.97][31347-0-0-0.99][31422-2-2-0.64][31422-2-2-0.71]
[31422-2-0-0.21][31429-3-0-0.96][31429-3-0-0.97][31429-3-0-0.98][31431-0-0-0.99][31431-0-0-0.14][31431-0-0--0.11][31432-1-1-0.55][31432-1-1-0.78][31432-1-1-0.99]
[31477-0-0-0.99][31477-0-0-0.99][31477-0-0-0.99][31524-1-3-0.51][31524-1-2-0.16][31524-1-0--0.11][31597-1-2-0.84][31597-1-2-0.94][31597-1-2-0.19][31619-1-0-0.64]
[31619-1-0-0.93][31619-1-0-0.99][31701-0-0-0.99][31701-0-0-0.99][31701-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31854-3-0-0.99][31854-3-3-0.99]
[31854-3-3-0.99][32074-1-2--0.37][32074-1-2--0.36][32074-1-3-0.67][32078-3-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32111-1-0-0.21][32111-1-1-0.77][32111-1-1-0.99]
[32127-1-2-0.99][32127-1-2-0.99][32127-1-2-0.99][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-3--0.58][32263-2-0--0.86][32263-2-0--0.49][32365-0-0-0.76]
[32365-0-0-0.91][32365-0-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32473-3-0-0.84][32473-3-0-0.83]
[32473-3-0-0.92][32574-3-0-0.99][32574-3-0-0.99][32574-3-0-0.99][32584-0-0-0.68][32584-0-0-0.61][32584-0-0-0.69][32622-0-0-0.18][32622-0-0-0.08][32622-0-0--0.28]
[32858-3-0-0.99][32858-3-0-0.99][32858-3-0-0.99][32969-3-0-0.99][32969-3-0-0.99][32969-3-0-0.99][33016-2-1-0.99][33016-2-1-0.99][33016-2-2-0.99][33031-1-0-0.06]
[33031-1-1--0.13][33031-1-1-0.04][33035-2-2-0.99][33035-2-2-0.99][33035-2-2-0.99][33133-2-1-0.99][33133-2-1-0.99][33133-2-1-0.99][33173-2-0--0.76][33173-2-2-0.04]
[33173-2-2--0.63][33175-3-2-0.25][33175-3-2-0.29][33175-3-2-0.30][33306-3-1-0.99][33306-3-1-0.99][33306-3-1-0.96][33309-2-0--0.12][33309-2-0--0.44][33309-2-0--0.16]
[33474-0-0-0.77][33474-0-0-0.98][33474-0-0-0.99][33478-2-0-0.99][33478-2-0-0.89][33478-2-0-0.96][33618-1-1-0.81][33618-1-1-0.68][33618-1-1-0.90][33712-0-0-0.44]
[33712-0-0-0.47][33712-0-0-0.59][33782-2-2-0.99][33782-2-2-0.99][33782-2-2-0.99][33914-3-3-0.18][33914-3-3-0.79][33914-3-3-0.55][34076-3-3--0.04][34076-3-3-0.43]
[34076-3-0-0.24][34112-2-2-0.99][34112-2-1-0.99][34112-2-1-0.99][34138-2-2-0.98][34138-2-2-0.96][34138-2-2-0.99][34239-1-0-0.72][34239-1-0-0.44][34239-1-1-0.11]
[34364-2-1-0.99][34364-2-2-0.99][34364-2-2-0.98][34617-1-1--0.10][34617-1-1-0.98][34617-1-2-0.71][34751-3-3-0.99][34751-3-3-0.99][34751-3-3-0.99][34783-2-1--0.16]
[34783-2-2-0.92][34783-2-2-0.15][35015-3-2-0.99][35015-3-2-0.80][35015-3-2-0.49][35018-1-2-0.96][35018-1-1-0.99][35018-1-1-0.92][35288-2-3-0.53][35288-2-2-0.02]
[35288-2-2--0.37]
---------------------------
I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.764 | Acc: 76.375% | Wgt Acc: 76.225%
	I - Batch: 100 | Loss: 0.760 | Acc: 75.562% | Wgt Acc: 75.282%
	I - Batch: 150 | Loss: 0.752 | Acc: 75.792% | Wgt Acc: 75.442%
	I - Batch: 200 | Loss: 0.748 | Acc: 75.844% | Wgt Acc: 75.549%
	I - Batch: 250 | Loss: 0.747 | Acc: 76.225% | Wgt Acc: 75.901%
	I - Batch: 300 | Loss: 0.743 | Acc: 76.271% | Wgt Acc: 75.978%
	I - Batch: 350 | Loss: 0.745 | Acc: 76.018% | Wgt Acc: 75.762%
	I - Batch: 400 | Loss: 0.746 | Acc: 75.969% | Wgt Acc: 75.731%
	I - Batch: 450 | Loss: 0.743 | Acc: 76.208% | Wgt Acc: 76.015%
I - num batch: 478
I - Train -- Loss: 0.741 | Acc: 76.495% | Wgt Acc: 76.315% | LR: 1.000000e-03 | Dur: 318.07s
I - Confusion Matrix: [row->prediction - col->label]
[[1681.   42.   53.  315.]
 [  91. 1429.  402.  110.]
 [ 103.  212. 1664.  118.]
 [ 216.   51.   83. 1071.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.048 | Acc: 60.500% | Wgt Acc: 59.717%
I - num batch: 62
I - Val -- Loss: 1.040 | Acc: 60.449% | Wgt Acc: 59.715% | Dur: 38.45s
I - Confusion Matrix: [row->prediction - col->label]
[[214.  19.  25.  77.]
 [  8. 131.  56.  23.]
 [ 11.  63. 114.  24.]
 [ 31.  21.  30. 134.]]

I - Local maximum validation set accuracy:  60.45

I - Validation set results: 
[14-1-2--0.12][14-1-1-0.51][14-1-1-0.81][50-3-3--0.40][50-3-3--0.22][50-3-3--0.35][124-2-2-0.01][124-2-2-0.58][124-2-2-0.80][127-0-0-0.99]
[127-0-0-0.88][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.99][567-0-0-0.67][573-1-1--0.19][573-1-1-0.35]
[573-1-1-0.20][615-0-3-0.89][615-0-3-0.99][615-0-3-0.85][695-1-0-0.97][695-1-0-0.93][695-1-0-0.92][722-3-0-0.99][722-3-3-0.94][722-3-3-0.91]
[826-0-0-0.96][826-0-0-0.99][826-0-0-0.99][878-0-0-0.99][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.61][1103-0-0-0.17][1103-0-0-0.27][1212-3-3-0.99]
[1212-3-3-0.53][1212-3-3-0.22][1368-0-0-0.99][1368-0-0-0.99][1368-0-0-0.99][2181-2-1--0.29][2181-2-1--0.28][2181-2-1--0.39][2476-2-2-0.49][2476-2-2-0.73]
[2476-2-2-0.62][2721-2-2-0.55][2721-2-2-0.82][2721-2-2-0.99][2818-1-3--0.43][2818-1-3-0.52][2818-1-3-0.59][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-2-0.99][3231-2-2-0.99][3231-2-2-0.99][3333-2-3-0.89][3333-2-3-0.95][3333-2-3-0.96][3482-2-2-0.38][3482-2-2-0.56][3482-2-2-0.55][3536-3-3-0.03]
[3536-3-3--0.34][3536-3-3-0.14][3625-1-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3909-0-0-0.71][3909-0-0-0.99][3909-0-0-0.99][4035-0-0-0.03][4035-0-0-0.05]
[4035-0-0--0.38][4140-0-0-0.99][4140-0-0-0.99][4140-0-0-0.99][4214-1-3-0.99][4214-1-3--0.11][4214-1-1-0.59][4346-1-0-0.55][4346-1-0-0.99][4346-1-0-0.99]
[4581-2-2-0.79][4581-2-2-0.78][4581-2-2-0.54][4708-3-2-0.76][4708-3-2-0.73][4708-3-2-0.96][4838-3-3--0.55][4838-3-2--0.56][4838-3-2--0.70][4845-1-2--0.10]
[4845-1-2--0.40][4845-1-2--0.39][4868-0-0-0.99][4868-0-0-0.99][4868-0-0-0.99][4939-0-0--0.29][4939-0-2--0.66][4939-0-2-0.22][4984-2-2--0.06][4984-2-2--0.15]
[4984-2-2-0.59][5078-1-2-0.55][5078-1-2-0.71][5078-1-2-0.93][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-1-0.10][5479-1-1-0.24][5479-1-1-0.33]
[5717-0-0-0.22][5717-0-0-0.98][5717-0-1-0.48][5843-1-1-0.82][5843-1-2-0.14][5843-1-1-0.89][5949-3-0-0.37][5949-3-3-0.99][5949-3-3-0.99][5987-2-2-0.71]
[5987-2-2-0.64][5987-2-1-0.73][6014-3-3-0.32][6014-3-3-0.53][6014-3-3-0.61][6033-3-0-0.06][6033-3-2--0.41][6033-3-0-0.68][6313-0-0-0.77][6313-0-0-0.88]
[6313-0-0-0.86][6421-3-3-0.99][6421-3-3-0.97][6421-3-3-0.84][6500-1-0-0.27][6500-1-0-0.11][6500-1-0-0.29][6583-3-2-0.77][6583-3-3-0.52][6583-3-3-0.58]
[6683-3-3-0.92][6683-3-3-0.99][6683-3-3-0.99][6825-2-3-0.38][6825-2-3-0.88][6825-2-3-0.83][6998-3-3--0.45][6998-3-3-0.65][6998-3-3--0.52][7049-3-3-0.92]
[7049-3-3-0.62][7049-3-3-0.49][7517-1-1-0.99][7517-1-1-0.99][7517-1-1-0.99][7521-1-1-0.55][7521-1-0-0.96][7521-1-1-0.72][7528-1-1-0.51][7528-1-3-0.43]
[7528-1-3-0.74][7949-1-2-0.44][7949-1-2-0.41][7949-1-2--0.04][8135-1-0-0.99][8135-1-0-0.92][8135-1-0-0.94][8185-3-0-0.99][8185-3-0-0.99][8185-3-0-0.99]
[8269-3-2-0.55][8269-3-1-0.23][8269-3-1-0.96][8273-3-3-0.76][8273-3-3-0.99][8273-3-3-0.45][8543-3-0-0.99][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.58]
[8666-1-1-0.94][8666-1-1-0.73][8672-0-0-0.99][8672-0-0-0.99][8672-0-3-0.90][8903-1-1-0.63][8903-1-2-0.74][8903-1-2-0.30][9001-2-0-0.89][9001-2-2-0.99]
[9001-2-2-0.99][9036-2-2-0.99][9036-2-2-0.69][9036-2-2-0.85][9281-3-3--0.15][9281-3-2-0.01][9281-3-2--0.12][9300-2-2-0.95][9300-2-2-0.99][9300-2-2-0.94]
[9571-0-3-0.47][9571-0-3-0.54][9571-0-3-0.67][9617-1-1-0.96][9617-1-1--0.04][9617-1-1-0.47][9644-2-1-0.56][9644-2-1-0.87][9644-2-2-0.72][9705-2-0-0.20]
[9705-2-0--0.46][9705-2-0--0.33][9801-0-3-0.96][9801-0-3-0.97][9801-0-3-0.99][9803-3-3-0.82][9803-3-3-0.79][9803-3-3-0.96][9865-3-0-0.29][9865-3-3-0.18]
[9865-3-0-0.56][9896-2-2-0.97][9896-2-2-0.87][9896-2-2-0.90][10314-1-1-0.89][10314-1-1-0.49][10314-1-2-0.04][10337-3-3-0.99][10337-3-3-0.99][10337-3-3-0.99]
[10403-0-0-0.88][10403-0-0-0.61][10403-0-0-0.97][10653-2-1-0.76][10653-2-1-0.54][10653-2-1-0.53][10704-2-3-0.96][10704-2-1-0.90][10704-2-3-0.98][10719-1-1-0.85]
[10719-1-1-0.99][10719-1-1-0.99][10727-1-1-0.61][10727-1-1-0.96][10727-1-1-0.89][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-0--0.39][10969-2-0--0.55]
[10969-2-0--0.25][11042-0-0-0.99][11042-0-0-0.77][11042-0-0-0.99][11088-1-1-0.99][11088-1-1-0.99][11088-1-1-0.96][11322-0-0-0.99][11322-0-0-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11398-2-2-0.99][11398-2-2-0.85][11499-0-0-0.80][11499-0-0-0.86][11499-0-0-0.75][11502-3-0-0.72][11502-3-2--0.09][11502-3-0-0.99][11512-3-3-0.99]
[11512-3-3-0.99][11512-3-3-0.36][11608-1-1-0.99][11608-1-1-0.99][11608-1-1-0.93][11610-0-0-0.21][11610-0-0-0.99][11610-0-0--0.39][11692-0-0-0.99][11692-0-0-0.99]
[11692-0-0-0.65][11905-0-0-0.99][11905-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][11993-1-1-0.99][11993-1-1-0.99][12002-2-0-0.92][12002-2-0--0.18][12002-2-3-0.57]
[12052-0-0-0.31][12052-0-0-0.99][12052-0-0-0.97][12201-0-0-0.99][12201-0-3-0.95][12201-0-0-0.99][12235-2-2-0.94][12235-2-1-0.76][12235-2-2-0.53][12320-1-2-0.73]
[12320-1-2-0.93][12320-1-0-0.79][12377-2-1-0.50][12377-2-2-0.32][12377-2-2-0.77][12398-2-0-0.39][12398-2-0-0.68][12398-2-0-0.43][12503-1-2-0.99][12503-1-2-0.99]
[12503-1-1-0.93][12617-0-1--0.09][12617-0-1--0.70][12617-0-1--0.40][12685-3-1-0.04][12685-3-3-0.37][12685-3-3-0.99][12738-2-3-0.03][12738-2-3-0.67][12738-2-3--0.05]
[12742-2-2-0.69][12742-2-1-0.32][12742-2-2-0.99][12823-0-0-0.82][12823-0-0-0.89][12823-0-0-0.82][13110-1-1-0.99][13110-1-1-0.91][13110-1-1-0.94][13240-3-3-0.99]
[13240-3-3-0.99][13240-3-3-0.99][13253-1-1-0.99][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-2--0.00][13634-1-2--0.03]
[13634-1-2--0.04][13763-2-1-0.11][13763-2-2--0.07][13763-2-1-0.28][13905-3-0-0.99][13905-3-0-0.42][13905-3-0-0.01][14060-2-1-0.70][14060-2-1-0.99][14060-2-1-0.92]
[14065-3-3-0.10][14065-3-0-0.84][14065-3-3-0.39][14147-3-3-0.63][14147-3-3-0.81][14147-3-0-0.91][14595-2-2-0.47][14595-2-2-0.63][14595-2-2-0.63][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.96][14788-2-2-0.99][14788-2-2-0.99][14788-2-3-0.99][14869-1-1-0.56][14869-1-1-0.47][14869-1-1-0.58][14872-3-0-0.69][14872-3-0-0.99]
[14872-3-0-0.55][14877-1-1-0.17][14877-1-1-0.35][14877-1-1-0.57][14927-0-3-0.20][14927-0-3-0.29][14927-0-3-0.31][15066-0-0-0.99][15066-0-0-0.99][15066-0-0-0.99]
[15175-1-2-0.71][15175-1-2-0.54][15175-1-2-0.53][15178-2-0--0.77][15178-2-3--0.90][15178-2-3--0.83][15375-3-0-0.94][15375-3-3-0.56][15375-3-0--0.46][15389-3-3-0.99]
[15389-3-3-0.99][15389-3-3-0.99][15568-2-1-0.29][15568-2-1-0.89][15568-2-1-0.99][15675-3-3-0.91][15675-3-3-0.58][15675-3-3-0.35][15869-1-2-0.65][15869-1-2-0.34]
[15869-1-2-0.50][16207-3-0-0.41][16207-3-0-0.03][16207-3-0-0.58][16236-0-0--0.13][16236-0-0-0.29][16236-0-0--0.28][16302-3-0-0.99][16302-3-0-0.99][16302-3-0-0.99]
[16331-2-2-0.76][16331-2-2-0.65][16331-2-2-0.67][16381-0-0-0.16][16381-0-3-0.07][16381-0-3-0.60][16488-1-1-0.95][16488-1-1-0.99][16488-1-1-0.92][16495-0-2--0.31]
[16495-0-0-0.99][16495-0-0-0.98][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-2-0.99][16719-1-2-0.99][16719-1-2-0.99][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.04][16828-0-0-0.61][16828-0-0-0.56][17137-3-0-0.99][17137-3-3-0.21][17137-3-0-0.99][17245-1-3--0.08][17245-1-2--0.15][17245-1-3-0.23]
[17278-3-0--0.30][17278-3-2--0.08][17278-3-1--0.06][17282-0-0-0.99][17282-0-0-0.79][17282-0-0-0.30][17311-2-2-0.99][17311-2-2-0.99][17311-2-2-0.99][17336-2-1--0.16]
[17336-2-1-0.67][17336-2-1-0.94][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-0-0.52][17627-0-2--0.08][17627-0-3--0.07][17877-3-1-0.99][17877-3-1-0.57]
[17877-3-0-0.32][17924-1-3--0.33][17924-1-3-0.26][17924-1-3--0.60][17984-3-0-0.99][17984-3-0-0.99][17984-3-0-0.99][18211-0-1--0.13][18211-0-3-0.53][18211-0-3-0.01]
[18276-3-0-0.87][18276-3-0-0.99][18276-3-0-0.78][18287-1-1-0.12][18287-1-1-0.98][18287-1-1-0.88][18394-0-0-0.99][18394-0-0-0.97][18394-0-0-0.99][18428-0-0-0.88]
[18428-0-0-0.71][18428-0-0-0.99][18442-0-3-0.99][18442-0-3-0.99][18442-0-0-0.97][18478-3-3--0.34][18478-3-3--0.41][18478-3-3--0.14][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-0--0.47][18616-0-0--0.12][18616-0-0-0.23][18663-0-0-0.73][18663-0-0-0.94][18663-0-0-0.79][18718-0-0-0.99][18718-0-0-0.99][18718-0-0-0.99]
[18766-2-3-0.60][18766-2-3-0.85][18766-2-3-0.91][18824-2-2-0.97][18824-2-1-0.66][18824-2-1-0.60][18890-3-2-0.64][18890-3-2-0.83][18890-3-2-0.62][18930-3-2-0.29]
[18930-3-2-0.23][18930-3-2-0.53][18938-3-0--0.27][18938-3-2--0.35][18938-3-0--0.56][19817-1-2-0.88][19817-1-2-0.99][19817-1-2-0.99][19839-0-0-0.99][19839-0-0-0.67]
[19839-0-0-0.99][19930-3-0-0.65][19930-3-3-0.76][19930-3-3-0.99][19944-0-0-0.42][19944-0-2-0.97][19944-0-2-0.99][20036-2-2-0.99][20036-2-2-0.99][20036-2-2-0.99]
[20101-3-0--0.49][20101-3-3-0.99][20101-3-3-0.99][20474-1-2-0.22][20474-1-2-0.12][20474-1-2--0.35][20547-3-0-0.91][20547-3-3--0.26][20547-3-0-0.46][20929-2-2-0.89]
[20929-2-1-0.83][20929-2-1-0.53][21245-1-1-0.99][21245-1-1-0.56][21245-1-1-0.93][21257-3-3--0.22][21257-3-1-0.19][21257-3-1-0.99][21293-1-1-0.99][21293-1-1-0.99]
[21293-1-1-0.99][21316-1-1-0.96][21316-1-1-0.99][21316-1-3-0.79][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1-0.90][21448-1-1-0.95][21448-1-1-0.58]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-2-0.65][21487-2-2-0.94][21487-2-2-0.86][21714-0-0-0.79][21714-0-0-0.85][21714-0-0-0.69][21943-3-3-0.30]
[21943-3-2-0.08][21943-3-1-0.66][21947-0-0-0.73][21947-0-0-0.74][21947-0-0-0.69][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21965-2-2-0.99]
[21965-2-1-0.41][21998-1-3--0.25][21998-1-1--0.35][21998-1-1-0.11][22025-0-2-0.94][22025-0-2-0.80][22025-0-2-0.82][22228-3-0-0.99][22228-3-0-0.99][22228-3-0-0.99]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-3-0.99][22494-3-3-0.99][22494-3-3-0.99][22757-0-0-0.99][22757-0-0-0.99][22757-0-0-0.99][22811-3-3-0.13]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-2-0.21][22976-3-2-0.37][22976-3-1-0.99][22985-3-3-0.89][22985-3-3-0.73][22985-3-3-0.73][23014-0-0-0.99][23014-0-0-0.99]
[23014-0-3-0.99][23112-1-1-0.99][23112-1-1-0.99][23112-1-1-0.98][23144-3-0-0.97][23144-3-3-0.99][23144-3-0-0.96][23168-2-0-0.59][23168-2-0--0.18][23168-2-2--0.04]
[23219-0-0--0.25][23219-0-3-0.61][23219-0-3-0.16][23363-3-1--0.30][23363-3-3-0.71][23363-3-3-0.93][23470-0-0-0.37][23470-0-0-0.58][23470-0-0-0.14][23486-2-3-0.73]
[23486-2-3-0.45][23486-2-2-0.16][23497-0-0-0.99][23497-0-3-0.99][23497-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-3--0.82][23690-1-2-0.95]
[23690-1-1-0.99][23921-2-1-0.83][23921-2-2-0.55][23921-2-2-0.89][23936-1-3-0.99][23936-1-3-0.99][23936-1-3-0.99][24040-3-0-0.50][24040-3-0-0.43][24040-3-0-0.26]
[24111-1-1-0.99][24111-1-1-0.99][24111-1-1-0.99][24182-0-0-0.99][24182-0-0-0.99][24182-0-0-0.99][24238-3-3-0.62][24238-3-0-0.77][24238-3-3-0.90][24290-2-0-0.99]
[24290-2-0-0.99][24290-2-0-0.99][24345-0-0-0.99][24345-0-0-0.92][24345-0-2-0.65][24364-1-2-0.49][24364-1-2-0.98][24364-1-2-0.92][24427-3-0-0.99][24427-3-0-0.99]
[24427-3-0-0.99][24477-2-2-0.96][24477-2-2-0.99][24477-2-2-0.99][24495-2-1-0.99][24495-2-1-0.89][24495-2-1-0.69][24893-2-1-0.88][24893-2-1-0.99][24893-2-1-0.52]
[25012-1-1-0.12][25012-1-1-0.28][25012-1-2-0.40][25121-2-2-0.96][25121-2-2-0.96][25121-2-2-0.95][25165-3-3-0.39][25165-3-3-0.52][25165-3-3-0.44][25183-0-0-0.96]
[25183-0-0-0.99][25183-0-0-0.99][25297-3-3-0.99][25297-3-3-0.99][25297-3-3-0.99][25398-0-0-0.55][25398-0-0-0.95][25398-0-0-0.99][25574-2-2-0.90][25574-2-2-0.95]
[25574-2-2-0.92][25644-1-1-0.99][25644-1-1-0.99][25644-1-1-0.44][25718-1-1-0.99][25718-1-1-0.84][25718-1-1--0.28][25774-2-3-0.40][25774-2-3-0.63][25774-2-2-0.75]
[26032-3-0-0.57][26032-3-3--0.03][26032-3-3-0.80][26051-3-3-0.98][26051-3-3-0.99][26051-3-3-0.99][26120-0-0-0.57][26120-0-0-0.99][26120-0-0-0.99][26321-1-1-0.74]
[26321-1-1-0.83][26321-1-2--0.11][26732-1-1-0.38][26732-1-1-0.79][26732-1-1-0.30][26784-3-3-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-3-0.19][26827-3-3--0.19]
[26827-3-2-0.26][26833-0-3-0.96][26833-0-3-0.99][26833-0-3-0.99][26838-2-1-0.59][26838-2-2--0.26][26838-2-1--0.43][26860-1-2-0.33][26860-1-2-0.99][26860-1-2-0.99]
[26948-0-0-0.99][26948-0-0-0.71][26948-0-0-0.98][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-0--0.29][27098-1-0-0.19][27098-1-0-0.85][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.42][27639-3-1-0.43][27639-3-1-0.56][27639-3-1-0.48][27698-3-3-0.99][27698-3-3-0.97][27698-3-3-0.99][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0-0.42][27890-1-1-0.48][27890-1-1-0.29][27890-1-1-0.32][28040-0-2-0.96][28040-0-0-0.34][28040-0-0-0.87][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-1-0.23][28577-1-1-0.21][28577-1-1-0.13][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-1--0.45][29198-3-1--0.26][29198-3-1--0.15][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-2-0.33][29877-2-3-0.29][29877-2-1-0.41][30035-1-1-0.99][30035-1-2-0.95][30035-1-1-0.99][30098-0-3-0.99][30098-0-0-0.91]
[30098-0-0-0.97][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.75][30572-2-3-0.99][30572-2-3-0.07][30716-0-1-0.87][30716-0-1-0.60][30716-0-1-0.73]
[30806-2-2--0.25][30806-2-2--0.85][30806-2-2--0.86][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.99][31007-0-0-0.99][31007-0-0-0.99][31007-0-0--0.15][31181-3-3-0.99]
[31181-3-3-0.72][31181-3-3-0.41][31238-0-0-0.99][31238-0-3-0.88][31238-0-0-0.99][31347-0-0-0.99][31347-0-3-0.94][31347-0-0-0.99][31422-2-2-0.40][31422-2-2-0.18]
[31422-2-0-0.05][31429-3-3--0.30][31429-3-3--0.59][31429-3-0--0.25][31431-0-0-0.99][31431-0-0-0.66][31431-0-0--0.25][31432-1-1-0.60][31432-1-1-0.90][31432-1-1-0.98]
[31477-0-0-0.99][31477-0-0-0.99][31477-0-0-0.99][31524-1-3-0.99][31524-1-3-0.22][31524-1-0--0.01][31597-1-2-0.71][31597-1-2-0.87][31597-1-2-0.93][31619-1-2-0.78]
[31619-1-0-0.98][31619-1-2-0.99][31701-0-0-0.99][31701-0-0-0.99][31701-0-0-0.97][31755-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31854-3-3-0.89][31854-3-3-0.99]
[31854-3-3-0.93][32074-1-2-0.00][32074-1-2--0.24][32074-1-3-0.79][32078-3-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32111-1-1-0.36][32111-1-1-0.97][32111-1-1-0.99]
[32127-1-2-0.93][32127-1-2-0.99][32127-1-2-0.83][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-3--0.07][32263-2-3--0.72][32263-2-2--0.27][32365-0-0-0.09]
[32365-0-0-0.12][32365-0-0-0.70][32411-2-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32429-3-0-0.99][32473-3-0-0.45][32473-3-0-0.25]
[32473-3-0-0.16][32574-3-3-0.99][32574-3-0-0.99][32574-3-0-0.99][32584-0-0--0.03][32584-0-0--0.16][32584-0-0--0.11][32622-0-0--0.39][32622-0-0-0.01][32622-0-0-0.35]
[32858-3-0-0.99][32858-3-0-0.99][32858-3-0-0.99][32969-3-0--0.27][32969-3-0--0.63][32969-3-0--0.34][33016-2-2-0.99][33016-2-2-0.99][33016-2-2-0.99][33031-1-1--0.17]
[33031-1-1-0.70][33031-1-1-0.75][33035-2-2-0.99][33035-2-2-0.99][33035-2-2-0.99][33133-2-1-0.99][33133-2-1-0.93][33133-2-1-0.99][33173-2-1--0.08][33173-2-1-0.06]
[33173-2-1-0.04][33175-3-1-0.37][33175-3-1-0.42][33175-3-1-0.41][33306-3-1-0.83][33306-3-1-0.80][33306-3-1-0.86][33309-2-3--0.51][33309-2-3-0.33][33309-2-3-0.25]
[33474-0-0-0.66][33474-0-0-0.81][33474-0-0-0.99][33478-2-0-0.25][33478-2-0-0.50][33478-2-0-0.18][33618-1-1-0.75][33618-1-1-0.72][33618-1-1-0.75][33712-0-0-0.15]
[33712-0-0-0.42][33712-0-0-0.37][33782-2-2-0.99][33782-2-2-0.99][33782-2-2-0.99][33914-3-3-0.64][33914-3-3-0.95][33914-3-3-0.62][34076-3-3--0.33][34076-3-3-0.04]
[34076-3-3--0.32][34112-2-1-0.99][34112-2-1-0.99][34112-2-1-0.99][34138-2-2-0.51][34138-2-1-0.53][34138-2-1-0.65][34239-1-1-0.41][34239-1-2--0.32][34239-1-1-0.86]
[34364-2-1-0.99][34364-2-2-0.96][34364-2-2-0.99][34617-1-1-0.98][34617-1-1-0.99][34617-1-2--0.06][34751-3-3-0.99][34751-3-3-0.99][34751-3-3-0.99][34783-2-2-0.27]
[34783-2-2-0.93][34783-2-1-0.87][35015-3-2-0.99][35015-3-3-0.99][35015-3-3-0.94][35018-1-2-0.76][35018-1-1-0.99][35018-1-1-0.63][35288-2-2-0.86][35288-2-2--0.28]
[35288-2-2-0.07]
---------------------------
I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.664 | Acc: 80.375% | Wgt Acc: 80.187%
	I - Batch: 100 | Loss: 0.672 | Acc: 81.062% | Wgt Acc: 80.834%
	I - Batch: 150 | Loss: 0.683 | Acc: 80.250% | Wgt Acc: 80.004%
	I - Batch: 200 | Loss: 0.694 | Acc: 79.406% | Wgt Acc: 79.227%
	I - Batch: 250 | Loss: 0.695 | Acc: 79.425% | Wgt Acc: 79.257%
	I - Batch: 300 | Loss: 0.695 | Acc: 79.688% | Wgt Acc: 79.489%
	I - Batch: 350 | Loss: 0.697 | Acc: 79.786% | Wgt Acc: 79.621%
	I - Batch: 400 | Loss: 0.697 | Acc: 79.703% | Wgt Acc: 79.525%
	I - Batch: 450 | Loss: 0.697 | Acc: 79.931% | Wgt Acc: 79.758%
I - num batch: 478
I - Train -- Loss: 0.697 | Acc: 79.780% | Wgt Acc: 79.609% | LR: 1.000000e-03 | Dur: 320.97s
I - Confusion Matrix: [row->prediction - col->label]
[[1737.   43.   55.  289.]
 [  79. 1469.  311.   77.]
 [  71.  178. 1746.  104.]
 [ 204.   44.   90. 1144.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.077 | Acc: 58.125% | Wgt Acc: 57.079%
I - num batch: 62
I - Val -- Loss: 1.081 | Acc: 56.677% | Wgt Acc: 55.774% | Dur: 34.40s
I - Confusion Matrix: [row->prediction - col->label]
[[176.   9.  10.  55.]
 [ 23. 134.  67.  47.]
 [ 39.  86. 141.  51.]
 [ 26.   5.   7. 105.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.677 | Acc: 82.500% | Wgt Acc: 82.249%
	I - Batch: 100 | Loss: 0.668 | Acc: 81.750% | Wgt Acc: 81.539%
	I - Batch: 150 | Loss: 0.670 | Acc: 81.500% | Wgt Acc: 81.329%
	I - Batch: 200 | Loss: 0.668 | Acc: 82.000% | Wgt Acc: 81.828%
	I - Batch: 250 | Loss: 0.666 | Acc: 82.250% | Wgt Acc: 82.064%
	I - Batch: 300 | Loss: 0.667 | Acc: 81.958% | Wgt Acc: 81.758%
	I - Batch: 350 | Loss: 0.670 | Acc: 81.732% | Wgt Acc: 81.546%
	I - Batch: 400 | Loss: 0.671 | Acc: 81.734% | Wgt Acc: 81.548%
	I - Batch: 450 | Loss: 0.675 | Acc: 81.458% | Wgt Acc: 81.267%
I - num batch: 478
I - Train -- Loss: 0.675 | Acc: 81.508% | Wgt Acc: 81.325% | LR: 1.000000e-03 | Dur: 323.20s
I - Confusion Matrix: [row->prediction - col->label]
[[1756.   48.   72.  255.]
 [  76. 1486.  248.   67.]
 [  74.  164. 1805.  111.]
 [ 185.   36.   77. 1181.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.045 | Acc: 61.500% | Wgt Acc: 60.911%
I - num batch: 62
I - Val -- Loss: 1.042 | Acc: 60.347% | Wgt Acc: 59.851% | Dur: 34.28s
I - Confusion Matrix: [row->prediction - col->label]
[[179.  18.  11.  57.]
 [ 13. 133.  48.  20.]
 [ 19.  70. 138.  39.]
 [ 53.  13.  28. 142.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.616 | Acc: 85.625% | Wgt Acc: 85.480%
	I - Batch: 100 | Loss: 0.624 | Acc: 85.500% | Wgt Acc: 85.414%
	I - Batch: 150 | Loss: 0.623 | Acc: 85.917% | Wgt Acc: 85.776%
	I - Batch: 200 | Loss: 0.628 | Acc: 85.500% | Wgt Acc: 85.295%
	I - Batch: 250 | Loss: 0.632 | Acc: 84.950% | Wgt Acc: 84.772%
	I - Batch: 300 | Loss: 0.634 | Acc: 84.708% | Wgt Acc: 84.493%
	I - Batch: 350 | Loss: 0.637 | Acc: 84.500% | Wgt Acc: 84.278%
	I - Batch: 400 | Loss: 0.638 | Acc: 84.469% | Wgt Acc: 84.283%
	I - Batch: 450 | Loss: 0.640 | Acc: 84.250% | Wgt Acc: 84.113%
I - num batch: 478
I - Train -- Loss: 0.640 | Acc: 84.308% | Wgt Acc: 84.174% | LR: 1.000000e-03 | Dur: 321.33s
I - Confusion Matrix: [row->prediction - col->label]
[[1797.   34.   45.  229.]
 [  79. 1544.  228.   65.]
 [  51.  129. 1868.   87.]
 [ 164.   27.   61. 1233.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.087 | Acc: 57.875% | Wgt Acc: 55.775%
I - num batch: 62
I - Val -- Loss: 1.083 | Acc: 57.594% | Wgt Acc: 55.525% | Dur: 33.03s
I - Confusion Matrix: [row->prediction - col->label]
[[213.  26.  21.  92.]
 [ 14. 101.  28.  17.]
 [ 22.  99. 160.  58.]
 [ 15.   8.  16.  91.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.602 | Acc: 86.250% | Wgt Acc: 86.004%
	I - Batch: 100 | Loss: 0.600 | Acc: 86.312% | Wgt Acc: 86.072%
	I - Batch: 150 | Loss: 0.608 | Acc: 85.458% | Wgt Acc: 85.261%
	I - Batch: 200 | Loss: 0.614 | Acc: 85.219% | Wgt Acc: 85.014%
	I - Batch: 250 | Loss: 0.621 | Acc: 84.925% | Wgt Acc: 84.710%
	I - Batch: 300 | Loss: 0.624 | Acc: 85.000% | Wgt Acc: 84.819%
	I - Batch: 350 | Loss: 0.624 | Acc: 85.161% | Wgt Acc: 84.988%
	I - Batch: 400 | Loss: 0.622 | Acc: 85.391% | Wgt Acc: 85.240%
	I - Batch: 450 | Loss: 0.624 | Acc: 85.139% | Wgt Acc: 85.025%
I - num batch: 478
I - Train -- Loss: 0.621 | Acc: 85.395% | Wgt Acc: 85.280% | LR: 1.000000e-03 | Dur: 319.91s
I - Confusion Matrix: [row->prediction - col->label]
[[1802.   39.   52.  210.]
 [  66. 1551.  183.   52.]
 [  66.  114. 1903.   83.]
 [ 157.   30.   64. 1269.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.049 | Acc: 58.875% | Wgt Acc: 58.162%
I - num batch: 62
I - Val -- Loss: 1.049 | Acc: 58.818% | Wgt Acc: 58.130% | Dur: 33.97s
I - Confusion Matrix: [row->prediction - col->label]
[[191.  27.  22.  71.]
 [  5. 111.  38.  14.]
 [ 22.  80. 127.  25.]
 [ 46.  16.  38. 148.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.614 | Acc: 86.750% | Wgt Acc: 86.603%
	I - Batch: 100 | Loss: 0.618 | Acc: 85.562% | Wgt Acc: 85.499%
	I - Batch: 150 | Loss: 0.613 | Acc: 86.125% | Wgt Acc: 86.052%
	I - Batch: 200 | Loss: 0.604 | Acc: 86.625% | Wgt Acc: 86.560%
	I - Batch: 250 | Loss: 0.608 | Acc: 86.550% | Wgt Acc: 86.451%
	I - Batch: 300 | Loss: 0.607 | Acc: 86.542% | Wgt Acc: 86.481%
	I - Batch: 350 | Loss: 0.608 | Acc: 86.232% | Wgt Acc: 86.166%
	I - Batch: 400 | Loss: 0.606 | Acc: 86.578% | Wgt Acc: 86.511%
	I - Batch: 450 | Loss: 0.603 | Acc: 86.750% | Wgt Acc: 86.701%
I - num batch: 478
I - Train -- Loss: 0.601 | Acc: 86.939% | Wgt Acc: 86.890% | LR: 1.000000e-03 | Dur: 315.52s
I - Confusion Matrix: [row->prediction - col->label]
[[1807.   26.   47.  180.]
 [  73. 1585.  161.   46.]
 [  60.   97. 1942.   79.]
 [ 151.   26.   52. 1309.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.099 | Acc: 57.375% | Wgt Acc: 56.247%
I - num batch: 62
I - Val -- Loss: 1.102 | Acc: 56.269% | Wgt Acc: 55.208% | Dur: 34.28s
I - Confusion Matrix: [row->prediction - col->label]
[[155.   6.  12.  40.]
 [ 22. 110.  36.  22.]
 [ 51. 110. 167.  76.]
 [ 36.   8.  10. 120.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.566 | Acc: 89.750% | Wgt Acc: 89.500%
	I - Batch: 100 | Loss: 0.550 | Acc: 90.312% | Wgt Acc: 90.124%
	I - Batch: 150 | Loss: 0.543 | Acc: 90.583% | Wgt Acc: 90.446%
	I - Batch: 200 | Loss: 0.537 | Acc: 90.938% | Wgt Acc: 90.862%
	I - Batch: 250 | Loss: 0.539 | Acc: 90.825% | Wgt Acc: 90.751%
	I - Batch: 300 | Loss: 0.542 | Acc: 90.812% | Wgt Acc: 90.742%
	I - Batch: 350 | Loss: 0.545 | Acc: 90.571% | Wgt Acc: 90.484%
	I - Batch: 400 | Loss: 0.542 | Acc: 90.844% | Wgt Acc: 90.730%
	I - Batch: 450 | Loss: 0.539 | Acc: 90.986% | Wgt Acc: 90.883%
I - num batch: 478
I - Train -- Loss: 0.538 | Acc: 91.074% | Wgt Acc: 90.980% | LR: 5.000000e-04 | Dur: 322.53s
I - Confusion Matrix: [row->prediction - col->label]
[[1911.   23.   33.  132.]
 [  36. 1640.  106.   47.]
 [  46.   55. 2031.   58.]
 [  98.   16.   32. 1377.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.042 | Acc: 58.875% | Wgt Acc: 57.968%
I - num batch: 62
I - Val -- Loss: 1.040 | Acc: 58.308% | Wgt Acc: 57.360% | Dur: 35.07s
I - Confusion Matrix: [row->prediction - col->label]
[[206.  28.  26.  82.]
 [  5. 103.  36.  11.]
 [  6.  79. 121.  23.]
 [ 47.  24.  42. 142.]]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.518 | Acc: 91.875% | Wgt Acc: 91.716%
	I - Batch: 100 | Loss: 0.513 | Acc: 92.312% | Wgt Acc: 92.198%
	I - Batch: 150 | Loss: 0.514 | Acc: 92.667% | Wgt Acc: 92.566%
	I - Batch: 200 | Loss: 0.514 | Acc: 92.781% | Wgt Acc: 92.717%
	I - Batch: 250 | Loss: 0.516 | Acc: 92.675% | Wgt Acc: 92.573%
	I - Batch: 300 | Loss: 0.516 | Acc: 92.708% | Wgt Acc: 92.589%
	I - Batch: 350 | Loss: 0.517 | Acc: 92.536% | Wgt Acc: 92.426%
	I - Batch: 400 | Loss: 0.516 | Acc: 92.625% | Wgt Acc: 92.496%
	I - Batch: 450 | Loss: 0.517 | Acc: 92.528% | Wgt Acc: 92.395%
I - num batch: 478
I - Train -- Loss: 0.520 | Acc: 92.396% | Wgt Acc: 92.253% | LR: 5.000000e-04 | Dur: 316.85s
I - Confusion Matrix: [row->prediction - col->label]
[[1948.   22.   30.  116.]
 [  38. 1646.   78.   36.]
 [  30.   51. 2067.   63.]
 [  75.   15.   27. 1399.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.028 | Acc: 60.125% | Wgt Acc: 58.717%
I - num batch: 62
I - Val -- Loss: 1.029 | Acc: 60.245% | Wgt Acc: 58.945% | Dur: 33.22s
I - Confusion Matrix: [row->prediction - col->label]
[[206.  21.  22.  79.]
 [ 12. 109.  32.  17.]
 [ 13.  88. 146.  32.]
 [ 33.  16.  25. 130.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.517 | Acc: 92.375% | Wgt Acc: 92.232%
	I - Batch: 100 | Loss: 0.511 | Acc: 92.500% | Wgt Acc: 92.406%
	I - Batch: 150 | Loss: 0.509 | Acc: 93.042% | Wgt Acc: 92.899%
	I - Batch: 200 | Loss: 0.509 | Acc: 93.406% | Wgt Acc: 93.271%
	I - Batch: 250 | Loss: 0.506 | Acc: 93.475% | Wgt Acc: 93.364%
	I - Batch: 300 | Loss: 0.507 | Acc: 93.396% | Wgt Acc: 93.276%
	I - Batch: 350 | Loss: 0.507 | Acc: 93.357% | Wgt Acc: 93.214%
	I - Batch: 400 | Loss: 0.507 | Acc: 93.594% | Wgt Acc: 93.457%
	I - Batch: 450 | Loss: 0.506 | Acc: 93.611% | Wgt Acc: 93.484%
I - num batch: 478
I - Train -- Loss: 0.506 | Acc: 93.626% | Wgt Acc: 93.519% | LR: 5.000000e-04 | Dur: 321.64s
I - Confusion Matrix: [row->prediction - col->label]
[[1958.   16.   26.  106.]
 [  27. 1669.   55.   32.]
 [  38.   43. 2098.   47.]
 [  68.    6.   23. 1429.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.042 | Acc: 59.000% | Wgt Acc: 57.857%
I - num batch: 62
I - Val -- Loss: 1.038 | Acc: 58.308% | Wgt Acc: 57.314% | Dur: 36.07s
I - Confusion Matrix: [row->prediction - col->label]
[[191.  19.  20.  68.]
 [ 11. 108.  34.  17.]
 [ 13.  90. 138.  38.]
 [ 49.  17.  33. 135.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.487 | Acc: 94.875% | Wgt Acc: 94.706%
	I - Batch: 100 | Loss: 0.483 | Acc: 94.750% | Wgt Acc: 94.701%
	I - Batch: 150 | Loss: 0.487 | Acc: 94.292% | Wgt Acc: 94.299%
	I - Batch: 200 | Loss: 0.488 | Acc: 94.094% | Wgt Acc: 94.057%
	I - Batch: 250 | Loss: 0.489 | Acc: 94.300% | Wgt Acc: 94.239%
	I - Batch: 300 | Loss: 0.487 | Acc: 94.458% | Wgt Acc: 94.395%
	I - Batch: 350 | Loss: 0.489 | Acc: 94.446% | Wgt Acc: 94.383%
	I - Batch: 400 | Loss: 0.490 | Acc: 94.422% | Wgt Acc: 94.355%
	I - Batch: 450 | Loss: 0.489 | Acc: 94.528% | Wgt Acc: 94.458%
I - num batch: 478
I - Train -- Loss: 0.490 | Acc: 94.477% | Wgt Acc: 94.400% | LR: 5.000000e-04 | Dur: 321.32s
I - Confusion Matrix: [row->prediction - col->label]
[[1966.   11.   21.   80.]
 [  34. 1681.   44.   40.]
 [  37.   31. 2116.   38.]
 [  54.   11.   21. 1456.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.057 | Acc: 58.750% | Wgt Acc: 58.162%
I - num batch: 62
I - Val -- Loss: 1.053 | Acc: 58.818% | Wgt Acc: 58.243% | Dur: 36.27s
I - Confusion Matrix: [row->prediction - col->label]
[[170.   9.  12.  45.]
 [ 20. 130.  52.  23.]
 [ 28.  86. 143.  56.]
 [ 46.   9.  18. 134.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 95.000% | Wgt Acc: 94.966%
	I - Batch: 100 | Loss: 0.474 | Acc: 95.250% | Wgt Acc: 95.201%
	I - Batch: 150 | Loss: 0.475 | Acc: 95.292% | Wgt Acc: 95.218%
	I - Batch: 200 | Loss: 0.478 | Acc: 95.219% | Wgt Acc: 95.152%
	I - Batch: 250 | Loss: 0.478 | Acc: 95.325% | Wgt Acc: 95.230%
	I - Batch: 300 | Loss: 0.476 | Acc: 95.479% | Wgt Acc: 95.410%
	I - Batch: 350 | Loss: 0.479 | Acc: 95.196% | Wgt Acc: 95.124%
	I - Batch: 400 | Loss: 0.481 | Acc: 94.969% | Wgt Acc: 94.903%
	I - Batch: 450 | Loss: 0.482 | Acc: 94.972% | Wgt Acc: 94.916%
I - num batch: 478
I - Train -- Loss: 0.481 | Acc: 95.027% | Wgt Acc: 94.975% | LR: 5.000000e-04 | Dur: 322.80s
I - Confusion Matrix: [row->prediction - col->label]
[[1961.   11.   16.   72.]
 [  32. 1692.   36.   31.]
 [  33.   25. 2136.   39.]
 [  65.    6.   14. 1472.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.080 | Acc: 57.750% | Wgt Acc: 56.080%
I - num batch: 62
I - Val -- Loss: 1.069 | Acc: 58.308% | Wgt Acc: 56.793% | Dur: 38.21s
I - Confusion Matrix: [row->prediction - col->label]
[[212.  21.  26.  92.]
 [ 12. 113.  47.  23.]
 [ 10.  86. 140.  36.]
 [ 30.  14.  12. 107.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 95.250% | Wgt Acc: 95.189%
	I - Batch: 100 | Loss: 0.472 | Acc: 95.750% | Wgt Acc: 95.664%
	I - Batch: 150 | Loss: 0.479 | Acc: 95.417% | Wgt Acc: 95.283%
	I - Batch: 200 | Loss: 0.478 | Acc: 95.375% | Wgt Acc: 95.247%
	I - Batch: 250 | Loss: 0.474 | Acc: 95.375% | Wgt Acc: 95.281%
	I - Batch: 300 | Loss: 0.475 | Acc: 95.271% | Wgt Acc: 95.179%
	I - Batch: 350 | Loss: 0.475 | Acc: 95.339% | Wgt Acc: 95.246%
	I - Batch: 400 | Loss: 0.475 | Acc: 95.391% | Wgt Acc: 95.303%
	I - Batch: 450 | Loss: 0.474 | Acc: 95.389% | Wgt Acc: 95.312%
I - num batch: 478
I - Train -- Loss: 0.474 | Acc: 95.433% | Wgt Acc: 95.356% | LR: 5.000000e-04 | Dur: 296.94s
I - Confusion Matrix: [row->prediction - col->label]
[[1990.   10.   15.   71.]
 [  19. 1690.   38.   30.]
 [  27.   33. 2133.   34.]
 [  55.    1.   16. 1479.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.040 | Acc: 60.500% | Wgt Acc: 59.661%
I - num batch: 62
I - Val -- Loss: 1.036 | Acc: 59.837% | Wgt Acc: 59.149% | Dur: 29.73s
I - Confusion Matrix: [row->prediction - col->label]
[[194.  24.  24.  60.]
 [ 17. 123.  50.  22.]
 [  9.  69. 129.  35.]
 [ 44.  18.  22. 141.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 95.625% | Wgt Acc: 95.492%
	I - Batch: 100 | Loss: 0.461 | Acc: 96.188% | Wgt Acc: 96.109%
	I - Batch: 150 | Loss: 0.461 | Acc: 96.125% | Wgt Acc: 96.068%
	I - Batch: 200 | Loss: 0.467 | Acc: 95.844% | Wgt Acc: 95.757%
	I - Batch: 250 | Loss: 0.464 | Acc: 96.000% | Wgt Acc: 95.923%
	I - Batch: 300 | Loss: 0.462 | Acc: 96.208% | Wgt Acc: 96.135%
	I - Batch: 350 | Loss: 0.461 | Acc: 96.179% | Wgt Acc: 96.100%
	I - Batch: 400 | Loss: 0.465 | Acc: 96.000% | Wgt Acc: 95.913%
	I - Batch: 450 | Loss: 0.466 | Acc: 95.903% | Wgt Acc: 95.813%
I - num batch: 478
I - Train -- Loss: 0.467 | Acc: 95.851% | Wgt Acc: 95.760% | LR: 5.000000e-04 | Dur: 280.22s
I - Confusion Matrix: [row->prediction - col->label]
[[2006.   10.   16.   68.]
 [  19. 1697.   27.   31.]
 [  26.   23. 2140.   34.]
 [  40.    4.   19. 1481.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.055 | Acc: 59.375% | Wgt Acc: 59.051%
I - num batch: 62
I - Val -- Loss: 1.055 | Acc: 58.818% | Wgt Acc: 58.582% | Dur: 31.11s
I - Confusion Matrix: [row->prediction - col->label]
[[161.  15.  11.  41.]
 [ 21. 128.  54.  23.]
 [ 19.  75. 137.  43.]
 [ 63.  16.  23. 151.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.444 | Acc: 97.375% | Wgt Acc: 97.337%
	I - Batch: 100 | Loss: 0.451 | Acc: 96.938% | Wgt Acc: 96.906%
	I - Batch: 150 | Loss: 0.448 | Acc: 97.333% | Wgt Acc: 97.296%
	I - Batch: 200 | Loss: 0.451 | Acc: 97.250% | Wgt Acc: 97.199%
	I - Batch: 250 | Loss: 0.452 | Acc: 97.000% | Wgt Acc: 96.976%
	I - Batch: 300 | Loss: 0.451 | Acc: 96.917% | Wgt Acc: 96.898%
	I - Batch: 350 | Loss: 0.453 | Acc: 96.839% | Wgt Acc: 96.801%
	I - Batch: 400 | Loss: 0.449 | Acc: 96.844% | Wgt Acc: 96.820%
	I - Batch: 450 | Loss: 0.450 | Acc: 96.833% | Wgt Acc: 96.805%
I - num batch: 478
I - Train -- Loss: 0.450 | Acc: 96.807% | Wgt Acc: 96.768% | LR: 5.000000e-04 | Dur: 279.18s
I - Confusion Matrix: [row->prediction - col->label]
[[2009.    6.   16.   52.]
 [  20. 1708.   16.   21.]
 [  28.   19. 2160.   21.]
 [  34.    1.   10. 1520.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.079 | Acc: 57.500% | Wgt Acc: 56.663%
I - num batch: 62
I - Val -- Loss: 1.069 | Acc: 58.104% | Wgt Acc: 57.337% | Dur: 30.23s
I - Confusion Matrix: [row->prediction - col->label]
[[188.  22.  28.  55.]
 [ 25. 126.  50.  30.]
 [ 15.  70. 130.  47.]
 [ 36.  16.  17. 126.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.436 | Acc: 97.250% | Wgt Acc: 97.283%
	I - Batch: 100 | Loss: 0.436 | Acc: 97.375% | Wgt Acc: 97.392%
	I - Batch: 150 | Loss: 0.434 | Acc: 97.375% | Wgt Acc: 97.367%
	I - Batch: 200 | Loss: 0.433 | Acc: 97.562% | Wgt Acc: 97.560%
	I - Batch: 250 | Loss: 0.437 | Acc: 97.425% | Wgt Acc: 97.398%
	I - Batch: 300 | Loss: 0.438 | Acc: 97.375% | Wgt Acc: 97.346%
	I - Batch: 350 | Loss: 0.440 | Acc: 97.393% | Wgt Acc: 97.376%
	I - Batch: 400 | Loss: 0.442 | Acc: 97.219% | Wgt Acc: 97.213%
	I - Batch: 450 | Loss: 0.442 | Acc: 97.208% | Wgt Acc: 97.198%
I - num batch: 478
I - Train -- Loss: 0.443 | Acc: 97.160% | Wgt Acc: 97.137% | LR: 5.000000e-04 | Dur: 279.95s
I - Confusion Matrix: [row->prediction - col->label]
[[2019.    5.   12.   45.]
 [  19. 1716.   20.   14.]
 [  18.   13. 2160.   26.]
 [  35.    0.   10. 1529.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.033 | Acc: 62.375% | Wgt Acc: 61.660%
I - num batch: 62
I - Val -- Loss: 1.036 | Acc: 61.060% | Wgt Acc: 60.485% | Dur: 30.71s
I - Confusion Matrix: [row->prediction - col->label]
[[198.  23.  26.  58.]
 [ 13. 129.  49.  19.]
 [ 10.  65. 126.  35.]
 [ 43.  17.  24. 146.]]

I - Local maximum validation set accuracy:  61.06

I - Validation set results: 
[14-1-2-0.36][14-1-1-0.09][14-1-1-0.41][50-3-1-0.31][50-3-1--0.20][50-3-2--0.44][124-2-2--0.57][124-2-2-0.77][124-2-2-0.25][127-0-0-0.62]
[127-0-0-0.68][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.69][567-0-0-0.93][573-1-1--0.16][573-1-1--0.01]
[573-1-1--0.18][615-0-0-0.58][615-0-3-0.57][615-0-0-0.75][695-1-0-0.92][695-1-0-0.91][695-1-0-0.92][722-3-3-0.73][722-3-3-0.93][722-3-3-0.99]
[826-0-0-0.48][826-0-0-0.94][826-0-0-0.92][878-0-0-0.99][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.59][1103-0-0-0.21][1103-0-0-0.18][1212-3-3-0.66]
[1212-3-3-0.11][1212-3-3--0.22][1368-0-0-0.99][1368-0-0-0.90][1368-0-0-0.88][2181-2-0--1.00][2181-2-0--1.00][2181-2-0--1.00][2476-2-2-0.99][2476-2-2-0.99]
[2476-2-2-0.95][2721-2-2-0.72][2721-2-2-0.97][2721-2-2-0.99][2818-1-2--0.32][2818-1-3-0.33][2818-1-3-0.89][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-2-0.99][3231-2-2-0.99][3231-2-2-0.99][3333-2-2--0.02][3333-2-2--0.27][3333-2-2-0.00][3482-2-2-0.57][3482-2-2--0.05][3482-2-2--0.19][3536-3-3-0.05]
[3536-3-3--0.46][3536-3-3-0.26][3625-1-1-0.99][3625-1-1-0.99][3625-1-1-0.99][3909-0-0-0.42][3909-0-0-0.94][3909-0-0-0.95][4035-0-3--0.77][4035-0-3--0.67]
[4035-0-2--0.45][4140-0-0-0.93][4140-0-0--0.16][4140-0-0-0.76][4214-1-3-0.02][4214-1-3-0.06][4214-1-2--0.29][4346-1-0-0.89][4346-1-0-0.33][4346-1-0-0.27]
[4581-2-2-0.36][4581-2-2-0.30][4581-2-2-0.50][4708-3-2-0.99][4708-3-2-0.89][4708-3-2-0.83][4838-3-2--0.28][4838-3-2-0.98][4838-3-0--0.12][4845-1-1-0.41]
[4845-1-1-0.57][4845-1-1-0.49][4868-0-0-0.99][4868-0-0-0.99][4868-0-0-0.99][4939-0-3--0.31][4939-0-1-0.36][4939-0-1-0.31][4984-2-2-0.99][4984-2-2-0.99]
[4984-2-2-0.97][5078-1-1-0.23][5078-1-2-0.84][5078-1-2-0.95][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-2-0.21][5479-1-2-0.53][5479-1-2-0.66]
[5717-0-0-0.10][5717-0-0-0.97][5717-0-1-0.46][5843-1-1-0.77][5843-1-2--0.25][5843-1-1-0.19][5949-3-3-0.51][5949-3-3-0.58][5949-3-0-0.84][5987-2-2--0.49]
[5987-2-1-0.45][5987-2-1-0.19][6014-3-3-0.94][6014-3-3--0.01][6014-3-3-0.93][6033-3-0-0.08][6033-3-1--0.39][6033-3-0-0.74][6313-0-0-0.82][6313-0-0-0.34]
[6313-0-0-0.19][6421-3-3-0.99][6421-3-3-0.81][6421-3-3-0.23][6500-1-2--0.68][6500-1-2--0.89][6500-1-2--0.83][6583-3-2-0.92][6583-3-2-0.69][6583-3-2-0.36]
[6683-3-3-0.99][6683-3-3-0.99][6683-3-3-0.99][6825-2-3-0.96][6825-2-3-0.81][6825-2-3-0.87][6998-3-3--0.44][6998-3-3-0.17][6998-3-0-0.47][7049-3-3--0.24]
[7049-3-3-0.11][7049-3-3--0.17][7517-1-1-0.98][7517-1-1-0.99][7517-1-1-0.99][7521-1-0-0.99][7521-1-0-0.99][7521-1-0-0.99][7528-1-1-0.02][7528-1-1--0.49]
[7528-1-2-0.39][7949-1-1-0.64][7949-1-1-0.45][7949-1-1-0.46][8135-1-0-0.99][8135-1-0-0.99][8135-1-0-0.99][8185-3-0-0.99][8185-3-0-0.90][8185-3-0-0.99]
[8269-3-2-0.30][8269-3-2--0.04][8269-3-1-0.45][8273-3-3-0.97][8273-3-3-0.98][8273-3-3-0.93][8543-3-0-0.55][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.74]
[8666-1-1-0.96][8666-1-1-0.95][8672-0-0-0.15][8672-0-0-0.69][8672-0-3-0.05][8903-1-1-0.38][8903-1-2-0.55][8903-1-2-0.67][9001-2-0-0.59][9001-2-1-0.99]
[9001-2-1-0.99][9036-2-2-0.95][9036-2-2-0.95][9036-2-1-0.75][9281-3-1--0.26][9281-3-2--0.65][9281-3-0-0.13][9300-2-2-0.83][9300-2-2-0.92][9300-2-2--0.18]
[9571-0-3--0.10][9571-0-3-0.04][9571-0-0--0.16][9617-1-1-0.70][9617-1-1-0.20][9617-1-1-0.22][9644-2-2-0.99][9644-2-2-0.99][9644-2-2-0.99][9705-2-0-0.01]
[9705-2-0--0.46][9705-2-0--0.77][9801-0-3-0.96][9801-0-3-0.46][9801-0-3-0.99][9803-3-3-0.76][9803-3-3-0.95][9803-3-3-0.99][9865-3-0-0.24][9865-3-3-0.67]
[9865-3-3-0.94][9896-2-2-0.06][9896-2-2-0.42][9896-2-2-0.76][10314-1-0-0.56][10314-1-0-0.63][10314-1-0-0.91][10337-3-3-0.99][10337-3-3-0.79][10337-3-3-0.66]
[10403-0-0-0.24][10403-0-2-0.41][10403-0-0-0.60][10653-2-1--0.39][10653-2-1--0.17][10653-2-1-0.43][10704-2-3-0.61][10704-2-3--0.21][10704-2-3-0.36][10719-1-1-0.61]
[10719-1-1-0.82][10719-1-1-0.91][10727-1-1-0.17][10727-1-1-0.37][10727-1-1-0.55][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-3--0.26][10969-2-3--0.20]
[10969-2-3--0.21][11042-0-0-0.95][11042-0-0-0.43][11042-0-0-0.99][11088-1-1-0.99][11088-1-1-0.99][11088-1-1-0.99][11322-0-0-0.99][11322-0-0-0.62][11322-0-0-0.56]
[11398-2-2-0.99][11398-2-2-0.52][11398-2-0-0.66][11499-0-0-0.69][11499-0-0-0.93][11499-0-0-0.65][11502-3-0-0.35][11502-3-2-0.04][11502-3-0--0.43][11512-3-3-0.99]
[11512-3-3-0.99][11512-3-3-0.43][11608-1-1-0.99][11608-1-1-0.99][11608-1-1-0.85][11610-0-3-0.65][11610-0-0-0.99][11610-0-0-0.99][11692-0-0-0.99][11692-0-0-0.99]
[11692-0-0-0.60][11905-0-0-0.94][11905-0-0-0.99][11905-0-0-0.83][11993-1-1-0.92][11993-1-1-0.79][11993-1-2-0.22][12002-2-3-0.98][12002-2-2--0.02][12002-2-3-0.78]
[12052-0-0-0.63][12052-0-0-0.99][12052-0-0-0.99][12201-0-3-0.99][12201-0-3-0.96][12201-0-3-0.95][12235-2-2-0.92][12235-2-1-0.37][12235-2-2-0.86][12320-1-0-0.99]
[12320-1-0-0.99][12320-1-0-0.99][12377-2-1-0.80][12377-2-1-0.07][12377-2-2-0.12][12398-2-2--0.03][12398-2-2-0.25][12398-2-2-0.19][12503-1-2--0.28][12503-1-2-0.42]
[12503-1-1-0.83][12617-0-1-0.99][12617-0-1-0.90][12617-0-1-0.84][12685-3-2--0.20][12685-3-1--0.72][12685-3-3-0.35][12738-2-2-0.46][12738-2-3--0.12][12738-2-0-0.05]
[12742-2-2-0.99][12742-2-2-0.97][12742-2-2-0.99][12823-0-0-0.39][12823-0-0--0.26][12823-0-0-0.28][13110-1-1-0.54][13110-1-3-0.08][13110-1-3--0.16][13240-3-3-0.99]
[13240-3-3-0.83][13240-3-3-0.91][13253-1-1-0.98][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-3--0.13][13634-1-3--0.22]
[13634-1-2--0.22][13763-2-2-0.19][13763-2-2-0.97][13763-2-2-0.04][13905-3-3--0.23][13905-3-3--0.23][13905-3-3--0.10][14060-2-1-0.74][14060-2-1-0.99][14060-2-1-0.49]
[14065-3-0--0.06][14065-3-0-0.94][14065-3-3--0.41][14147-3-3-0.20][14147-3-3-0.88][14147-3-0-0.64][14595-2-2-0.10][14595-2-2-0.96][14595-2-2-0.21][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.99][14788-2-2-0.99][14788-2-2-0.99][14788-2-2-0.77][14869-1-1-0.54][14869-1-1-0.59][14869-1-1-0.60][14872-3-0-0.79][14872-3-0-0.73]
[14872-3-0-0.42][14877-1-1-0.96][14877-1-1-0.99][14877-1-1-0.99][14927-0-0-0.58][14927-0-0-0.55][14927-0-3-0.58][15066-0-0-0.89][15066-0-0-0.54][15066-0-0-0.99]
[15175-1-1-0.18][15175-1-1-0.17][15175-1-1-0.28][15178-2-3-0.45][15178-2-3-0.98][15178-2-3-0.99][15375-3-0-0.48][15375-3-3-0.12][15375-3-1--0.60][15389-3-3-0.68]
[15389-3-2--0.12][15389-3-3-0.52][15568-2-1-0.76][15568-2-1-0.63][15568-2-1-0.96][15675-3-3-0.99][15675-3-3-0.99][15675-3-3-0.99][15869-1-2--0.57][15869-1-1--0.04]
[15869-1-3-0.66][16207-3-0-0.99][16207-3-0-0.94][16207-3-0-0.90][16236-0-0--0.14][16236-0-0-0.30][16236-0-0--0.17][16302-3-0-0.61][16302-3-3-0.27][16302-3-3-0.99]
[16331-2-2-0.67][16331-2-2-0.98][16331-2-2-0.89][16381-0-3-0.51][16381-0-3-0.99][16381-0-3-0.79][16488-1-1-0.95][16488-1-1-0.93][16488-1-1-0.23][16495-0-0-0.54]
[16495-0-0-0.99][16495-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-2-0.70][16719-1-2-0.99][16719-1-2-0.99][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.75][16828-0-0-0.49][16828-0-0-0.25][17137-3-1-0.40][17137-3-3-0.76][17137-3-1-0.33][17245-1-3-0.02][17245-1-2-0.26][17245-1-3--0.02]
[17278-3-0-0.22][17278-3-2--0.06][17278-3-0-0.73][17282-0-0-0.01][17282-0-2-0.58][17282-0-3--0.44][17311-2-2-0.94][17311-2-2-0.99][17311-2-2-0.99][17336-2-2--0.29]
[17336-2-1-0.18][17336-2-1-0.33][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-0-0.70][17627-0-0--0.25][17627-0-0-0.05][17877-3-1-0.26][17877-3-0-0.05]
[17877-3-0-0.40][17924-1-1--0.15][17924-1-1-0.59][17924-1-1--0.28][17984-3-3-0.99][17984-3-0-0.76][17984-3-3-0.80][18211-0-1--0.13][18211-0-1-0.25][18211-0-1-0.23]
[18276-3-3-0.48][18276-3-3-0.28][18276-3-3-0.99][18287-1-1-0.28][18287-1-1-0.99][18287-1-1-0.49][18394-0-0-0.99][18394-0-0-0.99][18394-0-0-0.96][18428-0-0-0.52]
[18428-0-0-0.36][18428-0-0-0.99][18442-0-3-0.99][18442-0-3-0.99][18442-0-3-0.99][18478-3-3-0.83][18478-3-3-0.73][18478-3-3-0.88][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-0-0.36][18616-0-0-0.75][18616-0-0-0.48][18663-0-0-0.95][18663-0-0-0.96][18663-0-0-0.79][18718-0-0-0.96][18718-0-0-0.99][18718-0-3-0.99]
[18766-2-3-0.21][18766-2-3-0.03][18766-2-3-0.49][18824-2-2-0.81][18824-2-1-0.49][18824-2-1-0.91][18890-3-3-0.57][18890-3-3-0.76][18890-3-3-0.64][18930-3-2-0.41]
[18930-3-2--0.00][18930-3-2-0.67][18938-3-0-0.06][18938-3-2-0.30][18938-3-0--0.54][19817-1-2-0.99][19817-1-2-0.99][19817-1-2-0.99][19839-0-0-0.94][19839-0-0-0.57]
[19839-0-0-0.84][19930-3-0-0.66][19930-3-3-0.33][19930-3-3-0.39][19944-0-0-0.43][19944-0-2-0.67][19944-0-2-0.44][20036-2-2-0.96][20036-2-2-0.89][20036-2-2-0.95]
[20101-3-1--0.44][20101-3-3-0.81][20101-3-3-0.50][20474-1-2-0.70][20474-1-2-0.60][20474-1-2-0.44][20547-3-0-0.47][20547-3-0-0.06][20547-3-0-0.10][20929-2-2-0.92]
[20929-2-2-0.99][20929-2-2-0.88][21245-1-1-0.99][21245-1-1-0.10][21245-1-1-0.96][21257-3-3-0.93][21257-3-0-0.63][21257-3-1-0.66][21293-1-1-0.50][21293-1-1-0.40]
[21293-1-1-0.54][21316-1-1-0.88][21316-1-1-0.99][21316-1-3--0.24][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-2--0.32][21448-1-1-0.60][21448-1-1--0.03]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-2-0.94][21487-2-2-0.87][21487-2-2-0.75][21714-0-0-0.16][21714-0-0-0.34][21714-0-0-0.42][21943-3-2-0.68]
[21943-3-2-0.52][21943-3-1-0.92][21947-0-0-0.92][21947-0-0-0.66][21947-0-0-0.49][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21965-2-2-0.99]
[21965-2-1--0.03][21998-1-1-0.31][21998-1-1-0.38][21998-1-1-0.87][22025-0-2--0.28][22025-0-2--0.29][22025-0-2--0.26][22228-3-3-0.84][22228-3-3-0.74][22228-3-3-0.73]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-3-0.74][22494-3-3-0.97][22494-3-3-0.99][22757-0-0-0.94][22757-0-3-0.94][22757-0-0-0.78][22811-3-3-0.49]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-2--0.10][22976-3-1-0.34][22976-3-1-0.99][22985-3-3-0.73][22985-3-3-0.39][22985-3-3-0.68][23014-0-3-0.47][23014-0-3-0.47]
[23014-0-3-0.99][23112-1-1-0.85][23112-1-2-0.70][23112-1-2-0.86][23144-3-3-0.99][23144-3-3-0.99][23144-3-3-0.13][23168-2-0-0.28][23168-2-0--0.40][23168-2-2-0.83]
[23219-0-0--0.54][23219-0-0-0.52][23219-0-0-0.71][23363-3-3--0.08][23363-3-3-0.68][23363-3-3-0.98][23470-0-0-0.40][23470-0-0-0.19][23470-0-3--0.21][23486-2-2-0.15]
[23486-2-2--0.12][23486-2-2--0.69][23497-0-3-0.99][23497-0-3-0.99][23497-0-3-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-2--0.54][23690-1-2-0.86]
[23690-1-2-0.99][23921-2-1-0.92][23921-2-2-0.48][23921-2-2-0.69][23936-1-2-0.95][23936-1-2-0.85][23936-1-2-0.99][24040-3-0-0.93][24040-3-0-0.62][24040-3-0-0.56]
[24111-1-1-0.94][24111-1-1-0.96][24111-1-1-0.99][24182-0-0-0.99][24182-0-0-0.96][24182-0-0-0.99][24238-3-0-0.99][24238-3-0-0.99][24238-3-0-0.99][24290-2-0-0.99]
[24290-2-0-0.93][24290-2-0-0.97][24345-0-0-0.54][24345-0-3--0.32][24345-0-0-0.65][24364-1-2-0.87][24364-1-2-0.99][24364-1-2-0.99][24427-3-0-0.99][24427-3-0-0.91]
[24427-3-0-0.99][24477-2-2-0.88][24477-2-2-0.99][24477-2-2-0.34][24495-2-1-0.58][24495-2-1-0.37][24495-2-1-0.15][24893-2-1--0.71][24893-2-2--0.43][24893-2-1--0.43]
[25012-1-1-0.70][25012-1-1-0.29][25012-1-2-0.35][25121-2-0-0.99][25121-2-0-0.99][25121-2-0-0.99][25165-3-3-0.99][25165-3-3-0.99][25165-3-3-0.99][25183-0-0-0.99]
[25183-0-0-0.99][25183-0-0-0.99][25297-3-3-0.99][25297-3-3-0.94][25297-3-3-0.97][25398-0-0-0.47][25398-0-0-0.96][25398-0-0-0.91][25574-2-2-0.99][25574-2-2-0.08]
[25574-2-2-0.09][25644-1-1-0.99][25644-1-1-0.99][25644-1-1-0.57][25718-1-1-0.76][25718-1-1-0.30][25718-1-2--0.05][25774-2-2-0.99][25774-2-2-0.41][25774-2-2-0.93]
[26032-3-3-0.99][26032-3-3-0.99][26032-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26051-3-3-0.94][26120-0-0-0.76][26120-0-0-0.99][26120-0-0-0.99][26321-1-1-0.24]
[26321-1-1-0.40][26321-1-0-0.19][26732-1-1-0.94][26732-1-1-0.99][26732-1-1-0.95][26784-3-3-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-2--0.44][26827-3-3--0.55]
[26827-3-2-0.03][26833-0-3-0.44][26833-0-3-0.99][26833-0-3-0.99][26838-2-1-0.09][26838-2-2--0.14][26838-2-2--0.28][26860-1-0-0.15][26860-1-2-0.30][26860-1-3-0.19]
[26948-0-0-0.76][26948-0-0-0.73][26948-0-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-1--0.32][27098-1-0--0.29][27098-1-3-0.70][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.30][27639-3-3-0.72][27639-3-3-0.54][27639-3-3-0.91][27698-3-3-0.88][27698-3-3-0.99][27698-3-3-0.99][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0-0.61][27890-1-1-0.73][27890-1-1-0.31][27890-1-1-0.81][28040-0-2--0.15][28040-0-0-0.61][28040-0-0-0.99][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-1-0.98][28577-1-1-0.97][28577-1-1-0.99][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-2--0.55][29198-3-1--0.56][29198-3-2--0.64][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-2-0.09][29877-2-1-0.07][29877-2-1-0.24][30035-1-1-0.20][30035-1-2-0.72][30035-1-1-0.94][30098-0-3-0.99][30098-0-3-0.61]
[30098-0-1-0.65][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-3-0.99][30572-2-3-0.99][30572-2-2-0.99][30716-0-1-0.88][30716-0-1-0.99][30716-0-1-0.98]
[30806-2-2-0.48][30806-2-2-0.19][30806-2-2--0.02][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.78][31007-0-0-0.81][31007-0-0-0.99][31007-0-0-0.64][31181-3-0--0.49]
[31181-3-2--0.63][31181-3-2--0.64][31238-0-3-0.70][31238-0-3-0.38][31238-0-3-0.52][31347-0-0-0.98][31347-0-0-0.74][31347-0-0-0.56][31422-2-0-0.41][31422-2-0-0.32]
[31422-2-0-0.74][31429-3-3-0.18][31429-3-3--0.19][31429-3-3-0.82][31431-0-0--0.47][31431-0-0-0.03][31431-0-0-0.31][31432-1-1-0.72][31432-1-1-0.85][31432-1-1-0.73]
[31477-0-0-0.96][31477-0-0-0.88][31477-0-0-0.83][31524-1-3-0.99][31524-1-2-0.28][31524-1-0--0.20][31597-1-2-0.03][31597-1-2-0.99][31597-1-2--0.10][31619-1-2-0.88]
[31619-1-2-0.99][31619-1-2-0.99][31701-0-0-0.99][31701-0-0-0.83][31701-0-0-0.40][31755-0-0-0.99][31755-0-0-0.99][31755-0-0-0.99][31854-3-0-0.15][31854-3-3-0.26]
[31854-3-3--0.52][32074-1-2-0.16][32074-1-2-0.06][32074-1-0--0.07][32078-3-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32111-1-1--0.15][32111-1-1-0.59][32111-1-1-0.99]
[32127-1-1-0.22][32127-1-2-0.04][32127-1-2-0.44][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-1--0.50][32263-2-2--0.62][32263-2-1--0.65][32365-0-0-0.89]
[32365-0-0-0.67][32365-0-0-0.99][32411-2-0-0.98][32411-2-0-0.85][32411-2-0-0.99][32429-3-0-0.62][32429-3-0-0.92][32429-3-0-0.44][32473-3-3-0.83][32473-3-3-0.61]
[32473-3-3-0.61][32574-3-3-0.96][32574-3-3-0.99][32574-3-3-0.99][32584-0-3-0.03][32584-0-3--0.13][32584-0-3--0.26][32622-0-0--0.05][32622-0-0-0.89][32622-0-2-0.63]
[32858-3-0-0.99][32858-3-0-0.99][32858-3-0-0.99][32969-3-2-0.76][32969-3-2-0.99][32969-3-2-0.93][33016-2-2-0.99][33016-2-2-0.99][33016-2-2-0.99][33031-1-1--0.06]
[33031-1-1-0.27][33031-1-1-0.64][33035-2-2-0.97][33035-2-2-0.99][33035-2-2-0.99][33133-2-1-0.99][33133-2-1-0.71][33133-2-1-0.74][33173-2-1-0.30][33173-2-1-0.17]
[33173-2-1-0.90][33175-3-1-0.99][33175-3-1-0.98][33175-3-1-0.99][33306-3-3-0.99][33306-3-3-0.99][33306-3-3-0.99][33309-2-3-0.20][33309-2-3-0.58][33309-2-3--0.49]
[33474-0-0-0.25][33474-0-0-0.11][33474-0-0-0.99][33478-2-0--0.05][33478-2-0--0.03][33478-2-0--0.42][33618-1-1-0.99][33618-1-1-0.99][33618-1-1-0.99][33712-0-0--0.07]
[33712-0-0-0.88][33712-0-0-0.72][33782-2-1-0.40][33782-2-1-0.64][33782-2-2-0.32][33914-3-3-0.73][33914-3-3-0.16][33914-3-3-0.15][34076-3-2-0.34][34076-3-2-0.56]
[34076-3-2--0.05][34112-2-1--0.40][34112-2-1-0.02][34112-2-1-0.26][34138-2-2-0.94][34138-2-2-0.95][34138-2-2-0.97][34239-1-3--0.14][34239-1-2--0.68][34239-1-3--0.89]
[34364-2-1-0.94][34364-2-2-0.53][34364-2-2-0.90][34617-1-2--0.23][34617-1-1-0.80][34617-1-2-0.35][34751-3-3-0.68][34751-3-3-0.79][34751-3-3-0.46][34783-2-2--0.38]
[34783-2-2-0.63][34783-2-1--0.00][35015-3-3-0.99][35015-3-3-0.99][35015-3-3-0.99][35018-1-2-0.41][35018-1-1-0.67][35018-1-2-0.31][35288-2-3-0.79][35288-2-2-0.68]
[35288-2-2-0.12]
---------------------------
I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.445 | Acc: 96.750% | Wgt Acc: 96.684%
	I - Batch: 100 | Loss: 0.440 | Acc: 97.312% | Wgt Acc: 97.274%
	I - Batch: 150 | Loss: 0.438 | Acc: 97.500% | Wgt Acc: 97.495%
	I - Batch: 200 | Loss: 0.437 | Acc: 97.469% | Wgt Acc: 97.480%
	I - Batch: 250 | Loss: 0.436 | Acc: 97.525% | Wgt Acc: 97.539%
	I - Batch: 300 | Loss: 0.437 | Acc: 97.583% | Wgt Acc: 97.589%
	I - Batch: 350 | Loss: 0.440 | Acc: 97.446% | Wgt Acc: 97.454%
	I - Batch: 400 | Loss: 0.440 | Acc: 97.359% | Wgt Acc: 97.370%
	I - Batch: 450 | Loss: 0.441 | Acc: 97.264% | Wgt Acc: 97.274%
I - num batch: 478
I - Train -- Loss: 0.441 | Acc: 97.278% | Wgt Acc: 97.287% | LR: 5.000000e-04 | Dur: 280.44s
I - Confusion Matrix: [row->prediction - col->label]
[[2012.    4.   18.   38.]
 [  22. 1718.   16.   15.]
 [  19.   12. 2161.   19.]
 [  38.    0.    7. 1542.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.085 | Acc: 58.000% | Wgt Acc: 56.996%
I - num batch: 62
I - Val -- Loss: 1.090 | Acc: 57.900% | Wgt Acc: 56.907% | Dur: 33.61s
I - Confusion Matrix: [row->prediction - col->label]
[[192.  24.  24.  60.]
 [ 14. 114.  44.  17.]
 [ 20.  85. 135.  54.]
 [ 38.  11.  22. 127.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.422 | Acc: 97.250% | Wgt Acc: 97.215%
	I - Batch: 100 | Loss: 0.416 | Acc: 97.938% | Wgt Acc: 97.915%
	I - Batch: 150 | Loss: 0.411 | Acc: 98.208% | Wgt Acc: 98.188%
	I - Batch: 200 | Loss: 0.407 | Acc: 98.469% | Wgt Acc: 98.459%
	I - Batch: 250 | Loss: 0.407 | Acc: 98.500% | Wgt Acc: 98.474%
	I - Batch: 300 | Loss: 0.407 | Acc: 98.521% | Wgt Acc: 98.490%
	I - Batch: 350 | Loss: 0.405 | Acc: 98.643% | Wgt Acc: 98.613%
	I - Batch: 400 | Loss: 0.406 | Acc: 98.641% | Wgt Acc: 98.605%
	I - Batch: 450 | Loss: 0.406 | Acc: 98.653% | Wgt Acc: 98.619%
I - num batch: 478
I - Train -- Loss: 0.405 | Acc: 98.639% | Wgt Acc: 98.602% | LR: 2.500000e-04 | Dur: 277.42s
I - Confusion Matrix: [row->prediction - col->label]
[[2064.    1.    9.   27.]
 [   8. 1727.    8.   12.]
 [   5.    6. 2183.   12.]
 [  14.    0.    2. 1563.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.040 | Acc: 61.500% | Wgt Acc: 61.299%
I - num batch: 62
I - Val -- Loss: 1.041 | Acc: 60.245% | Wgt Acc: 60.168% | Dur: 31.28s
I - Confusion Matrix: [row->prediction - col->label]
[[191.  23.  23.  60.]
 [ 16. 137.  64.  19.]
 [  9.  57. 107.  23.]
 [ 48.  17.  31. 156.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.394 | Acc: 98.500% | Wgt Acc: 98.494%
	I - Batch: 100 | Loss: 0.394 | Acc: 98.812% | Wgt Acc: 98.841%
	I - Batch: 150 | Loss: 0.395 | Acc: 98.917% | Wgt Acc: 98.947%
	I - Batch: 200 | Loss: 0.395 | Acc: 99.000% | Wgt Acc: 99.035%
	I - Batch: 250 | Loss: 0.395 | Acc: 98.900% | Wgt Acc: 98.924%
	I - Batch: 300 | Loss: 0.395 | Acc: 98.875% | Wgt Acc: 98.891%
	I - Batch: 350 | Loss: 0.397 | Acc: 98.804% | Wgt Acc: 98.805%
	I - Batch: 400 | Loss: 0.397 | Acc: 98.781% | Wgt Acc: 98.776%
	I - Batch: 450 | Loss: 0.397 | Acc: 98.806% | Wgt Acc: 98.802%
I - num batch: 478
I - Train -- Loss: 0.397 | Acc: 98.822% | Wgt Acc: 98.820% | LR: 2.500000e-04 | Dur: 280.48s
I - Confusion Matrix: [row->prediction - col->label]
[[2058.    3.    7.   20.]
 [   8. 1727.    8.    5.]
 [  13.    4. 2185.    8.]
 [  12.    0.    2. 1581.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.046 | Acc: 61.125% | Wgt Acc: 60.272%
I - num batch: 62
I - Val -- Loss: 1.038 | Acc: 60.856% | Wgt Acc: 60.168% | Dur: 33.24s
I - Confusion Matrix: [row->prediction - col->label]
[[216.  24.  24.  69.]
 [ 15. 126.  48.  20.]
 [  8.  70. 112.  26.]
 [ 25.  14.  41. 143.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.398 | Acc: 98.875% | Wgt Acc: 98.901%
	I - Batch: 100 | Loss: 0.394 | Acc: 99.188% | Wgt Acc: 99.209%
	I - Batch: 150 | Loss: 0.392 | Acc: 99.292% | Wgt Acc: 99.296%
	I - Batch: 200 | Loss: 0.390 | Acc: 99.344% | Wgt Acc: 99.345%
	I - Batch: 250 | Loss: 0.390 | Acc: 99.275% | Wgt Acc: 99.273%
	I - Batch: 300 | Loss: 0.390 | Acc: 99.250% | Wgt Acc: 99.249%
	I - Batch: 350 | Loss: 0.391 | Acc: 99.196% | Wgt Acc: 99.187%
	I - Batch: 400 | Loss: 0.391 | Acc: 99.141% | Wgt Acc: 99.134%
	I - Batch: 450 | Loss: 0.391 | Acc: 99.139% | Wgt Acc: 99.133%
I - num batch: 478
I - Train -- Loss: 0.391 | Acc: 99.136% | Wgt Acc: 99.130% | LR: 2.500000e-04 | Dur: 262.71s
I - Confusion Matrix: [row->prediction - col->label]
[[2066.    0.    3.   18.]
 [   8. 1731.    4.    6.]
 [  10.    3. 2192.    4.]
 [   7.    0.    3. 1586.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.040 | Acc: 59.375% | Wgt Acc: 58.495%
I - num batch: 62
I - Val -- Loss: 1.029 | Acc: 60.347% | Wgt Acc: 59.511% | Dur: 34.03s
I - Confusion Matrix: [row->prediction - col->label]
[[213.  27.  29.  81.]
 [ 10. 122.  47.  13.]
 [  3.  75. 119.  26.]
 [ 38.  10.  30. 138.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.389 | Acc: 99.125% | Wgt Acc: 99.040%
	I - Batch: 100 | Loss: 0.388 | Acc: 99.312% | Wgt Acc: 99.269%
	I - Batch: 150 | Loss: 0.387 | Acc: 99.375% | Wgt Acc: 99.345%
	I - Batch: 200 | Loss: 0.384 | Acc: 99.344% | Wgt Acc: 99.312%
	I - Batch: 250 | Loss: 0.383 | Acc: 99.400% | Wgt Acc: 99.381%
	I - Batch: 300 | Loss: 0.384 | Acc: 99.396% | Wgt Acc: 99.381%
	I - Batch: 350 | Loss: 0.383 | Acc: 99.411% | Wgt Acc: 99.405%
	I - Batch: 400 | Loss: 0.385 | Acc: 99.359% | Wgt Acc: 99.363%
	I - Batch: 450 | Loss: 0.385 | Acc: 99.347% | Wgt Acc: 99.349%
I - num batch: 478
I - Train -- Loss: 0.387 | Acc: 99.306% | Wgt Acc: 99.313% | LR: 2.500000e-04 | Dur: 328.87s
I - Confusion Matrix: [row->prediction - col->label]
[[2067.    1.    5.   10.]
 [   6. 1731.    2.    2.]
 [   8.    1. 2194.    6.]
 [  10.    1.    1. 1596.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.076 | Acc: 59.375% | Wgt Acc: 57.301%
I - num batch: 62
I - Val -- Loss: 1.069 | Acc: 59.837% | Wgt Acc: 57.858% | Dur: 34.59s
I - Confusion Matrix: [row->prediction - col->label]
[[218.  23.  19.  79.]
 [  8.  85.  25.   9.]
 [  9. 119. 162.  48.]
 [ 29.   7.  19. 122.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.392 | Acc: 99.000% | Wgt Acc: 98.962%
	I - Batch: 100 | Loss: 0.390 | Acc: 99.000% | Wgt Acc: 98.989%
	I - Batch: 150 | Loss: 0.389 | Acc: 99.125% | Wgt Acc: 99.120%
	I - Batch: 200 | Loss: 0.390 | Acc: 99.125% | Wgt Acc: 99.128%
	I - Batch: 250 | Loss: 0.388 | Acc: 99.250% | Wgt Acc: 99.252%
	I - Batch: 300 | Loss: 0.388 | Acc: 99.167% | Wgt Acc: 99.170%
	I - Batch: 350 | Loss: 0.388 | Acc: 99.161% | Wgt Acc: 99.168%
	I - Batch: 400 | Loss: 0.388 | Acc: 99.188% | Wgt Acc: 99.194%
	I - Batch: 450 | Loss: 0.388 | Acc: 99.222% | Wgt Acc: 99.230%
I - num batch: 478
I - Train -- Loss: 0.388 | Acc: 99.254% | Wgt Acc: 99.263% | LR: 2.500000e-04 | Dur: 327.89s
I - Confusion Matrix: [row->prediction - col->label]
[[2065.    0.    7.   14.]
 [   9. 1733.    2.    1.]
 [   6.    1. 2193.    6.]
 [  11.    0.    0. 1593.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.026 | Acc: 62.000% | Wgt Acc: 61.327%
I - num batch: 62
I - Val -- Loss: 1.026 | Acc: 62.283% | Wgt Acc: 61.775% | Dur: 34.40s
I - Confusion Matrix: [row->prediction - col->label]
[[191.  20.  19.  52.]
 [ 14. 120.  40.  15.]
 [ 11.  81. 136.  27.]
 [ 48.  13.  30. 164.]]

I - Local maximum validation set accuracy:  62.28

I - Validation set results: 
[14-1-3-0.25][14-1-1--0.09][14-1-1-0.45][50-3-1--0.22][50-3-2--0.24][50-3-2--0.44][124-2-2--0.39][124-2-2-0.95][124-2-2-0.48][127-0-0-0.98]
[127-0-0-0.98][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.75][567-0-0-0.49][573-1-1--0.20][573-1-1-0.14]
[573-1-1-0.02][615-0-3-0.74][615-0-3-0.72][615-0-3-0.68][695-1-0-0.42][695-1-2-0.46][695-1-2-0.86][722-3-3-0.99][722-3-3-0.93][722-3-3-0.89]
[826-0-0-0.65][826-0-0-0.92][826-0-0-0.94][878-0-0-0.51][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.77][1103-0-0-0.12][1103-0-0-0.06][1212-3-3-0.99]
[1212-3-3-0.53][1212-3-3-0.25][1368-0-0-0.97][1368-0-0-0.82][1368-0-0-0.86][2181-2-2--0.04][2181-2-2-0.20][2181-2-2-0.19][2476-2-2-0.99][2476-2-2-0.96]
[2476-2-2-0.98][2721-2-2-0.93][2721-2-2-0.96][2721-2-2-0.99][2818-1-2--0.16][2818-1-3-0.47][2818-1-3-0.80][2886-2-1-0.99][2886-2-1-0.99][2886-2-1-0.99]
[3231-2-2-0.87][3231-2-2-0.83][3231-2-2-0.90][3333-2-2--0.65][3333-2-2--0.79][3333-2-2--0.44][3482-2-2-0.21][3482-2-1--0.14][3482-2-1--0.11][3536-3-3-0.38]
[3536-3-3--0.30][3536-3-3-0.19][3625-1-1-0.98][3625-1-1-0.94][3625-1-1-0.88][3909-0-0-0.44][3909-0-0-0.96][3909-0-0-0.99][4035-0-0--0.28][4035-0-0-0.03]
[4035-0-0--0.23][4140-0-0-0.82][4140-0-0-0.31][4140-0-0-0.83][4214-1-3-0.22][4214-1-3-0.48][4214-1-2-0.36][4346-1-0-0.39][4346-1-0--0.81][4346-1-0--0.62]
[4581-2-2-0.05][4581-2-2-0.08][4581-2-2-0.56][4708-3-3-0.57][4708-3-2-0.29][4708-3-2--0.01][4838-3-2--0.16][4838-3-2-0.76][4838-3-0--0.33][4845-1-1-0.38]
[4845-1-1-0.37][4845-1-1-0.27][4868-0-0-0.99][4868-0-0-0.99][4868-0-0-0.93][4939-0-3--0.22][4939-0-1--0.14][4939-0-1--0.27][4984-2-2-0.93][4984-2-2-0.70]
[4984-2-2-0.51][5078-1-2-0.37][5078-1-2-0.97][5078-1-2-0.88][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-2-0.96][5479-1-2-0.99][5479-1-2-0.99]
[5717-0-0-0.43][5717-0-0-0.91][5717-0-1-0.26][5843-1-1-0.74][5843-1-1--0.35][5843-1-2-0.24][5949-3-0-0.08][5949-3-0-0.90][5949-3-0-0.96][5987-2-2-0.65]
[5987-2-2-0.46][5987-2-2-0.41][6014-3-1-0.86][6014-3-1-0.54][6014-3-1-0.71][6033-3-0--0.32][6033-3-3--0.88][6033-3-0-0.25][6313-0-0-0.40][6313-0-0-0.82]
[6313-0-0--0.10][6421-3-3-0.97][6421-3-3-0.75][6421-3-3-0.47][6500-1-2--0.64][6500-1-2--0.79][6500-1-2--0.75][6583-3-2-0.97][6583-3-2-0.76][6583-3-2-0.57]
[6683-3-3-0.86][6683-3-3-0.97][6683-3-3-0.99][6825-2-3-0.61][6825-2-3-0.66][6825-2-3-0.60][6998-3-3--0.17][6998-3-3--0.23][6998-3-0--0.18][7049-3-3--0.13]
[7049-3-3-0.31][7049-3-3-0.27][7517-1-1-0.87][7517-1-1-0.99][7517-1-1-0.99][7521-1-0-0.45][7521-1-0-0.99][7521-1-0-0.29][7528-1-1--0.06][7528-1-3--0.40]
[7528-1-3-0.17][7949-1-1-0.08][7949-1-2-0.38][7949-1-2--0.15][8135-1-0-0.87][8135-1-0-0.99][8135-1-0-0.93][8185-3-0-0.99][8185-3-0-0.99][8185-3-0-0.99]
[8269-3-2-0.26][8269-3-2--0.02][8269-3-1-0.31][8273-3-3-0.99][8273-3-3-0.97][8273-3-3-0.99][8543-3-0-0.66][8543-3-0-0.99][8543-3-0-0.99][8666-1-1-0.07]
[8666-1-1-0.33][8666-1-1-0.24][8672-0-3-0.69][8672-0-3-0.43][8672-0-3-0.46][8903-1-1-0.13][8903-1-1-0.29][8903-1-2-0.51][9001-2-0-0.28][9001-2-2-0.45]
[9001-2-1-0.34][9036-2-2-0.76][9036-2-2-0.77][9036-2-1-0.83][9281-3-0-0.40][9281-3-0--0.29][9281-3-0-0.11][9300-2-2-0.43][9300-2-2-0.63][9300-2-2-0.16]
[9571-0-3--0.17][9571-0-3--0.18][9571-0-3--0.19][9617-1-1-0.18][9617-1-2--0.11][9617-1-1-0.16][9644-2-2-0.99][9644-2-2-0.99][9644-2-2-0.99][9705-2-0--0.62]
[9705-2-2--0.36][9705-2-2--0.48][9801-0-3-0.99][9801-0-3-0.42][9801-0-3-0.99][9803-3-3-0.84][9803-3-3-0.87][9803-3-3-0.94][9865-3-3-0.48][9865-3-3-0.99]
[9865-3-3-0.99][9896-2-2-0.48][9896-2-2-0.34][9896-2-2-0.99][10314-1-0-0.29][10314-1-0-0.58][10314-1-0-0.63][10337-3-3-0.99][10337-3-3-0.37][10337-3-3-0.61]
[10403-0-2--0.11][10403-0-2--0.10][10403-0-0-0.36][10653-2-2--0.01][10653-2-1--0.06][10653-2-1-0.51][10704-2-3-0.99][10704-2-3-0.27][10704-2-3-0.99][10719-1-1-0.73]
[10719-1-1-0.93][10719-1-1-0.99][10727-1-1--0.08][10727-1-2-0.53][10727-1-2-0.21][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-3-0.51][10969-2-3-0.27]
[10969-2-3-0.02][11042-0-0-0.93][11042-0-0-0.55][11042-0-0-0.99][11088-1-1-0.99][11088-1-1-0.99][11088-1-1-0.99][11322-0-0-0.99][11322-0-0-0.44][11322-0-0-0.25]
[11398-2-2-0.90][11398-2-2-0.51][11398-2-0-0.17][11499-0-0-0.60][11499-0-0-0.83][11499-0-0-0.50][11502-3-2-0.14][11502-3-2-0.75][11502-3-2--0.15][11512-3-3-0.99]
[11512-3-3-0.99][11512-3-3-0.52][11608-1-1-0.99][11608-1-1-0.80][11608-1-2-0.85][11610-0-3-0.49][11610-0-0-0.98][11610-0-0-0.66][11692-0-0-0.94][11692-0-0-0.63]
[11692-0-0--0.03][11905-0-0-0.99][11905-0-0-0.99][11905-0-0-0.70][11993-1-2-0.52][11993-1-2-0.65][11993-1-2-0.95][12002-2-3-0.81][12002-2-3--0.04][12002-2-3-0.82]
[12052-0-0-0.46][12052-0-0-0.99][12052-0-0-0.97][12201-0-3-0.98][12201-0-3-0.81][12201-0-3-0.98][12235-2-2-0.96][12235-2-2-0.16][12235-2-2-0.73][12320-1-0-0.99]
[12320-1-0-0.99][12320-1-0-0.99][12377-2-1-0.39][12377-2-2-0.18][12377-2-2-0.43][12398-2-2--0.09][12398-2-2--0.46][12398-2-3--0.59][12503-1-1--0.15][12503-1-1-0.23]
[12503-1-1-0.91][12617-0-1--0.03][12617-0-1--0.35][12617-0-1--0.13][12685-3-1--0.26][12685-3-3--0.23][12685-3-3-0.52][12738-2-2-0.82][12738-2-2-0.11][12738-2-2--0.54]
[12742-2-2-0.91][12742-2-2-0.73][12742-2-2-0.99][12823-0-0-0.85][12823-0-3-0.16][12823-0-0-0.50][13110-1-3--0.51][13110-1-1--0.57][13110-1-2-0.04][13240-3-3-0.99]
[13240-3-3-0.99][13240-3-3-0.99][13253-1-1-0.99][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-2-0.40][13634-1-2-0.48]
[13634-1-2-0.58][13763-2-2-0.29][13763-2-2-0.84][13763-2-2-0.34][13905-3-3--0.05][13905-3-3--0.18][13905-3-2--0.18][14060-2-1-0.45][14060-2-1-0.93][14060-2-1--0.42]
[14065-3-0-0.29][14065-3-0-0.82][14065-3-3--0.66][14147-3-3--0.15][14147-3-3-0.97][14147-3-0-0.48][14595-2-2-0.43][14595-2-2-0.99][14595-2-2-0.54][14687-2-2-0.99]
[14687-2-2-0.99][14687-2-2-0.99][14788-2-2-0.99][14788-2-2-0.99][14788-2-2-0.73][14869-1-1-0.28][14869-1-2-0.20][14869-1-2-0.31][14872-3-0--0.07][14872-3-0--0.21]
[14872-3-0--0.33][14877-1-1-0.98][14877-1-1-0.99][14877-1-1-0.99][14927-0-3-0.88][14927-0-3-0.95][14927-0-3-0.78][15066-0-0-0.81][15066-0-0-0.38][15066-0-0-0.99]
[15175-1-1-0.18][15175-1-1-0.31][15175-1-1-0.61][15178-2-3-0.21][15178-2-3-0.92][15178-2-3-0.99][15375-3-3-0.43][15375-3-3--0.21][15375-3-0--0.41][15389-3-3-0.93]
[15389-3-3-0.52][15389-3-3-0.91][15568-2-1-0.62][15568-2-2--0.03][15568-2-1-0.35][15675-3-3-0.99][15675-3-3-0.99][15675-3-3-0.99][15869-1-1-0.23][15869-1-1-0.07]
[15869-1-3-0.58][16207-3-0-0.95][16207-3-0-0.25][16207-3-0-0.52][16236-0-0-0.44][16236-0-0-0.82][16236-0-2-0.31][16302-3-0-0.15][16302-3-3-0.39][16302-3-3-0.99]
[16331-2-2-0.06][16331-2-2-0.51][16331-2-2-0.23][16381-0-3-0.99][16381-0-3-0.99][16381-0-3-0.69][16488-1-1-0.98][16488-1-1-0.75][16488-1-1-0.02][16495-0-0-0.96]
[16495-0-0-0.99][16495-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-2-0.99][16719-1-2-0.99][16719-1-2-0.99][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.99][16828-0-0-0.69][16828-0-0-0.50][17137-3-3--0.25][17137-3-3-0.50][17137-3-3-0.53][17245-1-2--0.19][17245-1-2-0.21][17245-1-1-0.14]
[17278-3-0-0.06][17278-3-0--0.37][17278-3-0-0.31][17282-0-0-0.29][17282-0-0-0.39][17282-0-0--0.08][17311-2-2-0.99][17311-2-2-0.98][17311-2-2-0.97][17336-2-1--0.29]
[17336-2-1-0.35][17336-2-1-0.58][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-0-0.80][17627-0-1--0.03][17627-0-0-0.05][17877-3-3--0.13][17877-3-0--0.10]
[17877-3-0-0.14][17924-1-1--0.41][17924-1-1-0.59][17924-1-1--0.46][17984-3-3-0.99][17984-3-0-0.74][17984-3-3-0.16][18211-0-1--0.22][18211-0-1-0.29][18211-0-1--0.02]
[18276-3-3-0.78][18276-3-3-0.68][18276-3-3-0.99][18287-1-1-0.50][18287-1-1-0.99][18287-1-1-0.52][18394-0-0-0.99][18394-0-0-0.99][18394-0-0-0.95][18428-0-0-0.04]
[18428-0-3-0.42][18428-0-0-0.99][18442-0-3-0.99][18442-0-3-0.99][18442-0-3-0.99][18478-3-3-0.80][18478-3-3-0.67][18478-3-3-0.75][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-0-0.34][18616-0-0-0.51][18616-0-0-0.66][18663-0-0-0.95][18663-0-0-0.99][18663-0-0-0.60][18718-0-0-0.93][18718-0-0-0.99][18718-0-3-0.84]
[18766-2-1-0.83][18766-2-1--0.11][18766-2-3--0.11][18824-2-2-0.93][18824-2-1-0.43][18824-2-1-0.73][18890-3-3-0.43][18890-3-3-0.75][18890-3-3-0.78][18930-3-2--0.35]
[18930-3-2--0.13][18930-3-2-0.62][18938-3-0--0.30][18938-3-3--0.38][18938-3-3--0.79][19817-1-2-0.85][19817-1-2-0.77][19817-1-2-0.84][19839-0-0-0.24][19839-0-0--0.43]
[19839-0-0--0.11][19930-3-0-0.76][19930-3-3-0.23][19930-3-3-0.43][19944-0-0-0.38][19944-0-2-0.32][19944-0-0-0.14][20036-2-2-0.99][20036-2-2-0.97][20036-2-2-0.98]
[20101-3-1--0.54][20101-3-3-0.71][20101-3-3-0.77][20474-1-2-0.15][20474-1-2-0.49][20474-1-2-0.40][20547-3-1--0.41][20547-3-3-0.34][20547-3-0--0.37][20929-2-2-0.07]
[20929-2-2-0.99][20929-2-2-0.96][21245-1-1-0.79][21245-1-2-0.78][21245-1-1-0.61][21257-3-3-0.95][21257-3-2--0.07][21257-3-1--0.36][21293-1-1-0.64][21293-1-1-0.53]
[21293-1-1-0.75][21316-1-1-0.79][21316-1-1-0.96][21316-1-3--0.32][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1-0.42][21448-1-1-0.78][21448-1-1--0.06]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-2-0.99][21487-2-2-0.99][21487-2-2-0.99][21714-0-3-0.38][21714-0-3--0.34][21714-0-0--0.50][21943-3-2-0.55]
[21943-3-2--0.05][21943-3-1-0.99][21947-0-0-0.96][21947-0-0-0.40][21947-0-0--0.19][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-1-0.76][21965-2-2-0.99]
[21965-2-2--0.27][21998-1-1-0.11][21998-1-1-0.45][21998-1-1-0.88][22025-0-2--0.60][22025-0-2--0.62][22025-0-1--0.39][22228-3-3-0.98][22228-3-3-0.89][22228-3-3-0.93]
[22446-1-1-0.99][22446-1-1-0.99][22446-1-1-0.99][22494-3-3-0.49][22494-3-3-0.60][22494-3-3-0.99][22757-0-3-0.76][22757-0-3-0.97][22757-0-3-0.76][22811-3-3-0.62]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-3-0.28][22976-3-1-0.24][22976-3-1-0.98][22985-3-3-0.87][22985-3-3-0.54][22985-3-3-0.62][23014-0-3-0.34][23014-0-0-0.33]
[23014-0-3-0.99][23112-1-2-0.83][23112-1-2-0.97][23112-1-2-0.92][23144-3-3-0.99][23144-3-3-0.99][23144-3-3-0.76][23168-2-0--0.35][23168-2-0--0.55][23168-2-2--0.02]
[23219-0-0--0.09][23219-0-0-0.69][23219-0-0-0.94][23363-3-3--0.01][23363-3-3-0.70][23363-3-3-0.99][23470-0-0-0.34][23470-0-0-0.03][23470-0-3--0.42][23486-2-3-0.14]
[23486-2-3--0.44][23486-2-3--0.64][23497-0-3-0.99][23497-0-3-0.99][23497-0-3-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-2--0.50][23690-1-2-0.08]
[23690-1-2--0.17][23921-2-1-0.80][23921-2-2-0.58][23921-2-2-0.54][23936-1-2-0.99][23936-1-2-0.90][23936-1-2-0.99][24040-3-0-0.68][24040-3-0-0.33][24040-3-0-0.15]
[24111-1-1-0.70][24111-1-2-0.82][24111-1-2-0.86][24182-0-0-0.99][24182-0-0-0.99][24182-0-0-0.99][24238-3-0-0.91][24238-3-0-0.99][24238-3-0-0.99][24290-2-0-0.99]
[24290-2-0-0.88][24290-2-0-0.84][24345-0-0-0.61][24345-0-2--0.02][24345-0-2-0.65][24364-1-2-0.99][24364-1-2-0.99][24364-1-2-0.99][24427-3-0-0.99][24427-3-0-0.99]
[24427-3-0-0.99][24477-2-2-0.92][24477-2-2-0.90][24477-2-2-0.70][24495-2-1-0.74][24495-2-1-0.25][24495-2-1-0.37][24893-2-2--0.61][24893-2-1--0.12][24893-2-1--0.54]
[25012-1-1-0.70][25012-1-1-0.57][25012-1-2-0.38][25121-2-0-0.97][25121-2-0-0.99][25121-2-0-0.99][25165-3-3-0.99][25165-3-3-0.99][25165-3-3-0.99][25183-0-0-0.96]
[25183-0-0-0.92][25183-0-0-0.92][25297-3-3-0.99][25297-3-3-0.99][25297-3-3-0.99][25398-0-0-0.38][25398-0-0-0.96][25398-0-0-0.92][25574-2-2-0.91][25574-2-2--0.06]
[25574-2-2--0.16][25644-1-1-0.99][25644-1-1-0.99][25644-1-1-0.24][25718-1-2-0.67][25718-1-1--0.36][25718-1-2-0.04][25774-2-2-0.99][25774-2-2-0.53][25774-2-2-0.99]
[26032-3-3-0.99][26032-3-3-0.99][26032-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26120-0-0-0.49][26120-0-0-0.97][26120-0-0-0.99][26321-1-1--0.46]
[26321-1-1--0.17][26321-1-0--0.16][26732-1-1-0.68][26732-1-1-0.49][26732-1-1-0.88][26784-3-3-0.99][26784-3-3-0.99][26784-3-3-0.99][26827-3-3-0.37][26827-3-3-0.39]
[26827-3-3-0.57][26833-0-3--0.13][26833-0-3-0.85][26833-0-0-0.66][26838-2-2-0.37][26838-2-3-0.02][26838-2-3--0.23][26860-1-2-0.39][26860-1-2-0.49][26860-1-3-0.77]
[26948-0-0-0.09][26948-0-0-0.31][26948-0-0-0.99][27049-3-0-0.15][27049-3-0--0.27][27049-3-0-0.67][27098-1-1--0.39][27098-1-1--0.63][27098-1-0-0.49][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.44][27639-3-3--0.43][27639-3-3--0.68][27639-3-3-0.25][27698-3-3-0.73][27698-3-3-0.94][27698-3-3-0.68][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0--0.03][27890-1-1-0.56][27890-1-1-0.22][27890-1-2-0.13][28040-0-2-0.19][28040-0-0-0.53][28040-0-0-0.99][28503-2-2-0.99][28503-2-2-0.99][28503-2-2-0.99]
[28577-1-1-0.62][28577-1-1-0.61][28577-1-1-0.60][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-2--0.43][29198-3-3--0.11][29198-3-3--0.03][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-2--0.03][29877-2-2--0.08][29877-2-1-0.15][30035-1-1-0.41][30035-1-2-0.84][30035-1-1-0.91][30098-0-3-0.99][30098-0-3-0.88]
[30098-0-3-0.85][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.89][30572-2-3-0.95][30572-2-2-0.98][30716-0-1--0.04][30716-0-1-0.41][30716-0-1-0.07]
[30806-2-2-0.11][30806-2-2-0.35][30806-2-2-0.37][30906-1-1-0.99][30906-1-1-0.99][30906-1-1-0.65][31007-0-0-0.20][31007-0-0-0.18][31007-0-0--0.29][31181-3-0--0.81]
[31181-3-2--0.23][31181-3-2--0.67][31238-0-0--0.44][31238-0-0--0.08][31238-0-0-0.19][31347-0-0-0.78][31347-0-0-0.28][31347-0-0-0.64][31422-2-2--0.21][31422-2-0--0.16]
[31422-2-0--0.10][31429-3-3-0.69][31429-3-3-0.35][31429-3-3-0.44][31431-0-0-0.56][31431-0-0-0.47][31431-0-2--0.25][31432-1-1-0.58][31432-1-1-0.94][31432-1-1-0.70]
[31477-0-0-0.80][31477-0-0-0.93][31477-0-0-0.88][31524-1-3-0.76][31524-1-2--0.01][31524-1-0--0.19][31597-1-2-0.45][31597-1-2-0.94][31597-1-3--0.44][31619-1-2-0.99]
[31619-1-2-0.99][31619-1-2-0.99][31701-0-0-0.97][31701-0-0-0.44][31701-0-0--0.00][31755-0-0-0.99][31755-0-0-0.74][31755-0-0-0.48][31854-3-3-0.22][31854-3-3-0.67]
[31854-3-3-0.31][32074-1-2-0.29][32074-1-2-0.40][32074-1-0--0.17][32078-3-3-0.97][32078-3-3-0.99][32078-3-3-0.55][32111-1-2-0.22][32111-1-1-0.68][32111-1-1-0.99]
[32127-1-1-0.74][32127-1-1-0.41][32127-1-1-0.60][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-2--0.55][32263-2-3--0.73][32263-2-2--0.59][32365-0-0-0.91]
[32365-0-0-0.52][32365-0-0-0.99][32411-2-0-0.98][32411-2-0-0.78][32411-2-0-0.99][32429-3-0-0.69][32429-3-0-0.60][32429-3-0-0.64][32473-3-3-0.87][32473-3-3-0.74]
[32473-3-3-0.78][32574-3-3-0.99][32574-3-3-0.99][32574-3-3-0.99][32584-0-3-0.56][32584-0-3-0.45][32584-0-3-0.26][32622-0-0-0.83][32622-0-0-0.99][32622-0-0-0.96]
[32858-3-3-0.75][32858-3-3-0.88][32858-3-3-0.87][32969-3-2--0.85][32969-3-2--0.78][32969-3-2--0.45][33016-2-2-0.99][33016-2-1-0.50][33016-2-1-0.41][33031-1-1--0.31]
[33031-1-1--0.12][33031-1-1-0.21][33035-2-2-0.97][33035-2-2-0.91][33035-2-2-0.99][33133-2-2-0.85][33133-2-2-0.75][33133-2-2-0.97][33173-2-1--0.16][33173-2-1--0.19]
[33173-2-1-0.75][33175-3-1-0.15][33175-3-1--0.07][33175-3-1-0.33][33306-3-3-0.91][33306-3-3-0.83][33306-3-3-0.93][33309-2-3-0.81][33309-2-3-0.79][33309-2-3--0.05]
[33474-0-0-0.07][33474-0-0-0.06][33474-0-0-0.99][33478-2-0-0.18][33478-2-0-0.10][33478-2-0--0.03][33618-1-1-0.99][33618-1-1-0.99][33618-1-1-0.99][33712-0-2--0.13]
[33712-0-0-0.73][33712-0-0-0.43][33782-2-1--0.56][33782-2-2--0.45][33782-2-2-0.24][33914-3-3-0.71][33914-3-3-0.77][33914-3-3-0.92][34076-3-3-0.67][34076-3-3--0.00]
[34076-3-3--0.80][34112-2-1--0.52][34112-2-3--0.20][34112-2-3-0.40][34138-2-2-0.94][34138-2-2-0.97][34138-2-2-0.99][34239-1-1--0.34][34239-1-2--0.32][34239-1-1--0.42]
[34364-2-1-0.99][34364-2-1-0.28][34364-2-2-0.82][34617-1-2--0.19][34617-1-1-0.37][34617-1-2-0.17][34751-3-3-0.90][34751-3-3-0.79][34751-3-3-0.42][34783-2-2-0.15]
[34783-2-2-0.77][34783-2-1-0.15][35015-3-3-0.58][35015-3-3-0.60][35015-3-3-0.97][35018-1-2-0.58][35018-1-2-0.71][35018-1-2-0.95][35288-2-3-0.84][35288-2-2-0.90]
[35288-2-2-0.16]
---------------------------
I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.374 | Acc: 99.500% | Wgt Acc: 99.521%
	I - Batch: 100 | Loss: 0.375 | Acc: 99.500% | Wgt Acc: 99.521%
	I - Batch: 150 | Loss: 0.374 | Acc: 99.500% | Wgt Acc: 99.513%
	I - Batch: 200 | Loss: 0.374 | Acc: 99.562% | Wgt Acc: 99.571%
	I - Batch: 250 | Loss: 0.373 | Acc: 99.550% | Wgt Acc: 99.555%
	I - Batch: 300 | Loss: 0.375 | Acc: 99.458% | Wgt Acc: 99.470%
	I - Batch: 350 | Loss: 0.374 | Acc: 99.500% | Wgt Acc: 99.510%
	I - Batch: 400 | Loss: 0.374 | Acc: 99.547% | Wgt Acc: 99.557%
	I - Batch: 450 | Loss: 0.374 | Acc: 99.542% | Wgt Acc: 99.553%
I - num batch: 478
I - Train -- Loss: 0.374 | Acc: 99.555% | Wgt Acc: 99.567% | LR: 1.250000e-04 | Dur: 326.18s
I - Confusion Matrix: [row->prediction - col->label]
[[2074.    0.    3.    6.]
 [   7. 1733.    3.    1.]
 [   3.    1. 2196.    3.]
 [   7.    0.    0. 1604.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.052 | Acc: 60.750% | Wgt Acc: 59.578%
I - num batch: 62
I - Val -- Loss: 1.055 | Acc: 60.245% | Wgt Acc: 59.149% | Dur: 35.41s
I - Confusion Matrix: [row->prediction - col->label]
[[232.  42.  39.  92.]
 [  3. 104.  36.  11.]
 [  1.  71. 111.  11.]
 [ 28.  17.  39. 144.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.369 | Acc: 99.625% | Wgt Acc: 99.605%
	I - Batch: 100 | Loss: 0.368 | Acc: 99.750% | Wgt Acc: 99.732%
	I - Batch: 150 | Loss: 0.370 | Acc: 99.708% | Wgt Acc: 99.710%
	I - Batch: 200 | Loss: 0.371 | Acc: 99.656% | Wgt Acc: 99.655%
	I - Batch: 250 | Loss: 0.371 | Acc: 99.650% | Wgt Acc: 99.657%
	I - Batch: 300 | Loss: 0.370 | Acc: 99.708% | Wgt Acc: 99.714%
	I - Batch: 350 | Loss: 0.369 | Acc: 99.732% | Wgt Acc: 99.735%
	I - Batch: 400 | Loss: 0.369 | Acc: 99.703% | Wgt Acc: 99.708%
	I - Batch: 450 | Loss: 0.369 | Acc: 99.708% | Wgt Acc: 99.709%
I - num batch: 478
I - Train -- Loss: 0.369 | Acc: 99.699% | Wgt Acc: 99.702% | LR: 1.250000e-04 | Dur: 331.60s
I - Confusion Matrix: [row->prediction - col->label]
[[2079.    0.    2.    6.]
 [   4. 1734.    0.    1.]
 [   3.    0. 2200.    2.]
 [   5.    0.    0. 1605.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.036 | Acc: 59.875% | Wgt Acc: 59.078%
I - num batch: 62
I - Val -- Loss: 1.041 | Acc: 59.939% | Wgt Acc: 59.284% | Dur: 35.11s
I - Confusion Matrix: [row->prediction - col->label]
[[215.  25.  36.  80.]
 [  7. 113.  41.  12.]
 [  2.  72. 107.  13.]
 [ 40.  24.  41. 153.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.371 | Acc: 99.375% | Wgt Acc: 99.377%
	I - Batch: 100 | Loss: 0.369 | Acc: 99.625% | Wgt Acc: 99.633%
	I - Batch: 150 | Loss: 0.368 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 200 | Loss: 0.368 | Acc: 99.688% | Wgt Acc: 99.689%
	I - Batch: 250 | Loss: 0.368 | Acc: 99.700% | Wgt Acc: 99.701%
	I - Batch: 300 | Loss: 0.367 | Acc: 99.750% | Wgt Acc: 99.751%
	I - Batch: 350 | Loss: 0.368 | Acc: 99.768% | Wgt Acc: 99.770%
	I - Batch: 400 | Loss: 0.367 | Acc: 99.766% | Wgt Acc: 99.771%
	I - Batch: 450 | Loss: 0.367 | Acc: 99.750% | Wgt Acc: 99.753%
I - num batch: 478
I - Train -- Loss: 0.367 | Acc: 99.751% | Wgt Acc: 99.755% | LR: 1.250000e-04 | Dur: 328.79s
I - Confusion Matrix: [row->prediction - col->label]
[[2081.    0.    1.    4.]
 [   3. 1734.    0.    1.]
 [   3.    0. 2200.    2.]
 [   4.    0.    1. 1607.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.038 | Acc: 60.375% | Wgt Acc: 59.217%
I - num batch: 62
I - Val -- Loss: 1.037 | Acc: 61.162% | Wgt Acc: 60.100% | Dur: 35.40s
I - Confusion Matrix: [row->prediction - col->label]
[[213.  22.  26.  70.]
 [  9. 103.  28.  13.]
 [  5.  98. 133.  24.]
 [ 37.  11.  38. 151.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.364 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.367 | Acc: 99.625% | Wgt Acc: 99.647%
	I - Batch: 150 | Loss: 0.366 | Acc: 99.750% | Wgt Acc: 99.765%
	I - Batch: 200 | Loss: 0.367 | Acc: 99.656% | Wgt Acc: 99.662%
	I - Batch: 250 | Loss: 0.366 | Acc: 99.725% | Wgt Acc: 99.730%
	I - Batch: 300 | Loss: 0.366 | Acc: 99.750% | Wgt Acc: 99.751%
	I - Batch: 350 | Loss: 0.366 | Acc: 99.750% | Wgt Acc: 99.750%
	I - Batch: 400 | Loss: 0.365 | Acc: 99.781% | Wgt Acc: 99.782%
	I - Batch: 450 | Loss: 0.365 | Acc: 99.806% | Wgt Acc: 99.806%
I - num batch: 478
I - Train -- Loss: 0.365 | Acc: 99.804% | Wgt Acc: 99.805% | LR: 1.250000e-04 | Dur: 327.67s
I - Confusion Matrix: [row->prediction - col->label]
[[2082.    0.    0.    4.]
 [   2. 1734.    0.    1.]
 [   3.    0. 2202.    1.]
 [   4.    0.    0. 1608.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.017 | Acc: 62.250% | Wgt Acc: 61.244%
I - num batch: 62
I - Val -- Loss: 1.019 | Acc: 61.978% | Wgt Acc: 61.073% | Dur: 34.37s
I - Confusion Matrix: [row->prediction - col->label]
[[228.  25.  35.  80.]
 [  8. 120.  42.  15.]
 [  1.  81. 115.  18.]
 [ 27.   8.  33. 145.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.363 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.362 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.364 | Acc: 99.875% | Wgt Acc: 99.878%
	I - Batch: 200 | Loss: 0.363 | Acc: 99.906% | Wgt Acc: 99.909%
	I - Batch: 250 | Loss: 0.363 | Acc: 99.900% | Wgt Acc: 99.899%
	I - Batch: 300 | Loss: 0.363 | Acc: 99.896% | Wgt Acc: 99.892%
	I - Batch: 350 | Loss: 0.362 | Acc: 99.911% | Wgt Acc: 99.908%
	I - Batch: 400 | Loss: 0.362 | Acc: 99.891% | Wgt Acc: 99.884%
	I - Batch: 450 | Loss: 0.363 | Acc: 99.861% | Wgt Acc: 99.859%
I - num batch: 478
I - Train -- Loss: 0.363 | Acc: 99.843% | Wgt Acc: 99.841% | LR: 1.250000e-04 | Dur: 328.77s
I - Confusion Matrix: [row->prediction - col->label]
[[2085.    0.    0.    4.]
 [   3. 1734.    0.    0.]
 [   3.    0. 2202.    2.]
 [   0.    0.    0. 1608.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.044 | Acc: 60.875% | Wgt Acc: 59.772%
I - num batch: 62
I - Val -- Loss: 1.046 | Acc: 61.060% | Wgt Acc: 60.054% | Dur: 39.90s
I - Confusion Matrix: [row->prediction - col->label]
[[224.  29.  32.  85.]
 [  5. 113.  34.  13.]
 [  3.  82. 119.  17.]
 [ 32.  10.  40. 143.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.361 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.363 | Acc: 99.938% | Wgt Acc: 99.943%
	I - Batch: 150 | Loss: 0.361 | Acc: 99.958% | Wgt Acc: 99.962%
	I - Batch: 200 | Loss: 0.363 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 250 | Loss: 0.362 | Acc: 99.900% | Wgt Acc: 99.898%
	I - Batch: 300 | Loss: 0.362 | Acc: 99.833% | Wgt Acc: 99.836%
	I - Batch: 350 | Loss: 0.362 | Acc: 99.821% | Wgt Acc: 99.819%
	I - Batch: 400 | Loss: 0.363 | Acc: 99.797% | Wgt Acc: 99.799%
	I - Batch: 450 | Loss: 0.363 | Acc: 99.806% | Wgt Acc: 99.806%
I - num batch: 478
I - Train -- Loss: 0.363 | Acc: 99.817% | Wgt Acc: 99.817% | LR: 1.250000e-04 | Dur: 331.16s
I - Confusion Matrix: [row->prediction - col->label]
[[2083.    0.    0.    4.]
 [   5. 1734.    0.    0.]
 [   2.    0. 2202.    2.]
 [   1.    0.    0. 1608.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.053 | Acc: 60.250% | Wgt Acc: 58.912%
I - num batch: 62
I - Val -- Loss: 1.058 | Acc: 60.347% | Wgt Acc: 59.081% | Dur: 40.14s
I - Confusion Matrix: [row->prediction - col->label]
[[221.  24.  27.  81.]
 [ 12. 107.  35.  17.]
 [  2.  91. 130.  26.]
 [ 29.  12.  33. 134.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.363 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.362 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.361 | Acc: 99.875% | Wgt Acc: 99.869%
	I - Batch: 200 | Loss: 0.361 | Acc: 99.844% | Wgt Acc: 99.838%
	I - Batch: 250 | Loss: 0.362 | Acc: 99.875% | Wgt Acc: 99.870%
	I - Batch: 300 | Loss: 0.362 | Acc: 99.854% | Wgt Acc: 99.854%
	I - Batch: 350 | Loss: 0.362 | Acc: 99.875% | Wgt Acc: 99.875%
	I - Batch: 400 | Loss: 0.361 | Acc: 99.891% | Wgt Acc: 99.891%
	I - Batch: 450 | Loss: 0.362 | Acc: 99.889% | Wgt Acc: 99.890%
I - num batch: 478
I - Train -- Loss: 0.361 | Acc: 99.895% | Wgt Acc: 99.897% | LR: 1.250000e-04 | Dur: 325.59s
I - Confusion Matrix: [row->prediction - col->label]
[[2086.    0.    0.    2.]
 [   3. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   1.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.041 | Acc: 61.875% | Wgt Acc: 60.661%
I - num batch: 62
I - Val -- Loss: 1.047 | Acc: 62.080% | Wgt Acc: 60.892% | Dur: 34.22s
I - Confusion Matrix: [row->prediction - col->label]
[[225.  25.  26.  82.]
 [  7. 117.  32.  14.]
 [  2.  84. 131.  26.]
 [ 30.   8.  36. 136.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.359 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.359 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.358 | Acc: 99.958% | Wgt Acc: 99.962%
	I - Batch: 200 | Loss: 0.359 | Acc: 99.875% | Wgt Acc: 99.880%
	I - Batch: 250 | Loss: 0.359 | Acc: 99.850% | Wgt Acc: 99.854%
	I - Batch: 300 | Loss: 0.360 | Acc: 99.854% | Wgt Acc: 99.854%
	I - Batch: 350 | Loss: 0.360 | Acc: 99.857% | Wgt Acc: 99.859%
	I - Batch: 400 | Loss: 0.360 | Acc: 99.875% | Wgt Acc: 99.877%
	I - Batch: 450 | Loss: 0.360 | Acc: 99.875% | Wgt Acc: 99.878%
I - num batch: 478
I - Train -- Loss: 0.360 | Acc: 99.882% | Wgt Acc: 99.885% | LR: 1.250000e-04 | Dur: 329.56s
I - Confusion Matrix: [row->prediction - col->label]
[[2085.    0.    0.    2.]
 [   3. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   2.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.031 | Acc: 60.250% | Wgt Acc: 59.550%
I - num batch: 62
I - Val -- Loss: 1.036 | Acc: 60.856% | Wgt Acc: 60.258% | Dur: 35.70s
I - Confusion Matrix: [row->prediction - col->label]
[[209.  21.  25.  63.]
 [  4. 111.  37.  14.]
 [  6.  86. 115.  19.]
 [ 45.  16.  48. 162.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.359 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.358 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.358 | Acc: 99.906% | Wgt Acc: 99.901%
	I - Batch: 250 | Loss: 0.358 | Acc: 99.925% | Wgt Acc: 99.921%
	I - Batch: 300 | Loss: 0.359 | Acc: 99.938% | Wgt Acc: 99.934%
	I - Batch: 350 | Loss: 0.360 | Acc: 99.929% | Wgt Acc: 99.927%
	I - Batch: 400 | Loss: 0.360 | Acc: 99.922% | Wgt Acc: 99.922%
	I - Batch: 450 | Loss: 0.360 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 478
I - Train -- Loss: 0.360 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 329.19s
I - Confusion Matrix: [row->prediction - col->label]
[[2088.    0.    0.    2.]
 [   2. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.034 | Acc: 62.125% | Wgt Acc: 61.494%
I - num batch: 62
I - Val -- Loss: 1.039 | Acc: 61.876% | Wgt Acc: 61.368% | Dur: 36.42s
I - Confusion Matrix: [row->prediction - col->label]
[[215.  23.  34.  65.]
 [ 12. 124.  40.  15.]
 [  4.  75. 110.  20.]
 [ 33.  12.  41. 158.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.356 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.357 | Acc: 99.917% | Wgt Acc: 99.916%
	I - Batch: 200 | Loss: 0.357 | Acc: 99.875% | Wgt Acc: 99.881%
	I - Batch: 250 | Loss: 0.357 | Acc: 99.875% | Wgt Acc: 99.876%
	I - Batch: 300 | Loss: 0.357 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 350 | Loss: 0.358 | Acc: 99.839% | Wgt Acc: 99.839%
	I - Batch: 400 | Loss: 0.358 | Acc: 99.859% | Wgt Acc: 99.859%
	I - Batch: 450 | Loss: 0.359 | Acc: 99.861% | Wgt Acc: 99.859%
I - num batch: 478
I - Train -- Loss: 0.359 | Acc: 99.869% | Wgt Acc: 99.867% | LR: 1.250000e-04 | Dur: 328.74s
I - Confusion Matrix: [row->prediction - col->label]
[[2086.    0.    0.    4.]
 [   4. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    0.    0. 1609.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.039 | Acc: 61.500% | Wgt Acc: 60.466%
I - num batch: 62
I - Val -- Loss: 1.048 | Acc: 60.856% | Wgt Acc: 59.873% | Dur: 35.52s
I - Confusion Matrix: [row->prediction - col->label]
[[218.  28.  37.  74.]
 [  9. 120.  38.  16.]
 [  3.  78. 123.  32.]
 [ 34.   8.  27. 136.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.358 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.359 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.358 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.358 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 250 | Loss: 0.358 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.358 | Acc: 99.938% | Wgt Acc: 99.934%
	I - Batch: 350 | Loss: 0.358 | Acc: 99.929% | Wgt Acc: 99.927%
	I - Batch: 400 | Loss: 0.358 | Acc: 99.938% | Wgt Acc: 99.937%
	I - Batch: 450 | Loss: 0.359 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 478
I - Train -- Loss: 0.358 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 327.23s
I - Confusion Matrix: [row->prediction - col->label]
[[2088.    0.    0.    2.]
 [   3. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.010 | Acc: 62.750% | Wgt Acc: 62.077%
I - num batch: 62
I - Val -- Loss: 1.019 | Acc: 62.181% | Wgt Acc: 61.572% | Dur: 37.52s
I - Confusion Matrix: [row->prediction - col->label]
[[219.  27.  35.  76.]
 [  8. 126.  39.  16.]
 [  3.  67. 112.  13.]
 [ 34.  14.  39. 153.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.358 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.358 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.358 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.357 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.358 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.359 | Acc: 99.896% | Wgt Acc: 99.887%
	I - Batch: 350 | Loss: 0.359 | Acc: 99.911% | Wgt Acc: 99.903%
	I - Batch: 400 | Loss: 0.359 | Acc: 99.906% | Wgt Acc: 99.898%
	I - Batch: 450 | Loss: 0.359 | Acc: 99.917% | Wgt Acc: 99.909%
I - num batch: 478
I - Train -- Loss: 0.359 | Acc: 99.921% | Wgt Acc: 99.914% | LR: 1.250000e-04 | Dur: 330.50s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    1.    0.    2.]
 [   1. 1733.    0.    0.]
 [   0.    0. 2202.    2.]
 [   0.    0.    0. 1610.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.065 | Acc: 61.000% | Wgt Acc: 59.745%
I - num batch: 62
I - Val -- Loss: 1.062 | Acc: 60.754% | Wgt Acc: 59.579% | Dur: 37.79s
I - Confusion Matrix: [row->prediction - col->label]
[[237.  37.  42.  98.]
 [  6. 121.  43.  17.]
 [  1.  64. 112.  17.]
 [ 20.  12.  28. 126.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.356 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.356 | Acc: 99.917% | Wgt Acc: 99.915%
	I - Batch: 200 | Loss: 0.355 | Acc: 99.938% | Wgt Acc: 99.937%
	I - Batch: 250 | Loss: 0.356 | Acc: 99.950% | Wgt Acc: 99.949%
	I - Batch: 300 | Loss: 0.356 | Acc: 99.938% | Wgt Acc: 99.934%
	I - Batch: 350 | Loss: 0.357 | Acc: 99.911% | Wgt Acc: 99.912%
	I - Batch: 400 | Loss: 0.357 | Acc: 99.922% | Wgt Acc: 99.923%
	I - Batch: 450 | Loss: 0.357 | Acc: 99.931% | Wgt Acc: 99.931%
I - num batch: 478
I - Train -- Loss: 0.357 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-04 | Dur: 326.78s
I - Confusion Matrix: [row->prediction - col->label]
[[2088.    0.    0.    2.]
 [   2. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   1.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.045 | Acc: 60.625% | Wgt Acc: 59.911%
I - num batch: 62
I - Val -- Loss: 1.052 | Acc: 59.939% | Wgt Acc: 59.307% | Dur: 36.11s
I - Confusion Matrix: [row->prediction - col->label]
[[213.  24.  26.  74.]
 [  7. 120.  51.  17.]
 [  3.  66. 108.  20.]
 [ 41.  24.  40. 147.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.357 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.356 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.355 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.355 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.355 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.356 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.355 | Acc: 99.982% | Wgt Acc: 99.980%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.356 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.356 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 328.49s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.040 | Acc: 60.625% | Wgt Acc: 59.883%
I - num batch: 62
I - Val -- Loss: 1.039 | Acc: 60.754% | Wgt Acc: 60.100% | Dur: 37.03s
I - Confusion Matrix: [row->prediction - col->label]
[[224.  31.  37.  78.]
 [  9. 124.  49.  20.]
 [  2.  68. 102.  14.]
 [ 29.  11.  37. 146.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.354 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.355 | Acc: 99.917% | Wgt Acc: 99.915%
	I - Batch: 200 | Loss: 0.356 | Acc: 99.938% | Wgt Acc: 99.937%
	I - Batch: 250 | Loss: 0.356 | Acc: 99.925% | Wgt Acc: 99.927%
	I - Batch: 300 | Loss: 0.356 | Acc: 99.917% | Wgt Acc: 99.916%
	I - Batch: 350 | Loss: 0.356 | Acc: 99.929% | Wgt Acc: 99.928%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.922% | Wgt Acc: 99.919%
	I - Batch: 450 | Loss: 0.355 | Acc: 99.931% | Wgt Acc: 99.928%
I - num batch: 478
I - Train -- Loss: 0.355 | Acc: 99.935% | Wgt Acc: 99.932% | LR: 1.250000e-04 | Dur: 327.22s
I - Confusion Matrix: [row->prediction - col->label]
[[2089.    0.    0.    2.]
 [   1. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.050 | Acc: 61.375% | Wgt Acc: 59.911%
I - num batch: 62
I - Val -- Loss: 1.070 | Acc: 59.633% | Wgt Acc: 58.197% | Dur: 36.25s
I - Confusion Matrix: [row->prediction - col->label]
[[227.  23.  31.  85.]
 [  4. 109.  36.  18.]
 [  5.  91. 128.  34.]
 [ 28.  11.  30. 121.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.359 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.359 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.359 | Acc: 99.917% | Wgt Acc: 99.906%
	I - Batch: 200 | Loss: 0.358 | Acc: 99.906% | Wgt Acc: 99.894%
	I - Batch: 250 | Loss: 0.358 | Acc: 99.925% | Wgt Acc: 99.916%
	I - Batch: 300 | Loss: 0.358 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 350 | Loss: 0.358 | Acc: 99.946% | Wgt Acc: 99.940%
	I - Batch: 400 | Loss: 0.357 | Acc: 99.922% | Wgt Acc: 99.915%
	I - Batch: 450 | Loss: 0.357 | Acc: 99.931% | Wgt Acc: 99.925%
I - num batch: 478
I - Train -- Loss: 0.357 | Acc: 99.935% | Wgt Acc: 99.929% | LR: 1.250000e-04 | Dur: 327.40s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    0.    0.    2.]
 [   0. 1733.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    1.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.013 | Acc: 62.250% | Wgt Acc: 61.743%
I - num batch: 62
I - Val -- Loss: 1.020 | Acc: 61.978% | Wgt Acc: 61.481% | Dur: 35.64s
I - Confusion Matrix: [row->prediction - col->label]
[[205.  23.  25.  55.]
 [ 10. 112.  34.  13.]
 [  3.  81. 120.  19.]
 [ 46.  18.  46. 171.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.352 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.352 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.352 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.353 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.353 | Acc: 99.982% | Wgt Acc: 99.980%
	I - Batch: 400 | Loss: 0.354 | Acc: 99.969% | Wgt Acc: 99.968%
	I - Batch: 450 | Loss: 0.354 | Acc: 99.958% | Wgt Acc: 99.956%
I - num batch: 478
I - Train -- Loss: 0.355 | Acc: 99.948% | Wgt Acc: 99.944% | LR: 1.250000e-04 | Dur: 326.24s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    0.    0.    2.]
 [   1. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.033 | Acc: 62.125% | Wgt Acc: 61.327%
I - num batch: 62
I - Val -- Loss: 1.037 | Acc: 62.080% | Wgt Acc: 61.322% | Dur: 35.97s
I - Confusion Matrix: [row->prediction - col->label]
[[224.  32.  31.  72.]
 [  3. 110.  34.  12.]
 [  3.  73. 113.  12.]
 [ 34.  19.  47. 162.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.355 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.355 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.356 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.355 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.355 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.355 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 350 | Loss: 0.355 | Acc: 99.964% | Wgt Acc: 99.960%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.356 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.356 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 328.28s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.023 | Acc: 59.750% | Wgt Acc: 59.134%
I - num batch: 62
I - Val -- Loss: 1.025 | Acc: 60.041% | Wgt Acc: 59.466% | Dur: 38.05s
I - Confusion Matrix: [row->prediction - col->label]
[[205.  22.  28.  64.]
 [  5. 110.  34.  14.]
 [  6.  81. 114.  20.]
 [ 48.  21.  49. 160.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.352 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.353 | Acc: 99.917% | Wgt Acc: 99.906%
	I - Batch: 200 | Loss: 0.354 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 250 | Loss: 0.355 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.355 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 350 | Loss: 0.355 | Acc: 99.946% | Wgt Acc: 99.940%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.953% | Wgt Acc: 99.947%
	I - Batch: 450 | Loss: 0.355 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.355 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 327.66s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.044 | Acc: 63.500% | Wgt Acc: 62.660%
I - num batch: 62
I - Val -- Loss: 1.049 | Acc: 63.507% | Wgt Acc: 62.840% | Dur: 36.31s
I - Confusion Matrix: [row->prediction - col->label]
[[219.  24.  27.  65.]
 [  2. 112.  26.  11.]
 [  2.  79. 121.  11.]
 [ 41.  19.  51. 171.]]

I - Local maximum validation set accuracy:  63.51

I - Validation set results: 
[14-1-2-0.15][14-1-2--0.03][14-1-1--0.02][50-3-1--0.27][50-3-3--0.42][50-3-3--0.73][124-2-2-0.15][124-2-2-0.91][124-2-2-0.59][127-0-0-0.99]
[127-0-0-0.99][127-0-0-0.99][443-2-2-0.99][443-2-2-0.99][443-2-2-0.99][567-0-0-0.99][567-0-0-0.67][567-0-0-0.99][573-1-1--0.20][573-1-1-0.23]
[573-1-1--0.01][615-0-3-0.54][615-0-3-0.59][615-0-3-0.89][695-1-2-0.74][695-1-2-0.99][695-1-2-0.99][722-3-3-0.99][722-3-3-0.99][722-3-3-0.82]
[826-0-0-0.96][826-0-0-0.99][826-0-0-0.99][878-0-0-0.79][878-0-0-0.99][878-0-0-0.99][1103-0-0-0.16][1103-0-0-0.18][1103-0-0-0.20][1212-3-3-0.27]
[1212-3-3-0.41][1212-3-3--0.56][1368-0-0-0.99][1368-0-0-0.93][1368-0-0-0.92][2181-2-2--0.11][2181-2-2-0.21][2181-2-2-0.09][2476-2-0-0.82][2476-2-0-0.99]
[2476-2-2-0.64][2721-2-2-0.99][2721-2-2-0.99][2721-2-2-0.99][2818-1-2--0.11][2818-1-3-0.67][2818-1-3-0.99][2886-2-1-0.94][2886-2-1-0.93][2886-2-1-0.93]
[3231-2-2-0.98][3231-2-2-0.93][3231-2-2-0.99][3333-2-3-0.11][3333-2-3-0.57][3333-2-3-0.41][3482-2-2-0.70][3482-2-2-0.04][3482-2-1--0.43][3536-3-0-0.43]
[3536-3-0--0.27][3536-3-3--0.05][3625-1-1-0.97][3625-1-1-0.73][3625-1-1-0.75][3909-0-0-0.93][3909-0-0-0.99][3909-0-0-0.99][4035-0-0-0.46][4035-0-0-0.83]
[4035-0-0-0.90][4140-0-0-0.99][4140-0-0-0.97][4140-0-0-0.99][4214-1-0-0.79][4214-1-3-0.55][4214-1-2--0.12][4346-1-0-0.90][4346-1-0-0.52][4346-1-0-0.49]
[4581-2-2--0.45][4581-2-2--0.47][4581-2-2-0.67][4708-3-2--0.15][4708-3-2-0.57][4708-3-2-0.09][4838-3-3-0.66][4838-3-3-0.33][4838-3-3-0.06][4845-1-1--0.44]
[4845-1-1--0.48][4845-1-1--0.23][4868-0-0-0.98][4868-0-0-0.99][4868-0-0-0.99][4939-0-0-0.55][4939-0-3--0.37][4939-0-0--0.44][4984-2-2-0.93][4984-2-2-0.86]
[4984-2-2-0.84][5078-1-1--0.03][5078-1-2-0.63][5078-1-2-0.32][5396-0-0-0.99][5396-0-0-0.99][5396-0-0-0.99][5479-1-2--0.26][5479-1-2--0.20][5479-1-2-0.25]
[5717-0-0-0.64][5717-0-0-0.99][5717-0-0--0.12][5843-1-1-0.62][5843-1-1-0.08][5843-1-1--0.20][5949-3-0-0.77][5949-3-0-0.99][5949-3-0-0.99][5987-2-2-0.15]
[5987-2-2--0.19][5987-2-2-0.11][6014-3-1-0.47][6014-3-1--0.33][6014-3-3-0.75][6033-3-0-0.99][6033-3-0-0.50][6033-3-0-0.94][6313-0-0-0.50][6313-0-0-0.33]
[6313-0-0-0.27][6421-3-3-0.74][6421-3-3-0.06][6421-3-3--0.43][6500-1-2--0.70][6500-1-1--0.77][6500-1-2--0.74][6583-3-3-0.57][6583-3-3-0.64][6583-3-3-0.15]
[6683-3-3-0.62][6683-3-3-0.81][6683-3-3-0.98][6825-2-3-0.78][6825-2-3-0.91][6825-2-3-0.64][6998-3-3-0.04][6998-3-3-0.19][6998-3-0--0.18][7049-3-3--0.52]
[7049-3-3-0.02][7049-3-3-0.02][7517-1-1-0.63][7517-1-1-0.97][7517-1-1-0.99][7521-1-0-0.99][7521-1-0-0.99][7521-1-0-0.99][7528-1-1--0.10][7528-1-1--0.48]
[7528-1-3-0.10][7949-1-2-0.21][7949-1-2-0.63][7949-1-2-0.10][8135-1-0-0.93][8135-1-0-0.99][8135-1-0-0.95][8185-3-0-0.99][8185-3-0-0.99][8185-3-0-0.99]
[8269-3-2--0.02][8269-3-2--0.13][8269-3-1--0.04][8273-3-3-0.99][8273-3-3-0.99][8273-3-3-0.99][8543-3-3-0.74][8543-3-0-0.99][8543-3-0-0.99][8666-1-2--0.77]
[8666-1-1--0.49][8666-1-2--0.50][8672-0-0-0.92][8672-0-0-0.86][8672-0-3--0.02][8903-1-1--0.09][8903-1-2-0.11][8903-1-2-0.80][9001-2-0-0.65][9001-2-1-0.62]
[9001-2-1-0.80][9036-2-2-0.71][9036-2-2-0.49][9036-2-2-0.05][9281-3-3-0.30][9281-3-3-0.48][9281-3-3-0.18][9300-2-2-0.22][9300-2-2-0.30][9300-2-2-0.11]
[9571-0-0-0.12][9571-0-0--0.26][9571-0-3-0.03][9617-1-1-0.45][9617-1-1--0.57][9617-1-1-0.13][9644-2-2-0.99][9644-2-2-0.99][9644-2-2-0.99][9705-2-0--0.30]
[9705-2-2--0.34][9705-2-2--0.55][9801-0-3-0.44][9801-0-3--0.10][9801-0-3-0.72][9803-3-3-0.28][9803-3-3-0.46][9803-3-3-0.72][9865-3-0-0.69][9865-3-3-0.99]
[9865-3-3-0.95][9896-2-2-0.55][9896-2-2-0.49][9896-2-2-0.87][10314-1-0-0.99][10314-1-0-0.99][10314-1-0-0.99][10337-3-3-0.99][10337-3-3--0.12][10337-3-3-0.41]
[10403-0-0-0.11][10403-0-0--0.21][10403-0-0-0.62][10653-2-2--0.01][10653-2-3-0.18][10653-2-1-0.06][10704-2-3-0.99][10704-2-3-0.49][10704-2-3-0.99][10719-1-2--0.06]
[10719-1-1-0.45][10719-1-1-0.72][10727-1-1--0.14][10727-1-1-0.29][10727-1-1-0.62][10836-0-0-0.99][10836-0-0-0.99][10836-0-0-0.99][10969-2-3-0.15][10969-2-3-0.12]
[10969-2-3--0.11][11042-0-0-0.92][11042-0-0-0.40][11042-0-0-0.99][11088-1-1-0.99][11088-1-1-0.99][11088-1-1-0.99][11322-0-0-0.99][11322-0-0-0.89][11322-0-0-0.94]
[11398-2-2--0.38][11398-2-2-0.01][11398-2-0-0.06][11499-0-0-0.95][11499-0-0-0.92][11499-0-0-0.83][11502-3-0--0.47][11502-3-2--0.51][11502-3-2--0.17][11512-3-3-0.99]
[11512-3-3-0.94][11512-3-3-0.41][11608-1-2-0.99][11608-1-2-0.82][11608-1-2-0.91][11610-0-3-0.84][11610-0-0-0.84][11610-0-0-0.96][11692-0-0-0.99][11692-0-0-0.99]
[11692-0-0-0.70][11905-0-0-0.99][11905-0-0-0.99][11905-0-0-0.99][11993-1-2-0.57][11993-1-2-0.73][11993-1-2-0.96][12002-2-0-0.91][12002-2-3-0.36][12002-2-3-0.30]
[12052-0-0-0.64][12052-0-0-0.94][12052-0-0-0.99][12201-0-3-0.77][12201-0-3-0.59][12201-0-3-0.89][12235-2-2-0.90][12235-2-2-0.55][12235-2-2-0.85][12320-1-0-0.99]
[12320-1-0-0.99][12320-1-0-0.99][12377-2-0--0.05][12377-2-2--0.42][12377-2-0-0.08][12398-2-3-0.20][12398-2-3-0.16][12398-2-3-0.62][12503-1-1-0.43][12503-1-1--0.05]
[12503-1-1-0.26][12617-0-3-0.42][12617-0-3-0.90][12617-0-3-0.06][12685-3-1--0.31][12685-3-3--0.01][12685-3-3-0.45][12738-2-2-0.92][12738-2-2--0.03][12738-2-2--0.61]
[12742-2-2-0.97][12742-2-2-0.95][12742-2-2-0.99][12823-0-0-0.99][12823-0-0-0.34][12823-0-0-0.82][13110-1-2-0.06][13110-1-2-0.69][13110-1-2-0.77][13240-3-0-0.95]
[13240-3-0-0.98][13240-3-0-0.98][13253-1-1-0.99][13253-1-1-0.99][13253-1-1-0.99][13273-0-0-0.99][13273-0-0-0.99][13273-0-0-0.99][13634-1-3-0.66][13634-1-3-0.83]
[13634-1-3-0.54][13763-2-3--0.00][13763-2-3--0.25][13763-2-3--0.05][13905-3-3--0.52][13905-3-0--0.29][13905-3-3--0.14][14060-2-3-0.08][14060-2-1-0.08][14060-2-3-0.27]
[14065-3-0-0.55][14065-3-0-0.77][14065-3-3--0.58][14147-3-0-0.22][14147-3-3-0.59][14147-3-0-0.84][14595-2-1--0.46][14595-2-2-0.56][14595-2-2--0.29][14687-2-2-0.96]
[14687-2-2-0.99][14687-2-3-0.97][14788-2-2-0.99][14788-2-2-0.99][14788-2-2-0.99][14869-1-1-0.02][14869-1-2--0.12][14869-1-2--0.03][14872-3-0--0.30][14872-3-0--0.05]
[14872-3-0-0.14][14877-1-1-0.98][14877-1-1-0.99][14877-1-1-0.99][14927-0-0-0.96][14927-0-0-0.86][14927-0-3-0.55][15066-0-0-0.96][15066-0-0-0.70][15066-0-0-0.99]
[15175-1-1-0.85][15175-1-1-0.92][15175-1-1-0.99][15178-2-2--0.82][15178-2-3-0.11][15178-2-3-0.10][15375-3-3-0.31][15375-3-3--0.04][15375-3-0--0.39][15389-3-3-0.85]
[15389-3-3--0.62][15389-3-3--0.16][15568-2-1-0.55][15568-2-3-0.71][15568-2-1-0.06][15675-3-3-0.99][15675-3-3-0.99][15675-3-3-0.99][15869-1-0--0.54][15869-1-1--0.50]
[15869-1-3-0.28][16207-3-0-0.99][16207-3-0-0.78][16207-3-0-0.25][16236-0-0-0.92][16236-0-0-0.99][16236-0-0-0.31][16302-3-0--0.16][16302-3-3-0.44][16302-3-3-0.90]
[16331-2-2-0.99][16331-2-2-0.99][16331-2-2-0.99][16381-0-3-0.99][16381-0-3-0.99][16381-0-3-0.73][16488-1-1-0.65][16488-1-1-0.74][16488-1-1--0.03][16495-0-0-0.99]
[16495-0-0-0.99][16495-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16650-0-0-0.99][16719-1-2-0.48][16719-1-2-0.70][16719-1-2-0.92][16801-0-0-0.99][16801-0-0-0.99]
[16801-0-0-0.99][16828-0-0-0.94][16828-0-0-0.66][16828-0-0-0.85][17137-3-3-0.30][17137-3-3-0.94][17137-3-3-0.69][17245-1-1-0.07][17245-1-1--0.21][17245-1-1--0.07]
[17278-3-0-0.11][17278-3-0--0.35][17278-3-0-0.54][17282-0-0-0.15][17282-0-0-0.29][17282-0-0--0.33][17311-2-2-0.74][17311-2-2-0.33][17311-2-2-0.87][17336-2-1--0.30]
[17336-2-2--0.25][17336-2-2--0.12][17608-3-3-0.99][17608-3-3-0.99][17608-3-3-0.99][17627-0-0-0.86][17627-0-0--0.14][17627-0-0-0.60][17877-3-3--0.15][17877-3-0-0.18]
[17877-3-0-0.63][17924-1-1--0.70][17924-1-1-0.41][17924-1-1--0.73][17984-3-3-0.99][17984-3-0-0.05][17984-3-3-0.02][18211-0-0--0.44][18211-0-3--0.42][18211-0-3-0.25]
[18276-3-3-0.82][18276-3-0-0.63][18276-3-3-0.47][18287-1-1--0.13][18287-1-1-0.97][18287-1-1-0.84][18394-0-0-0.99][18394-0-0-0.99][18394-0-0-0.94][18428-0-0-0.88]
[18428-0-0-0.74][18428-0-0-0.99][18442-0-3-0.98][18442-0-3-0.99][18442-0-3-0.95][18478-3-3-0.28][18478-3-3-0.13][18478-3-3-0.18][18607-0-0-0.99][18607-0-0-0.99]
[18607-0-0-0.99][18616-0-0-0.31][18616-0-0-0.56][18616-0-0-0.46][18663-0-0--0.47][18663-0-0--0.19][18663-0-0--0.24][18718-0-0-0.99][18718-0-0-0.99][18718-0-0-0.92]
[18766-2-1-0.07][18766-2-1-0.42][18766-2-1-0.61][18824-2-2-0.99][18824-2-2-0.27][18824-2-2-0.43][18890-3-3--0.13][18890-3-3-0.50][18890-3-3-0.43][18930-3-0--0.14]
[18930-3-0-0.26][18930-3-0--0.12][18938-3-0--0.16][18938-3-3-0.24][18938-3-3-0.13][19817-1-2-0.68][19817-1-2-0.55][19817-1-2-0.81][19839-0-0-0.90][19839-0-0-0.54]
[19839-0-0-0.68][19930-3-0-0.73][19930-3-0-0.17][19930-3-0-0.74][19944-0-0-0.55][19944-0-2-0.15][19944-0-0-0.27][20036-2-2-0.95][20036-2-2-0.82][20036-2-2-0.93]
[20101-3-3-0.15][20101-3-3-0.71][20101-3-3-0.57][20474-1-2-0.59][20474-1-2-0.51][20474-1-2-0.50][20547-3-3-0.43][20547-3-0-0.85][20547-3-0-0.00][20929-2-2--0.08]
[20929-2-2-0.99][20929-2-2-0.75][21245-1-1--0.08][21245-1-2-0.15][21245-1-1-0.86][21257-3-3-0.99][21257-3-2--0.42][21257-3-3-0.22][21293-1-1--0.03][21293-1-1-0.22]
[21293-1-1-0.16][21316-1-1-0.77][21316-1-1-0.86][21316-1-1--0.64][21384-1-2-0.99][21384-1-2-0.99][21384-1-2-0.99][21448-1-1--0.24][21448-1-1-0.28][21448-1-0--0.63]
[21483-0-0-0.99][21483-0-0-0.99][21483-0-0-0.99][21487-2-2-0.99][21487-2-2-0.99][21487-2-2-0.99][21714-0-3-0.57][21714-0-3-0.24][21714-0-3-0.29][21943-3-3-0.25]
[21943-3-2--0.22][21943-3-1-0.60][21947-0-0-0.99][21947-0-0-0.95][21947-0-0-0.76][21948-0-0-0.99][21948-0-0-0.99][21948-0-0-0.99][21965-2-2-0.81][21965-2-2-0.99]
[21965-2-2--0.42][21998-1-2--0.06][21998-1-1-0.38][21998-1-1-0.79][22025-0-1--0.40][22025-0-3--0.26][22025-0-3--0.40][22228-3-3-0.74][22228-3-3-0.68][22228-3-3-0.78]
[22446-1-1-0.82][22446-1-1-0.62][22446-1-1-0.14][22494-3-3-0.77][22494-3-3-0.99][22494-3-3-0.99][22757-0-0-0.50][22757-0-3-0.50][22757-0-3-0.39][22811-3-3-0.43]
[22811-3-3-0.99][22811-3-3-0.99][22976-3-3--0.06][22976-3-1-0.39][22976-3-1-0.85][22985-3-3-0.44][22985-3-3-0.62][22985-3-0-0.04][23014-0-0-0.51][23014-0-0-0.82]
[23014-0-3-0.88][23112-1-2-0.68][23112-1-2-0.88][23112-1-2-0.92][23144-3-3-0.82][23144-3-3-0.88][23144-3-0-0.40][23168-2-3--0.24][23168-2-3-0.22][23168-2-3-0.63]
[23219-0-0-0.67][23219-0-0-0.99][23219-0-0-0.99][23363-3-3-0.45][23363-3-3-0.58][23363-3-3-0.97][23470-0-0-0.80][23470-0-0-0.56][23470-0-3--0.20][23486-2-3-0.75]
[23486-2-3--0.24][23486-2-3--0.73][23497-0-3-0.99][23497-0-3-0.99][23497-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23516-0-0-0.99][23690-1-2--0.84][23690-1-3--0.14]
[23690-1-3-0.32][23921-2-1-0.10][23921-2-2-0.55][23921-2-2-0.39][23936-1-2-0.99][23936-1-2-0.68][23936-1-2-0.99][24040-3-0-0.89][24040-3-0-0.60][24040-3-0-0.25]
[24111-1-1-0.69][24111-1-1-0.46][24111-1-1-0.59][24182-0-0-0.99][24182-0-0-0.99][24182-0-0-0.99][24238-3-0-0.99][24238-3-0-0.99][24238-3-0-0.99][24290-2-0-0.99]
[24290-2-0-0.99][24290-2-0-0.99][24345-0-0-0.84][24345-0-2--0.27][24345-0-0-0.18][24364-1-2-0.13][24364-1-2-0.95][24364-1-2-0.99][24427-3-0-0.95][24427-3-0-0.99]
[24427-3-0-0.99][24477-2-2-0.83][24477-2-2-0.30][24477-2-2-0.08][24495-2-1-0.40][24495-2-1--0.19][24495-2-1-0.13][24893-2-2--0.26][24893-2-2--0.28][24893-2-3--0.88]
[25012-1-1-0.27][25012-1-1-0.24][25012-1-2-0.34][25121-2-0-0.99][25121-2-0-0.99][25121-2-0-0.99][25165-3-3--0.59][25165-3-3--0.53][25165-3-3--0.27][25183-0-0-0.99]
[25183-0-0-0.99][25183-0-0-0.99][25297-3-3-0.95][25297-3-3-0.72][25297-3-3-0.32][25398-0-0-0.61][25398-0-0-0.99][25398-0-0-0.99][25574-2-2--0.07][25574-2-3-0.07]
[25574-2-3--0.27][25644-1-1-0.99][25644-1-1-0.99][25644-1-1-0.10][25718-1-2-0.07][25718-1-2--0.61][25718-1-0--0.22][25774-2-2--0.05][25774-2-3-0.54][25774-2-2-0.73]
[26032-3-3-0.99][26032-3-3-0.86][26032-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26051-3-3-0.99][26120-0-0-0.58][26120-0-0-0.99][26120-0-0-0.99][26321-1-1-0.03]
[26321-1-1-0.46][26321-1-1--0.92][26732-1-1-0.95][26732-1-1-0.83][26732-1-1-0.96][26784-3-3-0.96][26784-3-3-0.98][26784-3-3-0.72][26827-3-3-0.94][26827-3-3-0.99]
[26827-3-3-0.75][26833-0-0-0.42][26833-0-0-0.99][26833-0-0-0.88][26838-2-2-0.16][26838-2-3-0.56][26838-2-3-0.45][26860-1-2-0.09][26860-1-2--0.14][26860-1-1-0.78]
[26948-0-0-0.54][26948-0-0-0.67][26948-0-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27049-3-0-0.99][27098-1-0--0.37][27098-1-0--0.24][27098-1-0-0.92][27526-0-0-0.99]
[27526-0-0-0.99][27526-0-0-0.48][27639-3-3-0.11][27639-3-3--0.04][27639-3-3-0.86][27698-3-3-0.73][27698-3-3-0.84][27698-3-3-0.63][27772-0-0-0.99][27772-0-0-0.99]
[27772-0-0-0.42][27890-1-1--0.17][27890-1-1--0.07][27890-1-2-0.41][28040-0-0-0.20][28040-0-0-0.87][28040-0-0-0.99][28503-2-2-0.97][28503-2-2-0.94][28503-2-2-0.83]
[28577-1-1-0.48][28577-1-1-0.33][28577-1-1-0.21][28959-0-0-0.99][28959-0-0-0.99][28959-0-0-0.99][29198-3-3-0.63][29198-3-3-0.57][29198-3-3-0.78][29777-0-0-0.99]
[29777-0-0-0.99][29777-0-0-0.99][29877-2-3--0.52][29877-2-1--0.53][29877-2-1--0.38][30035-1-3-0.99][30035-1-3-0.29][30035-1-3-0.81][30098-0-3-0.41][30098-0-0-0.85]
[30098-0-0-0.99][30326-1-1-0.99][30326-1-1-0.99][30326-1-1-0.99][30572-2-2-0.82][30572-2-3-0.59][30572-2-2-0.99][30716-0-0-0.93][30716-0-0-0.99][30716-0-0-0.87]
[30806-2-0-0.20][30806-2-0-0.02][30806-2-3-0.53][30906-1-1-0.99][30906-1-1-0.94][30906-1-1-0.55][31007-0-0-0.83][31007-0-0-0.86][31007-0-3-0.37][31181-3-3--0.71]
[31181-3-3--0.44][31181-3-2--0.59][31238-0-0-0.49][31238-0-0-0.55][31238-0-0-0.78][31347-0-0-0.99][31347-0-0-0.64][31347-0-0-0.86][31422-2-0-0.99][31422-2-0-0.99]
[31422-2-0-0.99][31429-3-3-0.54][31429-3-3-0.20][31429-3-3-0.15][31431-0-0-0.99][31431-0-0-0.82][31431-0-0-0.14][31432-1-1-0.18][31432-1-1-0.54][31432-1-1-0.05]
[31477-0-0-0.96][31477-0-0-0.99][31477-0-0-0.99][31524-1-2--0.35][31524-1-3--0.13][31524-1-0-0.15][31597-1-2-0.85][31597-1-2-0.87][31597-1-3--0.31][31619-1-0-0.54]
[31619-1-2-0.99][31619-1-2-0.99][31701-0-0-0.99][31701-0-0-0.94][31701-0-0-0.70][31755-0-0-0.99][31755-0-0-0.94][31755-0-0-0.87][31854-3-3-0.52][31854-3-3--0.02]
[31854-3-3-0.00][32074-1-2--0.09][32074-1-2--0.17][32074-1-3--0.03][32078-3-3-0.99][32078-3-3-0.99][32078-3-3-0.99][32111-1-1-0.05][32111-1-1-0.77][32111-1-1-0.98]
[32127-1-1-0.79][32127-1-1-0.18][32127-1-1-0.50][32140-3-3-0.99][32140-3-3-0.99][32140-3-3-0.99][32263-2-0--0.63][32263-2-2--0.54][32263-2-0--0.63][32365-0-0-0.94]
[32365-0-0-0.87][32365-0-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32429-3-0-0.58][32429-3-0-0.99][32473-3-3-0.99][32473-3-3-0.93]
[32473-3-3-0.90][32574-3-3-0.99][32574-3-3-0.99][32574-3-3-0.99][32584-0-3-0.75][32584-0-3-0.63][32584-0-3-0.50][32622-0-1--0.41][32622-0-0-0.79][32622-0-0-0.26]
[32858-3-3-0.53][32858-3-3-0.84][32858-3-3-0.55][32969-3-3--0.86][32969-3-3--0.82][32969-3-2--0.35][33016-2-2-0.69][33016-2-2-0.63][33016-2-2-0.79][33031-1-3-0.44]
[33031-1-3--0.08][33031-1-3--0.53][33035-2-2-0.95][33035-2-2-0.95][33035-2-2-0.98][33133-2-2-0.83][33133-2-2-0.95][33133-2-2-0.99][33173-2-3--0.36][33173-2-1--0.32]
[33173-2-2-0.42][33175-3-1-0.68][33175-3-1-0.52][33175-3-1-0.90][33306-3-3-0.96][33306-3-3-0.99][33306-3-3-0.96][33309-2-3-0.70][33309-2-3-0.67][33309-2-3--0.28]
[33474-0-0-0.13][33474-0-0--0.22][33474-0-0-0.99][33478-2-0-0.07][33478-2-0--0.10][33478-2-0-0.09][33618-1-1-0.65][33618-1-1-0.90][33618-1-1-0.88][33712-0-0-0.81]
[33712-0-0-0.99][33712-0-0-0.68][33782-2-1--0.01][33782-2-1-0.24][33782-2-1--0.86][33914-3-3-0.53][33914-3-3-0.69][33914-3-3-0.86][34076-3-3-0.39][34076-3-3--0.04]
[34076-3-3--0.38][34112-2-3-0.79][34112-2-3-0.99][34112-2-3-0.99][34138-2-2-0.99][34138-2-2-0.99][34138-2-2-0.99][34239-1-2-0.25][34239-1-2-0.54][34239-1-2-0.08]
[34364-2-1-0.67][34364-2-2--0.14][34364-2-2-0.50][34617-1-2--0.52][34617-1-2-0.04][34617-1-2-0.09][34751-3-3-0.37][34751-3-3-0.06][34751-3-3-0.10][34783-2-2--0.55]
[34783-2-2-0.52][34783-2-2--0.03][35015-3-3-0.50][35015-3-3-0.39][35015-3-3-0.56][35018-1-2-0.85][35018-1-2-0.61][35018-1-2-0.55][35288-2-3-0.51][35288-2-2-0.84]
[35288-2-3--0.47]
---------------------------
I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.354 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.354 | Acc: 99.812% | Wgt Acc: 99.789%
	I - Batch: 150 | Loss: 0.353 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 200 | Loss: 0.353 | Acc: 99.906% | Wgt Acc: 99.895%
	I - Batch: 250 | Loss: 0.353 | Acc: 99.925% | Wgt Acc: 99.916%
	I - Batch: 300 | Loss: 0.354 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 350 | Loss: 0.354 | Acc: 99.946% | Wgt Acc: 99.940%
	I - Batch: 400 | Loss: 0.354 | Acc: 99.953% | Wgt Acc: 99.947%
	I - Batch: 450 | Loss: 0.354 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.354 | Acc: 99.948% | Wgt Acc: 99.944% | LR: 1.250000e-04 | Dur: 327.60s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.016 | Acc: 62.875% | Wgt Acc: 62.104%
I - num batch: 62
I - Val -- Loss: 1.016 | Acc: 63.405% | Wgt Acc: 62.794% | Dur: 38.07s
I - Confusion Matrix: [row->prediction - col->label]
[[219.  29.  27.  69.]
 [  6. 126.  37.  17.]
 [  5.  63. 118.  13.]
 [ 34.  16.  43. 159.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.355 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.355 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.355 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 250 | Loss: 0.355 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.355 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.355 | Acc: 99.982% | Wgt Acc: 99.980%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.355 | Acc: 99.972% | Wgt Acc: 99.969%
I - num batch: 478
I - Train -- Loss: 0.354 | Acc: 99.974% | Wgt Acc: 99.971% | LR: 1.250000e-04 | Dur: 332.48s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    1.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1612.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.029 | Acc: 61.000% | Wgt Acc: 59.800%
I - num batch: 62
I - Val -- Loss: 1.034 | Acc: 60.754% | Wgt Acc: 59.669% | Dur: 35.95s
I - Confusion Matrix: [row->prediction - col->label]
[[233.  35.  39.  89.]
 [  2. 109.  30.  13.]
 [  3.  75. 112.  14.]
 [ 26.  15.  44. 142.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.352 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.352 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.352 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 350 | Loss: 0.353 | Acc: 99.964% | Wgt Acc: 99.960%
	I - Batch: 400 | Loss: 0.353 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.353 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.353 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 328.91s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.033 | Acc: 61.375% | Wgt Acc: 60.411%
I - num batch: 62
I - Val -- Loss: 1.036 | Acc: 61.162% | Wgt Acc: 60.258% | Dur: 36.72s
I - Confusion Matrix: [row->prediction - col->label]
[[222.  25.  30.  78.]
 [ 10. 119.  33.  14.]
 [  3.  75. 117.  24.]
 [ 29.  15.  45. 142.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.356 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.355 | Acc: 99.917% | Wgt Acc: 99.906%
	I - Batch: 200 | Loss: 0.354 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 250 | Loss: 0.353 | Acc: 99.950% | Wgt Acc: 99.944%
	I - Batch: 300 | Loss: 0.353 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 350 | Loss: 0.353 | Acc: 99.946% | Wgt Acc: 99.940%
	I - Batch: 400 | Loss: 0.353 | Acc: 99.953% | Wgt Acc: 99.947%
	I - Batch: 450 | Loss: 0.353 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.353 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 330.12s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.061 | Acc: 60.250% | Wgt Acc: 59.023%
I - num batch: 62
I - Val -- Loss: 1.059 | Acc: 60.652% | Wgt Acc: 59.466% | Dur: 35.21s
I - Confusion Matrix: [row->prediction - col->label]
[[201.  20.  22.  58.]
 [ 16. 105.  26.  21.]
 [ 10. 100. 148.  38.]
 [ 37.   9.  29. 141.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.351 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.351 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.352 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.352 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.352 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.353 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.353 | Acc: 99.964% | Wgt Acc: 99.960%
	I - Batch: 400 | Loss: 0.353 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.353 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 478
I - Train -- Loss: 0.353 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-04 | Dur: 328.40s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.027 | Acc: 62.125% | Wgt Acc: 61.160%
I - num batch: 62
I - Val -- Loss: 1.036 | Acc: 60.550% | Wgt Acc: 59.669% | Dur: 34.92s
I - Confusion Matrix: [row->prediction - col->label]
[[229.  29.  38.  78.]
 [  4. 126.  42.  23.]
 [  2.  68. 106.  24.]
 [ 29.  11.  39. 133.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 250 | Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 300 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 350 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 400 | Loss: 0.354 | Acc: 99.984% | Wgt Acc: 99.986%
	I - Batch: 450 | Loss: 0.354 | Acc: 99.958% | Wgt Acc: 99.956%
I - num batch: 478
I - Train -- Loss: 0.354 | Acc: 99.961% | Wgt Acc: 99.959% | LR: 1.250000e-04 | Dur: 325.22s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    0.    0.    1.]
 [   0. 1734.    0.    0.]
 [   1.    0. 2202.    1.]
 [   0.    0.    0. 1612.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.044 | Acc: 60.250% | Wgt Acc: 59.300%
I - num batch: 62
I - Val -- Loss: 1.045 | Acc: 60.449% | Wgt Acc: 59.579% | Dur: 33.95s
I - Confusion Matrix: [row->prediction - col->label]
[[222.  38.  35.  75.]
 [  4. 105.  28.  11.]
 [  0.  71. 112.  18.]
 [ 38.  20.  50. 154.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 250 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 300 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 350 | Loss: 0.351 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 400 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 450 | Loss: 0.352 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 478
I - Train -- Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-04 | Dur: 327.02s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    0.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    0.]
 [   0.    0.    0. 1614.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.054 | Acc: 61.250% | Wgt Acc: 59.939%
I - num batch: 62
I - Val -- Loss: 1.059 | Acc: 60.754% | Wgt Acc: 59.488% | Dur: 35.98s
I - Confusion Matrix: [row->prediction - col->label]
[[227.  30.  32.  69.]
 [  9. 112.  36.  11.]
 [  5.  83. 126.  47.]
 [ 23.   9.  31. 131.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.355 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.354 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 250 | Loss: 0.353 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 300 | Loss: 0.353 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.353 | Acc: 99.964% | Wgt Acc: 99.964%
	I - Batch: 400 | Loss: 0.354 | Acc: 99.969% | Wgt Acc: 99.968%
	I - Batch: 450 | Loss: 0.354 | Acc: 99.972% | Wgt Acc: 99.972%
I - num batch: 478
I - Train -- Loss: 0.355 | Acc: 99.961% | Wgt Acc: 99.959% | LR: 1.250000e-04 | Dur: 329.52s
I - Confusion Matrix: [row->prediction - col->label]
[[2090.    0.    0.    1.]
 [   1. 1734.    0.    0.]
 [   0.    0. 2202.    1.]
 [   0.    0.    0. 1612.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.040 | Acc: 62.000% | Wgt Acc: 61.188%
I - num batch: 62
I - Val -- Loss: 1.042 | Acc: 61.570% | Wgt Acc: 60.870% | Dur: 36.38s
I - Confusion Matrix: [row->prediction - col->label]
[[220.  19.  32.  64.]
 [ 11. 124.  34.  20.]
 [  4.  73. 112.  26.]
 [ 29.  18.  47. 148.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.362 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.358 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.356 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 200 | Loss: 0.356 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 250 | Loss: 0.356 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.355 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.355 | Acc: 99.982% | Wgt Acc: 99.980%
	I - Batch: 400 | Loss: 0.355 | Acc: 99.984% | Wgt Acc: 99.982%
	I - Batch: 450 | Loss: 0.354 | Acc: 99.986% | Wgt Acc: 99.984%
I - num batch: 478
I - Train -- Loss: 0.354 | Acc: 99.987% | Wgt Acc: 99.985% | LR: 1.250000e-04 | Dur: 326.54s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    1.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    0.]
 [   0.    0.    0. 1613.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.033 | Acc: 61.000% | Wgt Acc: 60.411%
I - num batch: 62
I - Val -- Loss: 1.032 | Acc: 60.143% | Wgt Acc: 59.579% | Dur: 36.51s
I - Confusion Matrix: [row->prediction - col->label]
[[225.  30.  45.  79.]
 [  5. 128.  46.  18.]
 [  3.  59.  94.  18.]
 [ 31.  17.  40. 143.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.352 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.351 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.351 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.351 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.351 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.351 | Acc: 99.979% | Wgt Acc: 99.977%
	I - Batch: 350 | Loss: 0.351 | Acc: 99.982% | Wgt Acc: 99.980%
	I - Batch: 400 | Loss: 0.351 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.351 | Acc: 99.972% | Wgt Acc: 99.969%
I - num batch: 478
I - Train -- Loss: 0.351 | Acc: 99.974% | Wgt Acc: 99.971% | LR: 1.250000e-04 | Dur: 328.11s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    0.]
 [   0.    0.    0. 1612.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.032 | Acc: 61.125% | Wgt Acc: 60.217%
I - num batch: 62
I - Val -- Loss: 1.039 | Acc: 60.449% | Wgt Acc: 59.579% | Dur: 36.77s
I - Confusion Matrix: [row->prediction - col->label]
[[223.  24.  31.  69.]
 [  7. 106.  42.  15.]
 [  6.  83. 111.  21.]
 [ 28.  21.  41. 153.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.350 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.349 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.349 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 200 | Loss: 0.349 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 250 | Loss: 0.350 | Acc: 99.975% | Wgt Acc: 99.972%
	I - Batch: 300 | Loss: 0.351 | Acc: 99.958% | Wgt Acc: 99.953%
	I - Batch: 350 | Loss: 0.351 | Acc: 99.964% | Wgt Acc: 99.960%
	I - Batch: 400 | Loss: 0.351 | Acc: 99.969% | Wgt Acc: 99.965%
	I - Batch: 450 | Loss: 0.351 | Acc: 99.972% | Wgt Acc: 99.969%
I - num batch: 478
I - Train -- Loss: 0.351 | Acc: 99.974% | Wgt Acc: 99.971% | LR: 1.250000e-04 | Dur: 326.87s
I - Confusion Matrix: [row->prediction - col->label]
[[2091.    0.    0.    2.]
 [   0. 1734.    0.    0.]
 [   0.    0. 2202.    0.]
 [   0.    0.    0. 1612.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.028 | Acc: 60.375% | Wgt Acc: 59.578%
I - num batch: 62
I - Val -- Loss: 1.029 | Acc: 60.754% | Wgt Acc: 60.032% | Dur: 37.06s
I - Confusion Matrix: [row->prediction - col->label]
[[198.  20.  24.  58.]
 [ 11. 103.  30.  13.]
 [  9.  99. 131.  23.]
 [ 46.  12.  40. 164.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.348 | Acc: 100.000% | Wgt Acc: 100.000%
