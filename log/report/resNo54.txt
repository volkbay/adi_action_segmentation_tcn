Wed Oct 26 01:05:43 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.2, 0.25, 0.2, 0.25, 0.1], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': '/new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat'], 'lastLayerInitUniform': False, 'learningRate': 0.0001, 'logBatchAt': 50, 'maxValidationAcc': 71.55963302752293, 'maxValidationTrainNo': 53, 'modelVersion': 14, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 54, 'validationAccThr': 70, 'warmStartConfig': {'checkpointFile': './sav/model9_trainNo39_at_epoch_22_with_acc_70_34_checkpoint.pth.tar', 'checkpointModelNo': 9, 'freezeSpatialCNN': True, 'warmStartFlag': False}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Train set length:  2547
I - Label distribution: [697. 578. 734. 538.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Test set length:  327
I - Label distribution: [88. 78. 75. 86.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(3) data number in dataset:  tensor([ 29333,  81975,  89895, 135122, 146912,  50821, 117163,  75044, 134820,
        136987, 169661, 143876, 179760,  31622, 196808,  77345])
I - Initializing model TCNv14
I - Number of Model Parameters: 949408
I - Model output shape:  torch.Size([16, 4])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv14                                   [16, 4]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         --
│    └─ReLU: 2-2319                      [16, 128, 64, 64]         --
│    └─Conv2d: 2-2                       --                        6,272
│    └─BatchNorm2d: 2-2317               [16, 128, 64, 64]         --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-2318                    [16, 128, 64, 64]         --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [128, 48, 1, 1]           --
│    └─Empty: 2-9                        [128, 48, 1, 1]           --
│    └─Empty: 2-10                       [128]                     --
│    └─Empty: 2-11                       [128]                     --
│    └─BatchNorm2d: 2-12                 [16, 128, 64, 64]         --
│    └─Scaler: 2-13                      [16, 128, 64, 64]         --
│    └─Empty: 2-14                       --                        --
│    └─Empty: 2-15                       --                        --
│    └─ReLU: 2-16                        [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-2331                      [16, 128, 64, 64]         --
│    └─Conv2d: 2-18                      --                        147,584
│    └─BatchNorm2d: 2-2329               [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-20                       [16, 128, 64, 64]         --
│    └─Clamp: 2-21                       [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-2330                    [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-2                 [16, 128, 64, 64]         147,590
│    └─OutputShiftSqueeze: 2-23          --                        --
│    └─One: 2-24                         [1]                       --
│    └─OutputScale: 2-25                 --                        --
│    └─Empty: 2-26                       [128, 128, 3, 3]          --
│    └─Empty: 2-27                       [128, 128, 3, 3]          --
│    └─Empty: 2-28                       [128]                     --
│    └─Empty: 2-29                       [128]                     --
│    └─BatchNorm2d: 2-30                 [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 32, 32]         (recursive)
│    └─ReLU: 2-2346                      [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-2334                 [16, 128, 32, 32]         --
│    └─Conv2d: 2-33                      --                        147,584
│    └─BatchNorm2d: 2-2344               [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-35                      [16, 128, 64, 64]         --
│    └─ReLU: 2-36                        [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2345                    [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-38                       [16, 128, 64, 64]         --
│    └─Clamp: 2-39                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-4          [16, 128, 32, 32]         131,078
│    └─MaxPool2d: 2-40                   [16, 128, 32, 32]         --
│    └─Empty: 2-41                       [16, 128, 32, 32]         --
│    └─Empty: 2-42                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-43          --                        --
│    └─Empty: 2-2335                     [16, 128, 32, 32]         --
│    └─Empty: 2-2336                     [16, 128, 32, 32]         --
│    └─One: 2-46                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-2358                      [16, 128, 32, 32]         --
│    └─Conv2d: 2-48                      --                        16,512
│    └─BatchNorm2d: 2-2356               [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-50                 --                        --
│    └─Empty: 2-51                       [128, 128, 3, 3]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-2357                    [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-53                       [128, 128, 3, 3]          --
│    └─Empty: 2-54                       [128]                     --
│    └─Empty: 2-55                       [128]                     --
│    └─BatchNorm2d: 2-56                 [16, 128, 32, 32]         --
│    └─Scaler: 2-57                      [16, 128, 32, 32]         --
│    └─ReLU: 2-58                        [16, 128, 32, 32]         --
│    └─Empty: 2-59                       [16, 128, 32, 32]         --
│    └─Clamp: 2-60                       [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-5                 [16, 128, 32, 32]         16,518
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 32, 32]         (recursive)
│    └─ReLU: 2-2373                      [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-2361                 [16, 128, 32, 32]         --
│    └─Conv2d: 2-63                      --                        147,584
│    └─BatchNorm2d: 2-2371               [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2372                    [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-68                 --                        --
│    └─Empty: 2-69                       [128, 128, 1, 1]          --
│    └─Empty: 2-70                       [128, 128, 1, 1]          --
│    └─Empty: 2-71                       [128]                     --
│    └─Empty: 2-72                       [128]                     --
│    └─BatchNorm2d: 2-73                 [16, 128, 32, 32]         --
│    └─Scaler: 2-74                      [16, 128, 32, 32]         --
│    └─ReLU: 2-75                        [16, 128, 32, 32]         --
│    └─Empty: 2-76                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-2388                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-2376                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-79                      --                        147,584
│    └─BatchNorm2d: 2-2386               [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-81                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-8          [16, 128, 32, 32]         131,078
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2387                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─MaxPool2d: 2-83                   [16, 128, 32, 32]         --
│    └─Empty: 2-84                       [16, 128, 32, 32]         --
│    └─Empty: 2-85                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-86          --                        --
│    └─One: 2-87                         [1]                       --
│    └─OutputScale: 2-88                 --                        --
│    └─Empty: 2-89                       [128, 128, 3, 3]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-2377                     [16, 128, 16, 16]         --
│    └─Empty: 2-2378                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-92                       [128, 128, 3, 3]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-2400                      [16, 128, 16, 16]         --
│    └─Conv2d: 2-94                      --                        16,512
│    └─BatchNorm2d: 2-2398               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-96                       [128]                     --
│    └─Empty: 2-97                       [128]                     --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-2399                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─BatchNorm2d: 2-99                 [16, 128, 32, 32]         --
│    └─Scaler: 2-100                     [16, 128, 32, 32]         --
│    └─ReLU: 2-101                       [16, 128, 32, 32]         --
│    └─Empty: 2-102                      [16, 128, 32, 32]         --
│    └─Clamp: 2-103                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-104                  [16, 128, 16, 16]         --
│    └─Empty: 2-105                      [16, 128, 16, 16]         --
│    └─Empty: 2-106                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-2415                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-2403                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-109                     --                        147,584
│    └─BatchNorm2d: 2-2413               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputShiftSqueeze: 2-111         --                        --
│    └─One: 2-112                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2414                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-114                --                        --
│    └─Empty: 2-115                      [128, 128, 3, 3]          --
│    └─Empty: 2-116                      [128, 128, 3, 3]          --
│    └─Empty: 2-117                      [128]                     --
│    └─Empty: 2-118                      [128]                     --
│    └─BatchNorm2d: 2-119                [16, 128, 16, 16]         --
│    └─Scaler: 2-120                     [16, 128, 16, 16]         --
│    └─ReLU: 2-121                       [16, 128, 16, 16]         --
│    └─Empty: 2-122                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 128, 8, 8]           (recursive)
│    └─ReLU: 2-2430                      [16, 128, 8, 8]           --
│    └─MaxPool2d: 2-2418                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-125                     --                        147,584
│    └─BatchNorm2d: 2-2428               [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Clamp: 2-127                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-12                [16, 128, 16, 16]         14,454
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2429                    [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-129         --                        --
│    └─One: 2-130                        [1]                       --
│    └─OutputScale: 2-131                --                        --
│    └─Empty: 2-132                      [128, 128, 1, 1]          --
│    └─Empty: 2-133                      [128, 128, 1, 1]          --
│    └─Empty: 2-134                      [128]                     --
│    └─Empty: 2-135                      [128]                     --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-2419                     [16, 128, 8, 8]           --
│    └─Empty: 2-2420                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─BatchNorm2d: 2-138                [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-2442                      [16, 16, 8, 8]            --
│    └─Conv2d: 2-140                     --                        2,064
│    └─BatchNorm2d: 2-2440               [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-142                     [16, 128, 16, 16]         --
│    └─ReLU: 2-143                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-2441                    [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-145                      [16, 128, 16, 16]         --
│    └─Clamp: 2-146                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-147                  [16, 128, 16, 16]         --
│    └─Empty: 2-148                      [16, 128, 16, 16]         --
│    └─Empty: 2-149                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-150         --                        --
│    └─One: 2-151                        [1]                       --
│    └─OutputScale: 2-152                --                        --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 16, 8, 8]            (recursive)
│    └─ReLU: 2-2457                      [16, 16, 8, 8]            --
│    └─MaxPool2d: 2-2445                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-155                     --                        18,448
│    └─BatchNorm2d: 2-2455               [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-157                      [128, 128, 3, 3]          --
│    └─Empty: 2-158                      [128, 128, 3, 3]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-2456                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-160                      [128]                     --
│    └─Empty: 2-161                      [128]                     --
│    └─BatchNorm2d: 2-162                [16, 128, 16, 16]         --
│    └─Scaler: 2-163                     [16, 128, 16, 16]         --
│    └─ReLU: 2-164                       [16, 128, 16, 16]         --
│    └─Empty: 2-165                      [16, 128, 16, 16]         --
│    └─Clamp: 2-166                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-167                  [16, 128, 8, 8]           --
│    └─Empty: 2-168                      [16, 128, 8, 8]           --
│    └─Empty: 2-169                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-170         --                        --
│    └─One: 2-171                        [1]                       --
│    └─OutputScale: 2-172                --                        --
├─Linear: 1                              --                        --
│    └─Scaler: 2-173                     --                        --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-174                      [128, 128, 3, 3]          --
│    └─Empty: 2-175                      [128, 128, 3, 3]          --
│    └─Empty: 2-176                      [128]                     --
│    └─Empty: 2-177                      [128]                     --
│    └─BatchNorm2d: 2-178                [16, 128, 8, 8]           --
│    └─Scaler: 2-179                     [16, 128, 8, 8]           --
│    └─ReLU: 2-180                       [16, 128, 8, 8]           --
│    └─Empty: 2-181                      [16, 128, 8, 8]           --
│    └─Clamp: 2-182                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-16                [16, 16, 8, 8]            2,070
│    └─OutputShiftSqueeze: 2-183         --                        --
│    └─One: 2-184                        [1]                       --
│    └─OutputScale: 2-185                --                        --
│    └─Empty: 2-186                      [16, 128, 1, 1]           --
│    └─Empty: 2-187                      [16, 128, 1, 1]           --
│    └─Empty: 2-188                      [16]                      --
│    └─Empty: 2-189                      [16]                      --
│    └─BatchNorm2d: 2-190                [16, 16, 8, 8]            --
│    └─Scaler: 2-191                     [16, 16, 8, 8]            --
│    └─ReLU: 2-192                       [16, 16, 8, 8]            --
│    └─Empty: 2-193                      [16, 16, 8, 8]            --
│    └─Clamp: 2-194                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 16, 8, 8]            18,454
│    └─MaxPool2d: 2-195                  [16, 128, 8, 8]           --
│    └─Empty: 2-196                      [16, 128, 8, 8]           --
│    └─Empty: 2-197                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-198         --                        --
│    └─One: 2-199                        [1]                       --
│    └─OutputScale: 2-200                --                        --
│    └─Empty: 2-201                      [16, 128, 3, 3]           --
│    └─Empty: 2-202                      [16, 128, 3, 3]           --
│    └─Empty: 2-203                      [16]                      --
│    └─Empty: 2-204                      [16]                      --
│    └─BatchNorm2d: 2-205                [16, 16, 8, 8]            --
│    └─Scaler: 2-206                     [16, 16, 8, 8]            --
│    └─ReLU: 2-207                       [16, 16, 8, 8]            --
│    └─Empty: 2-208                      [16, 16, 8, 8]            --
│    └─Clamp: 2-209                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-18                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-210         --                        --
│    └─One: 2-211                        [1]                       --
│    └─OutputScale: 2-212                --                        --
│    └─Empty: 2-213                      [128, 48, 1, 1]           --
│    └─Empty: 2-214                      [128, 48, 1, 1]           --
│    └─Empty: 2-215                      [128]                     --
│    └─Empty: 2-216                      [128]                     --
│    └─BatchNorm2d: 2-217                [16, 128, 64, 64]         --
│    └─Scaler: 2-218                     [16, 128, 64, 64]         --
│    └─ReLU: 2-219                       [16, 128, 64, 64]         --
│    └─Empty: 2-220                      [16, 128, 64, 64]         --
│    └─Clamp: 2-221                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-19                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-222         --                        --
│    └─One: 2-223                        [1]                       --
│    └─OutputScale: 2-224                --                        --
│    └─Empty: 2-225                      [128, 128, 3, 3]          --
│    └─Empty: 2-226                      [128, 128, 3, 3]          --
│    └─Empty: 2-227                      [128]                     --
│    └─Empty: 2-228                      [128]                     --
│    └─BatchNorm2d: 2-229                [16, 128, 64, 64]         --
│    └─Scaler: 2-230                     [16, 128, 64, 64]         --
│    └─ReLU: 2-231                       [16, 128, 64, 64]         --
│    └─Empty: 2-232                      [16, 128, 64, 64]         --
│    └─Clamp: 2-233                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-20         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-234                  [16, 128, 32, 32]         --
│    └─Empty: 2-235                      [16, 128, 32, 32]         --
│    └─Empty: 2-236                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-237         --                        --
│    └─One: 2-238                        [1]                       --
│    └─OutputScale: 2-239                --                        --
│    └─Empty: 2-240                      [128, 128, 3, 3]          --
│    └─Empty: 2-241                      [128, 128, 3, 3]          --
│    └─Empty: 2-242                      [128]                     --
│    └─Empty: 2-243                      [128]                     --
│    └─BatchNorm2d: 2-244                [16, 128, 32, 32]         --
│    └─Scaler: 2-245                     [16, 128, 32, 32]         --
│    └─ReLU: 2-246                       [16, 128, 32, 32]         --
│    └─Empty: 2-247                      [16, 128, 32, 32]         --
│    └─Clamp: 2-248                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-21                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-249         --                        --
│    └─One: 2-250                        [1]                       --
│    └─OutputScale: 2-251                --                        --
│    └─Empty: 2-252                      [128, 128, 1, 1]          --
│    └─Empty: 2-253                      [128, 128, 1, 1]          --
│    └─Empty: 2-254                      [128]                     --
│    └─Empty: 2-255                      [128]                     --
│    └─BatchNorm2d: 2-256                [16, 128, 32, 32]         --
│    └─Scaler: 2-257                     [16, 128, 32, 32]         --
│    └─ReLU: 2-258                       [16, 128, 32, 32]         --
│    └─Empty: 2-259                      [16, 128, 32, 32]         --
│    └─Clamp: 2-260                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-261                  [16, 128, 32, 32]         --
│    └─Empty: 2-262                      [16, 128, 32, 32]         --
│    └─Empty: 2-263                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-264         --                        --
│    └─One: 2-265                        [1]                       --
│    └─OutputScale: 2-266                --                        --
│    └─Empty: 2-267                      [128, 128, 3, 3]          --
│    └─Empty: 2-268                      [128, 128, 3, 3]          --
│    └─Empty: 2-269                      [128]                     --
│    └─Empty: 2-270                      [128]                     --
│    └─BatchNorm2d: 2-271                [16, 128, 32, 32]         --
│    └─Scaler: 2-272                     [16, 128, 32, 32]         --
│    └─ReLU: 2-273                       [16, 128, 32, 32]         --
│    └─Empty: 2-274                      [16, 128, 32, 32]         --
│    └─Clamp: 2-275                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-276                  [16, 128, 16, 16]         --
│    └─Empty: 2-277                      [16, 128, 16, 16]         --
│    └─Empty: 2-278                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-279         --                        --
│    └─One: 2-280                        [1]                       --
│    └─OutputScale: 2-281                --                        --
│    └─Empty: 2-282                      [128, 128, 3, 3]          --
│    └─Empty: 2-283                      [128, 128, 3, 3]          --
│    └─Empty: 2-284                      [128]                     --
│    └─Empty: 2-285                      [128]                     --
│    └─BatchNorm2d: 2-286                [16, 128, 16, 16]         --
│    └─Scaler: 2-287                     [16, 128, 16, 16]         --
│    └─ReLU: 2-288                       [16, 128, 16, 16]         --
│    └─Empty: 2-289                      [16, 128, 16, 16]         --
│    └─Clamp: 2-290                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-24                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-291         --                        --
│    └─One: 2-292                        [1]                       --
│    └─OutputScale: 2-293                --                        --
│    └─Empty: 2-294                      [128, 128, 1, 1]          --
│    └─Empty: 2-295                      [128, 128, 1, 1]          --
│    └─Empty: 2-296                      [128]                     --
│    └─Empty: 2-297                      [128]                     --
│    └─BatchNorm2d: 2-298                [16, 128, 16, 16]         --
│    └─Scaler: 2-299                     [16, 128, 16, 16]         --
│    └─ReLU: 2-300                       [16, 128, 16, 16]         --
│    └─Empty: 2-301                      [16, 128, 16, 16]         --
│    └─Clamp: 2-302                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-303                  [16, 128, 16, 16]         --
│    └─Empty: 2-304                      [16, 128, 16, 16]         --
│    └─Empty: 2-305                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-306         --                        --
│    └─One: 2-307                        [1]                       --
│    └─OutputScale: 2-308                --                        --
│    └─Empty: 2-309                      [128, 128, 3, 3]          --
│    └─Empty: 2-310                      [128, 128, 3, 3]          --
│    └─Empty: 2-311                      [128]                     --
│    └─Empty: 2-312                      [128]                     --
│    └─BatchNorm2d: 2-313                [16, 128, 16, 16]         --
│    └─Scaler: 2-314                     [16, 128, 16, 16]         --
│    └─ReLU: 2-315                       [16, 128, 16, 16]         --
│    └─Empty: 2-316                      [16, 128, 16, 16]         --
│    └─Clamp: 2-317                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-318                  [16, 128, 8, 8]           --
│    └─Empty: 2-319                      [16, 128, 8, 8]           --
│    └─Empty: 2-320                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-321         --                        --
│    └─One: 2-322                        [1]                       --
│    └─OutputScale: 2-323                --                        --
│    └─Empty: 2-324                      [128, 128, 3, 3]          --
│    └─Empty: 2-325                      [128, 128, 3, 3]          --
│    └─Empty: 2-326                      [128]                     --
│    └─Empty: 2-327                      [128]                     --
│    └─BatchNorm2d: 2-328                [16, 128, 8, 8]           --
│    └─Scaler: 2-329                     [16, 128, 8, 8]           --
│    └─ReLU: 2-330                       [16, 128, 8, 8]           --
│    └─Empty: 2-331                      [16, 128, 8, 8]           --
│    └─Clamp: 2-332                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-27                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-333         --                        --
│    └─One: 2-334                        [1]                       --
│    └─OutputScale: 2-335                --                        --
│    └─Empty: 2-336                      [16, 128, 1, 1]           --
│    └─Empty: 2-337                      [16, 128, 1, 1]           --
│    └─Empty: 2-338                      [16]                      --
│    └─Empty: 2-339                      [16]                      --
│    └─BatchNorm2d: 2-340                [16, 16, 8, 8]            --
│    └─Scaler: 2-341                     [16, 16, 8, 8]            --
│    └─ReLU: 2-342                       [16, 16, 8, 8]            --
│    └─Empty: 2-343                      [16, 16, 8, 8]            --
│    └─Clamp: 2-344                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-345                  [16, 128, 8, 8]           --
│    └─Empty: 2-346                      [16, 128, 8, 8]           --
│    └─Empty: 2-347                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-348         --                        --
│    └─One: 2-349                        [1]                       --
│    └─OutputScale: 2-350                --                        --
│    └─Empty: 2-351                      [16, 128, 3, 3]           --
│    └─Empty: 2-352                      [16, 128, 3, 3]           --
│    └─Empty: 2-353                      [16]                      --
│    └─Empty: 2-354                      [16]                      --
│    └─BatchNorm2d: 2-355                [16, 16, 8, 8]            --
│    └─Scaler: 2-356                     [16, 16, 8, 8]            --
│    └─ReLU: 2-357                       [16, 16, 8, 8]            --
│    └─Empty: 2-358                      [16, 16, 8, 8]            --
│    └─Clamp: 2-359                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-29                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-360         --                        --
│    └─One: 2-361                        [1]                       --
│    └─OutputScale: 2-362                --                        --
│    └─Empty: 2-363                      [128, 48, 1, 1]           --
│    └─Empty: 2-364                      [128, 48, 1, 1]           --
│    └─Empty: 2-365                      [128]                     --
│    └─Empty: 2-366                      [128]                     --
│    └─BatchNorm2d: 2-367                [16, 128, 64, 64]         --
│    └─Scaler: 2-368                     [16, 128, 64, 64]         --
│    └─ReLU: 2-369                       [16, 128, 64, 64]         --
│    └─Empty: 2-370                      [16, 128, 64, 64]         --
│    └─Clamp: 2-371                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-30                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-372         --                        --
│    └─One: 2-373                        [1]                       --
│    └─OutputScale: 2-374                --                        --
│    └─Empty: 2-375                      [128, 128, 3, 3]          --
│    └─Empty: 2-376                      [128, 128, 3, 3]          --
│    └─Empty: 2-377                      [128]                     --
│    └─Empty: 2-378                      [128]                     --
│    └─BatchNorm2d: 2-379                [16, 128, 64, 64]         --
│    └─Scaler: 2-380                     [16, 128, 64, 64]         --
│    └─ReLU: 2-381                       [16, 128, 64, 64]         --
│    └─Empty: 2-382                      [16, 128, 64, 64]         --
│    └─Clamp: 2-383                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-384                  [16, 128, 32, 32]         --
│    └─Empty: 2-385                      [16, 128, 32, 32]         --
│    └─Empty: 2-386                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-387         --                        --
│    └─One: 2-388                        [1]                       --
│    └─OutputScale: 2-389                --                        --
│    └─Empty: 2-390                      [128, 128, 3, 3]          --
│    └─Empty: 2-391                      [128, 128, 3, 3]          --
│    └─Empty: 2-392                      [128]                     --
│    └─Empty: 2-393                      [128]                     --
│    └─BatchNorm2d: 2-394                [16, 128, 32, 32]         --
│    └─Scaler: 2-395                     [16, 128, 32, 32]         --
│    └─ReLU: 2-396                       [16, 128, 32, 32]         --
│    └─Empty: 2-397                      [16, 128, 32, 32]         --
│    └─Clamp: 2-398                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-32                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-399         --                        --
│    └─One: 2-400                        [1]                       --
│    └─OutputScale: 2-401                --                        --
│    └─Empty: 2-402                      [128, 128, 1, 1]          --
│    └─Empty: 2-403                      [128, 128, 1, 1]          --
│    └─Empty: 2-404                      [128]                     --
│    └─Empty: 2-405                      [128]                     --
│    └─BatchNorm2d: 2-406                [16, 128, 32, 32]         --
│    └─Scaler: 2-407                     [16, 128, 32, 32]         --
│    └─ReLU: 2-408                       [16, 128, 32, 32]         --
│    └─Empty: 2-409                      [16, 128, 32, 32]         --
│    └─Clamp: 2-410                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-411                  [16, 128, 32, 32]         --
│    └─Empty: 2-412                      [16, 128, 32, 32]         --
│    └─Empty: 2-413                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-414         --                        --
│    └─One: 2-415                        [1]                       --
│    └─OutputScale: 2-416                --                        --
│    └─Empty: 2-417                      [128, 128, 3, 3]          --
│    └─Empty: 2-418                      [128, 128, 3, 3]          --
│    └─Empty: 2-419                      [128]                     --
│    └─Empty: 2-420                      [128]                     --
│    └─BatchNorm2d: 2-421                [16, 128, 32, 32]         --
│    └─Scaler: 2-422                     [16, 128, 32, 32]         --
│    └─ReLU: 2-423                       [16, 128, 32, 32]         --
│    └─Empty: 2-424                      [16, 128, 32, 32]         --
│    └─Clamp: 2-425                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-426                  [16, 128, 16, 16]         --
│    └─Empty: 2-427                      [16, 128, 16, 16]         --
│    └─Empty: 2-428                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-429         --                        --
│    └─One: 2-430                        [1]                       --
│    └─OutputScale: 2-431                --                        --
│    └─Empty: 2-432                      [128, 128, 3, 3]          --
│    └─Empty: 2-433                      [128, 128, 3, 3]          --
│    └─Empty: 2-434                      [128]                     --
│    └─Empty: 2-435                      [128]                     --
│    └─BatchNorm2d: 2-436                [16, 128, 16, 16]         --
│    └─Scaler: 2-437                     [16, 128, 16, 16]         --
│    └─ReLU: 2-438                       [16, 128, 16, 16]         --
│    └─Empty: 2-439                      [16, 128, 16, 16]         --
│    └─Clamp: 2-440                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-35                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-441         --                        --
│    └─One: 2-442                        [1]                       --
│    └─OutputScale: 2-443                --                        --
│    └─Empty: 2-444                      [128, 128, 1, 1]          --
│    └─Empty: 2-445                      [128, 128, 1, 1]          --
│    └─Empty: 2-446                      [128]                     --
│    └─Empty: 2-447                      [128]                     --
│    └─BatchNorm2d: 2-448                [16, 128, 16, 16]         --
│    └─Scaler: 2-449                     [16, 128, 16, 16]         --
│    └─ReLU: 2-450                       [16, 128, 16, 16]         --
│    └─Empty: 2-451                      [16, 128, 16, 16]         --
│    └─Clamp: 2-452                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-36         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-453                  [16, 128, 16, 16]         --
│    └─Empty: 2-454                      [16, 128, 16, 16]         --
│    └─Empty: 2-455                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-456         --                        --
│    └─One: 2-457                        [1]                       --
│    └─OutputScale: 2-458                --                        --
│    └─Empty: 2-459                      [128, 128, 3, 3]          --
│    └─Empty: 2-460                      [128, 128, 3, 3]          --
│    └─Empty: 2-461                      [128]                     --
│    └─Empty: 2-462                      [128]                     --
│    └─BatchNorm2d: 2-463                [16, 128, 16, 16]         --
│    └─Scaler: 2-464                     [16, 128, 16, 16]         --
│    └─ReLU: 2-465                       [16, 128, 16, 16]         --
│    └─Empty: 2-466                      [16, 128, 16, 16]         --
│    └─Clamp: 2-467                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-37         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-468                  [16, 128, 8, 8]           --
│    └─Empty: 2-469                      [16, 128, 8, 8]           --
│    └─Empty: 2-470                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-471         --                        --
│    └─One: 2-472                        [1]                       --
│    └─OutputScale: 2-473                --                        --
│    └─Empty: 2-474                      [128, 128, 3, 3]          --
│    └─Empty: 2-475                      [128, 128, 3, 3]          --
│    └─Empty: 2-476                      [128]                     --
│    └─Empty: 2-477                      [128]                     --
│    └─BatchNorm2d: 2-478                [16, 128, 8, 8]           --
│    └─Scaler: 2-479                     [16, 128, 8, 8]           --
│    └─ReLU: 2-480                       [16, 128, 8, 8]           --
│    └─Empty: 2-481                      [16, 128, 8, 8]           --
│    └─Clamp: 2-482                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-38                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-483         --                        --
│    └─One: 2-484                        [1]                       --
│    └─OutputScale: 2-485                --                        --
│    └─Empty: 2-486                      [16, 128, 1, 1]           --
│    └─Empty: 2-487                      [16, 128, 1, 1]           --
│    └─Empty: 2-488                      [16]                      --
│    └─Empty: 2-489                      [16]                      --
│    └─BatchNorm2d: 2-490                [16, 16, 8, 8]            --
│    └─Scaler: 2-491                     [16, 16, 8, 8]            --
│    └─ReLU: 2-492                       [16, 16, 8, 8]            --
│    └─Empty: 2-493                      [16, 16, 8, 8]            --
│    └─Clamp: 2-494                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-495                  [16, 128, 8, 8]           --
│    └─Empty: 2-496                      [16, 128, 8, 8]           --
│    └─Empty: 2-497                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-498         --                        --
│    └─One: 2-499                        [1]                       --
│    └─OutputScale: 2-500                --                        --
│    └─Empty: 2-501                      [16, 128, 3, 3]           --
│    └─Empty: 2-502                      [16, 128, 3, 3]           --
│    └─Empty: 2-503                      [16]                      --
│    └─Empty: 2-504                      [16]                      --
│    └─BatchNorm2d: 2-505                [16, 16, 8, 8]            --
│    └─Scaler: 2-506                     [16, 16, 8, 8]            --
│    └─ReLU: 2-507                       [16, 16, 8, 8]            --
│    └─Empty: 2-508                      [16, 16, 8, 8]            --
│    └─Clamp: 2-509                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-40                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-510         --                        --
│    └─One: 2-511                        [1]                       --
│    └─OutputScale: 2-512                --                        --
│    └─Empty: 2-513                      [128, 48, 1, 1]           --
│    └─Empty: 2-514                      [128, 48, 1, 1]           --
│    └─Empty: 2-515                      [128]                     --
│    └─Empty: 2-516                      [128]                     --
│    └─BatchNorm2d: 2-517                [16, 128, 64, 64]         --
│    └─Scaler: 2-518                     [16, 128, 64, 64]         --
│    └─ReLU: 2-519                       [16, 128, 64, 64]         --
│    └─Empty: 2-520                      [16, 128, 64, 64]         --
│    └─Clamp: 2-521                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-41                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-522         --                        --
│    └─One: 2-523                        [1]                       --
│    └─OutputScale: 2-524                --                        --
│    └─Empty: 2-525                      [128, 128, 3, 3]          --
│    └─Empty: 2-526                      [128, 128, 3, 3]          --
│    └─Empty: 2-527                      [128]                     --
│    └─Empty: 2-528                      [128]                     --
│    └─BatchNorm2d: 2-529                [16, 128, 64, 64]         --
│    └─Scaler: 2-530                     [16, 128, 64, 64]         --
│    └─ReLU: 2-531                       [16, 128, 64, 64]         --
│    └─Empty: 2-532                      [16, 128, 64, 64]         --
│    └─Clamp: 2-533                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-42         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-534                  [16, 128, 32, 32]         --
│    └─Empty: 2-535                      [16, 128, 32, 32]         --
│    └─Empty: 2-536                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-537         --                        --
│    └─One: 2-538                        [1]                       --
│    └─OutputScale: 2-539                --                        --
│    └─Empty: 2-540                      [128, 128, 3, 3]          --
│    └─Empty: 2-541                      [128, 128, 3, 3]          --
│    └─Empty: 2-542                      [128]                     --
│    └─Empty: 2-543                      [128]                     --
│    └─BatchNorm2d: 2-544                [16, 128, 32, 32]         --
│    └─Scaler: 2-545                     [16, 128, 32, 32]         --
│    └─ReLU: 2-546                       [16, 128, 32, 32]         --
│    └─Empty: 2-547                      [16, 128, 32, 32]         --
│    └─Clamp: 2-548                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-43                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-549         --                        --
│    └─One: 2-550                        [1]                       --
│    └─OutputScale: 2-551                --                        --
│    └─Empty: 2-552                      [128, 128, 1, 1]          --
│    └─Empty: 2-553                      [128, 128, 1, 1]          --
│    └─Empty: 2-554                      [128]                     --
│    └─Empty: 2-555                      [128]                     --
│    └─BatchNorm2d: 2-556                [16, 128, 32, 32]         --
│    └─Scaler: 2-557                     [16, 128, 32, 32]         --
│    └─ReLU: 2-558                       [16, 128, 32, 32]         --
│    └─Empty: 2-559                      [16, 128, 32, 32]         --
│    └─Clamp: 2-560                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-44         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-561                  [16, 128, 32, 32]         --
│    └─Empty: 2-562                      [16, 128, 32, 32]         --
│    └─Empty: 2-563                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-564         --                        --
│    └─One: 2-565                        [1]                       --
│    └─OutputScale: 2-566                --                        --
│    └─Empty: 2-567                      [128, 128, 3, 3]          --
│    └─Empty: 2-568                      [128, 128, 3, 3]          --
│    └─Empty: 2-569                      [128]                     --
│    └─Empty: 2-570                      [128]                     --
│    └─BatchNorm2d: 2-571                [16, 128, 32, 32]         --
│    └─Scaler: 2-572                     [16, 128, 32, 32]         --
│    └─ReLU: 2-573                       [16, 128, 32, 32]         --
│    └─Empty: 2-574                      [16, 128, 32, 32]         --
│    └─Clamp: 2-575                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-576                  [16, 128, 16, 16]         --
│    └─Empty: 2-577                      [16, 128, 16, 16]         --
│    └─Empty: 2-578                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-579         --                        --
│    └─One: 2-580                        [1]                       --
│    └─OutputScale: 2-581                --                        --
│    └─Empty: 2-582                      [128, 128, 3, 3]          --
│    └─Empty: 2-583                      [128, 128, 3, 3]          --
│    └─Empty: 2-584                      [128]                     --
│    └─Empty: 2-585                      [128]                     --
│    └─BatchNorm2d: 2-586                [16, 128, 16, 16]         --
│    └─Scaler: 2-587                     [16, 128, 16, 16]         --
│    └─ReLU: 2-588                       [16, 128, 16, 16]         --
│    └─Empty: 2-589                      [16, 128, 16, 16]         --
│    └─Clamp: 2-590                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-46                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-591         --                        --
│    └─One: 2-592                        [1]                       --
│    └─OutputScale: 2-593                --                        --
│    └─Empty: 2-594                      [128, 128, 1, 1]          --
│    └─Empty: 2-595                      [128, 128, 1, 1]          --
│    └─Empty: 2-596                      [128]                     --
│    └─Empty: 2-597                      [128]                     --
│    └─BatchNorm2d: 2-598                [16, 128, 16, 16]         --
│    └─Scaler: 2-599                     [16, 128, 16, 16]         --
│    └─ReLU: 2-600                       [16, 128, 16, 16]         --
│    └─Empty: 2-601                      [16, 128, 16, 16]         --
│    └─Clamp: 2-602                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-603                  [16, 128, 16, 16]         --
│    └─Empty: 2-604                      [16, 128, 16, 16]         --
│    └─Empty: 2-605                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-606         --                        --
│    └─One: 2-607                        [1]                       --
│    └─OutputScale: 2-608                --                        --
│    └─Empty: 2-609                      [128, 128, 3, 3]          --
│    └─Empty: 2-610                      [128, 128, 3, 3]          --
│    └─Empty: 2-611                      [128]                     --
│    └─Empty: 2-612                      [128]                     --
│    └─BatchNorm2d: 2-613                [16, 128, 16, 16]         --
│    └─Scaler: 2-614                     [16, 128, 16, 16]         --
│    └─ReLU: 2-615                       [16, 128, 16, 16]         --
│    └─Empty: 2-616                      [16, 128, 16, 16]         --
│    └─Clamp: 2-617                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-618                  [16, 128, 8, 8]           --
│    └─Empty: 2-619                      [16, 128, 8, 8]           --
│    └─Empty: 2-620                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-621         --                        --
│    └─One: 2-622                        [1]                       --
│    └─OutputScale: 2-623                --                        --
│    └─Empty: 2-624                      [128, 128, 3, 3]          --
│    └─Empty: 2-625                      [128, 128, 3, 3]          --
│    └─Empty: 2-626                      [128]                     --
│    └─Empty: 2-627                      [128]                     --
│    └─BatchNorm2d: 2-628                [16, 128, 8, 8]           --
│    └─Scaler: 2-629                     [16, 128, 8, 8]           --
│    └─ReLU: 2-630                       [16, 128, 8, 8]           --
│    └─Empty: 2-631                      [16, 128, 8, 8]           --
│    └─Clamp: 2-632                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-49                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-633         --                        --
│    └─One: 2-634                        [1]                       --
│    └─OutputScale: 2-635                --                        --
│    └─Empty: 2-636                      [16, 128, 1, 1]           --
│    └─Empty: 2-637                      [16, 128, 1, 1]           --
│    └─Empty: 2-638                      [16]                      --
│    └─Empty: 2-639                      [16]                      --
│    └─BatchNorm2d: 2-640                [16, 16, 8, 8]            --
│    └─Scaler: 2-641                     [16, 16, 8, 8]            --
│    └─ReLU: 2-642                       [16, 16, 8, 8]            --
│    └─Empty: 2-643                      [16, 16, 8, 8]            --
│    └─Clamp: 2-644                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-50         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-645                  [16, 128, 8, 8]           --
│    └─Empty: 2-646                      [16, 128, 8, 8]           --
│    └─Empty: 2-647                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-648         --                        --
│    └─One: 2-649                        [1]                       --
│    └─OutputScale: 2-650                --                        --
│    └─Empty: 2-651                      [16, 128, 3, 3]           --
│    └─Empty: 2-652                      [16, 128, 3, 3]           --
│    └─Empty: 2-653                      [16]                      --
│    └─Empty: 2-654                      [16]                      --
│    └─BatchNorm2d: 2-655                [16, 16, 8, 8]            --
│    └─Scaler: 2-656                     [16, 16, 8, 8]            --
│    └─ReLU: 2-657                       [16, 16, 8, 8]            --
│    └─Empty: 2-658                      [16, 16, 8, 8]            --
│    └─Clamp: 2-659                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-51                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-660         --                        --
│    └─One: 2-661                        [1]                       --
│    └─OutputScale: 2-662                --                        --
│    └─Empty: 2-663                      [128, 48, 1, 1]           --
│    └─Empty: 2-664                      [128, 48, 1, 1]           --
│    └─Empty: 2-665                      [128]                     --
│    └─Empty: 2-666                      [128]                     --
│    └─BatchNorm2d: 2-667                [16, 128, 64, 64]         --
│    └─Scaler: 2-668                     [16, 128, 64, 64]         --
│    └─ReLU: 2-669                       [16, 128, 64, 64]         --
│    └─Empty: 2-670                      [16, 128, 64, 64]         --
│    └─Clamp: 2-671                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-52                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-672         --                        --
│    └─One: 2-673                        [1]                       --
│    └─OutputScale: 2-674                --                        --
│    └─Empty: 2-675                      [128, 128, 3, 3]          --
│    └─Empty: 2-676                      [128, 128, 3, 3]          --
│    └─Empty: 2-677                      [128]                     --
│    └─Empty: 2-678                      [128]                     --
│    └─BatchNorm2d: 2-679                [16, 128, 64, 64]         --
│    └─Scaler: 2-680                     [16, 128, 64, 64]         --
│    └─ReLU: 2-681                       [16, 128, 64, 64]         --
│    └─Empty: 2-682                      [16, 128, 64, 64]         --
│    └─Clamp: 2-683                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-53         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-684                  [16, 128, 32, 32]         --
│    └─Empty: 2-685                      [16, 128, 32, 32]         --
│    └─Empty: 2-686                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-687         --                        --
│    └─One: 2-688                        [1]                       --
│    └─OutputScale: 2-689                --                        --
│    └─Empty: 2-690                      [128, 128, 3, 3]          --
│    └─Empty: 2-691                      [128, 128, 3, 3]          --
│    └─Empty: 2-692                      [128]                     --
│    └─Empty: 2-693                      [128]                     --
│    └─BatchNorm2d: 2-694                [16, 128, 32, 32]         --
│    └─Scaler: 2-695                     [16, 128, 32, 32]         --
│    └─ReLU: 2-696                       [16, 128, 32, 32]         --
│    └─Empty: 2-697                      [16, 128, 32, 32]         --
│    └─Clamp: 2-698                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-54                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-699         --                        --
│    └─One: 2-700                        [1]                       --
│    └─OutputScale: 2-701                --                        --
│    └─Empty: 2-702                      [128, 128, 1, 1]          --
│    └─Empty: 2-703                      [128, 128, 1, 1]          --
│    └─Empty: 2-704                      [128]                     --
│    └─Empty: 2-705                      [128]                     --
│    └─BatchNorm2d: 2-706                [16, 128, 32, 32]         --
│    └─Scaler: 2-707                     [16, 128, 32, 32]         --
│    └─ReLU: 2-708                       [16, 128, 32, 32]         --
│    └─Empty: 2-709                      [16, 128, 32, 32]         --
│    └─Clamp: 2-710                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-711                  [16, 128, 32, 32]         --
│    └─Empty: 2-712                      [16, 128, 32, 32]         --
│    └─Empty: 2-713                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-714         --                        --
│    └─One: 2-715                        [1]                       --
│    └─OutputScale: 2-716                --                        --
│    └─Empty: 2-717                      [128, 128, 3, 3]          --
│    └─Empty: 2-718                      [128, 128, 3, 3]          --
│    └─Empty: 2-719                      [128]                     --
│    └─Empty: 2-720                      [128]                     --
│    └─BatchNorm2d: 2-721                [16, 128, 32, 32]         --
│    └─Scaler: 2-722                     [16, 128, 32, 32]         --
│    └─ReLU: 2-723                       [16, 128, 32, 32]         --
│    └─Empty: 2-724                      [16, 128, 32, 32]         --
│    └─Clamp: 2-725                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-726                  [16, 128, 16, 16]         --
│    └─Empty: 2-727                      [16, 128, 16, 16]         --
│    └─Empty: 2-728                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-729         --                        --
│    └─One: 2-730                        [1]                       --
│    └─OutputScale: 2-731                --                        --
│    └─Empty: 2-732                      [128, 128, 3, 3]          --
│    └─Empty: 2-733                      [128, 128, 3, 3]          --
│    └─Empty: 2-734                      [128]                     --
│    └─Empty: 2-735                      [128]                     --
│    └─BatchNorm2d: 2-736                [16, 128, 16, 16]         --
│    └─Scaler: 2-737                     [16, 128, 16, 16]         --
│    └─ReLU: 2-738                       [16, 128, 16, 16]         --
│    └─Empty: 2-739                      [16, 128, 16, 16]         --
│    └─Clamp: 2-740                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-57                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-741         --                        --
│    └─One: 2-742                        [1]                       --
│    └─OutputScale: 2-743                --                        --
│    └─Empty: 2-744                      [128, 128, 1, 1]          --
│    └─Empty: 2-745                      [128, 128, 1, 1]          --
│    └─Empty: 2-746                      [128]                     --
│    └─Empty: 2-747                      [128]                     --
│    └─BatchNorm2d: 2-748                [16, 128, 16, 16]         --
│    └─Scaler: 2-749                     [16, 128, 16, 16]         --
│    └─ReLU: 2-750                       [16, 128, 16, 16]         --
│    └─Empty: 2-751                      [16, 128, 16, 16]         --
│    └─Clamp: 2-752                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-753                  [16, 128, 16, 16]         --
│    └─Empty: 2-754                      [16, 128, 16, 16]         --
│    └─Empty: 2-755                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-756         --                        --
│    └─One: 2-757                        [1]                       --
│    └─OutputScale: 2-758                --                        --
│    └─Empty: 2-759                      [128, 128, 3, 3]          --
│    └─Empty: 2-760                      [128, 128, 3, 3]          --
│    └─Empty: 2-761                      [128]                     --
│    └─Empty: 2-762                      [128]                     --
│    └─BatchNorm2d: 2-763                [16, 128, 16, 16]         --
│    └─Scaler: 2-764                     [16, 128, 16, 16]         --
│    └─ReLU: 2-765                       [16, 128, 16, 16]         --
│    └─Empty: 2-766                      [16, 128, 16, 16]         --
│    └─Clamp: 2-767                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-59         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-768                  [16, 128, 8, 8]           --
│    └─Empty: 2-769                      [16, 128, 8, 8]           --
│    └─Empty: 2-770                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-771         --                        --
│    └─One: 2-772                        [1]                       --
│    └─OutputScale: 2-773                --                        --
│    └─Empty: 2-774                      [128, 128, 3, 3]          --
│    └─Empty: 2-775                      [128, 128, 3, 3]          --
│    └─Empty: 2-776                      [128]                     --
│    └─Empty: 2-777                      [128]                     --
│    └─BatchNorm2d: 2-778                [16, 128, 8, 8]           --
│    └─Scaler: 2-779                     [16, 128, 8, 8]           --
│    └─ReLU: 2-780                       [16, 128, 8, 8]           --
│    └─Empty: 2-781                      [16, 128, 8, 8]           --
│    └─Clamp: 2-782                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-60                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [16, 128, 1, 1]           --
│    └─Empty: 2-787                      [16, 128, 1, 1]           --
│    └─Empty: 2-788                      [16]                      --
│    └─Empty: 2-789                      [16]                      --
│    └─BatchNorm2d: 2-790                [16, 16, 8, 8]            --
│    └─Scaler: 2-791                     [16, 16, 8, 8]            --
│    └─ReLU: 2-792                       [16, 16, 8, 8]            --
│    └─Empty: 2-793                      [16, 16, 8, 8]            --
│    └─Clamp: 2-794                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-61         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-795                  [16, 128, 8, 8]           --
│    └─Empty: 2-796                      [16, 128, 8, 8]           --
│    └─Empty: 2-797                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-798         --                        --
│    └─One: 2-799                        [1]                       --
│    └─OutputScale: 2-800                --                        --
│    └─Empty: 2-801                      [16, 128, 3, 3]           --
│    └─Empty: 2-802                      [16, 128, 3, 3]           --
│    └─Empty: 2-803                      [16]                      --
│    └─Empty: 2-804                      [16]                      --
│    └─BatchNorm2d: 2-805                [16, 16, 8, 8]            --
│    └─Scaler: 2-806                     [16, 16, 8, 8]            --
│    └─ReLU: 2-807                       [16, 16, 8, 8]            --
│    └─Empty: 2-808                      [16, 16, 8, 8]            --
│    └─Clamp: 2-809                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-62                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [128, 48, 1, 1]           --
│    └─Empty: 2-814                      [128, 48, 1, 1]           --
│    └─Empty: 2-815                      [128]                     --
│    └─Empty: 2-816                      [128]                     --
│    └─BatchNorm2d: 2-817                [16, 128, 64, 64]         --
│    └─Scaler: 2-818                     [16, 128, 64, 64]         --
│    └─ReLU: 2-819                       [16, 128, 64, 64]         --
│    └─Empty: 2-820                      [16, 128, 64, 64]         --
│    └─Clamp: 2-821                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-63                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-822         --                        --
│    └─One: 2-823                        [1]                       --
│    └─OutputScale: 2-824                --                        --
│    └─Empty: 2-825                      [128, 128, 3, 3]          --
│    └─Empty: 2-826                      [128, 128, 3, 3]          --
│    └─Empty: 2-827                      [128]                     --
│    └─Empty: 2-828                      [128]                     --
│    └─BatchNorm2d: 2-829                [16, 128, 64, 64]         --
│    └─Scaler: 2-830                     [16, 128, 64, 64]         --
│    └─ReLU: 2-831                       [16, 128, 64, 64]         --
│    └─Empty: 2-832                      [16, 128, 64, 64]         --
│    └─Clamp: 2-833                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-64         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-834                  [16, 128, 32, 32]         --
│    └─Empty: 2-835                      [16, 128, 32, 32]         --
│    └─Empty: 2-836                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-837         --                        --
│    └─One: 2-838                        [1]                       --
│    └─OutputScale: 2-839                --                        --
│    └─Empty: 2-840                      [128, 128, 3, 3]          --
│    └─Empty: 2-841                      [128, 128, 3, 3]          --
│    └─Empty: 2-842                      [128]                     --
│    └─Empty: 2-843                      [128]                     --
│    └─BatchNorm2d: 2-844                [16, 128, 32, 32]         --
│    └─Scaler: 2-845                     [16, 128, 32, 32]         --
│    └─ReLU: 2-846                       [16, 128, 32, 32]         --
│    └─Empty: 2-847                      [16, 128, 32, 32]         --
│    └─Clamp: 2-848                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-65                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-849         --                        --
│    └─One: 2-850                        [1]                       --
│    └─OutputScale: 2-851                --                        --
│    └─Empty: 2-852                      [128, 128, 1, 1]          --
│    └─Empty: 2-853                      [128, 128, 1, 1]          --
│    └─Empty: 2-854                      [128]                     --
│    └─Empty: 2-855                      [128]                     --
│    └─BatchNorm2d: 2-856                [16, 128, 32, 32]         --
│    └─Scaler: 2-857                     [16, 128, 32, 32]         --
│    └─ReLU: 2-858                       [16, 128, 32, 32]         --
│    └─Empty: 2-859                      [16, 128, 32, 32]         --
│    └─Clamp: 2-860                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-861                  [16, 128, 32, 32]         --
│    └─Empty: 2-862                      [16, 128, 32, 32]         --
│    └─Empty: 2-863                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-864         --                        --
│    └─One: 2-865                        [1]                       --
│    └─OutputScale: 2-866                --                        --
│    └─Empty: 2-867                      [128, 128, 3, 3]          --
│    └─Empty: 2-868                      [128, 128, 3, 3]          --
│    └─Empty: 2-869                      [128]                     --
│    └─Empty: 2-870                      [128]                     --
│    └─BatchNorm2d: 2-871                [16, 128, 32, 32]         --
│    └─Scaler: 2-872                     [16, 128, 32, 32]         --
│    └─ReLU: 2-873                       [16, 128, 32, 32]         --
│    └─Empty: 2-874                      [16, 128, 32, 32]         --
│    └─Clamp: 2-875                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-67         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-876                  [16, 128, 16, 16]         --
│    └─Empty: 2-877                      [16, 128, 16, 16]         --
│    └─Empty: 2-878                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-879         --                        --
│    └─One: 2-880                        [1]                       --
│    └─OutputScale: 2-881                --                        --
│    └─Empty: 2-882                      [128, 128, 3, 3]          --
│    └─Empty: 2-883                      [128, 128, 3, 3]          --
│    └─Empty: 2-884                      [128]                     --
│    └─Empty: 2-885                      [128]                     --
│    └─BatchNorm2d: 2-886                [16, 128, 16, 16]         --
│    └─Scaler: 2-887                     [16, 128, 16, 16]         --
│    └─ReLU: 2-888                       [16, 128, 16, 16]         --
│    └─Empty: 2-889                      [16, 128, 16, 16]         --
│    └─Clamp: 2-890                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-68                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-891         --                        --
│    └─One: 2-892                        [1]                       --
│    └─OutputScale: 2-893                --                        --
│    └─Empty: 2-894                      [128, 128, 1, 1]          --
│    └─Empty: 2-895                      [128, 128, 1, 1]          --
│    └─Empty: 2-896                      [128]                     --
│    └─Empty: 2-897                      [128]                     --
│    └─BatchNorm2d: 2-898                [16, 128, 16, 16]         --
│    └─Scaler: 2-899                     [16, 128, 16, 16]         --
│    └─ReLU: 2-900                       [16, 128, 16, 16]         --
│    └─Empty: 2-901                      [16, 128, 16, 16]         --
│    └─Clamp: 2-902                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-69         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-903                  [16, 128, 16, 16]         --
│    └─Empty: 2-904                      [16, 128, 16, 16]         --
│    └─Empty: 2-905                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-906         --                        --
│    └─One: 2-907                        [1]                       --
│    └─OutputScale: 2-908                --                        --
│    └─Empty: 2-909                      [128, 128, 3, 3]          --
│    └─Empty: 2-910                      [128, 128, 3, 3]          --
│    └─Empty: 2-911                      [128]                     --
│    └─Empty: 2-912                      [128]                     --
│    └─BatchNorm2d: 2-913                [16, 128, 16, 16]         --
│    └─Scaler: 2-914                     [16, 128, 16, 16]         --
│    └─ReLU: 2-915                       [16, 128, 16, 16]         --
│    └─Empty: 2-916                      [16, 128, 16, 16]         --
│    └─Clamp: 2-917                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-70         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-918                  [16, 128, 8, 8]           --
│    └─Empty: 2-919                      [16, 128, 8, 8]           --
│    └─Empty: 2-920                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [128, 128, 3, 3]          --
│    └─Empty: 2-925                      [128, 128, 3, 3]          --
│    └─Empty: 2-926                      [128]                     --
│    └─Empty: 2-927                      [128]                     --
│    └─BatchNorm2d: 2-928                [16, 128, 8, 8]           --
│    └─Scaler: 2-929                     [16, 128, 8, 8]           --
│    └─ReLU: 2-930                       [16, 128, 8, 8]           --
│    └─Empty: 2-931                      [16, 128, 8, 8]           --
│    └─Clamp: 2-932                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-71                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [16, 128, 1, 1]           --
│    └─Empty: 2-937                      [16, 128, 1, 1]           --
│    └─Empty: 2-938                      [16]                      --
│    └─Empty: 2-939                      [16]                      --
│    └─BatchNorm2d: 2-940                [16, 16, 8, 8]            --
│    └─Scaler: 2-941                     [16, 16, 8, 8]            --
│    └─ReLU: 2-942                       [16, 16, 8, 8]            --
│    └─Empty: 2-943                      [16, 16, 8, 8]            --
│    └─Clamp: 2-944                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-72         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-945                  [16, 128, 8, 8]           --
│    └─Empty: 2-946                      [16, 128, 8, 8]           --
│    └─Empty: 2-947                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-948         --                        --
│    └─One: 2-949                        [1]                       --
│    └─OutputScale: 2-950                --                        --
│    └─Empty: 2-951                      [16, 128, 3, 3]           --
│    └─Empty: 2-952                      [16, 128, 3, 3]           --
│    └─Empty: 2-953                      [16]                      --
│    └─Empty: 2-954                      [16]                      --
│    └─BatchNorm2d: 2-955                [16, 16, 8, 8]            --
│    └─Scaler: 2-956                     [16, 16, 8, 8]            --
│    └─ReLU: 2-957                       [16, 16, 8, 8]            --
│    └─Empty: 2-958                      [16, 16, 8, 8]            --
│    └─Clamp: 2-959                      [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-73                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-960         --                        --
│    └─One: 2-961                        [1]                       --
│    └─OutputScale: 2-962                --                        --
│    └─Empty: 2-963                      [128, 48, 1, 1]           --
│    └─Empty: 2-964                      [128, 48, 1, 1]           --
│    └─Empty: 2-965                      [128]                     --
│    └─Empty: 2-966                      [128]                     --
│    └─BatchNorm2d: 2-967                [16, 128, 64, 64]         --
│    └─Scaler: 2-968                     [16, 128, 64, 64]         --
│    └─ReLU: 2-969                       [16, 128, 64, 64]         --
│    └─Empty: 2-970                      [16, 128, 64, 64]         --
│    └─Clamp: 2-971                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-74                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-972         --                        --
│    └─One: 2-973                        [1]                       --
│    └─OutputScale: 2-974                --                        --
│    └─Empty: 2-975                      [128, 128, 3, 3]          --
│    └─Empty: 2-976                      [128, 128, 3, 3]          --
│    └─Empty: 2-977                      [128]                     --
│    └─Empty: 2-978                      [128]                     --
│    └─BatchNorm2d: 2-979                [16, 128, 64, 64]         --
│    └─Scaler: 2-980                     [16, 128, 64, 64]         --
│    └─ReLU: 2-981                       [16, 128, 64, 64]         --
│    └─Empty: 2-982                      [16, 128, 64, 64]         --
│    └─Clamp: 2-983                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-984                  [16, 128, 32, 32]         --
│    └─Empty: 2-985                      [16, 128, 32, 32]         --
│    └─Empty: 2-986                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-987         --                        --
│    └─One: 2-988                        [1]                       --
│    └─OutputScale: 2-989                --                        --
│    └─Empty: 2-990                      [128, 128, 3, 3]          --
│    └─Empty: 2-991                      [128, 128, 3, 3]          --
│    └─Empty: 2-992                      [128]                     --
│    └─Empty: 2-993                      [128]                     --
│    └─BatchNorm2d: 2-994                [16, 128, 32, 32]         --
│    └─Scaler: 2-995                     [16, 128, 32, 32]         --
│    └─ReLU: 2-996                       [16, 128, 32, 32]         --
│    └─Empty: 2-997                      [16, 128, 32, 32]         --
│    └─Clamp: 2-998                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-76                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-999         --                        --
│    └─One: 2-1000                       [1]                       --
│    └─OutputScale: 2-1001               --                        --
│    └─Empty: 2-1002                     [128, 128, 1, 1]          --
│    └─Empty: 2-1003                     [128, 128, 1, 1]          --
│    └─Empty: 2-1004                     [128]                     --
│    └─Empty: 2-1005                     [128]                     --
│    └─BatchNorm2d: 2-1006               [16, 128, 32, 32]         --
│    └─Scaler: 2-1007                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1008                      [16, 128, 32, 32]         --
│    └─Empty: 2-1009                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1010                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1011                 [16, 128, 32, 32]         --
│    └─Empty: 2-1012                     [16, 128, 32, 32]         --
│    └─Empty: 2-1013                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1014        --                        --
│    └─One: 2-1015                       [1]                       --
│    └─OutputScale: 2-1016               --                        --
│    └─Empty: 2-1017                     [128, 128, 3, 3]          --
│    └─Empty: 2-1018                     [128, 128, 3, 3]          --
│    └─Empty: 2-1019                     [128]                     --
│    └─Empty: 2-1020                     [128]                     --
│    └─BatchNorm2d: 2-1021               [16, 128, 32, 32]         --
│    └─Scaler: 2-1022                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1023                      [16, 128, 32, 32]         --
│    └─Empty: 2-1024                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1025                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-78         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1026                 [16, 128, 16, 16]         --
│    └─Empty: 2-1027                     [16, 128, 16, 16]         --
│    └─Empty: 2-1028                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1029        --                        --
│    └─One: 2-1030                       [1]                       --
│    └─OutputScale: 2-1031               --                        --
│    └─Empty: 2-1032                     [128, 128, 3, 3]          --
│    └─Empty: 2-1033                     [128, 128, 3, 3]          --
│    └─Empty: 2-1034                     [128]                     --
│    └─Empty: 2-1035                     [128]                     --
│    └─BatchNorm2d: 2-1036               [16, 128, 16, 16]         --
│    └─Scaler: 2-1037                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1038                      [16, 128, 16, 16]         --
│    └─Empty: 2-1039                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1040                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-79                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1041        --                        --
│    └─One: 2-1042                       [1]                       --
│    └─OutputScale: 2-1043               --                        --
│    └─Empty: 2-1044                     [128, 128, 1, 1]          --
│    └─Empty: 2-1045                     [128, 128, 1, 1]          --
│    └─Empty: 2-1046                     [128]                     --
│    └─Empty: 2-1047                     [128]                     --
│    └─BatchNorm2d: 2-1048               [16, 128, 16, 16]         --
│    └─Scaler: 2-1049                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1050                      [16, 128, 16, 16]         --
│    └─Empty: 2-1051                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1052                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1053                 [16, 128, 16, 16]         --
│    └─Empty: 2-1054                     [16, 128, 16, 16]         --
│    └─Empty: 2-1055                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1056        --                        --
│    └─One: 2-1057                       [1]                       --
│    └─OutputScale: 2-1058               --                        --
│    └─Empty: 2-1059                     [128, 128, 3, 3]          --
│    └─Empty: 2-1060                     [128, 128, 3, 3]          --
│    └─Empty: 2-1061                     [128]                     --
│    └─Empty: 2-1062                     [128]                     --
│    └─BatchNorm2d: 2-1063               [16, 128, 16, 16]         --
│    └─Scaler: 2-1064                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1065                      [16, 128, 16, 16]         --
│    └─Empty: 2-1066                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1067                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1068                 [16, 128, 8, 8]           --
│    └─Empty: 2-1069                     [16, 128, 8, 8]           --
│    └─Empty: 2-1070                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1071        --                        --
│    └─One: 2-1072                       [1]                       --
│    └─OutputScale: 2-1073               --                        --
│    └─Empty: 2-1074                     [128, 128, 3, 3]          --
│    └─Empty: 2-1075                     [128, 128, 3, 3]          --
│    └─Empty: 2-1076                     [128]                     --
│    └─Empty: 2-1077                     [128]                     --
│    └─BatchNorm2d: 2-1078               [16, 128, 8, 8]           --
│    └─Scaler: 2-1079                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1080                      [16, 128, 8, 8]           --
│    └─Empty: 2-1081                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1082                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-82                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1083        --                        --
│    └─One: 2-1084                       [1]                       --
│    └─OutputScale: 2-1085               --                        --
│    └─Empty: 2-1086                     [16, 128, 1, 1]           --
│    └─Empty: 2-1087                     [16, 128, 1, 1]           --
│    └─Empty: 2-1088                     [16]                      --
│    └─Empty: 2-1089                     [16]                      --
│    └─BatchNorm2d: 2-1090               [16, 16, 8, 8]            --
│    └─Scaler: 2-1091                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1092                      [16, 16, 8, 8]            --
│    └─Empty: 2-1093                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1094                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1095                 [16, 128, 8, 8]           --
│    └─Empty: 2-1096                     [16, 128, 8, 8]           --
│    └─Empty: 2-1097                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1098        --                        --
│    └─One: 2-1099                       [1]                       --
│    └─OutputScale: 2-1100               --                        --
│    └─Empty: 2-1101                     [16, 128, 3, 3]           --
│    └─Empty: 2-1102                     [16, 128, 3, 3]           --
│    └─Empty: 2-1103                     [16]                      --
│    └─Empty: 2-1104                     [16]                      --
│    └─BatchNorm2d: 2-1105               [16, 16, 8, 8]            --
│    └─Scaler: 2-1106                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1107                      [16, 16, 8, 8]            --
│    └─Empty: 2-1108                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1109                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-84                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1110        --                        --
│    └─One: 2-1111                       [1]                       --
│    └─OutputScale: 2-1112               --                        --
│    └─Empty: 2-1113                     [128, 48, 1, 1]           --
│    └─Empty: 2-1114                     [128, 48, 1, 1]           --
│    └─Empty: 2-1115                     [128]                     --
│    └─Empty: 2-1116                     [128]                     --
│    └─BatchNorm2d: 2-1117               [16, 128, 64, 64]         --
│    └─Scaler: 2-1118                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1119                      [16, 128, 64, 64]         --
│    └─Empty: 2-1120                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1121                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-85                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1122        --                        --
│    └─One: 2-1123                       [1]                       --
│    └─OutputScale: 2-1124               --                        --
│    └─Empty: 2-1125                     [128, 128, 3, 3]          --
│    └─Empty: 2-1126                     [128, 128, 3, 3]          --
│    └─Empty: 2-1127                     [128]                     --
│    └─Empty: 2-1128                     [128]                     --
│    └─BatchNorm2d: 2-1129               [16, 128, 64, 64]         --
│    └─Scaler: 2-1130                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1131                      [16, 128, 64, 64]         --
│    └─Empty: 2-1132                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1133                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-86         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1134                 [16, 128, 32, 32]         --
│    └─Empty: 2-1135                     [16, 128, 32, 32]         --
│    └─Empty: 2-1136                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1137        --                        --
│    └─One: 2-1138                       [1]                       --
│    └─OutputScale: 2-1139               --                        --
│    └─Empty: 2-1140                     [128, 128, 3, 3]          --
│    └─Empty: 2-1141                     [128, 128, 3, 3]          --
│    └─Empty: 2-1142                     [128]                     --
│    └─Empty: 2-1143                     [128]                     --
│    └─BatchNorm2d: 2-1144               [16, 128, 32, 32]         --
│    └─Scaler: 2-1145                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1146                      [16, 128, 32, 32]         --
│    └─Empty: 2-1147                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1148                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-87                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1149        --                        --
│    └─One: 2-1150                       [1]                       --
│    └─OutputScale: 2-1151               --                        --
│    └─Empty: 2-1152                     [128, 128, 1, 1]          --
│    └─Empty: 2-1153                     [128, 128, 1, 1]          --
│    └─Empty: 2-1154                     [128]                     --
│    └─Empty: 2-1155                     [128]                     --
│    └─BatchNorm2d: 2-1156               [16, 128, 32, 32]         --
│    └─Scaler: 2-1157                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1158                      [16, 128, 32, 32]         --
│    └─Empty: 2-1159                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1160                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-88         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1161                 [16, 128, 32, 32]         --
│    └─Empty: 2-1162                     [16, 128, 32, 32]         --
│    └─Empty: 2-1163                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1164        --                        --
│    └─One: 2-1165                       [1]                       --
│    └─OutputScale: 2-1166               --                        --
│    └─Empty: 2-1167                     [128, 128, 3, 3]          --
│    └─Empty: 2-1168                     [128, 128, 3, 3]          --
│    └─Empty: 2-1169                     [128]                     --
│    └─Empty: 2-1170                     [128]                     --
│    └─BatchNorm2d: 2-1171               [16, 128, 32, 32]         --
│    └─Scaler: 2-1172                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1173                      [16, 128, 32, 32]         --
│    └─Empty: 2-1174                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1175                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1176                 [16, 128, 16, 16]         --
│    └─Empty: 2-1177                     [16, 128, 16, 16]         --
│    └─Empty: 2-1178                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1179        --                        --
│    └─One: 2-1180                       [1]                       --
│    └─OutputScale: 2-1181               --                        --
│    └─Empty: 2-1182                     [128, 128, 3, 3]          --
│    └─Empty: 2-1183                     [128, 128, 3, 3]          --
│    └─Empty: 2-1184                     [128]                     --
│    └─Empty: 2-1185                     [128]                     --
│    └─BatchNorm2d: 2-1186               [16, 128, 16, 16]         --
│    └─Scaler: 2-1187                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1188                      [16, 128, 16, 16]         --
│    └─Empty: 2-1189                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1190                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-90                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1191        --                        --
│    └─One: 2-1192                       [1]                       --
│    └─OutputScale: 2-1193               --                        --
│    └─Empty: 2-1194                     [128, 128, 1, 1]          --
│    └─Empty: 2-1195                     [128, 128, 1, 1]          --
│    └─Empty: 2-1196                     [128]                     --
│    └─Empty: 2-1197                     [128]                     --
│    └─BatchNorm2d: 2-1198               [16, 128, 16, 16]         --
│    └─Scaler: 2-1199                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1200                      [16, 128, 16, 16]         --
│    └─Empty: 2-1201                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1202                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-91         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1203                 [16, 128, 16, 16]         --
│    └─Empty: 2-1204                     [16, 128, 16, 16]         --
│    └─Empty: 2-1205                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1206        --                        --
│    └─One: 2-1207                       [1]                       --
│    └─OutputScale: 2-1208               --                        --
│    └─Empty: 2-1209                     [128, 128, 3, 3]          --
│    └─Empty: 2-1210                     [128, 128, 3, 3]          --
│    └─Empty: 2-1211                     [128]                     --
│    └─Empty: 2-1212                     [128]                     --
│    └─BatchNorm2d: 2-1213               [16, 128, 16, 16]         --
│    └─Scaler: 2-1214                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1215                      [16, 128, 16, 16]         --
│    └─Empty: 2-1216                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1217                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1218                 [16, 128, 8, 8]           --
│    └─Empty: 2-1219                     [16, 128, 8, 8]           --
│    └─Empty: 2-1220                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1221        --                        --
│    └─One: 2-1222                       [1]                       --
│    └─OutputScale: 2-1223               --                        --
│    └─Empty: 2-1224                     [128, 128, 3, 3]          --
│    └─Empty: 2-1225                     [128, 128, 3, 3]          --
│    └─Empty: 2-1226                     [128]                     --
│    └─Empty: 2-1227                     [128]                     --
│    └─BatchNorm2d: 2-1228               [16, 128, 8, 8]           --
│    └─Scaler: 2-1229                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1230                      [16, 128, 8, 8]           --
│    └─Empty: 2-1231                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1232                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-93                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1233        --                        --
│    └─One: 2-1234                       [1]                       --
│    └─OutputScale: 2-1235               --                        --
│    └─Empty: 2-1236                     [16, 128, 1, 1]           --
│    └─Empty: 2-1237                     [16, 128, 1, 1]           --
│    └─Empty: 2-1238                     [16]                      --
│    └─Empty: 2-1239                     [16]                      --
│    └─BatchNorm2d: 2-1240               [16, 16, 8, 8]            --
│    └─Scaler: 2-1241                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1242                      [16, 16, 8, 8]            --
│    └─Empty: 2-1243                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1244                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1245                 [16, 128, 8, 8]           --
│    └─Empty: 2-1246                     [16, 128, 8, 8]           --
│    └─Empty: 2-1247                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1248        --                        --
│    └─One: 2-1249                       [1]                       --
│    └─OutputScale: 2-1250               --                        --
│    └─Empty: 2-1251                     [16, 128, 3, 3]           --
│    └─Empty: 2-1252                     [16, 128, 3, 3]           --
│    └─Empty: 2-1253                     [16]                      --
│    └─Empty: 2-1254                     [16]                      --
│    └─BatchNorm2d: 2-1255               [16, 16, 8, 8]            --
│    └─Scaler: 2-1256                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1257                      [16, 16, 8, 8]            --
│    └─Empty: 2-1258                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1259                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1260        --                        --
│    └─One: 2-1261                       [1]                       --
│    └─OutputScale: 2-1262               --                        --
│    └─Empty: 2-1263                     [128, 48, 1, 1]           --
│    └─Empty: 2-1264                     [128, 48, 1, 1]           --
│    └─Empty: 2-1265                     [128]                     --
│    └─Empty: 2-1266                     [128]                     --
│    └─BatchNorm2d: 2-1267               [16, 128, 64, 64]         --
│    └─Scaler: 2-1268                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1269                      [16, 128, 64, 64]         --
│    └─Empty: 2-1270                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1271                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-96                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1272        --                        --
│    └─One: 2-1273                       [1]                       --
│    └─OutputScale: 2-1274               --                        --
│    └─Empty: 2-1275                     [128, 128, 3, 3]          --
│    └─Empty: 2-1276                     [128, 128, 3, 3]          --
│    └─Empty: 2-1277                     [128]                     --
│    └─Empty: 2-1278                     [128]                     --
│    └─BatchNorm2d: 2-1279               [16, 128, 64, 64]         --
│    └─Scaler: 2-1280                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1281                      [16, 128, 64, 64]         --
│    └─Empty: 2-1282                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1283                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1284                 [16, 128, 32, 32]         --
│    └─Empty: 2-1285                     [16, 128, 32, 32]         --
│    └─Empty: 2-1286                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1287        --                        --
│    └─One: 2-1288                       [1]                       --
│    └─OutputScale: 2-1289               --                        --
│    └─Empty: 2-1290                     [128, 128, 3, 3]          --
│    └─Empty: 2-1291                     [128, 128, 3, 3]          --
│    └─Empty: 2-1292                     [128]                     --
│    └─Empty: 2-1293                     [128]                     --
│    └─BatchNorm2d: 2-1294               [16, 128, 32, 32]         --
│    └─Scaler: 2-1295                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1296                      [16, 128, 32, 32]         --
│    └─Empty: 2-1297                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1298                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-98                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1299        --                        --
│    └─One: 2-1300                       [1]                       --
│    └─OutputScale: 2-1301               --                        --
│    └─Empty: 2-1302                     [128, 128, 1, 1]          --
│    └─Empty: 2-1303                     [128, 128, 1, 1]          --
│    └─Empty: 2-1304                     [128]                     --
│    └─Empty: 2-1305                     [128]                     --
│    └─BatchNorm2d: 2-1306               [16, 128, 32, 32]         --
│    └─Scaler: 2-1307                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1308                      [16, 128, 32, 32]         --
│    └─Empty: 2-1309                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1310                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1311                 [16, 128, 32, 32]         --
│    └─Empty: 2-1312                     [16, 128, 32, 32]         --
│    └─Empty: 2-1313                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1314        --                        --
│    └─One: 2-1315                       [1]                       --
│    └─OutputScale: 2-1316               --                        --
│    └─Empty: 2-1317                     [128, 128, 3, 3]          --
│    └─Empty: 2-1318                     [128, 128, 3, 3]          --
│    └─Empty: 2-1319                     [128]                     --
│    └─Empty: 2-1320                     [128]                     --
│    └─BatchNorm2d: 2-1321               [16, 128, 32, 32]         --
│    └─Scaler: 2-1322                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1323                      [16, 128, 32, 32]         --
│    └─Empty: 2-1324                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1325                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1326                 [16, 128, 16, 16]         --
│    └─Empty: 2-1327                     [16, 128, 16, 16]         --
│    └─Empty: 2-1328                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1329        --                        --
│    └─One: 2-1330                       [1]                       --
│    └─OutputScale: 2-1331               --                        --
│    └─Empty: 2-1332                     [128, 128, 3, 3]          --
│    └─Empty: 2-1333                     [128, 128, 3, 3]          --
│    └─Empty: 2-1334                     [128]                     --
│    └─Empty: 2-1335                     [128]                     --
│    └─BatchNorm2d: 2-1336               [16, 128, 16, 16]         --
│    └─Scaler: 2-1337                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1338                      [16, 128, 16, 16]         --
│    └─Empty: 2-1339                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1340                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-101               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1341        --                        --
│    └─One: 2-1342                       [1]                       --
│    └─OutputScale: 2-1343               --                        --
│    └─Empty: 2-1344                     [128, 128, 1, 1]          --
│    └─Empty: 2-1345                     [128, 128, 1, 1]          --
│    └─Empty: 2-1346                     [128]                     --
│    └─Empty: 2-1347                     [128]                     --
│    └─BatchNorm2d: 2-1348               [16, 128, 16, 16]         --
│    └─Scaler: 2-1349                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1350                      [16, 128, 16, 16]         --
│    └─Empty: 2-1351                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1352                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1353                 [16, 128, 16, 16]         --
│    └─Empty: 2-1354                     [16, 128, 16, 16]         --
│    └─Empty: 2-1355                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1356        --                        --
│    └─One: 2-1357                       [1]                       --
│    └─OutputScale: 2-1358               --                        --
│    └─Empty: 2-1359                     [128, 128, 3, 3]          --
│    └─Empty: 2-1360                     [128, 128, 3, 3]          --
│    └─Empty: 2-1361                     [128]                     --
│    └─Empty: 2-1362                     [128]                     --
│    └─BatchNorm2d: 2-1363               [16, 128, 16, 16]         --
│    └─Scaler: 2-1364                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1365                      [16, 128, 16, 16]         --
│    └─Empty: 2-1366                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1367                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1368                 [16, 128, 8, 8]           --
│    └─Empty: 2-1369                     [16, 128, 8, 8]           --
│    └─Empty: 2-1370                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1371        --                        --
│    └─One: 2-1372                       [1]                       --
│    └─OutputScale: 2-1373               --                        --
│    └─Empty: 2-1374                     [128, 128, 3, 3]          --
│    └─Empty: 2-1375                     [128, 128, 3, 3]          --
│    └─Empty: 2-1376                     [128]                     --
│    └─Empty: 2-1377                     [128]                     --
│    └─BatchNorm2d: 2-1378               [16, 128, 8, 8]           --
│    └─Scaler: 2-1379                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1380                      [16, 128, 8, 8]           --
│    └─Empty: 2-1381                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1382                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-104               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1383        --                        --
│    └─One: 2-1384                       [1]                       --
│    └─OutputScale: 2-1385               --                        --
│    └─Empty: 2-1386                     [16, 128, 1, 1]           --
│    └─Empty: 2-1387                     [16, 128, 1, 1]           --
│    └─Empty: 2-1388                     [16]                      --
│    └─Empty: 2-1389                     [16]                      --
│    └─BatchNorm2d: 2-1390               [16, 16, 8, 8]            --
│    └─Scaler: 2-1391                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1392                      [16, 16, 8, 8]            --
│    └─Empty: 2-1393                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1394                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-105        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1395                 [16, 128, 8, 8]           --
│    └─Empty: 2-1396                     [16, 128, 8, 8]           --
│    └─Empty: 2-1397                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1398        --                        --
│    └─One: 2-1399                       [1]                       --
│    └─OutputScale: 2-1400               --                        --
│    └─Empty: 2-1401                     [16, 128, 3, 3]           --
│    └─Empty: 2-1402                     [16, 128, 3, 3]           --
│    └─Empty: 2-1403                     [16]                      --
│    └─Empty: 2-1404                     [16]                      --
│    └─BatchNorm2d: 2-1405               [16, 16, 8, 8]            --
│    └─Scaler: 2-1406                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1407                      [16, 16, 8, 8]            --
│    └─Empty: 2-1408                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1409                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-106               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1410        --                        --
│    └─One: 2-1411                       [1]                       --
│    └─OutputScale: 2-1412               --                        --
│    └─Empty: 2-1413                     [128, 48, 1, 1]           --
│    └─Empty: 2-1414                     [128, 48, 1, 1]           --
│    └─Empty: 2-1415                     [128]                     --
│    └─Empty: 2-1416                     [128]                     --
│    └─BatchNorm2d: 2-1417               [16, 128, 64, 64]         --
│    └─Scaler: 2-1418                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1419                      [16, 128, 64, 64]         --
│    └─Empty: 2-1420                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1421                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-107               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1422        --                        --
│    └─One: 2-1423                       [1]                       --
│    └─OutputScale: 2-1424               --                        --
│    └─Empty: 2-1425                     [128, 128, 3, 3]          --
│    └─Empty: 2-1426                     [128, 128, 3, 3]          --
│    └─Empty: 2-1427                     [128]                     --
│    └─Empty: 2-1428                     [128]                     --
│    └─BatchNorm2d: 2-1429               [16, 128, 64, 64]         --
│    └─Scaler: 2-1430                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1431                      [16, 128, 64, 64]         --
│    └─Empty: 2-1432                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1433                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-108        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1434                 [16, 128, 32, 32]         --
│    └─Empty: 2-1435                     [16, 128, 32, 32]         --
│    └─Empty: 2-1436                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1437        --                        --
│    └─One: 2-1438                       [1]                       --
│    └─OutputScale: 2-1439               --                        --
│    └─Empty: 2-1440                     [128, 128, 3, 3]          --
│    └─Empty: 2-1441                     [128, 128, 3, 3]          --
│    └─Empty: 2-1442                     [128]                     --
│    └─Empty: 2-1443                     [128]                     --
│    └─BatchNorm2d: 2-1444               [16, 128, 32, 32]         --
│    └─Scaler: 2-1445                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1446                      [16, 128, 32, 32]         --
│    └─Empty: 2-1447                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1448                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-109               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1449        --                        --
│    └─One: 2-1450                       [1]                       --
│    └─OutputScale: 2-1451               --                        --
│    └─Empty: 2-1452                     [128, 128, 1, 1]          --
│    └─Empty: 2-1453                     [128, 128, 1, 1]          --
│    └─Empty: 2-1454                     [128]                     --
│    └─Empty: 2-1455                     [128]                     --
│    └─BatchNorm2d: 2-1456               [16, 128, 32, 32]         --
│    └─Scaler: 2-1457                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1458                      [16, 128, 32, 32]         --
│    └─Empty: 2-1459                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1460                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-110        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1461                 [16, 128, 32, 32]         --
│    └─Empty: 2-1462                     [16, 128, 32, 32]         --
│    └─Empty: 2-1463                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1464        --                        --
│    └─One: 2-1465                       [1]                       --
│    └─OutputScale: 2-1466               --                        --
│    └─Empty: 2-1467                     [128, 128, 3, 3]          --
│    └─Empty: 2-1468                     [128, 128, 3, 3]          --
│    └─Empty: 2-1469                     [128]                     --
│    └─Empty: 2-1470                     [128]                     --
│    └─BatchNorm2d: 2-1471               [16, 128, 32, 32]         --
│    └─Scaler: 2-1472                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1473                      [16, 128, 32, 32]         --
│    └─Empty: 2-1474                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1475                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1476                 [16, 128, 16, 16]         --
│    └─Empty: 2-1477                     [16, 128, 16, 16]         --
│    └─Empty: 2-1478                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1479        --                        --
│    └─One: 2-1480                       [1]                       --
│    └─OutputScale: 2-1481               --                        --
│    └─Empty: 2-1482                     [128, 128, 3, 3]          --
│    └─Empty: 2-1483                     [128, 128, 3, 3]          --
│    └─Empty: 2-1484                     [128]                     --
│    └─Empty: 2-1485                     [128]                     --
│    └─BatchNorm2d: 2-1486               [16, 128, 16, 16]         --
│    └─Scaler: 2-1487                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1488                      [16, 128, 16, 16]         --
│    └─Empty: 2-1489                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1490                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-112               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1491        --                        --
│    └─One: 2-1492                       [1]                       --
│    └─OutputScale: 2-1493               --                        --
│    └─Empty: 2-1494                     [128, 128, 1, 1]          --
│    └─Empty: 2-1495                     [128, 128, 1, 1]          --
│    └─Empty: 2-1496                     [128]                     --
│    └─Empty: 2-1497                     [128]                     --
│    └─BatchNorm2d: 2-1498               [16, 128, 16, 16]         --
│    └─Scaler: 2-1499                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1500                      [16, 128, 16, 16]         --
│    └─Empty: 2-1501                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1502                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1503                 [16, 128, 16, 16]         --
│    └─Empty: 2-1504                     [16, 128, 16, 16]         --
│    └─Empty: 2-1505                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1506        --                        --
│    └─One: 2-1507                       [1]                       --
│    └─OutputScale: 2-1508               --                        --
│    └─Empty: 2-1509                     [128, 128, 3, 3]          --
│    └─Empty: 2-1510                     [128, 128, 3, 3]          --
│    └─Empty: 2-1511                     [128]                     --
│    └─Empty: 2-1512                     [128]                     --
│    └─BatchNorm2d: 2-1513               [16, 128, 16, 16]         --
│    └─Scaler: 2-1514                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1515                      [16, 128, 16, 16]         --
│    └─Empty: 2-1516                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1517                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1518                 [16, 128, 8, 8]           --
│    └─Empty: 2-1519                     [16, 128, 8, 8]           --
│    └─Empty: 2-1520                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1521        --                        --
│    └─One: 2-1522                       [1]                       --
│    └─OutputScale: 2-1523               --                        --
│    └─Empty: 2-1524                     [128, 128, 3, 3]          --
│    └─Empty: 2-1525                     [128, 128, 3, 3]          --
│    └─Empty: 2-1526                     [128]                     --
│    └─Empty: 2-1527                     [128]                     --
│    └─BatchNorm2d: 2-1528               [16, 128, 8, 8]           --
│    └─Scaler: 2-1529                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1530                      [16, 128, 8, 8]           --
│    └─Empty: 2-1531                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1532                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-115               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1533        --                        --
│    └─One: 2-1534                       [1]                       --
│    └─OutputScale: 2-1535               --                        --
│    └─Empty: 2-1536                     [16, 128, 1, 1]           --
│    └─Empty: 2-1537                     [16, 128, 1, 1]           --
│    └─Empty: 2-1538                     [16]                      --
│    └─Empty: 2-1539                     [16]                      --
│    └─BatchNorm2d: 2-1540               [16, 16, 8, 8]            --
│    └─Scaler: 2-1541                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1542                      [16, 16, 8, 8]            --
│    └─Empty: 2-1543                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1544                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1545                 [16, 128, 8, 8]           --
│    └─Empty: 2-1546                     [16, 128, 8, 8]           --
│    └─Empty: 2-1547                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1548        --                        --
│    └─One: 2-1549                       [1]                       --
│    └─OutputScale: 2-1550               --                        --
│    └─Empty: 2-1551                     [16, 128, 3, 3]           --
│    └─Empty: 2-1552                     [16, 128, 3, 3]           --
│    └─Empty: 2-1553                     [16]                      --
│    └─Empty: 2-1554                     [16]                      --
│    └─BatchNorm2d: 2-1555               [16, 16, 8, 8]            --
│    └─Scaler: 2-1556                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1557                      [16, 16, 8, 8]            --
│    └─Empty: 2-1558                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1559                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-117               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1560        --                        --
│    └─One: 2-1561                       [1]                       --
│    └─OutputScale: 2-1562               --                        --
│    └─Empty: 2-1563                     [128, 48, 1, 1]           --
│    └─Empty: 2-1564                     [128, 48, 1, 1]           --
│    └─Empty: 2-1565                     [128]                     --
│    └─Empty: 2-1566                     [128]                     --
│    └─BatchNorm2d: 2-1567               [16, 128, 64, 64]         --
│    └─Scaler: 2-1568                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1569                      [16, 128, 64, 64]         --
│    └─Empty: 2-1570                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1571                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-118               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1572        --                        --
│    └─One: 2-1573                       [1]                       --
│    └─OutputScale: 2-1574               --                        --
│    └─Empty: 2-1575                     [128, 128, 3, 3]          --
│    └─Empty: 2-1576                     [128, 128, 3, 3]          --
│    └─Empty: 2-1577                     [128]                     --
│    └─Empty: 2-1578                     [128]                     --
│    └─BatchNorm2d: 2-1579               [16, 128, 64, 64]         --
│    └─Scaler: 2-1580                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1581                      [16, 128, 64, 64]         --
│    └─Empty: 2-1582                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1583                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1584                 [16, 128, 32, 32]         --
│    └─Empty: 2-1585                     [16, 128, 32, 32]         --
│    └─Empty: 2-1586                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1587        --                        --
│    └─One: 2-1588                       [1]                       --
│    └─OutputScale: 2-1589               --                        --
│    └─Empty: 2-1590                     [128, 128, 3, 3]          --
│    └─Empty: 2-1591                     [128, 128, 3, 3]          --
│    └─Empty: 2-1592                     [128]                     --
│    └─Empty: 2-1593                     [128]                     --
│    └─BatchNorm2d: 2-1594               [16, 128, 32, 32]         --
│    └─Scaler: 2-1595                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1596                      [16, 128, 32, 32]         --
│    └─Empty: 2-1597                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1598                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-120               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1599        --                        --
│    └─One: 2-1600                       [1]                       --
│    └─OutputScale: 2-1601               --                        --
│    └─Empty: 2-1602                     [128, 128, 1, 1]          --
│    └─Empty: 2-1603                     [128, 128, 1, 1]          --
│    └─Empty: 2-1604                     [128]                     --
│    └─Empty: 2-1605                     [128]                     --
│    └─BatchNorm2d: 2-1606               [16, 128, 32, 32]         --
│    └─Scaler: 2-1607                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1608                      [16, 128, 32, 32]         --
│    └─Empty: 2-1609                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1610                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1611                 [16, 128, 32, 32]         --
│    └─Empty: 2-1612                     [16, 128, 32, 32]         --
│    └─Empty: 2-1613                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1614        --                        --
│    └─One: 2-1615                       [1]                       --
│    └─OutputScale: 2-1616               --                        --
│    └─Empty: 2-1617                     [128, 128, 3, 3]          --
│    └─Empty: 2-1618                     [128, 128, 3, 3]          --
│    └─Empty: 2-1619                     [128]                     --
│    └─Empty: 2-1620                     [128]                     --
│    └─BatchNorm2d: 2-1621               [16, 128, 32, 32]         --
│    └─Scaler: 2-1622                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1623                      [16, 128, 32, 32]         --
│    └─Empty: 2-1624                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1625                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-122        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1626                 [16, 128, 16, 16]         --
│    └─Empty: 2-1627                     [16, 128, 16, 16]         --
│    └─Empty: 2-1628                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [128, 128, 3, 3]          --
│    └─Empty: 2-1633                     [128, 128, 3, 3]          --
│    └─Empty: 2-1634                     [128]                     --
│    └─Empty: 2-1635                     [128]                     --
│    └─BatchNorm2d: 2-1636               [16, 128, 16, 16]         --
│    └─Scaler: 2-1637                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1638                      [16, 128, 16, 16]         --
│    └─Empty: 2-1639                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1640                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-123               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [128, 128, 1, 1]          --
│    └─Empty: 2-1645                     [128, 128, 1, 1]          --
│    └─Empty: 2-1646                     [128]                     --
│    └─Empty: 2-1647                     [128]                     --
│    └─BatchNorm2d: 2-1648               [16, 128, 16, 16]         --
│    └─Scaler: 2-1649                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1650                      [16, 128, 16, 16]         --
│    └─Empty: 2-1651                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1652                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1653                 [16, 128, 16, 16]         --
│    └─Empty: 2-1654                     [16, 128, 16, 16]         --
│    └─Empty: 2-1655                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [128, 128, 3, 3]          --
│    └─Empty: 2-1660                     [128, 128, 3, 3]          --
│    └─Empty: 2-1661                     [128]                     --
│    └─Empty: 2-1662                     [128]                     --
│    └─BatchNorm2d: 2-1663               [16, 128, 16, 16]         --
│    └─Scaler: 2-1664                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1665                      [16, 128, 16, 16]         --
│    └─Empty: 2-1666                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1667                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-125        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1668                 [16, 128, 8, 8]           --
│    └─Empty: 2-1669                     [16, 128, 8, 8]           --
│    └─Empty: 2-1670                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1671        --                        --
│    └─One: 2-1672                       [1]                       --
│    └─OutputScale: 2-1673               --                        --
│    └─Empty: 2-1674                     [128, 128, 3, 3]          --
│    └─Empty: 2-1675                     [128, 128, 3, 3]          --
│    └─Empty: 2-1676                     [128]                     --
│    └─Empty: 2-1677                     [128]                     --
│    └─BatchNorm2d: 2-1678               [16, 128, 8, 8]           --
│    └─Scaler: 2-1679                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1680                      [16, 128, 8, 8]           --
│    └─Empty: 2-1681                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1682                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-126               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [16, 128, 1, 1]           --
│    └─Empty: 2-1687                     [16, 128, 1, 1]           --
│    └─Empty: 2-1688                     [16]                      --
│    └─Empty: 2-1689                     [16]                      --
│    └─BatchNorm2d: 2-1690               [16, 16, 8, 8]            --
│    └─Scaler: 2-1691                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1692                      [16, 16, 8, 8]            --
│    └─Empty: 2-1693                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1694                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-127        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1695                 [16, 128, 8, 8]           --
│    └─Empty: 2-1696                     [16, 128, 8, 8]           --
│    └─Empty: 2-1697                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1698        --                        --
│    └─One: 2-1699                       [1]                       --
│    └─OutputScale: 2-1700               --                        --
│    └─Empty: 2-1701                     [16, 128, 3, 3]           --
│    └─Empty: 2-1702                     [16, 128, 3, 3]           --
│    └─Empty: 2-1703                     [16]                      --
│    └─Empty: 2-1704                     [16]                      --
│    └─BatchNorm2d: 2-1705               [16, 16, 8, 8]            --
│    └─Scaler: 2-1706                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1707                      [16, 16, 8, 8]            --
│    └─Empty: 2-1708                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1709                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-128               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [128, 48, 1, 1]           --
│    └─Empty: 2-1714                     [128, 48, 1, 1]           --
│    └─Empty: 2-1715                     [128]                     --
│    └─Empty: 2-1716                     [128]                     --
│    └─BatchNorm2d: 2-1717               [16, 128, 64, 64]         --
│    └─Scaler: 2-1718                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1719                      [16, 128, 64, 64]         --
│    └─Empty: 2-1720                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1721                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-129               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1722        --                        --
│    └─One: 2-1723                       [1]                       --
│    └─OutputScale: 2-1724               --                        --
│    └─Empty: 2-1725                     [128, 128, 3, 3]          --
│    └─Empty: 2-1726                     [128, 128, 3, 3]          --
│    └─Empty: 2-1727                     [128]                     --
│    └─Empty: 2-1728                     [128]                     --
│    └─BatchNorm2d: 2-1729               [16, 128, 64, 64]         --
│    └─Scaler: 2-1730                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1731                      [16, 128, 64, 64]         --
│    └─Empty: 2-1732                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1733                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1734                 [16, 128, 32, 32]         --
│    └─Empty: 2-1735                     [16, 128, 32, 32]         --
│    └─Empty: 2-1736                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1737        --                        --
│    └─One: 2-1738                       [1]                       --
│    └─OutputScale: 2-1739               --                        --
│    └─Empty: 2-1740                     [128, 128, 3, 3]          --
│    └─Empty: 2-1741                     [128, 128, 3, 3]          --
│    └─Empty: 2-1742                     [128]                     --
│    └─Empty: 2-1743                     [128]                     --
│    └─BatchNorm2d: 2-1744               [16, 128, 32, 32]         --
│    └─Scaler: 2-1745                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1746                      [16, 128, 32, 32]         --
│    └─Empty: 2-1747                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1748                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-131               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1749        --                        --
│    └─One: 2-1750                       [1]                       --
│    └─OutputScale: 2-1751               --                        --
│    └─Empty: 2-1752                     [128, 128, 1, 1]          --
│    └─Empty: 2-1753                     [128, 128, 1, 1]          --
│    └─Empty: 2-1754                     [128]                     --
│    └─Empty: 2-1755                     [128]                     --
│    └─BatchNorm2d: 2-1756               [16, 128, 32, 32]         --
│    └─Scaler: 2-1757                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1758                      [16, 128, 32, 32]         --
│    └─Empty: 2-1759                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1760                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1761                 [16, 128, 32, 32]         --
│    └─Empty: 2-1762                     [16, 128, 32, 32]         --
│    └─Empty: 2-1763                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1764        --                        --
│    └─One: 2-1765                       [1]                       --
│    └─OutputScale: 2-1766               --                        --
│    └─Empty: 2-1767                     [128, 128, 3, 3]          --
│    └─Empty: 2-1768                     [128, 128, 3, 3]          --
│    └─Empty: 2-1769                     [128]                     --
│    └─Empty: 2-1770                     [128]                     --
│    └─BatchNorm2d: 2-1771               [16, 128, 32, 32]         --
│    └─Scaler: 2-1772                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1773                      [16, 128, 32, 32]         --
│    └─Empty: 2-1774                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1775                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1776                 [16, 128, 16, 16]         --
│    └─Empty: 2-1777                     [16, 128, 16, 16]         --
│    └─Empty: 2-1778                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1779        --                        --
│    └─One: 2-1780                       [1]                       --
│    └─OutputScale: 2-1781               --                        --
│    └─Empty: 2-1782                     [128, 128, 3, 3]          --
│    └─Empty: 2-1783                     [128, 128, 3, 3]          --
│    └─Empty: 2-1784                     [128]                     --
│    └─Empty: 2-1785                     [128]                     --
│    └─BatchNorm2d: 2-1786               [16, 128, 16, 16]         --
│    └─Scaler: 2-1787                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1788                      [16, 128, 16, 16]         --
│    └─Empty: 2-1789                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1790                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-134               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1791        --                        --
│    └─One: 2-1792                       [1]                       --
│    └─OutputScale: 2-1793               --                        --
│    └─Empty: 2-1794                     [128, 128, 1, 1]          --
│    └─Empty: 2-1795                     [128, 128, 1, 1]          --
│    └─Empty: 2-1796                     [128]                     --
│    └─Empty: 2-1797                     [128]                     --
│    └─BatchNorm2d: 2-1798               [16, 128, 16, 16]         --
│    └─Scaler: 2-1799                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1800                      [16, 128, 16, 16]         --
│    └─Empty: 2-1801                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1802                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-135        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1803                 [16, 128, 16, 16]         --
│    └─Empty: 2-1804                     [16, 128, 16, 16]         --
│    └─Empty: 2-1805                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1806        --                        --
│    └─One: 2-1807                       [1]                       --
│    └─OutputScale: 2-1808               --                        --
│    └─Empty: 2-1809                     [128, 128, 3, 3]          --
│    └─Empty: 2-1810                     [128, 128, 3, 3]          --
│    └─Empty: 2-1811                     [128]                     --
│    └─Empty: 2-1812                     [128]                     --
│    └─BatchNorm2d: 2-1813               [16, 128, 16, 16]         --
│    └─Scaler: 2-1814                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1815                      [16, 128, 16, 16]         --
│    └─Empty: 2-1816                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1817                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1818                 [16, 128, 8, 8]           --
│    └─Empty: 2-1819                     [16, 128, 8, 8]           --
│    └─Empty: 2-1820                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [128, 128, 3, 3]          --
│    └─Empty: 2-1825                     [128, 128, 3, 3]          --
│    └─Empty: 2-1826                     [128]                     --
│    └─Empty: 2-1827                     [128]                     --
│    └─BatchNorm2d: 2-1828               [16, 128, 8, 8]           --
│    └─Scaler: 2-1829                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1830                      [16, 128, 8, 8]           --
│    └─Empty: 2-1831                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1832                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-137               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1833        --                        --
│    └─One: 2-1834                       [1]                       --
│    └─OutputScale: 2-1835               --                        --
│    └─Empty: 2-1836                     [16, 128, 1, 1]           --
│    └─Empty: 2-1837                     [16, 128, 1, 1]           --
│    └─Empty: 2-1838                     [16]                      --
│    └─Empty: 2-1839                     [16]                      --
│    └─BatchNorm2d: 2-1840               [16, 16, 8, 8]            --
│    └─Scaler: 2-1841                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1842                      [16, 16, 8, 8]            --
│    └─Empty: 2-1843                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1844                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-138        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1845                 [16, 128, 8, 8]           --
│    └─Empty: 2-1846                     [16, 128, 8, 8]           --
│    └─Empty: 2-1847                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1848        --                        --
│    └─One: 2-1849                       [1]                       --
│    └─OutputScale: 2-1850               --                        --
│    └─Empty: 2-1851                     [16, 128, 3, 3]           --
│    └─Empty: 2-1852                     [16, 128, 3, 3]           --
│    └─Empty: 2-1853                     [16]                      --
│    └─Empty: 2-1854                     [16]                      --
│    └─BatchNorm2d: 2-1855               [16, 16, 8, 8]            --
│    └─Scaler: 2-1856                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1857                      [16, 16, 8, 8]            --
│    └─Empty: 2-1858                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1859                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-139               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1860        --                        --
│    └─One: 2-1861                       [1]                       --
│    └─OutputScale: 2-1862               --                        --
│    └─Empty: 2-1863                     [128, 48, 1, 1]           --
│    └─Empty: 2-1864                     [128, 48, 1, 1]           --
│    └─Empty: 2-1865                     [128]                     --
│    └─Empty: 2-1866                     [128]                     --
│    └─BatchNorm2d: 2-1867               [16, 128, 64, 64]         --
│    └─Scaler: 2-1868                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1869                      [16, 128, 64, 64]         --
│    └─Empty: 2-1870                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1871                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-140               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1872        --                        --
│    └─One: 2-1873                       [1]                       --
│    └─OutputScale: 2-1874               --                        --
│    └─Empty: 2-1875                     [128, 128, 3, 3]          --
│    └─Empty: 2-1876                     [128, 128, 3, 3]          --
│    └─Empty: 2-1877                     [128]                     --
│    └─Empty: 2-1878                     [128]                     --
│    └─BatchNorm2d: 2-1879               [16, 128, 64, 64]         --
│    └─Scaler: 2-1880                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1881                      [16, 128, 64, 64]         --
│    └─Empty: 2-1882                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1883                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1884                 [16, 128, 32, 32]         --
│    └─Empty: 2-1885                     [16, 128, 32, 32]         --
│    └─Empty: 2-1886                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1887        --                        --
│    └─One: 2-1888                       [1]                       --
│    └─OutputScale: 2-1889               --                        --
│    └─Empty: 2-1890                     [128, 128, 3, 3]          --
│    └─Empty: 2-1891                     [128, 128, 3, 3]          --
│    └─Empty: 2-1892                     [128]                     --
│    └─Empty: 2-1893                     [128]                     --
│    └─BatchNorm2d: 2-1894               [16, 128, 32, 32]         --
│    └─Scaler: 2-1895                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1896                      [16, 128, 32, 32]         --
│    └─Empty: 2-1897                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1898                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-142               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1899        --                        --
│    └─One: 2-1900                       [1]                       --
│    └─OutputScale: 2-1901               --                        --
│    └─Empty: 2-1902                     [128, 128, 1, 1]          --
│    └─Empty: 2-1903                     [128, 128, 1, 1]          --
│    └─Empty: 2-1904                     [128]                     --
│    └─Empty: 2-1905                     [128]                     --
│    └─BatchNorm2d: 2-1906               [16, 128, 32, 32]         --
│    └─Scaler: 2-1907                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1908                      [16, 128, 32, 32]         --
│    └─Empty: 2-1909                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1910                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1911                 [16, 128, 32, 32]         --
│    └─Empty: 2-1912                     [16, 128, 32, 32]         --
│    └─Empty: 2-1913                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1914        --                        --
│    └─One: 2-1915                       [1]                       --
│    └─OutputScale: 2-1916               --                        --
│    └─Empty: 2-1917                     [128, 128, 3, 3]          --
│    └─Empty: 2-1918                     [128, 128, 3, 3]          --
│    └─Empty: 2-1919                     [128]                     --
│    └─Empty: 2-1920                     [128]                     --
│    └─BatchNorm2d: 2-1921               [16, 128, 32, 32]         --
│    └─Scaler: 2-1922                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1923                      [16, 128, 32, 32]         --
│    └─Empty: 2-1924                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1925                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-144        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1926                 [16, 128, 16, 16]         --
│    └─Empty: 2-1927                     [16, 128, 16, 16]         --
│    └─Empty: 2-1928                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1929        --                        --
│    └─One: 2-1930                       [1]                       --
│    └─OutputScale: 2-1931               --                        --
│    └─Empty: 2-1932                     [128, 128, 3, 3]          --
│    └─Empty: 2-1933                     [128, 128, 3, 3]          --
│    └─Empty: 2-1934                     [128]                     --
│    └─Empty: 2-1935                     [128]                     --
│    └─BatchNorm2d: 2-1936               [16, 128, 16, 16]         --
│    └─Scaler: 2-1937                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1938                      [16, 128, 16, 16]         --
│    └─Empty: 2-1939                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1940                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-145               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1941        --                        --
│    └─One: 2-1942                       [1]                       --
│    └─OutputScale: 2-1943               --                        --
│    └─Empty: 2-1944                     [128, 128, 1, 1]          --
│    └─Empty: 2-1945                     [128, 128, 1, 1]          --
│    └─Empty: 2-1946                     [128]                     --
│    └─Empty: 2-1947                     [128]                     --
│    └─BatchNorm2d: 2-1948               [16, 128, 16, 16]         --
│    └─Scaler: 2-1949                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1950                      [16, 128, 16, 16]         --
│    └─Empty: 2-1951                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1952                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-146        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1953                 [16, 128, 16, 16]         --
│    └─Empty: 2-1954                     [16, 128, 16, 16]         --
│    └─Empty: 2-1955                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1956        --                        --
│    └─One: 2-1957                       [1]                       --
│    └─OutputScale: 2-1958               --                        --
│    └─Empty: 2-1959                     [128, 128, 3, 3]          --
│    └─Empty: 2-1960                     [128, 128, 3, 3]          --
│    └─Empty: 2-1961                     [128]                     --
│    └─Empty: 2-1962                     [128]                     --
│    └─BatchNorm2d: 2-1963               [16, 128, 16, 16]         --
│    └─Scaler: 2-1964                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1965                      [16, 128, 16, 16]         --
│    └─Empty: 2-1966                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1967                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1968                 [16, 128, 8, 8]           --
│    └─Empty: 2-1969                     [16, 128, 8, 8]           --
│    └─Empty: 2-1970                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1971        --                        --
│    └─One: 2-1972                       [1]                       --
│    └─OutputScale: 2-1973               --                        --
│    └─Empty: 2-1974                     [128, 128, 3, 3]          --
│    └─Empty: 2-1975                     [128, 128, 3, 3]          --
│    └─Empty: 2-1976                     [128]                     --
│    └─Empty: 2-1977                     [128]                     --
│    └─BatchNorm2d: 2-1978               [16, 128, 8, 8]           --
│    └─Scaler: 2-1979                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1980                      [16, 128, 8, 8]           --
│    └─Empty: 2-1981                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1982                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-148               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1983        --                        --
│    └─One: 2-1984                       [1]                       --
│    └─OutputScale: 2-1985               --                        --
│    └─Empty: 2-1986                     [16, 128, 1, 1]           --
│    └─Empty: 2-1987                     [16, 128, 1, 1]           --
│    └─Empty: 2-1988                     [16]                      --
│    └─Empty: 2-1989                     [16]                      --
│    └─BatchNorm2d: 2-1990               [16, 16, 8, 8]            --
│    └─Scaler: 2-1991                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1992                      [16, 16, 8, 8]            --
│    └─Empty: 2-1993                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1994                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-149        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1995                 [16, 128, 8, 8]           --
│    └─Empty: 2-1996                     [16, 128, 8, 8]           --
│    └─Empty: 2-1997                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1998        --                        --
│    └─One: 2-1999                       [1]                       --
│    └─OutputScale: 2-2000               --                        --
│    └─Empty: 2-2001                     [16, 128, 3, 3]           --
│    └─Empty: 2-2002                     [16, 128, 3, 3]           --
│    └─Empty: 2-2003                     [16]                      --
│    └─Empty: 2-2004                     [16]                      --
│    └─BatchNorm2d: 2-2005               [16, 16, 8, 8]            --
│    └─Scaler: 2-2006                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2007                      [16, 16, 8, 8]            --
│    └─Empty: 2-2008                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2009                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-150               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2010        --                        --
│    └─One: 2-2011                       [1]                       --
│    └─OutputScale: 2-2012               --                        --
│    └─Empty: 2-2013                     [128, 48, 1, 1]           --
│    └─Empty: 2-2014                     [128, 48, 1, 1]           --
│    └─Empty: 2-2015                     [128]                     --
│    └─Empty: 2-2016                     [128]                     --
│    └─BatchNorm2d: 2-2017               [16, 128, 64, 64]         --
│    └─Scaler: 2-2018                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2019                      [16, 128, 64, 64]         --
│    └─Empty: 2-2020                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2021                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-151               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2022        --                        --
│    └─One: 2-2023                       [1]                       --
│    └─OutputScale: 2-2024               --                        --
│    └─Empty: 2-2025                     [128, 128, 3, 3]          --
│    └─Empty: 2-2026                     [128, 128, 3, 3]          --
│    └─Empty: 2-2027                     [128]                     --
│    └─Empty: 2-2028                     [128]                     --
│    └─BatchNorm2d: 2-2029               [16, 128, 64, 64]         --
│    └─Scaler: 2-2030                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2031                      [16, 128, 64, 64]         --
│    └─Empty: 2-2032                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2033                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-152        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2034                 [16, 128, 32, 32]         --
│    └─Empty: 2-2035                     [16, 128, 32, 32]         --
│    └─Empty: 2-2036                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2037        --                        --
│    └─One: 2-2038                       [1]                       --
│    └─OutputScale: 2-2039               --                        --
│    └─Empty: 2-2040                     [128, 128, 3, 3]          --
│    └─Empty: 2-2041                     [128, 128, 3, 3]          --
│    └─Empty: 2-2042                     [128]                     --
│    └─Empty: 2-2043                     [128]                     --
│    └─BatchNorm2d: 2-2044               [16, 128, 32, 32]         --
│    └─Scaler: 2-2045                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2046                      [16, 128, 32, 32]         --
│    └─Empty: 2-2047                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2048                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-153               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2049        --                        --
│    └─One: 2-2050                       [1]                       --
│    └─OutputScale: 2-2051               --                        --
│    └─Empty: 2-2052                     [128, 128, 1, 1]          --
│    └─Empty: 2-2053                     [128, 128, 1, 1]          --
│    └─Empty: 2-2054                     [128]                     --
│    └─Empty: 2-2055                     [128]                     --
│    └─BatchNorm2d: 2-2056               [16, 128, 32, 32]         --
│    └─Scaler: 2-2057                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2058                      [16, 128, 32, 32]         --
│    └─Empty: 2-2059                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2060                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-154        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2061                 [16, 128, 32, 32]         --
│    └─Empty: 2-2062                     [16, 128, 32, 32]         --
│    └─Empty: 2-2063                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2064        --                        --
│    └─One: 2-2065                       [1]                       --
│    └─OutputScale: 2-2066               --                        --
│    └─Empty: 2-2067                     [128, 128, 3, 3]          --
│    └─Empty: 2-2068                     [128, 128, 3, 3]          --
│    └─Empty: 2-2069                     [128]                     --
│    └─Empty: 2-2070                     [128]                     --
│    └─BatchNorm2d: 2-2071               [16, 128, 32, 32]         --
│    └─Scaler: 2-2072                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2073                      [16, 128, 32, 32]         --
│    └─Empty: 2-2074                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2075                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-155        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2076                 [16, 128, 16, 16]         --
│    └─Empty: 2-2077                     [16, 128, 16, 16]         --
│    └─Empty: 2-2078                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2079        --                        --
│    └─One: 2-2080                       [1]                       --
│    └─OutputScale: 2-2081               --                        --
│    └─Empty: 2-2082                     [128, 128, 3, 3]          --
│    └─Empty: 2-2083                     [128, 128, 3, 3]          --
│    └─Empty: 2-2084                     [128]                     --
│    └─Empty: 2-2085                     [128]                     --
│    └─BatchNorm2d: 2-2086               [16, 128, 16, 16]         --
│    └─Scaler: 2-2087                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2088                      [16, 128, 16, 16]         --
│    └─Empty: 2-2089                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2090                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-156               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2091        --                        --
│    └─One: 2-2092                       [1]                       --
│    └─OutputScale: 2-2093               --                        --
│    └─Empty: 2-2094                     [128, 128, 1, 1]          --
│    └─Empty: 2-2095                     [128, 128, 1, 1]          --
│    └─Empty: 2-2096                     [128]                     --
│    └─Empty: 2-2097                     [128]                     --
│    └─BatchNorm2d: 2-2098               [16, 128, 16, 16]         --
│    └─Scaler: 2-2099                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2100                      [16, 128, 16, 16]         --
│    └─Empty: 2-2101                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2102                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-157        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2103                 [16, 128, 16, 16]         --
│    └─Empty: 2-2104                     [16, 128, 16, 16]         --
│    └─Empty: 2-2105                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2106        --                        --
│    └─One: 2-2107                       [1]                       --
│    └─OutputScale: 2-2108               --                        --
│    └─Empty: 2-2109                     [128, 128, 3, 3]          --
│    └─Empty: 2-2110                     [128, 128, 3, 3]          --
│    └─Empty: 2-2111                     [128]                     --
│    └─Empty: 2-2112                     [128]                     --
│    └─BatchNorm2d: 2-2113               [16, 128, 16, 16]         --
│    └─Scaler: 2-2114                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2115                      [16, 128, 16, 16]         --
│    └─Empty: 2-2116                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2117                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2118                 [16, 128, 8, 8]           --
│    └─Empty: 2-2119                     [16, 128, 8, 8]           --
│    └─Empty: 2-2120                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2121        --                        --
│    └─One: 2-2122                       [1]                       --
│    └─OutputScale: 2-2123               --                        --
│    └─Empty: 2-2124                     [128, 128, 3, 3]          --
│    └─Empty: 2-2125                     [128, 128, 3, 3]          --
│    └─Empty: 2-2126                     [128]                     --
│    └─Empty: 2-2127                     [128]                     --
│    └─BatchNorm2d: 2-2128               [16, 128, 8, 8]           --
│    └─Scaler: 2-2129                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2130                      [16, 128, 8, 8]           --
│    └─Empty: 2-2131                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2132                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-159               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2133        --                        --
│    └─One: 2-2134                       [1]                       --
│    └─OutputScale: 2-2135               --                        --
│    └─Empty: 2-2136                     [16, 128, 1, 1]           --
│    └─Empty: 2-2137                     [16, 128, 1, 1]           --
│    └─Empty: 2-2138                     [16]                      --
│    └─Empty: 2-2139                     [16]                      --
│    └─BatchNorm2d: 2-2140               [16, 16, 8, 8]            --
│    └─Scaler: 2-2141                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2142                      [16, 16, 8, 8]            --
│    └─Empty: 2-2143                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2144                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2145                 [16, 128, 8, 8]           --
│    └─Empty: 2-2146                     [16, 128, 8, 8]           --
│    └─Empty: 2-2147                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2148        --                        --
│    └─One: 2-2149                       [1]                       --
│    └─OutputScale: 2-2150               --                        --
│    └─Empty: 2-2151                     [16, 128, 3, 3]           --
│    └─Empty: 2-2152                     [16, 128, 3, 3]           --
│    └─Empty: 2-2153                     [16]                      --
│    └─Empty: 2-2154                     [16]                      --
│    └─BatchNorm2d: 2-2155               [16, 16, 8, 8]            --
│    └─Scaler: 2-2156                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2157                      [16, 16, 8, 8]            --
│    └─Empty: 2-2158                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2159                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-161               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2160        --                        --
│    └─One: 2-2161                       [1]                       --
│    └─OutputScale: 2-2162               --                        --
│    └─Empty: 2-2163                     [128, 48, 1, 1]           --
│    └─Empty: 2-2164                     [128, 48, 1, 1]           --
│    └─Empty: 2-2165                     [128]                     --
│    └─Empty: 2-2166                     [128]                     --
│    └─BatchNorm2d: 2-2167               [16, 128, 64, 64]         --
│    └─Scaler: 2-2168                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2169                      [16, 128, 64, 64]         --
│    └─Empty: 2-2170                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2171                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-162               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2172        --                        --
│    └─One: 2-2173                       [1]                       --
│    └─OutputScale: 2-2174               --                        --
│    └─Empty: 2-2175                     [128, 128, 3, 3]          --
│    └─Empty: 2-2176                     [128, 128, 3, 3]          --
│    └─Empty: 2-2177                     [128]                     --
│    └─Empty: 2-2178                     [128]                     --
│    └─BatchNorm2d: 2-2179               [16, 128, 64, 64]         --
│    └─Scaler: 2-2180                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2181                      [16, 128, 64, 64]         --
│    └─Empty: 2-2182                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2183                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-163        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2184                 [16, 128, 32, 32]         --
│    └─Empty: 2-2185                     [16, 128, 32, 32]         --
│    └─Empty: 2-2186                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2187        --                        --
│    └─One: 2-2188                       [1]                       --
│    └─OutputScale: 2-2189               --                        --
│    └─Empty: 2-2190                     [128, 128, 3, 3]          --
│    └─Empty: 2-2191                     [128, 128, 3, 3]          --
│    └─Empty: 2-2192                     [128]                     --
│    └─Empty: 2-2193                     [128]                     --
│    └─BatchNorm2d: 2-2194               [16, 128, 32, 32]         --
│    └─Scaler: 2-2195                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2196                      [16, 128, 32, 32]         --
│    └─Empty: 2-2197                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2198                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-164               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2199        --                        --
│    └─One: 2-2200                       [1]                       --
│    └─OutputScale: 2-2201               --                        --
│    └─Empty: 2-2202                     [128, 128, 1, 1]          --
│    └─Empty: 2-2203                     [128, 128, 1, 1]          --
│    └─Empty: 2-2204                     [128]                     --
│    └─Empty: 2-2205                     [128]                     --
│    └─BatchNorm2d: 2-2206               [16, 128, 32, 32]         --
│    └─Scaler: 2-2207                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2208                      [16, 128, 32, 32]         --
│    └─Empty: 2-2209                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2210                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2211                 [16, 128, 32, 32]         --
│    └─Empty: 2-2212                     [16, 128, 32, 32]         --
│    └─Empty: 2-2213                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2214        --                        --
│    └─One: 2-2215                       [1]                       --
│    └─OutputScale: 2-2216               --                        --
│    └─Empty: 2-2217                     [128, 128, 3, 3]          --
│    └─Empty: 2-2218                     [128, 128, 3, 3]          --
│    └─Empty: 2-2219                     [128]                     --
│    └─Empty: 2-2220                     [128]                     --
│    └─BatchNorm2d: 2-2221               [16, 128, 32, 32]         --
│    └─Scaler: 2-2222                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2223                      [16, 128, 32, 32]         --
│    └─Empty: 2-2224                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2225                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-166        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2226                 [16, 128, 16, 16]         --
│    └─Empty: 2-2227                     [16, 128, 16, 16]         --
│    └─Empty: 2-2228                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2229        --                        --
│    └─One: 2-2230                       [1]                       --
│    └─OutputScale: 2-2231               --                        --
│    └─Empty: 2-2232                     [128, 128, 3, 3]          --
│    └─Empty: 2-2233                     [128, 128, 3, 3]          --
│    └─Empty: 2-2234                     [128]                     --
│    └─Empty: 2-2235                     [128]                     --
│    └─BatchNorm2d: 2-2236               [16, 128, 16, 16]         --
│    └─Scaler: 2-2237                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2238                      [16, 128, 16, 16]         --
│    └─Empty: 2-2239                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2240                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-167               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2241        --                        --
│    └─One: 2-2242                       [1]                       --
│    └─OutputScale: 2-2243               --                        --
│    └─Empty: 2-2244                     [128, 128, 1, 1]          --
│    └─Empty: 2-2245                     [128, 128, 1, 1]          --
│    └─Empty: 2-2246                     [128]                     --
│    └─Empty: 2-2247                     [128]                     --
│    └─BatchNorm2d: 2-2248               [16, 128, 16, 16]         --
│    └─Scaler: 2-2249                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2250                      [16, 128, 16, 16]         --
│    └─Empty: 2-2251                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2252                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2253                 [16, 128, 16, 16]         --
│    └─Empty: 2-2254                     [16, 128, 16, 16]         --
│    └─Empty: 2-2255                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2256        --                        --
│    └─One: 2-2257                       [1]                       --
│    └─OutputScale: 2-2258               --                        --
│    └─Empty: 2-2259                     [128, 128, 3, 3]          --
│    └─Empty: 2-2260                     [128, 128, 3, 3]          --
│    └─Empty: 2-2261                     [128]                     --
│    └─Empty: 2-2262                     [128]                     --
│    └─BatchNorm2d: 2-2263               [16, 128, 16, 16]         --
│    └─Scaler: 2-2264                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2265                      [16, 128, 16, 16]         --
│    └─Empty: 2-2266                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2267                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-169        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2268                 [16, 128, 8, 8]           --
│    └─Empty: 2-2269                     [16, 128, 8, 8]           --
│    └─Empty: 2-2270                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2271        --                        --
│    └─One: 2-2272                       [1]                       --
│    └─OutputScale: 2-2273               --                        --
│    └─Empty: 2-2274                     [128, 128, 3, 3]          --
│    └─Empty: 2-2275                     [128, 128, 3, 3]          --
│    └─Empty: 2-2276                     [128]                     --
│    └─Empty: 2-2277                     [128]                     --
│    └─BatchNorm2d: 2-2278               [16, 128, 8, 8]           --
│    └─Scaler: 2-2279                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2280                      [16, 128, 8, 8]           --
│    └─Empty: 2-2281                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2282                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-170               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2283        --                        --
│    └─One: 2-2284                       [1]                       --
│    └─OutputScale: 2-2285               --                        --
│    └─Empty: 2-2286                     [16, 128, 1, 1]           --
│    └─Empty: 2-2287                     [16, 128, 1, 1]           --
│    └─Empty: 2-2288                     [16]                      --
│    └─Empty: 2-2289                     [16]                      --
│    └─BatchNorm2d: 2-2290               [16, 16, 8, 8]            --
│    └─Scaler: 2-2291                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2292                      [16, 16, 8, 8]            --
│    └─Empty: 2-2293                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2294                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-171        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2295                 [16, 128, 8, 8]           --
│    └─Empty: 2-2296                     [16, 128, 8, 8]           --
│    └─Empty: 2-2297                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2298        --                        --
│    └─One: 2-2299                       [1]                       --
│    └─OutputScale: 2-2300               --                        --
│    └─Empty: 2-2301                     [16, 128, 3, 3]           --
│    └─Empty: 2-2302                     [16, 128, 3, 3]           --
│    └─Empty: 2-2303                     [16]                      --
│    └─Empty: 2-2304                     [16]                      --
│    └─BatchNorm2d: 2-2305               [16, 16, 8, 8]            --
│    └─Scaler: 2-2306                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2307                      [16, 16, 8, 8]            --
│    └─Empty: 2-2308                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2309                     [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-172               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2310        --                        --
│    └─One: 2-2311                       [1]                       --
│    └─OutputScale: 2-2312               --                        --
│    └─Empty: 2-2313                     [128, 48, 1, 1]           --
│    └─Empty: 2-2314                     [128, 48, 1, 1]           --
│    └─Empty: 2-2315                     [128]                     --
│    └─Empty: 2-2316                     [128]                     --
│    └─BatchNorm2d: 2-2317               [16, 128, 64, 64]         --
│    └─Scaler: 2-2318                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2319                      [16, 128, 64, 64]         --
│    └─Empty: 2-2320                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2321                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-173               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2322        --                        --
│    └─One: 2-2323                       [1]                       --
│    └─OutputScale: 2-2324               --                        --
│    └─Empty: 2-2325                     [128, 128, 3, 3]          --
│    └─Empty: 2-2326                     [128, 128, 3, 3]          --
│    └─Empty: 2-2327                     [128]                     --
│    └─Empty: 2-2328                     [128]                     --
│    └─BatchNorm2d: 2-2329               [16, 128, 64, 64]         --
│    └─Scaler: 2-2330                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2331                      [16, 128, 64, 64]         --
│    └─Empty: 2-2332                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2333                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-174        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2334                 [16, 128, 32, 32]         --
│    └─Empty: 2-2335                     [16, 128, 32, 32]         --
│    └─Empty: 2-2336                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2337        --                        --
│    └─One: 2-2338                       [1]                       --
│    └─OutputScale: 2-2339               --                        --
│    └─Empty: 2-2340                     [128, 128, 3, 3]          --
│    └─Empty: 2-2341                     [128, 128, 3, 3]          --
│    └─Empty: 2-2342                     [128]                     --
│    └─Empty: 2-2343                     [128]                     --
│    └─BatchNorm2d: 2-2344               [16, 128, 32, 32]         --
│    └─Scaler: 2-2345                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2346                      [16, 128, 32, 32]         --
│    └─Empty: 2-2347                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2348                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-175               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2349        --                        --
│    └─One: 2-2350                       [1]                       --
│    └─OutputScale: 2-2351               --                        --
│    └─Empty: 2-2352                     [128, 128, 1, 1]          --
│    └─Empty: 2-2353                     [128, 128, 1, 1]          --
│    └─Empty: 2-2354                     [128]                     --
│    └─Empty: 2-2355                     [128]                     --
│    └─BatchNorm2d: 2-2356               [16, 128, 32, 32]         --
│    └─Scaler: 2-2357                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2358                      [16, 128, 32, 32]         --
│    └─Empty: 2-2359                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2360                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-176        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2361                 [16, 128, 32, 32]         --
│    └─Empty: 2-2362                     [16, 128, 32, 32]         --
│    └─Empty: 2-2363                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2364        --                        --
│    └─One: 2-2365                       [1]                       --
│    └─OutputScale: 2-2366               --                        --
│    └─Empty: 2-2367                     [128, 128, 3, 3]          --
│    └─Empty: 2-2368                     [128, 128, 3, 3]          --
│    └─Empty: 2-2369                     [128]                     --
│    └─Empty: 2-2370                     [128]                     --
│    └─BatchNorm2d: 2-2371               [16, 128, 32, 32]         --
│    └─Scaler: 2-2372                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2373                      [16, 128, 32, 32]         --
│    └─Empty: 2-2374                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2375                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2376                 [16, 128, 16, 16]         --
│    └─Empty: 2-2377                     [16, 128, 16, 16]         --
│    └─Empty: 2-2378                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2379        --                        --
│    └─One: 2-2380                       [1]                       --
│    └─OutputScale: 2-2381               --                        --
│    └─Empty: 2-2382                     [128, 128, 3, 3]          --
│    └─Empty: 2-2383                     [128, 128, 3, 3]          --
│    └─Empty: 2-2384                     [128]                     --
│    └─Empty: 2-2385                     [128]                     --
│    └─BatchNorm2d: 2-2386               [16, 128, 16, 16]         --
│    └─Scaler: 2-2387                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2388                      [16, 128, 16, 16]         --
│    └─Empty: 2-2389                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2390                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-178               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2391        --                        --
│    └─One: 2-2392                       [1]                       --
│    └─OutputScale: 2-2393               --                        --
│    └─Empty: 2-2394                     [128, 128, 1, 1]          --
│    └─Empty: 2-2395                     [128, 128, 1, 1]          --
│    └─Empty: 2-2396                     [128]                     --
│    └─Empty: 2-2397                     [128]                     --
│    └─BatchNorm2d: 2-2398               [16, 128, 16, 16]         --
│    └─Scaler: 2-2399                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2400                      [16, 128, 16, 16]         --
│    └─Empty: 2-2401                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2402                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2403                 [16, 128, 16, 16]         --
│    └─Empty: 2-2404                     [16, 128, 16, 16]         --
│    └─Empty: 2-2405                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2406        --                        --
│    └─One: 2-2407                       [1]                       --
│    └─OutputScale: 2-2408               --                        --
│    └─Empty: 2-2409                     [128, 128, 3, 3]          --
│    └─Empty: 2-2410                     [128, 128, 3, 3]          --
│    └─Empty: 2-2411                     [128]                     --
│    └─Empty: 2-2412                     [128]                     --
│    └─BatchNorm2d: 2-2413               [16, 128, 16, 16]         --
│    └─Scaler: 2-2414                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2415                      [16, 128, 16, 16]         --
│    └─Empty: 2-2416                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2417                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-180        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2418                 [16, 128, 8, 8]           --
│    └─Empty: 2-2419                     [16, 128, 8, 8]           --
│    └─Empty: 2-2420                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2421        --                        --
│    └─One: 2-2422                       [1]                       --
│    └─OutputScale: 2-2423               --                        --
│    └─Empty: 2-2424                     [128, 128, 3, 3]          --
│    └─Empty: 2-2425                     [128, 128, 3, 3]          --
│    └─Empty: 2-2426                     [128]                     --
│    └─Empty: 2-2427                     [128]                     --
│    └─BatchNorm2d: 2-2428               [16, 128, 8, 8]           --
│    └─Scaler: 2-2429                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2430                      [16, 128, 8, 8]           --
│    └─Empty: 2-2431                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2432                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-181               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2433        --                        --
│    └─One: 2-2434                       [1]                       --
│    └─OutputScale: 2-2435               --                        --
│    └─Empty: 2-2436                     [16, 128, 1, 1]           --
│    └─Empty: 2-2437                     [16, 128, 1, 1]           --
│    └─Empty: 2-2438                     [16]                      --
│    └─Empty: 2-2439                     [16]                      --
│    └─BatchNorm2d: 2-2440               [16, 16, 8, 8]            --
│    └─Scaler: 2-2441                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2442                      [16, 16, 8, 8]            --
│    └─Empty: 2-2443                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2444                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2445                 [16, 128, 8, 8]           --
│    └─Empty: 2-2446                     [16, 128, 8, 8]           --
│    └─Empty: 2-2447                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2448        --                        --
│    └─One: 2-2449                       [1]                       --
│    └─OutputScale: 2-2450               --                        --
│    └─Empty: 2-2451                     [16, 128, 3, 3]           --
│    └─Empty: 2-2452                     [16, 128, 3, 3]           --
│    └─Empty: 2-2453                     [16]                      --
│    └─Empty: 2-2454                     [16]                      --
│    └─BatchNorm2d: 2-2455               [16, 16, 8, 8]            --
│    └─Scaler: 2-2456                    [16, 16, 8, 8]            --
│    └─ReLU: 2-2457                      [16, 16, 8, 8]            --
│    └─Empty: 2-2458                     [16, 16, 8, 8]            --
│    └─Clamp: 2-2459                     [16, 16, 8, 8]            --
├─Linear: 1-183                          [16, 4]                   4,102
│    └─OutputShiftSqueeze: 2-2460        --                        --
│    └─One: 2-2461                       [1]                       --
│    └─OutputScale: 2-2462               --                        --
│    └─Empty: 2-2463                     [4, 1024]                 --
│    └─Empty: 2-2464                     [4, 1024]                 --
│    └─Empty: 2-2465                     [16, 4]                   --
│    └─Empty: 2-2466                     [16, 4]                   --
│    └─Clamp: 2-2467                     [16, 4]                   --
├─Linear: 1-184                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2468        --                        --
│    └─One: 2-2469                       [1]                       --
│    └─OutputScale: 2-2470               --                        --
│    └─Empty: 2-2471                     [4, 1024]                 --
│    └─Empty: 2-2472                     [4, 1024]                 --
│    └─Empty: 2-2473                     [16, 4]                   --
│    └─Empty: 2-2474                     [16, 4]                   --
│    └─Clamp: 2-2475                     [16, 4]                   --
├─Linear: 1-185                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2476        --                        --
│    └─One: 2-2477                       [1]                       --
│    └─OutputScale: 2-2478               --                        --
│    └─Empty: 2-2479                     [4, 1024]                 --
│    └─Empty: 2-2480                     [4, 1024]                 --
│    └─Empty: 2-2481                     [16, 4]                   --
│    └─Empty: 2-2482                     [16, 4]                   --
│    └─Clamp: 2-2483                     [16, 4]                   --
├─Linear: 1-186                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2484        --                        --
│    └─One: 2-2485                       [1]                       --
│    └─OutputScale: 2-2486               --                        --
│    └─Empty: 2-2487                     [4, 1024]                 --
│    └─Empty: 2-2488                     [4, 1024]                 --
│    └─Empty: 2-2489                     [16, 4]                   --
│    └─Empty: 2-2490                     [16, 4]                   --
│    └─Clamp: 2-2491                     [16, 4]                   --
├─Linear: 1-187                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2492        --                        --
│    └─One: 2-2493                       [1]                       --
│    └─OutputScale: 2-2494               --                        --
│    └─Empty: 2-2495                     [4, 1024]                 --
│    └─Empty: 2-2496                     [4, 1024]                 --
│    └─Empty: 2-2497                     [16, 4]                   --
│    └─Empty: 2-2498                     [16, 4]                   --
│    └─Clamp: 2-2499                     [16, 4]                   --
├─Linear: 1-188                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2500        --                        --
│    └─One: 2-2501                       [1]                       --
│    └─OutputScale: 2-2502               --                        --
│    └─Empty: 2-2503                     [4, 1024]                 --
│    └─Empty: 2-2504                     [4, 1024]                 --
│    └─Empty: 2-2505                     [16, 4]                   --
│    └─Empty: 2-2506                     [16, 4]                   --
│    └─Clamp: 2-2507                     [16, 4]                   --
├─Linear: 1-189                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2508        --                        --
│    └─One: 2-2509                       [1]                       --
│    └─OutputScale: 2-2510               --                        --
│    └─Empty: 2-2511                     [4, 1024]                 --
│    └─Empty: 2-2512                     [4, 1024]                 --
│    └─Empty: 2-2513                     [16, 4]                   --
│    └─Empty: 2-2514                     [16, 4]                   --
│    └─Clamp: 2-2515                     [16, 4]                   --
├─Linear: 1-190                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2516        --                        --
│    └─One: 2-2517                       [1]                       --
│    └─OutputScale: 2-2518               --                        --
│    └─Empty: 2-2519                     [4, 1024]                 --
│    └─Empty: 2-2520                     [4, 1024]                 --
│    └─Empty: 2-2521                     [16, 4]                   --
│    └─Empty: 2-2522                     [16, 4]                   --
│    └─Clamp: 2-2523                     [16, 4]                   --
├─Linear: 1-191                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2524        --                        --
│    └─One: 2-2525                       [1]                       --
│    └─OutputScale: 2-2526               --                        --
│    └─Empty: 2-2527                     [4, 1024]                 --
│    └─Empty: 2-2528                     [4, 1024]                 --
│    └─Empty: 2-2529                     [16, 4]                   --
│    └─Empty: 2-2530                     [16, 4]                   --
│    └─Clamp: 2-2531                     [16, 4]                   --
├─Linear: 1-192                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2532        --                        --
│    └─One: 2-2533                       [1]                       --
│    └─OutputScale: 2-2534               --                        --
│    └─Empty: 2-2535                     [4, 1024]                 --
│    └─Empty: 2-2536                     [4, 1024]                 --
│    └─Empty: 2-2537                     [16, 4]                   --
│    └─Empty: 2-2538                     [16, 4]                   --
│    └─Clamp: 2-2539                     [16, 4]                   --
├─Linear: 1-193                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2540        --                        --
│    └─One: 2-2541                       [1]                       --
│    └─OutputScale: 2-2542               --                        --
│    └─Empty: 2-2543                     [4, 1024]                 --
│    └─Empty: 2-2544                     [4, 1024]                 --
│    └─Empty: 2-2545                     [16, 4]                   --
│    └─Empty: 2-2546                     [16, 4]                   --
│    └─Clamp: 2-2547                     [16, 4]                   --
├─Linear: 1-194                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2548        --                        --
│    └─One: 2-2549                       [1]                       --
│    └─OutputScale: 2-2550               --                        --
│    └─Empty: 2-2551                     [4, 1024]                 --
│    └─Empty: 2-2552                     [4, 1024]                 --
│    └─Empty: 2-2553                     [16, 4]                   --
│    └─Empty: 2-2554                     [16, 4]                   --
│    └─Clamp: 2-2555                     [16, 4]                   --
├─Linear: 1-195                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2556        --                        --
│    └─One: 2-2557                       [1]                       --
│    └─OutputScale: 2-2558               --                        --
│    └─Empty: 2-2559                     [4, 1024]                 --
│    └─Empty: 2-2560                     [4, 1024]                 --
│    └─Empty: 2-2561                     [16, 4]                   --
│    └─Empty: 2-2562                     [16, 4]                   --
│    └─Clamp: 2-2563                     [16, 4]                   --
├─Linear: 1-196                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2564        --                        --
│    └─One: 2-2565                       [1]                       --
│    └─OutputScale: 2-2566               --                        --
│    └─Empty: 2-2567                     [4, 1024]                 --
│    └─Empty: 2-2568                     [4, 1024]                 --
│    └─Empty: 2-2569                     [16, 4]                   --
│    └─Empty: 2-2570                     [16, 4]                   --
│    └─Clamp: 2-2571                     [16, 4]                   --
├─Linear: 1-197                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2572        --                        --
│    └─One: 2-2573                       [1]                       --
│    └─OutputScale: 2-2574               --                        --
│    └─Empty: 2-2575                     [4, 1024]                 --
│    └─Empty: 2-2576                     [4, 1024]                 --
│    └─Empty: 2-2577                     [16, 4]                   --
│    └─Empty: 2-2578                     [16, 4]                   --
│    └─Clamp: 2-2579                     [16, 4]                   --
├─Linear: 1-198                          [16, 4]                   (recursive)
│    └─OutputShiftSqueeze: 2-2580        --                        --
│    └─One: 2-2581                       [1]                       --
│    └─OutputScale: 2-2582               --                        --
│    └─Empty: 2-2583                     [4, 1024]                 --
│    └─Empty: 2-2584                     [4, 1024]                 --
│    └─Empty: 2-2585                     [16, 4]                   --
│    └─Empty: 2-2586                     [16, 4]                   --
│    └─Clamp: 2-2587                     [16, 4]                   --
==========================================================================================
Total params: 949,480
Trainable params: 949,408
Non-trainable params: 72
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 3.78
Estimated Total Size (MB): 205.11
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.331 | Acc: 36.250% | Wgt Acc: 37.317%
	I - Batch: 100 | Loss: 1.276 | Acc: 42.438% | Wgt Acc: 43.129%
	I - Batch: 150 | Loss: 1.228 | Acc: 45.458% | Wgt Acc: 46.212%
I - num batch: 160
I - Train -- Loss: 1.218 | Acc: 46.172% | Wgt Acc: 46.860% | LR: 1.000000e-04 | Dur: 142.47s
I - Confusion Matrix: [row->prediction - col->label]
[[292.  55.  87. 145.]
 [ 96. 334. 248.  72.]
 [ 96. 120. 291.  62.]
 [213.  69. 108. 259.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.172 | Acc: 45.872% | Wgt Acc: 45.924% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[38.  1.  4. 19.]
 [13. 48. 32. 16.]
 [21. 28. 36. 23.]
 [16.  1.  3. 28.]]

I - Local maximum validation set accuracy:  45.87

I - Validation set results: 
[14-1-2-0.19][50-3-1-0.23][124-2-1-0.89][127-0-0-0.66][443-2-2-0.92][567-0-0-0.74][573-1-1-1.01][615-0-0-0.50][695-1-2-0.34][722-3-0-0.85]
[826-0-0-0.57][878-0-3-0.38][1103-0-2-0.28][1212-3-2-0.17][1368-0-2-0.08][2181-2-0-0.33][2476-2-2-0.70][2721-2-1-0.77][2818-1-1-0.44][2886-2-1-1.65]
[3231-2-2-1.18][3333-2-1-0.48][3482-2-2-1.04][3536-3-1-0.35][3625-1-1-1.10][3909-0-1-1.19][4035-0-0-0.69][4140-0-2-0.80][4214-1-3-0.35][4346-1-0-0.50]
[4581-2-2-1.04][4708-3-2-0.83][4838-3-1-0.43][4845-1-1-0.42][4868-0-0-0.23][4939-0-1-0.93][4984-2-2-0.32][5078-1-2-0.80][5396-0-0-1.37][5479-1-1-0.84]
[5717-0-1-0.36][5843-1-1-0.79][5949-3-3-1.04][5987-2-1-0.64][6014-3-1-0.65][6033-3-2-0.26][6313-0-0-0.27][6421-3-3-0.48][6500-1-1-0.55][6583-3-3-0.40]
[6683-3-1-0.36][6825-2-0-0.01][6998-3-2-0.42][7049-3-2-0.23][7517-1-1-1.07][7521-1-1-0.57][7528-1-2-0.29][7949-1-2-0.76][8135-1-1-0.57][8185-3-0-0.67]
[8269-3-2-0.56][8273-3-3-0.55][8543-3-0-1.28][8666-1-1-0.42][8672-0-0-1.13][8903-1-2-0.87][9001-2-1-0.82][9036-2-2-1.19][9281-3-2-0.27][9300-2-2-0.71]
[9571-0-0-0.41][9617-1-1-0.81][9644-2-2-0.75][9705-2-1-0.68][9801-0-1-0.23][9803-3-1-0.21][9865-3-0-0.67][9896-2-1-0.82][10314-1-1-1.20][10337-3-3-0.18]
[10403-0-2-0.79][10653-2-1-0.65][10704-2-1-0.62][10719-1-1-1.23][10727-1-1-1.54][10836-0-3-1.45][10969-2-2--0.01][11042-0-2-0.29][11088-1-2-1.15][11322-0-0-0.67]
[11398-2-2-0.75][11499-0-1-0.59][11502-3-0-0.30][11512-3-1-0.83][11608-1-1-1.17][11610-0-1-0.35][11692-0-3-0.43][11905-0-0-1.16][11993-1-1-1.39][12002-2-1-0.27]
[12052-0-0-0.54][12201-0-3-1.23][12235-2-1-0.95][12320-1-1-0.39][12377-2-1-0.83][12398-2-2-0.12][12503-1-2-0.78][12617-0-1-0.81][12685-3-2-0.57][12738-2-1-0.11]
[12742-2-2-1.32][12823-0-3-1.22][13110-1-2-0.86][13240-3-3-0.39][13253-1-1-1.79][13273-0-0-1.29][13634-1-1-0.47][13763-2-1-0.28][13905-3-0-0.44][14060-2-1-0.97]
[14065-3-3-0.58][14147-3-3-0.05][14595-2-1-0.82][14687-2-2-0.60][14788-2-2-0.71][14869-1-1-0.64][14872-3-2-0.80][14877-1-1-0.76][14927-0-3-0.11][15066-0-0-1.31]
[15175-1-2-0.68][15178-2-0-0.09][15375-3-0-0.77][15389-3-3-0.61][15568-2-1-0.08][15675-3-1-0.45][15869-1-2-0.33][16207-3-0-0.09][16236-0-2-0.19][16302-3-3-0.60]
[16331-2-2-1.50][16381-0-2-0.30][16488-1-1-1.30][16495-0-2-0.21][16650-0-0-1.17][16719-1-2-0.19][16801-0-0-0.87][16828-0-3-0.97][17137-3-3-0.69][17245-1-2-0.13]
[17278-3-1--0.02][17282-0-0-0.03][17311-2-2-0.83][17336-2-1-0.94][17608-3-0-1.29][17627-0-0-0.09][17877-3-1-0.58][17924-1-2-0.28][17984-3-0-0.72][18211-0-2-0.82]
[18276-3-0-0.70][18287-1-1-0.58][18394-0-0-0.81][18428-0-0-1.40][18442-0-0-0.68][18478-3-0-0.61][18607-0-1-0.85][18616-0-2-0.43][18663-0-0-0.51][18718-0-0-0.94]
[18766-2-2-0.62][18824-2-2-1.20][18890-3-1-0.81][18930-3-2-0.23][18938-3-3-0.20][19817-1-2-0.70][19839-0-2-0.83][19930-3-0-0.66][19944-0-2-0.68][20036-2-2-0.78]
[20101-3-1-0.23][20474-1-2-1.04][20547-3-1-0.57][20929-2-1-0.59][21245-1-1-0.88][21257-3-3-0.04][21293-1-1-1.21][21316-1-1-0.56][21384-1-2-0.80][21448-1-1-1.10]
[21483-0-0-0.60][21487-2-2-1.05][21714-0-2-0.07][21943-3-2-1.04][21947-0-0-0.09][21948-0-0-0.92][21965-2-2-1.05][21998-1-1-0.94][22025-0-2-0.68][22228-3-0-0.18]
[22446-1-1-0.87][22494-3-3-0.93][22757-0-0-1.12][22811-3-3-0.63][22976-3-2-1.13][22985-3-0-0.60][23014-0-3-1.04][23112-1-1-0.93][23144-3-3-0.54][23168-2-2-0.70]
[23219-0-2-0.22][23363-3-2-0.42][23470-0-1-0.20][23486-2-2-0.42][23497-0-3-1.18][23516-0-0-1.48][23690-1-2-0.41][23921-2-1-0.80][23936-1-2-0.86][24040-3-2-0.44]
[24111-1-1-1.31][24182-0-3-1.36][24238-3-3-0.59][24290-2-2-0.50][24345-0-2-0.38][24364-1-2-0.07][24427-3-2-0.47][24477-2-2-0.77][24495-2-1-1.26][24893-2-1-0.74]
[25012-1-2-0.09][25121-2-2-0.99][25165-3-2-0.49][25183-0-1-0.40][25297-3-3-0.56][25398-0-0-0.45][25574-2-2-1.12][25644-1-1-1.07][25718-1-1-0.35][25774-2-2--0.03]
[26032-3-0-0.39][26051-3-3-0.85][26120-0-0-0.10][26321-1-1-0.34][26732-1-1-0.96][26784-3-3-1.12][26827-3-3-0.27][26833-0-3-0.66][26838-2-3-0.08][26860-1-2-0.87]
[26948-0-2-0.31][27049-3-0-0.41][27098-1-1-0.88][27526-0-0-0.69][27639-3-2-0.49][27698-3-3-0.70][27772-0-3-0.56][27890-1-1-0.93][28040-0-0-0.13][28503-2-2-1.49]
[28577-1-1-0.65][28959-0-3-1.42][29198-3-2-1.24][29777-0-0-1.32][29877-2-1-0.18][30035-1-2-0.74][30098-0-3-0.83][30326-1-1-1.28][30572-2-1-0.27][30716-0-1-0.45]
[30806-2-1-0.12][30906-1-1-1.16][31007-0-2-0.62][31181-3-2-0.17][31238-0-0-0.55][31347-0-3-1.00][31422-2-1-0.86][31429-3-2-0.20][31431-0-0-0.21][31432-1-1-0.70]
[31477-0-3-1.10][31524-1-2-0.45][31597-1-1-1.12][31619-1-2-0.73][31701-0-2-0.28][31755-0-0-0.75][31854-3-3-0.49][32074-1-1-0.11][32078-3-2-0.16][32111-1-1-1.31]
[32127-1-2-1.35][32140-3-3-0.59][32263-2-0-0.10][32365-0-1-0.53][32411-2-3-1.22][32429-3-0-0.77][32473-3-3-0.88][32574-3-3-0.73][32584-0-2-0.84][32622-0-2-1.17]
[32858-3-2-0.10][32969-3-0-0.89][33016-2-2-0.67][33031-1-2-0.33][33035-2-2-0.84][33133-2-2-0.41][33173-2-1-0.64][33175-3-1-0.77][33306-3-1-0.83][33309-2-2-0.46]
[33474-0-1-0.63][33478-2-2-0.30][33618-1-1-0.21][33712-0-0-0.17][33782-2-1-1.22][33914-3-3-0.33][34076-3-1-0.39][34112-2-1-0.63][34138-2-1-0.87][34239-1-1-1.04]
[34364-2-1-0.94][34617-1-2-1.27][34751-3-3-0.99][34783-2-2-0.61][35015-3-2-0.12][35018-1-1-1.07][35288-2-3-0.10]
---------------------------
I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.014 | Acc: 58.875% | Wgt Acc: 59.273%
	I - Batch: 100 | Loss: 1.008 | Acc: 59.812% | Wgt Acc: 60.017%
	I - Batch: 150 | Loss: 0.989 | Acc: 60.750% | Wgt Acc: 60.841%
I - num batch: 160
I - Train -- Loss: 0.983 | Acc: 61.052% | Wgt Acc: 61.129% | LR: 1.000000e-04 | Dur: 145.65s
I - Confusion Matrix: [row->prediction - col->label]
[[440.  20.  35. 150.]
 [ 58. 409. 217.  51.]
 [ 61. 121. 425.  56.]
 [138.  28.  57. 281.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.187 | Acc: 51.376% | Wgt Acc: 51.019% | Dur: 13.10s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  9. 11. 25.]
 [ 0. 23.  5.  0.]
 [ 0. 20. 29.  5.]
 [28. 26. 30. 56.]]

I - Local maximum validation set accuracy:  51.38

I - Validation set results: 
[14-1-3-0.22][50-3-0-1.39][124-2-2-0.18][127-0-0-2.97][443-2-2-1.04][567-0-0-2.91][573-1-1-0.18][615-0-0-2.08][695-1-3-0.46][722-3-0-2.60]
[826-0-0-2.30][878-0-3-2.32][1103-0-0-1.06][1212-3-3-1.44][1368-0-0-1.55][2181-2-3-1.41][2476-2-3-0.30][2721-2-2-0.84][2818-1-0-0.17][2886-2-1-1.80]
[3231-2-2-1.56][3333-2-3-1.39][3482-2-2-0.41][3536-3-3-1.33][3625-1-1-0.26][3909-0-0-0.17][4035-0-3-2.20][4140-0-0-1.61][4214-1-3-1.68][4346-1-3-1.67]
[4581-2-2-0.89][4708-3-3-0.91][4838-3-3-0.56][4845-1-3-0.66][4868-0-0-2.25][4939-0-0-0.64][4984-2-3-1.61][5078-1-2-0.21][5396-0-0-3.26][5479-1-2-0.18]
[5717-0-0-2.17][5843-1-3-0.24][5949-3-3-2.33][5987-2-1-0.95][6014-3-3-1.41][6033-3-0-2.15][6313-0-3-1.70][6421-3-3-2.12][6500-1-3-0.96][6583-3-3-1.78]
[6683-3-3-1.30][6825-2-3-1.42][6998-3-3-0.72][7049-3-3-1.51][7517-1-1-0.35][7521-1-3-0.57][7528-1-3-1.22][7949-1-2-0.36][8135-1-0-0.92][8185-3-0-2.55]
[8269-3-0-0.09][8273-3-3-2.21][8543-3-0-2.84][8666-1-3-0.74][8672-0-0-3.17][8903-1-3-0.35][9001-2-1-0.65][9036-2-2-0.97][9281-3-0-1.09][9300-2-0-0.73]
[9571-0-3-2.33][9617-1-1-0.08][9644-2-2-0.36][9705-2-2-0.10][9801-0-3-1.89][9803-3-3-1.34][9865-3-3-2.61][9896-2-2-0.46][10314-1-2-0.85][10337-3-3-2.23]
[10403-0-0-0.78][10653-2-3-0.30][10704-2-3-0.98][10719-1-1-0.90][10727-1-1-1.42][10836-0-0-3.38][10969-2-3-1.27][11042-0-0-1.74][11088-1-2-1.16][11322-0-0-3.02]
[11398-2-2-1.26][11499-0-3-1.42][11502-3-3-2.38][11512-3-3-1.55][11608-1-1-1.51][11610-0-3-1.46][11692-0-3-2.03][11905-0-0-3.44][11993-1-2-0.47][12002-2-0-1.84]
[12052-0-0-2.11][12201-0-0-2.69][12235-2-1-0.71][12320-1-0-0.81][12377-2-0-0.11][12398-2-3-1.20][12503-1-1-1.02][12617-0-3-0.63][12685-3-3-0.92][12738-2-3-1.41]
[12742-2-2-1.27][12823-0-3-2.89][13110-1-3-0.29][13240-3-3-2.24][13253-1-1-2.13][13273-0-0-3.44][13634-1-3-0.24][13763-2-3-1.42][13905-3-0-1.95][14060-2-3-0.42]
[14065-3-3-2.11][14147-3-3-1.61][14595-2-2-0.67][14687-2-3-0.97][14788-2-3-0.75][14869-1-1--0.01][14872-3-0-0.62][14877-1-1-0.23][14927-0-3-2.11][15066-0-0-3.53]
[15175-1-2-0.31][15178-2-3-1.44][15375-3-3-1.81][15389-3-3-2.43][15568-2-1-0.43][15675-3-3-1.78][15869-1-0-0.40][16207-3-0-1.53][16236-0-3-1.30][16302-3-0-1.98]
[16331-2-2-1.53][16381-0-0-1.69][16488-1-1-0.68][16495-0-0-2.02][16650-0-0-3.21][16719-1-3-0.49][16801-0-0-3.38][16828-0-3-2.02][17137-3-0-2.33][17245-1-0-0.62]
[17278-3-0-1.01][17282-0-0-0.77][17311-2-0-0.41][17336-2-3-0.80][17608-3-0-3.02][17627-0-3-1.09][17877-3-2-0.15][17924-1-0-0.73][17984-3-0-2.68][18211-0-3-2.04]
[18276-3-0-2.87][18287-1-0-0.45][18394-0-0-2.41][18428-0-0-0.16][18442-0-0-2.46][18478-3-0-2.39][18607-0-0-0.70][18616-0-0-0.66][18663-0-0-2.21][18718-0-0-2.67]
[18766-2-2-0.20][18824-2-2-0.46][18890-3-2-0.13][18930-3-0-1.34][18938-3-3-1.78][19817-1-2-0.15][19839-0-0-0.51][19930-3-3-2.22][19944-0-0-0.30][20036-2-0-0.18]
[20101-3-3-1.45][20474-1-2-1.27][20547-3-0-1.40][20929-2-3-0.30][21245-1-2-0.73][21257-3-3-1.37][21293-1-1-0.52][21316-1-3-0.42][21384-1-2-0.43][21448-1-2-0.35]
[21483-0-0-2.24][21487-2-2-1.05][21714-0-0-1.66][21943-3-3-0.39][21947-0-0-2.08][21948-0-0-3.04][21965-2-2-0.97][21998-1-2-0.05][22025-0-3-1.38][22228-3-3-2.06]
[22446-1-1-1.01][22494-3-0-2.48][22757-0-3-2.68][22811-3-3-2.30][22976-3-2-0.52][22985-3-3-2.67][23014-0-3-3.00][23112-1-1-0.71][23144-3-3-2.35][23168-2-0-0.02]
[23219-0-3-2.08][23363-3-3-2.31][23470-0-0-0.87][23486-2-3-1.59][23497-0-3-2.76][23516-0-0-3.57][23690-1-3-0.93][23921-2-2-0.45][23936-1-3-0.79][24040-3-3-0.90]
[24111-1-1-1.19][24182-0-3-3.06][24238-3-3-2.21][24290-2-0-1.64][24345-0-0-1.61][24364-1-3-1.03][24427-3-3-2.58][24477-2-2-0.27][24495-2-0--0.04][24893-2-0-0.06]
[25012-1-3-0.47][25121-2-2-0.80][25165-3-3-1.56][25183-0-0-0.79][25297-3-3-2.49][25398-0-0-2.08][25574-2-2-0.30][25644-1-0-0.14][25718-1-3-0.59][25774-2-3-0.46]
[26032-3-3-2.03][26051-3-3-2.78][26120-0-0-1.45][26321-1-3-0.56][26732-1-1-0.19][26784-3-3-3.17][26827-3-3-2.29][26833-0-3-2.44][26838-2-3-0.06][26860-1-2-0.21]
[26948-0-0-1.08][27049-3-0-2.18][27098-1-3-1.12][27526-0-0-3.06][27639-3-3-1.65][27698-3-3-2.19][27772-0-3-2.31][27890-1-1-0.31][28040-0-0-0.85][28503-2-2-1.53]
[28577-1-1-0.49][28959-0-0-3.02][29198-3-2-0.76][29777-0-0-3.02][29877-2-3-1.02][30035-1-2-0.95][30098-0-3-2.32][30326-1-1-0.41][30572-2-3-0.81][30716-0-0-1.64]
[30806-2-3-1.23][30906-1-1-1.02][31007-0-0-1.75][31181-3-3-1.12][31238-0-3-2.26][31347-0-0-2.28][31422-2-2-0.12][31429-3-0-1.49][31431-0-0-1.90][31432-1-1-0.23]
[31477-0-3-2.73][31524-1-3-1.15][31597-1-2-0.85][31619-1-0-0.68][31701-0-0-2.40][31755-0-0-2.32][31854-3-3-2.14][32074-1-3-1.89][32078-3-3-1.50][32111-1-2-0.68]
[32127-1-2-1.19][32140-3-3-2.04][32263-2-0-0.92][32365-0-0-0.71][32411-2-3-2.92][32429-3-0-2.25][32473-3-0-1.77][32574-3-3-2.69][32584-0-0-0.68][32622-0-3-0.40]
[32858-3-3-1.71][32969-3-0-2.69][33016-2-2-0.50][33031-1-3-1.63][33035-2-2-0.52][33133-2-3-0.29][33173-2-3-0.61][33175-3-2-0.10][33306-3-3-0.26][33309-2-3-0.78]
[33474-0-3-0.75][33478-2-0-1.51][33618-1-3-0.87][33712-0-0-1.92][33782-2-2-0.87][33914-3-3-2.12][34076-3-3-1.14][34112-2-3-1.01][34138-2-3-0.44][34239-1-2-0.87]
[34364-2-2-1.01][34617-1-2-0.25][34751-3-3-2.50][34783-2-2-0.52][35015-3-3-1.39][35018-1-1-1.26][35288-2-3-1.00]
---------------------------
I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.867 | Acc: 69.375% | Wgt Acc: 69.677%
	I - Batch: 100 | Loss: 0.866 | Acc: 68.500% | Wgt Acc: 68.612%
	I - Batch: 150 | Loss: 0.863 | Acc: 67.917% | Wgt Acc: 67.765%
I - num batch: 160
I - Train -- Loss: 0.863 | Acc: 67.727% | Wgt Acc: 67.542% | LR: 1.000000e-04 | Dur: 165.78s
I - Confusion Matrix: [row->prediction - col->label]
[[510.  24.  35. 123.]
 [ 41. 416. 165.  42.]
 [ 45. 111. 480.  54.]
 [101.  27.  54. 319.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.928 | Acc: 61.774% | Wgt Acc: 60.734% | Dur: 17.91s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  4.  5. 31.]
 [ 4. 43. 14.  2.]
 [ 6. 25. 49. 10.]
 [11.  6.  7. 43.]]

I - Local maximum validation set accuracy:  61.77

I - Validation set results: 
[14-1-2-0.86][50-3-3-0.39][124-2-2-0.72][127-0-0-1.86][443-2-2-2.65][567-0-0-1.28][573-1-1-1.14][615-0-3-0.90][695-1-2-0.91][722-3-0-2.03]
[826-0-0-2.51][878-0-0-1.21][1103-0-0-0.32][1212-3-3-0.66][1368-0-0-0.79][2181-2-3-0.46][2476-2-2-1.01][2721-2-2-1.42][2818-1-1-0.34][2886-2-1-1.67]
[3231-2-2-1.74][3333-2-2-0.59][3482-2-2-1.00][3536-3-3-1.11][3625-1-1-1.79][3909-0-0-0.82][4035-0-3-1.40][4140-0-0-1.22][4214-1-2-0.21][4346-1-3-0.61]
[4581-2-2-1.73][4708-3-2-0.56][4838-3-1-0.34][4845-1-3-0.22][4868-0-0-2.28][4939-0-2-1.34][4984-2-2-0.91][5078-1-1-0.28][5396-0-0-2.85][5479-1-1-0.83]
[5717-0-0-1.28][5843-1-1-1.22][5949-3-3-0.64][5987-2-1-1.65][6014-3-3-0.52][6033-3-0-1.37][6313-0-0-0.82][6421-3-3-1.11][6500-1-1-0.33][6583-3-3-0.77]
[6683-3-3-0.91][6825-2-0-0.64][6998-3-3-0.52][7049-3-3-0.36][7517-1-1-1.59][7521-1-0--0.03][7528-1-3-0.25][7949-1-2-1.23][8135-1-0-1.12][8185-3-0-1.93]
[8269-3-2-0.26][8273-3-3-1.01][8543-3-0-2.48][8666-1-1-0.39][8672-0-0-2.22][8903-1-2-1.01][9001-2-1-0.70][9036-2-2-2.01][9281-3-3-0.07][9300-2-2-1.51]
[9571-0-3-0.66][9617-1-1-0.86][9644-2-2-1.46][9705-2-2-0.11][9801-0-0-1.70][9803-3-3-0.55][9865-3-3-1.52][9896-2-2-1.14][10314-1-2-0.95][10337-3-3-1.82]
[10403-0-2-0.19][10653-2-1-0.79][10704-2-1-0.48][10719-1-1-1.33][10727-1-1-1.47][10836-0-0-4.05][10969-2-3-1.22][11042-0-0-0.46][11088-1-1-2.16][11322-0-0-2.87]
[11398-2-2-2.11][11499-0-3-0.85][11502-3-0-1.54][11512-3-3-1.46][11608-1-1-1.93][11610-0-0-2.25][11692-0-0-1.33][11905-0-0-2.14][11993-1-2-1.00][12002-2-2-0.19]
[12052-0-0-1.69][12201-0-0-2.03][12235-2-1-0.94][12320-1-0-0.73][12377-2-1-0.34][12398-2-3--0.03][12503-1-1-1.36][12617-0-1-0.97][12685-3-3-0.14][12738-2-3-1.25]
[12742-2-2-1.78][12823-0-3-2.09][13110-1-1-0.94][13240-3-0-1.60][13253-1-1-2.09][13273-0-0-3.02][13634-1-2-0.33][13763-2-3-0.20][13905-3-0-0.55][14060-2-1-1.16]
[14065-3-3-0.83][14147-3-3-0.48][14595-2-2-1.35][14687-2-2-1.70][14788-2-2-1.37][14869-1-1-0.77][14872-3-0-0.79][14877-1-1-1.16][14927-0-0-0.65][15066-0-0-2.58]
[15175-1-1-0.86][15178-2-3-0.07][15375-3-0-1.24][15389-3-3-0.82][15568-2-1-1.18][15675-3-3-0.76][15869-1-2-1.03][16207-3-0-0.87][16236-0-2--0.16][16302-3-0-0.79]
[16331-2-2-2.24][16381-0-0-0.22][16488-1-1-1.35][16495-0-0-1.64][16650-0-0-2.43][16719-1-2-0.70][16801-0-0-3.65][16828-0-0-1.54][17137-3-0-1.88][17245-1-2-0.37]
[17278-3-0-0.37][17282-0-1-0.30][17311-2-2-1.50][17336-2-2-1.43][17608-3-0-1.94][17627-0-0-0.20][17877-3-0-0.44][17924-1-3-0.27][17984-3-0-2.01][18211-0-3-1.72]
[18276-3-0-1.50][18287-1-1-0.49][18394-0-0-1.86][18428-0-0-2.65][18442-0-0-2.21][18478-3-3-0.69][18607-0-0-0.73][18616-0-1-0.25][18663-0-0-1.37][18718-0-0-2.25]
[18766-2-2-0.98][18824-2-2-1.58][18890-3-2-0.71][18930-3-2-0.50][18938-3-3-0.57][19817-1-2-1.13][19839-0-0-0.85][19930-3-3-0.94][19944-0-2-0.58][20036-2-2-1.30]
[20101-3-0-0.46][20474-1-2-0.90][20547-3-1-1.05][20929-2-2-0.76][21245-1-1-1.04][21257-3-2-0.16][21293-1-1-1.67][21316-1-1-1.45][21384-1-2-0.56][21448-1-1-1.20]
[21483-0-0-1.55][21487-2-2-1.27][21714-0-0-1.06][21943-3-2-1.27][21947-0-0-0.75][21948-0-0-3.06][21965-2-2-0.83][21998-1-2-0.10][22025-0-3-0.43][22228-3-3-1.47]
[22446-1-1-1.97][22494-3-0-1.76][22757-0-0-2.31][22811-3-0-2.07][22976-3-2-1.07][22985-3-3-1.44][23014-0-0-2.71][23112-1-1-1.86][23144-3-0-1.48][23168-2-0-0.17]
[23219-0-3-1.13][23363-3-3-0.59][23470-0-0-0.44][23486-2-1-0.24][23497-0-3-2.25][23516-0-0-2.41][23690-1-1-1.00][23921-2-2-1.48][23936-1-2-1.27][24040-3-0-0.96]
[24111-1-1-1.50][24182-0-0-3.19][24238-3-3-0.99][24290-2-0-0.93][24345-0-0-1.25][24364-1-2-0.79][24427-3-0-1.77][24477-2-2-1.34][24495-2-1-1.05][24893-2-2-1.19]
[25012-1-1-0.57][25121-2-2-1.42][25165-3-3-0.46][25183-0-0-0.90][25297-3-3-1.37][25398-0-0-1.05][25574-2-1-1.34][25644-1-1-1.62][25718-1-1-0.50][25774-2-2-0.42]
[26032-3-0-1.68][26051-3-3-1.66][26120-0-0-0.50][26321-1-1-0.60][26732-1-1-1.12][26784-3-3-1.74][26827-3-3-0.95][26833-0-3-1.85][26838-2-2-0.53][26860-1-2-0.58]
[26948-0-0-0.78][27049-3-0-1.51][27098-1-0-1.30][27526-0-0-1.45][27639-3-3-0.68][27698-3-3-1.90][27772-0-0-3.02][27890-1-1-1.08][28040-0-0-1.10][28503-2-2-2.13]
[28577-1-1-1.61][28959-0-0-2.35][29198-3-2-0.34][29777-0-0-2.95][29877-2-2-0.47][30035-1-2-1.34][30098-0-0-1.44][30326-1-1-1.55][30572-2-2-0.85][30716-0-2-0.13]
[30806-2-2-0.20][30906-1-1-1.94][31007-0-0-0.71][31181-3-0-0.75][31238-0-3-1.73][31347-0-0-2.86][31422-2-2-0.84][31429-3-0-0.36][31431-0-1--0.02][31432-1-1-1.30]
[31477-0-0-1.88][31524-1-2-0.96][31597-1-2-1.89][31619-1-3-0.15][31701-0-0-1.46][31755-0-0-1.49][31854-3-3-1.13][32074-1-2-0.91][32078-3-3-1.25][32111-1-1-1.75]
[32127-1-2-2.10][32140-3-3-0.65][32263-2-0-0.48][32365-0-0-0.19][32411-2-0-1.55][32429-3-0-2.60][32473-3-3-0.97][32574-3-0-2.43][32584-0-0-0.91][32622-0-2-0.55]
[32858-3-0-1.75][32969-3-0-1.31][33016-2-2-0.89][33031-1-3-0.36][33035-2-2-1.64][33133-2-2-1.09][33173-2-2-0.47][33175-3-2-1.26][33306-3-2-0.82][33309-2-3-0.16]
[33474-0-0-0.14][33478-2-2-0.28][33618-1-1-1.16][33712-0-0-0.71][33782-2-1-1.96][33914-3-3-1.24][34076-3-3-0.75][34112-2-1-0.81][34138-2-2-0.85][34239-1-2-0.81]
[34364-2-2-1.63][34617-1-2-1.14][34751-3-3-1.25][34783-2-2-1.24][35015-3-3-0.56][35018-1-1-1.59][35288-2-2-0.71]
---------------------------
I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.824 | Acc: 69.250% | Wgt Acc: 69.017%
	I - Batch: 100 | Loss: 0.780 | Acc: 70.875% | Wgt Acc: 70.884%
	I - Batch: 150 | Loss: 0.766 | Acc: 71.833% | Wgt Acc: 71.756%
I - num batch: 160
I - Train -- Loss: 0.763 | Acc: 72.046% | Wgt Acc: 71.948% | LR: 1.000000e-04 | Dur: 198.79s
I - Confusion Matrix: [row->prediction - col->label]
[[526.  20.  27. 119.]
 [ 34. 452. 137.  32.]
 [ 39.  86. 516.  46.]
 [ 98.  20.  54. 341.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.923 | Acc: 60.245% | Wgt Acc: 59.851% | Dur: 16.66s
I - Confusion Matrix: [row->prediction - col->label]
[[51.  1.  3. 13.]
 [10. 46. 15.  7.]
 [11. 29. 53. 19.]
 [16.  2.  4. 47.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.664 | Acc: 78.375% | Wgt Acc: 78.059%
	I - Batch: 100 | Loss: 0.683 | Acc: 76.312% | Wgt Acc: 76.212%
	I - Batch: 150 | Loss: 0.672 | Acc: 76.708% | Wgt Acc: 76.547%
I - num batch: 160
I - Train -- Loss: 0.668 | Acc: 76.875% | Wgt Acc: 76.699% | LR: 1.000000e-04 | Dur: 199.78s
I - Confusion Matrix: [row->prediction - col->label]
[[546.  12.  26. 110.]
 [ 26. 483.  97.  31.]
 [ 28.  73. 574.  42.]
 [ 97.  10.  37. 355.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.952 | Acc: 64.526% | Wgt Acc: 64.334% | Dur: 17.23s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  9.  7. 18.]
 [ 0. 41. 10.  0.]
 [ 0. 20. 47.  6.]
 [27.  8. 11. 62.]]

I - Local maximum validation set accuracy:  64.53

I - Validation set results: 
[14-1-2-0.82][50-3-3-0.93][124-2-2-1.08][127-0-0-3.15][443-2-2-2.34][567-0-0-1.91][573-1-1-0.94][615-0-3-1.88][695-1-2-0.64][722-3-0-2.73]
[826-0-0-3.03][878-0-3-2.24][1103-0-0-1.11][1212-3-3-1.24][1368-0-0-2.07][2181-2-0-1.31][2476-2-2-0.35][2721-2-2-1.74][2818-1-1-0.53][2886-2-1-2.27]
[3231-2-2-2.30][3333-2-3-0.52][3482-2-2-1.20][3536-3-3-0.76][3625-1-1-2.26][3909-0-0-1.52][4035-0-3-1.58][4140-0-0-2.51][4214-1-3-1.85][4346-1-3-1.22]
[4581-2-2-0.98][4708-3-3-0.38][4838-3-0-0.09][4845-1-3-0.40][4868-0-0-3.43][4939-0-3-0.41][4984-2-2-0.99][5078-1-0-0.62][5396-0-0-3.45][5479-1-2-0.52]
[5717-0-0-2.68][5843-1-1-2.05][5949-3-3-1.58][5987-2-1-1.46][6014-3-3-0.88][6033-3-0-1.90][6313-0-0-2.17][6421-3-3-2.76][6500-1-1-0.47][6583-3-3-1.26]
[6683-3-3-1.51][6825-2-3-1.08][6998-3-3-1.18][7049-3-3-1.24][7517-1-1-1.63][7521-1-0-0.81][7528-1-3-0.43][7949-1-2-1.45][8135-1-0-1.50][8185-3-0-2.88]
[8269-3-0--0.04][8273-3-3-1.92][8543-3-0-3.57][8666-1-1-0.47][8672-0-0-2.64][8903-1-2-0.61][9001-2-1-1.48][9036-2-2-2.35][9281-3-3-0.84][9300-2-2-1.89]
[9571-0-3-1.34][9617-1-1-0.77][9644-2-2-1.38][9705-2-0-0.09][9801-0-3-1.56][9803-3-3-1.21][9865-3-3-2.90][9896-2-2-0.78][10314-1-2-0.44][10337-3-3-2.41]
[10403-0-0-0.61][10653-2-1--0.21][10704-2-2-0.29][10719-1-1-1.94][10727-1-1-2.08][10836-0-0-4.72][10969-2-3-1.31][11042-0-0-1.53][11088-1-1-1.50][11322-0-0-2.73]
[11398-2-2-2.03][11499-0-0-1.44][11502-3-3-2.01][11512-3-3-2.34][11608-1-1-1.34][11610-0-0-3.08][11692-0-0-2.24][11905-0-0-2.88][11993-1-1-1.13][12002-2-0-2.37]
[12052-0-0-3.22][12201-0-3-2.72][12235-2-2-0.71][12320-1-0-1.63][12377-2-1-0.52][12398-2-3-0.86][12503-1-1-0.28][12617-0-3-0.18][12685-3-3-0.65][12738-2-0-0.83]
[12742-2-2-2.10][12823-0-3-2.78][13110-1-2-0.03][13240-3-3-2.41][13253-1-1-2.39][13273-0-0-2.89][13634-1-2-0.85][13763-2-3-0.76][13905-3-3-0.78][14060-2-1-1.19]
[14065-3-3-1.52][14147-3-3-1.12][14595-2-2-1.22][14687-2-2-1.80][14788-2-2-1.12][14869-1-1-0.72][14872-3-0-1.70][14877-1-1-0.56][14927-0-0-1.36][15066-0-0-3.40]
[15175-1-1-0.89][15178-2-3-1.17][15375-3-3-1.64][15389-3-3-2.17][15568-2-1-0.93][15675-3-3-1.47][15869-1-3-0.27][16207-3-0-1.55][16236-0-3-0.34][16302-3-3-1.07]
[16331-2-2-1.93][16381-0-3-1.21][16488-1-1-2.14][16495-0-0-2.91][16650-0-0-3.33][16719-1-1-0.29][16801-0-0-4.39][16828-0-0-2.28][17137-3-3-1.36][17245-1-2-0.46]
[17278-3-3-0.76][17282-0-0-0.19][17311-2-2-1.31][17336-2-2-0.76][17608-3-3-3.35][17627-0-0-0.48][17877-3-2-0.63][17924-1-3-0.23][17984-3-0-2.90][18211-0-3-2.25]
[18276-3-3-1.93][18287-1-1-1.20][18394-0-0-2.37][18428-0-0-2.35][18442-0-3-2.85][18478-3-3-1.93][18607-0-0-1.96][18616-0-0-1.21][18663-0-0-1.71][18718-0-0-2.38]
[18766-2-2-1.48][18824-2-2-0.75][18890-3-2-0.76][18930-3-0--0.06][18938-3-3-1.39][19817-1-1-0.83][19839-0-0-1.12][19930-3-3-2.41][19944-0-0-1.14][20036-2-2-2.45]
[20101-3-3-1.41][20474-1-2-0.81][20547-3-0-1.38][20929-2-2-1.22][21245-1-2-0.57][21257-3-3-1.03][21293-1-1-1.41][21316-1-1-0.85][21384-1-1-1.35][21448-1-1-0.95]
[21483-0-0-3.40][21487-2-2-1.35][21714-0-0-1.39][21943-3-2-1.47][21947-0-0-2.17][21948-0-0-4.14][21965-2-2-1.47][21998-1-0-0.75][22025-0-3-0.66][22228-3-3-2.32]
[22446-1-1-2.35][22494-3-3-2.13][22757-0-0-2.48][22811-3-3-2.59][22976-3-2-0.28][22985-3-3-2.70][23014-0-3-3.46][23112-1-1-1.90][23144-3-3-2.17][23168-2-0-0.94]
[23219-0-3-1.85][23363-3-3-1.58][23470-0-3-0.41][23486-2-2-0.72][23497-0-3-2.82][23516-0-0-2.51][23690-1-1-0.19][23921-2-2-1.15][23936-1-2-1.06][24040-3-0-0.71]
[24111-1-1-1.45][24182-0-3-2.73][24238-3-3-1.98][24290-2-0-2.34][24345-0-0-1.37][24364-1-2-0.68][24427-3-0-2.48][24477-2-2-1.38][24495-2-1-1.26][24893-2-2-1.36]
[25012-1-1-0.03][25121-2-2-1.33][25165-3-3-1.16][25183-0-0-2.31][25297-3-3-2.30][25398-0-0-2.73][25574-2-2-0.28][25644-1-1-1.99][25718-1-1-0.26][25774-2-2-0.30]
[26032-3-3-1.90][26051-3-3-3.19][26120-0-0-1.08][26321-1-0-0.11][26732-1-1-1.71][26784-3-3-3.31][26827-3-3-2.41][26833-0-3-2.12][26838-2-3-0.59][26860-1-0-0.77]
[26948-0-0-1.37][27049-3-0-2.07][27098-1-0-0.39][27526-0-0-2.44][27639-3-3-1.80][27698-3-3-2.13][27772-0-0-3.40][27890-1-1-0.12][28040-0-3-0.21][28503-2-2-1.77]
[28577-1-1-1.92][28959-0-0-3.21][29198-3-0-0.89][29777-0-0-4.24][29877-2-1-0.39][30035-1-2-1.13][30098-0-0-1.22][30326-1-1-2.00][30572-2-2-0.73][30716-0-3-0.23]
[30806-2-2-0.69][30906-1-1-2.72][31007-0-0-1.91][31181-3-0-0.93][31238-0-3-1.97][31347-0-0-2.89][31422-2-2-0.24][31429-3-3-0.57][31431-0-3--0.06][31432-1-1-0.89]
[31477-0-3-2.93][31524-1-2-0.77][31597-1-2-1.79][31619-1-0-0.84][31701-0-0-3.25][31755-0-0-2.68][31854-3-3-2.48][32074-1-3--0.23][32078-3-3-1.19][32111-1-1-2.11]
[32127-1-2-2.03][32140-3-3-2.31][32263-2-0-1.26][32365-0-0-1.04][32411-2-3-2.63][32429-3-0-3.20][32473-3-3-1.61][32574-3-3-2.46][32584-0-0-1.12][32622-0-3-0.58]
[32858-3-0-2.57][32969-3-3-2.00][33016-2-2-1.50][33031-1-3-1.45][33035-2-2-1.70][33133-2-2-1.21][33173-2-2-0.18][33175-3-2-1.20][33306-3-2-0.69][33309-2-3-0.48]
[33474-0-0-1.57][33478-2-3-0.73][33618-1-1-0.24][33712-0-3-1.28][33782-2-1-0.64][33914-3-3-1.72][34076-3-3-0.92][34112-2-2-0.93][34138-2-2-0.86][34239-1-2-0.60]
[34364-2-2-1.67][34617-1-2-0.44][34751-3-3-2.28][34783-2-2-0.64][35015-3-3-1.14][35018-1-2-1.19][35288-2-3-0.68]
---------------------------
I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.610 | Acc: 78.375% | Wgt Acc: 78.356%
	I - Batch: 100 | Loss: 0.600 | Acc: 79.375% | Wgt Acc: 79.207%
	I - Batch: 150 | Loss: 0.608 | Acc: 78.333% | Wgt Acc: 78.184%
I - num batch: 160
I - Train -- Loss: 0.607 | Acc: 78.524% | Wgt Acc: 78.379% | LR: 1.000000e-04 | Dur: 197.34s
I - Confusion Matrix: [row->prediction - col->label]
[[549.  13.  16.  95.]
 [ 29. 482.  78.  28.]
 [ 27.  68. 591.  37.]
 [ 92.  15.  49. 378.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.995 | Acc: 60.856% | Wgt Acc: 58.492% | Dur: 17.43s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 10. 10. 44.]
 [ 4. 40.  5.  7.]
 [ 2. 26. 57. 10.]
 [ 5.  2.  3. 25.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.533 | Acc: 82.125% | Wgt Acc: 82.131%
	I - Batch: 100 | Loss: 0.526 | Acc: 83.000% | Wgt Acc: 82.892%
	I - Batch: 150 | Loss: 0.530 | Acc: 82.125% | Wgt Acc: 82.033%
I - num batch: 160
I - Train -- Loss: 0.539 | Acc: 81.547% | Wgt Acc: 81.476% | LR: 1.000000e-04 | Dur: 196.21s
I - Confusion Matrix: [row->prediction - col->label]
[[567.   8.  20.  83.]
 [ 26. 507.  74.  29.]
 [ 19.  52. 608.  31.]
 [ 85.  11.  32. 395.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.911 | Acc: 61.774% | Wgt Acc: 59.851% | Dur: 17.71s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 10.  7. 37.]
 [ 1. 37. 13.  6.]
 [ 3. 31. 53.  7.]
 [ 8.  0.  2. 36.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 84.875% | Wgt Acc: 84.668%
	I - Batch: 100 | Loss: 0.474 | Acc: 85.188% | Wgt Acc: 85.105%
	I - Batch: 150 | Loss: 0.475 | Acc: 84.875% | Wgt Acc: 84.886%
I - num batch: 160
I - Train -- Loss: 0.476 | Acc: 84.806% | Wgt Acc: 84.766% | LR: 1.000000e-04 | Dur: 200.06s
I - Confusion Matrix: [row->prediction - col->label]
[[583.  10.  13.  67.]
 [ 21. 520.  55.  16.]
 [ 17.  37. 635.  33.]
 [ 76.  11.  31. 422.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.970 | Acc: 59.633% | Wgt Acc: 58.220% | Dur: 17.69s
I - Confusion Matrix: [row->prediction - col->label]
[[66. 11.  9. 27.]
 [ 3. 38. 11.  6.]
 [ 8. 26. 52. 14.]
 [11.  3.  3. 39.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.400 | Acc: 88.750% | Wgt Acc: 88.725%
	I - Batch: 100 | Loss: 0.407 | Acc: 88.875% | Wgt Acc: 88.862%
	I - Batch: 150 | Loss: 0.419 | Acc: 87.417% | Wgt Acc: 87.382%
I - num batch: 160
I - Train -- Loss: 0.424 | Acc: 87.397% | Wgt Acc: 87.367% | LR: 1.000000e-04 | Dur: 197.71s
I - Confusion Matrix: [row->prediction - col->label]
[[600.   6.  21.  59.]
 [ 14. 535.  33.  17.]
 [ 17.  29. 654.  25.]
 [ 66.   8.  26. 437.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.536 | Acc: 44.648% | Wgt Acc: 43.207% | Dur: 17.23s
I - Confusion Matrix: [row->prediction - col->label]
[[29.  2.  0.  4.]
 [16. 40.  9. 15.]
 [33. 36. 65. 55.]
 [10.  0.  1. 12.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.417 | Acc: 87.750% | Wgt Acc: 87.781%
	I - Batch: 100 | Loss: 0.405 | Acc: 87.625% | Wgt Acc: 87.639%
	I - Batch: 150 | Loss: 0.399 | Acc: 87.667% | Wgt Acc: 87.670%
I - num batch: 160
I - Train -- Loss: 0.399 | Acc: 87.750% | Wgt Acc: 87.730% | LR: 1.000000e-04 | Dur: 197.51s
I - Confusion Matrix: [row->prediction - col->label]
[[593.  11.  12.  57.]
 [ 19. 529.  36.  11.]
 [ 17.  27. 665.  22.]
 [ 68.  11.  21. 448.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.852 | Acc: 68.502% | Wgt Acc: 68.071% | Dur: 17.34s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  3. 14.]
 [ 0. 41.  9.  1.]
 [ 2. 23. 49.  6.]
 [17.  9. 14. 65.]]

I - Local maximum validation set accuracy:  68.50

I - Validation set results: 
[14-1-2-1.37][50-3-3-0.83][124-2-2-1.16][127-0-0-3.72][443-2-2-4.00][567-0-0-2.70][573-1-1-1.38][615-0-0-1.19][695-1-2-1.08][722-3-3-2.31]
[826-0-0-3.36][878-0-0-2.79][1103-0-0-1.59][1212-3-3-0.67][1368-0-0-2.35][2181-2-3-1.20][2476-2-2-0.76][2721-2-2-2.73][2818-1-0-0.70][2886-2-1-2.66]
[3231-2-2-3.20][3333-2-2-0.70][3482-2-2-1.02][3536-3-3-2.17][3625-1-1-2.09][3909-0-0-0.67][4035-0-0-0.93][4140-0-0-2.06][4214-1-3-0.64][4346-1-3-0.74]
[4581-2-2-1.84][4708-3-3-1.18][4838-3-0-0.40][4845-1-2-0.62][4868-0-0-3.09][4939-0-2-0.34][4984-2-2-1.69][5078-1-0-0.43][5396-0-0-3.73][5479-1-1-0.30]
[5717-0-0-2.83][5843-1-1-0.78][5949-3-3-1.10][5987-2-2-0.61][6014-3-3-0.88][6033-3-0-1.56][6313-0-0-1.52][6421-3-3-2.70][6500-1-2-0.47][6583-3-3-1.73]
[6683-3-3-1.27][6825-2-3-0.43][6998-3-3-0.59][7049-3-3-0.81][7517-1-2-2.16][7521-1-1-0.96][7528-1-3-0.91][7949-1-2-1.32][8135-1-0-1.25][8185-3-0-2.16]
[8269-3-2-0.17][8273-3-3-2.31][8543-3-0-3.36][8666-1-1-2.04][8672-0-0-1.63][8903-1-1-1.80][9001-2-1-1.09][9036-2-2-1.97][9281-3-0-0.41][9300-2-2-3.91]
[9571-0-3-1.32][9617-1-1-0.61][9644-2-2-1.93][9705-2-1-0.37][9801-0-0-1.27][9803-3-3-0.90][9865-3-3-3.29][9896-2-2-1.38][10314-1-2-0.75][10337-3-3-3.26]
[10403-0-0-1.07][10653-2-2-0.60][10704-2-2-1.21][10719-1-1-2.28][10727-1-2-0.81][10836-0-0-5.70][10969-2-3-1.74][11042-0-0-0.94][11088-1-1-2.60][11322-0-0-3.51]
[11398-2-2-2.48][11499-0-0-1.28][11502-3-3-1.12][11512-3-3-2.56][11608-1-2-1.96][11610-0-3-1.74][11692-0-0-1.23][11905-0-0-3.82][11993-1-1-2.41][12002-2-3-0.45]
[12052-0-0-2.67][12201-0-3-3.12][12235-2-2-1.13][12320-1-0-2.36][12377-2-2-0.46][12398-2-3-0.59][12503-1-1-2.29][12617-0-3-1.16][12685-3-3-1.04][12738-2-3-0.49]
[12742-2-2-3.81][12823-0-3-2.62][13110-1-3-0.02][13240-3-3-2.80][13253-1-1-2.00][13273-0-0-3.83][13634-1-2-0.60][13763-2-3-1.19][13905-3-0-0.44][14060-2-1--0.02]
[14065-3-3-1.40][14147-3-3-1.34][14595-2-2-1.65][14687-2-2-2.89][14788-2-2-1.04][14869-1-1-2.36][14872-3-0-1.22][14877-1-1-2.37][14927-0-0-0.43][15066-0-0-3.47]
[15175-1-1-1.10][15178-2-3-1.14][15375-3-3-0.67][15389-3-3-1.49][15568-2-1-1.96][15675-3-3-2.34][15869-1-2-0.59][16207-3-0-1.97][16236-0-0-0.51][16302-3-3-0.58]
[16331-2-2-3.12][16381-0-3-1.20][16488-1-1-3.82][16495-0-0-3.80][16650-0-0-3.87][16719-1-2-1.17][16801-0-0-4.72][16828-0-0-1.77][17137-3-3-0.97][17245-1-2--0.08]
[17278-3-3-0.29][17282-0-0-0.07][17311-2-2-1.69][17336-2-2-0.19][17608-3-3-3.13][17627-0-0-0.83][17877-3-0--0.21][17924-1-2-0.81][17984-3-0-2.60][18211-0-3-3.32]
[18276-3-3-2.04][18287-1-1-0.63][18394-0-0-2.55][18428-0-3-1.45][18442-0-3-2.73][18478-3-3-1.05][18607-0-0-1.93][18616-0-0-1.02][18663-0-0-1.16][18718-0-0-3.09]
[18766-2-2-2.27][18824-2-2-1.45][18890-3-3-0.62][18930-3-2-0.03][18938-3-3-1.72][19817-1-2-0.68][19839-0-0-0.47][19930-3-3-1.40][19944-0-2-0.72][20036-2-2-3.30]
[20101-3-3-0.13][20474-1-1-0.76][20547-3-0-1.71][20929-2-2-2.24][21245-1-1-1.66][21257-3-3-0.60][21293-1-2-2.17][21316-1-1-2.87][21384-1-1-2.57][21448-1-1-0.81]
[21483-0-0-2.96][21487-2-2-2.13][21714-0-3-1.26][21943-3-2-0.58][21947-0-0-2.11][21948-0-0-4.36][21965-2-2-0.76][21998-1-2-0.61][22025-0-3-1.07][22228-3-3-3.46]
[22446-1-1-3.58][22494-3-3-2.07][22757-0-0-2.57][22811-3-3-3.73][22976-3-2-0.26][22985-3-3-3.05][23014-0-3-2.94][23112-1-1-2.16][23144-3-3-2.52][23168-2-0-0.46]
[23219-0-0-2.04][23363-3-3-2.24][23470-0-0-0.71][23486-2-2-0.42][23497-0-3-2.60][23516-0-0-2.17][23690-1-1-1.04][23921-2-2-1.92][23936-1-2-2.05][24040-3-3-0.20]
[24111-1-2-1.53][24182-0-0-3.01][24238-3-3-2.35][24290-2-0-2.29][24345-0-0-2.66][24364-1-1-0.52][24427-3-0-1.77][24477-2-2-2.79][24495-2-1-0.50][24893-2-2-2.40]
[25012-1-1-0.19][25121-2-2-1.37][25165-3-3-2.32][25183-0-0-2.48][25297-3-3-2.57][25398-0-0-2.94][25574-2-3-0.06][25644-1-1-0.96][25718-1-1-0.40][25774-2-3-1.35]
[26032-3-3-2.18][26051-3-3-3.65][26120-0-0-0.60][26321-1-1-1.17][26732-1-1-0.72][26784-3-3-3.01][26827-3-3-2.38][26833-0-3-1.80][26838-2-2-0.19][26860-1-2-0.59]
[26948-0-0-1.15][27049-3-0-1.93][27098-1-0-0.57][27526-0-0-2.25][27639-3-3-2.60][27698-3-3-2.04][27772-0-0-1.81][27890-1-3-0.25][28040-0-0-1.10][28503-2-2-3.08]
[28577-1-1-3.25][28959-0-0-3.34][29198-3-0-1.22][29777-0-0-4.76][29877-2-1-0.53][30035-1-1-0.84][30098-0-0-0.87][30326-1-1-3.14][30572-2-2-2.28][30716-0-0-0.52]
[30806-2-3-1.00][30906-1-1-2.24][31007-0-0-1.72][31181-3-3-1.12][31238-0-3-2.27][31347-0-0-3.33][31422-2-2-1.60][31429-3-3-0.03][31431-0-0-0.85][31432-1-1-2.40]
[31477-0-0-2.35][31524-1-2--0.28][31597-1-2-2.07][31619-1-3-0.16][31701-0-0-3.54][31755-0-0-3.39][31854-3-3-2.14][32074-1-3-0.83][32078-3-3-2.69][32111-1-1-1.95]
[32127-1-1-1.45][32140-3-3-2.35][32263-2-0-0.88][32365-0-0-1.30][32411-2-3-2.33][32429-3-3-2.47][32473-3-3-1.24][32574-3-3-2.76][32584-0-3-0.96][32622-0-3-0.42]
[32858-3-3-2.68][32969-3-3-2.01][33016-2-2-1.48][33031-1-3-1.51][33035-2-2-1.74][33133-2-2-1.44][33173-2-3-0.37][33175-3-2-1.12][33306-3-1-0.97][33309-2-3-0.63]
[33474-0-0-0.82][33478-2-1--0.32][33618-1-1-0.97][33712-0-0-0.99][33782-2-1-0.54][33914-3-3-0.43][34076-3-3-0.97][34112-2-2-1.13][34138-2-2-0.99][34239-1-2-0.43]
[34364-2-2-1.81][34617-1-3-0.57][34751-3-3-1.24][34783-2-2-1.56][35015-3-2-2.60][35018-1-1-1.67][35288-2-2-0.07]
---------------------------
I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.278 | Acc: 94.125% | Wgt Acc: 94.238%
	I - Batch: 100 | Loss: 0.267 | Acc: 94.750% | Wgt Acc: 94.844%
	I - Batch: 150 | Loss: 0.267 | Acc: 94.375% | Wgt Acc: 94.459%
I - num batch: 160
I - Train -- Loss: 0.275 | Acc: 94.150% | Wgt Acc: 94.223% | LR: 5.000000e-05 | Dur: 197.02s
I - Confusion Matrix: [row->prediction - col->label]
[[630.   2.   1.  33.]
 [  7. 569.  16.   6.]
 [ 13.   5. 709.   9.]
 [ 47.   2.   8. 490.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.898 | Acc: 66.667% | Wgt Acc: 66.508% | Dur: 14.01s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  6.  6. 26.]
 [ 4. 56. 16.  7.]
 [ 2. 10. 40.  2.]
 [11.  6. 13. 51.]]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.253 | Acc: 94.125% | Wgt Acc: 94.040%
	I - Batch: 100 | Loss: 0.251 | Acc: 94.625% | Wgt Acc: 94.577%
	I - Batch: 150 | Loss: 0.252 | Acc: 94.458% | Wgt Acc: 94.460%
I - num batch: 160
I - Train -- Loss: 0.250 | Acc: 94.543% | Wgt Acc: 94.542% | LR: 5.000000e-05 | Dur: 174.94s
I - Confusion Matrix: [row->prediction - col->label]
[[644.   2.   5.  38.]
 [  6. 566.  12.   3.]
 [ 14.   9. 709.   8.]
 [ 33.   1.   8. 489.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.816 | Acc: 65.443% | Wgt Acc: 65.014% | Dur: 14.84s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9.  5. 24.]
 [ 1. 46. 17.  4.]
 [ 4. 19. 41.  3.]
 [11.  4. 12. 55.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.223 | Acc: 95.500% | Wgt Acc: 95.574%
	I - Batch: 100 | Loss: 0.230 | Acc: 94.875% | Wgt Acc: 94.895%
	I - Batch: 150 | Loss: 0.225 | Acc: 94.958% | Wgt Acc: 94.954%
I - num batch: 160
I - Train -- Loss: 0.226 | Acc: 95.014% | Wgt Acc: 95.019% | LR: 5.000000e-05 | Dur: 175.35s
I - Confusion Matrix: [row->prediction - col->label]
[[647.   3.   5.  32.]
 [  5. 568.  11.   5.]
 [ 16.   7. 712.   8.]
 [ 29.   0.   6. 493.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.891 | Acc: 66.972% | Wgt Acc: 66.576% | Dur: 16.76s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  3.  4. 10.]
 [ 3. 37.  9.  5.]
 [ 5. 32. 54.  4.]
 [19.  6.  8. 67.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.215 | Acc: 96.125% | Wgt Acc: 96.164%
	I - Batch: 100 | Loss: 0.203 | Acc: 96.312% | Wgt Acc: 96.278%
	I - Batch: 150 | Loss: 0.207 | Acc: 96.083% | Wgt Acc: 96.064%
I - num batch: 160
I - Train -- Loss: 0.207 | Acc: 96.035% | Wgt Acc: 96.019% | LR: 5.000000e-05 | Dur: 196.77s
I - Confusion Matrix: [row->prediction - col->label]
[[658.   1.   5.  26.]
 [  4. 571.   7.   3.]
 [  7.   4. 718.  10.]
 [ 28.   2.   4. 499.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.922 | Acc: 66.361% | Wgt Acc: 66.236% | Dur: 16.78s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  4.  7. 25.]
 [ 3. 59. 27. 11.]
 [ 3. 10. 34.  2.]
 [ 6.  5.  7. 48.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.169 | Acc: 97.500% | Wgt Acc: 97.538%
	I - Batch: 100 | Loss: 0.173 | Acc: 97.125% | Wgt Acc: 97.161%
	I - Batch: 150 | Loss: 0.180 | Acc: 96.792% | Wgt Acc: 96.827%
I - num batch: 160
I - Train -- Loss: 0.182 | Acc: 96.702% | Wgt Acc: 96.753% | LR: 5.000000e-05 | Dur: 194.90s
I - Confusion Matrix: [row->prediction - col->label]
[[656.   1.   5.  17.]
 [  3. 573.   5.   4.]
 [ 10.   4. 722.   5.]
 [ 28.   0.   2. 512.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.083 | Acc: 58.716% | Wgt Acc: 58.220% | Dur: 16.71s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 11. 14. 48.]
 [ 8. 60. 32.  8.]
 [ 0.  6. 24.  1.]
 [ 1.  1.  5. 29.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.176 | Acc: 96.625% | Wgt Acc: 96.603%
	I - Batch: 100 | Loss: 0.168 | Acc: 97.438% | Wgt Acc: 97.448%
	I - Batch: 150 | Loss: 0.170 | Acc: 97.375% | Wgt Acc: 97.362%
I - num batch: 160
I - Train -- Loss: 0.169 | Acc: 97.409% | Wgt Acc: 97.408% | LR: 5.000000e-05 | Dur: 194.70s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   0.   4.  15.]
 [  2. 572.   4.   3.]
 [ 10.   5. 723.   5.]
 [ 14.   1.   3. 515.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.901 | Acc: 66.361% | Wgt Acc: 65.489% | Dur: 16.94s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  3.  5. 23.]
 [ 6. 49. 10.  4.]
 [ 8. 25. 57. 12.]
 [10.  1.  3. 47.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.166 | Acc: 96.750% | Wgt Acc: 96.817%
	I - Batch: 100 | Loss: 0.167 | Acc: 96.562% | Wgt Acc: 96.591%
	I - Batch: 150 | Loss: 0.165 | Acc: 96.750% | Wgt Acc: 96.751%
I - num batch: 160
I - Train -- Loss: 0.166 | Acc: 96.741% | Wgt Acc: 96.762% | LR: 5.000000e-05 | Dur: 192.96s
I - Confusion Matrix: [row->prediction - col->label]
[[663.   3.   5.  21.]
 [  5. 571.   6.   2.]
 [ 12.   3. 719.   4.]
 [ 17.   1.   4. 511.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.936 | Acc: 63.914% | Wgt Acc: 62.840% | Dur: 17.75s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  5.  3. 21.]
 [ 7. 45. 10.  8.]
 [ 9. 28. 60. 13.]
 [12.  0.  2. 44.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.136 | Acc: 98.000% | Wgt Acc: 98.016%
	I - Batch: 100 | Loss: 0.140 | Acc: 97.938% | Wgt Acc: 97.986%
	I - Batch: 150 | Loss: 0.140 | Acc: 98.000% | Wgt Acc: 98.038%
I - num batch: 160
I - Train -- Loss: 0.141 | Acc: 97.998% | Wgt Acc: 98.027% | LR: 5.000000e-05 | Dur: 192.97s
I - Confusion Matrix: [row->prediction - col->label]
[[674.   1.   2.  13.]
 [  3. 576.   2.   1.]
 [  9.   1. 725.   3.]
 [ 11.   0.   5. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.944 | Acc: 62.080% | Wgt Acc: 62.092% | Dur: 17.63s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 13. 10. 29.]
 [ 4. 50. 24.  2.]
 [ 1. 11. 30.  3.]
 [12.  4. 11. 52.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.123 | Acc: 98.000% | Wgt Acc: 98.081%
	I - Batch: 100 | Loss: 0.131 | Acc: 97.812% | Wgt Acc: 97.800%
	I - Batch: 150 | Loss: 0.128 | Acc: 97.875% | Wgt Acc: 97.896%
I - num batch: 160
I - Train -- Loss: 0.128 | Acc: 97.880% | Wgt Acc: 97.895% | LR: 5.000000e-05 | Dur: 193.40s
I - Confusion Matrix: [row->prediction - col->label]
[[675.   2.   2.  11.]
 [  2. 575.   4.   4.]
 [  6.   0. 724.   4.]
 [ 14.   1.   4. 519.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.837 | Acc: 66.667% | Wgt Acc: 65.693% | Dur: 16.15s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  5.  6. 23.]
 [ 3. 50. 17.  8.]
 [ 5. 23. 50. 10.]
 [ 7.  0.  2. 45.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.126 | Acc: 98.500% | Wgt Acc: 98.398%
	I - Batch: 100 | Loss: 0.121 | Acc: 98.625% | Wgt Acc: 98.577%
	I - Batch: 150 | Loss: 0.119 | Acc: 98.500% | Wgt Acc: 98.459%
I - num batch: 160
I - Train -- Loss: 0.120 | Acc: 98.469% | Wgt Acc: 98.443% | LR: 5.000000e-05 | Dur: 194.30s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   1.   2.  14.]
 [  2. 576.   0.   0.]
 [  7.   1. 730.   4.]
 [  6.   0.   2. 520.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.140 | Acc: 59.939% | Wgt Acc: 59.918% | Dur: 17.30s
I - Confusion Matrix: [row->prediction - col->label]
[[41.  2.  1.  5.]
 [ 9. 49. 13.  9.]
 [16. 24. 57. 23.]
 [22.  3.  4. 49.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 98.750% | Wgt Acc: 98.737%
	I - Batch: 100 | Loss: 0.095 | Acc: 98.688% | Wgt Acc: 98.677%
	I - Batch: 150 | Loss: 0.093 | Acc: 98.917% | Wgt Acc: 98.920%
I - num batch: 160
I - Train -- Loss: 0.095 | Acc: 98.901% | Wgt Acc: 98.903% | LR: 2.500000e-05 | Dur: 192.52s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   2.   1.   4.]
 [  1. 575.   0.   2.]
 [  6.   0. 732.   3.]
 [  7.   1.   1. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.971 | Acc: 64.220% | Wgt Acc: 63.179% | Dur: 17.44s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  2.  4. 13.]
 [ 4. 42.  9.  5.]
 [ 9. 30. 58. 20.]
 [13.  4.  4. 48.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.079 | Acc: 99.375% | Wgt Acc: 99.382%
	I - Batch: 100 | Loss: 0.085 | Acc: 99.250% | Wgt Acc: 99.241%
	I - Batch: 150 | Loss: 0.084 | Acc: 99.208% | Wgt Acc: 99.203%
I - num batch: 160
I - Train -- Loss: 0.084 | Acc: 99.176% | Wgt Acc: 99.168% | LR: 2.500000e-05 | Dur: 194.54s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   2.   6.]
 [  1. 577.   0.   0.]
 [  3.   1. 732.   3.]
 [  5.   0.   0. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.823 | Acc: 69.725% | Wgt Acc: 68.954% | Dur: 17.74s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 11.  8. 17.]
 [ 4. 44.  7.  3.]
 [ 3. 22. 51.  7.]
 [ 7.  1.  9. 59.]]

I - Local maximum validation set accuracy:  69.72

I - Validation set results: 
[14-1-2-0.75][50-3-1--0.08][124-2-2-1.26][127-0-0-4.28][443-2-2-4.49][567-0-0-2.99][573-1-1-2.64][615-0-0-1.39][695-1-2-2.24][722-3-0-2.29]
[826-0-0-4.35][878-0-0-4.36][1103-0-0-1.79][1212-3-0-0.55][1368-0-0-2.67][2181-2-3-1.90][2476-2-2-1.59][2721-2-2-4.33][2818-1-0--0.00][2886-2-2-1.28]
[3231-2-2-4.25][3333-2-2-0.93][3482-2-2-0.78][3536-3-3-0.92][3625-1-1-3.10][3909-0-0-1.73][4035-0-0-2.56][4140-0-0-2.30][4214-1-2-0.25][4346-1-0-0.53]
[4581-2-2-1.41][4708-3-3-2.06][4838-3-0-0.38][4845-1-2-0.58][4868-0-0-3.51][4939-0-1-0.27][4984-2-2-1.79][5078-1-0-0.42][5396-0-0-4.78][5479-1-1-1.27]
[5717-0-0-3.18][5843-1-1-1.03][5949-3-0-1.06][5987-2-2-0.77][6014-3-3-0.62][6033-3-3-1.06][6313-0-0-1.54][6421-3-3-2.35][6500-1-1-0.32][6583-3-3-1.58]
[6683-3-3-2.47][6825-2-1--0.04][6998-3-3-1.03][7049-3-3-1.45][7517-1-2-1.80][7521-1-1-0.77][7528-1-3-1.52][7949-1-2-2.44][8135-1-0-1.76][8185-3-0-2.50]
[8269-3-2-0.70][8273-3-3-2.13][8543-3-0-3.50][8666-1-1-2.42][8672-0-0-4.05][8903-1-1-0.12][9001-2-1-0.64][9036-2-2-2.72][9281-3-3-0.80][9300-2-2-3.78]
[9571-0-0-1.07][9617-1-1-2.36][9644-2-2-1.94][9705-2-2-0.28][9801-0-0-2.29][9803-3-3-1.73][9865-3-3-3.84][9896-2-2-2.01][10314-1-0-0.03][10337-3-3-2.61]
[10403-0-0-1.48][10653-2-0--0.31][10704-2-2-1.57][10719-1-1-1.89][10727-1-1-0.91][10836-0-0-6.47][10969-2-3-1.30][11042-0-0-1.62][11088-1-1-2.99][11322-0-0-4.17]
[11398-2-2-1.85][11499-0-0-1.84][11502-3-3-1.68][11512-3-3-3.07][11608-1-2-1.70][11610-0-0-1.56][11692-0-0-1.57][11905-0-0-3.88][11993-1-1-3.52][12002-2-2-0.81]
[12052-0-0-2.21][12201-0-0-2.56][12235-2-2-1.85][12320-1-0-2.43][12377-2-2-1.63][12398-2-0-1.29][12503-1-2-1.20][12617-0-0-0.15][12685-3-3-2.49][12738-2-0-1.20]
[12742-2-2-3.90][12823-0-3-2.01][13110-1-1-0.32][13240-3-3-2.09][13253-1-1-2.55][13273-0-0-4.79][13634-1-0-0.02][13763-2-3-0.81][13905-3-0-0.53][14060-2-1-1.35]
[14065-3-0-0.77][14147-3-3-1.67][14595-2-2-2.95][14687-2-2-3.33][14788-2-2-0.65][14869-1-2-1.49][14872-3-0-2.13][14877-1-1-4.39][14927-0-3-0.80][15066-0-0-3.11]
[15175-1-1-0.71][15178-2-2-0.64][15375-3-3-0.63][15389-3-3-1.85][15568-2-1-1.19][15675-3-3-3.03][15869-1-0--0.35][16207-3-0-1.81][16236-0-0-0.33][16302-3-0-0.88]
[16331-2-2-4.06][16381-0-3-0.93][16488-1-1-3.90][16495-0-0-3.99][16650-0-0-5.73][16719-1-2-0.79][16801-0-0-5.10][16828-0-0-2.12][17137-3-3-0.39][17245-1-2-0.43]
[17278-3-3-0.72][17282-0-0-0.49][17311-2-2-1.88][17336-2-1-1.97][17608-3-3-3.13][17627-0-0-1.18][17877-3-1-0.81][17924-1-2-0.58][17984-3-3-3.72][18211-0-3-3.39]
[18276-3-0-1.33][18287-1-1-2.37][18394-0-0-3.71][18428-0-0-2.53][18442-0-3-2.14][18478-3-3-1.04][18607-0-0-1.78][18616-0-0-2.37][18663-0-0-1.32][18718-0-0-3.89]
[18766-2-2-2.07][18824-2-2-2.20][18890-3-3-1.21][18930-3-2-0.29][18938-3-3-2.27][19817-1-2-1.16][19839-0-0-0.66][19930-3-3-1.89][19944-0-2-0.87][20036-2-2-3.14]
[20101-3-3-1.95][20474-1-1-0.23][20547-3-0-1.59][20929-2-2-1.62][21245-1-1-2.42][21257-3-3-1.17][21293-1-2-2.79][21316-1-1-3.47][21384-1-1-2.08][21448-1-1-0.84]
[21483-0-0-2.64][21487-2-2-1.45][21714-0-0-1.57][21943-3-2-1.12][21947-0-0-1.98][21948-0-0-4.98][21965-2-2-2.77][21998-1-1-0.63][22025-0-2-1.12][22228-3-3-3.41]
[22446-1-1-3.67][22494-3-3-2.22][22757-0-0-2.00][22811-3-3-3.78][22976-3-2-0.39][22985-3-3-3.04][23014-0-0-3.57][23112-1-1-3.74][23144-3-3-1.99][23168-2-0-0.62]
[23219-0-0-1.91][23363-3-3-0.80][23470-0-1-0.35][23486-2-3-0.87][23497-0-0-1.61][23516-0-0-2.13][23690-1-1-2.26][23921-2-2-2.15][23936-1-2-2.01][24040-3-2-0.02]
[24111-1-2-1.19][24182-0-0-4.39][24238-3-3-2.01][24290-2-0-2.51][24345-0-0-1.55][24364-1-1-0.57][24427-3-0-1.99][24477-2-2-3.70][24495-2-1-0.57][24893-2-2-1.32]
[25012-1-1-1.21][25121-2-2-1.00][25165-3-3-2.19][25183-0-0-2.74][25297-3-3-2.78][25398-0-0-3.67][25574-2-2-0.55][25644-1-1-2.09][25718-1-0-0.41][25774-2-3-0.43]
[26032-3-3-2.80][26051-3-3-3.69][26120-0-0-1.44][26321-1-2--0.11][26732-1-1-1.63][26784-3-3-3.82][26827-3-3-1.65][26833-0-3-1.53][26838-2-2-0.59][26860-1-2-1.15]
[26948-0-0-0.91][27049-3-0-1.83][27098-1-0-1.15][27526-0-0-3.32][27639-3-3-2.28][27698-3-3-1.96][27772-0-0-3.38][27890-1-1-2.84][28040-0-0-2.98][28503-2-2-4.05]
[28577-1-1-4.57][28959-0-0-4.13][29198-3-0-0.46][29777-0-0-5.75][29877-2-2-1.57][30035-1-1-2.07][30098-0-0-1.56][30326-1-1-4.28][30572-2-2-2.67][30716-0-1-1.74]
[30806-2-3-0.92][30906-1-1-4.70][31007-0-0-2.42][31181-3-3-0.98][31238-0-3-1.71][31347-0-0-4.61][31422-2-2-2.11][31429-3-3-0.22][31431-0-1-1.21][31432-1-1-3.54]
[31477-0-0-2.84][31524-1-2-0.85][31597-1-1-1.50][31619-1-2-0.37][31701-0-0-4.90][31755-0-0-4.78][31854-3-3-2.26][32074-1-1-2.00][32078-3-3-2.71][32111-1-1-4.90]
[32127-1-1-1.14][32140-3-3-2.70][32263-2-0-1.19][32365-0-0-2.71][32411-2-0-1.70][32429-3-3-2.24][32473-3-0-1.90][32574-3-3-1.91][32584-0-0-1.49][32622-0-2-1.50]
[32858-3-3-2.77][32969-3-3-1.60][33016-2-2-1.92][33031-1-0-1.31][33035-2-2-0.70][33133-2-2-2.19][33173-2-2-0.35][33175-3-2-1.37][33306-3-1-1.19][33309-2-3-1.46]
[33474-0-0-1.27][33478-2-0-1.01][33618-1-1-0.51][33712-0-0-1.39][33782-2-1-2.05][33914-3-3-2.36][34076-3-2-0.44][34112-2-2-0.59][34138-2-3-1.14][34239-1-2-0.88]
[34364-2-2-2.61][34617-1-2-0.53][34751-3-3-0.86][34783-2-2-1.32][35015-3-3-1.25][35018-1-1-1.78][35288-2-3-0.87]
---------------------------
I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.079 | Acc: 99.625% | Wgt Acc: 99.633%
	I - Batch: 100 | Loss: 0.078 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 150 | Loss: 0.079 | Acc: 99.542% | Wgt Acc: 99.549%
I - num batch: 160
I - Train -- Loss: 0.079 | Acc: 99.529% | Wgt Acc: 99.540% | LR: 2.500000e-05 | Dur: 182.78s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   2.]
 [  0. 578.   0.   0.]
 [  2.   0. 731.   2.]
 [  3.   0.   2. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.114 | Acc: 59.633% | Wgt Acc: 58.967% | Dur: 14.55s
I - Confusion Matrix: [row->prediction - col->label]
[[43.  1.  1.  3.]
 [ 6. 40.  6.  4.]
 [20. 34. 64. 31.]
 [19.  3.  4. 48.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.077 | Acc: 99.375% | Wgt Acc: 99.408%
	I - Batch: 100 | Loss: 0.075 | Acc: 99.562% | Wgt Acc: 99.577%
	I - Batch: 150 | Loss: 0.076 | Acc: 99.583% | Wgt Acc: 99.596%
I - num batch: 160
I - Train -- Loss: 0.076 | Acc: 99.568% | Wgt Acc: 99.584% | LR: 2.500000e-05 | Dur: 174.20s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   1.   2.]
 [  1. 578.   0.   0.]
 [  2.   0. 732.   1.]
 [  3.   0.   1. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.892 | Acc: 65.749% | Wgt Acc: 65.285% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  8.  4. 17.]
 [ 3. 39.  6.  1.]
 [ 5. 23. 53.  6.]
 [19.  8. 12. 62.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.080 | Acc: 98.875% | Wgt Acc: 98.816%
	I - Batch: 100 | Loss: 0.078 | Acc: 99.188% | Wgt Acc: 99.143%
	I - Batch: 150 | Loss: 0.074 | Acc: 99.375% | Wgt Acc: 99.352%
I - num batch: 160
I - Train -- Loss: 0.073 | Acc: 99.411% | Wgt Acc: 99.390% | LR: 2.500000e-05 | Dur: 186.43s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   8.]
 [  0. 578.   1.   0.]
 [  0.   0. 732.   1.]
 [  4.   0.   1. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.880 | Acc: 67.890% | Wgt Acc: 67.255% | Dur: 17.12s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  3.  1. 12.]
 [ 2. 44.  9.  4.]
 [12. 28. 59. 12.]
 [13.  3.  6. 58.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 99.625% | Wgt Acc: 99.635%
	I - Batch: 100 | Loss: 0.062 | Acc: 99.688% | Wgt Acc: 99.690%
	I - Batch: 150 | Loss: 0.063 | Acc: 99.667% | Wgt Acc: 99.662%
I - num batch: 160
I - Train -- Loss: 0.065 | Acc: 99.686% | Wgt Acc: 99.682% | LR: 1.250000e-05 | Dur: 194.46s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   3.]
 [  1. 578.   0.   0.]
 [  1.   0. 733.   1.]
 [  1.   0.   1. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.999 | Acc: 66.055% | Wgt Acc: 64.878% | Dur: 16.35s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 10. 11. 28.]
 [ 2. 39.  6.  2.]
 [ 3. 24. 48.  4.]
 [ 6.  5. 10. 52.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.057 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.065 | Acc: 99.812% | Wgt Acc: 99.817%
	I - Batch: 150 | Loss: 0.062 | Acc: 99.792% | Wgt Acc: 99.784%
I - num batch: 160
I - Train -- Loss: 0.064 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-05 | Dur: 193.26s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   3.]
 [  0. 578.   1.   0.]
 [  1.   0. 733.   0.]
 [  1.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.885 | Acc: 66.361% | Wgt Acc: 66.236% | Dur: 17.06s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  8. 25.]
 [ 4. 54. 17.  7.]
 [ 2. 14. 38.  1.]
 [10.  4. 12. 53.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.064 | Acc: 99.500% | Wgt Acc: 99.509%
	I - Batch: 150 | Loss: 0.062 | Acc: 99.667% | Wgt Acc: 99.671%
I - num batch: 160
I - Train -- Loss: 0.063 | Acc: 99.647% | Wgt Acc: 99.655% | LR: 1.250000e-05 | Dur: 196.36s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  2.   0. 734.   1.]
 [  4.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.024 | Acc: 66.055% | Wgt Acc: 65.761% | Dur: 16.68s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 11.  6. 23.]
 [ 2. 43.  9.  1.]
 [ 3. 14. 38.  1.]
 [ 9. 10. 22. 61.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.057 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.056 | Acc: 99.667% | Wgt Acc: 99.662%
I - num batch: 160
I - Train -- Loss: 0.057 | Acc: 99.647% | Wgt Acc: 99.637% | LR: 1.250000e-05 | Dur: 195.48s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   5.]
 [  0. 578.   0.   0.]
 [  2.   0. 733.   0.]
 [  1.   0.   1. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.044 | Acc: 65.749% | Wgt Acc: 63.859% | Dur: 16.20s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  9.  7. 22.]
 [ 2. 34.  6.  6.]
 [10. 35. 61. 12.]
 [ 2.  0.  1. 46.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.058 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.054 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 150 | Loss: 0.055 | Acc: 99.875% | Wgt Acc: 99.878%
I - num batch: 160
I - Train -- Loss: 0.056 | Acc: 99.804% | Wgt Acc: 99.797% | LR: 1.250000e-05 | Dur: 198.59s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   1.]
 [  2.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.844 | Acc: 70.642% | Wgt Acc: 70.516% | Dur: 16.85s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  4.  2. 10.]
 [ 5. 52. 11.  7.]
 [ 7. 18. 57.  7.]
 [16.  4.  5. 62.]]

I - Local maximum validation set accuracy:  70.64

I - Validation set results: 
[14-1-1-1.37][50-3-1--0.14][124-2-2-2.29][127-0-0-3.18][443-2-2-3.97][567-0-0-1.70][573-1-1-3.18][615-0-3-0.56][695-1-2-2.57][722-3-0-1.64]
[826-0-0-3.31][878-0-0-3.02][1103-0-0-0.96][1212-3-3-0.73][1368-0-0-2.18][2181-2-3-1.90][2476-2-2-2.73][2721-2-2-3.55][2818-1-1-0.57][2886-2-1-2.79]
[3231-2-2-5.35][3333-2-2-1.55][3482-2-2-1.93][3536-3-3-0.34][3625-1-1-3.71][3909-0-0-0.84][4035-0-0-2.29][4140-0-0-2.24][4214-1-3-3.14][4346-1-3-0.59]
[4581-2-2-2.01][4708-3-3-0.94][4838-3-2--0.03][4845-1-2-0.89][4868-0-0-3.42][4939-0-1-0.99][4984-2-2-2.62][5078-1-2-0.43][5396-0-0-3.49][5479-1-2-1.69]
[5717-0-0-2.52][5843-1-1-1.30][5949-3-3-1.18][5987-2-1-2.01][6014-3-1-0.72][6033-3-0-0.23][6313-0-0-0.73][6421-3-3-3.13][6500-1-2-0.50][6583-3-3-2.27]
[6683-3-3-1.15][6825-2-1--0.34][6998-3-3--0.30][7049-3-3-1.54][7517-1-1-1.53][7521-1-1-1.32][7528-1-2-0.64][7949-1-2-2.99][8135-1-0-0.54][8185-3-0-1.51]
[8269-3-1-1.71][8273-3-3-2.65][8543-3-0-3.14][8666-1-1-2.04][8672-0-3-1.39][8903-1-2-3.00][9001-2-1-3.10][9036-2-2-3.87][9281-3-3-0.75][9300-2-2-4.57]
[9571-0-3-0.97][9617-1-1-2.58][9644-2-2-2.89][9705-2-1-0.46][9801-0-0-1.71][9803-3-3-0.71][9865-3-3-2.40][9896-2-2-1.71][10314-1-0-0.83][10337-3-3-0.57]
[10403-0-2-0.37][10653-2-2-0.19][10704-2-2-2.30][10719-1-1-2.92][10727-1-1-3.64][10836-0-0-6.23][10969-2-3-0.41][11042-0-0-1.84][11088-1-1-4.13][11322-0-0-3.98]
[11398-2-2-2.75][11499-0-0-0.23][11502-3-3-1.58][11512-3-3-1.73][11608-1-2-1.92][11610-0-0-2.70][11692-0-0-1.36][11905-0-0-1.97][11993-1-1-4.44][12002-2-2-0.38]
[12052-0-0-2.09][12201-0-3-2.07][12235-2-2-3.14][12320-1-0-1.21][12377-2-1-1.93][12398-2-3-0.16][12503-1-1-1.59][12617-0-1-0.42][12685-3-3-0.60][12738-2-2-0.42]
[12742-2-2-5.31][12823-0-0-1.95][13110-1-1-1.27][13240-3-3-3.02][13253-1-1-2.53][13273-0-0-4.15][13634-1-1--0.29][13763-2-2-1.16][13905-3-3--0.35][14060-2-1-2.02]
[14065-3-3-0.69][14147-3-3-1.44][14595-2-2-2.21][14687-2-2-4.73][14788-2-2-3.60][14869-1-2-1.62][14872-3-0-0.45][14877-1-1-4.88][14927-0-0-0.47][15066-0-3-2.89]
[15175-1-1-0.97][15178-2-2-1.91][15375-3-3-0.19][15389-3-3-2.82][15568-2-1-1.14][15675-3-3-2.83][15869-1-3-0.05][16207-3-0-1.19][16236-0-2-1.35][16302-3-2-0.38]
[16331-2-2-5.36][16381-0-3--0.17][16488-1-1-4.50][16495-0-0-1.42][16650-0-0-4.19][16719-1-2-2.13][16801-0-0-5.28][16828-0-0-2.02][17137-3-3-0.69][17245-1-2-1.09]
[17278-3-3-0.32][17282-0-2-0.23][17311-2-2-2.70][17336-2-1-1.07][17608-3-3-4.04][17627-0-0-1.83][17877-3-1-1.63][17924-1-2-0.72][17984-3-3-3.67][18211-0-3-3.07]
[18276-3-3-1.60][18287-1-1-2.94][18394-0-0-2.91][18428-0-0-2.34][18442-0-3-2.43][18478-3-3-1.19][18607-0-0-2.00][18616-0-0-0.73][18663-0-0-0.47][18718-0-0-2.76]
[18766-2-2-2.41][18824-2-2-2.08][18890-3-3-1.07][18930-3-1-0.95][18938-3-3-2.24][19817-1-1-1.93][19839-0-0-1.19][19930-3-3-1.68][19944-0-2-0.72][20036-2-2-4.51]
[20101-3-3-0.56][20474-1-1-1.11][20547-3-3-2.40][20929-2-2-2.63][21245-1-1-2.41][21257-3-3-0.84][21293-1-2-3.01][21316-1-1-4.02][21384-1-1-2.37][21448-1-1-2.90]
[21483-0-0-1.87][21487-2-2-4.77][21714-0-3-1.08][21943-3-2-2.14][21947-0-0-3.21][21948-0-0-4.02][21965-2-2-2.76][21998-1-1-1.95][22025-0-2-1.67][22228-3-3-3.47]
[22446-1-1-3.97][22494-3-3-2.33][22757-0-3-2.11][22811-3-3-3.56][22976-3-2-0.13][22985-3-3-3.46][23014-0-3-3.18][23112-1-1-3.56][23144-3-3-1.93][23168-2-2-0.23]
[23219-0-0-1.03][23363-3-3-0.29][23470-0-1-1.03][23486-2-2-1.03][23497-0-3-2.93][23516-0-0-1.67][23690-1-2-3.02][23921-2-2-1.06][23936-1-2-2.84][24040-3-0-0.42]
[24111-1-1-1.44][24182-0-0-4.16][24238-3-3-1.83][24290-2-0-2.34][24345-0-0-1.03][24364-1-1-0.97][24427-3-0-0.98][24477-2-2-4.18][24495-2-1-1.76][24893-2-2-2.91]
[25012-1-1-1.25][25121-2-2-1.39][25165-3-3-1.50][25183-0-0-2.17][25297-3-3-3.98][25398-0-0-1.95][25574-2-2-2.82][25644-1-1-3.27][25718-1-1-0.65][25774-2-2-0.40]
[26032-3-3-3.18][26051-3-3-3.76][26120-0-1--0.53][26321-1-1-3.03][26732-1-1-2.82][26784-3-3-4.30][26827-3-3-1.90][26833-0-3-1.80][26838-2-2-0.40][26860-1-1-0.74]
[26948-0-0-0.42][27049-3-0-1.00][27098-1-1-1.16][27526-0-0-2.20][27639-3-3-2.08][27698-3-3-2.95][27772-0-0-2.96][27890-1-1-1.86][28040-0-0-0.34][28503-2-2-4.57]
[28577-1-1-5.63][28959-0-0-3.32][29198-3-2--0.15][29777-0-0-4.39][29877-2-2-2.33][30035-1-1-1.87][30098-0-0-0.69][30326-1-1-5.46][30572-2-2-3.75][30716-0-1-1.84]
[30806-2-3-0.78][30906-1-1-4.16][31007-0-0-2.13][31181-3-3-0.22][31238-0-3-1.67][31347-0-0-3.72][31422-2-2-2.04][31429-3-1-0.65][31431-0-2-0.10][31432-1-1-4.34]
[31477-0-3-2.13][31524-1-0--0.39][31597-1-1-2.28][31619-1-2-0.58][31701-0-0-3.42][31755-0-0-3.75][31854-3-3-2.57][32074-1-1-2.56][32078-3-3-2.19][32111-1-1-4.04]
[32127-1-1-1.96][32140-3-3-2.40][32263-2-2-0.05][32365-0-0-1.80][32411-2-3-2.24][32429-3-3-2.59][32473-3-0-1.00][32574-3-3-2.66][32584-0-0-0.77][32622-0-2-1.79]
[32858-3-3-2.20][32969-3-3-1.44][33016-2-2-4.21][33031-1-3-0.95][33035-2-2-2.04][33133-2-2-2.78][33173-2-2--0.37][33175-3-2-2.36][33306-3-1-1.18][33309-2-2-0.69]
[33474-0-0-0.13][33478-2-0--0.40][33618-1-1-1.17][33712-0-3-0.10][33782-2-1-3.02][33914-3-3-3.66][34076-3-2-1.36][34112-2-2-1.37][34138-2-2-0.24][34239-1-1-0.58]
[34364-2-2-2.16][34617-1-2-2.35][34751-3-3-1.26][34783-2-2-1.79][35015-3-3-1.45][35018-1-1-1.56][35288-2-2-0.74]
---------------------------
I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.061 | Acc: 99.375% | Wgt Acc: 99.406%
	I - Batch: 100 | Loss: 0.061 | Acc: 99.562% | Wgt Acc: 99.592%
	I - Batch: 150 | Loss: 0.062 | Acc: 99.583% | Wgt Acc: 99.606%
I - num batch: 160
I - Train -- Loss: 0.062 | Acc: 99.568% | Wgt Acc: 99.593% | LR: 1.250000e-05 | Dur: 195.59s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   1.   1.]
 [  0. 578.   0.   0.]
 [  3.   0. 730.   1.]
 [  2.   0.   3. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.944 | Acc: 65.443% | Wgt Acc: 64.334% | Dur: 17.15s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 15. 12. 27.]
 [ 1. 39.  7.  3.]
 [ 3. 21. 46.  4.]
 [ 7.  3. 10. 52.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 99.625% | Wgt Acc: 99.633%
	I - Batch: 100 | Loss: 0.057 | Acc: 99.562% | Wgt Acc: 99.563%
	I - Batch: 150 | Loss: 0.056 | Acc: 99.625% | Wgt Acc: 99.624%
I - num batch: 160
I - Train -- Loss: 0.058 | Acc: 99.647% | Wgt Acc: 99.646% | LR: 1.250000e-05 | Dur: 195.76s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   4.]
 [  1. 578.   1.   0.]
 [  1.   0. 733.   0.]
 [  2.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.929 | Acc: 66.055% | Wgt Acc: 65.897% | Dur: 17.39s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  9.  5. 16.]
 [ 5. 45. 14.  5.]
 [ 3. 18. 46.  4.]
 [16.  6. 10. 61.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.053 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.057 | Acc: 99.688% | Wgt Acc: 99.661%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.625% | Wgt Acc: 99.615%
I - num batch: 160
I - Train -- Loss: 0.058 | Acc: 99.647% | Wgt Acc: 99.637% | LR: 1.250000e-05 | Dur: 197.11s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   5.]
 [  1. 578.   0.   0.]
 [  1.   0. 733.   0.]
 [  1.   0.   1. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.927 | Acc: 65.443% | Wgt Acc: 64.878% | Dur: 15.82s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  5.  4. 20.]
 [ 6. 50. 13.  6.]
 [ 6. 22. 53. 11.]
 [14.  1.  5. 49.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.057 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.053 | Acc: 99.812% | Wgt Acc: 99.817%
	I - Batch: 150 | Loss: 0.054 | Acc: 99.792% | Wgt Acc: 99.784%
I - num batch: 160
I - Train -- Loss: 0.055 | Acc: 99.804% | Wgt Acc: 99.797% | LR: 1.250000e-05 | Dur: 194.16s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.]
 [  1. 577.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   1.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.965 | Acc: 67.278% | Wgt Acc: 66.101% | Dur: 14.88s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  8.  7. 20.]
 [ 4. 43.  9.  6.]
 [ 4. 24. 57. 10.]
 [10.  3.  2. 50.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.054 | Acc: 99.750% | Wgt Acc: 99.718%
	I - Batch: 100 | Loss: 0.051 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.052 | Acc: 99.667% | Wgt Acc: 99.652%
I - num batch: 160
I - Train -- Loss: 0.054 | Acc: 99.607% | Wgt Acc: 99.602% | LR: 1.250000e-05 | Dur: 174.59s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   3.]
 [  1. 577.   0.   0.]
 [  1.   1. 734.   1.]
 [  3.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.019 | Acc: 66.055% | Wgt Acc: 65.421% | Dur: 14.72s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  9.  7. 17.]
 [ 3. 34.  6.  2.]
 [ 3. 25. 46.  2.]
 [11. 10. 16. 65.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.053 | Acc: 99.750% | Wgt Acc: 99.774%
	I - Batch: 100 | Loss: 0.058 | Acc: 99.562% | Wgt Acc: 99.607%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.625% | Wgt Acc: 99.653%
I - num batch: 160
I - Train -- Loss: 0.057 | Acc: 99.647% | Wgt Acc: 99.673% | LR: 1.250000e-05 | Dur: 173.71s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   1.]
 [  1. 578.   1.   0.]
 [  2.   0. 731.   0.]
 [  2.   0.   2. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.037 | Acc: 62.385% | Wgt Acc: 61.889% | Dur: 16.42s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 19. 12. 35.]
 [ 2. 47. 15.  3.]
 [ 2. 11. 32.  0.]
 [ 7.  1. 16. 48.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.045 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.047 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.833% | Wgt Acc: 99.840%
I - num batch: 160
I - Train -- Loss: 0.048 | Acc: 99.843% | Wgt Acc: 99.850% | LR: 1.250000e-05 | Dur: 191.96s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  2.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.922 | Acc: 66.972% | Wgt Acc: 66.440% | Dur: 15.18s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  6.  7. 19.]
 [ 6. 48. 16.  9.]
 [ 4. 21. 47.  4.]
 [ 8.  3.  5. 54.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.045 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.049 | Acc: 99.688% | Wgt Acc: 99.705%
	I - Batch: 150 | Loss: 0.051 | Acc: 99.750% | Wgt Acc: 99.756%
I - num batch: 160
I - Train -- Loss: 0.052 | Acc: 99.764% | Wgt Acc: 99.770% | LR: 1.250000e-05 | Dur: 194.78s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   1.]
 [  0. 578.   0.   0.]
 [  2.   0. 732.   1.]
 [  0.   0.   1. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.068 | Acc: 63.914% | Wgt Acc: 63.927% | Dur: 16.60s
I - Confusion Matrix: [row->prediction - col->label]
[[67. 13.  9. 21.]
 [ 2. 42.  9.  1.]
 [ 2. 12. 37.  1.]
 [17. 11. 20. 63.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.049 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.048 | Acc: 99.812% | Wgt Acc: 99.802%
	I - Batch: 150 | Loss: 0.049 | Acc: 99.875% | Wgt Acc: 99.869%
I - num batch: 160
I - Train -- Loss: 0.049 | Acc: 99.882% | Wgt Acc: 99.876% | LR: 1.250000e-05 | Dur: 194.79s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.045 | Acc: 62.691% | Wgt Acc: 61.617% | Dur: 17.18s
I - Confusion Matrix: [row->prediction - col->label]
[[56.  4.  3. 17.]
 [ 6. 44.  9.  5.]
 [15. 27. 62. 21.]
 [11.  3.  1. 43.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.046 | Acc: 99.812% | Wgt Acc: 99.788%
	I - Batch: 150 | Loss: 0.046 | Acc: 99.833% | Wgt Acc: 99.821%
I - num batch: 160
I - Train -- Loss: 0.048 | Acc: 99.804% | Wgt Acc: 99.788% | LR: 1.250000e-05 | Dur: 195.95s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   2.]
 [  0.   0.   1. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.965 | Acc: 65.749% | Wgt Acc: 64.334% | Dur: 16.21s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  9.  8. 34.]
 [ 3. 49. 12.  8.]
 [ 3. 19. 51.  6.]
 [ 5.  1.  4. 38.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.051 | Acc: 99.625% | Wgt Acc: 99.634%
	I - Batch: 100 | Loss: 0.047 | Acc: 99.625% | Wgt Acc: 99.648%
	I - Batch: 150 | Loss: 0.046 | Acc: 99.750% | Wgt Acc: 99.765%
I - num batch: 160
I - Train -- Loss: 0.048 | Acc: 99.725% | Wgt Acc: 99.735% | LR: 1.250000e-05 | Dur: 194.84s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   1.]
 [  0. 577.   0.   0.]
 [  4.   0. 734.   0.]
 [  1.   1.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.944 | Acc: 66.055% | Wgt Acc: 65.625% | Dur: 17.13s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  4.  4. 12.]
 [ 3. 44. 10.  4.]
 [10. 27. 57. 12.]
 [18.  3.  4. 58.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 99.625% | Wgt Acc: 99.608%
	I - Batch: 100 | Loss: 0.047 | Acc: 99.688% | Wgt Acc: 99.690%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.667% | Wgt Acc: 99.671%
I - num batch: 160
I - Train -- Loss: 0.049 | Acc: 99.686% | Wgt Acc: 99.690% | LR: 1.250000e-05 | Dur: 197.99s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   3.]
 [  0. 578.   0.   0.]
 [  4.   0. 734.   0.]
 [  1.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.914 | Acc: 68.502% | Wgt Acc: 68.071% | Dur: 17.34s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  9.  8. 18.]
 [ 3. 45. 12.  3.]
 [ 1. 19. 44.  4.]
 [10.  5. 11. 61.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.053 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.049 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.047 | Acc: 99.875% | Wgt Acc: 99.869%
I - num batch: 160
I - Train -- Loss: 0.047 | Acc: 99.882% | Wgt Acc: 99.876% | LR: 1.250000e-05 | Dur: 196.66s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 577.   0.   1.]
 [  0.   1. 734.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.885 | Acc: 66.667% | Wgt Acc: 66.712% | Dur: 17.14s
I - Confusion Matrix: [row->prediction - col->label]
[[70. 11.  8. 23.]
 [ 5. 56. 17.  6.]
 [ 2. 10. 38.  3.]
 [11.  1. 12. 54.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.625% | Wgt Acc: 99.605%
	I - Batch: 100 | Loss: 0.044 | Acc: 99.750% | Wgt Acc: 99.733%
	I - Batch: 150 | Loss: 0.044 | Acc: 99.750% | Wgt Acc: 99.737%
I - num batch: 160
I - Train -- Loss: 0.046 | Acc: 99.725% | Wgt Acc: 99.717% | LR: 1.250000e-05 | Dur: 196.64s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   3.]
 [  2. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.889 | Acc: 68.196% | Wgt Acc: 67.255% | Dur: 16.77s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  3.  4. 16.]
 [ 3. 46.  8.  4.]
 [10. 28. 60. 14.]
 [10.  1.  3. 52.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.045 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.044 | Acc: 99.833% | Wgt Acc: 99.822%
I - num batch: 160
I - Train -- Loss: 0.044 | Acc: 99.843% | Wgt Acc: 99.832% | LR: 1.250000e-05 | Dur: 195.67s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   2.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   1.]
 [  0.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.970 | Acc: 63.914% | Wgt Acc: 62.772% | Dur: 17.39s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  4.  3. 15.]
 [ 2. 39.  7.  5.]
 [12. 34. 62. 17.]
 [15.  1.  3. 49.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.833% | Wgt Acc: 99.831%
I - num batch: 160
I - Train -- Loss: 0.042 | Acc: 99.843% | Wgt Acc: 99.841% | LR: 1.250000e-05 | Dur: 186.90s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   1.]
 [  1. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.025 | Acc: 66.361% | Wgt Acc: 64.878% | Dur: 14.33s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  7.  7. 27.]
 [ 3. 42.  8.  4.]
 [ 6. 27. 59. 10.]
 [ 8.  2.  1. 45.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.039 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.041 | Acc: 99.833% | Wgt Acc: 99.840%
I - num batch: 160
I - Train -- Loss: 0.040 | Acc: 99.843% | Wgt Acc: 99.850% | LR: 1.250000e-05 | Dur: 172.80s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   1.]
 [  0. 578.   0.   0.]
 [  1.   0. 733.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 62.385% | Wgt Acc: 61.889% | Dur: 14.25s
I - Confusion Matrix: [row->prediction - col->label]
[[55. 11.  4.  8.]
 [ 1. 26.  4.  1.]
 [ 8. 33. 54.  8.]
 [24.  8. 13. 69.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.812% | Wgt Acc: 99.788%
	I - Batch: 150 | Loss: 0.039 | Acc: 99.833% | Wgt Acc: 99.812%
I - num batch: 160
I - Train -- Loss: 0.039 | Acc: 99.843% | Wgt Acc: 99.823% | LR: 1.250000e-05 | Dur: 187.86s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   3.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   1.]
 [  0.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.096 | Acc: 67.278% | Wgt Acc: 65.761% | Dur: 18.29s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  3. 20.]
 [ 2. 38.  6.  1.]
 [ 7. 33. 63. 15.]
 [10.  2.  3. 50.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.038 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.038 | Acc: 99.833% | Wgt Acc: 99.831%
I - num batch: 160
I - Train -- Loss: 0.038 | Acc: 99.804% | Wgt Acc: 99.797% | LR: 1.250000e-05 | Dur: 196.99s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   1.   0.   0.]
 [  1. 576.   0.   0.]
 [  1.   1. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.923 | Acc: 68.196% | Wgt Acc: 67.663% | Dur: 16.25s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9.  7. 21.]
 [ 5. 55. 17.  9.]
 [ 4. 12. 47.  7.]
 [ 7.  2.  4. 49.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.035 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 193.69s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.079 | Acc: 65.138% | Wgt Acc: 64.606% | Dur: 16.37s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 19. 14. 23.]
 [ 3. 40.  6.  2.]
 [ 2. 16. 42.  2.]
 [11.  3. 13. 59.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.868%
I - num batch: 160
I - Train -- Loss: 0.036 | Acc: 99.882% | Wgt Acc: 99.876% | LR: 1.250000e-05 | Dur: 195.59s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.987 | Acc: 66.055% | Wgt Acc: 64.198% | Dur: 17.30s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 13.  7. 28.]
 [ 4. 39.  7.  6.]
 [ 6. 25. 61. 10.]
 [ 4.  1.  0. 42.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.035 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.750% | Wgt Acc: 99.733%
	I - Batch: 150 | Loss: 0.039 | Acc: 99.750% | Wgt Acc: 99.737%
I - num batch: 160
I - Train -- Loss: 0.039 | Acc: 99.686% | Wgt Acc: 99.682% | LR: 1.250000e-05 | Dur: 192.46s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   2.]
 [  0. 577.   0.   0.]
 [  1.   0. 733.   1.]
 [  2.   1.   1. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.970 | Acc: 64.526% | Wgt Acc: 63.111% | Dur: 15.82s
I - Confusion Matrix: [row->prediction - col->label]
[[82. 14. 11. 39.]
 [ 1. 48. 16.  5.]
 [ 3. 13. 44.  5.]
 [ 2.  3.  4. 37.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.750% | Wgt Acc: 99.718%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.812% | Wgt Acc: 99.788%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.875% | Wgt Acc: 99.859%
I - num batch: 160
I - Train -- Loss: 0.035 | Acc: 99.882% | Wgt Acc: 99.867% | LR: 1.250000e-05 | Dur: 195.85s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   2.]
 [  0. 577.   0.   0.]
 [  0.   1. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.905 | Acc: 68.196% | Wgt Acc: 67.255% | Dur: 17.60s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  8.  4. 24.]
 [ 2. 40.  9.  1.]
 [ 4. 28. 53.  3.]
 [10.  2.  9. 58.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-05 | Dur: 196.62s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.916 | Acc: 67.584% | Wgt Acc: 66.848% | Dur: 18.80s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  3.  5. 17.]
 [ 4. 49. 10.  4.]
 [ 9. 24. 58. 14.]
 [12.  2.  2. 51.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 193.93s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.906 | Acc: 66.972% | Wgt Acc: 66.644% | Dur: 16.18s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 13.  9. 28.]
 [ 3. 54. 19.  3.]
 [ 2. 10. 37.  4.]
 [ 6.  1. 10. 51.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.035 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 197.23s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.896 | Acc: 68.502% | Wgt Acc: 67.935% | Dur: 17.01s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  7.  5. 16.]
 [ 4. 44. 10.  5.]
 [ 3. 24. 50.  5.]
 [11.  3. 10. 60.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.030 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-05 | Dur: 192.65s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  2.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.978 | Acc: 66.667% | Wgt Acc: 65.557% | Dur: 16.43s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  4. 17.]
 [ 4. 44. 10.  7.]
 [ 9. 28. 60. 13.]
 [10.  1.  1. 49.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.917% | Wgt Acc: 99.906%
I - num batch: 160
I - Train -- Loss: 0.034 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-05 | Dur: 175.67s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.106 | Acc: 64.526% | Wgt Acc: 64.266% | Dur: 14.87s
I - Confusion Matrix: [row->prediction - col->label]
[[66. 14.  7. 14.]
 [ 2. 35.  7.  2.]
 [ 4. 14. 43.  3.]
 [16. 15. 18. 67.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.038 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.833% | Wgt Acc: 99.822%
I - num batch: 160
I - Train -- Loss: 0.036 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-05 | Dur: 175.42s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   2.]
 [  1. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  1.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.901 | Acc: 67.584% | Wgt Acc: 67.188% | Dur: 14.89s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  8.  7. 19.]
 [ 3. 49. 12.  7.]
 [ 3. 18. 48.  4.]
 [14.  3.  8. 56.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 193.57s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.077 | Acc: 62.080% | Wgt Acc: 60.870% | Dur: 17.15s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  6.  5. 15.]
 [ 3. 32.  7.  2.]
 [13. 39. 60. 17.]
 [13.  1.  3. 52.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.833% | Wgt Acc: 99.831%
I - num batch: 160
I - Train -- Loss: 0.035 | Acc: 99.804% | Wgt Acc: 99.805% | LR: 1.250000e-05 | Dur: 194.73s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   0.]
 [  1. 578.   0.   1.]
 [  1.   0. 733.   1.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.896 | Acc: 68.807% | Wgt Acc: 68.342% | Dur: 16.39s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  4.  3. 12.]
 [ 4. 46. 11.  4.]
 [ 8. 25. 53. 10.]
 [10.  3.  8. 60.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.625% | Wgt Acc: 99.605%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.030 | Acc: 99.875% | Wgt Acc: 99.868%
I - num batch: 160
I - Train -- Loss: 0.030 | Acc: 99.843% | Wgt Acc: 99.832% | LR: 1.250000e-05 | Dur: 196.25s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   1.   0.   2.]
 [  0. 577.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.948 | Acc: 67.278% | Wgt Acc: 66.644% | Dur: 16.85s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  2.  5. 15.]
 [ 2. 47. 10. 10.]
 [ 7. 26. 54.  7.]
 [14.  3.  6. 54.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.034 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.938% | Wgt Acc: 99.943%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 194.46s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.044 | Acc: 64.526% | Wgt Acc: 64.402% | Dur: 17.60s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  7. 13.]
 [ 1. 37.  8.  3.]
 [ 6. 27. 43.  3.]
 [17.  7. 17. 67.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.878%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.882% | Wgt Acc: 99.885% | LR: 1.250000e-05 | Dur: 191.58s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 733.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.115 | Acc: 62.691% | Wgt Acc: 62.568% | Dur: 16.60s
I - Confusion Matrix: [row->prediction - col->label]
[[64. 11.  7. 17.]
 [ 2. 35.  7.  1.]
 [ 2. 18. 40.  2.]
 [20. 14. 21. 66.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.750% | Wgt Acc: 99.718%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.750% | Wgt Acc: 99.732%
	I - Batch: 150 | Loss: 0.030 | Acc: 99.792% | Wgt Acc: 99.774%
I - num batch: 160
I - Train -- Loss: 0.034 | Acc: 99.764% | Wgt Acc: 99.752% | LR: 1.250000e-05 | Dur: 196.30s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   1.   2.]
 [  0. 578.   0.   1.]
 [  0.   0. 733.   1.]
 [  1.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.241 | Acc: 61.468% | Wgt Acc: 61.481% | Dur: 18.47s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 17. 15. 26.]
 [ 3. 43. 14.  2.]
 [ 2.  7. 24.  0.]
 [ 7. 11. 22. 58.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.037 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.833% | Wgt Acc: 99.822%
I - num batch: 160
I - Train -- Loss: 0.033 | Acc: 99.804% | Wgt Acc: 99.797% | LR: 1.250000e-05 | Dur: 196.17s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   1.   0.   1.]
 [  0. 576.   0.   0.]
 [  0.   1. 734.   0.]
 [  2.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.900 | Acc: 64.832% | Wgt Acc: 64.198% | Dur: 17.54s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  8.  5. 22.]
 [ 1. 42. 10.  3.]
 [ 7. 24. 49.  6.]
 [14.  4. 11. 55.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.833% | Wgt Acc: 99.822%
I - num batch: 160
I - Train -- Loss: 0.031 | Acc: 99.843% | Wgt Acc: 99.832% | LR: 1.250000e-05 | Dur: 196.36s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   1.]
 [  1.   0.   0. 535.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.890 | Acc: 69.419% | Wgt Acc: 68.750% | Dur: 16.55s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  9.  7. 18.]
 [ 1. 45.  7.  3.]
 [ 4. 23. 52.  6.]
 [12.  1.  9. 59.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.027 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.028 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.028 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.029 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 196.75s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.036 | Acc: 64.526% | Wgt Acc: 63.519% | Dur: 16.94s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  4.  3. 11.]
 [ 3. 38. 12.  8.]
 [11. 33. 58. 14.]
 [12.  3.  2. 53.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.026 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 188.37s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.936 | Acc: 66.361% | Wgt Acc: 65.217% | Dur: 16.00s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  9.  7. 30.]
 [ 6. 50. 13.  5.]
 [ 4. 18. 52.  9.]
 [ 5.  1.  3. 42.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.028 | Acc: 99.875% | Wgt Acc: 99.874%
	I - Batch: 150 | Loss: 0.028 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.028 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 174.33s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.937 | Acc: 66.667% | Wgt Acc: 65.693% | Dur: 14.61s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 12. 12. 24.]
 [ 2. 43.  9.  6.]
 [ 3. 21. 50.  4.]
 [10.  2.  4. 52.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.025 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.026 | Acc: 99.917% | Wgt Acc: 99.906%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-05 | Dur: 175.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   2.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.982 | Acc: 64.832% | Wgt Acc: 64.402% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 13.  7. 32.]
 [ 3. 50. 15.  3.]
 [ 2.  8. 37.  1.]
 [ 8.  7. 16. 50.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.027 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.025 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.025 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 173.15s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   1.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.891 | Acc: 69.419% | Wgt Acc: 68.886% | Dur: 14.79s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  6.  6. 20.]
 [ 5. 53. 15.  5.]
 [ 4. 18. 50.  8.]
 [ 8.  1.  4. 53.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.023 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.024 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-05 | Dur: 173.90s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.015 | Acc: 67.278% | Wgt Acc: 66.168% | Dur: 15.62s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  9.  7. 22.]
 [ 4. 47.  8.  6.]
 [ 8. 22. 58. 11.]
 [ 8.  0.  2. 47.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.030 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.029 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.027 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 173.27s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.937 | Acc: 67.890% | Wgt Acc: 67.595% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  9.  7. 22.]
 [ 2. 51. 14.  3.]
 [ 5. 15. 41.  5.]
 [ 7.  3. 13. 56.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.022 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.022 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.023 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 174.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.903 | Acc: 66.667% | Wgt Acc: 65.693% | Dur: 15.45s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 10.  7. 28.]
 [ 2. 47. 18.  4.]
 [ 4. 20. 45.  6.]
 [ 4.  1.  5. 48.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.025 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.024 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 173.87s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.016 | Acc: 64.832% | Wgt Acc: 63.859% | Dur: 13.44s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  4.  4. 15.]
 [ 1. 40.  8.  3.]
 [11. 31. 58. 16.]
 [14.  3.  5. 52.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.029 | Acc: 99.875% | Wgt Acc: 99.858%
	I - Batch: 100 | Loss: 0.027 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.028 | Acc: 99.917% | Wgt Acc: 99.916%
I - num batch: 160
I - Train -- Loss: 0.029 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 144.37s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   1.   0.   0.]
 [  0. 577.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.073 | Acc: 63.914% | Wgt Acc: 64.266% | Dur: 11.76s
I - Confusion Matrix: [row->prediction - col->label]
[[68. 15.  9. 20.]
 [ 3. 49. 22.  4.]
 [ 2. 10. 31.  1.]
 [15.  4. 13. 61.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.026 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.025 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.031 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-05 | Dur: 142.74s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   1.   0.   0.]
 [  0. 576.   0.   0.]
 [  0.   1. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.960 | Acc: 65.138% | Wgt Acc: 65.149% | Dur: 11.96s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  7. 10. 18.]
 [ 1. 49. 16.  5.]
 [ 3. 18. 39.  5.]
 [17.  4. 10. 58.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.625% | Wgt Acc: 99.663%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.750% | Wgt Acc: 99.761%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.792% | Wgt Acc: 99.793%
I - num batch: 160
I - Train -- Loss: 0.032 | Acc: 99.764% | Wgt Acc: 99.761% | LR: 1.250000e-05 | Dur: 142.84s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   1.   0.   2.]
 [  3. 577.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.964 | Acc: 68.807% | Wgt Acc: 68.410% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  5.  5.  9.]
 [ 2. 41.  4.  2.]
 [ 8. 31. 60.  9.]
 [20.  1.  6. 66.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.028 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.026 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.025 | Acc: 99.917% | Wgt Acc: 99.925%
I - num batch: 160
I - Train -- Loss: 0.026 | Acc: 99.921% | Wgt Acc: 99.929% | LR: 1.250000e-05 | Dur: 140.23s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.958 | Acc: 67.890% | Wgt Acc: 67.867% | Dur: 11.97s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 12. 10. 25.]
 [ 2. 54. 13.  3.]
 [ 1.  9. 37.  1.]
 [11.  3. 15. 57.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.030 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.027 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.027 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.027 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.34s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.922 | Acc: 67.890% | Wgt Acc: 67.255% | Dur: 11.89s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9.  7. 21.]
 [ 2. 43.  7.  1.]
 [ 4. 23. 48.  5.]
 [10.  3. 13. 59.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.025 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.023 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.023 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.023 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 143.24s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.022 | Acc: 66.055% | Wgt Acc: 65.557% | Dur: 12.08s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 14.  7. 22.]
 [ 2. 41. 11.  2.]
 [ 4. 18. 44.  2.]
 [11.  5. 13. 60.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.021 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.022 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.022 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 142.71s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.969 | Acc: 68.502% | Wgt Acc: 67.459% | Dur: 11.49s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  4.  7. 22.]
 [ 5. 50. 11.  8.]
 [ 5. 24. 57.  9.]
 [ 8.  0.  0. 47.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.11s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.989 | Acc: 66.972% | Wgt Acc: 65.897% | Dur: 11.98s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  5.  8. 20.]
 [ 2. 42.  9.  3.]
 [ 6. 31. 58. 11.]
 [13.  0.  0. 52.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.022 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.021 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 141.95s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.891 | Acc: 67.890% | Wgt Acc: 68.274% | Dur: 11.58s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  6.  6. 15.]
 [ 3. 51. 14.  2.]
 [ 3. 18. 39.  3.]
 [16.  3. 16. 66.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.020 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.020 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.33s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.911 | Acc: 67.584% | Wgt Acc: 67.867% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[70. 12.  6. 17.]
 [ 3. 54. 16.  5.]
 [ 2.  9. 36.  3.]
 [13.  3. 17. 61.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.61s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.087 | Acc: 63.609% | Wgt Acc: 62.840% | Dur: 11.39s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 16. 11. 27.]
 [ 2. 38.  7.  1.]
 [ 2. 20. 43.  3.]
 [12.  4. 14. 55.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.019 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.019 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.78s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.030 | Acc: 68.807% | Wgt Acc: 68.139% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  8.  7. 16.]
 [ 3. 47. 15.  6.]
 [ 6. 22. 50.  8.]
 [ 7.  1.  3. 56.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.89s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 67.584% | Wgt Acc: 66.372% | Dur: 11.29s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  9.  7. 26.]
 [ 3. 42. 10.  4.]
 [ 4. 25. 55.  5.]
 [ 8.  2.  3. 51.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.019 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.020 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.021 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 140.33s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.005 | Acc: 64.526% | Wgt Acc: 63.247% | Dur: 11.88s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 11.  9. 31.]
 [ 4. 47. 14. 10.]
 [ 5. 19. 49.  5.]
 [ 4.  1.  3. 40.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.85s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.912 | Acc: 66.667% | Wgt Acc: 66.168% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[69. 10.  7. 19.]
 [ 1. 45.  7.  3.]
 [ 4. 20. 47.  7.]
 [14.  3. 14. 57.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.66s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.042 | Acc: 64.832% | Wgt Acc: 62.840% | Dur: 12.00s
I - Confusion Matrix: [row->prediction - col->label]
[[80. 11.  9. 42.]
 [ 1. 45.  9.  4.]
 [ 5. 21. 55.  8.]
 [ 2.  1.  2. 32.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.020 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.019 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 142.43s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.013 | Acc: 64.220% | Wgt Acc: 63.315% | Dur: 12.49s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 14. 12. 32.]
 [ 2. 44. 11.  3.]
 [ 2. 14. 39.  3.]
 [ 5.  6. 13. 48.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.53s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.067 | Acc: 67.584% | Wgt Acc: 66.440% | Dur: 12.10s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 12.  7. 17.]
 [ 1. 32.  8.  2.]
 [ 6. 30. 54.  5.]
 [ 8.  4.  6. 62.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.018 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.018 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.83s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  1. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.917 | Acc: 67.584% | Wgt Acc: 66.372% | Dur: 12.16s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  3. 19.]
 [ 1. 42. 12.  4.]
 [ 7. 27. 56. 12.]
 [ 8.  3.  4. 51.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.75s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.042 | Acc: 67.890% | Wgt Acc: 66.576% | Dur: 11.81s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 13. 11. 30.]
 [ 1. 43.  7.  1.]
 [ 2. 20. 49.  6.]
 [ 4.  2.  8. 49.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.65s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 68.807% | Wgt Acc: 67.799% | Dur: 11.66s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 10.  7. 33.]
 [ 3. 55. 18.  5.]
 [ 3. 13. 48.  5.]
 [ 3.  0.  2. 43.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.719%
	I - Batch: 100 | Loss: 0.019 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 150 | Loss: 0.019 | Acc: 99.917% | Wgt Acc: 99.906%
I - num batch: 160
I - Train -- Loss: 0.019 | Acc: 99.921% | Wgt Acc: 99.912% | LR: 1.250000e-05 | Dur: 142.31s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   2.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.994 | Acc: 65.443% | Wgt Acc: 64.470% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 11. 12. 32.]
 [ 2. 44. 11.  3.]
 [ 4. 20. 43.  2.]
 [ 4.  3.  9. 49.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.970 | Acc: 66.972% | Wgt Acc: 66.033% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 15.  9. 26.]
 [ 1. 43. 11.  3.]
 [ 4. 16. 47.  4.]
 [ 7.  4.  8. 53.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.20s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.999 | Acc: 66.055% | Wgt Acc: 65.829% | Dur: 11.96s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  4. 13.]
 [ 2. 36.  8.  1.]
 [ 4. 23. 47.  3.]
 [18. 12. 16. 69.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.63s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.943 | Acc: 68.807% | Wgt Acc: 68.003% | Dur: 11.90s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  8.  6. 18.]
 [ 2. 40.  8.  3.]
 [ 4. 28. 54.  4.]
 [12.  2.  7. 61.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.017 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.018 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 141.40s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.023 | Acc: 66.972% | Wgt Acc: 65.625% | Dur: 11.47s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 11.  7. 26.]
 [ 2. 38.  5.  2.]
 [ 4. 28. 53.  6.]
 [ 6.  1. 10. 52.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.36s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.957 | Acc: 68.196% | Wgt Acc: 67.120% | Dur: 11.67s
I - Confusion Matrix: [row->prediction - col->label]
[[80.  9. 11. 34.]
 [ 3. 54. 13.  4.]
 [ 2. 14. 47.  6.]
 [ 3.  1.  4. 42.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.13s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.961 | Acc: 67.584% | Wgt Acc: 67.052% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  5.  8. 22.]
 [ 6. 56. 21. 11.]
 [ 3. 15. 43.  6.]
 [ 4.  2.  3. 47.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.63s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.066 | Acc: 65.443% | Wgt Acc: 64.606% | Dur: 12.10s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 13. 11. 19.]
 [ 2. 35.  6.  3.]
 [ 3. 22. 45.  4.]
 [ 9.  8. 13. 60.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.68s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.909 | Acc: 66.361% | Wgt Acc: 66.033% | Dur: 11.65s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  4.  4. 16.]
 [ 3. 47.  9.  3.]
 [ 9. 26. 54. 10.]
 [17.  1.  8. 57.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.22s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.975 | Acc: 64.832% | Wgt Acc: 63.791% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  8.  9. 34.]
 [ 4. 53. 16.  8.]
 [ 5. 15. 47.  6.]
 [ 5.  2.  3. 38.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.15s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.995 | Acc: 64.220% | Wgt Acc: 63.995% | Dur: 11.67s
I - Confusion Matrix: [row->prediction - col->label]
[[53.  3.  4.  9.]
 [ 1. 36.  5.  1.]
 [12. 34. 55. 10.]
 [22.  5. 11. 66.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.021 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.020 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.15s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.991 | Acc: 67.584% | Wgt Acc: 66.440% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  6. 17.]
 [ 2. 37.  8.  3.]
 [ 4. 34. 55.  9.]
 [10.  2.  6. 57.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 139.21s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.054 | Acc: 64.832% | Wgt Acc: 63.383% | Dur: 11.66s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  9.  5. 21.]
 [ 1. 31.  7.  2.]
 [ 8. 36. 56.  9.]
 [ 8.  2.  7. 54.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.70s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.954 | Acc: 68.502% | Wgt Acc: 67.595% | Dur: 11.54s
I - Confusion Matrix: [row->prediction - col->label]
[[78.  8.  8. 28.]
 [ 2. 52. 15.  6.]
 [ 3. 17. 47.  5.]
 [ 5.  1.  5. 47.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.44s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.891 | Acc: 68.807% | Wgt Acc: 68.818% | Dur: 11.52s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  4.  3. 12.]
 [ 2. 54. 17.  6.]
 [ 4. 18. 47.  9.]
 [17.  2.  8. 59.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 142.43s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 577.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   1.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.059 | Acc: 66.361% | Wgt Acc: 65.285% | Dur: 11.82s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  4.  4. 16.]
 [ 3. 40. 11.  4.]
 [ 5. 32. 56. 13.]
 [12.  2.  4. 53.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.60s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.937 | Acc: 68.502% | Wgt Acc: 69.293% | Dur: 11.50s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  8.  7. 16.]
 [ 4. 57. 20.  2.]
 [ 1.  9. 35.  1.]
 [18.  4. 13. 67.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 99.750% | Wgt Acc: 99.775%
	I - Batch: 100 | Loss: 0.017 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 150 | Loss: 0.017 | Acc: 99.875% | Wgt Acc: 99.887%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.882% | Wgt Acc: 99.894% | LR: 1.250000e-05 | Dur: 141.89s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  2.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.268 | Acc: 60.856% | Wgt Acc: 59.579% | Dur: 11.75s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 22. 15. 43.]
 [ 3. 42.  8.  3.]
 [ 2. 13. 39.  1.]
 [ 4.  1. 13. 39.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.92s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   1.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.945 | Acc: 67.278% | Wgt Acc: 67.595% | Dur: 11.75s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  4.  6. 11.]
 [ 2. 48. 12.  3.]
 [ 3. 18. 43.  5.]
 [21.  8. 14. 67.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.016 | Acc: 99.875% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.016 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 140.49s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.878 | Acc: 70.031% | Wgt Acc: 69.837% | Dur: 11.88s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  5.  7. 12.]
 [ 3. 51. 10.  5.]
 [ 7. 20. 50.  8.]
 [11.  2.  8. 61.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.015 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.73s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   1. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.000 | Acc: 68.502% | Wgt Acc: 67.935% | Dur: 12.04s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  5. 14.]
 [ 1. 40.  7.  1.]
 [ 7. 29. 54.  7.]
 [14.  4.  9. 64.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.43s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.098 | Acc: 62.385% | Wgt Acc: 60.530% | Dur: 11.76s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 15. 11. 44.]
 [ 1. 43. 14.  3.]
 [ 4. 19. 48.  7.]
 [ 2.  1.  2. 32.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.019 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.33s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.008 | Acc: 66.361% | Wgt Acc: 66.033% | Dur: 11.92s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  8.  6. 11.]
 [ 2. 38.  7.  2.]
 [ 5. 27. 50.  7.]
 [18.  5. 12. 66.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.92s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.066 | Acc: 68.807% | Wgt Acc: 67.731% | Dur: 12.00s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 10.  8. 26.]
 [ 2. 43. 10.  3.]
 [ 5. 21. 50.  3.]
 [ 3.  4.  7. 54.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.47s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.089 | Acc: 66.972% | Wgt Acc: 66.304% | Dur: 11.56s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  6. 18.]
 [ 5. 45. 11.  7.]
 [ 3. 25. 50.  6.]
 [11.  2.  8. 55.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.26s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.027 | Acc: 66.361% | Wgt Acc: 65.489% | Dur: 11.42s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  5.  8. 16.]
 [ 1. 38.  6.  2.]
 [10. 34. 57. 10.]
 [13.  1.  4. 58.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.04s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.003 | Acc: 66.972% | Wgt Acc: 66.033% | Dur: 11.75s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  5.  4. 17.]
 [ 3. 43. 10.  4.]
 [ 6. 29. 55. 12.]
 [11.  1.  6. 53.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.85s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.015 | Acc: 68.196% | Wgt Acc: 67.595% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  9.  5. 18.]
 [ 0. 39.  7.  0.]
 [ 5. 24. 50.  4.]
 [13.  6. 13. 64.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.090 | Acc: 62.997% | Wgt Acc: 62.228% | Dur: 11.86s
I - Confusion Matrix: [row->prediction - col->label]
[[70. 15.  8. 23.]
 [ 1. 35.  7.  1.]
 [ 5. 20. 44.  5.]
 [12.  8. 16. 57.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.69s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.026 | Acc: 66.972% | Wgt Acc: 67.120% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 12.  9. 19.]
 [ 1. 49. 12.  0.]
 [ 2. 11. 36.  4.]
 [14.  6. 18. 63.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.01s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.995 | Acc: 66.667% | Wgt Acc: 66.236% | Dur: 12.21s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 12.  8. 18.]
 [ 1. 40.  9.  2.]
 [ 4. 22. 42.  3.]
 [10.  4. 16. 63.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.05s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 62.691% | Wgt Acc: 60.870% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 18. 10. 37.]
 [ 1. 37.  8.  3.]
 [ 4. 21. 50.  7.]
 [ 4.  2.  7. 39.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.875% | Wgt Acc: 99.873%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.917% | Wgt Acc: 99.915%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.921% | Wgt Acc: 99.920% | LR: 1.250000e-05 | Dur: 141.43s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.196 | Acc: 64.832% | Wgt Acc: 63.655% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 12.  5. 18.]
 [ 0. 26.  5.  0.]
 [ 3. 32. 51.  5.]
 [13.  8. 14. 63.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.014 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 142.40s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.914 | Acc: 68.807% | Wgt Acc: 68.886% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 12.  8. 21.]
 [ 2. 54. 15.  3.]
 [ 2. 10. 39.  2.]
 [12.  2. 13. 60.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.94s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.028 | Acc: 66.055% | Wgt Acc: 65.489% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 10.  8. 26.]
 [ 4. 51. 16.  7.]
 [ 3. 15. 44.  4.]
 [ 9.  2.  7. 49.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 142.33s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.131 | Acc: 66.361% | Wgt Acc: 65.353% | Dur: 11.89s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  4.  6. 15.]
 [ 1. 39.  7.  3.]
 [ 7. 31. 58. 13.]
 [15.  4.  4. 55.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.030 | Acc: 66.055% | Wgt Acc: 65.082% | Dur: 12.13s
I - Confusion Matrix: [row->prediction - col->label]
[[78.  9.  8. 34.]
 [ 3. 54. 21.  8.]
 [ 3. 13. 44.  4.]
 [ 4.  2.  2. 40.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.40s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.988 | Acc: 67.584% | Wgt Acc: 66.780% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 12.  7. 22.]
 [ 1. 42. 11.  2.]
 [ 5. 19. 50.  5.]
 [10.  5.  7. 57.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.72s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.055 | Acc: 66.361% | Wgt Acc: 65.082% | Dur: 11.69s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  7.  7. 26.]
 [ 3. 50. 13.  7.]
 [ 7. 21. 53. 13.]
 [ 4.  0.  2. 40.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.014 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.82s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.972 | Acc: 66.055% | Wgt Acc: 65.353% | Dur: 11.69s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 13. 13. 24.]
 [ 2. 42.  7.  2.]
 [ 3. 18. 42.  4.]
 [ 7.  5. 13. 56.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.013 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 142.49s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   1.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.998 | Acc: 66.667% | Wgt Acc: 65.761% | Dur: 11.92s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  5.  4. 14.]
 [ 2. 39.  8.  4.]
 [11. 32. 60. 11.]
 [13.  2.  3. 57.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.002 | Acc: 65.749% | Wgt Acc: 65.149% | Dur: 11.69s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 12.  9. 17.]
 [ 3. 39. 12.  4.]
 [ 4. 19. 44.  5.]
 [ 9.  8. 10. 60.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.018 | Acc: 99.938% | Wgt Acc: 99.930%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 141.91s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 577.   0.   0.]
 [  0.   1. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.966 | Acc: 68.196% | Wgt Acc: 67.935% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[65. 10.  8. 12.]
 [ 2. 42.  7.  2.]
 [ 6. 22. 50.  6.]
 [15.  4. 10. 66.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.20s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.085 | Acc: 65.138% | Wgt Acc: 64.606% | Dur: 11.85s
I - Confusion Matrix: [row->prediction - col->label]
[[68. 13.  9. 17.]
 [ 1. 34.  4.  1.]
 [ 6. 25. 46.  3.]
 [13.  6. 16. 65.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.012 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.012 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.02s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.280 | Acc: 62.691% | Wgt Acc: 61.617% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 11. 13. 41.]
 [ 2. 50. 21.  4.]
 [ 3. 15. 39.  4.]
 [ 4.  2.  2. 37.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.025 | Acc: 99.625% | Wgt Acc: 99.605%
	I - Batch: 100 | Loss: 0.019 | Acc: 99.812% | Wgt Acc: 99.803%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.875% | Wgt Acc: 99.869%
I - num batch: 160
I - Train -- Loss: 0.016 | Acc: 99.882% | Wgt Acc: 99.876% | LR: 1.250000e-05 | Dur: 141.92s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   1.]
 [  0.   0.   0. 536.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.943 | Acc: 67.890% | Wgt Acc: 67.459% | Dur: 12.10s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 10.  6. 22.]
 [ 4. 51. 15.  4.]
 [ 5. 15. 46.  6.]
 [ 8.  2.  8. 54.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.12s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.076 | Acc: 66.361% | Wgt Acc: 66.372% | Dur: 11.63s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 14. 17. 24.]
 [ 2. 50. 11.  2.]
 [ 2. 11. 32.  1.]
 [ 8.  3. 15. 59.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 140.07s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.943 | Acc: 69.113% | Wgt Acc: 68.410% | Dur: 11.95s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  3. 14.]
 [ 3. 46.  9.  4.]
 [ 8. 25. 57. 11.]
 [11.  2.  6. 57.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.18s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.069 | Acc: 65.749% | Wgt Acc: 64.878% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 15. 14. 25.]
 [ 1. 40.  6.  3.]
 [ 3. 20. 44.  3.]
 [ 8.  3. 11. 55.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.46s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.066 | Acc: 66.055% | Wgt Acc: 64.606% | Dur: 11.40s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 12. 10. 26.]
 [ 1. 36.  5.  3.]
 [ 6. 27. 54.  6.]
 [ 6.  3.  6. 51.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.96s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.242 | Acc: 64.526% | Wgt Acc: 62.772% | Dur: 12.13s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 11. 13. 39.]
 [ 1. 41.  6.  4.]
 [ 5. 22. 50.  4.]
 [ 1.  4.  6. 39.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.018 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.015 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.014 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.014 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.19s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.066 | Acc: 65.443% | Wgt Acc: 65.217% | Dur: 11.53s
I - Confusion Matrix: [row->prediction - col->label]
[[72. 16. 11. 20.]
 [ 2. 42.  8.  1.]
 [ 2. 14. 38.  3.]
 [12.  6. 18. 62.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 140.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   1.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.516 | Acc: 59.633% | Wgt Acc: 57.133% | Dur: 12.09s
I - Confusion Matrix: [row->prediction - col->label]
[[82.  8.  9. 53.]
 [ 2. 46. 14. 10.]
 [ 4. 24. 52.  8.]
 [ 0.  0.  0. 15.]]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.017 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.27s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.067 | Acc: 65.749% | Wgt Acc: 64.334% | Dur: 11.58s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  5. 21.]
 [ 5. 41. 11.  6.]
 [ 6. 31. 56. 13.]
 [ 5.  1.  3. 46.]]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.07s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.955 | Acc: 67.890% | Wgt Acc: 67.323% | Dur: 11.90s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  5. 18.]
 [ 2. 45. 16.  5.]
 [ 4. 20. 47.  5.]
 [10.  7.  7. 58.]]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 143.08s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.052 | Acc: 67.278% | Wgt Acc: 65.761% | Dur: 11.95s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 12.  8. 32.]
 [ 2. 44. 10.  3.]
 [ 3. 21. 53.  7.]
 [ 4.  1.  4. 44.]]

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.011 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 142.27s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  1.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.965 | Acc: 66.972% | Wgt Acc: 66.644% | Dur: 11.20s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  8.  9. 16.]
 [ 2. 43. 10.  6.]
 [ 5. 22. 45.  2.]
 [12.  5. 11. 62.]]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.90s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.107 | Acc: 65.749% | Wgt Acc: 65.014% | Dur: 12.07s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  5.  7. 14.]
 [ 1. 35.  8.  1.]
 [ 7. 35. 55.  9.]
 [17.  3.  5. 62.]]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.79s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.984 | Acc: 66.972% | Wgt Acc: 66.440% | Dur: 11.56s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 10.  8. 19.]
 [ 4. 45. 16.  6.]
 [ 2. 19. 44.  4.]
 [ 9.  4.  7. 57.]]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.59s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.098 | Acc: 62.385% | Wgt Acc: 62.704% | Dur: 12.15s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  6.  9. 13.]
 [ 2. 39. 12.  2.]
 [ 4. 17. 34.  3.]
 [19. 16. 20. 68.]]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.010 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 142.58s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   1.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.017 | Acc: 65.138% | Wgt Acc: 64.606% | Dur: 12.03s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 14. 12. 25.]
 [ 2. 42. 13.  3.]
 [ 3. 14. 39.  1.]
 [ 8.  8. 11. 57.]]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.65s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.903 | Acc: 68.807% | Wgt Acc: 68.342% | Dur: 11.97s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  5.  8. 23.]
 [ 4. 55. 18.  7.]
 [ 3. 16. 46.  5.]
 [ 8.  2.  3. 51.]]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.77s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.087 | Acc: 65.443% | Wgt Acc: 64.198% | Dur: 12.43s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 11. 10. 27.]
 [ 3. 40.  9.  4.]
 [ 4. 22. 50.  6.]
 [ 6.  5.  6. 49.]]

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.009 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.18s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.933 | Acc: 67.278% | Wgt Acc: 67.120% | Dur: 11.63s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  6. 15.]
 [ 4. 50. 18.  7.]
 [ 4. 19. 47.  6.]
 [15.  4.  4. 58.]]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.10s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.246 | Acc: 64.220% | Wgt Acc: 62.500% | Dur: 11.71s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 13. 11. 30.]
 [ 1. 30.  5.  2.]
 [ 4. 31. 52.  4.]
 [ 5.  4.  7. 50.]]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.22s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.133 | Acc: 65.443% | Wgt Acc: 64.334% | Dur: 11.78s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 10. 11. 37.]
 [ 2. 53. 15.  7.]
 [ 6. 15. 46.  4.]
 [ 3.  0.  3. 38.]]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 0.014 | Acc: 99.875% | Wgt Acc: 99.887%
	I - Batch: 100 | Loss: 0.012 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.011 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.37s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.030 | Acc: 65.443% | Wgt Acc: 64.878% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  6.  6. 20.]
 [ 2. 41.  7.  2.]
 [ 4. 27. 50.  6.]
 [17.  4. 12. 58.]]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.82s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.021 | Acc: 66.055% | Wgt Acc: 65.625% | Dur: 11.46s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9.  9. 17.]
 [ 1. 40.  9.  2.]
 [ 4. 22. 42.  5.]
 [11.  7. 15. 62.]]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.82s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.013 | Acc: 67.890% | Wgt Acc: 67.255% | Dur: 11.71s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  9.  6. 19.]
 [ 2. 45. 12.  3.]
 [ 5. 22. 49.  7.]
 [10.  2.  8. 57.]]

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.25s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.134 | Acc: 65.749% | Wgt Acc: 64.470% | Dur: 11.95s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  4.  6. 21.]
 [ 5. 53. 14. 10.]
 [ 7. 20. 55. 19.]
 [ 5.  1.  0. 36.]]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 143.07s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.954 | Acc: 67.584% | Wgt Acc: 67.391% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[67. 10.  6. 19.]
 [ 3. 45. 12.  0.]
 [ 3. 21. 46.  4.]
 [15.  2. 11. 63.]]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.00s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.954 | Acc: 68.807% | Wgt Acc: 68.614% | Dur: 11.94s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  9.  7. 18.]
 [ 2. 48. 11.  1.]
 [ 6. 18. 46.  5.]
 [11.  3. 11. 62.]]

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 0.023 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.019 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.016 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.015 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.40s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   1.   0.]
 [  0.   0. 733.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.052 | Acc: 66.361% | Wgt Acc: 65.082% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 14. 10. 30.]
 [ 4. 38.  9.  1.]
 [ 2. 23. 49.  3.]
 [ 4.  3.  7. 52.]]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.97s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.031 | Acc: 62.997% | Wgt Acc: 61.413% | Dur: 11.38s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 14. 11. 33.]
 [ 2. 36.  7.  2.]
 [ 5. 26. 51.  7.]
 [ 6.  2.  6. 44.]]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.60s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.000 | Acc: 69.113% | Wgt Acc: 68.342% | Dur: 11.84s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  7.  8. 22.]
 [ 1. 51. 13.  3.]
 [ 4. 19. 49. 10.]
 [ 8.  1.  5. 51.]]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.29s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.974 | Acc: 68.807% | Wgt Acc: 68.818% | Dur: 11.88s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  7.  5. 14.]
 [ 2. 46.  9.  2.]
 [ 2. 15. 44.  3.]
 [16. 10. 17. 67.]]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.05s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.911 | Acc: 66.667% | Wgt Acc: 66.236% | Dur: 11.89s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 12.  8. 22.]
 [ 0. 47.  7.  2.]
 [ 3. 13. 44.  6.]
 [14.  6. 16. 56.]]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.73s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.185 | Acc: 63.303% | Wgt Acc: 61.753% | Dur: 11.95s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 10. 11. 23.]
 [ 1. 27.  5.  1.]
 [ 6. 36. 53.  8.]
 [ 8.  5.  6. 54.]]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.011 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.48s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.142 | Acc: 67.890% | Wgt Acc: 67.731% | Dur: 11.48s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 13. 13. 22.]
 [ 2. 48. 10.  1.]
 [ 2.  9. 38.  2.]
 [ 9.  8. 14. 61.]]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 0.012 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 139.93s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.068 | Acc: 67.890% | Wgt Acc: 66.304% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[78.  9.  4. 17.]
 [ 1. 32.  9.  2.]
 [ 4. 34. 56. 11.]
 [ 5.  3.  6. 56.]]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.45s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.991 | Acc: 64.832% | Wgt Acc: 64.334% | Dur: 12.12s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 13. 10. 31.]
 [ 3. 54. 17.  5.]
 [ 3. 10. 39.  5.]
 [ 8.  1.  9. 45.]]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.31s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.071 | Acc: 64.526% | Wgt Acc: 63.315% | Dur: 12.07s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  8. 10. 22.]
 [ 3. 37.  8.  2.]
 [ 4. 31. 51. 11.]
 [ 9.  2.  6. 51.]]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.41s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 67.584% | Wgt Acc: 66.440% | Dur: 11.63s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  6.  9. 25.]
 [ 4. 47.  9.  8.]
 [ 7. 25. 54.  6.]
 [ 4.  0.  3. 47.]]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 99.938% | Wgt Acc: 99.929%
	I - Batch: 150 | Loss: 0.008 | Acc: 99.958% | Wgt Acc: 99.953%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 141.58s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   1.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 537.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.070 | Acc: 68.807% | Wgt Acc: 67.595% | Dur: 11.81s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 10.  8. 23.]
 [ 1. 41.  7.  3.]
 [ 4. 25. 55.  6.]
 [ 8.  2.  5. 54.]]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.60s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.073 | Acc: 67.890% | Wgt Acc: 67.527% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 15. 10. 20.]
 [ 2. 44. 12.  2.]
 [ 2. 14. 41.  2.]
 [ 9.  5. 12. 62.]]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.56s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.101 | Acc: 65.749% | Wgt Acc: 65.761% | Dur: 11.23s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  5.  5. 12.]
 [ 3. 42.  8.  3.]
 [ 4. 25. 49.  5.]
 [23.  6. 13. 66.]]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.43s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.155 | Acc: 63.914% | Wgt Acc: 62.772% | Dur: 11.67s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  3.  4. 12.]
 [ 3. 40.  8.  5.]
 [13. 33. 61. 21.]
 [12.  2.  2. 48.]]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.54s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.234 | Acc: 63.914% | Wgt Acc: 62.704% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 17. 11. 28.]
 [ 2. 32.  4.  1.]
 [ 3. 24. 46.  2.]
 [ 7.  5. 14. 55.]]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 141.54s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.211 | Acc: 62.691% | Wgt Acc: 62.024% | Dur: 11.89s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 16. 14. 36.]
 [ 4. 53. 19.  7.]
 [ 2.  6. 33.  3.]
 [ 3.  3.  9. 40.]]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.17s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.993 | Acc: 66.361% | Wgt Acc: 66.304% | Dur: 12.21s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  5. 12.]
 [ 2. 42. 13.  5.]
 [ 4. 23. 45.  3.]
 [18.  6. 12. 66.]]

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.66s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.081 | Acc: 65.749% | Wgt Acc: 65.217% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  3.  4. 12.]
 [ 0. 36.  6.  0.]
 [ 9. 32. 56. 10.]
 [20.  7.  9. 64.]]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 144.81s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.076 | Acc: 65.443% | Wgt Acc: 64.674% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[69. 14.  5. 14.]
 [ 1. 31.  7.  3.]
 [ 5. 30. 49.  4.]
 [13.  3. 14. 65.]]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.98s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.920 | Acc: 68.196% | Wgt Acc: 68.003% | Dur: 11.82s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  8.  9. 16.]
 [ 4. 49. 14.  6.]
 [ 6. 14. 45.  4.]
 [ 9.  7.  7. 60.]]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.99s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.080 | Acc: 66.972% | Wgt Acc: 65.693% | Dur: 12.04s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  6.  7. 22.]
 [ 2. 43.  8.  3.]
 [ 8. 28. 58. 13.]
 [ 8.  1.  2. 48.]]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.67s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.982 | Acc: 66.055% | Wgt Acc: 65.761% | Dur: 11.76s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  9.  8. 19.]
 [ 3. 43. 10.  3.]
 [ 4. 17. 43.  3.]
 [12.  9. 14. 61.]]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.29s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.143 | Acc: 64.526% | Wgt Acc: 63.995% | Dur: 12.29s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 16. 13. 26.]
 [ 1. 40.  7.  1.]
 [ 3. 14. 37.  1.]
 [ 8.  8. 18. 58.]]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.65s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.975 | Acc: 68.196% | Wgt Acc: 67.527% | Dur: 12.06s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  5.  5. 22.]
 [ 3. 50. 15.  7.]
 [ 4. 21. 49.  5.]
 [ 9.  2.  6. 52.]]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 145.01s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.028 | Acc: 66.972% | Wgt Acc: 66.576% | Dur: 11.66s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  5. 10. 24.]
 [ 4. 57. 21.  7.]
 [ 5. 15. 41.  8.]
 [ 5.  1.  3. 47.]]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 145.28s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.971 | Acc: 67.584% | Wgt Acc: 67.731% | Dur: 12.04s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  2.  3. 11.]
 [ 6. 54. 14.  7.]
 [ 7. 21. 50.  9.]
 [17.  1.  8. 59.]]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 0.013 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.20s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.009 | Acc: 66.055% | Wgt Acc: 65.285% | Dur: 11.71s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 10.  9. 28.]
 [ 1. 48. 12.  2.]
 [ 5. 19. 44.  7.]
 [ 7.  1. 10. 49.]]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.96s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.146 | Acc: 65.443% | Wgt Acc: 64.198% | Dur: 12.61s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 11. 13. 32.]
 [ 1. 43.  9.  3.]
 [ 4. 21. 47.  5.]
 [ 5.  3.  6. 46.]]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.35s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.988 | Acc: 67.584% | Wgt Acc: 66.916% | Dur: 12.19s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  6. 10. 19.]
 [ 4. 47.  8.  4.]
 [ 4. 23. 53.  9.]
 [13.  2.  4. 54.]]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.56s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.929 | Acc: 66.361% | Wgt Acc: 66.712% | Dur: 12.43s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  8.  5. 13.]
 [ 3. 54. 21.  8.]
 [ 3. 11. 38.  5.]
 [17.  5. 11. 60.]]

I - Epoch: 200
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.90s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.112 | Acc: 65.749% | Wgt Acc: 64.810% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 13.  9. 26.]
 [ 2. 40. 10.  3.]
 [ 3. 23. 45.  3.]
 [ 7.  2. 11. 54.]]

I - Epoch: 201
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.36s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.994 | Acc: 66.972% | Wgt Acc: 66.848% | Dur: 11.43s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  9.  6. 16.]
 [ 3. 43.  8.  0.]
 [ 3. 19. 45.  5.]
 [16.  7. 16. 65.]]

I - Epoch: 202
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.12s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.091 | Acc: 66.667% | Wgt Acc: 65.285% | Dur: 11.75s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  3.  8. 24.]
 [ 4. 49. 11.  6.]
 [ 6. 26. 55. 16.]
 [ 4.  0.  1. 40.]]

I - Epoch: 203
I - Training: 
	I - Batch: 50 | Loss: 0.009 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.53s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.062 | Acc: 66.361% | Wgt Acc: 65.217% | Dur: 11.68s
I - Confusion Matrix: [row->prediction - col->label]
[[80. 12. 10. 34.]
 [ 3. 52. 17.  5.]
 [ 2. 13. 45.  7.]
 [ 3.  1.  3. 40.]]

I - Epoch: 204
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.61s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.938 | Acc: 68.807% | Wgt Acc: 68.682% | Dur: 11.93s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  7. 14.]
 [ 3. 51. 12.  5.]
 [ 5. 16. 48.  7.]
 [14.  6.  8. 60.]]

I - Epoch: 205
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.99s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.128 | Acc: 64.526% | Wgt Acc: 63.519% | Dur: 12.15s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 18. 12. 24.]
 [ 2. 35.  8.  1.]
 [ 4. 22. 46.  5.]
 [ 8.  3.  9. 56.]]

I - Epoch: 206
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.20s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.164 | Acc: 65.749% | Wgt Acc: 64.402% | Dur: 11.69s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 16. 10. 20.]
 [ 1. 31.  7.  1.]
 [ 6. 30. 53.  8.]
 [ 7.  1.  5. 57.]]

I - Epoch: 207
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.64s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.154 | Acc: 62.997% | Wgt Acc: 61.957% | Dur: 11.49s
I - Confusion Matrix: [row->prediction - col->label]
[[79. 19. 16. 37.]
 [ 2. 44. 11.  3.]
 [ 3. 14. 39.  2.]
 [ 4.  1.  9. 44.]]

I - Epoch: 208
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.49s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.113 | Acc: 64.220% | Wgt Acc: 63.111% | Dur: 12.00s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 12. 11. 34.]
 [ 3. 48. 17.  6.]
 [ 2. 15. 43.  5.]
 [ 5.  3.  4. 41.]]

I - Epoch: 209
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.74s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.018 | Acc: 64.526% | Wgt Acc: 63.451% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 16.  9. 27.]
 [ 2. 41. 10.  4.]
 [ 3. 18. 47.  6.]
 [ 9.  3.  9. 49.]]

I - Epoch: 210
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.024 | Acc: 64.832% | Wgt Acc: 64.402% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  9.  9. 16.]
 [ 3. 39.  8.  3.]
 [ 4. 22. 48.  6.]
 [17.  8. 10. 61.]]

I - Epoch: 211
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.97s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.035 | Acc: 67.278% | Wgt Acc: 66.440% | Dur: 11.44s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  7.  8. 20.]
 [ 1. 40. 10.  4.]
 [ 5. 27. 49.  4.]
 [ 9.  4.  8. 58.]]

I - Epoch: 212
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.993 | Acc: 67.278% | Wgt Acc: 67.459% | Dur: 11.88s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  9.  8. 17.]
 [ 3. 53. 15.  5.]
 [ 3. 12. 38.  4.]
 [13.  4. 14. 60.]]

I - Epoch: 213
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.50s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.025 | Acc: 66.972% | Wgt Acc: 66.440% | Dur: 12.01s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 13. 11. 23.]
 [ 2. 44. 10.  1.]
 [ 4. 16. 42.  4.]
 [ 7.  5. 12. 58.]]

I - Epoch: 214
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 99.938% | Wgt Acc: 99.944%
	I - Batch: 150 | Loss: 0.007 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.97s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.973 | Acc: 68.807% | Wgt Acc: 68.750% | Dur: 11.54s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  8.  8. 23.]
 [ 4. 58. 20.  7.]
 [ 2. 11. 38.  2.]
 [ 7.  1.  9. 54.]]

I - Epoch: 215
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.93s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.104 | Acc: 64.220% | Wgt Acc: 64.810% | Dur: 11.83s
I - Confusion Matrix: [row->prediction - col->label]
[[57.  5.  3.  9.]
 [ 2. 45. 17.  1.]
 [ 5. 20. 39.  7.]
 [24.  8. 16. 69.]]

I - Epoch: 216
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.89s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.979 | Acc: 66.361% | Wgt Acc: 66.372% | Dur: 11.85s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  8.  9. 16.]
 [ 3. 51. 16.  7.]
 [ 5. 15. 40.  5.]
 [12.  4. 10. 58.]]

I - Epoch: 217
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.33s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.925 | Acc: 68.807% | Wgt Acc: 68.614% | Dur: 12.09s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  5. 17.]
 [ 2. 53. 16.  4.]
 [ 6. 16. 46.  8.]
 [11.  4.  8. 57.]]

I - Epoch: 218
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.67s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.998 | Acc: 67.584% | Wgt Acc: 67.255% | Dur: 12.16s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  9.  5. 19.]
 [ 2. 45.  9.  2.]
 [ 3. 21. 46.  4.]
 [14.  3. 15. 61.]]

I - Epoch: 219
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.64s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.032 | Acc: 67.890% | Wgt Acc: 67.663% | Dur: 11.96s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 11. 10. 21.]
 [ 3. 48. 13.  2.]
 [ 2. 13. 39.  3.]
 [ 8.  6. 13. 60.]]

I - Epoch: 220
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.88s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.062 | Acc: 68.807% | Wgt Acc: 67.323% | Dur: 12.04s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  9.  4. 18.]
 [ 2. 36.  5.  4.]
 [ 5. 32. 63.  9.]
 [10.  1.  3. 55.]]

I - Epoch: 221
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.78s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.091 | Acc: 65.443% | Wgt Acc: 64.130% | Dur: 11.93s
I - Confusion Matrix: [row->prediction - col->label]
[[80. 19. 13. 32.]
 [ 0. 41.  9.  1.]
 [ 4. 17. 46.  6.]
 [ 4.  1.  7. 47.]]

I - Epoch: 222
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.44s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.059 | Acc: 65.443% | Wgt Acc: 64.470% | Dur: 11.81s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 11.  9. 27.]
 [ 4. 50. 15.  6.]
 [ 5. 15. 47. 10.]
 [ 5.  2.  4. 43.]]

I - Epoch: 223
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.78s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.216 | Acc: 62.997% | Wgt Acc: 61.549% | Dur: 11.96s
I - Confusion Matrix: [row->prediction - col->label]
[[82. 16. 13. 40.]
 [ 1. 41. 14.  3.]
 [ 4. 17. 42.  2.]
 [ 1.  4.  6. 41.]]

I - Epoch: 224
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.82s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.025 | Acc: 67.890% | Wgt Acc: 66.304% | Dur: 11.91s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  6.  5. 19.]
 [ 1. 41. 11.  5.]
 [ 6. 31. 57. 15.]
 [ 4.  0.  2. 47.]]

I - Epoch: 225
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.37s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.055 | Acc: 66.667% | Wgt Acc: 66.372% | Dur: 11.82s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 10. 10. 25.]
 [ 3. 54. 21.  6.]
 [ 2. 13. 36.  4.]
 [ 6.  1.  8. 51.]]

I - Epoch: 226
I - Training: 
	I - Batch: 50 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.91s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.942 | Acc: 68.502% | Wgt Acc: 68.682% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  6.  5. 16.]
 [ 3. 57. 15.  6.]
 [ 3. 13. 46.  6.]
 [19.  2.  9. 58.]]

I - Epoch: 227
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 135.16s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.087 | Acc: 66.055% | Wgt Acc: 64.878% | Dur: 10.36s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 16. 10. 30.]
 [ 1. 45. 11.  4.]
 [ 4. 16. 47.  6.]
 [ 5.  1.  7. 46.]]

I - Epoch: 228
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 129.54s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.043 | Acc: 65.138% | Wgt Acc: 63.859% | Dur: 10.29s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 13.  9. 28.]
 [ 1. 38.  7.  2.]
 [ 4. 25. 54.  6.]
 [12.  2.  5. 50.]]

I - Epoch: 229
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 129.97s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.928 | Acc: 65.138% | Wgt Acc: 65.217% | Dur: 10.10s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  9.  7. 19.]
 [ 3. 53. 20.  4.]
 [ 2. 13. 37.  8.]
 [15.  3. 11. 55.]]

I - Epoch: 230
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 127.64s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.061 | Acc: 66.055% | Wgt Acc: 67.188% | Dur: 10.16s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  7.  6. 11.]
 [ 4. 54. 16.  3.]
 [ 4.  8. 33.  1.]
 [22.  9. 20. 71.]]

I - Epoch: 231
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 128.12s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.983 | Acc: 67.584% | Wgt Acc: 67.935% | Dur: 10.15s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  8.  7. 18.]
 [ 3. 53. 17.  3.]
 [ 3. 12. 35.  2.]
 [12.  5. 16. 63.]]

I - Epoch: 232
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 128.18s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.242 | Acc: 61.468% | Wgt Acc: 59.511% | Dur: 10.20s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  3.  6. 21.]
 [ 5. 42.  9.  6.]
 [11. 32. 59. 29.]
 [ 2.  1.  1. 30.]]

I - Epoch: 233
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 128.15s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.977 | Acc: 67.890% | Wgt Acc: 67.527% | Dur: 10.19s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  6.  5. 17.]
 [ 1. 43.  8.  1.]
 [ 5. 19. 50.  5.]
 [16. 10. 12. 63.]]

I - Epoch: 234
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 127.85s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.967 | Acc: 68.502% | Wgt Acc: 67.595% | Dur: 10.10s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  6.  7. 19.]
 [ 4. 48. 13.  6.]
 [ 3. 22. 51. 10.]
 [ 7.  2.  4. 51.]]

I - Epoch: 235
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 127.57s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.262 | Acc: 62.080% | Wgt Acc: 61.821% | Dur: 10.14s
I - Confusion Matrix: [row->prediction - col->label]
[[70. 15. 13. 24.]
 [ 0. 37.  7.  0.]
 [ 4. 15. 35.  1.]
 [14. 11. 20. 61.]]

I - Epoch: 236
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 127.45s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.986 | Acc: 66.055% | Wgt Acc: 65.829% | Dur: 11.72s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  7.  4. 19.]
 [ 2. 52. 15.  4.]
 [ 7. 18. 48. 10.]
 [16.  1.  8. 53.]]

I - Epoch: 237
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.18s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.024 | Acc: 65.749% | Wgt Acc: 65.285% | Dur: 11.49s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 12. 10. 28.]
 [ 4. 52. 21.  4.]
 [ 2. 10. 37.  5.]
 [ 5.  4.  7. 49.]]

I - Epoch: 238
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.26s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.055 | Acc: 67.278% | Wgt Acc: 66.848% | Dur: 11.79s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  4. 13.]
 [ 2. 38.  8.  2.]
 [ 4. 28. 52.  5.]
 [18.  5. 11. 66.]]

I - Epoch: 239
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 139.97s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.083 | Acc: 63.914% | Wgt Acc: 62.704% | Dur: 11.81s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 15. 12. 31.]
 [ 2. 39. 11.  2.]
 [ 3. 21. 46.  5.]
 [ 7.  3.  6. 48.]]

I - Epoch: 240
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.42s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.153 | Acc: 67.278% | Wgt Acc: 65.761% | Dur: 11.61s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 13.  6. 18.]
 [ 1. 26.  6.  1.]
 [ 6. 36. 57.  5.]
 [ 6.  3.  6. 62.]]

I - Epoch: 241
I - Training: 
	I - Batch: 50 | Loss: 0.010 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.008 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.81s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.346 | Acc: 61.468% | Wgt Acc: 60.938% | Dur: 11.74s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 20. 16. 25.]
 [ 2. 34.  6.  1.]
 [ 2. 13. 33.  1.]
 [ 9. 11. 20. 59.]]

I - Epoch: 242
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 99.958% | Wgt Acc: 99.962%
I - num batch: 160
I - Train -- Loss: 0.007 | Acc: 99.961% | Wgt Acc: 99.965% | LR: 1.250000e-05 | Dur: 140.75s
I - Confusion Matrix: [row->prediction - col->label]
[[696.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  1.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.175 | Acc: 65.138% | Wgt Acc: 64.198% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[77. 18. 12. 30.]
 [ 2. 41.  8.  1.]
 [ 3. 15. 43.  3.]
 [ 6.  4. 12. 52.]]

I - Epoch: 243
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 140.58s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.084 | Acc: 62.997% | Wgt Acc: 62.500% | Dur: 11.94s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 15. 13. 31.]
 [ 2. 45. 16.  3.]
 [ 3. 14. 34.  1.]
 [ 7.  4. 12. 51.]]

I - Epoch: 244
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 141.96s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.062 | Acc: 64.832% | Wgt Acc: 65.082% | Dur: 11.62s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  9.  8. 14.]
 [ 2. 43.  8.  1.]
 [ 5. 16. 40.  4.]
 [19. 10. 19. 67.]]

I - Epoch: 245
I - Training: 
	I - Batch: 50 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.005 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.03s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.051 | Acc: 64.220% | Wgt Acc: 63.111% | Dur: 11.98s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 12.  7. 28.]
 [ 0. 37.  9.  2.]
 [ 4. 23. 50.  4.]
 [13.  6.  9. 52.]]

I - Epoch: 246
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.16s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.264 | Acc: 59.327% | Wgt Acc: 58.628% | Dur: 11.71s
I - Confusion Matrix: [row->prediction - col->label]
[[82. 16. 18. 43.]
 [ 2. 49. 25.  5.]
 [ 2.  9. 25.  0.]
 [ 2.  4.  7. 38.]]

I - Epoch: 247
I - Training: 
	I - Batch: 50 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.006 | Acc: 100.000% | Wgt Acc: 100.000% | LR: 1.250000e-05 | Dur: 142.40s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.118 | Acc: 65.443% | Wgt Acc: 64.402% | Dur: 11.87s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 14.  9. 23.]
 [ 0. 35.  4.  2.]
 [ 3. 25. 46.  4.]
 [ 9.  4. 16. 57.]]

I - Epoch: 248
I - Training: 
	I - Batch: 50 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 100 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
	I - Batch: 150 | Loss: 0.007 | Acc: 100.000% | Wgt Acc: 100.000%
I - num batch: 160
I - Train -- Loss: 0.011 | Acc: 99.961% | Wgt Acc: 99.956% | LR: 1.250000e-05 | Dur: 142.16s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 577.   0.   0.]
 [  0.   0. 734.   0.]
 [  0.   1.   0. 538.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.095 | Acc: 65.443% | Wgt Acc: 65.285% | Dur: 11.64s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  7.  5. 19.]
 [ 2. 42. 13.  1.]
 [ 5. 21. 42.  3.]
 [14.  8. 15. 63.]]

I - Epoch: 249
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.625% | Wgt Acc: 99.578%
	I - Batch: 100 | Loss: 0.022 | Acc: 99.750% | Wgt Acc: 99.719%
	I - Batch: 150 | Loss: 0.017 | Acc: 99.833% | Wgt Acc: 99.812%
I - num batch: 160
I - Train -- Loss: 0.017 | Acc: 99.843% | Wgt Acc: 99.823% | LR: 1.250000e-05 | Dur: 141.11s
I - Confusion Matrix: [row->prediction - col->label]
[[697.   0.   0.   0.]
 [  0. 578.   0.   4.]
 [  0.   0. 734.   0.]
 [  0.   0.   0. 534.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.960 | Acc: 69.725% | Wgt Acc: 69.905% | Dur: 11.55s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  3.  4.  8.]
 [ 3. 48. 12.  3.]
 [ 7. 21. 48.  6.]
 [15.  6. 11. 69.]]

I - Maximum validation set accuracy in current training:  70.64
