Mon Oct 31 20:22:55 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'blacklistFile': './blacklists/blacklist100.yaml', 'classWeights': [0.2, 0.25, 0.2, 0.25, 0.1], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': 'new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'lastLayerInitUniform': False, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 71.20315581854044, 'maxValidationTrainNo': 64, 'modelVersion': 20, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 71, 'validationAccThr': 75, 'warmStartConfig': {'checkpointFile': './sav/model17_trainNo60_at_epoch_197_with_acc_71_60_checkpoint.pth.tar', 'checkpointModelNo': 17, 'freezeSpatialCNN': False, 'warmStartFlag': False}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Train set length:  3547
I - Label distribution: [ 697.  578.  734.  538. 1000.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Loading file: dataset_test_background00_no_samples180.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test/new_background
I - New label distribution: [ 88.  78.  75.  86. 180.]

I - Test set length:  507
I - Label distribution: [ 88.  78.  75.  86. 180.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([172166,    928,    124, 177681,   1074, 191464,  32373,  42522, 146718,
        199361, 197185,  92979, 186480,   5048,    284,    418])
I - Initializing model TCNv20
I - Number of Model Parameters: 930060
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv20                                   [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         6,278
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [128, 48, 1, 1]           --
│    └─Empty: 2-5                        [128, 48, 1, 1]           --
│    └─Empty: 2-6                        [128]                     --
│    └─Empty: 2-7                        [128]                     --
│    └─BatchNorm2d: 2-8                  [16, 128, 64, 64]         --
│    └─Scaler: 2-9                       [16, 128, 64, 64]         --
│    └─ReLU: 2-10                        [16, 128, 64, 64]         --
│    └─Empty: 2-11                       [16, 128, 64, 64]         --
│    └─Clamp: 2-12                       [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-2                 [16, 128, 64, 64]         147,590
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [128, 128, 3, 3]          --
│    └─Empty: 2-17                       [128, 128, 3, 3]          --
│    └─Empty: 2-18                       [128]                     --
│    └─Empty: 2-19                       [128]                     --
│    └─BatchNorm2d: 2-20                 [16, 128, 64, 64]         256
│    └─Scaler: 2-21                      [16, 128, 64, 64]         --
│    └─ReLU: 2-22                        [16, 128, 64, 64]         --
│    └─Empty: 2-23                       [16, 128, 64, 64]         --
│    └─Clamp: 2-24                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-3          [16, 128, 32, 32]         147,590
│    └─MaxPool2d: 2-25                   [16, 128, 32, 32]         --
│    └─Empty: 2-26                       [16, 128, 32, 32]         --
│    └─Empty: 2-27                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-28          --                        --
│    └─One: 2-29                         [1]                       --
│    └─OutputScale: 2-30                 --                        --
│    └─Empty: 2-31                       [128, 128, 3, 3]          --
│    └─Empty: 2-32                       [128, 128, 3, 3]          --
│    └─Empty: 2-33                       [128]                     --
│    └─Empty: 2-34                       [128]                     --
│    └─BatchNorm2d: 2-35                 [16, 128, 32, 32]         256
│    └─Scaler: 2-36                      [16, 128, 32, 32]         --
│    └─ReLU: 2-37                        [16, 128, 32, 32]         --
│    └─Empty: 2-38                       [16, 128, 32, 32]         --
│    └─Clamp: 2-39                       [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-4                 [16, 128, 32, 32]         16,518
│    └─OutputShiftSqueeze: 2-40          --                        --
│    └─One: 2-41                         [1]                       --
│    └─OutputScale: 2-42                 --                        --
│    └─Empty: 2-43                       [128, 128, 1, 1]          --
│    └─Empty: 2-44                       [128, 128, 1, 1]          --
│    └─Empty: 2-45                       [128]                     --
│    └─Empty: 2-46                       [128]                     --
│    └─BatchNorm2d: 2-47                 [16, 128, 32, 32]         256
│    └─Scaler: 2-48                      [16, 128, 32, 32]         --
│    └─ReLU: 2-49                        [16, 128, 32, 32]         --
│    └─Empty: 2-50                       [16, 128, 32, 32]         --
│    └─Clamp: 2-51                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 128, 32, 32]         147,590
│    └─MaxPool2d: 2-52                   [16, 128, 32, 32]         --
│    └─Empty: 2-53                       [16, 128, 32, 32]         --
│    └─Empty: 2-54                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-55          --                        --
│    └─One: 2-56                         [1]                       --
│    └─OutputScale: 2-57                 --                        --
│    └─Empty: 2-58                       [128, 128, 3, 3]          --
│    └─Empty: 2-59                       [128, 128, 3, 3]          --
│    └─Empty: 2-60                       [128]                     --
│    └─Empty: 2-61                       [128]                     --
│    └─BatchNorm2d: 2-62                 [16, 128, 32, 32]         256
│    └─Scaler: 2-63                      [16, 128, 32, 32]         --
│    └─ReLU: 2-64                        [16, 128, 32, 32]         --
│    └─Empty: 2-65                       [16, 128, 32, 32]         --
│    └─Clamp: 2-66                       [16, 128, 32, 32]         --
├─Dropout2d: 1-6                         [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-67                   [16, 128, 16, 16]         --
│    └─Empty: 2-68                       [16, 128, 16, 16]         --
│    └─Empty: 2-69                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-70          --                        --
│    └─One: 2-71                         [1]                       --
│    └─OutputScale: 2-72                 --                        --
│    └─Empty: 2-73                       [128, 128, 3, 3]          --
│    └─Empty: 2-74                       [128, 128, 3, 3]          --
│    └─Empty: 2-75                       [128]                     --
│    └─Empty: 2-76                       [128]                     --
│    └─BatchNorm2d: 2-77                 [16, 128, 16, 16]         256
│    └─Scaler: 2-78                      [16, 128, 16, 16]         --
│    └─ReLU: 2-79                        [16, 128, 16, 16]         --
│    └─Empty: 2-80                       [16, 128, 16, 16]         --
│    └─Clamp: 2-81                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-8                 [16, 128, 16, 16]         16,518
│    └─OutputShiftSqueeze: 2-82          --                        --
│    └─One: 2-83                         [1]                       --
│    └─OutputScale: 2-84                 --                        --
│    └─Empty: 2-85                       [128, 128, 1, 1]          --
│    └─Empty: 2-86                       [128, 128, 1, 1]          --
│    └─Empty: 2-87                       [128]                     --
│    └─Empty: 2-88                       [128]                     --
│    └─BatchNorm2d: 2-89                 [16, 128, 16, 16]         256
│    └─Scaler: 2-90                      [16, 128, 16, 16]         --
│    └─ReLU: 2-91                        [16, 128, 16, 16]         --
│    └─Empty: 2-92                       [16, 128, 16, 16]         --
│    └─Clamp: 2-93                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 128, 16, 16]         147,590
│    └─MaxPool2d: 2-94                   [16, 128, 16, 16]         --
│    └─Empty: 2-95                       [16, 128, 16, 16]         --
│    └─Empty: 2-96                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-97          --                        --
│    └─One: 2-98                         [1]                       --
│    └─OutputScale: 2-99                 --                        --
│    └─Empty: 2-100                      [128, 128, 3, 3]          --
│    └─Empty: 2-101                      [128, 128, 3, 3]          --
│    └─Empty: 2-102                      [128]                     --
│    └─Empty: 2-103                      [128]                     --
│    └─BatchNorm2d: 2-104                [16, 128, 16, 16]         256
│    └─Scaler: 2-105                     [16, 128, 16, 16]         --
│    └─ReLU: 2-106                       [16, 128, 16, 16]         --
│    └─Empty: 2-107                      [16, 128, 16, 16]         --
│    └─Clamp: 2-108                      [16, 128, 16, 16]         --
├─Dropout2d: 1-10                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-109                  [16, 128, 8, 8]           --
│    └─Empty: 2-110                      [16, 128, 8, 8]           --
│    └─Empty: 2-111                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-112         --                        --
│    └─One: 2-113                        [1]                       --
│    └─OutputScale: 2-114                --                        --
│    └─Empty: 2-115                      [128, 128, 3, 3]          --
│    └─Empty: 2-116                      [128, 128, 3, 3]          --
│    └─Empty: 2-117                      [128]                     --
│    └─Empty: 2-118                      [128]                     --
│    └─BatchNorm2d: 2-119                [16, 128, 8, 8]           256
│    └─Scaler: 2-120                     [16, 128, 8, 8]           --
│    └─ReLU: 2-121                       [16, 128, 8, 8]           --
│    └─Empty: 2-122                      [16, 128, 8, 8]           --
│    └─Clamp: 2-123                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-12                [16, 2, 8, 8]             264
│    └─OutputShiftSqueeze: 2-124         --                        --
│    └─One: 2-125                        [1]                       --
│    └─OutputScale: 2-126                --                        --
│    └─Empty: 2-127                      [2, 128, 1, 1]            --
│    └─Empty: 2-128                      [2, 128, 1, 1]            --
│    └─Empty: 2-129                      [2]                       --
│    └─Empty: 2-130                      [2]                       --
│    └─BatchNorm2d: 2-131                [16, 2, 8, 8]             4
│    └─Scaler: 2-132                     [16, 2, 8, 8]             --
│    └─ReLU: 2-133                       [16, 2, 8, 8]             --
│    └─Empty: 2-134                      [16, 2, 8, 8]             --
│    └─Clamp: 2-135                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 2, 8, 8]             2,312
│    └─MaxPool2d: 2-136                  [16, 128, 8, 8]           --
│    └─Empty: 2-137                      [16, 128, 8, 8]           --
│    └─Empty: 2-138                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-139         --                        --
│    └─One: 2-140                        [1]                       --
│    └─OutputScale: 2-141                --                        --
│    └─Empty: 2-142                      [2, 128, 3, 3]            --
│    └─Empty: 2-143                      [2, 128, 3, 3]            --
│    └─Empty: 2-144                      [2]                       --
│    └─Empty: 2-145                      [2]                       --
│    └─BatchNorm2d: 2-146                [16, 2, 8, 8]             4
│    └─Scaler: 2-147                     [16, 2, 8, 8]             --
│    └─ReLU: 2-148                       [16, 2, 8, 8]             --
│    └─Empty: 2-149                      [16, 2, 8, 8]             --
│    └─Clamp: 2-150                      [16, 2, 8, 8]             --
├─Dropout2d: 1-14                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-15                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-151         --                        --
│    └─One: 2-152                        [1]                       --
│    └─OutputScale: 2-153                --                        --
│    └─Empty: 2-154                      [128, 48, 1, 1]           --
│    └─Empty: 2-155                      [128, 48, 1, 1]           --
│    └─Empty: 2-156                      [128]                     --
│    └─Empty: 2-157                      [128]                     --
│    └─BatchNorm2d: 2-158                [16, 128, 64, 64]         --
│    └─Scaler: 2-159                     [16, 128, 64, 64]         --
│    └─ReLU: 2-160                       [16, 128, 64, 64]         --
│    └─Empty: 2-161                      [16, 128, 64, 64]         --
│    └─Clamp: 2-162                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-16                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-163         --                        --
│    └─One: 2-164                        [1]                       --
│    └─OutputScale: 2-165                --                        --
│    └─Empty: 2-166                      [128, 128, 3, 3]          --
│    └─Empty: 2-167                      [128, 128, 3, 3]          --
│    └─Empty: 2-168                      [128]                     --
│    └─Empty: 2-169                      [128]                     --
│    └─BatchNorm2d: 2-170                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-171                     [16, 128, 64, 64]         --
│    └─ReLU: 2-172                       [16, 128, 64, 64]         --
│    └─Empty: 2-173                      [16, 128, 64, 64]         --
│    └─Clamp: 2-174                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-175                  [16, 128, 32, 32]         --
│    └─Empty: 2-176                      [16, 128, 32, 32]         --
│    └─Empty: 2-177                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-178         --                        --
│    └─One: 2-179                        [1]                       --
│    └─OutputScale: 2-180                --                        --
│    └─Empty: 2-181                      [128, 128, 3, 3]          --
│    └─Empty: 2-182                      [128, 128, 3, 3]          --
│    └─Empty: 2-183                      [128]                     --
│    └─Empty: 2-184                      [128]                     --
│    └─BatchNorm2d: 2-185                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-186                     [16, 128, 32, 32]         --
│    └─ReLU: 2-187                       [16, 128, 32, 32]         --
│    └─Empty: 2-188                      [16, 128, 32, 32]         --
│    └─Clamp: 2-189                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-18                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-190         --                        --
│    └─One: 2-191                        [1]                       --
│    └─OutputScale: 2-192                --                        --
│    └─Empty: 2-193                      [128, 128, 1, 1]          --
│    └─Empty: 2-194                      [128, 128, 1, 1]          --
│    └─Empty: 2-195                      [128]                     --
│    └─Empty: 2-196                      [128]                     --
│    └─BatchNorm2d: 2-197                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-198                     [16, 128, 32, 32]         --
│    └─ReLU: 2-199                       [16, 128, 32, 32]         --
│    └─Empty: 2-200                      [16, 128, 32, 32]         --
│    └─Clamp: 2-201                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-19         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-202                  [16, 128, 32, 32]         --
│    └─Empty: 2-203                      [16, 128, 32, 32]         --
│    └─Empty: 2-204                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-205         --                        --
│    └─One: 2-206                        [1]                       --
│    └─OutputScale: 2-207                --                        --
│    └─Empty: 2-208                      [128, 128, 3, 3]          --
│    └─Empty: 2-209                      [128, 128, 3, 3]          --
│    └─Empty: 2-210                      [128]                     --
│    └─Empty: 2-211                      [128]                     --
│    └─BatchNorm2d: 2-212                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-213                     [16, 128, 32, 32]         --
│    └─ReLU: 2-214                       [16, 128, 32, 32]         --
│    └─Empty: 2-215                      [16, 128, 32, 32]         --
│    └─Clamp: 2-216                      [16, 128, 32, 32]         --
├─Dropout2d: 1-20                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-21         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-217                  [16, 128, 16, 16]         --
│    └─Empty: 2-218                      [16, 128, 16, 16]         --
│    └─Empty: 2-219                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-220         --                        --
│    └─One: 2-221                        [1]                       --
│    └─OutputScale: 2-222                --                        --
│    └─Empty: 2-223                      [128, 128, 3, 3]          --
│    └─Empty: 2-224                      [128, 128, 3, 3]          --
│    └─Empty: 2-225                      [128]                     --
│    └─Empty: 2-226                      [128]                     --
│    └─BatchNorm2d: 2-227                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-228                     [16, 128, 16, 16]         --
│    └─ReLU: 2-229                       [16, 128, 16, 16]         --
│    └─Empty: 2-230                      [16, 128, 16, 16]         --
│    └─Clamp: 2-231                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-22                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-232         --                        --
│    └─One: 2-233                        [1]                       --
│    └─OutputScale: 2-234                --                        --
│    └─Empty: 2-235                      [128, 128, 1, 1]          --
│    └─Empty: 2-236                      [128, 128, 1, 1]          --
│    └─Empty: 2-237                      [128]                     --
│    └─Empty: 2-238                      [128]                     --
│    └─BatchNorm2d: 2-239                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-240                     [16, 128, 16, 16]         --
│    └─ReLU: 2-241                       [16, 128, 16, 16]         --
│    └─Empty: 2-242                      [16, 128, 16, 16]         --
│    └─Clamp: 2-243                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-244                  [16, 128, 16, 16]         --
│    └─Empty: 2-245                      [16, 128, 16, 16]         --
│    └─Empty: 2-246                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-247         --                        --
│    └─One: 2-248                        [1]                       --
│    └─OutputScale: 2-249                --                        --
│    └─Empty: 2-250                      [128, 128, 3, 3]          --
│    └─Empty: 2-251                      [128, 128, 3, 3]          --
│    └─Empty: 2-252                      [128]                     --
│    └─Empty: 2-253                      [128]                     --
│    └─BatchNorm2d: 2-254                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-255                     [16, 128, 16, 16]         --
│    └─ReLU: 2-256                       [16, 128, 16, 16]         --
│    └─Empty: 2-257                      [16, 128, 16, 16]         --
│    └─Clamp: 2-258                      [16, 128, 16, 16]         --
├─Dropout2d: 1-24                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-259                  [16, 128, 8, 8]           --
│    └─Empty: 2-260                      [16, 128, 8, 8]           --
│    └─Empty: 2-261                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-262         --                        --
│    └─One: 2-263                        [1]                       --
│    └─OutputScale: 2-264                --                        --
│    └─Empty: 2-265                      [128, 128, 3, 3]          --
│    └─Empty: 2-266                      [128, 128, 3, 3]          --
│    └─Empty: 2-267                      [128]                     --
│    └─Empty: 2-268                      [128]                     --
│    └─BatchNorm2d: 2-269                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-270                     [16, 128, 8, 8]           --
│    └─ReLU: 2-271                       [16, 128, 8, 8]           --
│    └─Empty: 2-272                      [16, 128, 8, 8]           --
│    └─Clamp: 2-273                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-26                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-274         --                        --
│    └─One: 2-275                        [1]                       --
│    └─OutputScale: 2-276                --                        --
│    └─Empty: 2-277                      [2, 128, 1, 1]            --
│    └─Empty: 2-278                      [2, 128, 1, 1]            --
│    └─Empty: 2-279                      [2]                       --
│    └─Empty: 2-280                      [2]                       --
│    └─BatchNorm2d: 2-281                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-282                     [16, 2, 8, 8]             --
│    └─ReLU: 2-283                       [16, 2, 8, 8]             --
│    └─Empty: 2-284                      [16, 2, 8, 8]             --
│    └─Clamp: 2-285                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-27         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-286                  [16, 128, 8, 8]           --
│    └─Empty: 2-287                      [16, 128, 8, 8]           --
│    └─Empty: 2-288                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-289         --                        --
│    └─One: 2-290                        [1]                       --
│    └─OutputScale: 2-291                --                        --
│    └─Empty: 2-292                      [2, 128, 3, 3]            --
│    └─Empty: 2-293                      [2, 128, 3, 3]            --
│    └─Empty: 2-294                      [2]                       --
│    └─Empty: 2-295                      [2]                       --
│    └─BatchNorm2d: 2-296                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-297                     [16, 2, 8, 8]             --
│    └─ReLU: 2-298                       [16, 2, 8, 8]             --
│    └─Empty: 2-299                      [16, 2, 8, 8]             --
│    └─Clamp: 2-300                      [16, 2, 8, 8]             --
├─Dropout2d: 1-28                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-29                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-301         --                        --
│    └─One: 2-302                        [1]                       --
│    └─OutputScale: 2-303                --                        --
│    └─Empty: 2-304                      [128, 48, 1, 1]           --
│    └─Empty: 2-305                      [128, 48, 1, 1]           --
│    └─Empty: 2-306                      [128]                     --
│    └─Empty: 2-307                      [128]                     --
│    └─BatchNorm2d: 2-308                [16, 128, 64, 64]         --
│    └─Scaler: 2-309                     [16, 128, 64, 64]         --
│    └─ReLU: 2-310                       [16, 128, 64, 64]         --
│    └─Empty: 2-311                      [16, 128, 64, 64]         --
│    └─Clamp: 2-312                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-30                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-313         --                        --
│    └─One: 2-314                        [1]                       --
│    └─OutputScale: 2-315                --                        --
│    └─Empty: 2-316                      [128, 128, 3, 3]          --
│    └─Empty: 2-317                      [128, 128, 3, 3]          --
│    └─Empty: 2-318                      [128]                     --
│    └─Empty: 2-319                      [128]                     --
│    └─BatchNorm2d: 2-320                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-321                     [16, 128, 64, 64]         --
│    └─ReLU: 2-322                       [16, 128, 64, 64]         --
│    └─Empty: 2-323                      [16, 128, 64, 64]         --
│    └─Clamp: 2-324                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-325                  [16, 128, 32, 32]         --
│    └─Empty: 2-326                      [16, 128, 32, 32]         --
│    └─Empty: 2-327                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-328         --                        --
│    └─One: 2-329                        [1]                       --
│    └─OutputScale: 2-330                --                        --
│    └─Empty: 2-331                      [128, 128, 3, 3]          --
│    └─Empty: 2-332                      [128, 128, 3, 3]          --
│    └─Empty: 2-333                      [128]                     --
│    └─Empty: 2-334                      [128]                     --
│    └─BatchNorm2d: 2-335                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-336                     [16, 128, 32, 32]         --
│    └─ReLU: 2-337                       [16, 128, 32, 32]         --
│    └─Empty: 2-338                      [16, 128, 32, 32]         --
│    └─Clamp: 2-339                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-32                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-340         --                        --
│    └─One: 2-341                        [1]                       --
│    └─OutputScale: 2-342                --                        --
│    └─Empty: 2-343                      [128, 128, 1, 1]          --
│    └─Empty: 2-344                      [128, 128, 1, 1]          --
│    └─Empty: 2-345                      [128]                     --
│    └─Empty: 2-346                      [128]                     --
│    └─BatchNorm2d: 2-347                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-348                     [16, 128, 32, 32]         --
│    └─ReLU: 2-349                       [16, 128, 32, 32]         --
│    └─Empty: 2-350                      [16, 128, 32, 32]         --
│    └─Clamp: 2-351                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-352                  [16, 128, 32, 32]         --
│    └─Empty: 2-353                      [16, 128, 32, 32]         --
│    └─Empty: 2-354                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-355         --                        --
│    └─One: 2-356                        [1]                       --
│    └─OutputScale: 2-357                --                        --
│    └─Empty: 2-358                      [128, 128, 3, 3]          --
│    └─Empty: 2-359                      [128, 128, 3, 3]          --
│    └─Empty: 2-360                      [128]                     --
│    └─Empty: 2-361                      [128]                     --
│    └─BatchNorm2d: 2-362                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-363                     [16, 128, 32, 32]         --
│    └─ReLU: 2-364                       [16, 128, 32, 32]         --
│    └─Empty: 2-365                      [16, 128, 32, 32]         --
│    └─Clamp: 2-366                      [16, 128, 32, 32]         --
├─Dropout2d: 1-34                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-35         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-367                  [16, 128, 16, 16]         --
│    └─Empty: 2-368                      [16, 128, 16, 16]         --
│    └─Empty: 2-369                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-370         --                        --
│    └─One: 2-371                        [1]                       --
│    └─OutputScale: 2-372                --                        --
│    └─Empty: 2-373                      [128, 128, 3, 3]          --
│    └─Empty: 2-374                      [128, 128, 3, 3]          --
│    └─Empty: 2-375                      [128]                     --
│    └─Empty: 2-376                      [128]                     --
│    └─BatchNorm2d: 2-377                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-378                     [16, 128, 16, 16]         --
│    └─ReLU: 2-379                       [16, 128, 16, 16]         --
│    └─Empty: 2-380                      [16, 128, 16, 16]         --
│    └─Clamp: 2-381                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-36                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-382         --                        --
│    └─One: 2-383                        [1]                       --
│    └─OutputScale: 2-384                --                        --
│    └─Empty: 2-385                      [128, 128, 1, 1]          --
│    └─Empty: 2-386                      [128, 128, 1, 1]          --
│    └─Empty: 2-387                      [128]                     --
│    └─Empty: 2-388                      [128]                     --
│    └─BatchNorm2d: 2-389                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-390                     [16, 128, 16, 16]         --
│    └─ReLU: 2-391                       [16, 128, 16, 16]         --
│    └─Empty: 2-392                      [16, 128, 16, 16]         --
│    └─Clamp: 2-393                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-37         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-394                  [16, 128, 16, 16]         --
│    └─Empty: 2-395                      [16, 128, 16, 16]         --
│    └─Empty: 2-396                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-397         --                        --
│    └─One: 2-398                        [1]                       --
│    └─OutputScale: 2-399                --                        --
│    └─Empty: 2-400                      [128, 128, 3, 3]          --
│    └─Empty: 2-401                      [128, 128, 3, 3]          --
│    └─Empty: 2-402                      [128]                     --
│    └─Empty: 2-403                      [128]                     --
│    └─BatchNorm2d: 2-404                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-405                     [16, 128, 16, 16]         --
│    └─ReLU: 2-406                       [16, 128, 16, 16]         --
│    └─Empty: 2-407                      [16, 128, 16, 16]         --
│    └─Clamp: 2-408                      [16, 128, 16, 16]         --
├─Dropout2d: 1-38                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-409                  [16, 128, 8, 8]           --
│    └─Empty: 2-410                      [16, 128, 8, 8]           --
│    └─Empty: 2-411                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-412         --                        --
│    └─One: 2-413                        [1]                       --
│    └─OutputScale: 2-414                --                        --
│    └─Empty: 2-415                      [128, 128, 3, 3]          --
│    └─Empty: 2-416                      [128, 128, 3, 3]          --
│    └─Empty: 2-417                      [128]                     --
│    └─Empty: 2-418                      [128]                     --
│    └─BatchNorm2d: 2-419                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-420                     [16, 128, 8, 8]           --
│    └─ReLU: 2-421                       [16, 128, 8, 8]           --
│    └─Empty: 2-422                      [16, 128, 8, 8]           --
│    └─Clamp: 2-423                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-40                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-424         --                        --
│    └─One: 2-425                        [1]                       --
│    └─OutputScale: 2-426                --                        --
│    └─Empty: 2-427                      [2, 128, 1, 1]            --
│    └─Empty: 2-428                      [2, 128, 1, 1]            --
│    └─Empty: 2-429                      [2]                       --
│    └─Empty: 2-430                      [2]                       --
│    └─BatchNorm2d: 2-431                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-432                     [16, 2, 8, 8]             --
│    └─ReLU: 2-433                       [16, 2, 8, 8]             --
│    └─Empty: 2-434                      [16, 2, 8, 8]             --
│    └─Clamp: 2-435                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-436                  [16, 128, 8, 8]           --
│    └─Empty: 2-437                      [16, 128, 8, 8]           --
│    └─Empty: 2-438                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-439         --                        --
│    └─One: 2-440                        [1]                       --
│    └─OutputScale: 2-441                --                        --
│    └─Empty: 2-442                      [2, 128, 3, 3]            --
│    └─Empty: 2-443                      [2, 128, 3, 3]            --
│    └─Empty: 2-444                      [2]                       --
│    └─Empty: 2-445                      [2]                       --
│    └─BatchNorm2d: 2-446                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-447                     [16, 2, 8, 8]             --
│    └─ReLU: 2-448                       [16, 2, 8, 8]             --
│    └─Empty: 2-449                      [16, 2, 8, 8]             --
│    └─Clamp: 2-450                      [16, 2, 8, 8]             --
├─Dropout2d: 1-42                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-43                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-451         --                        --
│    └─One: 2-452                        [1]                       --
│    └─OutputScale: 2-453                --                        --
│    └─Empty: 2-454                      [128, 48, 1, 1]           --
│    └─Empty: 2-455                      [128, 48, 1, 1]           --
│    └─Empty: 2-456                      [128]                     --
│    └─Empty: 2-457                      [128]                     --
│    └─BatchNorm2d: 2-458                [16, 128, 64, 64]         --
│    └─Scaler: 2-459                     [16, 128, 64, 64]         --
│    └─ReLU: 2-460                       [16, 128, 64, 64]         --
│    └─Empty: 2-461                      [16, 128, 64, 64]         --
│    └─Clamp: 2-462                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-44                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-463         --                        --
│    └─One: 2-464                        [1]                       --
│    └─OutputScale: 2-465                --                        --
│    └─Empty: 2-466                      [128, 128, 3, 3]          --
│    └─Empty: 2-467                      [128, 128, 3, 3]          --
│    └─Empty: 2-468                      [128]                     --
│    └─Empty: 2-469                      [128]                     --
│    └─BatchNorm2d: 2-470                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-471                     [16, 128, 64, 64]         --
│    └─ReLU: 2-472                       [16, 128, 64, 64]         --
│    └─Empty: 2-473                      [16, 128, 64, 64]         --
│    └─Clamp: 2-474                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-475                  [16, 128, 32, 32]         --
│    └─Empty: 2-476                      [16, 128, 32, 32]         --
│    └─Empty: 2-477                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-478         --                        --
│    └─One: 2-479                        [1]                       --
│    └─OutputScale: 2-480                --                        --
│    └─Empty: 2-481                      [128, 128, 3, 3]          --
│    └─Empty: 2-482                      [128, 128, 3, 3]          --
│    └─Empty: 2-483                      [128]                     --
│    └─Empty: 2-484                      [128]                     --
│    └─BatchNorm2d: 2-485                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-486                     [16, 128, 32, 32]         --
│    └─ReLU: 2-487                       [16, 128, 32, 32]         --
│    └─Empty: 2-488                      [16, 128, 32, 32]         --
│    └─Clamp: 2-489                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-46                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-490         --                        --
│    └─One: 2-491                        [1]                       --
│    └─OutputScale: 2-492                --                        --
│    └─Empty: 2-493                      [128, 128, 1, 1]          --
│    └─Empty: 2-494                      [128, 128, 1, 1]          --
│    └─Empty: 2-495                      [128]                     --
│    └─Empty: 2-496                      [128]                     --
│    └─BatchNorm2d: 2-497                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-498                     [16, 128, 32, 32]         --
│    └─ReLU: 2-499                       [16, 128, 32, 32]         --
│    └─Empty: 2-500                      [16, 128, 32, 32]         --
│    └─Clamp: 2-501                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-502                  [16, 128, 32, 32]         --
│    └─Empty: 2-503                      [16, 128, 32, 32]         --
│    └─Empty: 2-504                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-505         --                        --
│    └─One: 2-506                        [1]                       --
│    └─OutputScale: 2-507                --                        --
│    └─Empty: 2-508                      [128, 128, 3, 3]          --
│    └─Empty: 2-509                      [128, 128, 3, 3]          --
│    └─Empty: 2-510                      [128]                     --
│    └─Empty: 2-511                      [128]                     --
│    └─BatchNorm2d: 2-512                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-513                     [16, 128, 32, 32]         --
│    └─ReLU: 2-514                       [16, 128, 32, 32]         --
│    └─Empty: 2-515                      [16, 128, 32, 32]         --
│    └─Clamp: 2-516                      [16, 128, 32, 32]         --
├─Dropout2d: 1-48                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-517                  [16, 128, 16, 16]         --
│    └─Empty: 2-518                      [16, 128, 16, 16]         --
│    └─Empty: 2-519                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-520         --                        --
│    └─One: 2-521                        [1]                       --
│    └─OutputScale: 2-522                --                        --
│    └─Empty: 2-523                      [128, 128, 3, 3]          --
│    └─Empty: 2-524                      [128, 128, 3, 3]          --
│    └─Empty: 2-525                      [128]                     --
│    └─Empty: 2-526                      [128]                     --
│    └─BatchNorm2d: 2-527                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-528                     [16, 128, 16, 16]         --
│    └─ReLU: 2-529                       [16, 128, 16, 16]         --
│    └─Empty: 2-530                      [16, 128, 16, 16]         --
│    └─Clamp: 2-531                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-50                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-532         --                        --
│    └─One: 2-533                        [1]                       --
│    └─OutputScale: 2-534                --                        --
│    └─Empty: 2-535                      [128, 128, 1, 1]          --
│    └─Empty: 2-536                      [128, 128, 1, 1]          --
│    └─Empty: 2-537                      [128]                     --
│    └─Empty: 2-538                      [128]                     --
│    └─BatchNorm2d: 2-539                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-540                     [16, 128, 16, 16]         --
│    └─ReLU: 2-541                       [16, 128, 16, 16]         --
│    └─Empty: 2-542                      [16, 128, 16, 16]         --
│    └─Clamp: 2-543                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-544                  [16, 128, 16, 16]         --
│    └─Empty: 2-545                      [16, 128, 16, 16]         --
│    └─Empty: 2-546                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-547         --                        --
│    └─One: 2-548                        [1]                       --
│    └─OutputScale: 2-549                --                        --
│    └─Empty: 2-550                      [128, 128, 3, 3]          --
│    └─Empty: 2-551                      [128, 128, 3, 3]          --
│    └─Empty: 2-552                      [128]                     --
│    └─Empty: 2-553                      [128]                     --
│    └─BatchNorm2d: 2-554                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-555                     [16, 128, 16, 16]         --
│    └─ReLU: 2-556                       [16, 128, 16, 16]         --
│    └─Empty: 2-557                      [16, 128, 16, 16]         --
│    └─Clamp: 2-558                      [16, 128, 16, 16]         --
├─Dropout2d: 1-52                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-53         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-559                  [16, 128, 8, 8]           --
│    └─Empty: 2-560                      [16, 128, 8, 8]           --
│    └─Empty: 2-561                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-562         --                        --
│    └─One: 2-563                        [1]                       --
│    └─OutputScale: 2-564                --                        --
│    └─Empty: 2-565                      [128, 128, 3, 3]          --
│    └─Empty: 2-566                      [128, 128, 3, 3]          --
│    └─Empty: 2-567                      [128]                     --
│    └─Empty: 2-568                      [128]                     --
│    └─BatchNorm2d: 2-569                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-570                     [16, 128, 8, 8]           --
│    └─ReLU: 2-571                       [16, 128, 8, 8]           --
│    └─Empty: 2-572                      [16, 128, 8, 8]           --
│    └─Clamp: 2-573                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-54                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-574         --                        --
│    └─One: 2-575                        [1]                       --
│    └─OutputScale: 2-576                --                        --
│    └─Empty: 2-577                      [2, 128, 1, 1]            --
│    └─Empty: 2-578                      [2, 128, 1, 1]            --
│    └─Empty: 2-579                      [2]                       --
│    └─Empty: 2-580                      [2]                       --
│    └─BatchNorm2d: 2-581                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-582                     [16, 2, 8, 8]             --
│    └─ReLU: 2-583                       [16, 2, 8, 8]             --
│    └─Empty: 2-584                      [16, 2, 8, 8]             --
│    └─Clamp: 2-585                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-586                  [16, 128, 8, 8]           --
│    └─Empty: 2-587                      [16, 128, 8, 8]           --
│    └─Empty: 2-588                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-589         --                        --
│    └─One: 2-590                        [1]                       --
│    └─OutputScale: 2-591                --                        --
│    └─Empty: 2-592                      [2, 128, 3, 3]            --
│    └─Empty: 2-593                      [2, 128, 3, 3]            --
│    └─Empty: 2-594                      [2]                       --
│    └─Empty: 2-595                      [2]                       --
│    └─BatchNorm2d: 2-596                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-597                     [16, 2, 8, 8]             --
│    └─ReLU: 2-598                       [16, 2, 8, 8]             --
│    └─Empty: 2-599                      [16, 2, 8, 8]             --
│    └─Clamp: 2-600                      [16, 2, 8, 8]             --
├─Dropout2d: 1-56                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-57                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-601         --                        --
│    └─One: 2-602                        [1]                       --
│    └─OutputScale: 2-603                --                        --
│    └─Empty: 2-604                      [128, 48, 1, 1]           --
│    └─Empty: 2-605                      [128, 48, 1, 1]           --
│    └─Empty: 2-606                      [128]                     --
│    └─Empty: 2-607                      [128]                     --
│    └─BatchNorm2d: 2-608                [16, 128, 64, 64]         --
│    └─Scaler: 2-609                     [16, 128, 64, 64]         --
│    └─ReLU: 2-610                       [16, 128, 64, 64]         --
│    └─Empty: 2-611                      [16, 128, 64, 64]         --
│    └─Clamp: 2-612                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-58                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-613         --                        --
│    └─One: 2-614                        [1]                       --
│    └─OutputScale: 2-615                --                        --
│    └─Empty: 2-616                      [128, 128, 3, 3]          --
│    └─Empty: 2-617                      [128, 128, 3, 3]          --
│    └─Empty: 2-618                      [128]                     --
│    └─Empty: 2-619                      [128]                     --
│    └─BatchNorm2d: 2-620                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-621                     [16, 128, 64, 64]         --
│    └─ReLU: 2-622                       [16, 128, 64, 64]         --
│    └─Empty: 2-623                      [16, 128, 64, 64]         --
│    └─Clamp: 2-624                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-59         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-625                  [16, 128, 32, 32]         --
│    └─Empty: 2-626                      [16, 128, 32, 32]         --
│    └─Empty: 2-627                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-628         --                        --
│    └─One: 2-629                        [1]                       --
│    └─OutputScale: 2-630                --                        --
│    └─Empty: 2-631                      [128, 128, 3, 3]          --
│    └─Empty: 2-632                      [128, 128, 3, 3]          --
│    └─Empty: 2-633                      [128]                     --
│    └─Empty: 2-634                      [128]                     --
│    └─BatchNorm2d: 2-635                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-636                     [16, 128, 32, 32]         --
│    └─ReLU: 2-637                       [16, 128, 32, 32]         --
│    └─Empty: 2-638                      [16, 128, 32, 32]         --
│    └─Clamp: 2-639                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-60                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-640         --                        --
│    └─One: 2-641                        [1]                       --
│    └─OutputScale: 2-642                --                        --
│    └─Empty: 2-643                      [128, 128, 1, 1]          --
│    └─Empty: 2-644                      [128, 128, 1, 1]          --
│    └─Empty: 2-645                      [128]                     --
│    └─Empty: 2-646                      [128]                     --
│    └─BatchNorm2d: 2-647                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-648                     [16, 128, 32, 32]         --
│    └─ReLU: 2-649                       [16, 128, 32, 32]         --
│    └─Empty: 2-650                      [16, 128, 32, 32]         --
│    └─Clamp: 2-651                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-61         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-652                  [16, 128, 32, 32]         --
│    └─Empty: 2-653                      [16, 128, 32, 32]         --
│    └─Empty: 2-654                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-655         --                        --
│    └─One: 2-656                        [1]                       --
│    └─OutputScale: 2-657                --                        --
│    └─Empty: 2-658                      [128, 128, 3, 3]          --
│    └─Empty: 2-659                      [128, 128, 3, 3]          --
│    └─Empty: 2-660                      [128]                     --
│    └─Empty: 2-661                      [128]                     --
│    └─BatchNorm2d: 2-662                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-663                     [16, 128, 32, 32]         --
│    └─ReLU: 2-664                       [16, 128, 32, 32]         --
│    └─Empty: 2-665                      [16, 128, 32, 32]         --
│    └─Clamp: 2-666                      [16, 128, 32, 32]         --
├─Dropout2d: 1-62                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-667                  [16, 128, 16, 16]         --
│    └─Empty: 2-668                      [16, 128, 16, 16]         --
│    └─Empty: 2-669                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-670         --                        --
│    └─One: 2-671                        [1]                       --
│    └─OutputScale: 2-672                --                        --
│    └─Empty: 2-673                      [128, 128, 3, 3]          --
│    └─Empty: 2-674                      [128, 128, 3, 3]          --
│    └─Empty: 2-675                      [128]                     --
│    └─Empty: 2-676                      [128]                     --
│    └─BatchNorm2d: 2-677                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-678                     [16, 128, 16, 16]         --
│    └─ReLU: 2-679                       [16, 128, 16, 16]         --
│    └─Empty: 2-680                      [16, 128, 16, 16]         --
│    └─Clamp: 2-681                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-64                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-682         --                        --
│    └─One: 2-683                        [1]                       --
│    └─OutputScale: 2-684                --                        --
│    └─Empty: 2-685                      [128, 128, 1, 1]          --
│    └─Empty: 2-686                      [128, 128, 1, 1]          --
│    └─Empty: 2-687                      [128]                     --
│    └─Empty: 2-688                      [128]                     --
│    └─BatchNorm2d: 2-689                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-690                     [16, 128, 16, 16]         --
│    └─ReLU: 2-691                       [16, 128, 16, 16]         --
│    └─Empty: 2-692                      [16, 128, 16, 16]         --
│    └─Clamp: 2-693                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-694                  [16, 128, 16, 16]         --
│    └─Empty: 2-695                      [16, 128, 16, 16]         --
│    └─Empty: 2-696                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-697         --                        --
│    └─One: 2-698                        [1]                       --
│    └─OutputScale: 2-699                --                        --
│    └─Empty: 2-700                      [128, 128, 3, 3]          --
│    └─Empty: 2-701                      [128, 128, 3, 3]          --
│    └─Empty: 2-702                      [128]                     --
│    └─Empty: 2-703                      [128]                     --
│    └─BatchNorm2d: 2-704                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-705                     [16, 128, 16, 16]         --
│    └─ReLU: 2-706                       [16, 128, 16, 16]         --
│    └─Empty: 2-707                      [16, 128, 16, 16]         --
│    └─Clamp: 2-708                      [16, 128, 16, 16]         --
├─Dropout2d: 1-66                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-67         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-709                  [16, 128, 8, 8]           --
│    └─Empty: 2-710                      [16, 128, 8, 8]           --
│    └─Empty: 2-711                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-712         --                        --
│    └─One: 2-713                        [1]                       --
│    └─OutputScale: 2-714                --                        --
│    └─Empty: 2-715                      [128, 128, 3, 3]          --
│    └─Empty: 2-716                      [128, 128, 3, 3]          --
│    └─Empty: 2-717                      [128]                     --
│    └─Empty: 2-718                      [128]                     --
│    └─BatchNorm2d: 2-719                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-720                     [16, 128, 8, 8]           --
│    └─ReLU: 2-721                       [16, 128, 8, 8]           --
│    └─Empty: 2-722                      [16, 128, 8, 8]           --
│    └─Clamp: 2-723                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-68                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-724         --                        --
│    └─One: 2-725                        [1]                       --
│    └─OutputScale: 2-726                --                        --
│    └─Empty: 2-727                      [2, 128, 1, 1]            --
│    └─Empty: 2-728                      [2, 128, 1, 1]            --
│    └─Empty: 2-729                      [2]                       --
│    └─Empty: 2-730                      [2]                       --
│    └─BatchNorm2d: 2-731                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-732                     [16, 2, 8, 8]             --
│    └─ReLU: 2-733                       [16, 2, 8, 8]             --
│    └─Empty: 2-734                      [16, 2, 8, 8]             --
│    └─Clamp: 2-735                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-69         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-736                  [16, 128, 8, 8]           --
│    └─Empty: 2-737                      [16, 128, 8, 8]           --
│    └─Empty: 2-738                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-739         --                        --
│    └─One: 2-740                        [1]                       --
│    └─OutputScale: 2-741                --                        --
│    └─Empty: 2-742                      [2, 128, 3, 3]            --
│    └─Empty: 2-743                      [2, 128, 3, 3]            --
│    └─Empty: 2-744                      [2]                       --
│    └─Empty: 2-745                      [2]                       --
│    └─BatchNorm2d: 2-746                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-747                     [16, 2, 8, 8]             --
│    └─ReLU: 2-748                       [16, 2, 8, 8]             --
│    └─Empty: 2-749                      [16, 2, 8, 8]             --
│    └─Clamp: 2-750                      [16, 2, 8, 8]             --
├─Dropout2d: 1-70                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-71                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-751         --                        --
│    └─One: 2-752                        [1]                       --
│    └─OutputScale: 2-753                --                        --
│    └─Empty: 2-754                      [128, 48, 1, 1]           --
│    └─Empty: 2-755                      [128, 48, 1, 1]           --
│    └─Empty: 2-756                      [128]                     --
│    └─Empty: 2-757                      [128]                     --
│    └─BatchNorm2d: 2-758                [16, 128, 64, 64]         --
│    └─Scaler: 2-759                     [16, 128, 64, 64]         --
│    └─ReLU: 2-760                       [16, 128, 64, 64]         --
│    └─Empty: 2-761                      [16, 128, 64, 64]         --
│    └─Clamp: 2-762                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-72                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-763         --                        --
│    └─One: 2-764                        [1]                       --
│    └─OutputScale: 2-765                --                        --
│    └─Empty: 2-766                      [128, 128, 3, 3]          --
│    └─Empty: 2-767                      [128, 128, 3, 3]          --
│    └─Empty: 2-768                      [128]                     --
│    └─Empty: 2-769                      [128]                     --
│    └─BatchNorm2d: 2-770                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-771                     [16, 128, 64, 64]         --
│    └─ReLU: 2-772                       [16, 128, 64, 64]         --
│    └─Empty: 2-773                      [16, 128, 64, 64]         --
│    └─Clamp: 2-774                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-775                  [16, 128, 32, 32]         --
│    └─Empty: 2-776                      [16, 128, 32, 32]         --
│    └─Empty: 2-777                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-778         --                        --
│    └─One: 2-779                        [1]                       --
│    └─OutputScale: 2-780                --                        --
│    └─Empty: 2-781                      [128, 128, 3, 3]          --
│    └─Empty: 2-782                      [128, 128, 3, 3]          --
│    └─Empty: 2-783                      [128]                     --
│    └─Empty: 2-784                      [128]                     --
│    └─BatchNorm2d: 2-785                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-786                     [16, 128, 32, 32]         --
│    └─ReLU: 2-787                       [16, 128, 32, 32]         --
│    └─Empty: 2-788                      [16, 128, 32, 32]         --
│    └─Clamp: 2-789                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-74                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-790         --                        --
│    └─One: 2-791                        [1]                       --
│    └─OutputScale: 2-792                --                        --
│    └─Empty: 2-793                      [128, 128, 1, 1]          --
│    └─Empty: 2-794                      [128, 128, 1, 1]          --
│    └─Empty: 2-795                      [128]                     --
│    └─Empty: 2-796                      [128]                     --
│    └─BatchNorm2d: 2-797                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-798                     [16, 128, 32, 32]         --
│    └─ReLU: 2-799                       [16, 128, 32, 32]         --
│    └─Empty: 2-800                      [16, 128, 32, 32]         --
│    └─Clamp: 2-801                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-802                  [16, 128, 32, 32]         --
│    └─Empty: 2-803                      [16, 128, 32, 32]         --
│    └─Empty: 2-804                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-805         --                        --
│    └─One: 2-806                        [1]                       --
│    └─OutputScale: 2-807                --                        --
│    └─Empty: 2-808                      [128, 128, 3, 3]          --
│    └─Empty: 2-809                      [128, 128, 3, 3]          --
│    └─Empty: 2-810                      [128]                     --
│    └─Empty: 2-811                      [128]                     --
│    └─BatchNorm2d: 2-812                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-813                     [16, 128, 32, 32]         --
│    └─ReLU: 2-814                       [16, 128, 32, 32]         --
│    └─Empty: 2-815                      [16, 128, 32, 32]         --
│    └─Clamp: 2-816                      [16, 128, 32, 32]         --
├─Dropout2d: 1-76                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-817                  [16, 128, 16, 16]         --
│    └─Empty: 2-818                      [16, 128, 16, 16]         --
│    └─Empty: 2-819                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-820         --                        --
│    └─One: 2-821                        [1]                       --
│    └─OutputScale: 2-822                --                        --
│    └─Empty: 2-823                      [128, 128, 3, 3]          --
│    └─Empty: 2-824                      [128, 128, 3, 3]          --
│    └─Empty: 2-825                      [128]                     --
│    └─Empty: 2-826                      [128]                     --
│    └─BatchNorm2d: 2-827                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-828                     [16, 128, 16, 16]         --
│    └─ReLU: 2-829                       [16, 128, 16, 16]         --
│    └─Empty: 2-830                      [16, 128, 16, 16]         --
│    └─Clamp: 2-831                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-78                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-832         --                        --
│    └─One: 2-833                        [1]                       --
│    └─OutputScale: 2-834                --                        --
│    └─Empty: 2-835                      [128, 128, 1, 1]          --
│    └─Empty: 2-836                      [128, 128, 1, 1]          --
│    └─Empty: 2-837                      [128]                     --
│    └─Empty: 2-838                      [128]                     --
│    └─BatchNorm2d: 2-839                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-840                     [16, 128, 16, 16]         --
│    └─ReLU: 2-841                       [16, 128, 16, 16]         --
│    └─Empty: 2-842                      [16, 128, 16, 16]         --
│    └─Clamp: 2-843                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-844                  [16, 128, 16, 16]         --
│    └─Empty: 2-845                      [16, 128, 16, 16]         --
│    └─Empty: 2-846                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-847         --                        --
│    └─One: 2-848                        [1]                       --
│    └─OutputScale: 2-849                --                        --
│    └─Empty: 2-850                      [128, 128, 3, 3]          --
│    └─Empty: 2-851                      [128, 128, 3, 3]          --
│    └─Empty: 2-852                      [128]                     --
│    └─Empty: 2-853                      [128]                     --
│    └─BatchNorm2d: 2-854                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-855                     [16, 128, 16, 16]         --
│    └─ReLU: 2-856                       [16, 128, 16, 16]         --
│    └─Empty: 2-857                      [16, 128, 16, 16]         --
│    └─Clamp: 2-858                      [16, 128, 16, 16]         --
├─Dropout2d: 1-80                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-859                  [16, 128, 8, 8]           --
│    └─Empty: 2-860                      [16, 128, 8, 8]           --
│    └─Empty: 2-861                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-862         --                        --
│    └─One: 2-863                        [1]                       --
│    └─OutputScale: 2-864                --                        --
│    └─Empty: 2-865                      [128, 128, 3, 3]          --
│    └─Empty: 2-866                      [128, 128, 3, 3]          --
│    └─Empty: 2-867                      [128]                     --
│    └─Empty: 2-868                      [128]                     --
│    └─BatchNorm2d: 2-869                [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-870                     [16, 128, 8, 8]           --
│    └─ReLU: 2-871                       [16, 128, 8, 8]           --
│    └─Empty: 2-872                      [16, 128, 8, 8]           --
│    └─Clamp: 2-873                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-82                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-874         --                        --
│    └─One: 2-875                        [1]                       --
│    └─OutputScale: 2-876                --                        --
│    └─Empty: 2-877                      [2, 128, 1, 1]            --
│    └─Empty: 2-878                      [2, 128, 1, 1]            --
│    └─Empty: 2-879                      [2]                       --
│    └─Empty: 2-880                      [2]                       --
│    └─BatchNorm2d: 2-881                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-882                     [16, 2, 8, 8]             --
│    └─ReLU: 2-883                       [16, 2, 8, 8]             --
│    └─Empty: 2-884                      [16, 2, 8, 8]             --
│    └─Clamp: 2-885                      [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-886                  [16, 128, 8, 8]           --
│    └─Empty: 2-887                      [16, 128, 8, 8]           --
│    └─Empty: 2-888                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-889         --                        --
│    └─One: 2-890                        [1]                       --
│    └─OutputScale: 2-891                --                        --
│    └─Empty: 2-892                      [2, 128, 3, 3]            --
│    └─Empty: 2-893                      [2, 128, 3, 3]            --
│    └─Empty: 2-894                      [2]                       --
│    └─Empty: 2-895                      [2]                       --
│    └─BatchNorm2d: 2-896                [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-897                     [16, 2, 8, 8]             --
│    └─ReLU: 2-898                       [16, 2, 8, 8]             --
│    └─Empty: 2-899                      [16, 2, 8, 8]             --
│    └─Clamp: 2-900                      [16, 2, 8, 8]             --
├─Dropout2d: 1-84                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-85                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-901         --                        --
│    └─One: 2-902                        [1]                       --
│    └─OutputScale: 2-903                --                        --
│    └─Empty: 2-904                      [128, 48, 1, 1]           --
│    └─Empty: 2-905                      [128, 48, 1, 1]           --
│    └─Empty: 2-906                      [128]                     --
│    └─Empty: 2-907                      [128]                     --
│    └─BatchNorm2d: 2-908                [16, 128, 64, 64]         --
│    └─Scaler: 2-909                     [16, 128, 64, 64]         --
│    └─ReLU: 2-910                       [16, 128, 64, 64]         --
│    └─Empty: 2-911                      [16, 128, 64, 64]         --
│    └─Clamp: 2-912                      [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-86                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-913         --                        --
│    └─One: 2-914                        [1]                       --
│    └─OutputScale: 2-915                --                        --
│    └─Empty: 2-916                      [128, 128, 3, 3]          --
│    └─Empty: 2-917                      [128, 128, 3, 3]          --
│    └─Empty: 2-918                      [128]                     --
│    └─Empty: 2-919                      [128]                     --
│    └─BatchNorm2d: 2-920                [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-921                     [16, 128, 64, 64]         --
│    └─ReLU: 2-922                       [16, 128, 64, 64]         --
│    └─Empty: 2-923                      [16, 128, 64, 64]         --
│    └─Clamp: 2-924                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-87         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-925                  [16, 128, 32, 32]         --
│    └─Empty: 2-926                      [16, 128, 32, 32]         --
│    └─Empty: 2-927                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-928         --                        --
│    └─One: 2-929                        [1]                       --
│    └─OutputScale: 2-930                --                        --
│    └─Empty: 2-931                      [128, 128, 3, 3]          --
│    └─Empty: 2-932                      [128, 128, 3, 3]          --
│    └─Empty: 2-933                      [128]                     --
│    └─Empty: 2-934                      [128]                     --
│    └─BatchNorm2d: 2-935                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-936                     [16, 128, 32, 32]         --
│    └─ReLU: 2-937                       [16, 128, 32, 32]         --
│    └─Empty: 2-938                      [16, 128, 32, 32]         --
│    └─Clamp: 2-939                      [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-88                [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-940         --                        --
│    └─One: 2-941                        [1]                       --
│    └─OutputScale: 2-942                --                        --
│    └─Empty: 2-943                      [128, 128, 1, 1]          --
│    └─Empty: 2-944                      [128, 128, 1, 1]          --
│    └─Empty: 2-945                      [128]                     --
│    └─Empty: 2-946                      [128]                     --
│    └─BatchNorm2d: 2-947                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-948                     [16, 128, 32, 32]         --
│    └─ReLU: 2-949                       [16, 128, 32, 32]         --
│    └─Empty: 2-950                      [16, 128, 32, 32]         --
│    └─Clamp: 2-951                      [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-952                  [16, 128, 32, 32]         --
│    └─Empty: 2-953                      [16, 128, 32, 32]         --
│    └─Empty: 2-954                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-955         --                        --
│    └─One: 2-956                        [1]                       --
│    └─OutputScale: 2-957                --                        --
│    └─Empty: 2-958                      [128, 128, 3, 3]          --
│    └─Empty: 2-959                      [128, 128, 3, 3]          --
│    └─Empty: 2-960                      [128]                     --
│    └─Empty: 2-961                      [128]                     --
│    └─BatchNorm2d: 2-962                [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-963                     [16, 128, 32, 32]         --
│    └─ReLU: 2-964                       [16, 128, 32, 32]         --
│    └─Empty: 2-965                      [16, 128, 32, 32]         --
│    └─Clamp: 2-966                      [16, 128, 32, 32]         --
├─Dropout2d: 1-90                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-91         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-967                  [16, 128, 16, 16]         --
│    └─Empty: 2-968                      [16, 128, 16, 16]         --
│    └─Empty: 2-969                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-970         --                        --
│    └─One: 2-971                        [1]                       --
│    └─OutputScale: 2-972                --                        --
│    └─Empty: 2-973                      [128, 128, 3, 3]          --
│    └─Empty: 2-974                      [128, 128, 3, 3]          --
│    └─Empty: 2-975                      [128]                     --
│    └─Empty: 2-976                      [128]                     --
│    └─BatchNorm2d: 2-977                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-978                     [16, 128, 16, 16]         --
│    └─ReLU: 2-979                       [16, 128, 16, 16]         --
│    └─Empty: 2-980                      [16, 128, 16, 16]         --
│    └─Clamp: 2-981                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-92                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-982         --                        --
│    └─One: 2-983                        [1]                       --
│    └─OutputScale: 2-984                --                        --
│    └─Empty: 2-985                      [128, 128, 1, 1]          --
│    └─Empty: 2-986                      [128, 128, 1, 1]          --
│    └─Empty: 2-987                      [128]                     --
│    └─Empty: 2-988                      [128]                     --
│    └─BatchNorm2d: 2-989                [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-990                     [16, 128, 16, 16]         --
│    └─ReLU: 2-991                       [16, 128, 16, 16]         --
│    └─Empty: 2-992                      [16, 128, 16, 16]         --
│    └─Clamp: 2-993                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-93         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-994                  [16, 128, 16, 16]         --
│    └─Empty: 2-995                      [16, 128, 16, 16]         --
│    └─Empty: 2-996                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-997         --                        --
│    └─One: 2-998                        [1]                       --
│    └─OutputScale: 2-999                --                        --
│    └─Empty: 2-1000                     [128, 128, 3, 3]          --
│    └─Empty: 2-1001                     [128, 128, 3, 3]          --
│    └─Empty: 2-1002                     [128]                     --
│    └─Empty: 2-1003                     [128]                     --
│    └─BatchNorm2d: 2-1004               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1005                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1006                      [16, 128, 16, 16]         --
│    └─Empty: 2-1007                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1008                     [16, 128, 16, 16]         --
├─Dropout2d: 1-94                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1009                 [16, 128, 8, 8]           --
│    └─Empty: 2-1010                     [16, 128, 8, 8]           --
│    └─Empty: 2-1011                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1012        --                        --
│    └─One: 2-1013                       [1]                       --
│    └─OutputScale: 2-1014               --                        --
│    └─Empty: 2-1015                     [128, 128, 3, 3]          --
│    └─Empty: 2-1016                     [128, 128, 3, 3]          --
│    └─Empty: 2-1017                     [128]                     --
│    └─Empty: 2-1018                     [128]                     --
│    └─BatchNorm2d: 2-1019               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1020                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1021                      [16, 128, 8, 8]           --
│    └─Empty: 2-1022                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1023                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-96                [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1024        --                        --
│    └─One: 2-1025                       [1]                       --
│    └─OutputScale: 2-1026               --                        --
│    └─Empty: 2-1027                     [2, 128, 1, 1]            --
│    └─Empty: 2-1028                     [2, 128, 1, 1]            --
│    └─Empty: 2-1029                     [2]                       --
│    └─Empty: 2-1030                     [2]                       --
│    └─BatchNorm2d: 2-1031               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1032                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1033                      [16, 2, 8, 8]             --
│    └─Empty: 2-1034                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1035                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1036                 [16, 128, 8, 8]           --
│    └─Empty: 2-1037                     [16, 128, 8, 8]           --
│    └─Empty: 2-1038                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1039        --                        --
│    └─One: 2-1040                       [1]                       --
│    └─OutputScale: 2-1041               --                        --
│    └─Empty: 2-1042                     [2, 128, 3, 3]            --
│    └─Empty: 2-1043                     [2, 128, 3, 3]            --
│    └─Empty: 2-1044                     [2]                       --
│    └─Empty: 2-1045                     [2]                       --
│    └─BatchNorm2d: 2-1046               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1047                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1048                      [16, 2, 8, 8]             --
│    └─Empty: 2-1049                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1050                     [16, 2, 8, 8]             --
├─Dropout2d: 1-98                        [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-99                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1051        --                        --
│    └─One: 2-1052                       [1]                       --
│    └─OutputScale: 2-1053               --                        --
│    └─Empty: 2-1054                     [128, 48, 1, 1]           --
│    └─Empty: 2-1055                     [128, 48, 1, 1]           --
│    └─Empty: 2-1056                     [128]                     --
│    └─Empty: 2-1057                     [128]                     --
│    └─BatchNorm2d: 2-1058               [16, 128, 64, 64]         --
│    └─Scaler: 2-1059                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1060                      [16, 128, 64, 64]         --
│    └─Empty: 2-1061                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1062                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-100               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1063        --                        --
│    └─One: 2-1064                       [1]                       --
│    └─OutputScale: 2-1065               --                        --
│    └─Empty: 2-1066                     [128, 128, 3, 3]          --
│    └─Empty: 2-1067                     [128, 128, 3, 3]          --
│    └─Empty: 2-1068                     [128]                     --
│    └─Empty: 2-1069                     [128]                     --
│    └─BatchNorm2d: 2-1070               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1071                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1072                      [16, 128, 64, 64]         --
│    └─Empty: 2-1073                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1074                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-101        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1075                 [16, 128, 32, 32]         --
│    └─Empty: 2-1076                     [16, 128, 32, 32]         --
│    └─Empty: 2-1077                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1078        --                        --
│    └─One: 2-1079                       [1]                       --
│    └─OutputScale: 2-1080               --                        --
│    └─Empty: 2-1081                     [128, 128, 3, 3]          --
│    └─Empty: 2-1082                     [128, 128, 3, 3]          --
│    └─Empty: 2-1083                     [128]                     --
│    └─Empty: 2-1084                     [128]                     --
│    └─BatchNorm2d: 2-1085               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1086                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1087                      [16, 128, 32, 32]         --
│    └─Empty: 2-1088                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1089                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-102               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1090        --                        --
│    └─One: 2-1091                       [1]                       --
│    └─OutputScale: 2-1092               --                        --
│    └─Empty: 2-1093                     [128, 128, 1, 1]          --
│    └─Empty: 2-1094                     [128, 128, 1, 1]          --
│    └─Empty: 2-1095                     [128]                     --
│    └─Empty: 2-1096                     [128]                     --
│    └─BatchNorm2d: 2-1097               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1098                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1099                      [16, 128, 32, 32]         --
│    └─Empty: 2-1100                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1101                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1102                 [16, 128, 32, 32]         --
│    └─Empty: 2-1103                     [16, 128, 32, 32]         --
│    └─Empty: 2-1104                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1105        --                        --
│    └─One: 2-1106                       [1]                       --
│    └─OutputScale: 2-1107               --                        --
│    └─Empty: 2-1108                     [128, 128, 3, 3]          --
│    └─Empty: 2-1109                     [128, 128, 3, 3]          --
│    └─Empty: 2-1110                     [128]                     --
│    └─Empty: 2-1111                     [128]                     --
│    └─BatchNorm2d: 2-1112               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1113                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1114                      [16, 128, 32, 32]         --
│    └─Empty: 2-1115                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1116                     [16, 128, 32, 32]         --
├─Dropout2d: 1-104                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-105        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1117                 [16, 128, 16, 16]         --
│    └─Empty: 2-1118                     [16, 128, 16, 16]         --
│    └─Empty: 2-1119                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1120        --                        --
│    └─One: 2-1121                       [1]                       --
│    └─OutputScale: 2-1122               --                        --
│    └─Empty: 2-1123                     [128, 128, 3, 3]          --
│    └─Empty: 2-1124                     [128, 128, 3, 3]          --
│    └─Empty: 2-1125                     [128]                     --
│    └─Empty: 2-1126                     [128]                     --
│    └─BatchNorm2d: 2-1127               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1128                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1129                      [16, 128, 16, 16]         --
│    └─Empty: 2-1130                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1131                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-106               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1132        --                        --
│    └─One: 2-1133                       [1]                       --
│    └─OutputScale: 2-1134               --                        --
│    └─Empty: 2-1135                     [128, 128, 1, 1]          --
│    └─Empty: 2-1136                     [128, 128, 1, 1]          --
│    └─Empty: 2-1137                     [128]                     --
│    └─Empty: 2-1138                     [128]                     --
│    └─BatchNorm2d: 2-1139               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1140                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1141                      [16, 128, 16, 16]         --
│    └─Empty: 2-1142                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1143                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1144                 [16, 128, 16, 16]         --
│    └─Empty: 2-1145                     [16, 128, 16, 16]         --
│    └─Empty: 2-1146                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1147        --                        --
│    └─One: 2-1148                       [1]                       --
│    └─OutputScale: 2-1149               --                        --
│    └─Empty: 2-1150                     [128, 128, 3, 3]          --
│    └─Empty: 2-1151                     [128, 128, 3, 3]          --
│    └─Empty: 2-1152                     [128]                     --
│    └─Empty: 2-1153                     [128]                     --
│    └─BatchNorm2d: 2-1154               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1155                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1156                      [16, 128, 16, 16]         --
│    └─Empty: 2-1157                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1158                     [16, 128, 16, 16]         --
├─Dropout2d: 1-108                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1159                 [16, 128, 8, 8]           --
│    └─Empty: 2-1160                     [16, 128, 8, 8]           --
│    └─Empty: 2-1161                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1162        --                        --
│    └─One: 2-1163                       [1]                       --
│    └─OutputScale: 2-1164               --                        --
│    └─Empty: 2-1165                     [128, 128, 3, 3]          --
│    └─Empty: 2-1166                     [128, 128, 3, 3]          --
│    └─Empty: 2-1167                     [128]                     --
│    └─Empty: 2-1168                     [128]                     --
│    └─BatchNorm2d: 2-1169               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1170                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1171                      [16, 128, 8, 8]           --
│    └─Empty: 2-1172                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1173                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-110               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1174        --                        --
│    └─One: 2-1175                       [1]                       --
│    └─OutputScale: 2-1176               --                        --
│    └─Empty: 2-1177                     [2, 128, 1, 1]            --
│    └─Empty: 2-1178                     [2, 128, 1, 1]            --
│    └─Empty: 2-1179                     [2]                       --
│    └─Empty: 2-1180                     [2]                       --
│    └─BatchNorm2d: 2-1181               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1182                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1183                      [16, 2, 8, 8]             --
│    └─Empty: 2-1184                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1185                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1186                 [16, 128, 8, 8]           --
│    └─Empty: 2-1187                     [16, 128, 8, 8]           --
│    └─Empty: 2-1188                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1189        --                        --
│    └─One: 2-1190                       [1]                       --
│    └─OutputScale: 2-1191               --                        --
│    └─Empty: 2-1192                     [2, 128, 3, 3]            --
│    └─Empty: 2-1193                     [2, 128, 3, 3]            --
│    └─Empty: 2-1194                     [2]                       --
│    └─Empty: 2-1195                     [2]                       --
│    └─BatchNorm2d: 2-1196               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1197                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1198                      [16, 2, 8, 8]             --
│    └─Empty: 2-1199                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1200                     [16, 2, 8, 8]             --
├─Dropout2d: 1-112                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-113               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1201        --                        --
│    └─One: 2-1202                       [1]                       --
│    └─OutputScale: 2-1203               --                        --
│    └─Empty: 2-1204                     [128, 48, 1, 1]           --
│    └─Empty: 2-1205                     [128, 48, 1, 1]           --
│    └─Empty: 2-1206                     [128]                     --
│    └─Empty: 2-1207                     [128]                     --
│    └─BatchNorm2d: 2-1208               [16, 128, 64, 64]         --
│    └─Scaler: 2-1209                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1210                      [16, 128, 64, 64]         --
│    └─Empty: 2-1211                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1212                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-114               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1213        --                        --
│    └─One: 2-1214                       [1]                       --
│    └─OutputScale: 2-1215               --                        --
│    └─Empty: 2-1216                     [128, 128, 3, 3]          --
│    └─Empty: 2-1217                     [128, 128, 3, 3]          --
│    └─Empty: 2-1218                     [128]                     --
│    └─Empty: 2-1219                     [128]                     --
│    └─BatchNorm2d: 2-1220               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1221                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1222                      [16, 128, 64, 64]         --
│    └─Empty: 2-1223                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1224                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-115        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1225                 [16, 128, 32, 32]         --
│    └─Empty: 2-1226                     [16, 128, 32, 32]         --
│    └─Empty: 2-1227                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1228        --                        --
│    └─One: 2-1229                       [1]                       --
│    └─OutputScale: 2-1230               --                        --
│    └─Empty: 2-1231                     [128, 128, 3, 3]          --
│    └─Empty: 2-1232                     [128, 128, 3, 3]          --
│    └─Empty: 2-1233                     [128]                     --
│    └─Empty: 2-1234                     [128]                     --
│    └─BatchNorm2d: 2-1235               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1236                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1237                      [16, 128, 32, 32]         --
│    └─Empty: 2-1238                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1239                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-116               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1240        --                        --
│    └─One: 2-1241                       [1]                       --
│    └─OutputScale: 2-1242               --                        --
│    └─Empty: 2-1243                     [128, 128, 1, 1]          --
│    └─Empty: 2-1244                     [128, 128, 1, 1]          --
│    └─Empty: 2-1245                     [128]                     --
│    └─Empty: 2-1246                     [128]                     --
│    └─BatchNorm2d: 2-1247               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1248                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1249                      [16, 128, 32, 32]         --
│    └─Empty: 2-1250                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1251                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1252                 [16, 128, 32, 32]         --
│    └─Empty: 2-1253                     [16, 128, 32, 32]         --
│    └─Empty: 2-1254                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1255        --                        --
│    └─One: 2-1256                       [1]                       --
│    └─OutputScale: 2-1257               --                        --
│    └─Empty: 2-1258                     [128, 128, 3, 3]          --
│    └─Empty: 2-1259                     [128, 128, 3, 3]          --
│    └─Empty: 2-1260                     [128]                     --
│    └─Empty: 2-1261                     [128]                     --
│    └─BatchNorm2d: 2-1262               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1263                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1264                      [16, 128, 32, 32]         --
│    └─Empty: 2-1265                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1266                     [16, 128, 32, 32]         --
├─Dropout2d: 1-118                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1267                 [16, 128, 16, 16]         --
│    └─Empty: 2-1268                     [16, 128, 16, 16]         --
│    └─Empty: 2-1269                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1270        --                        --
│    └─One: 2-1271                       [1]                       --
│    └─OutputScale: 2-1272               --                        --
│    └─Empty: 2-1273                     [128, 128, 3, 3]          --
│    └─Empty: 2-1274                     [128, 128, 3, 3]          --
│    └─Empty: 2-1275                     [128]                     --
│    └─Empty: 2-1276                     [128]                     --
│    └─BatchNorm2d: 2-1277               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1278                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1279                      [16, 128, 16, 16]         --
│    └─Empty: 2-1280                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1281                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-120               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1282        --                        --
│    └─One: 2-1283                       [1]                       --
│    └─OutputScale: 2-1284               --                        --
│    └─Empty: 2-1285                     [128, 128, 1, 1]          --
│    └─Empty: 2-1286                     [128, 128, 1, 1]          --
│    └─Empty: 2-1287                     [128]                     --
│    └─Empty: 2-1288                     [128]                     --
│    └─BatchNorm2d: 2-1289               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1290                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1291                      [16, 128, 16, 16]         --
│    └─Empty: 2-1292                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1293                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1294                 [16, 128, 16, 16]         --
│    └─Empty: 2-1295                     [16, 128, 16, 16]         --
│    └─Empty: 2-1296                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1297        --                        --
│    └─One: 2-1298                       [1]                       --
│    └─OutputScale: 2-1299               --                        --
│    └─Empty: 2-1300                     [128, 128, 3, 3]          --
│    └─Empty: 2-1301                     [128, 128, 3, 3]          --
│    └─Empty: 2-1302                     [128]                     --
│    └─Empty: 2-1303                     [128]                     --
│    └─BatchNorm2d: 2-1304               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1305                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1306                      [16, 128, 16, 16]         --
│    └─Empty: 2-1307                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1308                     [16, 128, 16, 16]         --
├─Dropout2d: 1-122                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-123        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1309                 [16, 128, 8, 8]           --
│    └─Empty: 2-1310                     [16, 128, 8, 8]           --
│    └─Empty: 2-1311                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1312        --                        --
│    └─One: 2-1313                       [1]                       --
│    └─OutputScale: 2-1314               --                        --
│    └─Empty: 2-1315                     [128, 128, 3, 3]          --
│    └─Empty: 2-1316                     [128, 128, 3, 3]          --
│    └─Empty: 2-1317                     [128]                     --
│    └─Empty: 2-1318                     [128]                     --
│    └─BatchNorm2d: 2-1319               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1320                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1321                      [16, 128, 8, 8]           --
│    └─Empty: 2-1322                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1323                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-124               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1324        --                        --
│    └─One: 2-1325                       [1]                       --
│    └─OutputScale: 2-1326               --                        --
│    └─Empty: 2-1327                     [2, 128, 1, 1]            --
│    └─Empty: 2-1328                     [2, 128, 1, 1]            --
│    └─Empty: 2-1329                     [2]                       --
│    └─Empty: 2-1330                     [2]                       --
│    └─BatchNorm2d: 2-1331               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1332                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1333                      [16, 2, 8, 8]             --
│    └─Empty: 2-1334                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1335                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-125        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1336                 [16, 128, 8, 8]           --
│    └─Empty: 2-1337                     [16, 128, 8, 8]           --
│    └─Empty: 2-1338                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1339        --                        --
│    └─One: 2-1340                       [1]                       --
│    └─OutputScale: 2-1341               --                        --
│    └─Empty: 2-1342                     [2, 128, 3, 3]            --
│    └─Empty: 2-1343                     [2, 128, 3, 3]            --
│    └─Empty: 2-1344                     [2]                       --
│    └─Empty: 2-1345                     [2]                       --
│    └─BatchNorm2d: 2-1346               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1347                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1348                      [16, 2, 8, 8]             --
│    └─Empty: 2-1349                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1350                     [16, 2, 8, 8]             --
├─Dropout2d: 1-126                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-127               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1351        --                        --
│    └─One: 2-1352                       [1]                       --
│    └─OutputScale: 2-1353               --                        --
│    └─Empty: 2-1354                     [128, 48, 1, 1]           --
│    └─Empty: 2-1355                     [128, 48, 1, 1]           --
│    └─Empty: 2-1356                     [128]                     --
│    └─Empty: 2-1357                     [128]                     --
│    └─BatchNorm2d: 2-1358               [16, 128, 64, 64]         --
│    └─Scaler: 2-1359                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1360                      [16, 128, 64, 64]         --
│    └─Empty: 2-1361                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1362                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-128               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1363        --                        --
│    └─One: 2-1364                       [1]                       --
│    └─OutputScale: 2-1365               --                        --
│    └─Empty: 2-1366                     [128, 128, 3, 3]          --
│    └─Empty: 2-1367                     [128, 128, 3, 3]          --
│    └─Empty: 2-1368                     [128]                     --
│    └─Empty: 2-1369                     [128]                     --
│    └─BatchNorm2d: 2-1370               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1371                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1372                      [16, 128, 64, 64]         --
│    └─Empty: 2-1373                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1374                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1375                 [16, 128, 32, 32]         --
│    └─Empty: 2-1376                     [16, 128, 32, 32]         --
│    └─Empty: 2-1377                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1378        --                        --
│    └─One: 2-1379                       [1]                       --
│    └─OutputScale: 2-1380               --                        --
│    └─Empty: 2-1381                     [128, 128, 3, 3]          --
│    └─Empty: 2-1382                     [128, 128, 3, 3]          --
│    └─Empty: 2-1383                     [128]                     --
│    └─Empty: 2-1384                     [128]                     --
│    └─BatchNorm2d: 2-1385               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1386                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1387                      [16, 128, 32, 32]         --
│    └─Empty: 2-1388                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1389                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-130               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1390        --                        --
│    └─One: 2-1391                       [1]                       --
│    └─OutputScale: 2-1392               --                        --
│    └─Empty: 2-1393                     [128, 128, 1, 1]          --
│    └─Empty: 2-1394                     [128, 128, 1, 1]          --
│    └─Empty: 2-1395                     [128]                     --
│    └─Empty: 2-1396                     [128]                     --
│    └─BatchNorm2d: 2-1397               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1398                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1399                      [16, 128, 32, 32]         --
│    └─Empty: 2-1400                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1401                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1402                 [16, 128, 32, 32]         --
│    └─Empty: 2-1403                     [16, 128, 32, 32]         --
│    └─Empty: 2-1404                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1405        --                        --
│    └─One: 2-1406                       [1]                       --
│    └─OutputScale: 2-1407               --                        --
│    └─Empty: 2-1408                     [128, 128, 3, 3]          --
│    └─Empty: 2-1409                     [128, 128, 3, 3]          --
│    └─Empty: 2-1410                     [128]                     --
│    └─Empty: 2-1411                     [128]                     --
│    └─BatchNorm2d: 2-1412               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1413                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1414                      [16, 128, 32, 32]         --
│    └─Empty: 2-1415                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1416                     [16, 128, 32, 32]         --
├─Dropout2d: 1-132                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1417                 [16, 128, 16, 16]         --
│    └─Empty: 2-1418                     [16, 128, 16, 16]         --
│    └─Empty: 2-1419                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1420        --                        --
│    └─One: 2-1421                       [1]                       --
│    └─OutputScale: 2-1422               --                        --
│    └─Empty: 2-1423                     [128, 128, 3, 3]          --
│    └─Empty: 2-1424                     [128, 128, 3, 3]          --
│    └─Empty: 2-1425                     [128]                     --
│    └─Empty: 2-1426                     [128]                     --
│    └─BatchNorm2d: 2-1427               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1428                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1429                      [16, 128, 16, 16]         --
│    └─Empty: 2-1430                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1431                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-134               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1432        --                        --
│    └─One: 2-1433                       [1]                       --
│    └─OutputScale: 2-1434               --                        --
│    └─Empty: 2-1435                     [128, 128, 1, 1]          --
│    └─Empty: 2-1436                     [128, 128, 1, 1]          --
│    └─Empty: 2-1437                     [128]                     --
│    └─Empty: 2-1438                     [128]                     --
│    └─BatchNorm2d: 2-1439               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1440                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1441                      [16, 128, 16, 16]         --
│    └─Empty: 2-1442                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1443                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-135        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1444                 [16, 128, 16, 16]         --
│    └─Empty: 2-1445                     [16, 128, 16, 16]         --
│    └─Empty: 2-1446                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1447        --                        --
│    └─One: 2-1448                       [1]                       --
│    └─OutputScale: 2-1449               --                        --
│    └─Empty: 2-1450                     [128, 128, 3, 3]          --
│    └─Empty: 2-1451                     [128, 128, 3, 3]          --
│    └─Empty: 2-1452                     [128]                     --
│    └─Empty: 2-1453                     [128]                     --
│    └─BatchNorm2d: 2-1454               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1455                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1456                      [16, 128, 16, 16]         --
│    └─Empty: 2-1457                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1458                     [16, 128, 16, 16]         --
├─Dropout2d: 1-136                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-137        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1459                 [16, 128, 8, 8]           --
│    └─Empty: 2-1460                     [16, 128, 8, 8]           --
│    └─Empty: 2-1461                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1462        --                        --
│    └─One: 2-1463                       [1]                       --
│    └─OutputScale: 2-1464               --                        --
│    └─Empty: 2-1465                     [128, 128, 3, 3]          --
│    └─Empty: 2-1466                     [128, 128, 3, 3]          --
│    └─Empty: 2-1467                     [128]                     --
│    └─Empty: 2-1468                     [128]                     --
│    └─BatchNorm2d: 2-1469               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1470                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1471                      [16, 128, 8, 8]           --
│    └─Empty: 2-1472                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1473                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-138               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1474        --                        --
│    └─One: 2-1475                       [1]                       --
│    └─OutputScale: 2-1476               --                        --
│    └─Empty: 2-1477                     [2, 128, 1, 1]            --
│    └─Empty: 2-1478                     [2, 128, 1, 1]            --
│    └─Empty: 2-1479                     [2]                       --
│    └─Empty: 2-1480                     [2]                       --
│    └─BatchNorm2d: 2-1481               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1482                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1483                      [16, 2, 8, 8]             --
│    └─Empty: 2-1484                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1485                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-139        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1486                 [16, 128, 8, 8]           --
│    └─Empty: 2-1487                     [16, 128, 8, 8]           --
│    └─Empty: 2-1488                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1489        --                        --
│    └─One: 2-1490                       [1]                       --
│    └─OutputScale: 2-1491               --                        --
│    └─Empty: 2-1492                     [2, 128, 3, 3]            --
│    └─Empty: 2-1493                     [2, 128, 3, 3]            --
│    └─Empty: 2-1494                     [2]                       --
│    └─Empty: 2-1495                     [2]                       --
│    └─BatchNorm2d: 2-1496               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1497                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1498                      [16, 2, 8, 8]             --
│    └─Empty: 2-1499                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1500                     [16, 2, 8, 8]             --
├─Dropout2d: 1-140                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-141               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1501        --                        --
│    └─One: 2-1502                       [1]                       --
│    └─OutputScale: 2-1503               --                        --
│    └─Empty: 2-1504                     [128, 48, 1, 1]           --
│    └─Empty: 2-1505                     [128, 48, 1, 1]           --
│    └─Empty: 2-1506                     [128]                     --
│    └─Empty: 2-1507                     [128]                     --
│    └─BatchNorm2d: 2-1508               [16, 128, 64, 64]         --
│    └─Scaler: 2-1509                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1510                      [16, 128, 64, 64]         --
│    └─Empty: 2-1511                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1512                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-142               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1513        --                        --
│    └─One: 2-1514                       [1]                       --
│    └─OutputScale: 2-1515               --                        --
│    └─Empty: 2-1516                     [128, 128, 3, 3]          --
│    └─Empty: 2-1517                     [128, 128, 3, 3]          --
│    └─Empty: 2-1518                     [128]                     --
│    └─Empty: 2-1519                     [128]                     --
│    └─BatchNorm2d: 2-1520               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1521                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1522                      [16, 128, 64, 64]         --
│    └─Empty: 2-1523                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1524                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1525                 [16, 128, 32, 32]         --
│    └─Empty: 2-1526                     [16, 128, 32, 32]         --
│    └─Empty: 2-1527                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1528        --                        --
│    └─One: 2-1529                       [1]                       --
│    └─OutputScale: 2-1530               --                        --
│    └─Empty: 2-1531                     [128, 128, 3, 3]          --
│    └─Empty: 2-1532                     [128, 128, 3, 3]          --
│    └─Empty: 2-1533                     [128]                     --
│    └─Empty: 2-1534                     [128]                     --
│    └─BatchNorm2d: 2-1535               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1536                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1537                      [16, 128, 32, 32]         --
│    └─Empty: 2-1538                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1539                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-144               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1540        --                        --
│    └─One: 2-1541                       [1]                       --
│    └─OutputScale: 2-1542               --                        --
│    └─Empty: 2-1543                     [128, 128, 1, 1]          --
│    └─Empty: 2-1544                     [128, 128, 1, 1]          --
│    └─Empty: 2-1545                     [128]                     --
│    └─Empty: 2-1546                     [128]                     --
│    └─BatchNorm2d: 2-1547               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1548                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1549                      [16, 128, 32, 32]         --
│    └─Empty: 2-1550                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1551                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1552                 [16, 128, 32, 32]         --
│    └─Empty: 2-1553                     [16, 128, 32, 32]         --
│    └─Empty: 2-1554                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1555        --                        --
│    └─One: 2-1556                       [1]                       --
│    └─OutputScale: 2-1557               --                        --
│    └─Empty: 2-1558                     [128, 128, 3, 3]          --
│    └─Empty: 2-1559                     [128, 128, 3, 3]          --
│    └─Empty: 2-1560                     [128]                     --
│    └─Empty: 2-1561                     [128]                     --
│    └─BatchNorm2d: 2-1562               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1563                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1564                      [16, 128, 32, 32]         --
│    └─Empty: 2-1565                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1566                     [16, 128, 32, 32]         --
├─Dropout2d: 1-146                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1567                 [16, 128, 16, 16]         --
│    └─Empty: 2-1568                     [16, 128, 16, 16]         --
│    └─Empty: 2-1569                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1570        --                        --
│    └─One: 2-1571                       [1]                       --
│    └─OutputScale: 2-1572               --                        --
│    └─Empty: 2-1573                     [128, 128, 3, 3]          --
│    └─Empty: 2-1574                     [128, 128, 3, 3]          --
│    └─Empty: 2-1575                     [128]                     --
│    └─Empty: 2-1576                     [128]                     --
│    └─BatchNorm2d: 2-1577               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1578                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1579                      [16, 128, 16, 16]         --
│    └─Empty: 2-1580                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1581                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-148               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1582        --                        --
│    └─One: 2-1583                       [1]                       --
│    └─OutputScale: 2-1584               --                        --
│    └─Empty: 2-1585                     [128, 128, 1, 1]          --
│    └─Empty: 2-1586                     [128, 128, 1, 1]          --
│    └─Empty: 2-1587                     [128]                     --
│    └─Empty: 2-1588                     [128]                     --
│    └─BatchNorm2d: 2-1589               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1590                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1591                      [16, 128, 16, 16]         --
│    └─Empty: 2-1592                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1593                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-149        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1594                 [16, 128, 16, 16]         --
│    └─Empty: 2-1595                     [16, 128, 16, 16]         --
│    └─Empty: 2-1596                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1597        --                        --
│    └─One: 2-1598                       [1]                       --
│    └─OutputScale: 2-1599               --                        --
│    └─Empty: 2-1600                     [128, 128, 3, 3]          --
│    └─Empty: 2-1601                     [128, 128, 3, 3]          --
│    └─Empty: 2-1602                     [128]                     --
│    └─Empty: 2-1603                     [128]                     --
│    └─BatchNorm2d: 2-1604               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1605                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1606                      [16, 128, 16, 16]         --
│    └─Empty: 2-1607                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1608                     [16, 128, 16, 16]         --
├─Dropout2d: 1-150                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1609                 [16, 128, 8, 8]           --
│    └─Empty: 2-1610                     [16, 128, 8, 8]           --
│    └─Empty: 2-1611                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1612        --                        --
│    └─One: 2-1613                       [1]                       --
│    └─OutputScale: 2-1614               --                        --
│    └─Empty: 2-1615                     [128, 128, 3, 3]          --
│    └─Empty: 2-1616                     [128, 128, 3, 3]          --
│    └─Empty: 2-1617                     [128]                     --
│    └─Empty: 2-1618                     [128]                     --
│    └─BatchNorm2d: 2-1619               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1620                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1621                      [16, 128, 8, 8]           --
│    └─Empty: 2-1622                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1623                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-152               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1624        --                        --
│    └─One: 2-1625                       [1]                       --
│    └─OutputScale: 2-1626               --                        --
│    └─Empty: 2-1627                     [2, 128, 1, 1]            --
│    └─Empty: 2-1628                     [2, 128, 1, 1]            --
│    └─Empty: 2-1629                     [2]                       --
│    └─Empty: 2-1630                     [2]                       --
│    └─BatchNorm2d: 2-1631               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1632                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1633                      [16, 2, 8, 8]             --
│    └─Empty: 2-1634                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1635                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1636                 [16, 128, 8, 8]           --
│    └─Empty: 2-1637                     [16, 128, 8, 8]           --
│    └─Empty: 2-1638                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1639        --                        --
│    └─One: 2-1640                       [1]                       --
│    └─OutputScale: 2-1641               --                        --
│    └─Empty: 2-1642                     [2, 128, 3, 3]            --
│    └─Empty: 2-1643                     [2, 128, 3, 3]            --
│    └─Empty: 2-1644                     [2]                       --
│    └─Empty: 2-1645                     [2]                       --
│    └─BatchNorm2d: 2-1646               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1647                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1648                      [16, 2, 8, 8]             --
│    └─Empty: 2-1649                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1650                     [16, 2, 8, 8]             --
├─Dropout2d: 1-154                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-155               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1651        --                        --
│    └─One: 2-1652                       [1]                       --
│    └─OutputScale: 2-1653               --                        --
│    └─Empty: 2-1654                     [128, 48, 1, 1]           --
│    └─Empty: 2-1655                     [128, 48, 1, 1]           --
│    └─Empty: 2-1656                     [128]                     --
│    └─Empty: 2-1657                     [128]                     --
│    └─BatchNorm2d: 2-1658               [16, 128, 64, 64]         --
│    └─Scaler: 2-1659                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1660                      [16, 128, 64, 64]         --
│    └─Empty: 2-1661                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1662                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-156               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1663        --                        --
│    └─One: 2-1664                       [1]                       --
│    └─OutputScale: 2-1665               --                        --
│    └─Empty: 2-1666                     [128, 128, 3, 3]          --
│    └─Empty: 2-1667                     [128, 128, 3, 3]          --
│    └─Empty: 2-1668                     [128]                     --
│    └─Empty: 2-1669                     [128]                     --
│    └─BatchNorm2d: 2-1670               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1671                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1672                      [16, 128, 64, 64]         --
│    └─Empty: 2-1673                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1674                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-157        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1675                 [16, 128, 32, 32]         --
│    └─Empty: 2-1676                     [16, 128, 32, 32]         --
│    └─Empty: 2-1677                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1678        --                        --
│    └─One: 2-1679                       [1]                       --
│    └─OutputScale: 2-1680               --                        --
│    └─Empty: 2-1681                     [128, 128, 3, 3]          --
│    └─Empty: 2-1682                     [128, 128, 3, 3]          --
│    └─Empty: 2-1683                     [128]                     --
│    └─Empty: 2-1684                     [128]                     --
│    └─BatchNorm2d: 2-1685               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1686                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1687                      [16, 128, 32, 32]         --
│    └─Empty: 2-1688                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1689                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-158               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1690        --                        --
│    └─One: 2-1691                       [1]                       --
│    └─OutputScale: 2-1692               --                        --
│    └─Empty: 2-1693                     [128, 128, 1, 1]          --
│    └─Empty: 2-1694                     [128, 128, 1, 1]          --
│    └─Empty: 2-1695                     [128]                     --
│    └─Empty: 2-1696                     [128]                     --
│    └─BatchNorm2d: 2-1697               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1698                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1699                      [16, 128, 32, 32]         --
│    └─Empty: 2-1700                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1701                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-159        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1702                 [16, 128, 32, 32]         --
│    └─Empty: 2-1703                     [16, 128, 32, 32]         --
│    └─Empty: 2-1704                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1705        --                        --
│    └─One: 2-1706                       [1]                       --
│    └─OutputScale: 2-1707               --                        --
│    └─Empty: 2-1708                     [128, 128, 3, 3]          --
│    └─Empty: 2-1709                     [128, 128, 3, 3]          --
│    └─Empty: 2-1710                     [128]                     --
│    └─Empty: 2-1711                     [128]                     --
│    └─BatchNorm2d: 2-1712               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1713                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1714                      [16, 128, 32, 32]         --
│    └─Empty: 2-1715                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1716                     [16, 128, 32, 32]         --
├─Dropout2d: 1-160                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-161        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1717                 [16, 128, 16, 16]         --
│    └─Empty: 2-1718                     [16, 128, 16, 16]         --
│    └─Empty: 2-1719                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1720        --                        --
│    └─One: 2-1721                       [1]                       --
│    └─OutputScale: 2-1722               --                        --
│    └─Empty: 2-1723                     [128, 128, 3, 3]          --
│    └─Empty: 2-1724                     [128, 128, 3, 3]          --
│    └─Empty: 2-1725                     [128]                     --
│    └─Empty: 2-1726                     [128]                     --
│    └─BatchNorm2d: 2-1727               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1728                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1729                      [16, 128, 16, 16]         --
│    └─Empty: 2-1730                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1731                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-162               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1732        --                        --
│    └─One: 2-1733                       [1]                       --
│    └─OutputScale: 2-1734               --                        --
│    └─Empty: 2-1735                     [128, 128, 1, 1]          --
│    └─Empty: 2-1736                     [128, 128, 1, 1]          --
│    └─Empty: 2-1737                     [128]                     --
│    └─Empty: 2-1738                     [128]                     --
│    └─BatchNorm2d: 2-1739               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1740                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1741                      [16, 128, 16, 16]         --
│    └─Empty: 2-1742                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1743                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-163        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1744                 [16, 128, 16, 16]         --
│    └─Empty: 2-1745                     [16, 128, 16, 16]         --
│    └─Empty: 2-1746                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1747        --                        --
│    └─One: 2-1748                       [1]                       --
│    └─OutputScale: 2-1749               --                        --
│    └─Empty: 2-1750                     [128, 128, 3, 3]          --
│    └─Empty: 2-1751                     [128, 128, 3, 3]          --
│    └─Empty: 2-1752                     [128]                     --
│    └─Empty: 2-1753                     [128]                     --
│    └─BatchNorm2d: 2-1754               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1755                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1756                      [16, 128, 16, 16]         --
│    └─Empty: 2-1757                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1758                     [16, 128, 16, 16]         --
├─Dropout2d: 1-164                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1759                 [16, 128, 8, 8]           --
│    └─Empty: 2-1760                     [16, 128, 8, 8]           --
│    └─Empty: 2-1761                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1762        --                        --
│    └─One: 2-1763                       [1]                       --
│    └─OutputScale: 2-1764               --                        --
│    └─Empty: 2-1765                     [128, 128, 3, 3]          --
│    └─Empty: 2-1766                     [128, 128, 3, 3]          --
│    └─Empty: 2-1767                     [128]                     --
│    └─Empty: 2-1768                     [128]                     --
│    └─BatchNorm2d: 2-1769               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1770                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1771                      [16, 128, 8, 8]           --
│    └─Empty: 2-1772                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1773                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-166               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1774        --                        --
│    └─One: 2-1775                       [1]                       --
│    └─OutputScale: 2-1776               --                        --
│    └─Empty: 2-1777                     [2, 128, 1, 1]            --
│    └─Empty: 2-1778                     [2, 128, 1, 1]            --
│    └─Empty: 2-1779                     [2]                       --
│    └─Empty: 2-1780                     [2]                       --
│    └─BatchNorm2d: 2-1781               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1782                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1783                      [16, 2, 8, 8]             --
│    └─Empty: 2-1784                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1785                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1786                 [16, 128, 8, 8]           --
│    └─Empty: 2-1787                     [16, 128, 8, 8]           --
│    └─Empty: 2-1788                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1789        --                        --
│    └─One: 2-1790                       [1]                       --
│    └─OutputScale: 2-1791               --                        --
│    └─Empty: 2-1792                     [2, 128, 3, 3]            --
│    └─Empty: 2-1793                     [2, 128, 3, 3]            --
│    └─Empty: 2-1794                     [2]                       --
│    └─Empty: 2-1795                     [2]                       --
│    └─BatchNorm2d: 2-1796               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1797                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1798                      [16, 2, 8, 8]             --
│    └─Empty: 2-1799                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1800                     [16, 2, 8, 8]             --
├─Dropout2d: 1-168                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-169               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1801        --                        --
│    └─One: 2-1802                       [1]                       --
│    └─OutputScale: 2-1803               --                        --
│    └─Empty: 2-1804                     [128, 48, 1, 1]           --
│    └─Empty: 2-1805                     [128, 48, 1, 1]           --
│    └─Empty: 2-1806                     [128]                     --
│    └─Empty: 2-1807                     [128]                     --
│    └─BatchNorm2d: 2-1808               [16, 128, 64, 64]         --
│    └─Scaler: 2-1809                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1810                      [16, 128, 64, 64]         --
│    └─Empty: 2-1811                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1812                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-170               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1813        --                        --
│    └─One: 2-1814                       [1]                       --
│    └─OutputScale: 2-1815               --                        --
│    └─Empty: 2-1816                     [128, 128, 3, 3]          --
│    └─Empty: 2-1817                     [128, 128, 3, 3]          --
│    └─Empty: 2-1818                     [128]                     --
│    └─Empty: 2-1819                     [128]                     --
│    └─BatchNorm2d: 2-1820               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1821                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1822                      [16, 128, 64, 64]         --
│    └─Empty: 2-1823                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1824                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-171        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1825                 [16, 128, 32, 32]         --
│    └─Empty: 2-1826                     [16, 128, 32, 32]         --
│    └─Empty: 2-1827                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1828        --                        --
│    └─One: 2-1829                       [1]                       --
│    └─OutputScale: 2-1830               --                        --
│    └─Empty: 2-1831                     [128, 128, 3, 3]          --
│    └─Empty: 2-1832                     [128, 128, 3, 3]          --
│    └─Empty: 2-1833                     [128]                     --
│    └─Empty: 2-1834                     [128]                     --
│    └─BatchNorm2d: 2-1835               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1836                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1837                      [16, 128, 32, 32]         --
│    └─Empty: 2-1838                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1839                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-172               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1840        --                        --
│    └─One: 2-1841                       [1]                       --
│    └─OutputScale: 2-1842               --                        --
│    └─Empty: 2-1843                     [128, 128, 1, 1]          --
│    └─Empty: 2-1844                     [128, 128, 1, 1]          --
│    └─Empty: 2-1845                     [128]                     --
│    └─Empty: 2-1846                     [128]                     --
│    └─BatchNorm2d: 2-1847               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1848                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1849                      [16, 128, 32, 32]         --
│    └─Empty: 2-1850                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1851                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-173        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1852                 [16, 128, 32, 32]         --
│    └─Empty: 2-1853                     [16, 128, 32, 32]         --
│    └─Empty: 2-1854                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1855        --                        --
│    └─One: 2-1856                       [1]                       --
│    └─OutputScale: 2-1857               --                        --
│    └─Empty: 2-1858                     [128, 128, 3, 3]          --
│    └─Empty: 2-1859                     [128, 128, 3, 3]          --
│    └─Empty: 2-1860                     [128]                     --
│    └─Empty: 2-1861                     [128]                     --
│    └─BatchNorm2d: 2-1862               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1863                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1864                      [16, 128, 32, 32]         --
│    └─Empty: 2-1865                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1866                     [16, 128, 32, 32]         --
├─Dropout2d: 1-174                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1867                 [16, 128, 16, 16]         --
│    └─Empty: 2-1868                     [16, 128, 16, 16]         --
│    └─Empty: 2-1869                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1870        --                        --
│    └─One: 2-1871                       [1]                       --
│    └─OutputScale: 2-1872               --                        --
│    └─Empty: 2-1873                     [128, 128, 3, 3]          --
│    └─Empty: 2-1874                     [128, 128, 3, 3]          --
│    └─Empty: 2-1875                     [128]                     --
│    └─Empty: 2-1876                     [128]                     --
│    └─BatchNorm2d: 2-1877               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1878                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1879                      [16, 128, 16, 16]         --
│    └─Empty: 2-1880                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1881                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-176               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1882        --                        --
│    └─One: 2-1883                       [1]                       --
│    └─OutputScale: 2-1884               --                        --
│    └─Empty: 2-1885                     [128, 128, 1, 1]          --
│    └─Empty: 2-1886                     [128, 128, 1, 1]          --
│    └─Empty: 2-1887                     [128]                     --
│    └─Empty: 2-1888                     [128]                     --
│    └─BatchNorm2d: 2-1889               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1890                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1891                      [16, 128, 16, 16]         --
│    └─Empty: 2-1892                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1893                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1894                 [16, 128, 16, 16]         --
│    └─Empty: 2-1895                     [16, 128, 16, 16]         --
│    └─Empty: 2-1896                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1897        --                        --
│    └─One: 2-1898                       [1]                       --
│    └─OutputScale: 2-1899               --                        --
│    └─Empty: 2-1900                     [128, 128, 3, 3]          --
│    └─Empty: 2-1901                     [128, 128, 3, 3]          --
│    └─Empty: 2-1902                     [128]                     --
│    └─Empty: 2-1903                     [128]                     --
│    └─BatchNorm2d: 2-1904               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-1905                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1906                      [16, 128, 16, 16]         --
│    └─Empty: 2-1907                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1908                     [16, 128, 16, 16]         --
├─Dropout2d: 1-178                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1909                 [16, 128, 8, 8]           --
│    └─Empty: 2-1910                     [16, 128, 8, 8]           --
│    └─Empty: 2-1911                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1912        --                        --
│    └─One: 2-1913                       [1]                       --
│    └─OutputScale: 2-1914               --                        --
│    └─Empty: 2-1915                     [128, 128, 3, 3]          --
│    └─Empty: 2-1916                     [128, 128, 3, 3]          --
│    └─Empty: 2-1917                     [128]                     --
│    └─Empty: 2-1918                     [128]                     --
│    └─BatchNorm2d: 2-1919               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-1920                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1921                      [16, 128, 8, 8]           --
│    └─Empty: 2-1922                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1923                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-180               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-1924        --                        --
│    └─One: 2-1925                       [1]                       --
│    └─OutputScale: 2-1926               --                        --
│    └─Empty: 2-1927                     [2, 128, 1, 1]            --
│    └─Empty: 2-1928                     [2, 128, 1, 1]            --
│    └─Empty: 2-1929                     [2]                       --
│    └─Empty: 2-1930                     [2]                       --
│    └─BatchNorm2d: 2-1931               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1932                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1933                      [16, 2, 8, 8]             --
│    └─Empty: 2-1934                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1935                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-1936                 [16, 128, 8, 8]           --
│    └─Empty: 2-1937                     [16, 128, 8, 8]           --
│    └─Empty: 2-1938                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1939        --                        --
│    └─One: 2-1940                       [1]                       --
│    └─OutputScale: 2-1941               --                        --
│    └─Empty: 2-1942                     [2, 128, 3, 3]            --
│    └─Empty: 2-1943                     [2, 128, 3, 3]            --
│    └─Empty: 2-1944                     [2]                       --
│    └─Empty: 2-1945                     [2]                       --
│    └─BatchNorm2d: 2-1946               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-1947                    [16, 2, 8, 8]             --
│    └─ReLU: 2-1948                      [16, 2, 8, 8]             --
│    └─Empty: 2-1949                     [16, 2, 8, 8]             --
│    └─Clamp: 2-1950                     [16, 2, 8, 8]             --
├─Dropout2d: 1-182                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-183               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1951        --                        --
│    └─One: 2-1952                       [1]                       --
│    └─OutputScale: 2-1953               --                        --
│    └─Empty: 2-1954                     [128, 48, 1, 1]           --
│    └─Empty: 2-1955                     [128, 48, 1, 1]           --
│    └─Empty: 2-1956                     [128]                     --
│    └─Empty: 2-1957                     [128]                     --
│    └─BatchNorm2d: 2-1958               [16, 128, 64, 64]         --
│    └─Scaler: 2-1959                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1960                      [16, 128, 64, 64]         --
│    └─Empty: 2-1961                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1962                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-184               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1963        --                        --
│    └─One: 2-1964                       [1]                       --
│    └─OutputScale: 2-1965               --                        --
│    └─Empty: 2-1966                     [128, 128, 3, 3]          --
│    └─Empty: 2-1967                     [128, 128, 3, 3]          --
│    └─Empty: 2-1968                     [128]                     --
│    └─Empty: 2-1969                     [128]                     --
│    └─BatchNorm2d: 2-1970               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-1971                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1972                      [16, 128, 64, 64]         --
│    └─Empty: 2-1973                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1974                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1975                 [16, 128, 32, 32]         --
│    └─Empty: 2-1976                     [16, 128, 32, 32]         --
│    └─Empty: 2-1977                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1978        --                        --
│    └─One: 2-1979                       [1]                       --
│    └─OutputScale: 2-1980               --                        --
│    └─Empty: 2-1981                     [128, 128, 3, 3]          --
│    └─Empty: 2-1982                     [128, 128, 3, 3]          --
│    └─Empty: 2-1983                     [128]                     --
│    └─Empty: 2-1984                     [128]                     --
│    └─BatchNorm2d: 2-1985               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1986                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1987                      [16, 128, 32, 32]         --
│    └─Empty: 2-1988                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1989                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-186               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-1990        --                        --
│    └─One: 2-1991                       [1]                       --
│    └─OutputScale: 2-1992               --                        --
│    └─Empty: 2-1993                     [128, 128, 1, 1]          --
│    └─Empty: 2-1994                     [128, 128, 1, 1]          --
│    └─Empty: 2-1995                     [128]                     --
│    └─Empty: 2-1996                     [128]                     --
│    └─BatchNorm2d: 2-1997               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-1998                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1999                      [16, 128, 32, 32]         --
│    └─Empty: 2-2000                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2001                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2002                 [16, 128, 32, 32]         --
│    └─Empty: 2-2003                     [16, 128, 32, 32]         --
│    └─Empty: 2-2004                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2005        --                        --
│    └─One: 2-2006                       [1]                       --
│    └─OutputScale: 2-2007               --                        --
│    └─Empty: 2-2008                     [128, 128, 3, 3]          --
│    └─Empty: 2-2009                     [128, 128, 3, 3]          --
│    └─Empty: 2-2010                     [128]                     --
│    └─Empty: 2-2011                     [128]                     --
│    └─BatchNorm2d: 2-2012               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2013                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2014                      [16, 128, 32, 32]         --
│    └─Empty: 2-2015                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2016                     [16, 128, 32, 32]         --
├─Dropout2d: 1-188                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-189        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2017                 [16, 128, 16, 16]         --
│    └─Empty: 2-2018                     [16, 128, 16, 16]         --
│    └─Empty: 2-2019                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2020        --                        --
│    └─One: 2-2021                       [1]                       --
│    └─OutputScale: 2-2022               --                        --
│    └─Empty: 2-2023                     [128, 128, 3, 3]          --
│    └─Empty: 2-2024                     [128, 128, 3, 3]          --
│    └─Empty: 2-2025                     [128]                     --
│    └─Empty: 2-2026                     [128]                     --
│    └─BatchNorm2d: 2-2027               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2028                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2029                      [16, 128, 16, 16]         --
│    └─Empty: 2-2030                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2031                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-190               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2032        --                        --
│    └─One: 2-2033                       [1]                       --
│    └─OutputScale: 2-2034               --                        --
│    └─Empty: 2-2035                     [128, 128, 1, 1]          --
│    └─Empty: 2-2036                     [128, 128, 1, 1]          --
│    └─Empty: 2-2037                     [128]                     --
│    └─Empty: 2-2038                     [128]                     --
│    └─BatchNorm2d: 2-2039               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2040                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2041                      [16, 128, 16, 16]         --
│    └─Empty: 2-2042                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2043                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-191        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2044                 [16, 128, 16, 16]         --
│    └─Empty: 2-2045                     [16, 128, 16, 16]         --
│    └─Empty: 2-2046                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2047        --                        --
│    └─One: 2-2048                       [1]                       --
│    └─OutputScale: 2-2049               --                        --
│    └─Empty: 2-2050                     [128, 128, 3, 3]          --
│    └─Empty: 2-2051                     [128, 128, 3, 3]          --
│    └─Empty: 2-2052                     [128]                     --
│    └─Empty: 2-2053                     [128]                     --
│    └─BatchNorm2d: 2-2054               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2055                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2056                      [16, 128, 16, 16]         --
│    └─Empty: 2-2057                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2058                     [16, 128, 16, 16]         --
├─Dropout2d: 1-192                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-193        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2059                 [16, 128, 8, 8]           --
│    └─Empty: 2-2060                     [16, 128, 8, 8]           --
│    └─Empty: 2-2061                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2062        --                        --
│    └─One: 2-2063                       [1]                       --
│    └─OutputScale: 2-2064               --                        --
│    └─Empty: 2-2065                     [128, 128, 3, 3]          --
│    └─Empty: 2-2066                     [128, 128, 3, 3]          --
│    └─Empty: 2-2067                     [128]                     --
│    └─Empty: 2-2068                     [128]                     --
│    └─BatchNorm2d: 2-2069               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-2070                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2071                      [16, 128, 8, 8]           --
│    └─Empty: 2-2072                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2073                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-194               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-2074        --                        --
│    └─One: 2-2075                       [1]                       --
│    └─OutputScale: 2-2076               --                        --
│    └─Empty: 2-2077                     [2, 128, 1, 1]            --
│    └─Empty: 2-2078                     [2, 128, 1, 1]            --
│    └─Empty: 2-2079                     [2]                       --
│    └─Empty: 2-2080                     [2]                       --
│    └─BatchNorm2d: 2-2081               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2082                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2083                      [16, 2, 8, 8]             --
│    └─Empty: 2-2084                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2085                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-195        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-2086                 [16, 128, 8, 8]           --
│    └─Empty: 2-2087                     [16, 128, 8, 8]           --
│    └─Empty: 2-2088                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2089        --                        --
│    └─One: 2-2090                       [1]                       --
│    └─OutputScale: 2-2091               --                        --
│    └─Empty: 2-2092                     [2, 128, 3, 3]            --
│    └─Empty: 2-2093                     [2, 128, 3, 3]            --
│    └─Empty: 2-2094                     [2]                       --
│    └─Empty: 2-2095                     [2]                       --
│    └─BatchNorm2d: 2-2096               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2097                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2098                      [16, 2, 8, 8]             --
│    └─Empty: 2-2099                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2100                     [16, 2, 8, 8]             --
├─Dropout2d: 1-196                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-197               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2101        --                        --
│    └─One: 2-2102                       [1]                       --
│    └─OutputScale: 2-2103               --                        --
│    └─Empty: 2-2104                     [128, 48, 1, 1]           --
│    └─Empty: 2-2105                     [128, 48, 1, 1]           --
│    └─Empty: 2-2106                     [128]                     --
│    └─Empty: 2-2107                     [128]                     --
│    └─BatchNorm2d: 2-2108               [16, 128, 64, 64]         --
│    └─Scaler: 2-2109                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2110                      [16, 128, 64, 64]         --
│    └─Empty: 2-2111                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2112                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-198               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2113        --                        --
│    └─One: 2-2114                       [1]                       --
│    └─OutputScale: 2-2115               --                        --
│    └─Empty: 2-2116                     [128, 128, 3, 3]          --
│    └─Empty: 2-2117                     [128, 128, 3, 3]          --
│    └─Empty: 2-2118                     [128]                     --
│    └─Empty: 2-2119                     [128]                     --
│    └─BatchNorm2d: 2-2120               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-2121                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2122                      [16, 128, 64, 64]         --
│    └─Empty: 2-2123                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2124                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2125                 [16, 128, 32, 32]         --
│    └─Empty: 2-2126                     [16, 128, 32, 32]         --
│    └─Empty: 2-2127                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2128        --                        --
│    └─One: 2-2129                       [1]                       --
│    └─OutputScale: 2-2130               --                        --
│    └─Empty: 2-2131                     [128, 128, 3, 3]          --
│    └─Empty: 2-2132                     [128, 128, 3, 3]          --
│    └─Empty: 2-2133                     [128]                     --
│    └─Empty: 2-2134                     [128]                     --
│    └─BatchNorm2d: 2-2135               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2136                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2137                      [16, 128, 32, 32]         --
│    └─Empty: 2-2138                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2139                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-200               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2140        --                        --
│    └─One: 2-2141                       [1]                       --
│    └─OutputScale: 2-2142               --                        --
│    └─Empty: 2-2143                     [128, 128, 1, 1]          --
│    └─Empty: 2-2144                     [128, 128, 1, 1]          --
│    └─Empty: 2-2145                     [128]                     --
│    └─Empty: 2-2146                     [128]                     --
│    └─BatchNorm2d: 2-2147               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2148                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2149                      [16, 128, 32, 32]         --
│    └─Empty: 2-2150                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2151                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2152                 [16, 128, 32, 32]         --
│    └─Empty: 2-2153                     [16, 128, 32, 32]         --
│    └─Empty: 2-2154                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2155        --                        --
│    └─One: 2-2156                       [1]                       --
│    └─OutputScale: 2-2157               --                        --
│    └─Empty: 2-2158                     [128, 128, 3, 3]          --
│    └─Empty: 2-2159                     [128, 128, 3, 3]          --
│    └─Empty: 2-2160                     [128]                     --
│    └─Empty: 2-2161                     [128]                     --
│    └─BatchNorm2d: 2-2162               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2163                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2164                      [16, 128, 32, 32]         --
│    └─Empty: 2-2165                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2166                     [16, 128, 32, 32]         --
├─Dropout2d: 1-202                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-203        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2167                 [16, 128, 16, 16]         --
│    └─Empty: 2-2168                     [16, 128, 16, 16]         --
│    └─Empty: 2-2169                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2170        --                        --
│    └─One: 2-2171                       [1]                       --
│    └─OutputScale: 2-2172               --                        --
│    └─Empty: 2-2173                     [128, 128, 3, 3]          --
│    └─Empty: 2-2174                     [128, 128, 3, 3]          --
│    └─Empty: 2-2175                     [128]                     --
│    └─Empty: 2-2176                     [128]                     --
│    └─BatchNorm2d: 2-2177               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2178                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2179                      [16, 128, 16, 16]         --
│    └─Empty: 2-2180                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2181                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-204               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2182        --                        --
│    └─One: 2-2183                       [1]                       --
│    └─OutputScale: 2-2184               --                        --
│    └─Empty: 2-2185                     [128, 128, 1, 1]          --
│    └─Empty: 2-2186                     [128, 128, 1, 1]          --
│    └─Empty: 2-2187                     [128]                     --
│    └─Empty: 2-2188                     [128]                     --
│    └─BatchNorm2d: 2-2189               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2190                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2191                      [16, 128, 16, 16]         --
│    └─Empty: 2-2192                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2193                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-205        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2194                 [16, 128, 16, 16]         --
│    └─Empty: 2-2195                     [16, 128, 16, 16]         --
│    └─Empty: 2-2196                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2197        --                        --
│    └─One: 2-2198                       [1]                       --
│    └─OutputScale: 2-2199               --                        --
│    └─Empty: 2-2200                     [128, 128, 3, 3]          --
│    └─Empty: 2-2201                     [128, 128, 3, 3]          --
│    └─Empty: 2-2202                     [128]                     --
│    └─Empty: 2-2203                     [128]                     --
│    └─BatchNorm2d: 2-2204               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2205                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2206                      [16, 128, 16, 16]         --
│    └─Empty: 2-2207                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2208                     [16, 128, 16, 16]         --
├─Dropout2d: 1-206                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-207        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2209                 [16, 128, 8, 8]           --
│    └─Empty: 2-2210                     [16, 128, 8, 8]           --
│    └─Empty: 2-2211                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2212        --                        --
│    └─One: 2-2213                       [1]                       --
│    └─OutputScale: 2-2214               --                        --
│    └─Empty: 2-2215                     [128, 128, 3, 3]          --
│    └─Empty: 2-2216                     [128, 128, 3, 3]          --
│    └─Empty: 2-2217                     [128]                     --
│    └─Empty: 2-2218                     [128]                     --
│    └─BatchNorm2d: 2-2219               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-2220                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2221                      [16, 128, 8, 8]           --
│    └─Empty: 2-2222                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2223                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-208               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-2224        --                        --
│    └─One: 2-2225                       [1]                       --
│    └─OutputScale: 2-2226               --                        --
│    └─Empty: 2-2227                     [2, 128, 1, 1]            --
│    └─Empty: 2-2228                     [2, 128, 1, 1]            --
│    └─Empty: 2-2229                     [2]                       --
│    └─Empty: 2-2230                     [2]                       --
│    └─BatchNorm2d: 2-2231               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2232                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2233                      [16, 2, 8, 8]             --
│    └─Empty: 2-2234                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2235                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-2236                 [16, 128, 8, 8]           --
│    └─Empty: 2-2237                     [16, 128, 8, 8]           --
│    └─Empty: 2-2238                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2239        --                        --
│    └─One: 2-2240                       [1]                       --
│    └─OutputScale: 2-2241               --                        --
│    └─Empty: 2-2242                     [2, 128, 3, 3]            --
│    └─Empty: 2-2243                     [2, 128, 3, 3]            --
│    └─Empty: 2-2244                     [2]                       --
│    └─Empty: 2-2245                     [2]                       --
│    └─BatchNorm2d: 2-2246               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2247                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2248                      [16, 2, 8, 8]             --
│    └─Empty: 2-2249                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2250                     [16, 2, 8, 8]             --
├─Dropout2d: 1-210                       [16, 2, 8, 8]             --
├─FusedConv2dBNReLU: 1-211               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2251        --                        --
│    └─One: 2-2252                       [1]                       --
│    └─OutputScale: 2-2253               --                        --
│    └─Empty: 2-2254                     [128, 48, 1, 1]           --
│    └─Empty: 2-2255                     [128, 48, 1, 1]           --
│    └─Empty: 2-2256                     [128]                     --
│    └─Empty: 2-2257                     [128]                     --
│    └─BatchNorm2d: 2-2258               [16, 128, 64, 64]         --
│    └─Scaler: 2-2259                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2260                      [16, 128, 64, 64]         --
│    └─Empty: 2-2261                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2262                     [16, 128, 64, 64]         --
├─FusedConv2dBNReLU: 1-212               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-2263        --                        --
│    └─One: 2-2264                       [1]                       --
│    └─OutputScale: 2-2265               --                        --
│    └─Empty: 2-2266                     [128, 128, 3, 3]          --
│    └─Empty: 2-2267                     [128, 128, 3, 3]          --
│    └─Empty: 2-2268                     [128]                     --
│    └─Empty: 2-2269                     [128]                     --
│    └─BatchNorm2d: 2-2270               [16, 128, 64, 64]         (recursive)
│    └─Scaler: 2-2271                    [16, 128, 64, 64]         --
│    └─ReLU: 2-2272                      [16, 128, 64, 64]         --
│    └─Empty: 2-2273                     [16, 128, 64, 64]         --
│    └─Clamp: 2-2274                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2275                 [16, 128, 32, 32]         --
│    └─Empty: 2-2276                     [16, 128, 32, 32]         --
│    └─Empty: 2-2277                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2278        --                        --
│    └─One: 2-2279                       [1]                       --
│    └─OutputScale: 2-2280               --                        --
│    └─Empty: 2-2281                     [128, 128, 3, 3]          --
│    └─Empty: 2-2282                     [128, 128, 3, 3]          --
│    └─Empty: 2-2283                     [128]                     --
│    └─Empty: 2-2284                     [128]                     --
│    └─BatchNorm2d: 2-2285               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2286                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2287                      [16, 128, 32, 32]         --
│    └─Empty: 2-2288                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2289                     [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1-214               [16, 128, 32, 32]         (recursive)
│    └─OutputShiftSqueeze: 2-2290        --                        --
│    └─One: 2-2291                       [1]                       --
│    └─OutputScale: 2-2292               --                        --
│    └─Empty: 2-2293                     [128, 128, 1, 1]          --
│    └─Empty: 2-2294                     [128, 128, 1, 1]          --
│    └─Empty: 2-2295                     [128]                     --
│    └─Empty: 2-2296                     [128]                     --
│    └─BatchNorm2d: 2-2297               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2298                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2299                      [16, 128, 32, 32]         --
│    └─Empty: 2-2300                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2301                     [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-2302                 [16, 128, 32, 32]         --
│    └─Empty: 2-2303                     [16, 128, 32, 32]         --
│    └─Empty: 2-2304                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-2305        --                        --
│    └─One: 2-2306                       [1]                       --
│    └─OutputScale: 2-2307               --                        --
│    └─Empty: 2-2308                     [128, 128, 3, 3]          --
│    └─Empty: 2-2309                     [128, 128, 3, 3]          --
│    └─Empty: 2-2310                     [128]                     --
│    └─Empty: 2-2311                     [128]                     --
│    └─BatchNorm2d: 2-2312               [16, 128, 32, 32]         (recursive)
│    └─Scaler: 2-2313                    [16, 128, 32, 32]         --
│    └─ReLU: 2-2314                      [16, 128, 32, 32]         --
│    └─Empty: 2-2315                     [16, 128, 32, 32]         --
│    └─Clamp: 2-2316                     [16, 128, 32, 32]         --
├─Dropout2d: 1-216                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-217        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2317                 [16, 128, 16, 16]         --
│    └─Empty: 2-2318                     [16, 128, 16, 16]         --
│    └─Empty: 2-2319                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2320        --                        --
│    └─One: 2-2321                       [1]                       --
│    └─OutputScale: 2-2322               --                        --
│    └─Empty: 2-2323                     [128, 128, 3, 3]          --
│    └─Empty: 2-2324                     [128, 128, 3, 3]          --
│    └─Empty: 2-2325                     [128]                     --
│    └─Empty: 2-2326                     [128]                     --
│    └─BatchNorm2d: 2-2327               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2328                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2329                      [16, 128, 16, 16]         --
│    └─Empty: 2-2330                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2331                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-218               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-2332        --                        --
│    └─One: 2-2333                       [1]                       --
│    └─OutputScale: 2-2334               --                        --
│    └─Empty: 2-2335                     [128, 128, 1, 1]          --
│    └─Empty: 2-2336                     [128, 128, 1, 1]          --
│    └─Empty: 2-2337                     [128]                     --
│    └─Empty: 2-2338                     [128]                     --
│    └─BatchNorm2d: 2-2339               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2340                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2341                      [16, 128, 16, 16]         --
│    └─Empty: 2-2342                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2343                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-2344                 [16, 128, 16, 16]         --
│    └─Empty: 2-2345                     [16, 128, 16, 16]         --
│    └─Empty: 2-2346                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-2347        --                        --
│    └─One: 2-2348                       [1]                       --
│    └─OutputScale: 2-2349               --                        --
│    └─Empty: 2-2350                     [128, 128, 3, 3]          --
│    └─Empty: 2-2351                     [128, 128, 3, 3]          --
│    └─Empty: 2-2352                     [128]                     --
│    └─Empty: 2-2353                     [128]                     --
│    └─BatchNorm2d: 2-2354               [16, 128, 16, 16]         (recursive)
│    └─Scaler: 2-2355                    [16, 128, 16, 16]         --
│    └─ReLU: 2-2356                      [16, 128, 16, 16]         --
│    └─Empty: 2-2357                     [16, 128, 16, 16]         --
│    └─Clamp: 2-2358                     [16, 128, 16, 16]         --
├─Dropout2d: 1-220                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-2359                 [16, 128, 8, 8]           --
│    └─Empty: 2-2360                     [16, 128, 8, 8]           --
│    └─Empty: 2-2361                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2362        --                        --
│    └─One: 2-2363                       [1]                       --
│    └─OutputScale: 2-2364               --                        --
│    └─Empty: 2-2365                     [128, 128, 3, 3]          --
│    └─Empty: 2-2366                     [128, 128, 3, 3]          --
│    └─Empty: 2-2367                     [128]                     --
│    └─Empty: 2-2368                     [128]                     --
│    └─BatchNorm2d: 2-2369               [16, 128, 8, 8]           (recursive)
│    └─Scaler: 2-2370                    [16, 128, 8, 8]           --
│    └─ReLU: 2-2371                      [16, 128, 8, 8]           --
│    └─Empty: 2-2372                     [16, 128, 8, 8]           --
│    └─Clamp: 2-2373                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-222               [16, 2, 8, 8]             (recursive)
│    └─OutputShiftSqueeze: 2-2374        --                        --
│    └─One: 2-2375                       [1]                       --
│    └─OutputScale: 2-2376               --                        --
│    └─Empty: 2-2377                     [2, 128, 1, 1]            --
│    └─Empty: 2-2378                     [2, 128, 1, 1]            --
│    └─Empty: 2-2379                     [2]                       --
│    └─Empty: 2-2380                     [2]                       --
│    └─BatchNorm2d: 2-2381               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2382                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2383                      [16, 2, 8, 8]             --
│    └─Empty: 2-2384                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2385                     [16, 2, 8, 8]             --
├─FusedMaxPoolConv2dBNReLU: 1-223        [16, 2, 8, 8]             (recursive)
│    └─MaxPool2d: 2-2386                 [16, 128, 8, 8]           --
│    └─Empty: 2-2387                     [16, 128, 8, 8]           --
│    └─Empty: 2-2388                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-2389        --                        --
│    └─One: 2-2390                       [1]                       --
│    └─OutputScale: 2-2391               --                        --
│    └─Empty: 2-2392                     [2, 128, 3, 3]            --
│    └─Empty: 2-2393                     [2, 128, 3, 3]            --
│    └─Empty: 2-2394                     [2]                       --
│    └─Empty: 2-2395                     [2]                       --
│    └─BatchNorm2d: 2-2396               [16, 2, 8, 8]             (recursive)
│    └─Scaler: 2-2397                    [16, 2, 8, 8]             --
│    └─ReLU: 2-2398                      [16, 2, 8, 8]             --
│    └─Empty: 2-2399                     [16, 2, 8, 8]             --
│    └─Clamp: 2-2400                     [16, 2, 8, 8]             --
├─Dropout2d: 1-224                       [16, 2, 8, 8]             --
├─Linear: 1-225                          [16, 5]                   646
│    └─OutputShiftSqueeze: 2-2401        --                        --
│    └─One: 2-2402                       [1]                       --
│    └─OutputScale: 2-2403               --                        --
│    └─Empty: 2-2404                     [5, 128]                  --
│    └─Empty: 2-2405                     [5, 128]                  --
│    └─Empty: 2-2406                     [16, 5]                   --
│    └─Empty: 2-2407                     [16, 5]                   --
│    └─Clamp: 2-2408                     [16, 5]                   --
├─Linear: 1-226                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2409        --                        --
│    └─One: 2-2410                       [1]                       --
│    └─OutputScale: 2-2411               --                        --
│    └─Empty: 2-2412                     [5, 128]                  --
│    └─Empty: 2-2413                     [5, 128]                  --
│    └─Empty: 2-2414                     [16, 5]                   --
│    └─Empty: 2-2415                     [16, 5]                   --
│    └─Clamp: 2-2416                     [16, 5]                   --
├─Linear: 1-227                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2417        --                        --
│    └─One: 2-2418                       [1]                       --
│    └─OutputScale: 2-2419               --                        --
│    └─Empty: 2-2420                     [5, 128]                  --
│    └─Empty: 2-2421                     [5, 128]                  --
│    └─Empty: 2-2422                     [16, 5]                   --
│    └─Empty: 2-2423                     [16, 5]                   --
│    └─Clamp: 2-2424                     [16, 5]                   --
├─Linear: 1-228                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2425        --                        --
│    └─One: 2-2426                       [1]                       --
│    └─OutputScale: 2-2427               --                        --
│    └─Empty: 2-2428                     [5, 128]                  --
│    └─Empty: 2-2429                     [5, 128]                  --
│    └─Empty: 2-2430                     [16, 5]                   --
│    └─Empty: 2-2431                     [16, 5]                   --
│    └─Clamp: 2-2432                     [16, 5]                   --
├─Linear: 1-229                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2433        --                        --
│    └─One: 2-2434                       [1]                       --
│    └─OutputScale: 2-2435               --                        --
│    └─Empty: 2-2436                     [5, 128]                  --
│    └─Empty: 2-2437                     [5, 128]                  --
│    └─Empty: 2-2438                     [16, 5]                   --
│    └─Empty: 2-2439                     [16, 5]                   --
│    └─Clamp: 2-2440                     [16, 5]                   --
├─Linear: 1-230                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2441        --                        --
│    └─One: 2-2442                       [1]                       --
│    └─OutputScale: 2-2443               --                        --
│    └─Empty: 2-2444                     [5, 128]                  --
│    └─Empty: 2-2445                     [5, 128]                  --
│    └─Empty: 2-2446                     [16, 5]                   --
│    └─Empty: 2-2447                     [16, 5]                   --
│    └─Clamp: 2-2448                     [16, 5]                   --
├─Linear: 1-231                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2449        --                        --
│    └─One: 2-2450                       [1]                       --
│    └─OutputScale: 2-2451               --                        --
│    └─Empty: 2-2452                     [5, 128]                  --
│    └─Empty: 2-2453                     [5, 128]                  --
│    └─Empty: 2-2454                     [16, 5]                   --
│    └─Empty: 2-2455                     [16, 5]                   --
│    └─Clamp: 2-2456                     [16, 5]                   --
├─Linear: 1-232                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2457        --                        --
│    └─One: 2-2458                       [1]                       --
│    └─OutputScale: 2-2459               --                        --
│    └─Empty: 2-2460                     [5, 128]                  --
│    └─Empty: 2-2461                     [5, 128]                  --
│    └─Empty: 2-2462                     [16, 5]                   --
│    └─Empty: 2-2463                     [16, 5]                   --
│    └─Clamp: 2-2464                     [16, 5]                   --
├─Linear: 1-233                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2465        --                        --
│    └─One: 2-2466                       [1]                       --
│    └─OutputScale: 2-2467               --                        --
│    └─Empty: 2-2468                     [5, 128]                  --
│    └─Empty: 2-2469                     [5, 128]                  --
│    └─Empty: 2-2470                     [16, 5]                   --
│    └─Empty: 2-2471                     [16, 5]                   --
│    └─Clamp: 2-2472                     [16, 5]                   --
├─Linear: 1-234                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2473        --                        --
│    └─One: 2-2474                       [1]                       --
│    └─OutputScale: 2-2475               --                        --
│    └─Empty: 2-2476                     [5, 128]                  --
│    └─Empty: 2-2477                     [5, 128]                  --
│    └─Empty: 2-2478                     [16, 5]                   --
│    └─Empty: 2-2479                     [16, 5]                   --
│    └─Clamp: 2-2480                     [16, 5]                   --
├─Linear: 1-235                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2481        --                        --
│    └─One: 2-2482                       [1]                       --
│    └─OutputScale: 2-2483               --                        --
│    └─Empty: 2-2484                     [5, 128]                  --
│    └─Empty: 2-2485                     [5, 128]                  --
│    └─Empty: 2-2486                     [16, 5]                   --
│    └─Empty: 2-2487                     [16, 5]                   --
│    └─Clamp: 2-2488                     [16, 5]                   --
├─Linear: 1-236                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2489        --                        --
│    └─One: 2-2490                       [1]                       --
│    └─OutputScale: 2-2491               --                        --
│    └─Empty: 2-2492                     [5, 128]                  --
│    └─Empty: 2-2493                     [5, 128]                  --
│    └─Empty: 2-2494                     [16, 5]                   --
│    └─Empty: 2-2495                     [16, 5]                   --
│    └─Clamp: 2-2496                     [16, 5]                   --
├─Linear: 1-237                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2497        --                        --
│    └─One: 2-2498                       [1]                       --
│    └─OutputScale: 2-2499               --                        --
│    └─Empty: 2-2500                     [5, 128]                  --
│    └─Empty: 2-2501                     [5, 128]                  --
│    └─Empty: 2-2502                     [16, 5]                   --
│    └─Empty: 2-2503                     [16, 5]                   --
│    └─Clamp: 2-2504                     [16, 5]                   --
├─Linear: 1-238                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2505        --                        --
│    └─One: 2-2506                       [1]                       --
│    └─OutputScale: 2-2507               --                        --
│    └─Empty: 2-2508                     [5, 128]                  --
│    └─Empty: 2-2509                     [5, 128]                  --
│    └─Empty: 2-2510                     [16, 5]                   --
│    └─Empty: 2-2511                     [16, 5]                   --
│    └─Clamp: 2-2512                     [16, 5]                   --
├─Linear: 1-239                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2513        --                        --
│    └─One: 2-2514                       [1]                       --
│    └─OutputScale: 2-2515               --                        --
│    └─Empty: 2-2516                     [5, 128]                  --
│    └─Empty: 2-2517                     [5, 128]                  --
│    └─Empty: 2-2518                     [16, 5]                   --
│    └─Empty: 2-2519                     [16, 5]                   --
│    └─Clamp: 2-2520                     [16, 5]                   --
├─Linear: 1-240                          [16, 5]                   (recursive)
│    └─OutputShiftSqueeze: 2-2521        --                        --
│    └─One: 2-2522                       [1]                       --
│    └─OutputScale: 2-2523               --                        --
│    └─Empty: 2-2524                     [5, 128]                  --
│    └─Empty: 2-2525                     [5, 128]                  --
│    └─Empty: 2-2526                     [16, 5]                   --
│    └─Empty: 2-2527                     [16, 5]                   --
│    └─Clamp: 2-2528                     [16, 5]                   --
==========================================================================================
Total params: 930,132
Trainable params: 930,060
Non-trainable params: 72
Total mult-adds (M): 0.53
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 131.10
Params size (MB): 0.01
Estimated Total Size (MB): 332.44
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.592 | Acc: 21.125% | Wgt Acc: 24.875%
	I - Batch: 100 | Loss: 1.576 | Acc: 22.938% | Wgt Acc: 26.965%
	I - Batch: 150 | Loss: 1.549 | Acc: 23.875% | Wgt Acc: 28.106%
	I - Batch: 200 | Loss: 1.510 | Acc: 26.719% | Wgt Acc: 31.561%
I - num batch: 222
I - Train -- Loss: 1.494 | Acc: 27.460% | Wgt Acc: 32.351% | LR: 1.000000e-03 | Dur: 184.14s
I - Confusion Matrix: [row->prediction - col->label]
[[282. 114. 131. 205. 209.]
 [120. 229. 233.  71. 340.]
 [117. 166. 257.  63. 293.]
 [175.  66. 104. 197. 149.]
 [  3.   3.   9.   2.   9.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.512 | Acc: 25.049% | Wgt Acc: 31.878% | Dur: 16.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 36.   3.   3.  26.  10.]
 [ 20.  60.  58.  25. 131.]
 [ 18.  14.  12.  17.  29.]
 [ 14.   1.   2.  18.   9.]
 [  0.   0.   0.   0.   1.]]

I - Local maximum validation set accuracy:  25.05

I - Validation set results: 
[14-1-1-0.67][50-3-1-0.72][124-2-1-0.60][127-0-2-0.21][443-2-1-1.17][567-0-2-0.12][573-1-1-0.83][615-0-3-0.34][695-1-1-0.35][722-3-0-0.28]
[826-0-0-1.02][878-0-0-0.33][1103-0-2-0.46][1212-3-1-0.22][1368-0-2-0.64][2181-2-3-0.33][2476-2-1-0.69][2721-2-1-0.54][2818-1-2-0.75][2886-2-1-0.76]
[3231-2-1-1.07][3333-2-1-0.61][3482-2-1-0.44][3536-3-1-0.37][3625-1-1-0.82][3909-0-2-0.12][4035-0-1-0.05][4140-0-2-0.62][4214-1-0-1.00][4346-1-3-0.24]
[4581-2-2-0.77][4708-3-1-0.79][4838-3-1-0.95][4845-1-1-0.69][4868-0-0-1.02][4939-0-1-0.73][4984-2-2-0.14][5078-1-1-0.90][5396-0-0-1.83][5479-1-1-0.68]
[5717-0-2-0.38][5843-1-1-0.73][5949-3-3-0.62][5987-2-1-0.93][6014-3-1-0.36][6033-3-2-0.40][6313-0-0-0.22][6421-3-1-0.08][6500-1-1-0.76][6583-3-0-0.41]
[6683-3-1-0.58][6825-2-1-0.48][6998-3-1-0.69][7049-3-2-0.19][7517-1-1-0.82][7521-1-1--0.06][7528-1-1-0.36][7949-1-1-1.21][8135-1-1-0.41][8185-3-0-0.60]
[8269-3-2-0.79][8273-3-0-0.90][8543-3-3-1.33][8666-1-1-0.70][8672-0-0-1.62][8903-1-1-0.37][9001-2-1-0.90][9036-2-1-1.13][9281-3-1-0.78][9300-2-1-0.83]
[9571-0-1-0.26][9617-1-1-0.66][9644-2-1-0.92][9705-2-1--0.02][9801-0-3-0.45][9803-3-1-0.31][9865-3-0-0.02][9896-2-1-0.65][10314-1-2-0.67][10337-3-3-0.66]
[10403-0-2-0.46][10653-2-1-0.89][10704-2-1-0.36][10719-1-1-0.85][10727-1-2-0.49][10836-0-0-0.93][10969-2-2-0.05][11042-0-0-0.11][11088-1-1-1.03][11322-0-0-0.49]
[11398-2-0-0.12][11499-0-0-0.15][11502-3-2-0.34][11512-3-1-0.16][11608-1-1-1.21][11610-0-3-1.77][11692-0-0-0.38][11905-0-0-0.20][11993-1-2-0.70][12002-2-3-0.15]
[12052-0-0-0.22][12201-0-3-0.76][12235-2-1-1.02][12320-1-1-0.68][12377-2-1-0.84][12398-2-1-0.49][12503-1-2-0.85][12617-0-1-0.65][12685-3-3-0.14][12738-2-0-0.08]
[12742-2-1-1.03][12823-0-3-0.83][13110-1-1-0.87][13240-3-0-0.39][13253-1-1-0.73][13273-0-0-0.41][13634-1-1-0.65][13763-2-1-0.89][13905-3-0-0.25][14060-2-1-0.77]
[14065-3-3-1.04][14147-3-3-0.29][14595-2-1-0.77][14687-2-1-0.86][14788-2-1-0.61][14869-1-1-1.11][14872-3-2-0.42][14877-1-1-0.74][14927-0-0-0.39][15066-0-0-0.09]
[15175-1-1-0.86][15178-2-0-0.32][15375-3-1-0.08][15389-3-0-0.95][15568-2-1-0.90][15675-3-1-0.14][15869-1-2-0.74][16207-3-2-0.20][16236-0-1-0.21][16302-3-2-0.26]
[16331-2-1-0.95][16381-0-2-0.14][16488-1-1-0.52][16495-0-2-0.38][16650-0-1-0.04][16719-1-1-0.83][16801-0-3-0.46][16828-0-3-0.68][17137-3-1-0.08][17245-1-2-0.27]
[17278-3-1-0.32][17282-0-1-0.24][17311-2-2-0.68][17336-2-2-0.48][17608-3-0-1.12][17627-0-3-0.16][17877-3-1-0.70][17924-1-2-0.32][17984-3-0-0.78][18211-0-1-0.61]
[18276-3-0-0.11][18287-1-1-0.70][18394-0-0-0.83][18428-0-0-1.11][18442-0-3-0.38][18478-3-0-0.13][18607-0-1-0.68][18616-0-1-0.77][18663-0-1-0.16][18718-0-0-0.33]
[18766-2-1-0.94][18824-2-1-0.93][18890-3-2-0.68][18930-3-2-0.60][18938-3-3-0.23][19817-1-1-0.99][19839-0-3-0.08][19930-3-1-0.18][19944-0-1-0.32][20036-2-1-0.97]
[20101-3-3-0.28][20474-1-2-0.82][20547-3-2-0.51][20929-2-1-0.97][21245-1-2-0.71][21257-3-1-0.79][21293-1-1-0.82][21316-1-1-0.62][21384-1-1-1.04][21448-1-2-0.80]
[21483-0-0-0.62][21487-2-1-0.98][21714-0-0-0.54][21943-3-2-0.86][21947-0-1-0.44][21948-0-0-0.31][21965-2-1-1.21][21998-1-1-0.47][22025-0-1-0.80][22228-3-0-0.06]
[22446-1-1-0.92][22494-3-0-0.93][22757-0-0-2.16][22811-3-3-1.62][22976-3-1-0.96][22985-3-3-0.69][23014-0-0-0.72][23112-1-1-0.94][23144-3-3-1.41][23168-2-2-0.79]
[23219-0-2-0.32][23363-3-1-0.40][23470-0-1-0.37][23486-2-1-0.74][23497-0-3-1.60][23516-0-0-1.32][23690-1-1-1.03][23921-2-2-0.60][23936-1-1-0.93][24040-3-0-0.29]
[24111-1-1-0.93][24182-0-0-0.51][24238-3-3-1.03][24290-2-2-0.58][24345-0-2-0.21][24364-1-1-0.83][24427-3-1-0.41][24477-2-1-0.26][24495-2-2-0.51][24893-2-1-0.71]
[25012-1-1-0.83][25121-2-1-0.53][25165-3-2-0.47][25183-0-1-0.59][25297-3-3-0.07][25398-0-2-0.42][25574-2-1-1.06][25644-1-1-0.70][25718-1-1-0.80][25774-2-1-0.71]
[26032-3-0-0.89][26051-3-0-1.09][26120-0-0-0.33][26321-1-1-0.62][26732-1-1-0.74][26784-3-0-1.37][26827-3-2-0.18][26833-0-3-0.58][26838-2-1-0.48][26860-1-0-0.21]
[26948-0-2-0.47][27049-3-2-0.38][27098-1-0-0.20][27526-0-1-0.51][27639-3-2-0.17][27698-3-3-1.46][27772-0-0-0.96][27890-1-1-0.95][28040-0-2-0.48][28503-2-2-0.70]
[28577-1-1-0.67][28959-0-0-0.86][29198-3-1-0.95][29777-0-0-1.59][29877-2-1-0.73][30035-1-1-0.90][30098-0-2-0.24][30326-1-1-0.71][30572-2-1-0.82][30716-0-1-0.69]
[30806-2-1-0.12][30906-1-1-0.80][31007-0-0-0.19][31181-3-0-0.70][31238-0-3-0.44][31347-0-0-0.92][31422-2-1-0.54][31429-3-2-0.56][31431-0-0-0.75][31432-1-1-0.91]
[31477-0-3-1.34][31524-1-1-0.21][31597-1-1-0.87][31619-1-2-0.19][31701-0-0-1.15][31755-0-0-0.71][31854-3-3-0.16][32074-1-1-0.71][32078-3-3-0.50][32111-1-2-0.70]
[32127-1-1-1.22][32140-3-0-0.44][32263-2-1-0.60][32365-0-2-0.73][32411-2-1-0.20][32429-3-0-1.60][32473-3-0-1.21][32574-3-0-1.77][32584-0-2-0.46][32622-0-1-0.96]
[32858-3-0-1.33][32969-3-0-0.47][33016-2-2-0.91][33031-1-1-0.64][33035-2-1-0.87][33133-2-1-0.83][33173-2-1-0.55][33175-3-2-0.78][33306-3-1-0.66][33309-2-1-0.45]
[33474-0-1-0.49][33478-2-2-0.46][33618-1-1-0.91][33712-0-0--0.02][33782-2-1-1.20][33914-3-3--0.00][34076-3-3-0.17][34112-2-1-0.48][34138-2-1-0.61][34239-1-2-0.52]
[34364-2-1-0.92][34617-1-1-1.09][34751-3-0-0.45][34783-2-1-0.80][35015-3-1-0.32][35018-1-1-0.85][35288-2-1-0.58][0-4-1-0.80][1-4-0-0.08][2-4-1-0.72]
[3-4-1-1.08][4-4-1-0.30][5-4-1-0.86][6-4-2-0.45][7-4-1-0.99][8-4-1-0.16][9-4-2-0.85][10-4-1-0.84][11-4-1-0.54][12-4-1-0.61]
[14-4-3-0.44][15-4-3-0.97][16-4-1-0.83][17-4-1-0.38][18-4-1-1.04][19-4-3-1.04][20-4-1-0.35][21-4-1-1.01][22-4-1-0.77][23-4-2-0.58]
[24-4-2-0.67][25-4-3-0.30][26-4-1-0.44][27-4-0-0.03][28-4-1-0.64][29-4-1-0.82][30-4-2-0.61][31-4-1-0.54][32-4-2-1.21][33-4-1-0.47]
[34-4-1-0.13][35-4-3-0.07][37-4-2-0.09][39-4-2-0.36][40-4-2-0.15][41-4-1-1.07][42-4-1-0.62][43-4-1-0.63][45-4-1-0.92][46-4-1-1.09]
[47-4-1-0.98][48-4-1-1.01][51-4-1-1.03][52-4-2-0.47][53-4-1-0.76][54-4-1-0.68][55-4-1-0.37][56-4-1-1.00][57-4-3-0.33][58-4-1-1.17]
[59-4-1-0.45][60-4-1-0.64][61-4-1-0.74][62-4-0-0.28][63-4-1-0.80][64-4-1-0.59][65-4-1-0.93][66-4-1-1.04][67-4-2-0.31][68-4-1-0.62]
[69-4-2-0.31][70-4-1-0.99][72-4-1-0.48][73-4-1-0.91][74-4-2-0.31][75-4-1-0.68][77-4-1-0.94][78-4-1-0.68][79-4-1-0.81][80-4-1-0.84]
[81-4-1-0.95][82-4-2-0.67][83-4-1-0.66][84-4-1-0.96][85-4-1-1.08][86-4-4-0.15][87-4-1-0.74][88-4-1-0.78][89-4-1-0.89][90-4-1-0.74]
[91-4-2-0.57][92-4-1-0.29][93-4-2-0.71][94-4-1-0.99][95-4-1-0.57][96-4-1-1.08][97-4-2-0.77][98-4-2-0.98][99-4-1-0.46][100-4-1-0.76]
[101-4-1-1.00][102-4-1-1.05][103-4-2-0.12][104-4-1-1.04][105-4-1-0.90][106-4-1-0.87][107-4-1-0.43][108-4-2-0.56][109-4-1-0.53][110-4-1-0.80]
[111-4-0-0.70][112-4-1-0.89][113-4-1-0.70][114-4-0-0.24][115-4-2-0.50][116-4-1-0.71][117-4-1-0.93][119-4-1-0.53][121-4-1-1.01][122-4-1-0.42]
[124-4-1-0.67][125-4-1-0.88][126-4-1-0.50][127-4-1-0.89][128-4-2-0.22][129-4-1-0.47][130-4-1-0.77][131-4-1-0.26][132-4-1-0.09][133-4-1-0.35]
[135-4-1-0.52][136-4-1-0.61][137-4-1-0.52][138-4-0-0.28][139-4-2-0.60][140-4-1-0.42][141-4-3-0.71][142-4-1-1.09][143-4-1-1.02][144-4-2-0.31]
[145-4-1-1.17][148-4-0-0.64][149-4-1-0.15][150-4-1-1.09][151-4-1-0.78][152-4-1-1.00][153-4-1-0.86][154-4-1-0.93][155-4-1-0.82][156-4-1-0.44]
[157-4-2-0.29][158-4-1-0.17][160-4-1-0.43][161-4-3-0.22][162-4-1-0.59][164-4-1-0.55][165-4-1-0.68][167-4-1-0.84][168-4-2-0.73][170-4-1-0.25]
[171-4-1-0.31][172-4-1-0.78][173-4-1-0.74][174-4-0-0.24][175-4-1-0.60][177-4-0-0.15][178-4-2-0.52][179-4-1-0.14][180-4-1-0.79][181-4-3-0.38]
[182-4-1-0.23][183-4-1-0.82][184-4-2-0.41][186-4-1-0.62][187-4-1-0.86][188-4-1-0.36][189-4-1-0.23][190-4-1-0.86][191-4-1-0.74][192-4-1-0.25]
[193-4-1-0.76][194-4-1-0.95][195-4-0-0.39][196-4-1-0.81][197-4-1-1.05][198-4-1-0.90][199-4-2-0.35]
---------------------------
I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.335 | Acc: 34.875% | Wgt Acc: 40.697%
	I - Batch: 100 | Loss: 1.300 | Acc: 36.812% | Wgt Acc: 43.039%
	I - Batch: 150 | Loss: 1.287 | Acc: 36.375% | Wgt Acc: 42.690%
	I - Batch: 200 | Loss: 1.270 | Acc: 36.969% | Wgt Acc: 43.295%
I - num batch: 222
I - Train -- Loss: 1.268 | Acc: 36.735% | Wgt Acc: 42.987% | LR: 1.000000e-03 | Dur: 184.29s
I - Confusion Matrix: [row->prediction - col->label]
[[441.  22.  52. 205. 146.]
 [ 36. 318. 304.  49. 312.]
 [ 58. 186. 295.  55. 434.]
 [154.  47.  75. 229.  88.]
 [  8.   5.   8.   0.  20.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.392 | Acc: 34.911% | Wgt Acc: 42.522% | Dur: 18.91s
I - Confusion Matrix: [row->prediction - col->label]
[[33.  4.  3.  9. 14.]
 [ 4. 44. 36. 13. 77.]
 [ 4. 21. 28.  6. 45.]
 [44.  5.  7. 57. 29.]
 [ 3.  4.  1.  1. 15.]]

I - Local maximum validation set accuracy:  34.91

I - Validation set results: 
[14-1-2-0.71][50-3-3-0.23][124-2-1-0.80][127-0-3-2.64][443-2-2-1.43][567-0-0-1.36][573-1-1-0.85][615-0-3-1.05][695-1-4-0.21][722-3-3-1.97]
[826-0-3-1.56][878-0-3-1.55][1103-0-4-0.43][1212-3-3-0.28][1368-0-0-1.70][2181-2-3-0.67][2476-2-1-0.44][2721-2-1-1.08][2818-1-1-0.42][2886-2-1-1.19]
[3231-2-1-1.67][3333-2-3-0.86][3482-2-2-0.56][3536-3-3-1.79][3625-1-1-1.10][3909-0-3-0.48][4035-0-3-1.63][4140-0-0-0.74][4214-1-0-0.21][4346-1-0-0.94]
[4581-2-2-0.82][4708-3-1-0.24][4838-3-3-0.34][4845-1-2-1.55][4868-0-0-2.06][4939-0-4-0.32][4984-2-2-0.63][5078-1-1-0.67][5396-0-0-2.94][5479-1-1-0.99]
[5717-0-3-0.15][5843-1-1-1.13][5949-3-0-1.47][5987-2-1-0.81][6014-3-1-0.22][6033-3-0-1.13][6313-0-3-1.19][6421-3-3-1.04][6500-1-1-0.07][6583-3-3--0.02]
[6683-3-3-0.14][6825-2-3-0.32][6998-3-1-0.30][7049-3-3-0.25][7517-1-1-1.65][7521-1-1-0.08][7528-1-3-0.11][7949-1-2-0.77][8135-1-0-0.92][8185-3-3-1.32]
[8269-3-1-1.20][8273-3-3-1.80][8543-3-0-2.52][8666-1-3-0.22][8672-0-0-3.13][8903-1-1-0.19][9001-2-1-1.20][9036-2-1-1.22][9281-3-3-0.32][9300-2-1--0.05]
[9571-0-3-0.81][9617-1-1-0.75][9644-2-2-1.18][9705-2-2-0.24][9801-0-3-1.37][9803-3-3-1.20][9865-3-3-1.59][9896-2-2-1.19][10314-1-1-0.67][10337-3-3-1.82]
[10403-0-4-0.58][10653-2-1-0.62][10704-2-1-0.27][10719-1-1-1.14][10727-1-4-0.85][10836-0-3-2.93][10969-2-1-0.33][11042-0-0-1.74][11088-1-2-1.19][11322-0-0-2.13]
[11398-2-2-0.80][11499-0-3-0.30][11502-3-3-0.84][11512-3-1-0.17][11608-1-1-2.15][11610-0-3-1.99][11692-0-3-1.14][11905-0-0-2.79][11993-1-1-0.63][12002-2-3-1.06]
[12052-0-0-0.90][12201-0-3-1.84][12235-2-1-1.00][12320-1-0-0.33][12377-2-1-0.24][12398-2-3-1.06][12503-1-2-1.41][12617-0-1-0.51][12685-3-1-0.59][12738-2-1-0.60]
[12742-2-1-2.07][12823-0-3-2.00][13110-1-1-0.46][13240-3-3-1.26][13253-1-1-0.83][13273-0-0-2.41][13634-1-1-1.35][13763-2-1-0.53][13905-3-3-0.56][14060-2-1-0.86]
[14065-3-3-1.17][14147-3-2-0.23][14595-2-1-1.05][14687-2-2-0.95][14788-2-1-0.44][14869-1-1-1.33][14872-3-4-0.33][14877-1-2-1.01][14927-0-3-1.35][15066-0-3-2.89]
[15175-1-2-0.58][15178-2-3-1.14][15375-3-2-0.03][15389-3-3-1.88][15568-2-1-0.44][15675-3-3-1.86][15869-1-2-0.29][16207-3-3-0.88][16236-0-2-0.09][16302-3-2-0.59]
[16331-2-2-0.88][16381-0-0-1.44][16488-1-1-1.27][16495-0-0-0.38][16650-0-0-1.65][16719-1-2-0.39][16801-0-0-2.21][16828-0-3-1.10][17137-3-3--0.06][17245-1-2-0.44]
[17278-3-3-0.65][17282-0-2-0.08][17311-2-2-1.00][17336-2-1-1.53][17608-3-3-2.08][17627-0-3-0.16][17877-3-1-1.07][17924-1-2-0.24][17984-3-3-1.67][18211-0-3-1.47]
[18276-3-0-1.18][18287-1-1-0.95][18394-0-0-1.50][18428-0-0-0.03][18442-0-3-2.04][18478-3-0-1.35][18607-0-0-0.18][18616-0-3-0.60][18663-0-3-1.00][18718-0-3-1.76]
[18766-2-1-1.80][18824-2-2-0.45][18890-3-2-0.79][18930-3-2-0.42][18938-3-3-0.64][19817-1-2-0.72][19839-0-1-0.26][19930-3-3-0.45][19944-0-1-0.42][20036-2-2-0.89]
[20101-3-3-0.82][20474-1-1-1.29][20547-3-3-1.04][20929-2-2-0.97][21245-1-1-0.95][21257-3-0--0.14][21293-1-1-1.36][21316-1-1-1.21][21384-1-1-1.22][21448-1-1-0.73]
[21483-0-0-0.81][21487-2-2-1.27][21714-0-3-0.58][21943-3-1-0.37][21947-0-0-1.52][21948-0-0-2.42][21965-2-2-0.64][21998-1-1-0.46][22025-0-3-0.77][22228-3-3-1.64]
[22446-1-1-1.56][22494-3-3-1.72][22757-0-3-3.15][22811-3-3-0.77][22976-3-1-0.20][22985-3-3-2.05][23014-0-3-1.79][23112-1-1-1.09][23144-3-3-2.23][23168-2-0-0.94]
[23219-0-3-0.81][23363-3-3-1.42][23470-0-2-0.02][23486-2-1-0.52][23497-0-3-2.60][23516-0-3-2.77][23690-1-1-0.19][23921-2-1-1.11][23936-1-1-0.40][24040-3-2-0.76]
[24111-1-1-0.52][24182-0-3-2.21][24238-3-3-1.81][24290-2-0-0.73][24345-0-2--0.02][24364-1-2-0.42][24427-3-3-1.34][24477-2-2-0.74][24495-2-1-0.69][24893-2-1-0.93]
[25012-1-3--0.07][25121-2-4-0.46][25165-3-3-1.25][25183-0-3-1.06][25297-3-3-1.49][25398-0-0-0.26][25574-2-1-0.76][25644-1-1-0.76][25718-1-2-0.16][25774-2-2-1.06]
[26032-3-3-1.01][26051-3-3-2.49][26120-0-0-1.51][26321-1-2-0.29][26732-1-1-0.32][26784-3-3-2.63][26827-3-3-0.93][26833-0-3-1.90][26838-2-2-0.36][26860-1-4-0.35]
[26948-0-0-1.70][27049-3-3-1.10][27098-1-1-0.13][27526-0-0-1.82][27639-3-3-1.53][27698-3-3-2.02][27772-0-3-2.43][27890-1-1-0.92][28040-0-0-0.50][28503-2-1-1.41]
[28577-1-1-0.78][28959-0-0-2.73][29198-3-1-0.07][29777-0-0-2.92][29877-2-1-0.32][30035-1-1-1.07][30098-0-3-1.34][30326-1-1-0.48][30572-2-1-0.86][30716-0-0-0.17]
[30806-2-2-0.04][30906-1-1-0.67][31007-0-0-0.29][31181-3-3-0.64][31238-0-3-1.03][31347-0-3-1.94][31422-2-2-0.44][31429-3-3-0.56][31431-0-3-1.24][31432-1-1-0.75]
[31477-0-3-2.65][31524-1-3--0.00][31597-1-2-1.56][31619-1-2-0.01][31701-0-0-1.97][31755-0-3-0.43][31854-3-3-1.11][32074-1-2-0.38][32078-3-1-0.44][32111-1-4-0.60]
[32127-1-2-1.33][32140-3-3-1.24][32263-2-2-0.09][32365-0-0-0.19][32411-2-3-2.69][32429-3-0-2.32][32473-3-0-1.10][32574-3-3-2.93][32584-0-0-0.38][32622-0-1-0.62]
[32858-3-0-0.56][32969-3-3-1.74][33016-2-2-0.47][33031-1-3-0.36][33035-2-2-1.21][33133-2-2-0.76][33173-2-1-0.80][33175-3-1-1.30][33306-3-1-0.80][33309-2-1-0.67]
[33474-0-3-0.32][33478-2-0-0.75][33618-1-1-1.26][33712-0-3-1.06][33782-2-1-1.62][33914-3-3-1.20][34076-3-3-0.14][34112-2-1-0.37][34138-2-2-1.19][34239-1-2-1.14]
[34364-2-1-1.48][34617-1-2-0.36][34751-3-3-1.47][34783-2-2-0.83][35015-3-3-0.38][35018-1-1-0.95][35288-2-2-0.50][0-4-2-0.05][1-4-0-0.62][2-4-4-0.45]
[3-4-2-0.20][4-4-3-0.44][5-4-1-0.71][6-4-3-2.14][7-4-1-0.33][8-4-1-0.71][9-4-1-1.49][10-4-4-0.40][11-4-2-0.97][12-4-1-0.46]
[14-4-2--0.07][15-4-3-2.37][16-4-3--0.16][17-4-1-0.77][18-4-1-0.79][19-4-3-1.11][20-4-3-0.17][21-4-2-0.73][22-4-1-0.44][23-4-1-0.47]
[24-4-4-0.22][25-4-3-0.82][26-4-3-0.47][27-4-3-1.04][28-4-1-0.68][29-4-2-0.55][30-4-0-0.37][31-4-1-0.85][32-4-2-1.41][33-4-3-0.77]
[34-4-2-0.40][35-4-3-1.20][37-4-3-0.52][39-4-3-1.83][40-4-2-0.46][41-4-1-0.60][42-4-1-0.67][43-4-1-0.54][45-4-3-0.91][46-4-2-0.57]
[47-4-4-0.20][48-4-1-0.24][51-4-1-0.61][52-4-2-0.60][53-4-1-0.90][54-4-2-0.32][55-4-2-0.61][56-4-1-0.61][57-4-3-0.88][58-4-2-1.81]
[59-4-0-0.58][60-4-4-0.04][61-4-1-0.55][62-4-2-0.53][63-4-2-1.37][64-4-2-0.21][65-4-1-0.71][66-4-1-1.17][67-4-1-0.28][68-4-1-1.10]
[69-4-0-0.76][70-4-2-0.26][72-4-2-0.66][73-4-1-0.80][74-4-2-0.83][75-4-3-0.48][77-4-1-0.79][78-4-1-0.74][79-4-1-0.88][80-4-1-0.80]
[81-4-1-1.06][82-4-1-0.12][83-4-1-0.94][84-4-0-0.92][85-4-1-0.33][86-4-4-0.45][87-4-2-0.66][88-4-1--0.18][89-4-1-0.05][90-4-2-0.12]
[91-4-4-0.29][92-4-3-0.38][93-4-4-0.10][94-4-1-0.26][95-4-2-0.46][96-4-1-0.61][97-4-4-1.03][98-4-2-1.55][99-4-1-0.27][100-4-1-1.06]
[101-4-4-0.49][102-4-1-0.99][103-4-3-0.80][104-4-2-0.29][105-4-1-0.80][106-4-1-0.72][107-4-4-0.51][108-4-2-0.38][109-4-1-0.24][110-4-1-0.19]
[111-4-3-2.72][112-4-0-0.61][113-4-1-0.57][114-4-3-1.19][115-4-0-0.04][116-4-1-0.96][117-4-1-0.83][119-4-2-1.25][121-4-1-0.78][122-4-3-0.04]
[124-4-1-0.91][125-4-1-0.94][126-4-3-0.13][127-4-1-0.53][128-4-1-0.34][129-4-2-0.36][130-4-2-0.55][131-4-2-0.50][132-4-1-1.02][133-4-0-2.14]
[135-4-2-0.51][136-4-4-0.72][137-4-2-0.26][138-4-0-0.31][139-4-3-0.25][140-4-2-0.38][141-4-3-0.76][142-4-1-0.30][143-4-2-0.54][144-4-4-0.54]
[145-4-2-0.47][148-4-0-1.58][149-4-1-0.85][150-4-1-1.22][151-4-1-0.94][152-4-1-0.60][153-4-1-1.16][154-4-1-0.84][155-4-1--0.11][156-4-3-0.79]
[157-4-2-0.12][158-4-1-0.13][160-4-1-0.67][161-4-1-0.46][162-4-1-0.93][164-4-1-0.59][165-4-3-0.00][167-4-0-0.91][168-4-4-0.12][170-4-3-0.91]
[171-4-1-0.95][172-4-4-0.63][173-4-0-0.78][174-4-0-1.67][175-4-1-0.23][177-4-3-1.32][178-4-1-0.51][179-4-1-0.31][180-4-2-0.36][181-4-2-0.49]
[182-4-2-0.65][183-4-1-0.42][184-4-2-1.38][186-4-2-0.56][187-4-1-1.00][188-4-2-0.86][189-4-1-0.73][190-4-3-0.04][191-4-2--0.05][192-4-2-0.74]
[193-4-1-1.81][194-4-1-1.61][195-4-0-1.66][196-4-2-0.25][197-4-1-0.83][198-4-1-0.62][199-4-1-0.53]
---------------------------
I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 1.211 | Acc: 43.375% | Wgt Acc: 48.964%
	I - Batch: 100 | Loss: 1.215 | Acc: 43.188% | Wgt Acc: 48.781%
	I - Batch: 150 | Loss: 1.206 | Acc: 44.833% | Wgt Acc: 50.061%
	I - Batch: 200 | Loss: 1.208 | Acc: 44.656% | Wgt Acc: 49.692%
I - num batch: 222
I - Train -- Loss: 1.212 | Acc: 44.009% | Wgt Acc: 48.842% | LR: 1.000000e-03 | Dur: 181.97s
I - Confusion Matrix: [row->prediction - col->label]
[[416.  13.  29. 169. 127.]
 [ 24. 371. 246.  40. 304.]
 [ 33. 132. 330.  60. 271.]
 [181.  39.  85. 257. 111.]
 [ 43.  23.  44.  12. 187.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.406 | Acc: 37.870% | Wgt Acc: 39.028% | Dur: 16.21s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  7.  9. 55. 38.]
 [ 3. 33. 28.  5. 48.]
 [ 2. 20. 26.  6. 28.]
 [ 8.  6.  8. 16. 15.]
 [ 9. 12.  4.  4. 51.]]

I - Local maximum validation set accuracy:  37.87

I - Validation set results: 
[14-1-1-1.00][50-3-1-0.81][124-2-2-0.03][127-0-0-3.01][443-2-2-1.72][567-0-0-0.95][573-1-1-0.88][615-0-3-1.50][695-1-4-0.30][722-3-0-1.73]
[826-0-0-2.79][878-0-0-1.73][1103-0-4-0.53][1212-3-0-1.36][1368-0-0-1.39][2181-2-0-0.96][2476-2-1-0.80][2721-2-2-0.57][2818-1-2-0.26][2886-2-1-1.06]
[3231-2-1-1.35][3333-2-1-0.22][3482-2-2-0.10][3536-3-3-0.82][3625-1-1-1.48][3909-0-0-0.76][4035-0-0-2.16][4140-0-0-1.03][4214-1-0-0.73][4346-1-0-1.92]
[4581-2-2-0.56][4708-3-2-0.35][4838-3-1-0.27][4845-1-2-0.80][4868-0-0-2.91][4939-0-2-0.55][4984-2-0-1.22][5078-1-1-0.64][5396-0-0-3.84][5479-1-1-0.28]
[5717-0-0-0.67][5843-1-1-0.56][5949-3-0-2.25][5987-2-1-0.94][6014-3-0-0.75][6033-3-0-2.12][6313-0-0-1.07][6421-3-0-1.02][6500-1-3-0.27][6583-3-0-1.02]
[6683-3-0-0.20][6825-2-0-0.32][6998-3-2-0.49][7049-3-3-0.56][7517-1-1-1.11][7521-1-3-0.14][7528-1-3-0.84][7949-1-2-1.11][8135-1-0-0.66][8185-3-0-1.81]
[8269-3-4-0.39][8273-3-0-3.16][8543-3-0-3.29][8666-1-1-0.55][8672-0-0-3.65][8903-1-0-0.19][9001-2-1-1.46][9036-2-2-1.61][9281-3-3-0.03][9300-2-2-0.42]
[9571-0-0-0.98][9617-1-1-0.46][9644-2-2-0.62][9705-2-3-0.41][9801-0-0-2.17][9803-3-0-0.66][9865-3-0-2.62][9896-2-2-0.83][10314-1-2-0.83][10337-3-0-2.74]
[10403-0-4-0.45][10653-2-1-1.04][10704-2-1-0.20][10719-1-4-0.23][10727-1-4-0.84][10836-0-0-2.94][10969-2-0-0.77][11042-0-0-1.39][11088-1-4-0.78][11322-0-0-2.86]
[11398-2-4-0.17][11499-0-0-1.16][11502-3-0-0.42][11512-3-3-0.80][11608-1-1-2.17][11610-0-0-2.57][11692-0-0-2.04][11905-0-0-2.68][11993-1-2-0.54][12002-2-0-1.97]
[12052-0-0-0.66][12201-0-0-3.13][12235-2-1-1.21][12320-1-4-0.50][12377-2-1-0.67][12398-2-3-0.79][12503-1-2-0.74][12617-0-1-0.32][12685-3-3-0.41][12738-2-3-0.75]
[12742-2-1-1.24][12823-0-0-2.65][13110-1-2-0.56][13240-3-0-2.17][13253-1-1-0.80][13273-0-0-3.39][13634-1-3-0.39][13763-2-2-0.92][13905-3-0-1.08][14060-2-1-0.47]
[14065-3-0-2.17][14147-3-0-0.54][14595-2-4-0.53][14687-2-2-0.87][14788-2-2-0.61][14869-1-1-0.82][14872-3-4-0.60][14877-1-4-0.28][14927-0-3-1.63][15066-0-0-2.20]
[15175-1-2-0.46][15178-2-0-1.29][15375-3-3-0.07][15389-3-0-2.29][15568-2-1-0.48][15675-3-0-0.65][15869-1-2-0.49][16207-3-0-0.96][16236-0-0-0.67][16302-3-0-1.46]
[16331-2-2-0.64][16381-0-0-1.07][16488-1-1-0.51][16495-0-4-0.79][16650-0-0-2.56][16719-1-2-0.57][16801-0-0-2.83][16828-0-0-1.78][17137-3-0-1.02][17245-1-1-0.03]
[17278-3-0-0.40][17282-0-4-0.47][17311-2-2-0.52][17336-2-1-0.32][17608-3-0-2.82][17627-0-3-0.37][17877-3-0-0.43][17924-1-0-1.00][17984-3-0-2.31][18211-0-3-0.82]
[18276-3-0-1.63][18287-1-1-0.08][18394-0-0-2.67][18428-0-0-4.55][18442-0-0-2.31][18478-3-0-2.01][18607-0-0-0.30][18616-0-3-0.09][18663-0-0-0.27][18718-0-0-2.10]
[18766-2-2-0.71][18824-2-1-0.71][18890-3-2-0.85][18930-3-4-0.89][18938-3-0-1.60][19817-1-2-0.87][19839-0-0-0.48][19930-3-3-0.42][19944-0-1-0.62][20036-2-2-1.44]
[20101-3-0-1.40][20474-1-2-0.91][20547-3-4-0.17][20929-2-2-1.21][21245-1-2-0.45][21257-3-1-0.12][21293-1-1-0.91][21316-1-1-0.80][21384-1-3-0.18][21448-1-1-0.87]
[21483-0-0-1.66][21487-2-1-1.02][21714-0-0-1.18][21943-3-2-0.43][21947-0-4-0.34][21948-0-0-1.74][21965-2-2-1.01][21998-1-1-0.28][22025-0-3-0.99][22228-3-0-1.68]
[22446-1-1-1.30][22494-3-0-3.13][22757-0-0-3.54][22811-3-3-2.71][22976-3-2-0.47][22985-3-0-2.24][23014-0-0-3.36][23112-1-1-1.29][23144-3-0-3.30][23168-2-2-0.15]
[23219-0-0-0.53][23363-3-3-1.12][23470-0-4-0.50][23486-2-3-0.59][23497-0-0-2.97][23516-0-3-1.41][23690-1-1-0.90][23921-2-1-0.71][23936-1-3-0.29][24040-3-0-1.07]
[24111-1-4-0.89][24182-0-0-3.32][24238-3-3-2.32][24290-2-0-0.92][24345-0-0-1.43][24364-1-2-0.19][24427-3-0-1.63][24477-2-1-0.23][24495-2-1-0.16][24893-2-2-0.65]
[25012-1-2--0.03][25121-2-4-0.97][25165-3-0-1.35][25183-0-0-0.35][25297-3-3-1.12][25398-0-0-0.68][25574-2-1-0.64][25644-1-1-0.29][25718-1-0-0.41][25774-2-2-0.31]
[26032-3-0-1.55][26051-3-0-2.37][26120-0-4-0.21][26321-1-2-0.24][26732-1-2-0.65][26784-3-0-3.65][26827-3-0-1.24][26833-0-3-2.05][26838-2-1-0.00][26860-1-4-0.36]
[26948-0-0-1.05][27049-3-0-1.60][27098-1-4-0.10][27526-0-0-1.27][27639-3-3-0.71][27698-3-0-2.70][27772-0-0-3.14][27890-1-1-1.09][28040-0-4-0.69][28503-2-2-1.08]
[28577-1-1-1.10][28959-0-0-3.99][29198-3-1-0.24][29777-0-0-4.11][29877-2-2-0.50][30035-1-2-0.83][30098-0-0-1.24][30326-1-1-0.83][30572-2-2-0.36][30716-0-1-0.34]
[30806-2-3-0.52][30906-1-4-0.88][31007-0-0-0.29][31181-3-0-2.43][31238-0-0-2.20][31347-0-0-2.89][31422-2-1-0.55][31429-3-0-1.10][31431-0-0-2.70][31432-1-1-0.86]
[31477-0-0-3.38][31524-1-4--0.07][31597-1-1-0.58][31619-1-0-0.85][31701-0-0-3.21][31755-0-0-1.84][31854-3-3-1.21][32074-1-1-0.66][32078-3-3-1.62][32111-1-4-0.74]
[32127-1-2-1.32][32140-3-0-1.86][32263-2-4-0.49][32365-0-4-0.20][32411-2-3-1.97][32429-3-0-3.18][32473-3-0-1.89][32574-3-0-3.77][32584-0-0-0.82][32622-0-2-0.01]
[32858-3-0-3.58][32969-3-0-2.20][33016-2-2-0.68][33031-1-1-0.14][33035-2-2-0.59][33133-2-1-0.81][33173-2-3-0.06][33175-3-1-0.74][33306-3-2-0.66][33309-2-0-0.08]
[33474-0-0-0.38][33478-2-0-1.62][33618-1-1-0.57][33712-0-0-1.17][33782-2-1-1.55][33914-3-3-1.41][34076-3-0-1.65][34112-2-1-0.59][34138-2-1-0.41][34239-1-2-0.23]
[34364-2-1-1.16][34617-1-1-0.74][34751-3-3-2.08][34783-2-1-0.38][35015-3-0-1.00][35018-1-1-0.76][35288-2-3-0.65][0-4-1-0.71][1-4-0-0.98][2-4-4-0.40]
[3-4-2-0.74][4-4-3-0.27][5-4-1-0.79][6-4-4-0.12][7-4-1-1.07][8-4-3-0.18][9-4-4-0.83][10-4-4-0.69][11-4-2-0.27][12-4-3-0.33]
[14-4-0-1.32][15-4-0-2.49][16-4-2-0.28][17-4-3--0.07][18-4-4-0.72][19-4-3-2.17][20-4-4-0.37][21-4-1-0.58][22-4-4-0.72][23-4-1-0.25]
[24-4-2-0.08][25-4-0-1.47][26-4-1-0.01][27-4-0-1.92][28-4-2-0.40][29-4-1-0.79][30-4-4-0.65][31-4-1-0.31][32-4-4-1.03][33-4-0-0.43]
[34-4-0-1.36][35-4-0-1.72][37-4-0-0.91][39-4-0-1.65][40-4-4-0.28][41-4-1-0.24][42-4-4-0.42][43-4-1-0.31][45-4-2-0.13][46-4-2-0.56]
[47-4-4-0.86][48-4-2-0.39][51-4-4-0.88][52-4-4-0.31][53-4-2-0.35][54-4-4-0.19][55-4-0-1.25][56-4-4-0.82][57-4-0-1.40][58-4-2-1.22]
[59-4-4--0.09][60-4-1--0.01][61-4-4-0.56][62-4-0-1.11][63-4-2-1.16][64-4-2-0.53][65-4-1-0.86][66-4-4-1.18][67-4-0-0.20][68-4-1-1.17]
[69-4-0-0.55][70-4-2-0.67][72-4-4-0.74][73-4-1-1.03][74-4-4-0.01][75-4-2--0.04][77-4-1-1.00][78-4-1-0.18][79-4-1-0.74][80-4-1-0.87]
[81-4-2-1.22][82-4-2-0.10][83-4-1-0.65][84-4-1-0.72][85-4-1-0.47][86-4-4-0.17][87-4-1-0.54][88-4-4-0.39][89-4-3-0.14][90-4-4-0.44]
[91-4-4-0.74][92-4-3-0.15][93-4-0-0.49][94-4-1-0.44][95-4-1--0.10][96-4-4-0.43][97-4-4-0.99][98-4-2-1.22][99-4-4-0.54][100-4-2-0.36]
[101-4-1-0.88][102-4-4-0.46][103-4-0-0.89][104-4-4-0.52][105-4-1-0.76][106-4-2-0.51][107-4-4-0.36][108-4-2-0.29][109-4-1-0.04][110-4-1-0.72]
[111-4-0-3.16][112-4-4-0.62][113-4-1-0.01][114-4-0-1.59][115-4-4--0.01][116-4-1-0.68][117-4-1-0.62][119-4-2-0.75][121-4-1-1.29][122-4-3-0.52]
[124-4-1-0.10][125-4-1-0.71][126-4-3-0.22][127-4-2-0.40][128-4-0-0.58][129-4-4-0.36][130-4-4-0.47][131-4-0-0.75][132-4-0-0.92][133-4-0-2.35]
[135-4-2-0.18][136-4-4-0.30][137-4-1-0.31][138-4-0-1.17][139-4-0-0.72][140-4-4-0.36][141-4-0-2.58][142-4-4-0.76][143-4-4-1.12][144-4-4-1.39]
[145-4-1-1.23][148-4-0-1.99][149-4-0-0.44][150-4-1-1.15][151-4-4-1.24][152-4-1-1.56][153-4-1-0.79][154-4-1-1.06][155-4-1-0.62][156-4-0-0.35]
[157-4-0-0.96][158-4-3-1.00][160-4-1-0.13][161-4-3-0.05][162-4-4-0.44][164-4-2-0.52][165-4-4-0.40][167-4-0-0.47][168-4-4-0.36][170-4-0-2.79]
[171-4-3--0.24][172-4-1-1.18][173-4-1-0.53][174-4-0-1.47][175-4-4-0.31][177-4-0-2.03][178-4-4-0.46][179-4-0--0.15][180-4-4-0.93][181-4-3-0.43]
[182-4-3-0.77][183-4-1-0.62][184-4-4-0.68][186-4-2-0.01][187-4-1-0.72][188-4-2-0.44][189-4-4-0.41][190-4-1-0.80][191-4-0-0.14][192-4-3-0.39]
[193-4-2-0.28][194-4-0-0.92][195-4-0-0.68][196-4-2-0.55][197-4-1-0.85][198-4-4-0.66][199-4-4-0.36]
---------------------------
I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 1.194 | Acc: 44.625% | Wgt Acc: 49.153%
	I - Batch: 100 | Loss: 1.215 | Acc: 44.562% | Wgt Acc: 48.632%
	I - Batch: 150 | Loss: 1.196 | Acc: 45.583% | Wgt Acc: 49.683%
	I - Batch: 200 | Loss: 1.193 | Acc: 46.344% | Wgt Acc: 50.276%
I - num batch: 222
I - Train -- Loss: 1.187 | Acc: 46.462% | Wgt Acc: 50.413% | LR: 1.000000e-03 | Dur: 188.68s
I - Confusion Matrix: [row->prediction - col->label]
[[445.  13.  38. 160. 139.]
 [ 22. 318. 205.  41. 234.]
 [ 32. 166. 377.  53. 287.]
 [153.  44.  68. 271. 103.]
 [ 45.  37.  46.  13. 237.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.337 | Acc: 42.209% | Wgt Acc: 43.832% | Dur: 19.23s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  6.  5. 41. 33.]
 [ 3. 33. 17.  5. 36.]
 [ 3. 25. 36.  9. 44.]
 [ 8.  5. 10. 26. 11.]
 [11.  9.  7.  5. 56.]]

I - Local maximum validation set accuracy:  42.21

I - Validation set results: 
[14-1-1-1.12][50-3-1-0.47][124-2-2-0.49][127-0-0-1.85][443-2-2-1.63][567-0-0-1.02][573-1-1-0.89][615-0-3-0.61][695-1-4-0.46][722-3-3-1.02]
[826-0-0-2.13][878-0-0-1.97][1103-0-4-0.39][1212-3-3-0.34][1368-0-4-0.39][2181-2-3-0.15][2476-2-1-0.40][2721-2-2-1.11][2818-1-4-0.42][2886-2-1-1.03]
[3231-2-1-1.74][3333-2-1-0.67][3482-2-2-0.66][3536-3-3-1.29][3625-1-1-1.38][3909-0-0-1.06][4035-0-0-1.59][4140-0-0-1.20][4214-1-0-0.19][4346-1-0-1.02]
[4581-2-2-1.30][4708-3-1-0.27][4838-3-1-0.33][4845-1-2-1.22][4868-0-0-1.86][4939-0-2-0.67][4984-2-2-0.21][5078-1-4-1.03][5396-0-0-3.89][5479-1-1-0.46]
[5717-0-0-1.34][5843-1-1-0.81][5949-3-0-2.08][5987-2-1-1.06][6014-3-0--0.14][6033-3-0-0.42][6313-0-3-0.37][6421-3-3-0.03][6500-1-3-0.12][6583-3-3-0.34]
[6683-3-3--0.02][6825-2-3-0.03][6998-3-2-0.57][7049-3-3-0.20][7517-1-1-1.29][7521-1-1-0.08][7528-1-3-0.56][7949-1-2-1.18][8135-1-0-1.48][8185-3-0-1.17]
[8269-3-4-0.76][8273-3-0-2.48][8543-3-0-3.54][8666-1-1-0.29][8672-0-0-3.77][8903-1-2-0.51][9001-2-1-0.81][9036-2-2-1.34][9281-3-2-0.07][9300-2-4-0.22]
[9571-0-0-0.35][9617-1-1-0.46][9644-2-2-1.14][9705-2-3--0.07][9801-0-0-2.05][9803-3-0-1.00][9865-3-0-1.31][9896-2-2-1.49][10314-1-2-0.76][10337-3-0-2.52]
[10403-0-2-0.37][10653-2-1-0.62][10704-2-3-0.18][10719-1-1-1.11][10727-1-2-0.68][10836-0-0-2.89][10969-2-3-0.47][11042-0-0-1.93][11088-1-2-1.00][11322-0-0-3.13]
[11398-2-2-1.01][11499-0-0-0.97][11502-3-0-0.54][11512-3-3-0.34][11608-1-1-1.45][11610-0-0-2.11][11692-0-3-1.00][11905-0-0-2.44][11993-1-2-0.77][12002-2-3-0.76]
[12052-0-0-0.92][12201-0-0-2.35][12235-2-1-1.39][12320-1-4-0.41][12377-2-2-0.74][12398-2-3-0.52][12503-1-4-1.25][12617-0-1-0.21][12685-3-2-0.41][12738-2-2-0.32]
[12742-2-2-1.21][12823-0-0-1.79][13110-1-1-0.45][13240-3-0-2.03][13253-1-1-0.77][13273-0-0-3.49][13634-1-2-0.74][13763-2-2-0.53][13905-3-4-0.00][14060-2-1-0.31]
[14065-3-0-1.51][14147-3-0-0.72][14595-2-4-0.76][14687-2-2-1.12][14788-2-2-1.08][14869-1-1-1.57][14872-3-4-1.07][14877-1-2-0.85][14927-0-3-0.63][15066-0-0-3.14]
[15175-1-2-1.12][15178-2-0-1.08][15375-3-0-0.83][15389-3-0-1.19][15568-2-1-0.61][15675-3-3-1.25][15869-1-2-0.67][16207-3-0-0.50][16236-0-2-0.20][16302-3-3-0.47]
[16331-2-2-0.99][16381-0-0-1.93][16488-1-1-1.23][16495-0-4-0.71][16650-0-0-2.60][16719-1-2-0.79][16801-0-0-2.70][16828-0-0-1.53][17137-3-0-0.59][17245-1-2-0.60]
[17278-3-0--0.29][17282-0-4-0.30][17311-2-2-1.09][17336-2-1-1.20][17608-3-0-2.88][17627-0-0-0.75][17877-3-2-1.04][17924-1-0-0.60][17984-3-0-2.43][18211-0-3-0.46]
[18276-3-0-1.62][18287-1-1-0.25][18394-0-0-2.57][18428-0-0-2.08][18442-0-0-2.52][18478-3-0-1.55][18607-0-4-0.41][18616-0-3-0.23][18663-0-0-0.23][18718-0-0-1.92]
[18766-2-1-1.16][18824-2-2-0.63][18890-3-2-1.10][18930-3-4-0.65][18938-3-0-0.90][19817-1-2-1.14][19839-0-4-0.52][19930-3-3-0.22][19944-0-1-1.21][20036-2-2-1.71]
[20101-3-0-1.35][20474-1-2-1.12][20547-3-0-0.51][20929-2-2-0.88][21245-1-1-0.88][21257-3-2-0.85][21293-1-1-1.19][21316-1-3--0.12][21384-1-2-1.21][21448-1-1-0.40]
[21483-0-0-1.24][21487-2-1-1.15][21714-0-0-0.51][21943-3-2-0.94][21947-0-0-1.01][21948-0-0-2.25][21965-2-2-1.30][21998-1-1-0.23][22025-0-3-0.38][22228-3-0-2.21]
[22446-1-1-1.42][22494-3-0-2.46][22757-0-0-3.45][22811-3-3-1.04][22976-3-4-0.21][22985-3-0-1.99][23014-0-0-2.54][23112-1-1-1.23][23144-3-0-2.70][23168-2-4-0.29]
[23219-0-0-0.60][23363-3-3-1.10][23470-0-0-0.75][23486-2-2-0.40][23497-0-0-2.66][23516-0-0-2.60][23690-1-1-0.83][23921-2-2-0.99][23936-1-3-0.23][24040-3-2-0.36]
[24111-1-4-1.16][24182-0-0-3.20][24238-3-3-1.62][24290-2-0-0.59][24345-0-0-1.47][24364-1-2-1.13][24427-3-0-1.77][24477-2-2-0.79][24495-2-1-0.22][24893-2-2-1.54]
[25012-1-4--0.04][25121-2-4-0.73][25165-3-3-0.58][25183-0-0-0.37][25297-3-3-0.84][25398-0-4-0.32][25574-2-2-0.67][25644-1-1-1.38][25718-1-0-0.00][25774-2-3-0.79]
[26032-3-0-2.00][26051-3-0-1.78][26120-0-4-0.23][26321-1-2-0.20][26732-1-2-0.71][26784-3-3-1.69][26827-3-3-0.98][26833-0-0-1.90][26838-2-2-0.44][26860-1-4-0.89]
[26948-0-4-0.16][27049-3-3-0.45][27098-1-1-0.20][27526-0-0-1.78][27639-3-3-0.45][27698-3-0-1.89][27772-0-0-3.12][27890-1-1-0.91][28040-0-0-0.88][28503-2-2-1.46]
[28577-1-1-1.32][28959-0-0-3.06][29198-3-1-0.15][29777-0-0-3.40][29877-2-2-0.82][30035-1-2-1.31][30098-0-0-1.34][30326-1-1-0.83][30572-2-3-0.34][30716-0-4-0.30]
[30806-2-3--0.12][30906-1-4-1.07][31007-0-0-1.00][31181-3-0-0.83][31238-0-0-1.74][31347-0-0-2.31][31422-2-4-0.51][31429-3-0-0.63][31431-0-3-0.97][31432-1-1-0.87]
[31477-0-0-2.65][31524-1-0-0.21][31597-1-2-0.63][31619-1-2-0.25][31701-0-0-2.46][31755-0-0-1.78][31854-3-3-1.35][32074-1-2-0.62][32078-3-3-1.02][32111-1-1-0.99]
[32127-1-2-1.64][32140-3-0-0.85][32263-2-0-0.13][32365-0-4-0.30][32411-2-0-1.53][32429-3-0-3.46][32473-3-0-1.59][32574-3-0-4.16][32584-0-0-0.81][32622-0-1-1.06]
[32858-3-0-2.81][32969-3-0-1.65][33016-2-2-2.21][33031-1-3--0.02][33035-2-2-1.15][33133-2-2-1.11][33173-2-1-0.05][33175-3-1-0.53][33306-3-2-0.97][33309-2-4-0.01]
[33474-0-0-0.42][33478-2-0-1.17][33618-1-1-1.26][33712-0-0-1.67][33782-2-2-1.33][33914-3-3-1.07][34076-3-3-0.81][34112-2-1-0.67][34138-2-2-0.92][34239-1-2-0.65]
[34364-2-1-1.40][34617-1-1-0.97][34751-3-3-1.44][34783-2-4-0.64][35015-3-3-0.56][35018-1-1-1.21][35288-2-2-0.23][0-4-4-1.25][1-4-0-0.72][2-4-4-0.53]
[3-4-2-0.89][4-4-3-0.22][5-4-1-0.83][6-4-4-0.55][7-4-4-0.13][8-4-2-0.80][9-4-4-1.12][10-4-0-0.39][11-4-2-1.38][12-4-1-0.51]
[14-4-0-1.08][15-4-0-2.64][16-4-2-0.20][17-4-1-0.21][18-4-4-1.13][19-4-0-1.70][20-4-0-0.43][21-4-1-0.71][22-4-4-0.93][23-4-1-0.07]
[24-4-4-0.78][25-4-0-1.03][26-4-4--0.20][27-4-0-1.91][28-4-4-1.06][29-4-2-0.63][30-4-2-1.03][31-4-1-1.04][32-4-4-1.43][33-4-3-0.28]
[34-4-0-0.32][35-4-3-0.55][37-4-2-0.10][39-4-0-2.11][40-4-2-0.34][41-4-2-0.13][42-4-3-1.10][43-4-1-0.35][45-4-2-0.87][46-4-2-1.07]
[47-4-4-0.94][48-4-2-0.77][51-4-4-0.97][52-4-4-0.73][53-4-2-1.11][54-4-2-0.35][55-4-0-0.54][56-4-1-1.48][57-4-0-2.10][58-4-2-1.65]
[59-4-4--0.17][60-4-1-0.25][61-4-1-0.63][62-4-3-0.05][63-4-2-1.44][64-4-2-0.90][65-4-4-1.13][66-4-4-1.27][67-4-4-0.14][68-4-1-1.10]
[69-4-0-0.63][70-4-4-0.66][72-4-4-0.59][73-4-1-1.17][74-4-2-0.44][75-4-2--0.07][77-4-1-0.96][78-4-1-0.30][79-4-1-0.90][80-4-1-0.86]
[81-4-4-1.38][82-4-4-0.55][83-4-1-0.73][84-4-4-0.30][85-4-2-0.58][86-4-4-0.55][87-4-4-0.94][88-4-4-0.64][89-4-2-0.67][90-4-4-1.07]
[91-4-4-0.66][92-4-3-0.60][93-4-4-0.34][94-4-4-0.85][95-4-2-0.81][96-4-1-1.11][97-4-1-1.36][98-4-2-1.52][99-4-4-0.52][100-4-1-0.76]
[101-4-2-0.69][102-4-2-1.03][103-4-0-0.58][104-4-4-0.73][105-4-4-1.10][106-4-1-0.75][107-4-4-0.84][108-4-2-0.59][109-4-3--0.01][110-4-1-0.57]
[111-4-0-2.78][112-4-4-0.68][113-4-1--0.03][114-4-0-0.93][115-4-0-0.41][116-4-1-0.54][117-4-1-1.18][119-4-2-2.08][121-4-1-1.16][122-4-3-0.32]
[124-4-2-0.27][125-4-1-1.08][126-4-3-0.16][127-4-2-0.92][128-4-4-0.33][129-4-0-0.55][130-4-4-0.89][131-4-2-0.47][132-4-0-0.25][133-4-0-2.89]
[135-4-2-0.87][136-4-4-0.28][137-4-4-0.34][138-4-0-0.65][139-4-0-0.36][140-4-2-0.83][141-4-0-1.34][142-4-4-1.23][143-4-4-1.25][144-4-4-1.04]
[145-4-1-1.34][148-4-0-1.29][149-4-2-0.58][150-4-1-1.07][151-4-2-0.82][152-4-1-1.32][153-4-1-1.34][154-4-2-1.71][155-4-4-0.25][156-4-0-0.34]
[157-4-0-1.13][158-4-0-0.61][160-4-1-0.02][161-4-1-0.74][162-4-4-0.41][164-4-2-0.56][165-4-4-0.39][167-4-0-0.65][168-4-4-0.48][170-4-0-1.91]
[171-4-4--0.03][172-4-4-0.84][173-4-4-0.57][174-4-0-1.30][175-4-4-0.45][177-4-0-1.80][178-4-4-0.69][179-4-0-0.04][180-4-4-0.87][181-4-3-0.57]
[182-4-3-0.22][183-4-2-0.34][184-4-1-0.95][186-4-0-0.13][187-4-1-1.05][188-4-2-0.72][189-4-4-0.99][190-4-2-0.16][191-4-4-0.85][192-4-2-0.69]
[193-4-2-1.14][194-4-2--0.14][195-4-4-0.05][196-4-2-0.96][197-4-2-1.21][198-4-4-0.82][199-4-1-0.55]
---------------------------
I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 1.167 | Acc: 47.500% | Wgt Acc: 51.461%
	I - Batch: 100 | Loss: 1.153 | Acc: 48.562% | Wgt Acc: 52.598%
	I - Batch: 150 | Loss: 1.158 | Acc: 48.458% | Wgt Acc: 52.086%
	I - Batch: 200 | Loss: 1.145 | Acc: 48.906% | Wgt Acc: 52.488%
I - num batch: 222
I - Train -- Loss: 1.145 | Acc: 48.886% | Wgt Acc: 52.526% | LR: 1.000000e-03 | Dur: 182.15s
I - Confusion Matrix: [row->prediction - col->label]
[[461.  14.  28. 157. 164.]
 [ 23. 330. 190.  45. 207.]
 [ 35. 150. 396.  51. 260.]
 [143.  38.  62. 272.  94.]
 [ 35.  46.  58.  13. 275.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.405 | Acc: 43.590% | Wgt Acc: 47.817% | Dur: 15.89s
I - Confusion Matrix: [row->prediction - col->label]
[[43.  3.  4. 10. 28.]
 [ 3. 29. 14.  2. 28.]
 [ 0. 25. 33.  8. 31.]
 [37. 14. 19. 65. 42.]
 [ 5.  7.  5.  1. 51.]]

I - Local maximum validation set accuracy:  43.59

I - Validation set results: 
[14-1-2-0.85][50-3-3-0.23][124-2-2-1.32][127-0-0-4.18][443-2-2-1.70][567-0-0-2.64][573-1-1--0.24][615-0-0-2.84][695-1-4--0.04][722-3-3-2.94]
[826-0-3-2.27][878-0-0-2.13][1103-0-4-0.47][1212-3-3-0.97][1368-0-0-2.86][2181-2-3-0.81][2476-2-1-0.34][2721-2-2-1.53][2818-1-3--0.01][2886-2-2-1.13]
[3231-2-1-1.36][3333-2-3-1.07][3482-2-2-0.97][3536-3-3-1.64][3625-1-1-1.42][3909-0-3-1.03][4035-0-3-1.92][4140-0-0-1.51][4214-1-3-0.40][4346-1-0-2.11]
[4581-2-2-1.60][4708-3-3-0.43][4838-3-0-1.00][4845-1-2-1.14][4868-0-0-3.28][4939-0-4-0.49][4984-2-3-0.75][5078-1-4-0.46][5396-0-0-4.38][5479-1-1-0.94]
[5717-0-0-1.00][5843-1-1-1.19][5949-3-0-2.89][5987-2-4-0.89][6014-3-3-0.72][6033-3-0-1.39][6313-0-3-2.17][6421-3-3-1.84][6500-1-3-0.01][6583-3-3-0.79]
[6683-3-3-0.90][6825-2-3-0.99][6998-3-3-0.24][7049-3-3-0.44][7517-1-1-1.76][7521-1-3-0.37][7528-1-3-0.63][7949-1-2-0.77][8135-1-0-1.52][8185-3-3-1.87]
[8269-3-2-1.05][8273-3-3-2.12][8543-3-0-3.75][8666-1-3-0.23][8672-0-0-2.89][8903-1-1-0.31][9001-2-1-1.18][9036-2-2-1.94][9281-3-3-0.72][9300-2-4--0.34]
[9571-0-0-1.60][9617-1-1-0.21][9644-2-2-1.18][9705-2-3-0.01][9801-0-3-2.05][9803-3-3-1.78][9865-3-3-2.19][9896-2-2-1.17][10314-1-1-0.85][10337-3-3-2.30]
[10403-0-0-0.67][10653-2-2-0.36][10704-2-3-0.66][10719-1-1-1.14][10727-1-4-0.79][10836-0-3-3.59][10969-2-3-0.62][11042-0-0-2.16][11088-1-2-1.48][11322-0-0-3.83]
[11398-2-2-1.11][11499-0-3-0.83][11502-3-3-1.36][11512-3-3--0.03][11608-1-1-1.20][11610-0-3-2.01][11692-0-3-2.29][11905-0-0-3.60][11993-1-2-1.05][12002-2-3-3.24]
[12052-0-0-1.79][12201-0-3-2.22][12235-2-1-1.12][12320-1-0-1.60][12377-2-4-0.57][12398-2-3-1.23][12503-1-1-0.63][12617-0-1-0.80][12685-3-2-0.88][12738-2-2-0.13]
[12742-2-2-1.44][12823-0-3-2.50][13110-1-3-0.10][13240-3-3-2.00][13253-1-1-0.73][13273-0-0-4.27][13634-1-1-0.86][13763-2-3-0.90][13905-3-3-1.47][14060-2-1-1.12]
[14065-3-3-2.76][14147-3-3-0.49][14595-2-2-0.83][14687-2-3-0.68][14788-2-2-0.78][14869-1-1-1.34][14872-3-0-1.24][14877-1-2-1.08][14927-0-3-2.29][15066-0-0-4.01]
[15175-1-2-0.44][15178-2-3-1.32][15375-3-3-0.91][15389-3-3-2.32][15568-2-1--0.13][15675-3-3-1.85][15869-1-2-0.21][16207-3-3-1.30][16236-0-3-0.61][16302-3-3-1.23]
[16331-2-2-0.91][16381-0-0-2.45][16488-1-1-1.40][16495-0-3-0.49][16650-0-0-2.52][16719-1-4-0.18][16801-0-0-3.99][16828-0-0-2.19][17137-3-3-0.93][17245-1-2-0.67]
[17278-3-3-1.11][17282-0-3-0.60][17311-2-2-0.91][17336-2-1-1.10][17608-3-3-2.56][17627-0-1-0.03][17877-3-2-0.99][17924-1-2-0.33][17984-3-3-2.70][18211-0-3-1.54]
[18276-3-3-1.70][18287-1-1-0.39][18394-0-0-2.80][18428-0-3--0.20][18442-0-3-2.77][18478-3-0-2.12][18607-0-0-0.80][18616-0-3-0.99][18663-0-3-1.02][18718-0-3-2.63]
[18766-2-1-1.77][18824-2-2-0.81][18890-3-2-0.65][18930-3-4-0.36][18938-3-3-1.20][19817-1-2-0.99][19839-0-4-0.46][19930-3-3-1.77][19944-0-1-1.45][20036-2-2-1.74]
[20101-3-3-1.31][20474-1-2-1.24][20547-3-3-1.57][20929-2-2-1.76][21245-1-2-0.83][21257-3-3-1.02][21293-1-1-1.85][21316-1-1-1.72][21384-1-1-1.48][21448-1-2-0.28]
[21483-0-0-1.64][21487-2-2-1.30][21714-0-3-1.18][21943-3-2-0.58][21947-0-0-3.80][21948-0-0-4.24][21965-2-2-0.87][21998-1-1-0.33][22025-0-3-1.39][22228-3-3-2.41]
[22446-1-1-1.76][22494-3-0-2.71][22757-0-3-2.89][22811-3-3-2.17][22976-3-2-0.54][22985-3-3-2.11][23014-0-3-2.94][23112-1-2-1.08][23144-3-3-2.31][23168-2-0-2.11]
[23219-0-0-1.46][23363-3-3-2.83][23470-0-0-0.63][23486-2-3-0.66][23497-0-3-3.28][23516-0-0-3.79][23690-1-3-0.04][23921-2-2-1.07][23936-1-3-0.71][24040-3-2-1.09]
[24111-1-4-0.87][24182-0-3-2.88][24238-3-3-2.45][24290-2-3-1.18][24345-0-3-0.80][24364-1-3-0.27][24427-3-3-2.00][24477-2-2-0.97][24495-2-1-0.78][24893-2-2-0.67]
[25012-1-3-0.05][25121-2-2-0.81][25165-3-3-1.62][25183-0-0-1.79][25297-3-3-1.75][25398-0-0-1.54][25574-2-1-0.64][25644-1-1-1.76][25718-1-3-0.14][25774-2-2-1.39]
[26032-3-3-2.29][26051-3-3-3.12][26120-0-0-0.68][26321-1-2-0.50][26732-1-1-0.58][26784-3-3-2.75][26827-3-3-1.34][26833-0-3-3.23][26838-2-3-0.22][26860-1-2-1.06]
[26948-0-0-1.34][27049-3-3-1.85][27098-1-3-0.54][27526-0-0-2.79][27639-3-3-1.15][27698-3-3-2.47][27772-0-3-3.49][27890-1-1-0.60][28040-0-0-1.89][28503-2-1-0.99]
[28577-1-1-1.06][28959-0-0-4.88][29198-3-1-0.09][29777-0-0-3.95][29877-2-2-0.74][30035-1-2-1.50][30098-0-3-1.83][30326-1-1-1.06][30572-2-2-0.89][30716-0-0-0.49]
[30806-2-3-0.21][30906-1-4-0.76][31007-0-4-0.38][31181-3-3-0.73][31238-0-3-1.74][31347-0-3-2.23][31422-2-4-0.29][31429-3-3-0.80][31431-0-3-2.07][31432-1-1-1.07]
[31477-0-0-3.44][31524-1-2-1.15][31597-1-2-1.61][31619-1-2-0.08][31701-0-0-2.41][31755-0-3-1.35][31854-3-3-1.52][32074-1-2-0.47][32078-3-3-0.93][32111-1-1-0.94]
[32127-1-2-1.77][32140-3-3-1.70][32263-2-0-1.07][32365-0-0-1.03][32411-2-0-3.07][32429-3-0-2.90][32473-3-0-2.44][32574-3-3-3.28][32584-0-3-0.38][32622-0-4-0.16]
[32858-3-0-0.93][32969-3-3-2.27][33016-2-2-0.29][33031-1-3-1.01][33035-2-2-1.55][33133-2-2-1.19][33173-2-3-0.31][33175-3-1-1.03][33306-3-2-1.19][33309-2-3-0.05]
[33474-0-0-0.76][33478-2-0-1.71][33618-1-4-0.32][33712-0-3-1.88][33782-2-4-0.96][33914-3-3-1.09][34076-3-3-0.79][34112-2-1-1.05][34138-2-2-1.43][34239-1-2-1.48]
[34364-2-1-1.48][34617-1-2-0.56][34751-3-3-2.16][34783-2-1-0.74][35015-3-3-1.22][35018-1-1-1.33][35288-2-3-0.23][0-4-4-1.11][1-4-0-1.32][2-4-4-0.55]
[3-4-3-0.16][4-4-0-0.47][5-4-1-1.10][6-4-0-3.47][7-4-0-0.45][8-4-2-1.17][9-4-1-0.70][10-4-4-1.01][11-4-2-1.33][12-4-3-0.05]
[14-4-3-0.23][15-4-3-2.53][16-4-0-0.33][17-4-3--0.18][18-4-4-0.94][19-4-3-2.19][20-4-0-0.32][21-4-2-1.01][22-4-4-0.81][23-4-3--0.38]
[24-4-4-0.77][25-4-3-1.11][26-4-3-0.09][27-4-3-1.40][28-4-4-0.58][29-4-4-0.17][30-4-0-1.00][31-4-2-0.67][32-4-4-1.14][33-4-3-1.70]
[34-4-3-0.33][35-4-3-1.56][37-4-0-1.95][39-4-3-2.43][40-4-4-0.32][41-4-3-0.15][42-4-3-1.18][43-4-1-0.74][45-4-3-0.88][46-4-2-0.55]
[47-4-4-0.55][48-4-3--0.16][51-4-4-0.31][52-4-3-0.10][53-4-1-0.59][54-4-4--0.03][55-4-3-0.45][56-4-1-0.93][57-4-0-2.50][58-4-2-2.19]
[59-4-0-2.12][60-4-3-0.40][61-4-4-0.53][62-4-3-0.20][63-4-2-1.49][64-4-4-0.22][65-4-4-0.76][66-4-4-0.28][67-4-1-0.51][68-4-1-1.11]
[69-4-0-1.72][70-4-4-0.48][72-4-2-0.76][73-4-1-0.77][74-4-2-1.11][75-4-3-1.18][77-4-1-0.98][78-4-1--0.29][79-4-1-0.36][80-4-1-1.17]
[81-4-4-1.30][82-4-4-0.21][83-4-2-0.42][84-4-0-1.93][85-4-0-0.70][86-4-4-0.42][87-4-4-0.68][88-4-4-0.09][89-4-4-0.51][90-4-0-0.20]
[91-4-4-0.25][92-4-3-0.44][93-4-0-0.12][94-4-4-0.03][95-4-3-0.05][96-4-4-0.72][97-4-4-0.70][98-4-2-0.94][99-4-4--0.13][100-4-1-0.89]
[101-4-0-0.81][102-4-2-1.48][103-4-3-1.32][104-4-4-0.37][105-4-4-0.96][106-4-4-0.44][107-4-4-0.83][108-4-4-0.36][109-4-0-1.04][110-4-1-0.43]
[111-4-3-3.56][112-4-0-1.84][113-4-3-1.33][114-4-3-1.62][115-4-0-0.86][116-4-4--0.19][117-4-1-0.38][119-4-2-1.59][121-4-1-0.57][122-4-3-0.20]
[124-4-2-0.19][125-4-1-1.14][126-4-3-0.37][127-4-2-0.91][128-4-4-0.29][129-4-2-0.44][130-4-4-0.56][131-4-2-0.31][132-4-1-0.48][133-4-0-3.97]
[135-4-2-0.89][136-4-4-0.13][137-4-2-0.27][138-4-2--0.03][139-4-3-0.96][140-4-2-0.42][141-4-3-0.97][142-4-4-0.47][143-4-4-1.44][144-4-4-0.99]
[145-4-1-0.71][148-4-0-2.89][149-4-2-0.81][150-4-1-1.31][151-4-2-0.81][152-4-1-0.57][153-4-1-1.34][154-4-2-0.16][155-4-0-0.05][156-4-0-1.04]
[157-4-0-1.50][158-4-3-0.40][160-4-1-0.54][161-4-1-0.80][162-4-2-0.31][164-4-2-0.74][165-4-3--0.09][167-4-0-3.33][168-4-4-0.09][170-4-3-0.49]
[171-4-1-1.22][172-4-4-0.68][173-4-0-1.27][174-4-0-2.48][175-4-4-0.62][177-4-3-0.54][178-4-4-0.19][179-4-4--0.09][180-4-4-0.56][181-4-3-0.76]
[182-4-3-0.59][183-4-4-0.25][184-4-2-1.03][186-4-3-0.51][187-4-2-0.39][188-4-1-0.78][189-4-2-0.82][190-4-4-0.15][191-4-2-0.87][192-4-1-0.58]
[193-4-2-1.39][194-4-3-0.70][195-4-0-2.53][196-4-3-0.90][197-4-4-0.70][198-4-4-0.76][199-4-1-0.62]
---------------------------
I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 1.096 | Acc: 51.625% | Wgt Acc: 55.065%
	I - Batch: 100 | Loss: 1.120 | Acc: 49.625% | Wgt Acc: 53.243%
	I - Batch: 150 | Loss: 1.122 | Acc: 49.833% | Wgt Acc: 53.239%
	I - Batch: 200 | Loss: 1.120 | Acc: 50.500% | Wgt Acc: 53.861%
I - num batch: 222
I - Train -- Loss: 1.115 | Acc: 50.606% | Wgt Acc: 53.781% | LR: 1.000000e-03 | Dur: 188.91s
I - Confusion Matrix: [row->prediction - col->label]
[[458.  15.  21. 132. 128.]
 [ 24. 312. 173.  37. 174.]
 [ 21. 160. 414.  56. 275.]
 [150.  40.  63. 295. 107.]
 [ 44.  51.  63.  18. 316.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.296 | Acc: 43.787% | Wgt Acc: 46.288% | Dur: 16.26s
I - Confusion Matrix: [row->prediction - col->label]
[[41.  1.  2. 18. 12.]
 [ 4. 43. 27. 10. 44.]
 [ 4. 25. 32. 11. 43.]
 [26.  1.  5. 43. 18.]
 [13.  8.  9.  4. 63.]]

I - Local maximum validation set accuracy:  43.79

I - Validation set results: 
[14-1-2-1.39][50-3-1-0.69][124-2-2-1.45][127-0-0-2.52][443-2-2-1.64][567-0-0-1.01][573-1-1-1.22][615-0-0-1.39][695-1-2-0.86][722-3-0-1.83]
[826-0-0-2.29][878-0-0-1.40][1103-0-4-0.58][1212-3-3-0.32][1368-0-0-1.49][2181-2-3-0.03][2476-2-1-0.59][2721-2-2-1.43][2818-1-1-0.70][2886-2-1-1.31]
[3231-2-1-1.97][3333-2-1-1.29][3482-2-2-1.10][3536-3-3-1.43][3625-1-1-1.70][3909-0-1--0.03][4035-0-3-0.73][4140-0-0-1.15][4214-1-1-0.97][4346-1-0-0.83]
[4581-2-2-0.94][4708-3-2--0.13][4838-3-4-0.10][4845-1-2-1.09][4868-0-0-1.35][4939-0-4-0.96][4984-2-3-0.10][5078-1-4-1.00][5396-0-0-3.94][5479-1-1-1.75]
[5717-0-0-0.86][5843-1-1-1.11][5949-3-0-2.11][5987-2-4-0.87][6014-3-1-0.38][6033-3-0-0.61][6313-0-3-1.00][6421-3-3-0.61][6500-1-1-0.47][6583-3-3-0.58]
[6683-3-3--0.00][6825-2-3-0.19][6998-3-2-0.52][7049-3-3-0.29][7517-1-1-2.24][7521-1-1-1.16][7528-1-2-0.38][7949-1-2-1.56][8135-1-4-0.56][8185-3-3-0.95]
[8269-3-2-0.84][8273-3-3-1.09][8543-3-0-2.09][8666-1-1-1.26][8672-0-0-2.08][8903-1-1-0.21][9001-2-1-1.48][9036-2-2-2.03][9281-3-2-0.32][9300-2-1-0.35]
[9571-0-3-0.20][9617-1-4-0.60][9644-2-2-1.44][9705-2-1-0.34][9801-0-3-1.11][9803-3-3-0.33][9865-3-0-1.70][9896-2-2-1.44][10314-1-2-0.86][10337-3-3-1.73]
[10403-0-4-0.72][10653-2-1-0.88][10704-2-1-1.25][10719-1-1-1.40][10727-1-4-1.20][10836-0-3-2.28][10969-2-2-0.51][11042-0-0-1.60][11088-1-1-1.27][11322-0-0-2.14]
[11398-2-2-1.29][11499-0-4--0.19][11502-3-3-0.07][11512-3-1-0.39][11608-1-1-2.48][11610-0-3-1.57][11692-0-3-1.62][11905-0-0-2.66][11993-1-2-0.92][12002-2-3-1.10]
[12052-0-0-1.03][12201-0-3-1.74][12235-2-1-1.43][12320-1-4-0.46][12377-2-4-1.00][12398-2-1-0.23][12503-1-1-0.85][12617-0-1-0.88][12685-3-2-0.56][12738-2-1-0.17]
[12742-2-2-1.47][12823-0-3-1.58][13110-1-1-1.16][13240-3-0-0.47][13253-1-1-1.43][13273-0-0-3.50][13634-1-1-1.37][13763-2-2-0.93][13905-3-3-0.91][14060-2-1-1.62]
[14065-3-0-1.84][14147-3-1-0.54][14595-2-2-1.38][14687-2-2-1.17][14788-2-2-1.13][14869-1-1-1.77][14872-3-4-0.81][14877-1-1-0.73][14927-0-3-1.64][15066-0-0-2.54]
[15175-1-2-0.76][15178-2-0-0.39][15375-3-3-1.59][15389-3-3-1.93][15568-2-1-1.10][15675-3-3-0.26][15869-1-2-0.67][16207-3-0-0.29][16236-0-3-0.50][16302-3-3-0.47]
[16331-2-2-1.06][16381-0-0-1.50][16488-1-4-1.48][16495-0-4-1.16][16650-0-0-2.08][16719-1-2-0.50][16801-0-0-2.75][16828-0-0-1.14][17137-3-3-0.34][17245-1-1-0.76]
[17278-3-1-0.06][17282-0-1-0.51][17311-2-2-1.34][17336-2-2-1.13][17608-3-3-1.78][17627-0-0--0.04][17877-3-1-1.47][17924-1-2-0.64][17984-3-0-1.49][18211-0-3-0.29]
[18276-3-0-1.22][18287-1-1-1.33][18394-0-0-2.31][18428-0-0-0.33][18442-0-3-1.41][18478-3-0-1.40][18607-0-4-0.78][18616-0-3-0.08][18663-0-2-0.09][18718-0-0-1.47]
[18766-2-1-1.86][18824-2-4-0.91][18890-3-2-0.71][18930-3-2-0.76][18938-3-3-1.27][19817-1-2-1.12][19839-0-2-0.47][19930-3-3-0.24][19944-0-2-0.62][20036-2-2-1.92]
[20101-3-1-0.24][20474-1-2-1.69][20547-3-4-0.24][20929-2-2-1.88][21245-1-1-1.07][21257-3-1-0.70][21293-1-1-2.16][21316-1-1-2.20][21384-1-1-1.44][21448-1-1-1.06]
[21483-0-0-0.98][21487-2-2-1.16][21714-0-2-0.38][21943-3-2-1.07][21947-0-0-2.10][21948-0-0-2.05][21965-2-2-1.18][21998-1-1-0.89][22025-0-3-0.39][22228-3-3-1.09]
[22446-1-1-2.05][22494-3-0-2.08][22757-0-0-2.58][22811-3-3-0.92][22976-3-2-0.74][22985-3-0-1.98][23014-0-3-1.79][23112-1-1-1.46][23144-3-3-2.22][23168-2-4--0.06]
[23219-0-3--0.35][23363-3-3-1.22][23470-0-4-0.48][23486-2-2-0.50][23497-0-3-2.80][23516-0-0-3.47][23690-1-1-0.58][23921-2-1-1.23][23936-1-2-0.83][24040-3-2-0.58]
[24111-1-4-1.21][24182-0-3-2.13][24238-3-3-1.97][24290-2-4-0.25][24345-0-3-0.13][24364-1-2-1.09][24427-3-0-1.03][24477-2-2-1.41][24495-2-1-1.37][24893-2-1-1.25]
[25012-1-1-0.17][25121-2-4-1.23][25165-3-3-0.19][25183-0-0-0.30][25297-3-3-0.58][25398-0-0-0.65][25574-2-1-1.14][25644-1-1-2.31][25718-1-1-0.65][25774-2-2-1.26]
[26032-3-3-1.58][26051-3-3-2.18][26120-0-4-0.66][26321-1-1-1.38][26732-1-2-0.74][26784-3-3-2.56][26827-3-3-0.34][26833-0-3-2.21][26838-2-1-0.75][26860-1-2-0.98]
[26948-0-0-0.79][27049-3-3-0.84][27098-1-1-0.64][27526-0-0-1.18][27639-3-3-0.88][27698-3-3-1.79][27772-0-3-2.49][27890-1-1-1.26][28040-0-4-0.24][28503-2-2-1.43]
[28577-1-1-1.10][28959-0-0-4.04][29198-3-1-0.32][29777-0-0-3.82][29877-2-1-1.10][30035-1-2-1.26][30098-0-3-0.98][30326-1-1-1.60][30572-2-2-0.66][30716-0-4-0.76]
[30806-2-1-0.46][30906-1-1-1.09][31007-0-4-0.35][31181-3-3-0.62][31238-0-3-0.76][31347-0-3-1.72][31422-2-4-0.44][31429-3-4--0.09][31431-0-3-1.60][31432-1-1-1.25]
[31477-0-0-2.93][31524-1-2-0.29][31597-1-2-1.03][31619-1-2--0.03][31701-0-0-1.92][31755-0-0-0.77][31854-3-3-0.21][32074-1-3-0.24][32078-3-3-0.50][32111-1-4-1.26]
[32127-1-2-1.70][32140-3-3-1.13][32263-2-4-0.43][32365-0-4-0.15][32411-2-3-2.61][32429-3-0-2.75][32473-3-0-2.18][32574-3-0-2.58][32584-0-4--0.01][32622-0-1-0.58]
[32858-3-0-0.97][32969-3-3-1.54][33016-2-2-1.08][33031-1-1--0.02][33035-2-2-1.60][33133-2-1-1.20][33173-2-1-1.26][33175-3-1-0.84][33306-3-2-0.95][33309-2-1-0.58]
[33474-0-0--0.15][33478-2-0-0.61][33618-1-1-1.05][33712-0-0-0.67][33782-2-2-1.25][33914-3-3-0.84][34076-3-3-0.63][34112-2-1-0.75][34138-2-2-1.59][34239-1-2-1.39]
[34364-2-1-1.68][34617-1-2-0.70][34751-3-3-1.82][34783-2-4-0.90][35015-3-3-0.47][35018-1-2-1.32][35288-2-2-0.49][0-4-2-0.56][1-4-3-0.25][2-4-4-0.64]
[3-4-1-0.60][4-4-2-0.53][5-4-1-1.00][6-4-4-0.17][7-4-1-0.93][8-4-2-0.84][9-4-4-0.59][10-4-4-1.38][11-4-2-1.42][12-4-1-0.78]
[14-4-3--0.07][15-4-3-1.87][16-4-2-0.13][17-4-4-0.86][18-4-4-0.92][19-4-3-1.67][20-4-4-0.65][21-4-1-1.33][22-4-4-1.03][23-4-1-0.68]
[24-4-4-0.76][25-4-3-0.48][26-4-1--0.06][27-4-0-0.90][28-4-4-0.69][29-4-2-1.03][30-4-4-0.17][31-4-1-0.95][32-4-4-1.44][33-4-3-0.57]
[34-4-2--0.03][35-4-3-0.64][37-4-0-1.65][39-4-3-1.01][40-4-2-0.25][41-4-1-0.94][42-4-1-0.85][43-4-1-0.84][45-4-4-0.82][46-4-2-0.88]
[47-4-4-1.07][48-4-2-0.76][51-4-4-0.91][52-4-2-0.72][53-4-4-0.60][54-4-4-0.43][55-4-2-0.89][56-4-1-1.42][57-4-3-1.12][58-4-2-1.86]
[59-4-4-0.22][60-4-1-0.12][61-4-4-1.11][62-4-2-0.65][63-4-2-1.09][64-4-1-0.81][65-4-4-0.99][66-4-4-1.10][67-4-2-0.52][68-4-1-1.91]
[69-4-0-1.44][70-4-2-0.95][72-4-4-1.35][73-4-1-0.97][74-4-2-0.55][75-4-2-0.58][77-4-4-1.65][78-4-1-0.93][79-4-1-1.10][80-4-4-1.37]
[81-4-4-0.95][82-4-2-0.61][83-4-1-0.95][84-4-0-1.01][85-4-1-0.62][86-4-4-0.86][87-4-4-0.84][88-4-4-0.51][89-4-2-0.25][90-4-4-0.34]
[91-4-4-0.66][92-4-2-0.42][93-4-4-0.49][94-4-4-0.54][95-4-1-0.20][96-4-4-0.73][97-4-1-0.78][98-4-2-1.68][99-4-4-0.17][100-4-4-1.30]
[101-4-4-0.73][102-4-2-1.21][103-4-3-1.11][104-4-4-0.83][105-4-4-1.12][106-4-1-1.34][107-4-4-0.85][108-4-4-0.71][109-4-1-1.25][110-4-4-0.74]
[111-4-0-2.65][112-4-4-0.67][113-4-3-0.20][114-4-3-0.50][115-4-1-0.58][116-4-4-0.60][117-4-1-1.10][119-4-2-0.30][121-4-1-0.86][122-4-4--0.29]
[124-4-1-0.90][125-4-1-1.40][126-4-1-0.64][127-4-2-1.20][128-4-2-0.52][129-4-2-0.60][130-4-4-1.15][131-4-3-0.31][132-4-3-0.03][133-4-0-2.79]
[135-4-2-1.49][136-4-1-0.81][137-4-2-0.36][138-4-1-0.17][139-4-4-0.19][140-4-2-0.76][141-4-3-1.34][142-4-4-0.90][143-4-4-1.53][144-4-4-1.50]
[145-4-1-1.14][148-4-0-1.40][149-4-2-0.82][150-4-1-1.74][151-4-2-0.87][152-4-1-1.45][153-4-4-1.06][154-4-1-1.63][155-4-1-0.58][156-4-0-0.06]
[157-4-4-0.71][158-4-2-0.09][160-4-4-0.88][161-4-1-0.97][162-4-2-0.58][164-4-2-0.83][165-4-4-1.24][167-4-0-0.55][168-4-4-0.69][170-4-1-0.25]
[171-4-1-0.76][172-4-4-1.02][173-4-4-0.73][174-4-0-0.86][175-4-4-0.59][177-4-0-1.34][178-4-4-0.79][179-4-1-0.10][180-4-4-1.13][181-4-3-1.22]
[182-4-3-0.59][183-4-1-0.50][184-4-2-1.02][186-4-2-0.58][187-4-1-1.19][188-4-2-0.79][189-4-2-0.61][190-4-4-0.91][191-4-2-1.09][192-4-4-0.54]
[193-4-1-1.71][194-4-3-0.18][195-4-0-1.28][196-4-2-0.68][197-4-4-1.00][198-4-4-1.07][199-4-2-0.68]
---------------------------
I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 1.080 | Acc: 53.750% | Wgt Acc: 57.213%
	I - Batch: 100 | Loss: 1.086 | Acc: 52.625% | Wgt Acc: 56.509%
	I - Batch: 150 | Loss: 1.077 | Acc: 52.792% | Wgt Acc: 56.396%
	I - Batch: 200 | Loss: 1.088 | Acc: 52.188% | Wgt Acc: 55.424%
I - num batch: 222
I - Train -- Loss: 1.094 | Acc: 51.677% | Wgt Acc: 54.923% | LR: 1.000000e-03 | Dur: 185.29s
I - Confusion Matrix: [row->prediction - col->label]
[[456.  11.  17. 129. 151.]
 [ 18. 347. 181.  28. 188.]
 [ 25. 139. 400.  54. 222.]
 [141.  27.  62. 296. 105.]
 [ 57.  54.  74.  31. 334.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.324 | Acc: 45.562% | Wgt Acc: 50.437% | Dur: 23.77s
I - Confusion Matrix: [row->prediction - col->label]
[[54.  8.  6. 24. 31.]
 [ 3. 45. 20.  5. 54.]
 [ 0. 13. 33.  6. 25.]
 [28.  6. 13. 51. 22.]
 [ 3.  6.  3.  0. 48.]]

I - Local maximum validation set accuracy:  45.56

I - Validation set results: 
[14-1-1-1.64][50-3-3-0.35][124-2-2-0.52][127-0-0-2.45][443-2-2-1.38][567-0-0-2.07][573-1-1-0.84][615-0-3-1.55][695-1-2--0.04][722-3-3-2.22]
[826-0-0-1.54][878-0-0-2.04][1103-0-0-1.02][1212-3-3-0.59][1368-0-0-0.56][2181-2-0-0.69][2476-2-1--0.07][2721-2-2-1.63][2818-1-2--0.13][2886-2-1-1.44]
[3231-2-1-2.09][3333-2-1-1.10][3482-2-2-0.49][3536-3-3-1.92][3625-1-1-1.60][3909-0-3-1.39][4035-0-3-1.29][4140-0-0-2.03][4214-1-1-0.80][4346-1-0-1.84]
[4581-2-2-1.23][4708-3-2--0.19][4838-3-3-0.14][4845-1-1-0.82][4868-0-0-2.42][4939-0-4-0.65][4984-2-2-0.39][5078-1-4-0.78][5396-0-0-3.79][5479-1-1-1.12]
[5717-0-0-1.23][5843-1-1-1.62][5949-3-0-2.28][5987-2-1-1.18][6014-3-1--0.02][6033-3-0-0.73][6313-0-3-1.78][6421-3-3-1.02][6500-1-0-0.10][6583-3-3-0.81]
[6683-3-3-0.87][6825-2-3-0.68][6998-3-1--0.15][7049-3-3-0.34][7517-1-1-2.61][7521-1-1--0.02][7528-1-3-0.65][7949-1-2-0.85][8135-1-0-1.24][8185-3-3-1.12]
[8269-3-2-0.66][8273-3-3-1.41][8543-3-0-4.21][8666-1-3-0.25][8672-0-0-2.39][8903-1-1-0.46][9001-2-1-1.69][9036-2-2-1.73][9281-3-3-0.44][9300-2-1-0.00]
[9571-0-0-0.89][9617-1-1-0.18][9644-2-2-0.38][9705-2-1--0.18][9801-0-3-1.80][9803-3-0-1.73][9865-3-0-1.46][9896-2-2-1.35][10314-1-2-0.31][10337-3-3-2.02]
[10403-0-0-0.86][10653-2-1-0.53][10704-2-1-1.01][10719-1-1-1.22][10727-1-4-0.52][10836-0-0-3.00][10969-2-3-0.74][11042-0-0-1.73][11088-1-1-1.91][11322-0-0-3.14]
[11398-2-2-2.62][11499-0-3-0.66][11502-3-3-0.86][11512-3-3-0.55][11608-1-1-1.97][11610-0-3-1.77][11692-0-3-1.19][11905-0-0-2.69][11993-1-2-0.92][12002-2-3-1.02]
[12052-0-0-1.55][12201-0-3-1.97][12235-2-1-1.84][12320-1-0-0.74][12377-2-4-0.51][12398-2-3-0.60][12503-1-4-1.10][12617-0-1-0.98][12685-3-1-0.81][12738-2-3-0.82]
[12742-2-2-1.79][12823-0-3-1.79][13110-1-1-0.41][13240-3-0-1.85][13253-1-1-1.39][13273-0-0-4.35][13634-1-1-1.43][13763-2-3-0.57][13905-3-3-0.63][14060-2-1-1.12]
[14065-3-3-1.38][14147-3-3-0.94][14595-2-2-0.89][14687-2-2-1.46][14788-2-2-0.49][14869-1-1-1.60][14872-3-0-0.94][14877-1-1--0.06][14927-0-3-1.52][15066-0-0-3.27]
[15175-1-2-0.90][15178-2-0-0.63][15375-3-3-1.20][15389-3-3-1.52][15568-2-1-1.16][15675-3-3-1.89][15869-1-1-0.48][16207-3-3-0.75][16236-0-3-0.29][16302-3-0-0.73]
[16331-2-2-1.05][16381-0-0-2.17][16488-1-1-1.40][16495-0-0-0.85][16650-0-0-2.64][16719-1-2--0.03][16801-0-0-3.59][16828-0-0-2.27][17137-3-3-1.34][17245-1-2-0.48]
[17278-3-3--0.30][17282-0-3-0.80][17311-2-2-1.25][17336-2-2-0.96][17608-3-0-2.26][17627-0-3-0.92][17877-3-2-1.24][17924-1-4-0.16][17984-3-0-2.15][18211-0-3-1.59]
[18276-3-0-1.96][18287-1-1-1.03][18394-0-0-2.41][18428-0-0-4.03][18442-0-3-2.34][18478-3-0-2.12][18607-0-0-1.55][18616-0-3-0.63][18663-0-3-0.69][18718-0-0-1.82]
[18766-2-1-1.92][18824-2-1-0.56][18890-3-2-0.65][18930-3-0-0.93][18938-3-3-0.99][19817-1-2-1.38][19839-0-4-0.26][19930-3-3-0.98][19944-0-1-1.61][20036-2-2-1.68]
[20101-3-0-0.42][20474-1-1-1.41][20547-3-0-0.68][20929-2-2-1.51][21245-1-2-1.20][21257-3-3-0.58][21293-1-1-2.30][21316-1-1-1.80][21384-1-1-1.89][21448-1-1-0.10]
[21483-0-0-1.23][21487-2-2-1.03][21714-0-3-0.93][21943-3-2-0.22][21947-0-0-1.72][21948-0-0-3.32][21965-2-2-1.68][21998-1-1-0.11][22025-0-3-0.58][22228-3-3-2.24]
[22446-1-1-1.84][22494-3-0-2.30][22757-0-0-3.09][22811-3-3-2.62][22976-3-3--0.03][22985-3-3-1.78][23014-0-3-2.21][23112-1-1-1.37][23144-3-0-1.82][23168-2-3--0.15]
[23219-0-0-0.67][23363-3-3-1.88][23470-0-0-1.46][23486-2-3-0.60][23497-0-3-2.86][23516-0-0-3.33][23690-1-1-0.93][23921-2-2-1.07][23936-1-3-0.57][24040-3-2-0.76]
[24111-1-4-1.27][24182-0-3-2.40][24238-3-3-1.86][24290-2-0-1.39][24345-0-4-0.29][24364-1-2-0.78][24427-3-0-2.13][24477-2-2-1.24][24495-2-1-0.18][24893-2-2-0.71]
[25012-1-3--0.04][25121-2-2-0.82][25165-3-3-0.53][25183-0-0-1.24][25297-3-3-1.19][25398-0-0-1.60][25574-2-3-0.52][25644-1-1-2.49][25718-1-0-0.08][25774-2-2-0.83]
[26032-3-3-2.03][26051-3-3-2.17][26120-0-0-0.52][26321-1-1-0.88][26732-1-1-0.49][26784-3-3-2.19][26827-3-3-1.00][26833-0-3-2.69][26838-2-1-0.46][26860-1-1-1.19]
[26948-0-0-1.14][27049-3-0-1.51][27098-1-3-0.70][27526-0-0-1.73][27639-3-3-0.62][27698-3-3-2.07][27772-0-0-2.74][27890-1-1-1.19][28040-0-0-1.71][28503-2-2-1.79]
[28577-1-1-1.73][28959-0-0-2.48][29198-3-3-0.70][29777-0-0-3.43][29877-2-2-0.18][30035-1-1-1.50][30098-0-3-1.43][30326-1-1-1.22][30572-2-2-0.75][30716-0-0-0.23]
[30806-2-3-0.01][30906-1-4-0.81][31007-0-0-2.26][31181-3-3-0.65][31238-0-3-1.64][31347-0-3-1.80][31422-2-4-0.10][31429-3-0-0.40][31431-0-3-0.30][31432-1-1-0.48]
[31477-0-0-2.55][31524-1-0-0.73][31597-1-1-1.26][31619-1-0-0.21][31701-0-0-2.41][31755-0-0-1.58][31854-3-3-1.65][32074-1-0-0.90][32078-3-3-1.21][32111-1-1-1.44]
[32127-1-2-1.82][32140-3-3-1.12][32263-2-0-0.34][32365-0-0-1.35][32411-2-0-2.69][32429-3-0-3.12][32473-3-0-1.61][32574-3-0-3.24][32584-0-0-1.60][32622-0-1-0.98]
[32858-3-0-1.51][32969-3-3-1.44][33016-2-2-1.92][33031-1-3-0.84][33035-2-2-2.03][33133-2-2-1.47][33173-2-3-0.39][33175-3-1-1.01][33306-3-1-1.30][33309-2-3--0.10]
[33474-0-0-0.67][33478-2-0-0.76][33618-1-1-0.68][33712-0-0-1.47][33782-2-2-1.48][33914-3-3-0.56][34076-3-3-0.38][34112-2-1-1.63][34138-2-1-1.22][34239-1-1-0.75]
[34364-2-1-1.89][34617-1-1-0.88][34751-3-3-1.22][34783-2-4-0.53][35015-3-3-0.86][35018-1-2-1.31][35288-2-3-0.41][0-4-4-1.12][1-4-0-0.50][2-4-4-0.60]
[3-4-1-0.21][4-4-3-0.71][5-4-1-0.46][6-4-0-1.23][7-4-1-0.05][8-4-2-0.36][9-4-1-0.51][10-4-0-0.84][11-4-2-1.58][12-4-1-0.77]
[14-4-0-0.98][15-4-3-2.04][16-4-0--0.34][17-4-0-0.33][18-4-1-1.13][19-4-3-1.78][20-4-0-0.29][21-4-1-1.45][22-4-4-0.71][23-4-1-0.02]
[24-4-4-1.06][25-4-3-1.24][26-4-3-0.58][27-4-3-1.27][28-4-4-0.59][29-4-1-0.19][30-4-4-0.33][31-4-2-0.78][32-4-4-1.82][33-4-3-0.89]
[34-4-3-0.44][35-4-3-0.92][37-4-0-1.11][39-4-0-2.93][40-4-3-0.09][41-4-1-0.00][42-4-2-0.29][43-4-1-0.91][45-4-1-1.00][46-4-4-0.53]
[47-4-4-0.39][48-4-1-0.07][51-4-1-0.66][52-4-4-0.63][53-4-1-0.64][54-4-3--0.27][55-4-3-0.17][56-4-4-0.45][57-4-0-1.78][58-4-2-1.56]
[59-4-0-1.60][60-4-4-0.20][61-4-1-0.47][62-4-3-0.54][63-4-2-1.01][64-4-1-0.17][65-4-1-0.94][66-4-4-1.23][67-4-1-0.23][68-4-1-1.65]
[69-4-0-0.88][70-4-4-0.58][72-4-4-0.24][73-4-2-0.30][74-4-2-0.23][75-4-3-0.62][77-4-1-1.53][78-4-1--0.08][79-4-1-0.76][80-4-1-1.52]
[81-4-4-1.94][82-4-4-0.09][83-4-1-0.49][84-4-4--0.03][85-4-1-0.30][86-4-4-0.03][87-4-4-0.68][88-4-1-0.17][89-4-2--0.05][90-4-4-0.84]
[91-4-4-0.47][92-4-0-0.43][93-4-0-0.47][94-4-4-0.13][95-4-1--0.02][96-4-2-0.70][97-4-4-0.95][98-4-2-1.98][99-4-4--0.21][100-4-1-1.42]
[101-4-1-0.09][102-4-2-0.86][103-4-3-0.92][104-4-4-0.60][105-4-4-1.32][106-4-1-0.88][107-4-4-1.01][108-4-4--0.10][109-4-3-0.39][110-4-4-0.12]
[111-4-0-2.84][112-4-0-1.21][113-4-1-0.19][114-4-0-1.05][115-4-0-1.08][116-4-4-0.32][117-4-1-0.95][119-4-2-0.66][121-4-4--0.08][122-4-0-0.54]
[124-4-1-0.66][125-4-4-1.18][126-4-1-0.09][127-4-2-0.93][128-4-0-0.15][129-4-4-0.19][130-4-1-0.24][131-4-2-0.14][132-4-2-0.20][133-4-0-2.55]
[135-4-2-0.81][136-4-1-0.16][137-4-0--0.10][138-4-4-0.39][139-4-3-0.07][140-4-4--0.27][141-4-3-1.60][142-4-4-0.86][143-4-4-1.53][144-4-4-1.34]
[145-4-1-2.19][148-4-0-2.33][149-4-2-0.06][150-4-1-1.62][151-4-2-0.87][152-4-1-0.98][153-4-1-1.38][154-4-1-0.32][155-4-0--0.12][156-4-0-1.20]
[157-4-0-2.04][158-4-3-0.23][160-4-1-0.07][161-4-1-1.03][162-4-4-0.08][164-4-2-0.12][165-4-4-0.84][167-4-0-2.50][168-4-0--0.10][170-4-3-0.39]
[171-4-1-0.03][172-4-4-0.54][173-4-4-0.04][174-4-0-1.80][175-4-4--0.05][177-4-0-2.07][178-4-4-0.22][179-4-3-0.23][180-4-4-0.61][181-4-3-0.50]
[182-4-1-0.37][183-4-1-0.15][184-4-2-0.82][186-4-0-0.42][187-4-1-1.34][188-4-1-0.95][189-4-4-0.44][190-4-1-0.21][191-4-2-0.66][192-4-1-0.25]
[193-4-1-1.40][194-4-2-0.80][195-4-2-0.32][196-4-1-0.26][197-4-1-1.23][198-4-4-1.36][199-4-2-0.08]
---------------------------
I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 1.075 | Acc: 54.000% | Wgt Acc: 58.331%
	I - Batch: 100 | Loss: 1.079 | Acc: 53.562% | Wgt Acc: 57.457%
	I - Batch: 150 | Loss: 1.065 | Acc: 53.875% | Wgt Acc: 58.071%
	I - Batch: 200 | Loss: 1.071 | Acc: 53.156% | Wgt Acc: 57.136%
I - num batch: 222
I - Train -- Loss: 1.072 | Acc: 53.313% | Wgt Acc: 57.013% | LR: 1.000000e-03 | Dur: 188.26s
I - Confusion Matrix: [row->prediction - col->label]
[[482.   8.  18. 125. 140.]
 [ 15. 353. 156.  40. 184.]
 [ 30. 139. 431.  44. 254.]
 [125.  32.  59. 306. 103.]
 [ 45.  46.  70.  23. 319.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.272 | Acc: 49.901% | Wgt Acc: 52.511% | Dur: 16.75s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  7.  6. 35. 41.]
 [ 2. 42. 12.  2. 26.]
 [ 0. 11. 36.  4. 23.]
 [11.  7. 13. 42. 23.]
 [ 9. 11.  8.  3. 67.]]

I - Local maximum validation set accuracy:  49.90

I - Validation set results: 
[14-1-1-1.37][50-3-3--0.00][124-2-2-1.35][127-0-0-2.98][443-2-2-1.79][567-0-0-2.40][573-1-1-0.88][615-0-0-2.23][695-1-2-0.43][722-3-3-2.24]
[826-0-0-2.97][878-0-0-2.23][1103-0-4-0.61][1212-3-3-0.83][1368-0-0-2.09][2181-2-3-0.40][2476-2-4--0.20][2721-2-2-2.41][2818-1-1-0.35][2886-2-1-1.68]
[3231-2-2-1.31][3333-2-3-0.86][3482-2-4-0.63][3536-3-3-1.49][3625-1-1-2.04][3909-0-3-0.93][4035-0-3-1.36][4140-0-0-1.80][4214-1-3-0.23][4346-1-0-2.24]
[4581-2-2-1.83][4708-3-3-0.31][4838-3-0-0.44][4845-1-1-0.09][4868-0-0-2.40][4939-0-4-0.81][4984-2-2-0.52][5078-1-4-1.22][5396-0-0-4.13][5479-1-1-0.97]
[5717-0-0-1.23][5843-1-2-0.73][5949-3-0-2.85][5987-2-1-1.13][6014-3-3--0.22][6033-3-0-1.19][6313-0-3-1.73][6421-3-3-1.37][6500-1-0-0.40][6583-3-3-0.88]
[6683-3-3-0.89][6825-2-3-0.55][6998-3-3-0.01][7049-3-3-0.75][7517-1-1-2.11][7521-1-3--0.15][7528-1-3-0.83][7949-1-2-0.53][8135-1-0-1.23][8185-3-0-1.77]
[8269-3-2-1.40][8273-3-3-1.45][8543-3-0-4.28][8666-1-1-0.41][8672-0-0-4.60][8903-1-2-0.41][9001-2-1-1.35][9036-2-2-1.85][9281-3-0-0.20][9300-2-1--0.17]
[9571-0-0-0.88][9617-1-4-0.72][9644-2-2-0.66][9705-2-3--0.26][9801-0-0-1.88][9803-3-0-1.81][9865-3-0-3.12][9896-2-2-1.88][10314-1-4-0.44][10337-3-3-2.04]
[10403-0-4-0.71][10653-2-1-0.79][10704-2-3-0.56][10719-1-1-1.39][10727-1-4-0.95][10836-0-0-2.95][10969-2-3-0.42][11042-0-0-1.58][11088-1-1-2.11][11322-0-0-2.85]
[11398-2-4-1.29][11499-0-3-0.61][11502-3-0-1.12][11512-3-3-0.31][11608-1-1-2.03][11610-0-0-2.30][11692-0-0-1.82][11905-0-0-3.03][11993-1-2-0.99][12002-2-3-1.12]
[12052-0-0-1.46][12201-0-0-2.39][12235-2-1-1.25][12320-1-4-0.68][12377-2-4-0.97][12398-2-0-0.93][12503-1-1-0.68][12617-0-1-0.27][12685-3-3-0.33][12738-2-2-0.90]
[12742-2-2-2.04][12823-0-0-1.85][13110-1-1-0.15][13240-3-0-2.42][13253-1-1-1.53][13273-0-0-4.67][13634-1-1-0.60][13763-2-2-1.44][13905-3-3-1.07][14060-2-1-1.00]
[14065-3-0-2.52][14147-3-3-0.96][14595-2-2-1.39][14687-2-2-1.34][14788-2-2-0.71][14869-1-1-1.51][14872-3-0-0.84][14877-1-4-0.54][14927-0-3-2.00][15066-0-0-3.37]
[15175-1-4-1.00][15178-2-0-1.22][15375-3-0-2.26][15389-3-3-1.86][15568-2-1-0.72][15675-3-3-1.58][15869-1-4-0.10][16207-3-0-1.13][16236-0-3-0.32][16302-3-0-1.38]
[16331-2-2-1.74][16381-0-0-3.13][16488-1-1-2.00][16495-0-4-0.02][16650-0-0-2.59][16719-1-0-0.36][16801-0-0-3.47][16828-0-0-2.22][17137-3-0-1.32][17245-1-1-0.19]
[17278-3-3--0.11][17282-0-0--0.10][17311-2-2-1.72][17336-2-1-1.75][17608-3-0-2.63][17627-0-0-0.49][17877-3-4-0.54][17924-1-4-0.61][17984-3-0-2.23][18211-0-3-1.33]
[18276-3-0-1.25][18287-1-1-1.41][18394-0-0-3.22][18428-0-0-4.32][18442-0-3-2.10][18478-3-0-1.98][18607-0-0-1.22][18616-0-0-1.06][18663-0-0-0.42][18718-0-0-1.76]
[18766-2-1-2.04][18824-2-2-1.15][18890-3-2-0.91][18930-3-4-0.45][18938-3-3-1.25][19817-1-2-1.58][19839-0-4-0.91][19930-3-3-1.29][19944-0-4-1.67][20036-2-2-1.68]
[20101-3-3-1.18][20474-1-1-1.06][20547-3-3-0.62][20929-2-2-2.71][21245-1-2-0.93][21257-3-3-0.78][21293-1-1-2.33][21316-1-1-2.16][21384-1-1-1.60][21448-1-1--0.08]
[21483-0-0-1.69][21487-2-2-1.20][21714-0-0-1.24][21943-3-2-0.37][21947-0-0-3.36][21948-0-0-3.18][21965-2-2-0.82][21998-1-1-0.14][22025-0-3-0.48][22228-3-3-2.00]
[22446-1-1-0.76][22494-3-0-2.70][22757-0-0-3.13][22811-3-3-2.20][22976-3-1-0.31][22985-3-0-2.02][23014-0-0-2.38][23112-1-1-1.85][23144-3-0-2.22][23168-2-0-1.41]
[23219-0-0-1.44][23363-3-3-1.98][23470-0-4-0.19][23486-2-3-0.95][23497-0-0-2.54][23516-0-0-2.63][23690-1-2-0.23][23921-2-2-0.44][23936-1-2-0.90][24040-3-4-0.68]
[24111-1-4-1.33][24182-0-0-2.20][24238-3-3-1.70][24290-2-0-2.03][24345-0-0-1.47][24364-1-3-0.16][24427-3-0-2.27][24477-2-2-1.71][24495-2-1-0.57][24893-2-2-0.50]
[25012-1-3--0.09][25121-2-4-0.56][25165-3-0-0.77][25183-0-0-0.58][25297-3-3-1.42][25398-0-0-2.06][25574-2-3-0.64][25644-1-1-2.59][25718-1-0-0.65][25774-2-3-0.57]
[26032-3-3-2.08][26051-3-3-2.14][26120-0-0-2.50][26321-1-1-0.31][26732-1-1-0.52][26784-3-3-2.01][26827-3-0-1.53][26833-0-3-2.70][26838-2-2-0.58][26860-1-4-1.30]
[26948-0-0-2.08][27049-3-0-1.28][27098-1-0-1.45][27526-0-0-2.19][27639-3-0-1.16][27698-3-3-2.29][27772-0-0-2.36][27890-1-1-1.38][28040-0-0-1.25][28503-2-2-1.81]
[28577-1-1-1.73][28959-0-0-4.01][29198-3-3-0.27][29777-0-0-3.97][29877-2-2-0.56][30035-1-1-1.47][30098-0-0-1.72][30326-1-1-1.33][30572-2-2-1.18][30716-0-4-0.11]
[30806-2-3-0.21][30906-1-1-1.09][31007-0-4-1.08][31181-3-0-2.35][31238-0-3-1.42][31347-0-0-2.35][31422-2-4--0.01][31429-3-0-1.03][31431-0-0-0.69][31432-1-1-1.09]
[31477-0-0-3.08][31524-1-1-0.35][31597-1-1-1.39][31619-1-0--0.07][31701-0-0-3.71][31755-0-0-2.54][31854-3-3-1.57][32074-1-3-0.59][32078-3-3-1.28][32111-1-1-1.22]
[32127-1-2-2.17][32140-3-3-1.51][32263-2-4-0.18][32365-0-0-0.88][32411-2-0-3.12][32429-3-0-3.83][32473-3-0-2.71][32574-3-0-3.32][32584-0-0-1.95][32622-0-1-0.23]
[32858-3-0-2.48][32969-3-0-1.93][33016-2-2-1.35][33031-1-3-1.10][33035-2-2-2.28][33133-2-1-1.32][33173-2-2-0.86][33175-3-1-0.53][33306-3-2-1.02][33309-2-3--0.13]
[33474-0-0-0.82][33478-2-0-1.01][33618-1-1-0.48][33712-0-0-1.93][33782-2-2-1.01][33914-3-3-0.81][34076-3-3-0.75][34112-2-2-0.46][34138-2-2-1.94][34239-1-2-0.93]
[34364-2-2-1.80][34617-1-1-0.71][34751-3-3-1.69][34783-2-4-0.74][35015-3-3-0.77][35018-1-1-1.19][35288-2-3-0.53][0-4-3-0.01][1-4-0-1.36][2-4-0-0.89]
[3-4-1-0.08][4-4-0-0.31][5-4-1-0.54][6-4-4-1.12][7-4-0-1.09][8-4-2-1.06][9-4-4-0.55][10-4-0-1.32][11-4-2-1.58][12-4-3-0.29]
[14-4-0-0.78][15-4-0-1.96][16-4-3-0.41][17-4-4-0.26][18-4-4-1.46][19-4-0-2.17][20-4-4-0.32][21-4-1-1.37][22-4-4-1.11][23-4-0--0.40]
[24-4-4-1.25][25-4-0-1.04][26-4-3--0.23][27-4-0-2.54][28-4-4-0.74][29-4-2-0.68][30-4-3-0.34][31-4-1-0.50][32-4-4-1.83][33-4-3-1.18]
[34-4-3-0.23][35-4-0-2.52][37-4-0-0.94][39-4-0-2.49][40-4-4-0.61][41-4-1--0.21][42-4-4-0.52][43-4-1-1.01][45-4-3-1.24][46-4-4-0.65]
[47-4-4-0.81][48-4-4--0.10][51-4-1-0.65][52-4-4-0.44][53-4-4--0.36][54-4-0-0.37][55-4-0-0.42][56-4-1-0.44][57-4-0-2.94][58-4-2-2.22]
[59-4-0-1.80][60-4-3-0.36][61-4-4-0.88][62-4-3-0.46][63-4-2-1.46][64-4-4-0.61][65-4-4-1.04][66-4-4-1.16][67-4-2-0.28][68-4-1-1.56]
[69-4-0-1.86][70-4-4-0.87][72-4-4-1.15][73-4-2-0.63][74-4-2-0.56][75-4-3-0.27][77-4-4-1.91][78-4-4--0.19][79-4-1-0.56][80-4-1-0.73]
[81-4-4-0.91][82-4-4-0.54][83-4-1-0.64][84-4-0-2.32][85-4-0-0.50][86-4-1-0.54][87-4-4-0.91][88-4-4--0.18][89-4-4-0.14][90-4-0-0.15]
[91-4-4-0.25][92-4-3-0.22][93-4-0-1.03][94-4-1-0.10][95-4-3-0.13][96-4-4-0.97][97-4-4-1.35][98-4-2-1.75][99-4-4--0.27][100-4-2-1.04]
[101-4-4-0.46][102-4-2-1.03][103-4-3-1.12][104-4-4-1.03][105-4-1-1.20][106-4-4-0.89][107-4-4-1.19][108-4-4-0.84][109-4-4--0.16][110-4-1-0.28]
[111-4-0-2.69][112-4-0-1.10][113-4-3-0.67][114-4-0-1.17][115-4-0-1.09][116-4-2-0.41][117-4-4-0.91][119-4-4-0.53][121-4-1-1.13][122-4-0-0.48]
[124-4-3-0.16][125-4-1-2.00][126-4-4-0.50][127-4-2-1.02][128-4-0-0.83][129-4-4-0.44][130-4-4-0.56][131-4-3-0.30][132-4-3-0.20][133-4-0-1.57]
[135-4-2-1.60][136-4-1-0.17][137-4-4-0.37][138-4-4-0.91][139-4-0-0.99][140-4-4-0.29][141-4-2-0.99][142-4-4-0.83][143-4-4-1.50][144-4-4-1.38]
[145-4-4-0.60][148-4-0-3.00][149-4-2-0.94][150-4-1-1.20][151-4-2-1.37][152-4-1-1.23][153-4-4-0.82][154-4-3--0.15][155-4-4-0.51][156-4-0-1.44]
[157-4-4-0.75][158-4-0-0.29][160-4-1-0.14][161-4-1-1.53][162-4-4-0.17][164-4-2-0.91][165-4-4-1.02][167-4-0-1.33][168-4-4-0.25][170-4-0-2.61]
[171-4-0-0.65][172-4-4-0.88][173-4-0-0.67][174-4-0-2.56][175-4-4-0.83][177-4-0-2.19][178-4-4-1.26][179-4-3-0.32][180-4-4-0.89][181-4-2-0.56]
[182-4-2-0.31][183-4-0-0.36][184-4-4-1.19][186-4-4--0.06][187-4-1-1.26][188-4-2-0.98][189-4-4-0.63][190-4-4-0.52][191-4-3--0.18][192-4-2-0.14]
[193-4-2-2.22][194-4-3-0.99][195-4-1-0.30][196-4-3-0.48][197-4-1-1.34][198-4-4-1.24][199-4-4--0.21]
---------------------------
I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 1.027 | Acc: 55.000% | Wgt Acc: 59.037%
	I - Batch: 100 | Loss: 1.049 | Acc: 54.562% | Wgt Acc: 58.471%
	I - Batch: 150 | Loss: 1.043 | Acc: 54.708% | Wgt Acc: 58.160%
	I - Batch: 200 | Loss: 1.051 | Acc: 53.938% | Wgt Acc: 57.293%
I - num batch: 222
I - Train -- Loss: 1.044 | Acc: 54.666% | Wgt Acc: 57.900% | LR: 1.000000e-03 | Dur: 178.01s
I - Confusion Matrix: [row->prediction - col->label]
[[496.  12.  20. 127. 135.]
 [ 16. 339. 149.  33. 155.]
 [ 22. 150. 437.  47. 252.]
 [117.  28.  59. 314. 105.]
 [ 46.  49.  69.  17. 353.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.292 | Acc: 46.351% | Wgt Acc: 48.745% | Dur: 15.90s
I - Confusion Matrix: [row->prediction - col->label]
[[53.  3.  6. 24. 21.]
 [ 4. 49. 30.  9. 50.]
 [ 2. 12. 25.  4. 26.]
 [19.  3. 10. 40. 15.]
 [10. 11.  4.  9. 68.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 1.069 | Acc: 52.500% | Wgt Acc: 56.846%
	I - Batch: 100 | Loss: 1.058 | Acc: 54.250% | Wgt Acc: 57.867%
	I - Batch: 150 | Loss: 1.046 | Acc: 55.375% | Wgt Acc: 58.798%
	I - Batch: 200 | Loss: 1.050 | Acc: 54.688% | Wgt Acc: 57.984%
I - num batch: 222
I - Train -- Loss: 1.053 | Acc: 54.835% | Wgt Acc: 57.998% | LR: 1.000000e-03 | Dur: 184.64s
I - Confusion Matrix: [row->prediction - col->label]
[[493.  16.  13. 116. 134.]
 [ 12. 354. 166.  35. 171.]
 [ 16. 136. 418.  49. 210.]
 [122.  26.  65. 314. 119.]
 [ 54.  46.  72.  24. 366.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.281 | Acc: 48.915% | Wgt Acc: 53.111% | Dur: 19.16s
I - Confusion Matrix: [row->prediction - col->label]
[[33.  1.  2.  9.  9.]
 [ 2. 40.  8.  2. 27.]
 [ 8. 29. 57. 14. 64.]
 [43.  4.  6. 59. 21.]
 [ 2.  4.  2.  2. 59.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 1.013 | Acc: 55.875% | Wgt Acc: 58.833%
	I - Batch: 100 | Loss: 0.986 | Acc: 57.438% | Wgt Acc: 60.977%
	I - Batch: 150 | Loss: 0.988 | Acc: 57.125% | Wgt Acc: 60.328%
	I - Batch: 200 | Loss: 0.986 | Acc: 57.719% | Wgt Acc: 60.879%
I - num batch: 222
I - Train -- Loss: 0.989 | Acc: 57.344% | Wgt Acc: 60.598% | LR: 5.000000e-04 | Dur: 185.99s
I - Confusion Matrix: [row->prediction - col->label]
[[514.   7.  16. 106. 135.]
 [ 15. 361. 154.  31. 173.]
 [ 14. 126. 451.  52. 224.]
 [105.  35.  56. 327.  87.]
 [ 49.  49.  57.  22. 381.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.223 | Acc: 49.901% | Wgt Acc: 51.146% | Dur: 17.48s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  4.  5. 23. 32.]
 [ 1. 33. 16.  3. 25.]
 [ 1. 23. 33.  4. 24.]
 [22.  3. 12. 50. 20.]
 [ 6. 15.  9.  6. 79.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.972 | Acc: 58.000% | Wgt Acc: 61.746%
	I - Batch: 100 | Loss: 0.957 | Acc: 59.000% | Wgt Acc: 62.310%
	I - Batch: 150 | Loss: 0.961 | Acc: 58.875% | Wgt Acc: 62.039%
	I - Batch: 200 | Loss: 0.965 | Acc: 58.969% | Wgt Acc: 62.129%
I - num batch: 222
I - Train -- Loss: 0.968 | Acc: 58.726% | Wgt Acc: 61.884% | LR: 5.000000e-04 | Dur: 180.01s
I - Confusion Matrix: [row->prediction - col->label]
[[521.  10.  16. 109. 136.]
 [ 11. 361. 140.  27. 166.]
 [ 15. 124. 464.  47. 189.]
 [107.  31.  54. 338. 110.]
 [ 43.  52.  60.  17. 399.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.237 | Acc: 49.507% | Wgt Acc: 51.528% | Dur: 15.88s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  2.  3. 14. 18.]
 [ 3. 47. 23. 14. 46.]
 [ 1. 18. 37. 14. 39.]
 [16.  2.  3. 37.  5.]
 [10.  9.  9.  7. 72.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.942 | Acc: 58.625% | Wgt Acc: 62.298%
	I - Batch: 100 | Loss: 0.965 | Acc: 57.438% | Wgt Acc: 60.787%
	I - Batch: 150 | Loss: 0.980 | Acc: 57.042% | Wgt Acc: 60.063%
	I - Batch: 200 | Loss: 0.963 | Acc: 58.594% | Wgt Acc: 61.685%
I - num batch: 222
I - Train -- Loss: 0.954 | Acc: 58.951% | Wgt Acc: 62.102% | LR: 5.000000e-04 | Dur: 185.40s
I - Confusion Matrix: [row->prediction - col->label]
[[523.   7.  13. 121. 135.]
 [  9. 367. 134.  25. 172.]
 [ 16. 121. 470.  41. 192.]
 [102.  30.  54. 331. 101.]
 [ 47.  53.  63.  20. 400.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.215 | Acc: 51.085% | Wgt Acc: 54.694% | Dur: 17.00s
I - Confusion Matrix: [row->prediction - col->label]
[[54.  6.  3. 12. 28.]
 [ 1. 40. 17.  4. 34.]
 [ 1. 19. 38.  7. 26.]
 [27.  3.  8. 60. 25.]
 [ 5. 10.  9.  3. 67.]]

I - Local maximum validation set accuracy:  51.08

I - Validation set results: 
[14-1-2-1.67][50-3-4--0.08][124-2-2-2.19][127-0-0-3.33][443-2-2-1.47][567-0-0-1.68][573-1-1-1.04][615-0-3-2.04][695-1-2-1.67][722-3-3-2.88]
[826-0-0-2.49][878-0-3-1.80][1103-0-0-0.88][1212-3-3-1.04][1368-0-0-2.95][2181-2-2--0.02][2476-2-2-0.47][2721-2-2-1.91][2818-1-2-0.22][2886-2-1-1.97]
[3231-2-1-1.45][3333-2-1-1.09][3482-2-2-1.00][3536-3-3-1.51][3625-1-1-2.66][3909-0-0-0.11][4035-0-3-1.67][4140-0-0-2.78][4214-1-1-1.56][4346-1-0-1.00]
[4581-2-2-1.98][4708-3-2-0.22][4838-3-0-1.11][4845-1-1-0.81][4868-0-0-2.45][4939-0-2-0.65][4984-2-2-0.56][5078-1-4-0.64][5396-0-0-4.96][5479-1-1-2.12]
[5717-0-0-0.16][5843-1-1-1.58][5949-3-0-2.68][5987-2-4-1.49][6014-3-1-1.10][6033-3-0-1.30][6313-0-3-2.42][6421-3-3-1.76][6500-1-1-0.51][6583-3-3-0.80]
[6683-3-3-0.79][6825-2-3-1.22][6998-3-3--0.53][7049-3-3-0.67][7517-1-1-2.87][7521-1-1-0.04][7528-1-2-1.31][7949-1-2-1.22][8135-1-0-0.97][8185-3-0-2.30]
[8269-3-2-0.32][8273-3-3-1.76][8543-3-0-4.84][8666-1-1-1.41][8672-0-0-2.36][8903-1-2-0.45][9001-2-1-1.45][9036-2-2-3.08][9281-3-3-0.29][9300-2-2-0.50]
[9571-0-0-0.43][9617-1-0-0.30][9644-2-2-1.52][9705-2-4--0.05][9801-0-3-1.76][9803-3-3-1.70][9865-3-0-2.47][9896-2-4-1.57][10314-1-1-0.89][10337-3-3-2.57]
[10403-0-0-1.22][10653-2-1-0.45][10704-2-3-0.40][10719-1-1-1.91][10727-1-4-1.29][10836-0-0-4.54][10969-2-2-0.66][11042-0-0-0.90][11088-1-1-2.54][11322-0-0-3.08]
[11398-2-2-1.07][11499-0-0-0.38][11502-3-3-1.40][11512-3-3-0.59][11608-1-1-1.67][11610-0-0-1.76][11692-0-3-2.18][11905-0-0-3.31][11993-1-1-1.48][12002-2-3--0.02]
[12052-0-0-2.06][12201-0-3-2.41][12235-2-1-1.26][12320-1-0-0.68][12377-2-4-1.15][12398-2-3-0.84][12503-1-1-0.24][12617-0-1-0.87][12685-3-3-0.37][12738-2-0-0.29]
[12742-2-2-1.32][12823-0-3-2.17][13110-1-1-0.34][13240-3-0-2.62][13253-1-4-2.03][13273-0-0-5.35][13634-1-2--0.17][13763-2-2-1.58][13905-3-3-1.04][14060-2-1-1.67]
[14065-3-3-2.06][14147-3-3-0.95][14595-2-4-1.55][14687-2-2-2.53][14788-2-2-1.89][14869-1-1-1.57][14872-3-4-0.49][14877-1-1-0.97][14927-0-3-2.25][15066-0-0-3.07]
[15175-1-4-0.66][15178-2-3-0.35][15375-3-3-2.05][15389-3-3-2.32][15568-2-1-1.38][15675-3-3-1.22][15869-1-3-0.30][16207-3-3-1.05][16236-0-3-0.50][16302-3-3-0.47]
[16331-2-2-0.74][16381-0-0-1.39][16488-1-1-3.90][16495-0-3-0.39][16650-0-0-3.37][16719-1-2-0.08][16801-0-0-4.18][16828-0-0-2.18][17137-3-3-0.53][17245-1-1-0.60]
[17278-3-3-0.62][17282-0-3--0.27][17311-2-2-1.71][17336-2-1-2.42][17608-3-3-2.59][17627-0-4--0.04][17877-3-1-0.82][17924-1-4-0.06][17984-3-3-2.90][18211-0-3-2.18]
[18276-3-0-2.17][18287-1-1-1.94][18394-0-0-3.16][18428-0-0-0.38][18442-0-3-2.18][18478-3-0-1.69][18607-0-0-1.94][18616-0-0-1.13][18663-0-3-0.54][18718-0-0-2.33]
[18766-2-2-2.17][18824-2-2-1.20][18890-3-2-1.54][18930-3-2-0.55][18938-3-3-1.17][19817-1-2-1.17][19839-0-4-1.43][19930-3-3-1.80][19944-0-0-1.31][20036-2-2-2.48]
[20101-3-3-0.93][20474-1-2-1.58][20547-3-3-1.15][20929-2-2-2.05][21245-1-2-1.54][21257-3-2-0.62][21293-1-1-3.09][21316-1-1-2.75][21384-1-1-1.91][21448-1-2-0.87]
[21483-0-0-2.32][21487-2-2-1.93][21714-0-3-0.99][21943-3-2-1.48][21947-0-0-3.65][21948-0-0-4.05][21965-2-1-1.31][21998-1-1-0.94][22025-0-3-1.24][22228-3-3-1.92]
[22446-1-1-1.62][22494-3-0-2.70][22757-0-0-3.49][22811-3-3-3.44][22976-3-1-0.63][22985-3-3-2.03][23014-0-0-2.76][23112-1-1-1.64][23144-3-3-1.96][23168-2-0-2.20]
[23219-0-0-0.86][23363-3-3-2.71][23470-0-4-0.53][23486-2-2-1.09][23497-0-3-3.49][23516-0-0-3.80][23690-1-4-0.32][23921-2-2-1.30][23936-1-2-1.11][24040-3-4-0.38]
[24111-1-4-1.27][24182-0-3-2.71][24238-3-3-1.49][24290-2-4-0.93][24345-0-0-2.14][24364-1-2-1.68][24427-3-3-1.62][24477-2-1-1.28][24495-2-1-0.91][24893-2-2-1.69]
[25012-1-4--0.03][25121-2-2-1.10][25165-3-3-0.31][25183-0-0-0.67][25297-3-3-1.79][25398-0-0-1.84][25574-2-2-0.64][25644-1-1-3.94][25718-1-4--0.29][25774-2-2-1.72]
[26032-3-3-2.22][26051-3-3-2.53][26120-0-0-0.18][26321-1-1-0.72][26732-1-1-0.93][26784-3-3-3.17][26827-3-3-1.34][26833-0-3-3.45][26838-2-1-0.59][26860-1-4-1.74]
[26948-0-3-1.50][27049-3-3-1.61][27098-1-0-0.27][27526-0-0-3.52][27639-3-3-1.21][27698-3-3-1.95][27772-0-3-2.20][27890-1-1-0.30][28040-0-0-1.53][28503-2-2-1.58]
[28577-1-1-1.66][28959-0-0-5.28][29198-3-3-1.13][29777-0-0-4.79][29877-2-2-1.22][30035-1-2-1.09][30098-0-3-1.20][30326-1-1-3.13][30572-2-2-1.78][30716-0-4-0.34]
[30806-2-1-0.11][30906-1-1-0.99][31007-0-4-1.57][31181-3-3-1.21][31238-0-0-1.74][31347-0-3-2.28][31422-2-4-0.19][31429-3-3-0.66][31431-0-3-1.60][31432-1-1-1.23]
[31477-0-0-3.25][31524-1-2-0.60][31597-1-2-1.49][31619-1-0-0.45][31701-0-0-3.70][31755-0-0-2.59][31854-3-3-1.35][32074-1-3--0.04][32078-3-3-1.17][32111-1-1-1.74]
[32127-1-2-1.25][32140-3-3-1.94][32263-2-2--0.14][32365-0-0-0.89][32411-2-0-2.97][32429-3-0-3.26][32473-3-0-1.69][32574-3-3-2.42][32584-0-0-0.41][32622-0-3-0.76]
[32858-3-3-1.43][32969-3-3-1.79][33016-2-2-0.68][33031-1-3-1.29][33035-2-2-2.25][33133-2-2-1.91][33173-2-2-0.95][33175-3-1-1.28][33306-3-2-1.69][33309-2-3-0.01]
[33474-0-0-0.36][33478-2-3-0.07][33618-1-1--0.01][33712-0-3-1.38][33782-2-4-1.44][33914-3-3-1.75][34076-3-3-0.93][34112-2-1-2.23][34138-2-1-1.69][34239-1-1-0.99]
[34364-2-1-2.06][34617-1-2-0.91][34751-3-3-2.43][34783-2-4-0.80][35015-3-3-0.74][35018-1-1-1.73][35288-2-3-0.80][0-4-4-1.79][1-4-0-1.23][2-4-4-0.99]
[3-4-4-0.03][4-4-3-0.52][5-4-1--0.32][6-4-0-0.28][7-4-1--0.04][8-4-2-0.12][9-4-4-0.24][10-4-4-1.28][11-4-2-1.58][12-4-3--0.12]
[14-4-0-1.47][15-4-3-2.11][16-4-4--0.03][17-4-1-0.69][18-4-4-1.52][19-4-0-2.51][20-4-0--0.01][21-4-2-0.68][22-4-4-1.00][23-4-3--0.46]
[24-4-4-1.92][25-4-0-0.30][26-4-3-0.37][27-4-3-0.16][28-4-4-0.39][29-4-2-1.02][30-4-0-0.62][31-4-2-1.36][32-4-4-2.09][33-4-3-1.34]
[34-4-3-0.33][35-4-0-2.87][37-4-0-1.79][39-4-3-1.41][40-4-0-0.18][41-4-3--0.27][42-4-4-0.46][43-4-1-1.40][45-4-1-1.28][46-4-4-1.37]
[47-4-4-0.95][48-4-1-0.11][51-4-4-1.00][52-4-0-0.35][53-4-1-0.60][54-4-0-0.15][55-4-4-0.75][56-4-2-0.73][57-4-3-1.28][58-4-2-1.85]
[59-4-0-2.30][60-4-4-0.25][61-4-4-2.33][62-4-3-0.43][63-4-2-1.89][64-4-3-0.14][65-4-4-1.41][66-4-1-1.60][67-4-4-0.29][68-4-1-1.67]
[69-4-0-1.78][70-4-4-1.35][72-4-4-2.61][73-4-1-1.12][74-4-2-1.08][75-4-3-0.46][77-4-1-1.39][78-4-4--0.15][79-4-4-1.12][80-4-4-1.44]
[81-4-4-2.60][82-4-4--0.07][83-4-2-0.69][84-4-0-0.86][85-4-4-1.40][86-4-1-1.56][87-4-4-0.96][88-4-4-0.04][89-4-4-0.27][90-4-0-0.63]
[91-4-4--0.15][92-4-3-0.22][93-4-0-0.81][94-4-4-0.30][95-4-3-0.36][96-4-4-1.17][97-4-4-1.32][98-4-2-0.61][99-4-4-0.12][100-4-4-1.85]
[101-4-0-0.66][102-4-2-0.99][103-4-3-0.27][104-4-4-1.40][105-4-1-1.42][106-4-4-1.32][107-4-4-1.90][108-4-4-0.22][109-4-4-0.45][110-4-1-0.64]
[111-4-3-2.62][112-4-0-1.54][113-4-3-0.01][114-4-3-1.02][115-4-4--0.11][116-4-1-0.92][117-4-4-1.63][119-4-2-0.67][121-4-1-0.77][122-4-4--0.32]
[124-4-1-0.59][125-4-1-1.26][126-4-4--0.07][127-4-1-1.30][128-4-4-0.82][129-4-2-0.55][130-4-2-0.80][131-4-3-0.28][132-4-1-0.37][133-4-0-1.45]
[135-4-2-1.42][136-4-1-0.51][137-4-1-0.18][138-4-4-0.32][139-4-0-0.10][140-4-4-0.45][141-4-3-1.03][142-4-4-0.52][143-4-1-1.24][144-4-4-1.24]
[145-4-1-1.00][148-4-0-3.43][149-4-2-0.44][150-4-1-0.66][151-4-2-1.35][152-4-1-1.02][153-4-2-1.47][154-4-4-1.61][155-4-4-0.55][156-4-3-1.32]
[157-4-0-1.57][158-4-4--0.14][160-4-1-0.80][161-4-1-2.21][162-4-4-0.71][164-4-1-0.46][165-4-1-0.31][167-4-0-1.18][168-4-4-0.17][170-4-0-2.88]
[171-4-4-0.53][172-4-1-0.61][173-4-4-0.59][174-4-0-2.57][175-4-4-0.81][177-4-0-1.22][178-4-4-1.16][179-4-3--0.29][180-4-4-0.60][181-4-2-0.05]
[182-4-2-1.83][183-4-4-0.60][184-4-2-1.09][186-4-0-0.42][187-4-1-1.14][188-4-2-1.03][189-4-4-1.44][190-4-4-0.11][191-4-4-1.25][192-4-4-1.36]
[193-4-2-2.48][194-4-2-0.14][195-4-1-0.53][196-4-3-0.50][197-4-2-1.74][198-4-4-2.01][199-4-1-1.09]
---------------------------
I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.997 | Acc: 57.625% | Wgt Acc: 60.693%
	I - Batch: 100 | Loss: 0.970 | Acc: 57.938% | Wgt Acc: 61.100%
	I - Batch: 150 | Loss: 0.963 | Acc: 59.500% | Wgt Acc: 62.560%
	I - Batch: 200 | Loss: 0.948 | Acc: 59.969% | Wgt Acc: 63.206%
I - num batch: 222
I - Train -- Loss: 0.947 | Acc: 60.023% | Wgt Acc: 63.334% | LR: 5.000000e-04 | Dur: 180.55s
I - Confusion Matrix: [row->prediction - col->label]
[[503.  13.  11. 102. 136.]
 [ 14. 385. 129.  31. 161.]
 [ 13. 106. 483.  37. 196.]
 [122.  27.  47. 347.  96.]
 [ 45.  47.  64.  21. 411.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.256 | Acc: 50.888% | Wgt Acc: 53.548% | Dur: 15.64s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  3.  4. 23. 26.]
 [ 1. 36. 16.  2. 34.]
 [ 1. 22. 45.  7. 38.]
 [13.  2.  2. 45. 16.]
 [ 7. 15.  8.  9. 66.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.887 | Acc: 61.875% | Wgt Acc: 64.932%
	I - Batch: 100 | Loss: 0.913 | Acc: 60.000% | Wgt Acc: 63.434%
	I - Batch: 150 | Loss: 0.917 | Acc: 59.875% | Wgt Acc: 63.364%
	I - Batch: 200 | Loss: 0.911 | Acc: 60.531% | Wgt Acc: 63.716%
I - num batch: 222
I - Train -- Loss: 0.912 | Acc: 60.671% | Wgt Acc: 63.853% | LR: 5.000000e-04 | Dur: 181.68s
I - Confusion Matrix: [row->prediction - col->label]
[[510.   8.  15. 104. 120.]
 [ 10. 389. 130.  27. 150.]
 [ 17. 103. 477.  37. 203.]
 [105.  27.  45. 350. 101.]
 [ 55.  51.  67.  20. 426.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.227 | Acc: 51.874% | Wgt Acc: 54.094% | Dur: 16.83s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  3.  5. 23. 26.]
 [ 1. 41. 18.  2. 28.]
 [ 1. 15. 35.  2. 30.]
 [19.  8. 12. 50. 20.]
 [ 6. 11.  5.  9. 76.]]

I - Local maximum validation set accuracy:  51.87

I - Validation set results: 
[14-1-2-2.25][50-3-4--0.24][124-2-2-1.23][127-0-0-3.86][443-2-2-2.16][567-0-0-2.05][573-1-3--0.29][615-0-3-1.94][695-1-2-1.48][722-3-3-3.12]
[826-0-0-3.87][878-0-0-3.03][1103-0-0-0.87][1212-3-3-1.02][1368-0-0-1.62][2181-2-3-0.18][2476-2-2-0.46][2721-2-2-2.06][2818-1-4-0.39][2886-2-1-2.29]
[3231-2-2-2.86][3333-2-1-1.20][3482-2-2-0.92][3536-3-3-2.17][3625-1-1-3.00][3909-0-0-0.69][4035-0-3-2.24][4140-0-0-2.63][4214-1-3-0.97][4346-1-0-1.84]
[4581-2-2-1.60][4708-3-3--0.15][4838-3-0-0.44][4845-1-1-0.60][4868-0-0-2.72][4939-0-2-1.35][4984-2-2-0.86][5078-1-4-1.03][5396-0-0-5.42][5479-1-1-2.05]
[5717-0-0-0.63][5843-1-1-0.46][5949-3-0-2.70][5987-2-1-1.16][6014-3-0-1.00][6033-3-3-0.99][6313-0-3-2.76][6421-3-3-1.59][6500-1-1-0.40][6583-3-3-1.76]
[6683-3-3-1.09][6825-2-3-1.25][6998-3-4--0.19][7049-3-3-0.96][7517-1-1-3.37][7521-1-3--0.33][7528-1-3-0.78][7949-1-2-1.60][8135-1-0-2.28][8185-3-0-3.03]
[8269-3-4-1.04][8273-3-3-1.80][8543-3-0-5.92][8666-1-1-2.33][8672-0-0-2.74][8903-1-2-1.42][9001-2-1-2.03][9036-2-2-2.97][9281-3-4--0.10][9300-2-2-0.87]
[9571-0-3-0.80][9617-1-4-0.76][9644-2-2-1.68][9705-2-4-0.46][9801-0-0-2.49][9803-3-3-1.69][9865-3-0-3.52][9896-2-2-2.26][10314-1-1-0.64][10337-3-3-2.85]
[10403-0-0-0.37][10653-2-1-0.79][10704-2-1-0.42][10719-1-1-2.19][10727-1-4-0.68][10836-0-0-5.70][10969-2-3-1.16][11042-0-0-2.31][11088-1-1-2.57][11322-0-0-3.29]
[11398-2-2-2.13][11499-0-0-0.85][11502-3-0-1.42][11512-3-3-1.02][11608-1-1-2.98][11610-0-0-1.96][11692-0-3-1.77][11905-0-0-3.11][11993-1-2-0.85][12002-2-3-1.48]
[12052-0-0-1.47][12201-0-3-3.12][12235-2-1-1.82][12320-1-4-1.10][12377-2-4-1.15][12398-2-3-0.48][12503-1-1-1.45][12617-0-3-0.34][12685-3-3-0.66][12738-2-3-0.58]
[12742-2-2-2.28][12823-0-3-2.26][13110-1-1-0.96][13240-3-0-3.15][13253-1-4-1.97][13273-0-0-6.13][13634-1-1-0.19][13763-2-2-1.19][13905-3-3-0.82][14060-2-1-1.42]
[14065-3-3-2.66][14147-3-3-1.42][14595-2-2-1.68][14687-2-2-3.03][14788-2-2-1.52][14869-1-1-2.25][14872-3-4-0.94][14877-1-1-0.85][14927-0-3-2.34][15066-0-0-4.08]
[15175-1-4-1.54][15178-2-3-0.01][15375-3-0-2.86][15389-3-3-2.11][15568-2-1-1.02][15675-3-3-1.56][15869-1-1-0.21][16207-3-3-1.11][16236-0-3-0.39][16302-3-0-2.31]
[16331-2-2-1.91][16381-0-0-1.93][16488-1-1-3.06][16495-0-0-2.46][16650-0-0-4.09][16719-1-2-0.04][16801-0-0-5.00][16828-0-0-2.91][17137-3-3-1.06][17245-1-1-0.82]
[17278-3-0-0.63][17282-0-3--0.50][17311-2-2-2.36][17336-2-1-1.82][17608-3-3-3.18][17627-0-4--0.18][17877-3-4-0.90][17924-1-4-0.21][17984-3-0-4.19][18211-0-3-1.46]
[18276-3-0-2.59][18287-1-1--0.17][18394-0-0-3.35][18428-0-0-1.50][18442-0-3-2.85][18478-3-0-2.60][18607-0-0-2.03][18616-0-0-0.87][18663-0-3-0.88][18718-0-0-2.61]
[18766-2-1-2.20][18824-2-1-2.10][18890-3-2-0.30][18930-3-4-0.79][18938-3-0-1.71][19817-1-2-1.61][19839-0-4-0.90][19930-3-3-2.47][19944-0-4-2.38][20036-2-2-2.45]
[20101-3-3-1.86][20474-1-1-1.24][20547-3-3-0.94][20929-2-2-2.48][21245-1-2-1.68][21257-3-3-1.30][21293-1-1-3.33][21316-1-1-2.43][21384-1-1-2.58][21448-1-2-0.55]
[21483-0-0-2.29][21487-2-2-1.90][21714-0-0-1.09][21943-3-4-0.75][21947-0-0-1.53][21948-0-0-4.97][21965-2-2-2.11][21998-1-1-0.33][22025-0-3-0.24][22228-3-3-2.58]
[22446-1-1-1.24][22494-3-0-3.13][22757-0-0-5.04][22811-3-3-3.84][22976-3-1-1.00][22985-3-3-2.37][23014-0-0-4.05][23112-1-1-1.95][23144-3-3-2.65][23168-2-0-0.46]
[23219-0-0-1.20][23363-3-3-3.11][23470-0-0-0.49][23486-2-3-0.55][23497-0-3-4.00][23516-0-0-3.78][23690-1-4-0.13][23921-2-1-1.15][23936-1-2-0.83][24040-3-4-0.69]
[24111-1-4-1.87][24182-0-0-3.52][24238-3-3-1.91][24290-2-0-1.33][24345-0-4-1.43][24364-1-2-1.76][24427-3-0-2.59][24477-2-2-1.33][24495-2-1-0.35][24893-2-2-1.96]
[25012-1-2--0.09][25121-2-2-1.59][25165-3-3-0.52][25183-0-0-1.73][25297-3-3-1.67][25398-0-0-1.82][25574-2-3-0.05][25644-1-1-4.02][25718-1-0-0.20][25774-2-3-0.78]
[26032-3-3-1.82][26051-3-3-3.13][26120-0-4-0.40][26321-1-1-1.22][26732-1-1-1.19][26784-3-3-3.32][26827-3-3-1.30][26833-0-3-3.67][26838-2-2-0.94][26860-1-4-1.32]
[26948-0-0-1.21][27049-3-0-1.43][27098-1-1-0.80][27526-0-0-3.13][27639-3-3-1.17][27698-3-3-2.97][27772-0-0-3.96][27890-1-1-1.08][28040-0-3-0.09][28503-2-2-2.56]
[28577-1-1-1.76][28959-0-0-4.00][29198-3-3-1.22][29777-0-0-5.27][29877-2-2-1.36][30035-1-2-1.89][30098-0-0-1.82][30326-1-1-2.72][30572-2-3-1.16][30716-0-4-1.00]
[30806-2-1--0.20][30906-1-1-1.53][31007-0-0-2.77][31181-3-0-1.93][31238-0-0-2.93][31347-0-0-3.66][31422-2-4-0.30][31429-3-3-0.33][31431-0-0-0.61][31432-1-1-1.40]
[31477-0-0-4.09][31524-1-1-1.55][31597-1-2-1.54][31619-1-3-0.26][31701-0-0-3.22][31755-0-0-2.96][31854-3-3-2.50][32074-1-3-0.82][32078-3-3-1.64][32111-1-1-1.47]
[32127-1-2-1.94][32140-3-3-1.84][32263-2-0-0.50][32365-0-0-0.48][32411-2-0-3.27][32429-3-0-4.63][32473-3-0-2.28][32574-3-0-3.67][32584-0-0-1.54][32622-0-1-0.14]
[32858-3-0-3.06][32969-3-3-1.64][33016-2-2-2.14][33031-1-3-1.49][33035-2-2-3.06][33133-2-1-2.20][33173-2-2-1.07][33175-3-1-1.06][33306-3-2-1.01][33309-2-3--0.45]
[33474-0-0-0.82][33478-2-0-0.59][33618-1-3-0.23][33712-0-3-1.39][33782-2-4-2.29][33914-3-3-1.70][34076-3-3-1.20][34112-2-1-1.81][34138-2-2-1.74][34239-1-1-0.61]
[34364-2-1-2.56][34617-1-1-1.20][34751-3-3-3.07][34783-2-4-0.76][35015-3-3-1.09][35018-1-1-1.90][35288-2-2-1.08][0-4-1-0.17][1-4-0-0.57][2-4-4-0.71]
[3-4-4-0.52][4-4-4-0.06][5-4-1-2.06][6-4-0-2.68][7-4-1-0.33][8-4-2-0.27][9-4-1-0.24][10-4-4-1.69][11-4-2-2.19][12-4-3-0.05]
[14-4-0-1.60][15-4-0-2.84][16-4-3-0.10][17-4-1-0.22][18-4-4-1.00][19-4-3-1.66][20-4-0-0.85][21-4-1-1.35][22-4-4-1.19][23-4-4--0.24]
[24-4-4-2.06][25-4-3-1.19][26-4-3-1.24][27-4-3-0.78][28-4-1-1.13][29-4-2-0.85][30-4-2-0.59][31-4-2-0.82][32-4-4-2.71][33-4-3-0.93]
[34-4-3-0.32][35-4-0-1.56][37-4-3-0.72][39-4-0-2.94][40-4-2-1.15][41-4-0-0.85][42-4-4-0.77][43-4-1-1.57][45-4-3-1.53][46-4-4-1.58]
[47-4-4-1.41][48-4-1-0.71][51-4-4-1.29][52-4-4-1.19][53-4-1-0.30][54-4-0-0.32][55-4-4-1.11][56-4-1-1.52][57-4-3-2.19][58-4-2-1.26]
[59-4-0-2.08][60-4-1-0.15][61-4-4-2.45][62-4-3-0.62][63-4-4-1.03][64-4-2-0.52][65-4-4-1.79][66-4-4-1.44][67-4-2-0.17][68-4-1-0.90]
[69-4-0-1.14][70-4-4-1.15][72-4-4-1.63][73-4-2-0.98][74-4-2-1.17][75-4-3-0.14][77-4-4-2.59][78-4-1-0.09][79-4-1-1.22][80-4-4-1.86]
[81-4-4-1.65][82-4-4-0.20][83-4-4-0.18][84-4-4-0.47][85-4-4-1.53][86-4-4-0.65][87-4-4-0.49][88-4-1-0.99][89-4-4-0.29][90-4-0-0.64]
[91-4-4-0.59][92-4-3-0.01][93-4-4--0.41][94-4-4-0.51][95-4-4-0.23][96-4-4-1.11][97-4-1-2.20][98-4-2-2.02][99-4-4-0.51][100-4-4-1.37]
[101-4-4-0.97][102-4-2-1.37][103-4-3--0.01][104-4-4-0.88][105-4-4-1.48][106-4-1-1.46][107-4-4-1.64][108-4-4-0.38][109-4-1-0.28][110-4-4-0.74]
[111-4-0-3.68][112-4-4-1.18][113-4-2--0.12][114-4-0-1.49][115-4-4--0.06][116-4-4-0.70][117-4-4-2.03][119-4-2-0.88][121-4-2-1.05][122-4-4--0.00]
[124-4-3-0.21][125-4-4-1.35][126-4-1-0.21][127-4-2-2.03][128-4-4-0.56][129-4-4-0.20][130-4-4-0.89][131-4-3-0.25][132-4-2-0.10][133-4-0-1.71]
[135-4-2-1.11][136-4-4-0.34][137-4-2--0.37][138-4-4-1.65][139-4-4-0.57][140-4-4-1.04][141-4-0-3.07][142-4-4-1.30][143-4-4-1.61][144-4-4-2.01]
[145-4-1-2.40][148-4-0-3.60][149-4-4-0.37][150-4-1-1.25][151-4-2-1.19][152-4-1-1.56][153-4-1-1.49][154-4-4-1.16][155-4-1-1.19][156-4-0-1.11]
[157-4-0-1.20][158-4-3-0.26][160-4-1-1.44][161-4-2-2.51][162-4-4-0.33][164-4-2-0.82][165-4-4-1.88][167-4-0-0.87][168-4-4-0.25][170-4-0-3.12]
[171-4-4-1.25][172-4-2-1.08][173-4-4-1.58][174-4-0-2.44][175-4-4-1.15][177-4-0-2.83][178-4-4-1.30][179-4-0-0.20][180-4-4-0.68][181-4-3-1.22]
[182-4-2-1.18][183-4-4-0.69][184-4-2-1.23][186-4-0-0.77][187-4-1-1.74][188-4-2-0.93][189-4-4-1.54][190-4-4-0.06][191-4-4-0.36][192-4-4-1.06]
[193-4-2-2.79][194-4-3-0.18][195-4-0-1.56][196-4-2-0.22][197-4-2-1.57][198-4-4-2.84][199-4-1-1.35]
---------------------------
I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.890 | Acc: 63.375% | Wgt Acc: 66.972%
	I - Batch: 100 | Loss: 0.885 | Acc: 63.750% | Wgt Acc: 67.157%
	I - Batch: 150 | Loss: 0.884 | Acc: 63.500% | Wgt Acc: 66.972%
	I - Batch: 200 | Loss: 0.892 | Acc: 63.094% | Wgt Acc: 66.475%
I - num batch: 222
I - Train -- Loss: 0.893 | Acc: 62.898% | Wgt Acc: 66.161% | LR: 5.000000e-04 | Dur: 184.93s
I - Confusion Matrix: [row->prediction - col->label]
[[526.  10.  10.  97. 130.]
 [ 12. 413. 122.  28. 147.]
 [ 13.  91. 489.  33. 189.]
 [ 85.  26.  49. 357.  88.]
 [ 61.  38.  64.  23. 446.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.191 | Acc: 53.846% | Wgt Acc: 53.930% | Dur: 19.88s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  2.  4. 21. 17.]
 [ 3. 35. 13.  6. 26.]
 [ 2. 20. 40.  9. 38.]
 [13.  1.  4. 45.  7.]
 [ 9. 20. 14.  5. 92.]]

I - Local maximum validation set accuracy:  53.85

I - Validation set results: 
[14-1-2-2.14][50-3-4-0.29][124-2-2-1.63][127-0-0-2.94][443-2-2-1.67][567-0-0-1.91][573-1-1-1.08][615-0-3-1.51][695-1-2-1.07][722-3-3-2.53]
[826-0-0-2.19][878-0-0-2.00][1103-0-4-1.11][1212-3-3--0.26][1368-0-0-1.78][2181-2-2-0.03][2476-2-4-0.27][2721-2-2-1.39][2818-1-4-0.80][2886-2-1-1.77]
[3231-2-1-2.67][3333-2-1-2.08][3482-2-2-0.95][3536-3-3-0.91][3625-1-1-2.23][3909-0-0-0.85][4035-0-3-1.16][4140-0-0-0.99][4214-1-2-0.95][4346-1-0-1.31]
[4581-2-2-1.98][4708-3-2-1.23][4838-3-0-0.32][4845-1-2-0.92][4868-0-0-2.04][4939-0-4-0.25][4984-2-2-1.15][5078-1-4-0.92][5396-0-0-4.36][5479-1-1-2.40]
[5717-0-0-1.71][5843-1-1-2.25][5949-3-0-1.98][5987-2-4-1.18][6014-3-1-0.41][6033-3-3-0.07][6313-0-3-1.63][6421-3-3-0.89][6500-1-1-0.61][6583-3-3-0.56]
[6683-3-3-1.11][6825-2-3-0.66][6998-3-2-0.07][7049-3-1-0.47][7517-1-1-2.65][7521-1-1--0.02][7528-1-2--0.03][7949-1-2-1.84][8135-1-0-2.40][8185-3-0-2.17]
[8269-3-4-0.64][8273-3-0-1.19][8543-3-0-5.00][8666-1-1-1.72][8672-0-0-1.79][8903-1-4-0.28][9001-2-1-2.48][9036-2-2-3.05][9281-3-1-0.36][9300-2-2-0.30]
[9571-0-0-0.47][9617-1-4-0.73][9644-2-2-0.63][9705-2-4-0.29][9801-0-0-0.61][9803-3-3-1.33][9865-3-3-1.85][9896-2-2-1.53][10314-1-4-0.44][10337-3-3-1.61]
[10403-0-4-1.11][10653-2-4-0.47][10704-2-1-1.80][10719-1-1-2.42][10727-1-4-1.72][10836-0-0-4.70][10969-2-3-0.07][11042-0-0-1.08][11088-1-1-2.27][11322-0-0-2.51]
[11398-2-4-1.86][11499-0-0-0.42][11502-3-0-0.67][11512-3-3--0.16][11608-1-1-2.83][11610-0-0-0.91][11692-0-0-1.11][11905-0-0-1.59][11993-1-1-0.72][12002-2-3-2.03]
[12052-0-0-1.56][12201-0-0-2.39][12235-2-1-1.41][12320-1-4-2.09][12377-2-4-1.72][12398-2-3-0.17][12503-1-4-0.94][12617-0-1-1.20][12685-3-2-0.99][12738-2-0-0.77]
[12742-2-2-1.34][12823-0-0-1.47][13110-1-2-1.72][13240-3-0-2.65][13253-1-4-1.63][13273-0-0-4.75][13634-1-2-0.70][13763-2-2-1.35][13905-3-3-0.11][14060-2-1-2.39]
[14065-3-3-1.48][14147-3-3-0.08][14595-2-4-1.36][14687-2-2-2.40][14788-2-2-1.26][14869-1-1-1.33][14872-3-4-0.82][14877-1-1-0.77][14927-0-3-1.12][15066-0-0-3.22]
[15175-1-4-1.28][15178-2-4--0.08][15375-3-0-2.04][15389-3-3-1.68][15568-2-1-1.37][15675-3-3-0.36][15869-1-2-1.26][16207-3-3-0.03][16236-0-3-0.12][16302-3-0-1.45]
[16331-2-2-0.83][16381-0-3-0.68][16488-1-1-1.86][16495-0-0-1.74][16650-0-0-3.09][16719-1-4-0.37][16801-0-0-3.77][16828-0-0-1.54][17137-3-3-0.32][17245-1-4-0.68]
[17278-3-0-0.21][17282-0-1--0.28][17311-2-2-1.70][17336-2-1-2.00][17608-3-3-2.35][17627-0-0-0.91][17877-3-1-0.69][17924-1-4--0.00][17984-3-0-3.30][18211-0-3-0.65]
[18276-3-0-2.15][18287-1-1--0.09][18394-0-0-3.08][18428-0-1--0.28][18442-0-3-1.56][18478-3-0-1.74][18607-0-0-2.09][18616-0-0-0.63][18663-0-0-0.17][18718-0-0-2.90]
[18766-2-2-2.87][18824-2-1-1.32][18890-3-2-1.20][18930-3-4-1.44][18938-3-0-0.91][19817-1-2-1.49][19839-0-4-1.71][19930-3-3-1.42][19944-0-4-2.00][20036-2-2-2.30]
[20101-3-3-0.48][20474-1-2-1.37][20547-3-3-0.47][20929-2-2-2.37][21245-1-2-1.93][21257-3-3-0.26][21293-1-1-3.32][21316-1-1-2.49][21384-1-4-1.06][21448-1-2-1.23]
[21483-0-0-2.00][21487-2-2-1.83][21714-0-0-0.75][21943-3-2-0.67][21947-0-0-2.14][21948-0-0-4.70][21965-2-2-1.75][21998-1-1-0.36][22025-0-2-1.10][22228-3-3-1.53]
[22446-1-1-1.90][22494-3-0-2.72][22757-0-0-3.07][22811-3-3-2.51][22976-3-2-1.05][22985-3-3-1.36][23014-0-0-3.57][23112-1-1-1.40][23144-3-3-1.97][23168-2-0-0.50]
[23219-0-0-0.22][23363-3-3-1.87][23470-0-4-0.40][23486-2-2-0.94][23497-0-3-3.06][23516-0-0-2.85][23690-1-4-0.50][23921-2-2-1.54][23936-1-2-1.41][24040-3-4-1.11]
[24111-1-4-1.77][24182-0-0-2.84][24238-3-3-1.21][24290-2-4-0.82][24345-0-0-3.05][24364-1-2-1.54][24427-3-0-0.65][24477-2-4-1.32][24495-2-1-1.67][24893-2-2-2.01]
[25012-1-2-0.10][25121-2-2-1.35][25165-3-1-0.52][25183-0-0-1.48][25297-3-3-0.51][25398-0-0-1.40][25574-2-2-1.62][25644-1-1-3.39][25718-1-1-0.43][25774-2-2-0.58]
[26032-3-3-1.16][26051-3-3-2.00][26120-0-4-0.92][26321-1-1-1.50][26732-1-1-0.71][26784-3-3-2.66][26827-3-3-0.46][26833-0-3-2.64][26838-2-2-1.12][26860-1-4-1.79]
[26948-0-0-0.51][27049-3-3-0.27][27098-1-4-0.05][27526-0-0-1.45][27639-3-3-0.45][27698-3-3-1.80][27772-0-0-3.48][27890-1-1-1.21][28040-0-0-1.83][28503-2-2-2.02]
[28577-1-1-1.94][28959-0-0-4.17][29198-3-3-0.22][29777-0-0-4.34][29877-2-2-1.44][30035-1-2-1.85][30098-0-3-0.90][30326-1-1-2.66][30572-2-2-1.65][30716-0-4-1.00]
[30806-2-2-0.45][30906-1-1-1.80][31007-0-0-1.56][31181-3-3-0.28][31238-0-3-0.11][31347-0-0-3.27][31422-2-2-0.36][31429-3-2--0.07][31431-0-0--0.20][31432-1-1-1.85]
[31477-0-0-2.98][31524-1-2-0.07][31597-1-1-1.04][31619-1-3-0.07][31701-0-0-2.50][31755-0-0-2.51][31854-3-3-1.01][32074-1-4--0.28][32078-3-3-0.37][32111-1-1-1.68]
[32127-1-2-1.75][32140-3-3-1.35][32263-2-4-0.73][32365-0-0-1.17][32411-2-0-2.36][32429-3-0-3.54][32473-3-0-1.38][32574-3-0-2.55][32584-0-4-0.38][32622-0-2-0.00]
[32858-3-0-1.73][32969-3-0-1.47][33016-2-2-1.92][33031-1-1-0.34][33035-2-2-2.35][33133-2-2-1.96][33173-2-2-0.94][33175-3-1-1.47][33306-3-2-1.77][33309-2-0--0.56]
[33474-0-3-0.22][33478-2-4-0.41][33618-1-1-0.46][33712-0-0-1.23][33782-2-4-1.45][33914-3-3-0.62][34076-3-3-0.74][34112-2-1-2.71][34138-2-2-1.99][34239-1-1-0.55]
[34364-2-1-2.58][34617-1-2-1.19][34751-3-3-2.21][34783-2-4-1.02][35015-3-2-1.52][35018-1-4-0.95][35288-2-2-0.23][0-4-4-1.50][1-4-0-1.34][2-4-4-1.51]
[3-4-4-0.46][4-4-3--0.24][5-4-1-0.40][6-4-4-1.76][7-4-2-0.52][8-4-2-0.47][9-4-1-0.16][10-4-4-1.53][11-4-2-1.48][12-4-1-1.04]
[14-4-0-1.26][15-4-3-1.64][16-4-4-0.40][17-4-4-0.60][18-4-4-1.81][19-4-0-1.66][20-4-4-0.06][21-4-1-1.21][22-4-4-1.16][23-4-1-0.34]
[24-4-4-3.30][25-4-0-0.39][26-4-3--0.06][27-4-2-0.89][28-4-4-1.42][29-4-2-0.69][30-4-0-0.50][31-4-2-1.06][32-4-1-2.59][33-4-3-0.34]
[34-4-2-0.00][35-4-3--0.10][37-4-2-0.22][39-4-0-1.71][40-4-4-0.82][41-4-1-0.92][42-4-2-1.47][43-4-1-0.46][45-4-2-0.83][46-4-4-1.68]
[47-4-4-1.24][48-4-4-0.48][51-4-4-1.37][52-4-4-1.20][53-4-1-1.10][54-4-4-0.11][55-4-4-0.98][56-4-1-2.00][57-4-0-1.67][58-4-2-1.51]
[59-4-0-1.41][60-4-1--0.04][61-4-4-1.90][62-4-2-0.05][63-4-2-1.48][64-4-2-1.17][65-4-4-2.14][66-4-4-1.58][67-4-4-1.02][68-4-1-2.06]
[69-4-0-0.92][70-4-4-1.48][72-4-4-1.83][73-4-2-1.09][74-4-4-0.53][75-4-2-0.03][77-4-1-1.54][78-4-4-0.27][79-4-4-1.00][80-4-4-1.04]
[81-4-4-1.66][82-4-4-0.37][83-4-2-1.34][84-4-4-0.95][85-4-4-1.60][86-4-4-1.36][87-4-4-0.92][88-4-4-1.26][89-4-2-0.59][90-4-4-0.21]
[91-4-4-1.25][92-4-0-0.66][93-4-4--0.05][94-4-4-0.88][95-4-2-0.61][96-4-4-1.27][97-4-4-1.69][98-4-2-1.07][99-4-4-0.35][100-4-4-1.78]
[101-4-4-1.35][102-4-2-0.88][103-4-4--0.14][104-4-4-1.43][105-4-1-1.47][106-4-4-1.73][107-4-4-2.46][108-4-4-0.28][109-4-1-0.68][110-4-4-0.78]
[111-4-0-2.11][112-4-4-1.10][113-4-4-0.20][114-4-3-0.08][115-4-4-0.54][116-4-4-0.62][117-4-4-1.05][119-4-2-2.34][121-4-4-0.77][122-4-1-0.20]
[124-4-1-0.39][125-4-1-1.24][126-4-4-1.95][127-4-2-1.37][128-4-4-0.46][129-4-2-1.09][130-4-2-1.34][131-4-2-0.64][132-4-4-0.43][133-4-4-1.78]
[135-4-2-1.46][136-4-1-0.43][137-4-2-0.28][138-4-4-1.22][139-4-4-0.72][140-4-4-1.14][141-4-3-0.58][142-4-4-1.00][143-4-4-2.08][144-4-4-2.26]
[145-4-1-2.55][148-4-0-3.87][149-4-4-0.87][150-4-1-1.42][151-4-2-0.95][152-4-2-1.64][153-4-4-1.10][154-4-4-1.72][155-4-4-1.22][156-4-0-0.70]
[157-4-4-0.81][158-4-4-0.45][160-4-1-1.33][161-4-2-1.51][162-4-4-0.13][164-4-4-0.84][165-4-1-1.79][167-4-4-1.29][168-4-4-1.27][170-4-4-0.41]
[171-4-4-1.13][172-4-4-0.79][173-4-4-1.43][174-4-0-2.47][175-4-4-1.45][177-4-4-0.44][178-4-4-1.42][179-4-4-0.74][180-4-4-1.26][181-4-2-1.00]
[182-4-2-1.91][183-4-4-0.71][184-4-2-0.66][186-4-0-0.11][187-4-1-1.59][188-4-2-1.41][189-4-4-1.26][190-4-1-0.72][191-4-0-0.74][192-4-4-1.80]
[193-4-2-2.45][194-4-2-1.17][195-4-0-0.87][196-4-2-0.77][197-4-4-1.43][198-4-4-2.15][199-4-1-0.58]
---------------------------
I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.891 | Acc: 62.500% | Wgt Acc: 65.997%
	I - Batch: 100 | Loss: 0.878 | Acc: 62.625% | Wgt Acc: 65.769%
	I - Batch: 150 | Loss: 0.892 | Acc: 61.375% | Wgt Acc: 64.434%
	I - Batch: 200 | Loss: 0.888 | Acc: 62.031% | Wgt Acc: 65.062%
I - num batch: 222
I - Train -- Loss: 0.886 | Acc: 61.968% | Wgt Acc: 64.995% | LR: 5.000000e-04 | Dur: 182.69s
I - Confusion Matrix: [row->prediction - col->label]
[[521.   7.  12.  93. 140.]
 [ 19. 396. 117.  29. 138.]
 [ 13. 105. 478.  44. 188.]
 [ 93.  27.  61. 355.  86.]
 [ 51.  43.  66.  17. 448.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.339 | Acc: 48.718% | Wgt Acc: 53.712% | Dur: 16.05s
I - Confusion Matrix: [row->prediction - col->label]
[[51.  1.  3. 13. 19.]
 [ 1. 39. 13.  4. 39.]
 [ 1. 22. 47.  9. 41.]
 [30.  8.  8. 59. 30.]
 [ 5.  8.  4.  1. 51.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.873 | Acc: 62.250% | Wgt Acc: 65.617%
	I - Batch: 100 | Loss: 0.859 | Acc: 64.375% | Wgt Acc: 67.581%
	I - Batch: 150 | Loss: 0.857 | Acc: 64.750% | Wgt Acc: 67.764%
	I - Batch: 200 | Loss: 0.858 | Acc: 64.969% | Wgt Acc: 68.020%
I - num batch: 222
I - Train -- Loss: 0.866 | Acc: 64.703% | Wgt Acc: 67.904% | LR: 5.000000e-04 | Dur: 181.90s
I - Confusion Matrix: [row->prediction - col->label]
[[526.   5.  16.  78. 128.]
 [ 15. 416. 103.  24. 149.]
 [ 16.  95. 508.  41. 164.]
 [ 85.  25.  47. 376.  90.]
 [ 55.  37.  60.  19. 469.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.275 | Acc: 50.099% | Wgt Acc: 54.694% | Dur: 17.96s
I - Confusion Matrix: [row->prediction - col->label]
[[50.  2.  2.  9. 25.]
 [ 1. 43. 17.  3. 26.]
 [ 2. 15. 35.  4. 30.]
 [31. 11. 16. 65. 38.]
 [ 4.  7.  5.  5. 61.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.817 | Acc: 64.500% | Wgt Acc: 68.546%
	I - Batch: 100 | Loss: 0.838 | Acc: 65.250% | Wgt Acc: 68.797%
	I - Batch: 150 | Loss: 0.850 | Acc: 64.500% | Wgt Acc: 67.826%
	I - Batch: 200 | Loss: 0.856 | Acc: 64.375% | Wgt Acc: 67.755%
I - num batch: 222
I - Train -- Loss: 0.853 | Acc: 64.421% | Wgt Acc: 67.724% | LR: 5.000000e-04 | Dur: 180.68s
I - Confusion Matrix: [row->prediction - col->label]
[[529.   6.   8.  96. 139.]
 [  5. 421.  93.  26. 142.]
 [ 13.  86. 515.  35. 170.]
 [ 91.  24.  51. 363.  92.]
 [ 59.  41.  67.  18. 457.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.192 | Acc: 53.452% | Wgt Acc: 56.223% | Dur: 15.86s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  5.  5. 20. 25.]
 [ 0. 46. 24.  2. 30.]
 [ 1. 11. 29.  4. 20.]
 [20.  6. 10. 56. 27.]
 [ 5. 10.  7.  4. 78.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.835 | Acc: 65.625% | Wgt Acc: 69.481%
	I - Batch: 100 | Loss: 0.827 | Acc: 66.000% | Wgt Acc: 69.990%
	I - Batch: 150 | Loss: 0.824 | Acc: 66.417% | Wgt Acc: 70.285%
	I - Batch: 200 | Loss: 0.819 | Acc: 66.906% | Wgt Acc: 70.642%
I - num batch: 222
I - Train -- Loss: 0.818 | Acc: 66.958% | Wgt Acc: 70.686% | LR: 5.000000e-04 | Dur: 181.92s
I - Confusion Matrix: [row->prediction - col->label]
[[538.   6.   8.  84. 146.]
 [  9. 445.  84.  19. 154.]
 [ 12.  79. 544.  34. 165.]
 [ 81.  24.  41. 385.  72.]
 [ 57.  24.  57.  16. 463.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.194 | Acc: 52.663% | Wgt Acc: 54.421% | Dur: 19.59s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  4.  6. 28. 31.]
 [ 1. 41. 14.  4. 30.]
 [ 0. 13. 33.  4. 17.]
 [ 8.  4. 12. 44. 24.]
 [ 8. 16. 10.  6. 78.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.781 | Acc: 66.875% | Wgt Acc: 70.122%
	I - Batch: 100 | Loss: 0.759 | Acc: 68.062% | Wgt Acc: 71.560%
	I - Batch: 150 | Loss: 0.754 | Acc: 68.042% | Wgt Acc: 71.655%
	I - Batch: 200 | Loss: 0.749 | Acc: 68.844% | Wgt Acc: 72.359%
I - num batch: 222
I - Train -- Loss: 0.752 | Acc: 69.044% | Wgt Acc: 72.520% | LR: 2.500000e-04 | Dur: 183.66s
I - Confusion Matrix: [row->prediction - col->label]
[[554.   1.   9.  74. 123.]
 [  8. 458.  84.  20. 130.]
 [ 13.  62. 546.  31. 164.]
 [ 69.  21.  33. 392.  84.]
 [ 53.  36.  62.  21. 499.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.131 | Acc: 58.580% | Wgt Acc: 57.151% | Dur: 16.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   4.   6.  29.  26.]
 [  1.  38.  16.   5.  21.]
 [  0.  13.  38.   3.  15.]
 [  9.   4.   2.  39.   9.]
 [  5.  19.  13.  10. 109.]]

I - Local maximum validation set accuracy:  58.58

I - Validation set results: 
[14-1-2-1.82][50-3-4-0.49][124-2-2-0.88][127-0-0-3.50][443-2-2-1.60][567-0-0-1.55][573-1-1-0.84][615-0-3-1.87][695-1-2-0.90][722-3-3-2.34]
[826-0-0-2.83][878-0-0-3.80][1103-0-0-1.56][1212-3-0-0.32][1368-0-0-2.48][2181-2-3-0.03][2476-2-2-0.61][2721-2-2-1.35][2818-1-4-0.52][2886-2-1-2.01]
[3231-2-1-2.86][3333-2-1-1.24][3482-2-4-1.16][3536-3-3-1.01][3625-1-1-2.40][3909-0-0-1.22][4035-0-0-1.51][4140-0-0-1.66][4214-1-1-1.06][4346-1-0-0.62]
[4581-2-2-1.53][4708-3-2-0.72][4838-3-0-0.73][4845-1-1-0.57][4868-0-0-1.76][4939-0-4-0.40][4984-2-2-0.52][5078-1-4-1.31][5396-0-0-4.46][5479-1-1-2.58]
[5717-0-0-2.93][5843-1-4-0.41][5949-3-0-2.09][5987-2-4-1.10][6014-3-1-1.63][6033-3-3-0.37][6313-0-0-3.13][6421-3-3-1.12][6500-1-1-0.29][6583-3-3-1.44]
[6683-3-3-0.48][6825-2-0-0.75][6998-3-4-0.09][7049-3-3-1.09][7517-1-1-2.80][7521-1-0--0.57][7528-1-2-0.39][7949-1-2-1.08][8135-1-4-0.92][8185-3-0-2.06]
[8269-3-2-1.37][8273-3-0-1.31][8543-3-0-3.96][8666-1-1-2.83][8672-0-0-3.68][8903-1-2-0.29][9001-2-2-1.82][9036-2-2-2.68][9281-3-4--0.06][9300-2-2-0.32]
[9571-0-0-0.67][9617-1-1-0.39][9644-2-2-0.89][9705-2-4-0.07][9801-0-0-1.48][9803-3-0-0.74][9865-3-0-2.62][9896-2-4-1.83][10314-1-1-0.49][10337-3-3-1.37]
[10403-0-0-1.17][10653-2-1-0.01][10704-2-1-0.41][10719-1-1-2.45][10727-1-4-1.17][10836-0-0-7.04][10969-2-2-0.03][11042-0-0-0.44][11088-1-2-2.60][11322-0-0-2.34]
[11398-2-2-0.68][11499-0-0-1.06][11502-3-0-1.56][11512-3-0-0.24][11608-1-1-2.30][11610-0-0-2.05][11692-0-3-1.14][11905-0-0-2.45][11993-1-1-1.32][12002-2-2-0.25]
[12052-0-0-2.52][12201-0-0-3.23][12235-2-4-1.19][12320-1-4-1.79][12377-2-4-2.24][12398-2-1-0.02][12503-1-1-1.37][12617-0-1-0.15][12685-3-3-0.22][12738-2-0-1.12]
[12742-2-2-2.20][12823-0-0-1.73][13110-1-1-1.31][13240-3-0-3.95][13253-1-4-1.54][13273-0-0-6.50][13634-1-4-0.09][13763-2-2-0.58][13905-3-3-0.10][14060-2-1-1.91]
[14065-3-3-1.54][14147-3-0-1.64][14595-2-4-1.04][14687-2-2-2.93][14788-2-2-1.29][14869-1-1-1.90][14872-3-4-0.73][14877-1-1-1.38][14927-0-3-1.58][15066-0-0-4.15]
[15175-1-4-1.71][15178-2-3-0.11][15375-3-3-1.83][15389-3-3-1.96][15568-2-1-0.82][15675-3-3-1.15][15869-1-4--0.39][16207-3-4-0.08][16236-0-3--0.22][16302-3-0-2.71]
[16331-2-2-2.57][16381-0-3-0.67][16488-1-1-2.47][16495-0-0-2.36][16650-0-0-3.44][16719-1-4-0.27][16801-0-0-4.17][16828-0-0-2.20][17137-3-0-1.48][17245-1-1-1.34]
[17278-3-0--0.20][17282-0-0--0.53][17311-2-2-1.84][17336-2-1-0.28][17608-3-3-2.41][17627-0-0-0.71][17877-3-4-0.75][17924-1-4-0.19][17984-3-0-3.90][18211-0-0-1.29]
[18276-3-0-3.09][18287-1-4-0.23][18394-0-0-3.16][18428-0-0-0.88][18442-0-3-1.65][18478-3-0-2.55][18607-0-0-2.13][18616-0-0-0.47][18663-0-3-0.43][18718-0-0-3.31]
[18766-2-2-2.11][18824-2-1-1.36][18890-3-3-0.09][18930-3-4-1.82][18938-3-0-1.02][19817-1-4-0.79][19839-0-4-1.43][19930-3-3-1.85][19944-0-4-1.03][20036-2-2-2.04]
[20101-3-0-0.58][20474-1-1-1.21][20547-3-3-0.63][20929-2-1-1.23][21245-1-2-1.56][21257-3-3-0.81][21293-1-1-2.89][21316-1-1-2.42][21384-1-1-2.13][21448-1-2-0.50]
[21483-0-0-2.84][21487-2-2-1.38][21714-0-0-1.96][21943-3-4-0.70][21947-0-0-1.87][21948-0-0-5.33][21965-2-2-2.24][21998-1-1-0.58][22025-0-4-1.20][22228-3-3-1.52]
[22446-1-1-1.63][22494-3-0-2.86][22757-0-0-4.66][22811-3-3-2.11][22976-3-1-1.42][22985-3-3-1.82][23014-0-0-4.41][23112-1-1-1.21][23144-3-3-1.92][23168-2-0--0.10]
[23219-0-0-1.29][23363-3-3-1.39][23470-0-0-1.56][23486-2-2-1.45][23497-0-0-3.06][23516-0-0-2.86][23690-1-4--0.33][23921-2-2-0.82][23936-1-3-0.31][24040-3-4-0.91]
[24111-1-4-1.65][24182-0-0-3.66][24238-3-3-1.67][24290-2-4-1.50][24345-0-0-2.21][24364-1-2-1.04][24427-3-0-1.65][24477-2-4-1.40][24495-2-1-1.02][24893-2-2-1.54]
[25012-1-4-0.18][25121-2-2-1.54][25165-3-1-0.20][25183-0-0-2.42][25297-3-3-0.78][25398-0-0-1.96][25574-2-2-0.71][25644-1-1-3.89][25718-1-0-0.24][25774-2-2-0.13]
[26032-3-3-0.92][26051-3-3-2.02][26120-0-0-1.53][26321-1-1-1.80][26732-1-1-0.64][26784-3-3-2.79][26827-3-3-0.07][26833-0-3-2.28][26838-2-2-0.71][26860-1-4-1.09]
[26948-0-0-0.70][27049-3-0-0.48][27098-1-0-0.51][27526-0-0-1.09][27639-3-0-0.98][27698-3-3-1.63][27772-0-0-1.78][27890-1-1-1.14][28040-0-0-1.50][28503-2-2-2.41]
[28577-1-1-1.75][28959-0-0-3.75][29198-3-3-0.35][29777-0-0-4.82][29877-2-2-0.62][30035-1-2-1.79][30098-0-0-0.72][30326-1-1-3.16][30572-2-2-1.05][30716-0-4-1.48]
[30806-2-2--0.03][30906-1-1-1.29][31007-0-0-2.58][31181-3-3-0.84][31238-0-0-1.84][31347-0-0-3.68][31422-2-4-0.50][31429-3-4--0.09][31431-0-0-1.91][31432-1-1-1.34]
[31477-0-0-2.58][31524-1-1-1.72][31597-1-2-1.05][31619-1-3-0.45][31701-0-0-3.55][31755-0-0-3.32][31854-3-3-0.88][32074-1-3-0.10][32078-3-3-1.51][32111-1-1-0.82]
[32127-1-2-1.09][32140-3-3-0.97][32263-2-4-0.32][32365-0-0-2.47][32411-2-0-3.67][32429-3-0-3.61][32473-3-3-1.95][32574-3-0-2.29][32584-0-0-1.06][32622-0-3--0.34]
[32858-3-0-2.31][32969-3-0-1.66][33016-2-2-2.24][33031-1-3-0.89][33035-2-2-2.39][33133-2-1-2.14][33173-2-2-0.64][33175-3-1-1.13][33306-3-1-1.05][33309-2-0--0.45]
[33474-0-0-0.86][33478-2-0-0.18][33618-1-4--0.13][33712-0-0-1.25][33782-2-4-2.09][33914-3-0-0.04][34076-3-3-0.55][34112-2-1-2.03][34138-2-2-1.67][34239-1-1-0.29]
[34364-2-1-2.67][34617-1-2-1.19][34751-3-3-2.20][34783-2-4-1.47][35015-3-2-0.45][35018-1-1-1.27][35288-2-1-0.48][0-4-1-1.10][1-4-0-1.85][2-4-4-2.11]
[3-4-4--0.02][4-4-0-0.10][5-4-1-0.80][6-4-4-1.17][7-4-4-1.93][8-4-3-0.17][9-4-4--0.07][10-4-4-2.60][11-4-2-0.42][12-4-4--0.22]
[14-4-0-1.00][15-4-3-1.95][16-4-0-0.44][17-4-4-0.57][18-4-4-2.09][19-4-0-1.84][20-4-0-1.35][21-4-1-2.11][22-4-4-1.25][23-4-4--0.03]
[24-4-4-3.44][25-4-4-0.30][26-4-4-0.17][27-4-2-1.48][28-4-4-0.57][29-4-4-0.60][30-4-0-0.48][31-4-2-0.49][32-4-4-1.99][33-4-3-0.07]
[34-4-4-0.29][35-4-0-1.19][37-4-4-0.85][39-4-0-3.21][40-4-4-0.91][41-4-4-0.45][42-4-2-0.43][43-4-1-2.02][45-4-3-0.22][46-4-4-2.39]
[47-4-4-1.53][48-4-1-0.84][51-4-4-1.94][52-4-4-1.88][53-4-4--0.06][54-4-4-0.69][55-4-0-1.78][56-4-1-1.37][57-4-0-1.31][58-4-2-1.76]
[59-4-0-2.61][60-4-4-0.53][61-4-4-2.44][62-4-3--0.10][63-4-4-1.64][64-4-4-0.43][65-4-4-2.15][66-4-1-1.91][67-4-4-0.51][68-4-1-1.13]
[69-4-4-0.22][70-4-4-1.26][72-4-4-2.12][73-4-1-0.88][74-4-4-1.20][75-4-4--0.10][77-4-4-1.19][78-4-1-0.13][79-4-4-0.96][80-4-1-0.99]
[81-4-4-1.39][82-4-4-0.33][83-4-2-0.88][84-4-0-1.74][85-4-4-2.01][86-4-4-1.13][87-4-0-1.06][88-4-4-1.14][89-4-0-0.10][90-4-4-0.96]
[91-4-4-1.11][92-4-4-0.27][93-4-0-2.10][94-4-4-1.21][95-4-4-0.00][96-4-4-1.18][97-4-4-1.36][98-4-2-0.81][99-4-4-0.55][100-4-4-2.29]
[101-4-4-1.80][102-4-4-0.99][103-4-1--0.38][104-4-4-1.53][105-4-4-1.49][106-4-4-1.31][107-4-4-1.86][108-4-4-0.69][109-4-4-0.26][110-4-4-0.90]
[111-4-0-2.20][112-4-4-1.23][113-4-3-0.02][114-4-3-0.64][115-4-4-0.85][116-4-4-0.87][117-4-4-1.84][119-4-2-2.44][121-4-4-1.08][122-4-4--0.11]
[124-4-1-0.55][125-4-1-1.95][126-4-4-1.05][127-4-2-0.58][128-4-0-1.17][129-4-2-0.54][130-4-4-0.57][131-4-3-0.16][132-4-4--0.07][133-4-4-2.48]
[135-4-4-0.89][136-4-1-0.61][137-4-4-0.64][138-4-4-0.82][139-4-4-1.99][140-4-1-0.23][141-4-0-1.42][142-4-4-1.30][143-4-4-1.58][144-4-4-2.11]
[145-4-2-0.41][148-4-0-4.39][149-4-4-1.14][150-4-1-0.64][151-4-4-0.72][152-4-4-0.03][153-4-1-0.95][154-4-4-1.34][155-4-4-0.60][156-4-3-0.93]
[157-4-0-1.66][158-4-4-0.39][160-4-1-0.82][161-4-2-1.73][162-4-4-0.51][164-4-4-0.72][165-4-4-0.77][167-4-4-1.23][168-4-4-0.90][170-4-0-2.02]
[171-4-4-1.04][172-4-4-1.15][173-4-4-1.94][174-4-0-2.74][175-4-4-1.12][177-4-0-1.97][178-4-4-1.65][179-4-4-0.71][180-4-0-0.74][181-4-4-0.15]
[182-4-2-1.82][183-4-0-0.93][184-4-4-0.82][186-4-4-0.72][187-4-1-0.86][188-4-2-1.33][189-4-4-1.37][190-4-4--0.25][191-4-4-1.54][192-4-4-2.20]
[193-4-2-2.38][194-4-1--0.17][195-4-4-0.71][196-4-4-0.62][197-4-4-0.85][198-4-4-1.93][199-4-4-0.86]
---------------------------
I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.748 | Acc: 71.125% | Wgt Acc: 75.049%
	I - Batch: 100 | Loss: 0.731 | Acc: 71.000% | Wgt Acc: 74.603%
	I - Batch: 150 | Loss: 0.733 | Acc: 70.750% | Wgt Acc: 74.487%
	I - Batch: 200 | Loss: 0.736 | Acc: 70.344% | Wgt Acc: 73.812%
I - num batch: 222
I - Train -- Loss: 0.733 | Acc: 70.341% | Wgt Acc: 73.850% | LR: 2.500000e-04 | Dur: 193.12s
I - Confusion Matrix: [row->prediction - col->label]
[[562.   3.   6.  71. 132.]
 [  4. 466.  65.  17. 118.]
 [ 12.  55. 561.  30. 157.]
 [ 67.  16.  37. 397.  84.]
 [ 52.  38.  65.  23. 509.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.195 | Acc: 55.227% | Wgt Acc: 56.496% | Dur: 18.98s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  3.  2. 18. 21.]
 [ 2. 36. 12.  4. 25.]
 [ 2. 19. 43.  4. 27.]
 [17.  6. 10. 55. 19.]
 [ 9. 14.  8.  5. 88.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.651 | Acc: 73.000% | Wgt Acc: 76.439%
	I - Batch: 100 | Loss: 0.693 | Acc: 70.938% | Wgt Acc: 74.686%
	I - Batch: 150 | Loss: 0.706 | Acc: 70.958% | Wgt Acc: 74.501%
	I - Batch: 200 | Loss: 0.712 | Acc: 70.969% | Wgt Acc: 74.714%
I - num batch: 222
I - Train -- Loss: 0.709 | Acc: 71.215% | Wgt Acc: 74.962% | LR: 2.500000e-04 | Dur: 180.82s
I - Confusion Matrix: [row->prediction - col->label]
[[567.   0.   4.  76. 123.]
 [  6. 479.  67.  22. 138.]
 [ 10.  52. 575.  30. 150.]
 [ 65.  17.  33. 400.  84.]
 [ 49.  30.  55.  10. 505.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.149 | Acc: 55.227% | Wgt Acc: 55.950% | Dur: 15.66s
I - Confusion Matrix: [row->prediction - col->label]
[[58.  2.  3. 21. 15.]
 [ 2. 38. 14.  5. 24.]
 [ 1. 22. 44.  4. 34.]
 [14.  3.  5. 49. 16.]
 [13. 13.  9.  7. 91.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.644 | Acc: 75.250% | Wgt Acc: 78.917%
	I - Batch: 100 | Loss: 0.671 | Acc: 73.438% | Wgt Acc: 77.239%
	I - Batch: 150 | Loss: 0.673 | Acc: 73.208% | Wgt Acc: 76.803%
	I - Batch: 200 | Loss: 0.676 | Acc: 72.938% | Wgt Acc: 76.571%
I - num batch: 222
I - Train -- Loss: 0.676 | Acc: 72.907% | Wgt Acc: 76.496% | LR: 2.500000e-04 | Dur: 185.94s
I - Confusion Matrix: [row->prediction - col->label]
[[576.   4.   5.  58. 128.]
 [  5. 478.  57.  19. 138.]
 [  9.  51. 587.  27. 123.]
 [ 59.  10.  38. 415.  81.]
 [ 48.  35.  47.  19. 530.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.134 | Acc: 55.621% | Wgt Acc: 55.731% | Dur: 21.16s
I - Confusion Matrix: [row->prediction - col->label]
[[54.  2.  1. 13. 10.]
 [ 1. 37. 14.  7. 25.]
 [ 1. 22. 44.  8. 32.]
 [22.  4.  8. 50. 16.]
 [10. 13.  8.  8. 97.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.680 | Acc: 72.250% | Wgt Acc: 76.482%
	I - Batch: 100 | Loss: 0.669 | Acc: 73.125% | Wgt Acc: 77.176%
	I - Batch: 150 | Loss: 0.672 | Acc: 72.958% | Wgt Acc: 77.362%
	I - Batch: 200 | Loss: 0.669 | Acc: 72.906% | Wgt Acc: 77.273%
I - num batch: 222
I - Train -- Loss: 0.670 | Acc: 72.709% | Wgt Acc: 77.105% | LR: 2.500000e-04 | Dur: 178.16s
I - Confusion Matrix: [row->prediction - col->label]
[[584.   2.   5.  48. 129.]
 [  7. 475.  50.  15. 134.]
 [  5.  59. 601.  23. 169.]
 [ 52.  10.  26. 435.  84.]
 [ 49.  32.  52.  17. 484.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.101 | Acc: 57.791% | Wgt Acc: 56.168% | Dur: 15.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  19.  18.]
 [  0.  43.  20.   2.  23.]
 [  3.  17.  31.   4.  16.]
 [ 11.   3.   6.  44.   8.]
 [ 14.  13.  16.  17. 115.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.588 | Acc: 77.625% | Wgt Acc: 81.364%
	I - Batch: 100 | Loss: 0.605 | Acc: 76.188% | Wgt Acc: 79.870%
	I - Batch: 150 | Loss: 0.600 | Acc: 76.333% | Wgt Acc: 79.984%
	I - Batch: 200 | Loss: 0.601 | Acc: 75.875% | Wgt Acc: 79.895%
I - num batch: 222
I - Train -- Loss: 0.601 | Acc: 75.867% | Wgt Acc: 79.931% | LR: 1.250000e-04 | Dur: 188.09s
I - Confusion Matrix: [row->prediction - col->label]
[[588.   0.   1.  49. 114.]
 [  4. 511.  30.  13. 107.]
 [  5.  37. 616.  20. 157.]
 [ 44.  10.  32. 437.  83.]
 [ 56.  20.  55.  19. 539.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.116 | Acc: 60.158% | Wgt Acc: 58.734% | Dur: 17.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   1.  21.  30.]
 [  0.  37.  14.   4.  18.]
 [  0.  14.  31.   3.  11.]
 [ 10.   2.  11.  51.   5.]
 [  8.  20.  18.   7. 116.]]

I - Local maximum validation set accuracy:  60.16

I - Validation set results: 
[14-1-2-2.01][50-3-4-0.55][124-2-2-2.06][127-0-0-3.26][443-2-2-1.40][567-0-0-1.85][573-1-4--0.50][615-0-3-1.88][695-1-2-2.26][722-3-3-2.46]
[826-0-0-2.10][878-0-0-5.06][1103-0-0-1.53][1212-3-3--0.10][1368-0-0-3.13][2181-2-3-0.04][2476-2-2-0.68][2721-2-2-1.35][2818-1-4-0.30][2886-2-1-2.20]
[3231-2-2-3.18][3333-2-1-1.03][3482-2-4-0.84][3536-3-3-1.21][3625-1-1-2.46][3909-0-0-1.98][4035-0-0-1.96][4140-0-0-1.74][4214-1-1-0.31][4346-1-0-1.35]
[4581-2-2-1.55][4708-3-2-0.87][4838-3-0-1.23][4845-1-1-0.81][4868-0-0-2.85][4939-0-4-0.64][4984-2-2--0.92][5078-1-4-0.79][5396-0-0-4.27][5479-1-1-2.44]
[5717-0-0-1.22][5843-1-4-0.13][5949-3-0-2.35][5987-2-4-1.82][6014-3-3-1.00][6033-3-3-0.35][6313-0-0-2.76][6421-3-3-1.63][6500-1-2--0.18][6583-3-3-1.39]
[6683-3-3-0.95][6825-2-3-0.58][6998-3-4-0.35][7049-3-3-0.80][7517-1-1-2.70][7521-1-0--0.32][7528-1-1-0.29][7949-1-2-2.03][8135-1-0-1.49][8185-3-0-3.82]
[8269-3-2-1.11][8273-3-3-1.04][8543-3-0-3.94][8666-1-1-2.13][8672-0-0-2.85][8903-1-1-0.87][9001-2-1-2.32][9036-2-2-3.18][9281-3-3--0.14][9300-2-3-0.40]
[9571-0-0-1.16][9617-1-4-1.13][9644-2-2-1.00][9705-2-4-0.26][9801-0-0-1.65][9803-3-0-1.23][9865-3-3-2.66][9896-2-4-1.86][10314-1-1-0.26][10337-3-3-1.81]
[10403-0-4-0.89][10653-2-4-0.49][10704-2-1-0.36][10719-1-1-2.70][10727-1-4-1.59][10836-0-0-7.89][10969-2-3-0.24][11042-0-0-1.17][11088-1-1-4.39][11322-0-0-2.01]
[11398-2-2-1.27][11499-0-0-1.05][11502-3-3-1.03][11512-3-3-1.16][11608-1-1-3.01][11610-0-0-2.24][11692-0-3-2.38][11905-0-0-2.69][11993-1-1-1.21][12002-2-3-1.10]
[12052-0-0-2.55][12201-0-0-2.87][12235-2-1-1.47][12320-1-4-1.94][12377-2-4-2.12][12398-2-3-0.44][12503-1-1-0.01][12617-0-3--0.41][12685-3-1-0.17][12738-2-4-0.48]
[12742-2-2-2.30][12823-0-0-3.46][13110-1-2-0.09][13240-3-0-4.54][13253-1-4-1.19][13273-0-0-6.37][13634-1-1--0.23][13763-2-2-0.71][13905-3-3-0.62][14060-2-1-2.04]
[14065-3-3-1.37][14147-3-3-1.40][14595-2-4-1.49][14687-2-2-2.59][14788-2-2-2.81][14869-1-1-2.12][14872-3-4-0.95][14877-1-1-1.34][14927-0-3-1.72][15066-0-0-4.41]
[15175-1-4-2.09][15178-2-3-0.37][15375-3-3-1.98][15389-3-3-2.66][15568-2-4-0.94][15675-3-3-1.85][15869-1-4--0.22][16207-3-0-0.46][16236-0-0--0.10][16302-3-0-2.86]
[16331-2-2-3.65][16381-0-3-1.39][16488-1-1-2.82][16495-0-0-1.50][16650-0-0-4.12][16719-1-4-0.79][16801-0-0-4.59][16828-0-0-1.95][17137-3-3-0.54][17245-1-1-1.38]
[17278-3-0-1.19][17282-0-0--0.75][17311-2-2-2.71][17336-2-1-0.21][17608-3-3-2.96][17627-0-0-0.64][17877-3-3-0.32][17924-1-2--0.25][17984-3-0-3.98][18211-0-0-1.21]
[18276-3-0-2.40][18287-1-1-2.03][18394-0-0-3.52][18428-0-0-4.03][18442-0-3-2.55][18478-3-0-2.86][18607-0-0-3.07][18616-0-0-0.60][18663-0-0-0.63][18718-0-0-3.53]
[18766-2-2-2.50][18824-2-2-1.14][18890-3-3-0.41][18930-3-4-1.55][18938-3-0-1.82][19817-1-4-1.38][19839-0-4-1.77][19930-3-3-2.15][19944-0-4-2.43][20036-2-2-1.42]
[20101-3-3-1.61][20474-1-1-0.62][20547-3-3-0.69][20929-2-2-2.04][21245-1-2-1.45][21257-3-3-0.88][21293-1-1-3.02][21316-1-1-1.55][21384-1-1-1.99][21448-1-2-1.22]
[21483-0-0-3.92][21487-2-2-1.91][21714-0-0-3.06][21943-3-2-0.47][21947-0-0-2.02][21948-0-0-6.35][21965-2-2-2.75][21998-1-4-0.42][22025-0-4-1.11][22228-3-3-2.51]
[22446-1-1-1.98][22494-3-0-3.51][22757-0-0-5.03][22811-3-3-3.40][22976-3-1-1.25][22985-3-3-2.28][23014-0-0-3.79][23112-1-1-0.74][23144-3-3-3.40][23168-2-4-0.42]
[23219-0-0-0.72][23363-3-3-1.13][23470-0-0-1.30][23486-2-3--0.20][23497-0-3-2.49][23516-0-0-2.99][23690-1-4-0.20][23921-2-4-0.58][23936-1-2-1.18][24040-3-4-1.40]
[24111-1-4-0.99][24182-0-0-4.06][24238-3-3-2.58][24290-2-4-1.27][24345-0-4-2.02][24364-1-2-0.72][24427-3-4-0.39][24477-2-4-1.59][24495-2-1-1.24][24893-2-2-1.77]
[25012-1-4-0.43][25121-2-1-3.13][25165-3-3-0.32][25183-0-0-1.99][25297-3-3-1.83][25398-0-0-2.06][25574-2-2-0.21][25644-1-1-1.35][25718-1-0-0.65][25774-2-3-0.18]
[26032-3-3-1.71][26051-3-3-2.28][26120-0-0-1.70][26321-1-1-0.89][26732-1-1-0.26][26784-3-3-3.46][26827-3-3-1.06][26833-0-3-2.93][26838-2-2-0.48][26860-1-4-1.78]
[26948-0-0-2.11][27049-3-3-0.71][27098-1-4--0.06][27526-0-3-0.79][27639-3-0-1.10][27698-3-3-2.25][27772-0-0-3.67][27890-1-1-1.42][28040-0-0-0.55][28503-2-2-1.85]
[28577-1-1-1.90][28959-0-0-4.28][29198-3-3--0.06][29777-0-0-5.58][29877-2-2-1.52][30035-1-2-1.86][30098-0-0-1.25][30326-1-1-3.64][30572-2-3-0.70][30716-0-4-1.32]
[30806-2-3--0.25][30906-1-1-1.36][31007-0-0-2.89][31181-3-3-0.13][31238-0-0-1.13][31347-0-0-5.32][31422-2-4-0.64][31429-3-3-0.25][31431-0-0-1.04][31432-1-1-1.19]
[31477-0-0-2.79][31524-1-1-0.75][31597-1-2-0.44][31619-1-0-1.08][31701-0-0-2.54][31755-0-0-3.77][31854-3-3-1.07][32074-1-3-0.07][32078-3-3-1.19][32111-1-1-1.23]
[32127-1-2-0.98][32140-3-3-1.79][32263-2-4-0.45][32365-0-0-1.45][32411-2-0-3.73][32429-3-0-2.87][32473-3-0-1.74][32574-3-0-2.87][32584-0-0-1.28][32622-0-4-0.27]
[32858-3-0-2.23][32969-3-0-1.72][33016-2-1-0.91][33031-1-3-1.04][33035-2-1-1.84][33133-2-2-1.84][33173-2-2-0.70][33175-3-1-1.23][33306-3-1-0.40][33309-2-1--0.59]
[33474-0-0-0.58][33478-2-4-0.23][33618-1-4-0.26][33712-0-3-0.96][33782-2-4-2.16][33914-3-3-0.75][34076-3-0-1.10][34112-2-1-1.88][34138-2-2-1.73][34239-1-1-0.73]
[34364-2-2-2.69][34617-1-2-1.23][34751-3-3-1.97][34783-2-4-1.03][35015-3-4-0.65][35018-1-4-0.43][35288-2-1-0.40][0-4-4-2.02][1-4-0-1.03][2-4-4-1.31]
[3-4-4-0.15][4-4-4-0.70][5-4-1-2.17][6-4-4-1.63][7-4-4-3.34][8-4-4-0.18][9-4-1-0.19][10-4-4-2.33][11-4-4-1.11][12-4-4-0.04]
[14-4-0-0.12][15-4-3-2.49][16-4-0-0.16][17-4-4-0.91][18-4-4-1.64][19-4-0-1.33][20-4-0-1.17][21-4-1-2.46][22-4-4-1.24][23-4-4-0.21]
[24-4-4-3.16][25-4-4-0.38][26-4-4--0.09][27-4-2-2.62][28-4-4-0.63][29-4-4-1.00][30-4-0-1.57][31-4-4--0.06][32-4-4-1.85][33-4-1-0.11]
[34-4-4-0.26][35-4-0-1.81][37-4-4-1.08][39-4-0-1.66][40-4-0-1.04][41-4-4-0.01][42-4-4-1.08][43-4-2-0.47][45-4-3-0.52][46-4-4-1.90]
[47-4-4-1.60][48-4-4-0.22][51-4-4-1.43][52-4-4-1.64][53-4-4--0.09][54-4-4-0.63][55-4-4-1.46][56-4-4-1.09][57-4-0-0.86][58-4-1-1.06]
[59-4-0-2.16][60-4-4-0.70][61-4-4-1.68][62-4-3--0.19][63-4-4-1.62][64-4-2-1.36][65-4-4-2.00][66-4-4-1.14][67-4-2-0.35][68-4-1-1.98]
[69-4-0-1.47][70-4-4-1.46][72-4-4-0.99][73-4-1-1.32][74-4-2-0.91][75-4-4--0.29][77-4-1-0.77][78-4-1--0.08][79-4-4-1.30][80-4-4-0.92]
[81-4-4-2.07][82-4-4--0.01][83-4-4-0.29][84-4-4-1.73][85-4-4-2.13][86-4-4-1.42][87-4-4-1.81][88-4-4-0.94][89-4-0-0.66][90-4-4-1.18]
[91-4-4-0.77][92-4-0-0.90][93-4-0-2.13][94-4-4-0.62][95-4-4-0.27][96-4-4-1.73][97-4-4-1.81][98-4-4-0.95][99-4-4-0.80][100-4-4-1.77]
[101-4-4-2.98][102-4-4-1.04][103-4-1--0.07][104-4-4-1.31][105-4-4-0.81][106-4-4-1.14][107-4-4-2.36][108-4-2-0.90][109-4-4-0.03][110-4-4-1.62]
[111-4-0-2.13][112-4-4-1.33][113-4-3-0.25][114-4-0-0.89][115-4-4-0.64][116-4-4-0.79][117-4-4-1.57][119-4-4-1.11][121-4-4-0.72][122-4-4-0.14]
[124-4-1--0.58][125-4-1-1.75][126-4-4-1.92][127-4-1-0.91][128-4-0-1.25][129-4-2-1.09][130-4-4-0.80][131-4-3-0.43][132-4-4-1.45][133-4-4-2.75]
[135-4-4-0.31][136-4-1-0.97][137-4-1-0.41][138-4-4-0.93][139-4-4-2.17][140-4-4-1.00][141-4-0-1.11][142-4-4-1.59][143-4-4-2.34][144-4-4-2.07]
[145-4-1-2.22][148-4-0-5.50][149-4-4-0.89][150-4-1-1.02][151-4-4-0.50][152-4-2-0.18][153-4-4-1.41][154-4-4-1.30][155-4-4-1.37][156-4-0-0.87]
[157-4-0-0.47][158-4-4-0.39][160-4-4-0.12][161-4-2-2.73][162-4-4-0.62][164-4-4-0.94][165-4-4-0.91][167-4-0-1.62][168-4-4-0.37][170-4-0-2.95]
[171-4-4-1.44][172-4-4-1.73][173-4-4-2.04][174-4-0-0.97][175-4-4-1.25][177-4-0-2.18][178-4-4-0.67][179-4-4-0.48][180-4-0-0.90][181-4-4-0.40]
[182-4-2-1.89][183-4-4-1.15][184-4-4-1.46][186-4-4-0.81][187-4-1-1.15][188-4-4-1.30][189-4-4-1.87][190-4-4-0.34][191-4-0-1.34][192-4-4-1.25]
[193-4-2-3.13][194-4-0-0.44][195-4-0-0.70][196-4-4-0.61][197-4-4-1.00][198-4-4-2.28][199-4-4-0.57]
---------------------------
I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.554 | Acc: 77.875% | Wgt Acc: 82.152%
	I - Batch: 100 | Loss: 0.557 | Acc: 77.688% | Wgt Acc: 81.444%
	I - Batch: 150 | Loss: 0.560 | Acc: 77.583% | Wgt Acc: 81.539%
	I - Batch: 200 | Loss: 0.563 | Acc: 77.531% | Wgt Acc: 81.471%
I - num batch: 208
I - Train -- Loss: 0.564 | Acc: 77.614% | Wgt Acc: 81.517% | LR: 1.250000e-04 | Dur: 166.96s
I - Confusion Matrix: [row->prediction - col->label]
[[598.   1.   2.  53. 109.]
 [  6. 504.  33.  13.  95.]
 [  6.  34. 641.  16. 119.]
 [ 48.  15.  27. 444.  62.]
 [ 39.  24.  31.  12. 396.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.203 | Acc: 54.241% | Wgt Acc: 57.205% | Dur: 15.37s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  6.  3. 15. 26.]
 [ 0. 41.  9.  4. 16.]
 [ 1. 18. 37.  3. 34.]
 [22.  7. 18. 61. 27.]
 [ 6.  6.  8.  3. 77.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.567 | Acc: 76.250% | Wgt Acc: 80.788%
	I - Batch: 100 | Loss: 0.583 | Acc: 77.125% | Wgt Acc: 81.130%
	I - Batch: 150 | Loss: 0.585 | Acc: 77.083% | Wgt Acc: 81.281%
	I - Batch: 200 | Loss: 0.581 | Acc: 76.844% | Wgt Acc: 80.942%
I - num batch: 222
I - Train -- Loss: 0.581 | Acc: 76.882% | Wgt Acc: 80.961% | LR: 1.250000e-04 | Dur: 180.78s
I - Confusion Matrix: [row->prediction - col->label]
[[585.   1.   1.  49. 125.]
 [  6. 521.  27.  15. 108.]
 [  8.  28. 635.  22. 134.]
 [ 50.   7.  25. 438.  85.]
 [ 48.  21.  46.  14. 548.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.129 | Acc: 59.566% | Wgt Acc: 61.954% | Dur: 15.48s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  4.  2. 14. 27.]
 [ 1. 43. 13.  4. 23.]
 [ 0. 19. 45.  3. 26.]
 [14.  2.  8. 60. 16.]
 [ 7. 10.  7.  5. 88.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.552 | Acc: 79.250% | Wgt Acc: 83.009%
	I - Batch: 100 | Loss: 0.554 | Acc: 78.062% | Wgt Acc: 82.045%
	I - Batch: 150 | Loss: 0.561 | Acc: 77.375% | Wgt Acc: 81.272%
	I - Batch: 200 | Loss: 0.555 | Acc: 77.781% | Wgt Acc: 81.866%
I - num batch: 222
I - Train -- Loss: 0.551 | Acc: 78.010% | Wgt Acc: 82.103% | LR: 1.250000e-04 | Dur: 180.31s
I - Confusion Matrix: [row->prediction - col->label]
[[603.   1.   0.  38. 124.]
 [  3. 523.  36.   5. 102.]
 [  7.  23. 629.  21. 140.]
 [ 44.   3.  22. 452.  74.]
 [ 40.  28.  47.  22. 560.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.121 | Acc: 58.383% | Wgt Acc: 58.242% | Dur: 15.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  14.  21.]
 [  0.  35.  16.   3.  23.]
 [  1.  22.  36.   6.  22.]
 [ 13.   5.   7.  56.  10.]
 [  9.  12.  14.   7. 104.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.532 | Acc: 78.750% | Wgt Acc: 83.065%
	I - Batch: 100 | Loss: 0.531 | Acc: 78.875% | Wgt Acc: 83.331%
	I - Batch: 150 | Loss: 0.538 | Acc: 79.000% | Wgt Acc: 83.110%
	I - Batch: 200 | Loss: 0.535 | Acc: 78.969% | Wgt Acc: 83.109%
I - num batch: 222
I - Train -- Loss: 0.537 | Acc: 78.743% | Wgt Acc: 82.915% | LR: 1.250000e-04 | Dur: 180.09s
I - Confusion Matrix: [row->prediction - col->label]
[[596.   2.   2.  48. 136.]
 [  1. 526.  24.   3.  90.]
 [  7.  23. 646.  16. 137.]
 [ 36.   5.  16. 461.  73.]
 [ 57.  22.  46.  10. 564.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.068 | Acc: 59.763% | Wgt Acc: 58.788% | Dur: 15.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   2.  12.  15.]
 [  0.  37.  12.   4.  18.]
 [  0.  16.  40.   5.  25.]
 [ 17.   3.   5.  54.   9.]
 [ 12.  19.  16.  11. 113.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.537 | Acc: 77.375% | Wgt Acc: 81.436%
	I - Batch: 100 | Loss: 0.508 | Acc: 79.750% | Wgt Acc: 83.897%
	I - Batch: 150 | Loss: 0.508 | Acc: 79.458% | Wgt Acc: 83.603%
	I - Batch: 200 | Loss: 0.520 | Acc: 79.031% | Wgt Acc: 83.285%
I - num batch: 222
I - Train -- Loss: 0.518 | Acc: 79.194% | Wgt Acc: 83.464% | LR: 1.250000e-04 | Dur: 183.76s
I - Confusion Matrix: [row->prediction - col->label]
[[604.   1.   3.  32. 140.]
 [  4. 524.  17.   9.  89.]
 [  4.  27. 657.  18. 150.]
 [ 34.   7.  16. 464.  61.]
 [ 51.  19.  41.  15. 560.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.090 | Acc: 60.552% | Wgt Acc: 58.624% | Dur: 18.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   2.  18.  21.]
 [  0.  37.  19.   4.  17.]
 [  1.  14.  29.   1.  11.]
 [ 11.   3.   7.  53.   9.]
 [ 10.  20.  18.  10. 122.]]

I - Local maximum validation set accuracy:  60.55

I - Validation set results: 
[14-1-2-2.17][50-3-4-0.41][124-2-4-0.99][127-0-0-3.47][443-2-2-2.19][567-0-0-1.58][573-1-1--0.35][615-0-3-2.07][695-1-2-2.65][722-3-3-3.15]
[826-0-0-2.63][878-0-0-3.31][1103-0-0-2.05][1212-3-4-0.01][1368-0-0-4.38][2181-2-3-1.31][2476-2-1-0.63][2721-2-2-1.44][2818-1-4-0.56][2886-2-1-2.50]
[3231-2-2-3.01][3333-2-1-2.21][3482-2-4-0.98][3536-3-3-1.25][3625-1-1-2.62][3909-0-0-1.75][4035-0-0-2.55][4140-0-0-1.58][4214-1-3-0.94][4346-1-0-0.09]
[4581-2-2-2.28][4708-3-2-0.40][4838-3-0-1.49][4845-1-4-0.25][4868-0-0-3.25][4939-0-4-0.49][4984-2-2-0.08][5078-1-4-1.19][5396-0-0-4.81][5479-1-1-2.93]
[5717-0-0-2.33][5843-1-1-1.12][5949-3-0-2.61][5987-2-4-1.88][6014-3-3-1.48][6033-3-4--0.19][6313-0-0-2.73][6421-3-3-2.06][6500-1-1-0.27][6583-3-3-0.95]
[6683-3-3-0.83][6825-2-3-0.02][6998-3-0-0.09][7049-3-3-1.70][7517-1-1-3.70][7521-1-3-0.01][7528-1-1-0.78][7949-1-2-1.16][8135-1-4-0.93][8185-3-0-3.19]
[8269-3-4-0.78][8273-3-3-0.83][8543-3-0-4.97][8666-1-1-0.96][8672-0-0-4.78][8903-1-1-1.45][9001-2-1-2.21][9036-2-2-2.77][9281-3-3-0.60][9300-2-2-1.13]
[9571-0-0-0.30][9617-1-4-1.27][9644-2-2-1.56][9705-2-4-1.00][9801-0-3-0.20][9803-3-3-0.88][9865-3-3-3.16][9896-2-4-2.61][10314-1-1-1.05][10337-3-3-2.17]
[10403-0-4-1.47][10653-2-4-0.55][10704-2-1-1.15][10719-1-1-2.87][10727-1-4-1.35][10836-0-0-7.49][10969-2-3--0.04][11042-0-0-2.02][11088-1-1-4.82][11322-0-0-2.26]
[11398-2-2-1.21][11499-0-0-0.86][11502-3-3-0.58][11512-3-3-0.32][11608-1-1-3.05][11610-0-0-1.68][11692-0-3-2.98][11905-0-0-2.35][11993-1-1-2.83][12002-2-1-0.68]
[12052-0-0-2.20][12201-0-0-2.74][12235-2-4-1.48][12320-1-4-1.97][12377-2-4-1.91][12398-2-3-1.47][12503-1-1-1.05][12617-0-3-0.29][12685-3-3-0.50][12738-2-4-0.58]
[12742-2-2-2.53][12823-0-0-2.87][13110-1-2-0.63][13240-3-0-4.86][13253-1-4-1.53][13273-0-0-6.91][13634-1-4-0.38][13763-2-2-0.28][13905-3-3-1.05][14060-2-1-2.97]
[14065-3-3-2.04][14147-3-3-0.57][14595-2-4-1.41][14687-2-2-3.13][14788-2-2-2.36][14869-1-1-1.81][14872-3-4-0.96][14877-1-1-1.49][14927-0-3-1.89][15066-0-0-5.28]
[15175-1-4-2.28][15178-2-3-0.95][15375-3-3-2.31][15389-3-3-3.16][15568-2-4-0.62][15675-3-3-1.92][15869-1-0--0.01][16207-3-4-0.15][16236-0-0--0.43][16302-3-0-0.05]
[16331-2-2-4.51][16381-0-3-1.89][16488-1-1-3.38][16495-0-0-2.09][16650-0-0-4.44][16719-1-4-0.90][16801-0-0-4.39][16828-0-0-2.29][17137-3-3-0.78][17245-1-1-1.78]
[17278-3-0-0.50][17282-0-4--0.11][17311-2-2-3.30][17336-2-1-3.05][17608-3-3-3.58][17627-0-4-0.73][17877-3-0-2.39][17924-1-2-0.23][17984-3-0-3.89][18211-0-0-0.85]
[18276-3-0-2.77][18287-1-1-2.00][18394-0-0-3.95][18428-0-0-1.22][18442-0-3-2.78][18478-3-0-2.34][18607-0-0-3.29][18616-0-4-0.81][18663-0-0-0.35][18718-0-0-3.48]
[18766-2-2-2.98][18824-2-2-1.54][18890-3-3-0.38][18930-3-4-2.46][18938-3-3-1.17][19817-1-4-1.14][19839-0-4-2.28][19930-3-3-2.28][19944-0-4-2.89][20036-2-1-1.43]
[20101-3-3-0.94][20474-1-1-1.08][20547-3-3-0.58][20929-2-4-1.47][21245-1-2-1.61][21257-3-3-0.54][21293-1-1-3.15][21316-1-1-1.85][21384-1-4-2.13][21448-1-2-1.39]
[21483-0-0-4.33][21487-2-2-1.96][21714-0-0-2.15][21943-3-1-0.32][21947-0-0-3.03][21948-0-0-6.74][21965-2-2-3.23][21998-1-1-1.15][22025-0-4-1.42][22228-3-3-3.03]
[22446-1-1-1.77][22494-3-0-3.37][22757-0-0-5.48][22811-3-3-3.01][22976-3-1-2.02][22985-3-3-2.52][23014-0-0-4.65][23112-1-1-1.16][23144-3-3-3.03][23168-2-3-0.52]
[23219-0-0-1.10][23363-3-3-2.98][23470-0-0-0.08][23486-2-4--0.25][23497-0-3-2.69][23516-0-0-3.33][23690-1-4-0.56][23921-2-2-0.99][23936-1-2-0.38][24040-3-4-1.53]
[24111-1-4-1.72][24182-0-0-4.16][24238-3-3-2.83][24290-2-4-1.46][24345-0-0-0.65][24364-1-2-1.05][24427-3-0-2.96][24477-2-4-2.44][24495-2-1-1.24][24893-2-2-2.23]
[25012-1-2-0.72][25121-2-1-2.50][25165-3-3-0.93][25183-0-0-1.75][25297-3-3-2.03][25398-0-0-1.63][25574-2-4-0.32][25644-1-1-4.15][25718-1-0-0.41][25774-2-2--0.05]
[26032-3-3-1.33][26051-3-3-2.98][26120-0-0-1.45][26321-1-1-1.21][26732-1-2--0.05][26784-3-3-4.46][26827-3-3-0.52][26833-0-3-3.09][26838-2-2-1.04][26860-1-4-1.43]
[26948-0-0-1.91][27049-3-3-0.70][27098-1-4-0.46][27526-0-0-1.42][27639-3-0-0.56][27698-3-3-1.62][27772-0-0-3.54][27890-1-1-2.19][28040-0-0-0.90][28503-2-2-2.36]
[28577-1-1-2.14][28959-0-0-4.52][29198-3-4-0.20][29777-0-0-5.69][29877-2-2-0.64][30035-1-2-1.97][30098-0-0-0.98][30326-1-1-3.67][30572-2-1-1.02][30716-0-4-1.47]
[30806-2-1--0.10][30906-1-1-1.46][31007-0-0-2.90][31181-3-3-1.33][31238-0-3-0.69][31347-0-0-3.98][31422-2-2-0.44][31429-3-3--0.08][31431-0-3-1.61][31432-1-1-1.93]
[31477-0-0-3.16][31524-1-1-1.63][31597-1-4-0.26][31619-1-0-0.96][31701-0-0-3.74][31755-0-0-4.27][31854-3-3-1.08][32074-1-2-1.68][32078-3-3-1.98][32111-1-1-2.31]
[32127-1-4-1.40][32140-3-3-2.33][32263-2-4-0.08][32365-0-0-2.06][32411-2-0-3.80][32429-3-0-2.90][32473-3-3-2.23][32574-3-3-1.42][32584-0-4-0.93][32622-0-2-0.88]
[32858-3-0-1.82][32969-3-3-2.02][33016-2-2-2.49][33031-1-3-0.79][33035-2-1-2.15][33133-2-2-2.80][33173-2-2-0.40][33175-3-1-1.66][33306-3-1-1.30][33309-2-1-0.13]
[33474-0-0-0.98][33478-2-0-0.64][33618-1-4-0.87][33712-0-0-0.71][33782-2-1-2.77][33914-3-3-1.28][34076-3-0-1.01][34112-2-1-1.97][34138-2-1-0.91][34239-1-1-0.69]
[34364-2-1-2.21][34617-1-2-1.55][34751-3-3-2.78][34783-2-4-1.58][35015-3-4-0.30][35018-1-1-1.22][35288-2-3-0.89][0-4-1-0.54][1-4-0-0.64][2-4-4-1.08]
[3-4-4-0.10][4-4-3--0.29][5-4-1-0.61][6-4-0-2.40][7-4-4-3.41][8-4-4-0.83][9-4-1-0.67][10-4-4-3.26][11-4-4-1.66][12-4-4-0.04]
[14-4-0-0.31][15-4-3-2.72][16-4-0-1.33][17-4-4-1.48][18-4-4-2.21][19-4-0-1.55][20-4-0-0.91][21-4-1-2.64][22-4-4-1.33][23-4-4-1.36]
[24-4-4-2.99][25-4-3-0.52][26-4-4-0.01][27-4-2-1.33][28-4-4-0.90][29-4-4-1.13][30-4-0-0.50][31-4-4-0.23][32-4-4-2.35][33-4-4-0.45]
[34-4-4-0.48][35-4-0-1.48][37-4-4--0.14][39-4-0-2.22][40-4-4-1.11][41-4-0-0.54][42-4-4-1.39][43-4-2-0.11][45-4-3--0.02][46-4-4-2.62]
[47-4-4-1.93][48-4-1-0.74][51-4-4-1.96][52-4-4-1.87][53-4-4-0.38][54-4-4-0.99][55-4-4-1.36][56-4-1-1.29][57-4-0-1.88][58-4-1-1.06]
[59-4-0-3.12][60-4-4-0.41][61-4-4-3.02][62-4-2--0.29][63-4-2-1.79][64-4-4-0.69][65-4-4-2.84][66-4-4-1.94][67-4-4-1.26][68-4-1-0.89]
[69-4-0-0.81][70-4-4-1.52][72-4-4-1.03][73-4-4-0.41][74-4-2-1.20][75-4-4--0.05][77-4-4-0.94][78-4-1-1.45][79-4-4-1.31][80-4-4-1.66]
[81-4-4-1.39][82-4-4--0.18][83-4-4-0.58][84-4-4-1.43][85-4-4-2.41][86-4-4-2.53][87-4-4-1.58][88-4-4-1.08][89-4-0-0.35][90-4-4-1.02]
[91-4-4-1.24][92-4-4-0.17][93-4-4--0.12][94-4-4-1.24][95-4-4-0.04][96-4-4-2.29][97-4-4-2.54][98-4-4-0.77][99-4-4-0.96][100-4-4-2.39]
[101-4-4-3.33][102-4-4-1.49][103-4-4--0.30][104-4-4-1.83][105-4-1-1.42][106-4-4-1.69][107-4-4-3.05][108-4-4-0.58][109-4-4-0.70][110-4-4-1.51]
[111-4-3-2.38][112-4-4-1.31][113-4-4--0.02][114-4-3-0.74][115-4-4-1.41][116-4-4-1.41][117-4-4-2.47][119-4-4-1.55][121-4-4-1.43][122-4-4-0.39]
[124-4-1--0.44][125-4-1-1.65][126-4-4-2.50][127-4-4-0.31][128-4-0-1.38][129-4-2-1.39][130-4-4-1.03][131-4-2-0.51][132-4-4-1.38][133-4-4-3.33]
[135-4-4-1.38][136-4-4-0.01][137-4-1-1.16][138-4-4-1.67][139-4-4-1.97][140-4-4-1.11][141-4-3-0.53][142-4-4-2.13][143-4-4-2.15][144-4-4-3.25]
[145-4-1-1.28][148-4-0-5.31][149-4-4-1.92][150-4-1-0.58][151-4-4-0.92][152-4-4-0.29][153-4-2-0.59][154-4-4-2.87][155-4-4-1.46][156-4-3-1.32]
[157-4-0-1.82][158-4-4-0.94][160-4-1-0.89][161-4-2-2.33][162-4-4-1.01][164-4-4-1.11][165-4-4-1.38][167-4-0-1.83][168-4-4-0.44][170-4-0-2.57]
[171-4-4-1.83][172-4-4-1.79][173-4-4-2.56][174-4-4-0.95][175-4-4-1.53][177-4-4-2.03][178-4-4-1.25][179-4-4-0.67][180-4-4-1.06][181-4-3-1.45]
[182-4-2-1.38][183-4-4-0.92][184-4-4-1.41][186-4-0-0.04][187-4-4-0.31][188-4-4-1.11][189-4-4-1.58][190-4-4-1.12][191-4-4-1.88][192-4-4-1.75]
[193-4-2-3.00][194-4-0--0.29][195-4-1-1.03][196-4-4-1.13][197-4-4-1.69][198-4-4-2.58][199-4-4-1.50]
---------------------------
I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.483 | Acc: 81.750% | Wgt Acc: 85.270%
	I - Batch: 100 | Loss: 0.499 | Acc: 81.000% | Wgt Acc: 84.973%
	I - Batch: 150 | Loss: 0.501 | Acc: 80.375% | Wgt Acc: 84.405%
	I - Batch: 200 | Loss: 0.501 | Acc: 80.312% | Wgt Acc: 84.163%
I - num batch: 222
I - Train -- Loss: 0.501 | Acc: 80.462% | Wgt Acc: 84.343% | LR: 1.250000e-04 | Dur: 180.64s
I - Confusion Matrix: [row->prediction - col->label]
[[608.   2.   2.  25. 109.]
 [  2. 527.  20.   6.  97.]
 [  1.  20. 650.  15. 120.]
 [ 31.   4.  17. 472.  77.]
 [ 55.  25.  45.  20. 597.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.104 | Acc: 60.750% | Wgt Acc: 60.098% | Dur: 15.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  17.  19.]
 [  0.  36.  13.   3.  17.]
 [  0.  19.  40.   2.  21.]
 [ 13.   5.  11.  55.  12.]
 [  9.  14.  10.   9. 111.]]

I - Local maximum validation set accuracy:  60.75

I - Validation set results: 
[14-1-2-2.35][50-3-4-0.17][124-2-2-2.46][127-0-0-3.18][443-2-2-1.92][567-0-0-2.28][573-1-2--0.30][615-0-3-2.43][695-1-2-1.41][722-3-3-3.39]
[826-0-0-1.38][878-0-0-4.74][1103-0-4-1.24][1212-3-3-0.09][1368-0-0-2.50][2181-2-3-0.87][2476-2-2-1.35][2721-2-2-2.20][2818-1-4--0.10][2886-2-1-2.88]
[3231-2-2-4.18][3333-2-1-1.01][3482-2-2-1.19][3536-3-0-1.13][3625-1-1-2.84][3909-0-0-2.02][4035-0-0-1.87][4140-0-0-1.83][4214-1-3-1.31][4346-1-0-0.17]
[4581-2-4-1.39][4708-3-2-1.78][4838-3-0-0.24][4845-1-1-0.81][4868-0-0-2.49][4939-0-4-0.45][4984-2-2-1.19][5078-1-4-1.77][5396-0-0-4.20][5479-1-1-2.70]
[5717-0-0-3.18][5843-1-2-1.30][5949-3-3-1.43][5987-2-4-1.70][6014-3-3-1.42][6033-3-4--0.11][6313-0-0-2.96][6421-3-3-1.44][6500-1-2-0.39][6583-3-3-0.82]
[6683-3-3-0.89][6825-2-3-0.37][6998-3-4-0.36][7049-3-3-1.21][7517-1-1-3.00][7521-1-3-0.14][7528-1-2-0.44][7949-1-2-1.06][8135-1-4-0.49][8185-3-0-3.93]
[8269-3-1-1.79][8273-3-3-1.17][8543-3-0-4.57][8666-1-1-1.95][8672-0-0-4.47][8903-1-2-1.64][9001-2-2-2.85][9036-2-2-1.67][9281-3-3-0.49][9300-2-2-0.77]
[9571-0-0-0.53][9617-1-4-0.70][9644-2-1-0.48][9705-2-4-0.36][9801-0-0-0.34][9803-3-3-1.92][9865-3-3-2.69][9896-2-4-2.61][10314-1-1-0.95][10337-3-3-2.35]
[10403-0-0-1.80][10653-2-4-0.15][10704-2-1-0.75][10719-1-1-2.42][10727-1-4-1.20][10836-0-0-8.80][10969-2-3-0.57][11042-0-0-2.50][11088-1-1-4.14][11322-0-0-1.73]
[11398-2-2-0.58][11499-0-0-1.29][11502-3-3-1.24][11512-3-3-0.76][11608-1-1-2.88][11610-0-0-1.71][11692-0-3-2.56][11905-0-0-2.50][11993-1-1-1.71][12002-2-3-0.86]
[12052-0-0-2.01][12201-0-0-2.38][12235-2-4-1.49][12320-1-4-1.62][12377-2-4-1.82][12398-2-3-0.93][12503-1-1-0.56][12617-0-3-0.42][12685-3-3--0.20][12738-2-4-0.19]
[12742-2-2-3.07][12823-0-0-3.42][13110-1-2-0.67][13240-3-0-4.21][13253-1-4-2.67][13273-0-0-6.88][13634-1-4--0.19][13763-2-3-0.87][13905-3-3-1.19][14060-2-1-1.63]
[14065-3-3-1.71][14147-3-3-0.83][14595-2-2-1.67][14687-2-2-3.22][14788-2-2-3.32][14869-1-1-2.02][14872-3-4-1.05][14877-1-1-2.25][14927-0-3-2.57][15066-0-0-4.49]
[15175-1-4-2.25][15178-2-3-0.58][15375-3-3-2.08][15389-3-3-2.25][15568-2-4-0.96][15675-3-3-2.29][15869-1-0-0.48][16207-3-4-0.12][16236-0-0-0.21][16302-3-0-1.65]
[16331-2-2-4.52][16381-0-3-0.87][16488-1-1-5.64][16495-0-0-0.68][16650-0-0-3.87][16719-1-4-0.43][16801-0-0-5.07][16828-0-0-2.46][17137-3-3-0.66][17245-1-1-2.01]
[17278-3-3-0.53][17282-0-3--0.47][17311-2-2-2.89][17336-2-1-2.26][17608-3-3-3.37][17627-0-0-1.37][17877-3-0-1.77][17924-1-2-0.08][17984-3-0-3.98][18211-0-3-1.73]
[18276-3-0-2.19][18287-1-1-0.73][18394-0-0-3.51][18428-0-0-0.90][18442-0-3-3.09][18478-3-0-3.11][18607-0-0-2.10][18616-0-0-0.10][18663-0-0-0.23][18718-0-0-3.44]
[18766-2-2-3.04][18824-2-1-1.93][18890-3-3-0.19][18930-3-4-2.10][18938-3-3-0.88][19817-1-2-1.00][19839-0-4-1.50][19930-3-3-2.57][19944-0-4-2.83][20036-2-2-1.69]
[20101-3-3-1.44][20474-1-1--0.35][20547-3-3-1.58][20929-2-2-2.72][21245-1-2-2.48][21257-3-3-0.58][21293-1-1-2.00][21316-1-3-0.68][21384-1-1-1.74][21448-1-2-1.97]
[21483-0-0-4.25][21487-2-2-1.66][21714-0-0-2.86][21943-3-4-0.78][21947-0-0-2.38][21948-0-0-6.97][21965-2-2-1.36][21998-1-1-1.49][22025-0-4-2.21][22228-3-3-2.86]
[22446-1-1-2.09][22494-3-0-3.18][22757-0-0-5.52][22811-3-3-3.26][22976-3-2-0.93][22985-3-3-2.66][23014-0-0-3.35][23112-1-1-1.49][23144-3-3-2.24][23168-2-3--0.14]
[23219-0-0-0.68][23363-3-3-2.89][23470-0-0-1.33][23486-2-2-1.12][23497-0-3-3.68][23516-0-0-3.27][23690-1-1-1.00][23921-2-2-0.84][23936-1-2-1.01][24040-3-4-1.34]
[24111-1-4-1.35][24182-0-0-4.14][24238-3-3-2.32][24290-2-4-1.77][24345-0-4-0.41][24364-1-2-0.78][24427-3-0-2.11][24477-2-2-1.94][24495-2-1-1.19][24893-2-2-1.05]
[25012-1-1-0.46][25121-2-1-3.57][25165-3-3-0.71][25183-0-0-2.18][25297-3-3-2.72][25398-0-0-1.83][25574-2-2-1.03][25644-1-1-4.08][25718-1-3-0.05][25774-2-2-0.62]
[26032-3-3-1.89][26051-3-3-2.39][26120-0-0-1.67][26321-1-1-2.65][26732-1-1-0.08][26784-3-3-3.78][26827-3-3-0.28][26833-0-3-2.93][26838-2-2-1.02][26860-1-4-1.64]
[26948-0-0-2.47][27049-3-0-0.98][27098-1-0-0.28][27526-0-0-0.98][27639-3-0-0.09][27698-3-3-2.68][27772-0-0-4.59][27890-1-1-1.12][28040-0-0-1.02][28503-2-2-1.90]
[28577-1-1-2.84][28959-0-0-3.88][29198-3-3-0.19][29777-0-0-5.94][29877-2-2-2.09][30035-1-2-2.58][30098-0-0-0.59][30326-1-1-4.54][30572-2-1-0.72][30716-0-4-1.22]
[30806-2-2-0.34][30906-1-1-2.65][31007-0-0-3.28][31181-3-3-0.99][31238-0-3-2.39][31347-0-0-4.72][31422-2-2-1.53][31429-3-3-0.08][31431-0-0-2.74][31432-1-1-2.33]
[31477-0-3-2.57][31524-1-1-1.21][31597-1-2-1.12][31619-1-0-1.03][31701-0-0-3.90][31755-0-0-3.71][31854-3-3-1.49][32074-1-1-0.47][32078-3-3-2.34][32111-1-1-2.46]
[32127-1-4-1.01][32140-3-3-1.53][32263-2-3-0.06][32365-0-0-1.31][32411-2-3-2.77][32429-3-0-3.43][32473-3-3-2.67][32574-3-0-2.86][32584-0-4-1.27][32622-0-4-0.50]
[32858-3-3-2.32][32969-3-3-1.13][33016-2-2-1.38][33031-1-3-0.72][33035-2-2-1.66][33133-2-2-3.14][33173-2-2-0.25][33175-3-1-0.93][33306-3-1-1.09][33309-2-1--0.62]
[33474-0-0-0.09][33478-2-0-0.23][33618-1-4-0.64][33712-0-3-0.99][33782-2-1-2.23][33914-3-3-0.14][34076-3-0-1.52][34112-2-1-1.96][34138-2-2-1.05][34239-1-1-0.07]
[34364-2-2-3.28][34617-1-2-1.13][34751-3-3-2.29][34783-2-2-1.84][35015-3-4-0.93][35018-1-2-1.48][35288-2-3-0.81][0-4-1-0.42][1-4-4-0.55][2-4-4-1.09]
[3-4-4-0.62][4-4-3--0.18][5-4-3--0.49][6-4-4-2.08][7-4-4-2.59][8-4-4-0.24][9-4-2-0.28][10-4-4-2.15][11-4-4-1.85][12-4-2-0.32]
[14-4-3-1.07][15-4-3-1.26][16-4-4--0.02][17-4-4-0.33][18-4-4-1.86][19-4-3-1.20][20-4-0-2.14][21-4-1-0.30][22-4-4-1.03][23-4-4-1.15]
[24-4-4-2.62][25-4-4-0.21][26-4-4-0.31][27-4-2-1.72][28-4-1-0.38][29-4-4-0.27][30-4-3-1.07][31-4-4-0.51][32-4-4-1.97][33-4-4--0.09]
[34-4-4-0.41][35-4-0-2.34][37-4-4-1.00][39-4-0-1.07][40-4-0-1.37][41-4-4-0.66][42-4-4-1.41][43-4-4--0.17][45-4-2-1.42][46-4-4-2.53]
[47-4-4-1.76][48-4-1-1.06][51-4-4-1.65][52-4-0-0.86][53-4-4-0.07][54-4-4-0.52][55-4-0-1.07][56-4-2-1.55][57-4-0-0.87][58-4-2-2.00]
[59-4-0-3.29][60-4-4-0.61][61-4-4-1.24][62-4-3--0.35][63-4-2-1.43][64-4-2-1.54][65-4-4-1.85][66-4-4-1.36][67-4-2-1.82][68-4-1-1.50]
[69-4-4-0.58][70-4-4-2.02][72-4-4-1.16][73-4-1-0.90][74-4-2-1.52][75-4-4-0.00][77-4-2-1.72][78-4-1-0.78][79-4-2-1.38][80-4-4-0.91]
[81-4-4-2.13][82-4-4-0.01][83-4-4-0.25][84-4-4-0.88][85-4-4-2.34][86-4-4-1.14][87-4-4-1.22][88-4-4-1.52][89-4-0-0.60][90-4-4-0.40]
[91-4-4-0.98][92-4-4--0.23][93-4-0-2.79][94-4-1-0.91][95-4-3--0.13][96-4-4-1.50][97-4-4-2.24][98-4-4-1.15][99-4-4-0.74][100-4-4-2.51]
[101-4-4-3.49][102-4-4-1.07][103-4-4-0.14][104-4-4-0.99][105-4-1-1.59][106-4-4-0.71][107-4-4-2.49][108-4-4-1.00][109-4-4-0.56][110-4-4-1.29]
[111-4-0-2.03][112-4-0-0.66][113-4-2-0.55][114-4-3-0.29][115-4-4-1.34][116-4-4-0.88][117-4-4-2.37][119-4-4-1.71][121-4-4-1.46][122-4-4-0.51]
[124-4-2--0.86][125-4-4-0.92][126-4-4-1.73][127-4-1-1.54][128-4-0-1.68][129-4-2-1.33][130-4-4-0.51][131-4-2-0.23][132-4-4-0.29][133-4-4-3.05]
[135-4-4-0.86][136-4-1-0.67][137-4-1-0.81][138-4-4-1.58][139-4-4-2.91][140-4-4-1.22][141-4-0-0.97][142-4-4-1.60][143-4-4-1.98][144-4-4-2.72]
[145-4-1-3.58][148-4-0-4.09][149-4-4-0.59][150-4-4-0.67][151-4-1-0.97][152-4-4-0.52][153-4-2-1.48][154-4-4-2.07][155-4-4-1.25][156-4-3-0.69]
[157-4-0-2.78][158-4-4-0.75][160-4-1--0.04][161-4-2-2.49][162-4-4-0.70][164-4-4-1.23][165-4-4-0.96][167-4-4-1.15][168-4-4-0.25][170-4-0-2.49]
[171-4-4-1.10][172-4-4-1.38][173-4-4-2.61][174-4-0-0.66][175-4-4-1.70][177-4-4-2.28][178-4-4-1.60][179-4-3--0.64][180-4-4-1.15][181-4-4-0.67]
[182-4-2-1.65][183-4-4-1.10][184-4-2-1.01][186-4-3-0.06][187-4-1-1.23][188-4-4-0.84][189-4-4-1.41][190-4-4-0.71][191-4-4-0.91][192-4-4-1.53]
[193-4-2-3.57][194-4-0-0.53][195-4-4-0.01][196-4-4-1.15][197-4-1-1.11][198-4-4-1.69][199-4-4-0.92]
---------------------------
I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.515 | Acc: 79.750% | Wgt Acc: 83.373%
	I - Batch: 100 | Loss: 0.505 | Acc: 79.250% | Wgt Acc: 83.037%
	I - Batch: 150 | Loss: 0.492 | Acc: 79.958% | Wgt Acc: 84.009%
	I - Batch: 200 | Loss: 0.487 | Acc: 80.031% | Wgt Acc: 84.082%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 80.209% | Wgt Acc: 84.298% | LR: 1.250000e-04 | Dur: 190.44s
I - Confusion Matrix: [row->prediction - col->label]
[[604.   1.   1.  28. 127.]
 [  2. 529.  24.   5.  98.]
 [  3.  22. 660.  14. 141.]
 [ 36.   3.  12. 470.  52.]
 [ 52.  23.  37.  21. 582.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.155 | Acc: 58.383% | Wgt Acc: 58.461% | Dur: 16.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   6.   5.  16.  28.]
 [  0.  38.  15.   5.  19.]
 [  0.  13.  33.   3.  13.]
 [ 17.   4.  10.  57.  16.]
 [  7.  17.  12.   5. 104.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 80.625% | Wgt Acc: 84.755%
	I - Batch: 100 | Loss: 0.480 | Acc: 80.562% | Wgt Acc: 84.985%
	I - Batch: 150 | Loss: 0.469 | Acc: 81.708% | Wgt Acc: 85.778%
	I - Batch: 200 | Loss: 0.473 | Acc: 81.562% | Wgt Acc: 85.575%
I - num batch: 222
I - Train -- Loss: 0.476 | Acc: 81.252% | Wgt Acc: 85.350% | LR: 1.250000e-04 | Dur: 180.65s
I - Confusion Matrix: [row->prediction - col->label]
[[616.   1.   1.  32. 119.]
 [  1. 541.  15.   7.  88.]
 [  3.  14. 660.   9. 119.]
 [ 28.   5.  10. 472.  81.]
 [ 49.  17.  48.  18. 593.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.078 | Acc: 61.538% | Wgt Acc: 61.026% | Dur: 15.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   2.  12.  19.]
 [  0.  42.  13.   4.  24.]
 [  1.  20.  40.   3.  19.]
 [ 12.   2.   8.  54.   5.]
 [ 12.  10.  12.  13. 113.]]

I - Local maximum validation set accuracy:  61.54

I - Validation set results: 
[14-1-2-1.63][50-3-4--0.09][124-2-2-1.25][127-0-0-3.20][443-2-2-2.75][567-0-0-1.93][573-1-1--0.73][615-0-0-1.80][695-1-2-2.26][722-3-0-3.26]
[826-0-0-1.80][878-0-0-4.93][1103-0-4-1.43][1212-3-3-0.17][1368-0-0-3.70][2181-2-3-0.44][2476-2-2-0.74][2721-2-2-2.12][2818-1-4-0.65][2886-2-1-1.83]
[3231-2-2-3.88][3333-2-1-1.70][3482-2-2-1.45][3536-3-3-1.45][3625-1-1-2.99][3909-0-0-2.44][4035-0-0-2.55][4140-0-0-2.83][4214-1-1-0.30][4346-1-4-0.62]
[4581-2-2-2.67][4708-3-2-1.13][4838-3-4-0.61][4845-1-1-0.53][4868-0-0-2.78][4939-0-4-0.84][4984-2-3--0.51][5078-1-4-1.03][5396-0-0-4.82][5479-1-1-2.80]
[5717-0-0-1.74][5843-1-1-0.82][5949-3-0-1.98][5987-2-4-2.01][6014-3-3-1.93][6033-3-4--0.22][6313-0-0-2.82][6421-3-3-1.01][6500-1-2-0.61][6583-3-3-1.79]
[6683-3-3-1.34][6825-2-3-0.36][6998-3-4-0.08][7049-3-3-1.18][7517-1-1-3.61][7521-1-4--0.74][7528-1-1-0.25][7949-1-2-2.26][8135-1-0-1.29][8185-3-0-3.61]
[8269-3-2-1.14][8273-3-3-1.35][8543-3-0-4.64][8666-1-1-1.60][8672-0-0-5.01][8903-1-1-2.36][9001-2-4-0.83][9036-2-2-2.49][9281-3-4-0.27][9300-2-2-0.95]
[9571-0-0-1.15][9617-1-1-0.82][9644-2-2-1.37][9705-2-4--0.18][9801-0-0-0.94][9803-3-0-0.98][9865-3-3-3.38][9896-2-4-2.07][10314-1-1-0.97][10337-3-3-1.17]
[10403-0-4-1.13][10653-2-4-0.41][10704-2-1-0.85][10719-1-1-2.64][10727-1-4-1.87][10836-0-0-8.76][10969-2-3-0.53][11042-0-3-1.60][11088-1-1-2.65][11322-0-0-2.68]
[11398-2-2-1.42][11499-0-0-1.27][11502-3-3-1.78][11512-3-3-1.20][11608-1-1-4.16][11610-0-0-2.34][11692-0-3-2.85][11905-0-0-1.90][11993-1-1-1.55][12002-2-3-2.25]
[12052-0-0-3.36][12201-0-3-2.55][12235-2-2-1.15][12320-1-4-2.58][12377-2-4-1.95][12398-2-3-1.32][12503-1-2-1.11][12617-0-3-0.32][12685-3-1-0.63][12738-2-0-0.49]
[12742-2-2-3.32][12823-0-0-3.47][13110-1-2-1.18][13240-3-0-4.61][13253-1-4-1.33][13273-0-0-7.11][13634-1-1-0.02][13763-2-2-0.30][13905-3-3-1.62][14060-2-1-1.43]
[14065-3-3-1.04][14147-3-3-1.32][14595-2-4-1.41][14687-2-2-4.75][14788-2-2-3.68][14869-1-1-2.26][14872-3-4-0.76][14877-1-1-1.84][14927-0-3-2.52][15066-0-0-4.40]
[15175-1-4-2.32][15178-2-3-1.10][15375-3-3-1.72][15389-3-3-2.48][15568-2-1-1.01][15675-3-3-2.37][15869-1-0--0.08][16207-3-2-0.10][16236-0-0--0.01][16302-3-3-0.68]
[16331-2-2-5.22][16381-0-3-1.45][16488-1-1-3.86][16495-0-0-1.15][16650-0-0-4.50][16719-1-2-0.87][16801-0-0-4.36][16828-0-0-2.15][17137-3-3-1.34][17245-1-1-1.66]
[17278-3-0-1.69][17282-0-4--0.34][17311-2-2-3.08][17336-2-1-1.39][17608-3-3-2.97][17627-0-4-0.87][17877-3-1-0.88][17924-1-2-0.23][17984-3-0-4.01][18211-0-0-2.14]
[18276-3-3-1.85][18287-1-1-1.84][18394-0-0-3.93][18428-0-0-4.56][18442-0-3-3.29][18478-3-0-2.87][18607-0-0-3.50][18616-0-4-0.60][18663-0-0-0.09][18718-0-0-3.61]
[18766-2-2-2.57][18824-2-1-1.05][18890-3-3-0.71][18930-3-4-2.53][18938-3-3-1.34][19817-1-2-1.22][19839-0-4-1.16][19930-3-3-2.64][19944-0-4-2.10][20036-2-2-1.62]
[20101-3-3-1.36][20474-1-2-1.16][20547-3-4-0.48][20929-2-2-2.89][21245-1-1-0.63][21257-3-4--0.36][21293-1-1-3.40][21316-1-2-1.17][21384-1-1-2.64][21448-1-2-1.23]
[21483-0-0-3.81][21487-2-2-1.88][21714-0-0-2.34][21943-3-4-0.51][21947-0-0-3.35][21948-0-0-7.37][21965-2-2-3.33][21998-1-1-0.92][22025-0-4-1.41][22228-3-3-3.25]
[22446-1-1-2.39][22494-3-0-3.53][22757-0-0-6.12][22811-3-3-3.12][22976-3-1-1.67][22985-3-3-2.83][23014-0-0-5.86][23112-1-1-1.44][23144-3-3-3.68][23168-2-4--0.25]
[23219-0-0-1.03][23363-3-3-2.34][23470-0-0-0.86][23486-2-2-1.71][23497-0-3-3.57][23516-0-0-2.87][23690-1-1-2.13][23921-2-4-0.60][23936-1-2-1.17][24040-3-4-0.89]
[24111-1-4-1.51][24182-0-0-4.11][24238-3-3-2.90][24290-2-4-0.81][24345-0-4-0.80][24364-1-2-1.36][24427-3-0-1.09][24477-2-2-1.65][24495-2-1-1.25][24893-2-2-1.57]
[25012-1-1-0.75][25121-2-1-2.45][25165-3-3-0.94][25183-0-0-3.17][25297-3-3-2.59][25398-0-0-1.86][25574-2-2-1.04][25644-1-1-2.83][25718-1-0-0.28][25774-2-2-0.63]
[26032-3-3-2.03][26051-3-3-2.95][26120-0-0-2.32][26321-1-1-1.49][26732-1-2--0.34][26784-3-3-4.39][26827-3-3-1.82][26833-0-3-3.21][26838-2-2-1.23][26860-1-4-1.52]
[26948-0-0-0.99][27049-3-3-0.85][27098-1-1--0.14][27526-0-0-1.24][27639-3-3-0.05][27698-3-3-2.48][27772-0-0-4.42][27890-1-1-2.23][28040-0-4-1.22][28503-2-2-2.02]
[28577-1-1-3.03][28959-0-0-3.88][29198-3-4-0.34][29777-0-0-6.68][29877-2-2-0.50][30035-1-2-2.19][30098-0-0-0.72][30326-1-1-3.80][30572-2-2-0.83][30716-0-4-1.43]
[30806-2-2--0.33][30906-1-1-2.64][31007-0-0-2.16][31181-3-3-0.34][31238-0-3-1.01][31347-0-0-3.81][31422-2-4-0.76][31429-3-3-0.82][31431-0-0-2.01][31432-1-1-1.43]
[31477-0-3-2.89][31524-1-1-1.47][31597-1-2-0.27][31619-1-0-1.15][31701-0-0-2.74][31755-0-0-4.18][31854-3-3-1.58][32074-1-3--0.08][32078-3-3-3.09][32111-1-1-2.58]
[32127-1-2-1.10][32140-3-3-2.30][32263-2-4-0.28][32365-0-0-1.64][32411-2-3-3.29][32429-3-3-2.69][32473-3-3-2.42][32574-3-3-1.70][32584-0-0-1.00][32622-0-2-0.39]
[32858-3-3-2.43][32969-3-3-2.23][33016-2-2-3.50][33031-1-3-0.82][33035-2-2-2.04][33133-2-2-3.01][33173-2-2-0.37][33175-3-4-0.60][33306-3-1-0.40][33309-2-1--0.12]
[33474-0-0-0.01][33478-2-0-0.47][33618-1-1-0.66][33712-0-3-0.67][33782-2-1-2.28][33914-3-3-0.94][34076-3-0-1.31][34112-2-1-1.34][34138-2-2-0.72][34239-1-1--0.10]
[34364-2-2-1.71][34617-1-2-1.68][34751-3-3-2.58][34783-2-2-0.98][35015-3-3-0.45][35018-1-2-0.84][35288-2-1-0.77][0-4-1-0.71][1-4-4-0.92][2-4-4-1.31]
[3-4-4-1.12][4-4-4-0.98][5-4-1-1.54][6-4-4-2.14][7-4-4-0.95][8-4-4-0.33][9-4-2-0.53][10-4-4-2.98][11-4-4-2.10][12-4-4-0.13]
[14-4-0-0.50][15-4-3-2.06][16-4-4-0.51][17-4-4-0.51][18-4-4-2.51][19-4-0-1.35][20-4-0-1.41][21-4-1-0.30][22-4-4-1.13][23-4-4-0.66]
[24-4-4-3.48][25-4-3-0.99][26-4-1-0.45][27-4-2-1.76][28-4-4-1.54][29-4-4-0.95][30-4-3--0.31][31-4-4--0.06][32-4-4-2.53][33-4-4-0.48]
[34-4-2-0.04][35-4-0-0.81][37-4-4-1.67][39-4-0-1.06][40-4-4-0.17][41-4-0-1.91][42-4-4-1.46][43-4-1--0.16][45-4-1-1.41][46-4-4-2.17]
[47-4-4-1.89][48-4-1-0.93][51-4-4-2.43][52-4-4-2.12][53-4-1-0.47][54-4-4-0.57][55-4-4-1.32][56-4-1-1.65][57-4-0-2.50][58-4-1-0.88]
[59-4-0-2.45][60-4-4-0.90][61-4-4-1.43][62-4-4--0.41][63-4-2-1.29][64-4-2-2.32][65-4-4-2.86][66-4-4-0.58][67-4-4-1.52][68-4-1-0.96]
[69-4-0-1.32][70-4-4-0.95][72-4-4-1.18][73-4-1-1.45][74-4-2-2.17][75-4-2-0.53][77-4-4-1.01][78-4-1-2.19][79-4-4-1.55][80-4-4-1.39]
[81-4-4-0.92][82-4-1-0.38][83-4-4-0.33][84-4-4-1.37][85-4-4-2.37][86-4-4-1.00][87-4-4-1.77][88-4-4-1.81][89-4-0-1.19][90-4-4-0.34]
[91-4-2-1.08][92-4-4-0.63][93-4-0-2.24][94-4-1-1.10][95-4-4-0.97][96-4-4-1.41][97-4-4-1.90][98-4-2-1.60][99-4-4-0.82][100-4-4-2.72]
[101-4-4-4.28][102-4-4-1.56][103-4-4--0.45][104-4-4-1.21][105-4-4-1.77][106-4-4-1.49][107-4-4-2.67][108-4-4-1.39][109-4-4--0.00][110-4-4-1.98]
[111-4-0-2.58][112-4-4-1.17][113-4-3-0.33][114-4-0-0.69][115-4-4-1.27][116-4-4-0.94][117-4-4-1.88][119-4-2-3.03][121-4-1-1.20][122-4-4-0.39]
[124-4-1--0.37][125-4-4-0.96][126-4-4-2.57][127-4-1-1.60][128-4-4-0.93][129-4-1-0.05][130-4-4-0.23][131-4-3--0.09][132-4-4-0.73][133-4-4-2.79]
[135-4-4-1.03][136-4-2-0.14][137-4-1-0.82][138-4-4-0.47][139-4-4-2.14][140-4-4-0.81][141-4-0-2.61][142-4-4-2.41][143-4-4-2.12][144-4-4-3.01]
[145-4-2-1.54][148-4-0-5.19][149-4-4-0.95][150-4-1-0.93][151-4-4-1.03][152-4-1-0.66][153-4-2-1.74][154-4-4-2.39][155-4-4-2.52][156-4-0-0.72]
[157-4-0-0.56][158-4-4-0.57][160-4-4-0.81][161-4-2-1.98][162-4-4-0.70][164-4-4-0.80][165-4-4-1.55][167-4-0-2.06][168-4-4-0.84][170-4-0-3.00]
[171-4-4-1.23][172-4-4-2.42][173-4-4-2.92][174-4-4-0.60][175-4-4-1.72][177-4-4-1.87][178-4-4-1.63][179-4-4-0.08][180-4-4-1.67][181-4-4-0.99]
[182-4-2-1.11][183-4-4-1.38][184-4-2-0.64][186-4-4-0.84][187-4-4--0.14][188-4-2-1.15][189-4-4-1.19][190-4-4-1.02][191-4-4-1.56][192-4-4-0.92]
[193-4-2-2.60][194-4-1-1.15][195-4-1-0.57][196-4-2-1.21][197-4-4-0.90][198-4-4-2.65][199-4-4-1.24]
---------------------------
I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.417 | Acc: 83.375% | Wgt Acc: 87.030%
	I - Batch: 100 | Loss: 0.425 | Acc: 83.188% | Wgt Acc: 87.421%
	I - Batch: 150 | Loss: 0.443 | Acc: 82.583% | Wgt Acc: 86.793%
	I - Batch: 200 | Loss: 0.453 | Acc: 81.844% | Wgt Acc: 86.088%
I - num batch: 222
I - Train -- Loss: 0.454 | Acc: 81.759% | Wgt Acc: 85.989% | LR: 1.250000e-04 | Dur: 188.12s
I - Confusion Matrix: [row->prediction - col->label]
[[618.   0.   0.  22. 111.]
 [  0. 537.  18.   6. 103.]
 [  6.  15. 672.  15. 129.]
 [ 28.   6.  13. 483.  67.]
 [ 45.  20.  31.  12. 590.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.159 | Acc: 58.383% | Wgt Acc: 56.987% | Dur: 19.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   2.  14.  21.]
 [  0.  34.  10.   3.  20.]
 [  0.  15.  32.   5.  16.]
 [ 14.   4.  11.  54.   9.]
 [ 12.  22.  20.  10. 114.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.423 | Acc: 83.250% | Wgt Acc: 86.799%
	I - Batch: 100 | Loss: 0.410 | Acc: 84.375% | Wgt Acc: 88.137%
	I - Batch: 150 | Loss: 0.417 | Acc: 84.125% | Wgt Acc: 88.089%
	I - Batch: 200 | Loss: 0.423 | Acc: 83.875% | Wgt Acc: 87.775%
I - num batch: 222
I - Train -- Loss: 0.425 | Acc: 83.846% | Wgt Acc: 87.643% | LR: 1.250000e-04 | Dur: 181.24s
I - Confusion Matrix: [row->prediction - col->label]
[[621.   0.   0.  25. 113.]
 [  4. 552.  11.   2.  91.]
 [  2.   8. 684.   9. 108.]
 [ 27.   5.   9. 482.  53.]
 [ 43.  13.  30.  20. 635.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.156 | Acc: 59.763% | Wgt Acc: 58.734% | Dur: 15.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   4.  18.  18.]
 [  0.  32.  16.   3.  16.]
 [  0.  18.  37.   3.  22.]
 [ 13.   5.  10.  58.  11.]
 [ 12.  21.   8.   4. 113.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.411 | Acc: 84.375% | Wgt Acc: 88.233%
	I - Batch: 100 | Loss: 0.427 | Acc: 83.375% | Wgt Acc: 87.326%
	I - Batch: 150 | Loss: 0.429 | Acc: 83.083% | Wgt Acc: 87.099%
	I - Batch: 200 | Loss: 0.433 | Acc: 83.094% | Wgt Acc: 87.128%
I - num batch: 222
I - Train -- Loss: 0.433 | Acc: 82.972% | Wgt Acc: 87.117% | LR: 1.250000e-04 | Dur: 182.94s
I - Confusion Matrix: [row->prediction - col->label]
[[625.   1.   0.  26. 123.]
 [  0. 555.  14.   2.  90.]
 [  5.   9. 670.  10. 115.]
 [ 19.   0.  14. 483.  62.]
 [ 48.  13.  36.  17. 610.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.133 | Acc: 59.961% | Wgt Acc: 58.079% | Dur: 16.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   6.   3.  18.  18.]
 [  0.  36.  14.   6.  15.]
 [  0.  15.  32.   2.  19.]
 [ 16.   2.  12.  54.   7.]
 [ 11.  19.  14.   6. 121.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.375 | Acc: 85.500% | Wgt Acc: 89.491%
	I - Batch: 100 | Loss: 0.377 | Acc: 85.312% | Wgt Acc: 89.111%
	I - Batch: 150 | Loss: 0.390 | Acc: 84.792% | Wgt Acc: 88.636%
	I - Batch: 200 | Loss: 0.391 | Acc: 84.469% | Wgt Acc: 88.436%
I - num batch: 222
I - Train -- Loss: 0.393 | Acc: 84.325% | Wgt Acc: 88.319% | LR: 1.250000e-04 | Dur: 189.68s
I - Confusion Matrix: [row->prediction - col->label]
[[628.   1.   1.  20. 103.]
 [  2. 552.   8.   5.  86.]
 [  1.   8. 687.   7. 112.]
 [ 16.   3.  11. 494.  69.]
 [ 50.  14.  27.  12. 630.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.166 | Acc: 59.369% | Wgt Acc: 59.170% | Dur: 18.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   6.   2.  18.  28.]
 [  0.  38.  13.   5.  18.]
 [  0.  16.  40.   4.  20.]
 [ 11.   6.   9.  50.  10.]
 [  8.  12.  11.   9. 104.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.356 | Acc: 86.000% | Wgt Acc: 90.010%
	I - Batch: 100 | Loss: 0.376 | Acc: 85.000% | Wgt Acc: 89.238%
	I - Batch: 150 | Loss: 0.382 | Acc: 84.833% | Wgt Acc: 88.865%
	I - Batch: 200 | Loss: 0.391 | Acc: 84.688% | Wgt Acc: 88.743%
I - num batch: 222
I - Train -- Loss: 0.394 | Acc: 84.748% | Wgt Acc: 88.643% | LR: 1.250000e-04 | Dur: 186.31s
I - Confusion Matrix: [row->prediction - col->label]
[[633.   1.   1.  17. 109.]
 [  2. 550.   7.   3.  71.]
 [  2.  15. 687.   7. 121.]
 [ 14.   0.   8. 497.  60.]
 [ 46.  12.  31.  14. 639.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.119 | Acc: 58.185% | Wgt Acc: 57.751% | Dur: 16.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   2.   2.  15.  12.]
 [  1.  37.  14.   4.  18.]
 [  3.  23.  43.   5.  32.]
 [ 13.   2.   4.  53.  12.]
 [ 15.  14.  12.   9. 106.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.420 | Acc: 82.875% | Wgt Acc: 87.162%
	I - Batch: 100 | Loss: 0.406 | Acc: 84.688% | Wgt Acc: 88.383%
	I - Batch: 150 | Loss: 0.392 | Acc: 84.958% | Wgt Acc: 88.731%
	I - Batch: 200 | Loss: 0.387 | Acc: 85.406% | Wgt Acc: 89.089%
I - num batch: 222
I - Train -- Loss: 0.387 | Acc: 85.481% | Wgt Acc: 89.161% | LR: 1.250000e-04 | Dur: 180.86s
I - Confusion Matrix: [row->prediction - col->label]
[[632.   1.   0.  18. 110.]
 [  5. 554.   7.   3.  74.]
 [  1.   6. 695.  10. 103.]
 [ 14.   4.  10. 494.  56.]
 [ 45.  13.  22.  13. 657.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.178 | Acc: 58.777% | Wgt Acc: 58.406% | Dur: 15.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   3.  14.  21.]
 [  0.  36.  13.   4.  17.]
 [  0.  16.  34.   1.  21.]
 [ 14.   4.  10.  56.  14.]
 [  9.  18.  15.  11. 107.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.361 | Acc: 85.750% | Wgt Acc: 89.747%
	I - Batch: 100 | Loss: 0.370 | Acc: 85.438% | Wgt Acc: 89.152%
	I - Batch: 150 | Loss: 0.377 | Acc: 85.042% | Wgt Acc: 88.708%
	I - Batch: 200 | Loss: 0.375 | Acc: 85.469% | Wgt Acc: 89.219%
I - num batch: 222
I - Train -- Loss: 0.375 | Acc: 85.368% | Wgt Acc: 89.146% | LR: 1.250000e-04 | Dur: 182.35s
I - Confusion Matrix: [row->prediction - col->label]
[[628.   0.   0.  14. 103.]
 [  2. 553.   4.   5.  75.]
 [  1.   5. 696.   4. 101.]
 [ 18.   1.   8. 499.  69.]
 [ 48.  19.  26.  16. 652.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.187 | Acc: 58.974% | Wgt Acc: 56.386% | Dur: 15.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   8.   2.  26.  25.]
 [  0.  33.  13.   5.  15.]
 [  1.  13.  37.   2.  18.]
 [  7.   3.   6.  40.   4.]
 [  9.  21.  17.  13. 118.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.392 | Acc: 83.875% | Wgt Acc: 87.606%
	I - Batch: 100 | Loss: 0.366 | Acc: 85.188% | Wgt Acc: 88.941%
	I - Batch: 150 | Loss: 0.362 | Acc: 85.542% | Wgt Acc: 89.263%
	I - Batch: 200 | Loss: 0.356 | Acc: 85.938% | Wgt Acc: 89.692%
I - num batch: 222
I - Train -- Loss: 0.354 | Acc: 86.270% | Wgt Acc: 90.011% | LR: 1.250000e-04 | Dur: 184.65s
I - Confusion Matrix: [row->prediction - col->label]
[[637.   0.   0.  14. 121.]
 [  0. 562.   4.   0.  58.]
 [  0.   5. 696.   7.  99.]
 [ 20.   3.   9. 501.  58.]
 [ 40.   8.  25.  16. 664.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.133 | Acc: 61.144% | Wgt Acc: 56.932% | Dur: 19.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   3.  21.  16.]
 [  1.  32.  15.   4.   9.]
 [  0.  18.  30.   1.  18.]
 [  7.   3.   7.  43.   1.]
 [ 11.  22.  20.  17. 136.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.349 | Acc: 85.250% | Wgt Acc: 89.218%
	I - Batch: 100 | Loss: 0.344 | Acc: 86.062% | Wgt Acc: 89.836%
	I - Batch: 150 | Loss: 0.339 | Acc: 86.542% | Wgt Acc: 90.198%
	I - Batch: 200 | Loss: 0.344 | Acc: 86.000% | Wgt Acc: 89.929%
I - num batch: 222
I - Train -- Loss: 0.342 | Acc: 86.157% | Wgt Acc: 90.056% | LR: 1.250000e-04 | Dur: 181.28s
I - Confusion Matrix: [row->prediction - col->label]
[[636.   0.   0.  10. 110.]
 [  0. 565.   5.   2.  63.]
 [  3.   2. 695.   7. 114.]
 [ 10.   1.   4. 504.  57.]
 [ 48.  10.  30.  15. 656.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.215 | Acc: 57.199% | Wgt Acc: 55.568% | Dur: 15.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   1.   4.  20.  20.]
 [  0.  29.   7.   3.  12.]
 [  2.  25.  31.   2.  25.]
 [ 11.   7.  12.  53.  11.]
 [ 10.  16.  21.   8. 112.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.306 | Acc: 88.750% | Wgt Acc: 92.310%
	I - Batch: 100 | Loss: 0.314 | Acc: 87.688% | Wgt Acc: 91.113%
	I - Batch: 150 | Loss: 0.327 | Acc: 87.375% | Wgt Acc: 90.744%
	I - Batch: 200 | Loss: 0.334 | Acc: 87.062% | Wgt Acc: 90.444%
I - num batch: 222
I - Train -- Loss: 0.337 | Acc: 86.806% | Wgt Acc: 90.311% | LR: 1.250000e-04 | Dur: 188.22s
I - Confusion Matrix: [row->prediction - col->label]
[[652.   0.   1.  17.  97.]
 [  0. 559.   1.   5.  71.]
 [  2.   2. 688.   1.  99.]
 [ 11.   0.  13. 500.  53.]
 [ 32.  17.  31.  15. 680.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.171 | Acc: 58.185% | Wgt Acc: 56.659% | Dur: 19.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   1.   1.  14.  11.]
 [  0.  32.  10.   6.  22.]
 [  0.  18.  35.   1.  22.]
 [ 18.   6.  11.  56.  10.]
 [ 13.  21.  18.   9. 115.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.314 | Acc: 87.250% | Wgt Acc: 90.813%
	I - Batch: 100 | Loss: 0.321 | Acc: 87.000% | Wgt Acc: 90.700%
	I - Batch: 150 | Loss: 0.323 | Acc: 86.917% | Wgt Acc: 90.617%
	I - Batch: 200 | Loss: 0.333 | Acc: 86.938% | Wgt Acc: 90.543%
I - num batch: 222
I - Train -- Loss: 0.331 | Acc: 87.116% | Wgt Acc: 90.589% | LR: 1.250000e-04 | Dur: 180.71s
I - Confusion Matrix: [row->prediction - col->label]
[[638.   0.   0.  16.  96.]
 [  1. 561.   4.   5.  64.]
 [  0.   2. 696.   5.  90.]
 [ 14.   0.   9. 507.  62.]
 [ 44.  15.  25.   5. 688.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.231 | Acc: 58.185% | Wgt Acc: 57.314% | Dur: 15.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   5.  22.  25.]
 [  0.  33.  11.   0.  18.]
 [  0.  13.  27.   1.  11.]
 [ 13.  10.  14.  57.  16.]
 [  7.  17.  18.   6. 110.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.291 | Acc: 89.875% | Wgt Acc: 92.951%
	I - Batch: 100 | Loss: 0.307 | Acc: 88.375% | Wgt Acc: 91.944%
	I - Batch: 150 | Loss: 0.304 | Acc: 88.417% | Wgt Acc: 91.982%
	I - Batch: 200 | Loss: 0.319 | Acc: 87.750% | Wgt Acc: 91.420%
I - num batch: 222
I - Train -- Loss: 0.320 | Acc: 87.821% | Wgt Acc: 91.348% | LR: 1.250000e-04 | Dur: 193.06s
I - Confusion Matrix: [row->prediction - col->label]
[[647.   0.   0.  12.  98.]
 [  1. 565.   1.   1.  71.]
 [  1.   3. 705.   5.  87.]
 [ 10.   2.   4. 508.  54.]
 [ 38.   8.  24.  12. 690.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.138 | Acc: 60.552% | Wgt Acc: 56.878% | Dur: 21.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   1.   1.  19.   9.]
 [  1.  34.   9.   8.  16.]
 [  2.  18.  41.   5.  21.]
 [  6.   1.   3.  40.   4.]
 [ 17.  24.  21.  14. 130.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.286 | Acc: 89.375% | Wgt Acc: 92.657%
	I - Batch: 100 | Loss: 0.292 | Acc: 88.750% | Wgt Acc: 92.251%
	I - Batch: 150 | Loss: 0.301 | Acc: 88.667% | Wgt Acc: 91.942%
	I - Batch: 200 | Loss: 0.304 | Acc: 88.125% | Wgt Acc: 91.502%
I - num batch: 222
I - Train -- Loss: 0.305 | Acc: 87.990% | Wgt Acc: 91.431% | LR: 1.250000e-04 | Dur: 180.00s
I - Confusion Matrix: [row->prediction - col->label]
[[650.   0.   0.  11. 104.]
 [  1. 558.   2.   3.  72.]
 [  1.   8. 715.   5.  85.]
 [  8.   0.   0. 506.  47.]
 [ 37.  12.  17.  13. 692.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.180 | Acc: 58.974% | Wgt Acc: 58.242% | Dur: 15.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   2.  12.  17.]
 [  0.  33.  14.   2.  18.]
 [  0.  17.  35.   2.  18.]
 [ 20.   8.  12.  60.  16.]
 [  8.  17.  12.  10. 111.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.271 | Acc: 90.500% | Wgt Acc: 93.906%
	I - Batch: 100 | Loss: 0.269 | Acc: 90.375% | Wgt Acc: 93.595%
	I - Batch: 150 | Loss: 0.280 | Acc: 89.875% | Wgt Acc: 93.108%
	I - Batch: 200 | Loss: 0.291 | Acc: 89.344% | Wgt Acc: 92.475%
I - num batch: 222
I - Train -- Loss: 0.291 | Acc: 89.146% | Wgt Acc: 92.363% | LR: 1.250000e-04 | Dur: 186.89s
I - Confusion Matrix: [row->prediction - col->label]
[[649.   0.   0.   8.  86.]
 [  1. 567.   1.   2.  63.]
 [  0.   4. 713.   5.  83.]
 [ 12.   2.   3. 513.  48.]
 [ 35.   5.  17.  10. 720.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.216 | Acc: 60.355% | Wgt Acc: 59.170% | Dur: 18.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   3.  15.  12.]
 [  0.  35.  11.   3.  20.]
 [  1.  17.  33.   1.  18.]
 [ 14.   4.  13.  57.  14.]
 [  8.  18.  15.  10. 116.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.289 | Acc: 88.250% | Wgt Acc: 92.112%
	I - Batch: 100 | Loss: 0.284 | Acc: 88.750% | Wgt Acc: 92.201%
	I - Batch: 150 | Loss: 0.282 | Acc: 88.500% | Wgt Acc: 92.145%
	I - Batch: 200 | Loss: 0.283 | Acc: 88.656% | Wgt Acc: 92.260%
I - num batch: 222
I - Train -- Loss: 0.287 | Acc: 88.638% | Wgt Acc: 92.175% | LR: 1.250000e-04 | Dur: 182.62s
I - Confusion Matrix: [row->prediction - col->label]
[[647.   0.   0.   7. 118.]
 [  0. 564.   2.   2.  57.]
 [  0.   3. 719.   2.  78.]
 [ 10.   1.   3. 517.  50.]
 [ 40.  10.  10.  10. 697.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.225 | Acc: 59.369% | Wgt Acc: 57.697% | Dur: 17.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   3.  16.  18.]
 [  0.  37.  10.   3.  20.]
 [  0.  17.  29.   1.  15.]
 [ 13.   5.  16.  54.   8.]
 [ 13.  16.  17.  12. 119.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.258 | Acc: 88.875% | Wgt Acc: 92.445%
	I - Batch: 100 | Loss: 0.268 | Acc: 89.312% | Wgt Acc: 92.608%
	I - Batch: 150 | Loss: 0.270 | Acc: 89.667% | Wgt Acc: 92.895%
	I - Batch: 200 | Loss: 0.272 | Acc: 89.688% | Wgt Acc: 92.895%
I - num batch: 222
I - Train -- Loss: 0.267 | Acc: 89.822% | Wgt Acc: 93.025% | LR: 1.250000e-04 | Dur: 190.38s
I - Confusion Matrix: [row->prediction - col->label]
[[657.   1.   0.   5.  85.]
 [  0. 568.   3.   1.  64.]
 [  0.   2. 713.   2.  75.]
 [  9.   3.   2. 520.  48.]
 [ 31.   4.  16.  10. 728.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.113 | Acc: 63.511% | Wgt Acc: 60.535% | Dur: 18.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   3.  15.  11.]
 [  0.  35.   9.   8.  11.]
 [  0.  19.  37.   2.  19.]
 [  9.   2.   6.  52.   6.]
 [ 14.  19.  20.   9. 133.]]

I - Local maximum validation set accuracy:  63.51

I - Validation set results: 
[14-1-2-2.97][50-3-4-1.61][124-2-2-3.15][127-0-0-4.21][443-2-2-4.59][567-0-0-2.79][573-1-1--0.15][615-0-3-1.54][695-1-2-4.29][722-3-3-3.26]
[826-0-0-1.99][878-0-0-4.79][1103-0-4-1.23][1212-3-0-0.46][1368-0-0-4.51][2181-2-3-0.69][2476-2-2-1.42][2721-2-2-1.89][2818-1-0-0.51][2886-2-1-2.86]
[3231-2-2-4.27][3333-2-2-1.43][3482-2-2-1.96][3536-3-0-0.83][3625-1-1-4.43][3909-0-0-2.02][4035-0-0-2.11][4140-0-0-1.62][4214-1-1-1.80][4346-1-2-0.83]
[4581-2-2-2.18][4708-3-2-1.84][4838-3-0-0.98][4845-1-1-1.46][4868-0-0-3.09][4939-0-4-1.74][4984-2-2-0.47][5078-1-4-2.10][5396-0-0-4.32][5479-1-1-2.91]
[5717-0-0-1.06][5843-1-1-0.89][5949-3-3-1.42][5987-2-4-3.16][6014-3-1-0.22][6033-3-3-0.25][6313-0-0-2.06][6421-3-3-1.68][6500-1-2-1.16][6583-3-3-1.60]
[6683-3-3-1.74][6825-2-1-1.04][6998-3-3-0.13][7049-3-3-0.51][7517-1-1-3.62][7521-1-3--0.03][7528-1-2-0.05][7949-1-2-3.05][8135-1-0-1.39][8185-3-0-3.23]
[8269-3-1-2.20][8273-3-3-1.37][8543-3-0-3.58][8666-1-1-2.73][8672-0-0-2.14][8903-1-1-2.00][9001-2-1-4.51][9036-2-2-2.70][9281-3-3-0.04][9300-2-2-1.90]
[9571-0-0-1.23][9617-1-4-1.88][9644-2-4-1.07][9705-2-4-1.54][9801-0-0-1.23][9803-3-0-1.79][9865-3-3-3.71][9896-2-4-2.81][10314-1-4-0.42][10337-3-3-2.47]
[10403-0-4-1.37][10653-2-4-1.24][10704-2-1-1.71][10719-1-1-2.46][10727-1-4-2.07][10836-0-0-8.53][10969-2-3-0.47][11042-0-0-2.02][11088-1-1-1.76][11322-0-0-1.80]
[11398-2-4-2.03][11499-0-0-1.85][11502-3-3-1.66][11512-3-3-0.20][11608-1-1-5.51][11610-0-0-2.81][11692-0-3-2.05][11905-0-0-1.20][11993-1-1-3.38][12002-2-3-2.45]
[12052-0-0-2.43][12201-0-0-3.15][12235-2-2-1.66][12320-1-4-2.30][12377-2-4-3.17][12398-2-4-1.64][12503-1-2-1.03][12617-0-3--0.44][12685-3-1-0.35][12738-2-4-1.55]
[12742-2-2-2.71][12823-0-0-4.06][13110-1-2-2.10][13240-3-0-5.27][13253-1-4-2.86][13273-0-0-7.83][13634-1-4-1.16][13763-2-2-0.54][13905-3-3-0.29][14060-2-4-0.67]
[14065-3-3-2.15][14147-3-3-2.17][14595-2-2-2.09][14687-2-2-2.77][14788-2-2-4.27][14869-1-1-2.71][14872-3-4-0.60][14877-1-1-2.80][14927-0-3-1.54][15066-0-0-5.07]
[15175-1-4-2.10][15178-2-3-1.16][15375-3-0-2.30][15389-3-3-3.22][15568-2-4-2.67][15675-3-3-2.15][15869-1-0-0.93][16207-3-2-0.89][16236-0-0-1.51][16302-3-3-0.60]
[16331-2-2-6.19][16381-0-3-1.64][16488-1-1-4.63][16495-0-0-1.55][16650-0-0-4.89][16719-1-4-2.16][16801-0-0-4.91][16828-0-0-1.89][17137-3-3-0.82][17245-1-4-1.36]
[17278-3-0-1.05][17282-0-0--0.66][17311-2-2-4.44][17336-2-2-1.86][17608-3-3-3.79][17627-0-4-1.34][17877-3-4-1.08][17924-1-2-1.70][17984-3-3-2.93][18211-0-0-1.92]
[18276-3-3-2.32][18287-1-1-1.00][18394-0-0-4.30][18428-0-0-5.18][18442-0-3-3.88][18478-3-0-2.90][18607-0-0-3.62][18616-0-4-1.19][18663-0-0-0.96][18718-0-0-2.83]
[18766-2-2-2.90][18824-2-4-1.24][18890-3-3-0.23][18930-3-4-2.37][18938-3-3-1.58][19817-1-2-2.16][19839-0-4-2.53][19930-3-3-2.13][19944-0-4-2.68][20036-2-2-3.40]
[20101-3-3-0.71][20474-1-2-0.52][20547-3-3-1.72][20929-2-2-3.50][21245-1-2-2.30][21257-3-1-0.08][21293-1-1-5.06][21316-1-1-3.20][21384-1-1-2.29][21448-1-2-2.46]
[21483-0-0-4.44][21487-2-2-3.30][21714-0-0-2.94][21943-3-4-0.96][21947-0-0-3.48][21948-0-0-6.62][21965-2-2-2.35][21998-1-1-2.09][22025-0-4-2.04][22228-3-3-3.04]
[22446-1-1-1.10][22494-3-0-2.62][22757-0-0-4.96][22811-3-3-3.82][22976-3-1-2.17][22985-3-3-3.14][23014-0-3-3.22][23112-1-1-2.66][23144-3-3-3.45][23168-2-3-0.11]
[23219-0-4-0.88][23363-3-3-3.21][23470-0-4-1.00][23486-2-4-0.86][23497-0-3-3.36][23516-0-0-3.08][23690-1-4-1.72][23921-2-2-1.05][23936-1-2-1.25][24040-3-4-1.64]
[24111-1-4-1.67][24182-0-0-3.02][24238-3-3-3.59][24290-2-0-2.10][24345-0-0-1.35][24364-1-2-2.28][24427-3-0-1.37][24477-2-4-2.97][24495-2-1-1.87][24893-2-2-2.04]
[25012-1-4-0.81][25121-2-1-2.63][25165-3-3-1.30][25183-0-0-2.80][25297-3-3-4.47][25398-0-0-2.75][25574-2-2-2.54][25644-1-1-1.98][25718-1-4--0.07][25774-2-2-1.23]
[26032-3-3-1.42][26051-3-3-3.68][26120-0-4-2.79][26321-1-1-2.55][26732-1-1-1.74][26784-3-3-4.37][26827-3-4-0.04][26833-0-3-3.54][26838-2-4-0.64][26860-1-4-1.02]
[26948-0-0-0.67][27049-3-0-0.43][27098-1-4-0.67][27526-0-0-1.78][27639-3-3--0.01][27698-3-3-2.27][27772-0-0-4.81][27890-1-1-1.89][28040-0-0-1.29][28503-2-2-2.18]
[28577-1-1-3.85][28959-0-0-3.84][29198-3-1-1.40][29777-0-0-6.95][29877-2-2-0.93][30035-1-2-3.06][30098-0-4-0.45][30326-1-1-5.04][30572-2-2-1.32][30716-0-4-2.44]
[30806-2-4-0.30][30906-1-1-3.59][31007-0-0-1.99][31181-3-0-0.84][31238-0-0-2.23][31347-0-0-5.66][31422-2-2-0.96][31429-3-3-0.18][31431-0-0-2.40][31432-1-1-2.98]
[31477-0-0-2.75][31524-1-1-2.43][31597-1-1-1.80][31619-1-2-1.23][31701-0-0-2.07][31755-0-0-4.48][31854-3-3-0.02][32074-1-2-2.13][32078-3-3-2.15][32111-1-1-2.12]
[32127-1-4-1.29][32140-3-3-1.96][32263-2-0-0.59][32365-0-0-4.11][32411-2-3-3.07][32429-3-3-2.48][32473-3-3-1.94][32574-3-3-2.22][32584-0-0-1.81][32622-0-4-1.42]
[32858-3-3-1.76][32969-3-0-2.26][33016-2-2-2.44][33031-1-3-0.68][33035-2-2-1.98][33133-2-2-3.31][33173-2-4--0.26][33175-3-4-1.53][33306-3-1-1.63][33309-2-1-0.04]
[33474-0-0-1.36][33478-2-0-0.99][33618-1-4-1.04][33712-0-0-0.73][33782-2-4-2.00][33914-3-3-1.24][34076-3-4-1.67][34112-2-1-1.87][34138-2-4--0.15][34239-1-1--0.41]
[34364-2-2-2.79][34617-1-2-1.68][34751-3-1-2.04][34783-2-4-1.50][35015-3-3-0.52][35018-1-4-1.08][35288-2-1-0.77][0-4-1-0.91][1-4-4-1.66][2-4-4-2.73]
[3-4-4-1.21][4-4-4-0.17][5-4-1-0.13][6-4-4-2.28][7-4-4-1.76][8-4-4-0.97][9-4-4-1.34][10-4-4-3.39][11-4-4-2.59][12-4-4-1.50]
[14-4-4-0.73][15-4-3-2.92][16-4-4-0.60][17-4-4-2.25][18-4-4-2.19][19-4-3-1.41][20-4-0-1.97][21-4-4-1.03][22-4-4-1.63][23-4-4-1.72]
[24-4-4-3.72][25-4-4-0.98][26-4-1-0.24][27-4-2-3.88][28-4-4-2.24][29-4-4-0.69][30-4-0--0.15][31-4-4-1.19][32-4-4-2.75][33-4-4-0.62]
[34-4-4-1.57][35-4-4-1.94][37-4-2-1.31][39-4-0-5.22][40-4-4-1.76][41-4-0-1.73][42-4-2-2.45][43-4-4-1.29][45-4-2-2.11][46-4-4-3.80]
[47-4-4-2.45][48-4-4-1.00][51-4-4-2.86][52-4-4-1.40][53-4-2-1.63][54-4-4-1.21][55-4-4-2.74][56-4-4-2.40][57-4-0-1.74][58-4-2-1.92]
[59-4-0-4.07][60-4-4-1.81][61-4-4-3.45][62-4-4-0.52][63-4-2-1.80][64-4-4-1.43][65-4-4-2.33][66-4-4-1.34][67-4-4-1.57][68-4-1-2.95]
[69-4-4-0.76][70-4-4-3.00][72-4-4-0.82][73-4-1-1.06][74-4-2-1.72][75-4-2-0.17][77-4-4-1.32][78-4-4-0.19][79-4-4-1.91][80-4-4-1.76]
[81-4-2-1.48][82-4-4--0.02][83-4-4-0.95][84-4-4-1.94][85-4-4-3.69][86-4-4-2.66][87-4-4-2.07][88-4-4-2.48][89-4-0-0.10][90-4-4-0.68]
[91-4-4-1.72][92-4-4-0.93][93-4-0-2.64][94-4-4-1.13][95-4-4-0.65][96-4-4-3.60][97-4-4-3.03][98-4-2-2.27][99-4-4-1.33][100-4-4-3.68]
[101-4-4-4.56][102-4-4-1.88][103-4-4-1.06][104-4-4-2.35][105-4-1-1.21][106-4-4-2.38][107-4-4-3.22][108-4-2-1.56][109-4-4-0.26][110-4-4-1.57]
[111-4-3-2.33][112-4-0-1.52][113-4-4-0.61][114-4-3-0.27][115-4-4-1.14][116-4-4-1.78][117-4-4-3.46][119-4-4-1.84][121-4-4-1.39][122-4-4-1.13]
[124-4-4-0.65][125-4-4-1.49][126-4-4-3.17][127-4-1-2.94][128-4-4-1.20][129-4-2-1.47][130-4-4-1.51][131-4-2-0.97][132-4-4-2.39][133-4-4-3.61]
[135-4-4-2.24][136-4-4-1.23][137-4-4-1.64][138-4-4-2.19][139-4-4-3.23][140-4-4-1.30][141-4-2-2.12][142-4-4-2.30][143-4-4-2.72][144-4-4-2.54]
[145-4-1-2.83][148-4-0-5.44][149-4-4-1.93][150-4-4-1.73][151-4-4-1.98][152-4-4-0.42][153-4-1-1.22][154-4-4-2.89][155-4-4-2.91][156-4-3-0.09]
[157-4-0-1.86][158-4-4-0.78][160-4-1-0.90][161-4-2-2.84][162-4-4-1.60][164-4-4-1.15][165-4-4-2.18][167-4-4-1.74][168-4-4-1.27][170-4-4-1.87]
[171-4-4-2.56][172-4-4-2.44][173-4-4-3.61][174-4-4-1.59][175-4-4-2.87][177-4-4-1.49][178-4-4-1.81][179-4-4-1.89][180-4-4-2.00][181-4-3-0.76]
[182-4-2-2.95][183-4-4-1.73][184-4-4-1.77][186-4-4-1.34][187-4-4-1.76][188-4-4-2.33][189-4-4-1.21][190-4-4-1.26][191-4-4-2.42][192-4-4-1.67]
[193-4-2-3.02][194-4-1-1.36][195-4-4-0.74][196-4-2-1.39][197-4-4-2.27][198-4-4-2.85][199-4-4-1.82]
---------------------------
I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.264 | Acc: 90.500% | Wgt Acc: 93.396%
	I - Batch: 100 | Loss: 0.264 | Acc: 90.250% | Wgt Acc: 93.352%
	I - Batch: 150 | Loss: 0.265 | Acc: 90.458% | Wgt Acc: 93.395%
	I - Batch: 200 | Loss: 0.265 | Acc: 90.094% | Wgt Acc: 93.091%
I - num batch: 222
I - Train -- Loss: 0.261 | Acc: 90.302% | Wgt Acc: 93.265% | LR: 1.250000e-04 | Dur: 181.99s
I - Confusion Matrix: [row->prediction - col->label]
[[655.   0.   0.  11.  78.]
 [  1. 571.   3.   1.  49.]
 [  0.   3. 720.   1.  77.]
 [ 10.   0.   0. 513.  52.]
 [ 31.   4.  11.  12. 744.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.145 | Acc: 62.130% | Wgt Acc: 60.262% | Dur: 15.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.  13.  12.]
 [  0.  31.   9.   2.  15.]
 [  0.  18.  40.   1.  17.]
 [ 12.   7.   8.  57.  14.]
 [ 11.  19.  17.  13. 122.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.286 | Acc: 87.500% | Wgt Acc: 90.940%
	I - Batch: 100 | Loss: 0.261 | Acc: 89.625% | Wgt Acc: 92.830%
	I - Batch: 150 | Loss: 0.264 | Acc: 89.125% | Wgt Acc: 92.440%
	I - Batch: 200 | Loss: 0.267 | Acc: 88.906% | Wgt Acc: 92.092%
I - num batch: 222
I - Train -- Loss: 0.269 | Acc: 88.836% | Wgt Acc: 92.055% | LR: 1.250000e-04 | Dur: 190.21s
I - Confusion Matrix: [row->prediction - col->label]
[[638.   0.   0.  10. 104.]
 [  0. 571.   0.   1.  54.]
 [  1.   1. 716.   1.  74.]
 [ 10.   0.   3. 508.  50.]
 [ 48.   6.  15.  18. 718.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.209 | Acc: 61.736% | Wgt Acc: 60.153% | Dur: 20.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   6.   4.  20.  22.]
 [  0.  35.  10.   1.  18.]
 [  0.  13.  29.   2.  12.]
 [ 11.   8.  14.  55.   8.]
 [  3.  16.  18.   8. 120.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.259 | Acc: 90.250% | Wgt Acc: 93.138%
	I - Batch: 100 | Loss: 0.260 | Acc: 89.938% | Wgt Acc: 92.950%
	I - Batch: 150 | Loss: 0.263 | Acc: 89.708% | Wgt Acc: 92.860%
	I - Batch: 200 | Loss: 0.268 | Acc: 89.500% | Wgt Acc: 92.680%
I - num batch: 222
I - Train -- Loss: 0.270 | Acc: 89.569% | Wgt Acc: 92.694% | LR: 1.250000e-04 | Dur: 185.17s
I - Confusion Matrix: [row->prediction - col->label]
[[658.   0.   0.  13.  93.]
 [  0. 569.   4.   0.  53.]
 [  0.   1. 708.   5.  74.]
 [  9.   0.   3. 513.  51.]
 [ 30.   8.  19.   7. 729.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.226 | Acc: 60.355% | Wgt Acc: 57.642% | Dur: 15.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   4.  23.  22.]
 [  0.  37.   8.   4.  10.]
 [  0.   8.  26.   0.  15.]
 [  8.   6.  10.  49.   6.]
 [ 13.  24.  27.  10. 127.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.231 | Acc: 91.500% | Wgt Acc: 94.606%
	I - Batch: 100 | Loss: 0.226 | Acc: 91.188% | Wgt Acc: 94.172%
	I - Batch: 150 | Loss: 0.219 | Acc: 91.333% | Wgt Acc: 94.274%
	I - Batch: 200 | Loss: 0.221 | Acc: 91.281% | Wgt Acc: 94.230%
I - num batch: 208
I - Train -- Loss: 0.221 | Acc: 91.286% | Wgt Acc: 94.241% | LR: 1.250000e-04 | Dur: 168.42s
I - Confusion Matrix: [row->prediction - col->label]
[[659.   0.   0.   4.  75.]
 [  0. 571.   2.   2.  43.]
 [  1.   2. 723.   1.  62.]
 [  7.   2.   3. 524.  40.]
 [ 30.   3.   6.   7. 561.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.191 | Acc: 61.538% | Wgt Acc: 59.007% | Dur: 15.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.  10.   0.  19.  24.]
 [  0.  32.  11.   2.  10.]
 [  0.  13.  29.   2.  15.]
 [  8.   3.  11.  53.   5.]
 [  8.  20.  24.  10. 126.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.241 | Acc: 90.625% | Wgt Acc: 93.936%
	I - Batch: 100 | Loss: 0.233 | Acc: 91.500% | Wgt Acc: 94.514%
	I - Batch: 150 | Loss: 0.238 | Acc: 91.000% | Wgt Acc: 94.047%
	I - Batch: 200 | Loss: 0.243 | Acc: 90.750% | Wgt Acc: 93.870%
I - num batch: 222
I - Train -- Loss: 0.246 | Acc: 90.753% | Wgt Acc: 93.799% | LR: 1.250000e-04 | Dur: 185.43s
I - Confusion Matrix: [row->prediction - col->label]
[[664.   0.   0.   4.  91.]
 [  0. 572.   0.   3.  39.]
 [  0.   1. 720.   2.  72.]
 [  6.   2.   0. 519.  54.]
 [ 27.   3.  14.  10. 744.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.139 | Acc: 61.933% | Wgt Acc: 59.061% | Dur: 16.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   4.   5.  20.  17.]
 [  0.  34.   8.   3.   8.]
 [  0.  16.  33.   1.  19.]
 [  8.   2.   6.  50.   7.]
 [ 12.  22.  23.  12. 129.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.255 | Acc: 89.625% | Wgt Acc: 92.458%
	I - Batch: 100 | Loss: 0.254 | Acc: 90.062% | Wgt Acc: 92.972%
	I - Batch: 150 | Loss: 0.253 | Acc: 90.375% | Wgt Acc: 93.136%
	I - Batch: 200 | Loss: 0.245 | Acc: 90.688% | Wgt Acc: 93.389%
I - num batch: 222
I - Train -- Loss: 0.250 | Acc: 90.386% | Wgt Acc: 93.235% | LR: 1.250000e-04 | Dur: 180.21s
I - Confusion Matrix: [row->prediction - col->label]
[[658.   0.   0.  12.  76.]
 [  1. 569.   2.   1.  39.]
 [  1.   1. 718.   2.  76.]
 [  4.   1.   2. 511.  59.]
 [ 33.   7.  12.  12. 750.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.267 | Acc: 57.791% | Wgt Acc: 54.258% | Dur: 15.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   1.  22.  17.]
 [  0.  34.  12.  10.  17.]
 [  1.  15.  31.   2.  18.]
 [  4.   1.   5.  38.   3.]
 [ 18.  25.  26.  14. 125.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.250 | Acc: 90.500% | Wgt Acc: 93.532%
	I - Batch: 100 | Loss: 0.231 | Acc: 90.750% | Wgt Acc: 93.887%
	I - Batch: 150 | Loss: 0.232 | Acc: 91.083% | Wgt Acc: 93.973%
	I - Batch: 200 | Loss: 0.227 | Acc: 91.469% | Wgt Acc: 94.248%
I - num batch: 222
I - Train -- Loss: 0.225 | Acc: 91.514% | Wgt Acc: 94.242% | LR: 1.250000e-04 | Dur: 179.73s
I - Confusion Matrix: [row->prediction - col->label]
[[666.   0.   0.   6.  82.]
 [  0. 568.   0.   1.  32.]
 [  0.   3. 716.   2.  73.]
 [  5.   1.   3. 526.  43.]
 [ 26.   6.  15.   3. 770.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.163 | Acc: 65.089% | Wgt Acc: 62.828% | Dur: 15.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   2.   1.  13.  14.]
 [  0.  33.   5.   1.  15.]
 [  1.  18.  38.   1.   9.]
 [ 13.   5.   8.  60.  11.]
 [  6.  20.  23.  11. 131.]]

I - Local maximum validation set accuracy:  65.09

I - Validation set results: 
[14-1-2-2.24][50-3-4-1.08][124-2-2-2.27][127-0-0-4.72][443-2-2-3.12][567-0-0-3.74][573-1-1-0.69][615-0-3-2.55][695-1-2-3.38][722-3-3-3.60]
[826-0-0-3.36][878-0-3-2.59][1103-0-0-1.93][1212-3-3-1.92][1368-0-0-4.88][2181-2-3-1.50][2476-2-4-1.00][2721-2-2-2.47][2818-1-1--0.12][2886-2-1-2.25]
[3231-2-2-4.77][3333-2-3-2.00][3482-2-2-2.03][3536-3-0-1.29][3625-1-1-4.88][3909-0-0-3.95][4035-0-0-3.30][4140-0-0-4.30][4214-1-3-2.05][4346-1-4-0.39]
[4581-2-2-1.84][4708-3-2-1.39][4838-3-0-1.45][4845-1-4-0.01][4868-0-0-2.84][4939-0-4-1.45][4984-2-4-0.09][5078-1-4-1.86][5396-0-0-5.36][5479-1-1-2.81]
[5717-0-0-3.80][5843-1-1-1.17][5949-3-3-3.78][5987-2-4-3.05][6014-3-3-1.69][6033-3-4-0.65][6313-0-0-2.50][6421-3-3-2.42][6500-1-2--0.46][6583-3-3-1.49]
[6683-3-3-2.44][6825-2-1--0.24][6998-3-3-1.04][7049-3-3-2.28][7517-1-1-3.73][7521-1-3--0.20][7528-1-2-1.22][7949-1-2-2.48][8135-1-3-0.39][8185-3-0-5.94]
[8269-3-4-0.29][8273-3-3-1.62][8543-3-0-3.97][8666-1-1-2.03][8672-0-0-5.60][8903-1-1-2.24][9001-2-4-1.91][9036-2-2-3.00][9281-3-3-1.08][9300-2-2-1.18]
[9571-0-0-1.82][9617-1-4-2.05][9644-2-4-1.03][9705-2-4-2.01][9801-0-3-1.74][9803-3-3-0.81][9865-3-3-5.15][9896-2-4-2.26][10314-1-4-0.23][10337-3-3-1.47]
[10403-0-4-1.22][10653-2-4-1.20][10704-2-1-0.35][10719-1-1-1.10][10727-1-4-0.92][10836-0-0-8.71][10969-2-3-1.06][11042-0-0-2.38][11088-1-1-4.86][11322-0-0-2.20]
[11398-2-2-2.38][11499-0-3-1.45][11502-3-3-2.34][11512-3-3-2.36][11608-1-1-3.84][11610-0-0-2.85][11692-0-3-3.13][11905-0-0-2.64][11993-1-1-2.21][12002-2-3-1.53]
[12052-0-0-4.77][12201-0-0-3.53][12235-2-4-2.61][12320-1-4-2.55][12377-2-4-2.71][12398-2-3-1.50][12503-1-1-1.31][12617-0-2--0.03][12685-3-4-0.31][12738-2-4-1.25]
[12742-2-2-2.83][12823-0-0-4.09][13110-1-2-1.19][13240-3-0-5.97][13253-1-4-2.92][13273-0-0-7.32][13634-1-4-0.58][13763-2-2-1.50][13905-3-0-1.69][14060-2-1-1.19]
[14065-3-3-3.36][14147-3-3-2.80][14595-2-4-0.78][14687-2-2-3.53][14788-2-2-3.33][14869-1-1-1.89][14872-3-4-1.57][14877-1-1-3.11][14927-0-3-2.54][15066-0-0-5.57]
[15175-1-4-3.29][15178-2-3-2.50][15375-3-3-0.75][15389-3-3-4.08][15568-2-4-2.49][15675-3-3-4.42][15869-1-0-1.65][16207-3-4--0.30][16236-0-0--0.04][16302-3-3-0.46]
[16331-2-2-6.50][16381-0-3-1.82][16488-1-1-5.04][16495-0-0-1.37][16650-0-0-5.91][16719-1-4-1.33][16801-0-0-6.09][16828-0-0-1.35][17137-3-3-1.61][17245-1-4-2.02]
[17278-3-0-0.91][17282-0-0--0.40][17311-2-2-3.32][17336-2-2-0.77][17608-3-3-6.10][17627-0-0-4.59][17877-3-0-2.37][17924-1-2-0.90][17984-3-3-3.29][18211-0-3-2.55]
[18276-3-3-2.72][18287-1-4-0.41][18394-0-0-5.42][18428-0-0-4.34][18442-0-3-5.12][18478-3-0-4.56][18607-0-0-4.03][18616-0-0-1.03][18663-0-0-1.84][18718-0-0-3.17]
[18766-2-2-4.10][18824-2-4-1.59][18890-3-3-0.33][18930-3-4-3.44][18938-3-3-2.63][19817-1-2-2.10][19839-0-4-1.73][19930-3-3-2.03][19944-0-0-2.70][20036-2-2-3.00]
[20101-3-3-1.83][20474-1-2-0.32][20547-3-3-3.05][20929-2-2-3.61][21245-1-2-1.54][21257-3-3-0.20][21293-1-1-2.35][21316-1-2-0.33][21384-1-1-1.99][21448-1-2-2.73]
[21483-0-0-4.61][21487-2-2-2.05][21714-0-0-3.56][21943-3-4-0.97][21947-0-0-2.19][21948-0-0-6.60][21965-2-2-2.86][21998-1-1-1.96][22025-0-4-2.80][22228-3-3-3.11]
[22446-1-1-1.00][22494-3-3-3.43][22757-0-0-4.40][22811-3-3-2.43][22976-3-1-3.13][22985-3-3-4.26][23014-0-0-6.04][23112-1-1-1.45][23144-3-3-3.76][23168-2-3-0.70]
[23219-0-0-1.33][23363-3-3-3.45][23470-0-0-0.38][23486-2-4-0.18][23497-0-3-3.19][23516-0-0-4.00][23690-1-4-1.99][23921-2-4-1.57][23936-1-2-1.12][24040-3-4-1.42]
[24111-1-4-1.82][24182-0-0-5.54][24238-3-3-3.87][24290-2-4-2.19][24345-0-0-2.28][24364-1-2-1.94][24427-3-0-5.33][24477-2-4-2.64][24495-2-4-2.07][24893-2-2-1.27]
[25012-1-1-0.93][25121-2-1-2.68][25165-3-3-2.37][25183-0-0-3.81][25297-3-3-3.88][25398-0-0-3.45][25574-2-2-1.85][25644-1-1-3.99][25718-1-4-0.46][25774-2-2-0.93]
[26032-3-3-1.94][26051-3-3-5.16][26120-0-0-4.02][26321-1-1--0.04][26732-1-1-2.99][26784-3-3-5.45][26827-3-3-1.01][26833-0-3-3.27][26838-2-2--0.02][26860-1-4-1.49]
[26948-0-0-0.71][27049-3-0-1.48][27098-1-4-0.82][27526-0-0-2.06][27639-3-3-1.96][27698-3-3-2.59][27772-0-0-3.81][27890-1-1-0.45][28040-0-0-3.60][28503-2-2-2.85]
[28577-1-1-4.84][28959-0-0-5.73][29198-3-4-1.36][29777-0-0-7.22][29877-2-2-2.05][30035-1-1-2.90][30098-0-3-0.76][30326-1-1-4.90][30572-2-2-1.29][30716-0-4-2.51]
[30806-2-4-0.46][30906-1-1-3.94][31007-0-0-3.12][31181-3-3-1.70][31238-0-3-2.27][31347-0-0-5.41][31422-2-2-1.24][31429-3-3-0.58][31431-0-0-1.75][31432-1-1-1.86]
[31477-0-0-3.22][31524-1-2--0.10][31597-1-1-1.03][31619-1-0-2.54][31701-0-0-3.42][31755-0-0-4.63][31854-3-3-2.17][32074-1-3-0.32][32078-3-3-4.35][32111-1-1-1.00]
[32127-1-2-0.38][32140-3-3-3.41][32263-2-4-0.86][32365-0-0-4.92][32411-2-3-5.71][32429-3-3-2.58][32473-3-3-3.04][32574-3-3-1.96][32584-0-0-2.66][32622-0-4-0.91]
[32858-3-3-2.02][32969-3-0-3.41][33016-2-2-1.63][33031-1-3-0.38][33035-2-2-2.65][33133-2-2-3.62][33173-2-2--0.01][33175-3-4-1.48][33306-3-3-0.45][33309-2-2--0.40]
[33474-0-0-1.85][33478-2-0-0.04][33618-1-4-1.09][33712-0-0-2.20][33782-2-4-2.68][33914-3-3-2.86][34076-3-0-2.54][34112-2-2-0.76][34138-2-2-0.64][34239-1-4-0.81]
[34364-2-2-3.53][34617-1-2-1.43][34751-3-3-3.39][34783-2-4-1.34][35015-3-3-1.44][35018-1-2-2.95][35288-2-2-0.16][0-4-4-2.28][1-4-4-1.69][2-4-4-1.65]
[3-4-1-1.46][4-4-3-0.42][5-4-1-0.01][6-4-4-3.52][7-4-4-3.47][8-4-4-0.67][9-4-4-1.20][10-4-4-3.90][11-4-4-1.72][12-4-4-0.74]
[14-4-1-0.68][15-4-3-3.37][16-4-4-1.08][17-4-4-1.14][18-4-4-2.13][19-4-3-1.18][20-4-4-0.89][21-4-1-0.95][22-4-4-2.25][23-4-4-1.88]
[24-4-4-3.99][25-4-4-0.82][26-4-3-0.02][27-4-2-3.58][28-4-4-1.79][29-4-1-1.02][30-4-4-0.27][31-4-4-1.46][32-4-4-3.90][33-4-4-0.44]
[34-4-4-1.37][35-4-4-2.48][37-4-4-1.26][39-4-0-1.06][40-4-4-1.97][41-4-4-1.24][42-4-4-2.47][43-4-4-0.92][45-4-3-0.21][46-4-4-3.94]
[47-4-4-2.78][48-4-1-0.83][51-4-4-2.88][52-4-4-2.78][53-4-4-1.26][54-4-4-1.51][55-4-4-2.07][56-4-4-1.07][57-4-0-1.32][58-4-2-1.58]
[59-4-0-3.95][60-4-4-2.09][61-4-4-3.45][62-4-3-0.34][63-4-2-1.42][64-4-4-1.70][65-4-4-2.80][66-4-4-1.37][67-4-4-1.68][68-4-1-0.88]
[69-4-0-0.70][70-4-4-2.78][72-4-4-1.63][73-4-1-1.71][74-4-2-1.87][75-4-4-0.30][77-4-1-1.26][78-4-4--0.28][79-4-4-2.28][80-4-4-1.60]
[81-4-4-3.28][82-4-4-0.52][83-4-4-0.53][84-4-4-1.35][85-4-4-3.86][86-4-4-3.72][87-4-4-1.63][88-4-4-3.26][89-4-0-2.54][90-4-4-1.09]
[91-4-4-1.87][92-4-4-1.06][93-4-0-0.14][94-4-4-1.98][95-4-4-1.16][96-4-4-2.83][97-4-4-2.92][98-4-2-3.11][99-4-4-1.66][100-4-4-3.20]
[101-4-4-3.62][102-4-4-1.36][103-4-0-0.78][104-4-4-3.23][105-4-1-1.45][106-4-4-2.72][107-4-4-2.94][108-4-4-2.49][109-4-4--0.11][110-4-4-1.79]
[111-4-0-2.86][112-4-4-1.39][113-4-3-1.42][114-4-3-1.35][115-4-4-1.52][116-4-4-1.89][117-4-4-3.35][119-4-4-1.59][121-4-4-1.65][122-4-4-1.17]
[124-4-4-1.02][125-4-4-2.07][126-4-4-3.66][127-4-1-2.23][128-4-0-2.38][129-4-1-1.48][130-4-4-1.33][131-4-3-0.09][132-4-4-0.72][133-4-4-3.90]
[135-4-4-2.33][136-4-4-1.50][137-4-1-1.05][138-4-4-2.38][139-4-4-2.49][140-4-4-1.68][141-4-3-1.12][142-4-4-2.31][143-4-4-3.29][144-4-4-3.78]
[145-4-1-3.39][148-4-0-5.80][149-4-4-2.53][150-4-4-1.14][151-4-4-1.81][152-4-4-0.29][153-4-4-1.91][154-4-4-3.21][155-4-4-3.19][156-4-0-0.44]
[157-4-0-1.45][158-4-4-0.83][160-4-1-0.48][161-4-2-3.00][162-4-4-1.55][164-4-4-1.78][165-4-4-1.76][167-4-4-1.71][168-4-4-1.21][170-4-0-3.15]
[171-4-4-2.91][172-4-4-1.80][173-4-4-2.26][174-4-4-2.25][175-4-4-3.17][177-4-0-2.35][178-4-4-1.30][179-4-4-1.15][180-4-4-1.46][181-4-3-1.75]
[182-4-2-1.18][183-4-4-2.44][184-4-2-0.83][186-4-4-1.73][187-4-4-0.87][188-4-4-2.23][189-4-4-1.57][190-4-4-1.29][191-4-4-3.04][192-4-4-0.91]
[193-4-2-3.15][194-4-4-0.10][195-4-4-1.78][196-4-4-1.46][197-4-4-2.38][198-4-4-3.21][199-4-4-1.94]
---------------------------
I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.201 | Acc: 93.625% | Wgt Acc: 95.651%
	I - Batch: 100 | Loss: 0.200 | Acc: 93.625% | Wgt Acc: 95.920%
	I - Batch: 150 | Loss: 0.206 | Acc: 92.833% | Wgt Acc: 95.237%
	I - Batch: 200 | Loss: 0.211 | Acc: 92.469% | Wgt Acc: 94.945%
I - num batch: 222
I - Train -- Loss: 0.213 | Acc: 92.416% | Wgt Acc: 94.859% | LR: 1.250000e-04 | Dur: 188.77s
I - Confusion Matrix: [row->prediction - col->label]
[[666.   0.   0.   5.  77.]
 [  0. 575.   2.   1.  39.]
 [  0.   0. 719.   1.  59.]
 [  4.   0.   1. 523.  30.]
 [ 27.   3.  12.   8. 795.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.178 | Acc: 59.566% | Wgt Acc: 54.258% | Dur: 22.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   1.   4.  22.  13.]
 [  0.  26.   5.   3.  10.]
 [  0.  20.  27.   2.  13.]
 [  6.   2.   9.  42.   3.]
 [ 16.  29.  30.  17. 141.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.205 | Acc: 92.500% | Wgt Acc: 95.289%
	I - Batch: 100 | Loss: 0.219 | Acc: 91.562% | Wgt Acc: 94.314%
	I - Batch: 150 | Loss: 0.214 | Acc: 91.875% | Wgt Acc: 94.422%
	I - Batch: 200 | Loss: 0.214 | Acc: 92.000% | Wgt Acc: 94.575%
I - num batch: 222
I - Train -- Loss: 0.217 | Acc: 91.824% | Wgt Acc: 94.475% | LR: 1.250000e-04 | Dur: 183.87s
I - Confusion Matrix: [row->prediction - col->label]
[[666.   0.   0.   4.  81.]
 [  0. 573.   1.   1.  39.]
 [  1.   1. 719.   3.  60.]
 [  5.   1.   2. 522.  43.]
 [ 25.   3.  12.   8. 777.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.189 | Acc: 61.341% | Wgt Acc: 58.788% | Dur: 16.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   3.  16.  23.]
 [  0.  33.  12.   3.   7.]
 [  0.  14.  25.   0.  12.]
 [ 12.   5.   7.  58.   9.]
 [ 10.  21.  28.   9. 129.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.216 | Acc: 91.500% | Wgt Acc: 94.341%
	I - Batch: 100 | Loss: 0.203 | Acc: 92.188% | Wgt Acc: 94.920%
	I - Batch: 150 | Loss: 0.208 | Acc: 92.292% | Wgt Acc: 94.914%
	I - Batch: 200 | Loss: 0.209 | Acc: 92.094% | Wgt Acc: 94.682%
I - num batch: 222
I - Train -- Loss: 0.211 | Acc: 92.162% | Wgt Acc: 94.768% | LR: 1.250000e-04 | Dur: 189.25s
I - Confusion Matrix: [row->prediction - col->label]
[[668.   0.   0.   3.  87.]
 [  0. 570.   1.   0.  43.]
 [  1.   0. 723.   2.  61.]
 [  4.   1.   1. 526.  27.]
 [ 24.   7.   9.   7. 782.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.206 | Acc: 61.341% | Wgt Acc: 57.424% | Dur: 21.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   1.   1.  15.   8.]
 [  0.  33.  10.   2.   8.]
 [  1.  17.  28.   2.  20.]
 [ 15.   4.  11.  53.   5.]
 [ 14.  23.  25.  14. 139.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.209 | Acc: 91.750% | Wgt Acc: 94.458%
	I - Batch: 100 | Loss: 0.211 | Acc: 91.375% | Wgt Acc: 94.228%
	I - Batch: 150 | Loss: 0.215 | Acc: 91.167% | Wgt Acc: 94.063%
	I - Batch: 200 | Loss: 0.215 | Acc: 91.062% | Wgt Acc: 93.959%
I - num batch: 222
I - Train -- Loss: 0.217 | Acc: 91.063% | Wgt Acc: 93.919% | LR: 1.250000e-04 | Dur: 182.79s
I - Confusion Matrix: [row->prediction - col->label]
[[662.   0.   0.   1.  82.]
 [  1. 571.   3.   0.  43.]
 [  1.   0. 710.   2.  66.]
 [  4.   2.   2. 526.  48.]
 [ 29.   5.  19.   9. 761.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.182 | Acc: 60.947% | Wgt Acc: 58.406% | Dur: 16.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   3.  16.  19.]
 [  0.  32.   6.   1.  11.]
 [  0.  16.  28.   3.  14.]
 [ 13.   6.  12.  58.   8.]
 [ 12.  22.  26.   8. 128.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.176 | Acc: 93.250% | Wgt Acc: 95.764%
	I - Batch: 100 | Loss: 0.175 | Acc: 93.375% | Wgt Acc: 95.851%
	I - Batch: 150 | Loss: 0.182 | Acc: 93.250% | Wgt Acc: 95.635%
	I - Batch: 200 | Loss: 0.192 | Acc: 92.594% | Wgt Acc: 95.094%
I - num batch: 222
I - Train -- Loss: 0.195 | Acc: 92.529% | Wgt Acc: 95.017% | LR: 1.250000e-04 | Dur: 188.95s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   0.   0.   3.  60.]
 [  0. 570.   4.   1.  52.]
 [  1.   2. 719.   0.  58.]
 [  4.   0.   1. 525.  39.]
 [ 15.   6.  10.   9. 791.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.197 | Acc: 62.919% | Wgt Acc: 59.334% | Dur: 21.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   1.   2.  14.   9.]
 [  0.  35.   8.   4.  10.]
 [  1.  13.  31.   0.  19.]
 [ 10.   5.   4.  52.   4.]
 [ 14.  24.  30.  16. 138.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.189 | Acc: 92.375% | Wgt Acc: 94.258%
	I - Batch: 100 | Loss: 0.199 | Acc: 92.000% | Wgt Acc: 94.382%
	I - Batch: 150 | Loss: 0.198 | Acc: 92.250% | Wgt Acc: 94.667%
	I - Batch: 200 | Loss: 0.198 | Acc: 92.219% | Wgt Acc: 94.705%
I - num batch: 222
I - Train -- Loss: 0.197 | Acc: 92.275% | Wgt Acc: 94.738% | LR: 1.250000e-04 | Dur: 181.85s
I - Confusion Matrix: [row->prediction - col->label]
[[663.   0.   0.   4.  71.]
 [  0. 570.   1.   0.  35.]
 [  0.   0. 719.   1.  58.]
 [  2.   1.   4. 528.  43.]
 [ 32.   7.  10.   5. 793.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.204 | Acc: 61.538% | Wgt Acc: 59.498% | Dur: 15.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   3.  14.  19.]
 [  0.  37.   8.   2.  13.]
 [  1.  11.  26.   1.  10.]
 [  8.   4.   7.  57.  12.]
 [ 13.  22.  31.  12. 126.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.172 | Acc: 93.750% | Wgt Acc: 95.613%
	I - Batch: 100 | Loss: 0.171 | Acc: 93.875% | Wgt Acc: 95.823%
	I - Batch: 150 | Loss: 0.182 | Acc: 93.000% | Wgt Acc: 95.349%
	I - Batch: 200 | Loss: 0.190 | Acc: 92.844% | Wgt Acc: 95.185%
I - num batch: 222
I - Train -- Loss: 0.188 | Acc: 92.980% | Wgt Acc: 95.235% | LR: 1.250000e-04 | Dur: 190.71s
I - Confusion Matrix: [row->prediction - col->label]
[[669.   0.   1.   4.  71.]
 [  0. 570.   0.   2.  31.]
 [  0.   2. 724.   1.  48.]
 [  4.   0.   0. 526.  41.]
 [ 24.   6.   9.   5. 809.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.308 | Acc: 62.525% | Wgt Acc: 57.751% | Dur: 17.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   6.   4.  26.  21.]
 [  0.  34.   9.   1.   3.]
 [  0.  10.  22.   0.   8.]
 [  9.   6.   9.  46.   3.]
 [  9.  22.  31.  13. 145.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.209 | Acc: 92.125% | Wgt Acc: 94.565%
	I - Batch: 100 | Loss: 0.191 | Acc: 93.000% | Wgt Acc: 95.360%
	I - Batch: 150 | Loss: 0.189 | Acc: 92.667% | Wgt Acc: 95.104%
	I - Batch: 200 | Loss: 0.191 | Acc: 92.656% | Wgt Acc: 95.046%
I - num batch: 222
I - Train -- Loss: 0.190 | Acc: 92.783% | Wgt Acc: 95.152% | LR: 1.250000e-04 | Dur: 180.14s
I - Confusion Matrix: [row->prediction - col->label]
[[668.   0.   0.   2.  74.]
 [  0. 576.   0.   0.  39.]
 [  0.   0. 722.   1.  53.]
 [  4.   1.   1. 523.  32.]
 [ 25.   1.  11.  12. 802.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.212 | Acc: 61.933% | Wgt Acc: 58.242% | Dur: 15.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   1.  15.  15.]
 [  0.  29.   7.   2.   8.]
 [  0.  18.  32.   3.  15.]
 [ 13.   4.   7.  56.   5.]
 [ 15.  25.  28.  10. 137.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.158 | Acc: 93.750% | Wgt Acc: 96.018%
	I - Batch: 100 | Loss: 0.184 | Acc: 92.938% | Wgt Acc: 95.157%
	I - Batch: 150 | Loss: 0.183 | Acc: 92.917% | Wgt Acc: 95.230%
	I - Batch: 200 | Loss: 0.181 | Acc: 93.031% | Wgt Acc: 95.279%
I - num batch: 222
I - Train -- Loss: 0.184 | Acc: 92.895% | Wgt Acc: 95.197% | LR: 1.250000e-04 | Dur: 189.20s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   0.   0.   5.  67.]
 [  0. 574.   1.   0.  23.]
 [  0.   1. 724.   2.  54.]
 [  4.   0.   0. 521.  51.]
 [ 22.   3.   9.  10. 805.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.139 | Acc: 64.694% | Wgt Acc: 60.426% | Dur: 20.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   2.  14.   8.]
 [  0.  32.  10.   3.  10.]
 [  0.  13.  34.   1.  12.]
 [  9.   3.   7.  53.   5.]
 [ 15.  28.  22.  15. 145.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.189 | Acc: 93.125% | Wgt Acc: 95.248%
	I - Batch: 100 | Loss: 0.181 | Acc: 93.062% | Wgt Acc: 95.321%
	I - Batch: 150 | Loss: 0.181 | Acc: 93.083% | Wgt Acc: 95.314%
	I - Batch: 200 | Loss: 0.175 | Acc: 93.500% | Wgt Acc: 95.618%
I - num batch: 222
I - Train -- Loss: 0.176 | Acc: 93.431% | Wgt Acc: 95.505% | LR: 1.250000e-04 | Dur: 180.77s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   0.   0.   2.  66.]
 [  1. 572.   0.   1.  38.]
 [  0.   0. 725.   0.  47.]
 [  4.   2.   1. 524.  26.]
 [ 22.   4.   8.  11. 823.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.182 | Acc: 62.722% | Wgt Acc: 57.424% | Dur: 15.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   1.   0.  18.  10.]
 [  0.  29.   9.   2.   9.]
 [  1.  16.  30.   3.  12.]
 [  3.   2.   8.  45.   2.]
 [ 17.  30.  28.  18. 147.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.177 | Acc: 92.625% | Wgt Acc: 95.618%
	I - Batch: 100 | Loss: 0.180 | Acc: 92.938% | Wgt Acc: 95.616%
	I - Batch: 150 | Loss: 0.179 | Acc: 92.750% | Wgt Acc: 95.433%
	I - Batch: 200 | Loss: 0.182 | Acc: 92.875% | Wgt Acc: 95.393%
I - num batch: 222
I - Train -- Loss: 0.182 | Acc: 92.839% | Wgt Acc: 95.400% | LR: 1.250000e-04 | Dur: 181.72s
I - Confusion Matrix: [row->prediction - col->label]
[[676.   0.   0.   5.  71.]
 [  0. 574.   0.   0.  36.]
 [  0.   0. 727.   0.  53.]
 [  2.   0.   2. 526.  50.]
 [ 19.   4.   5.   7. 790.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.203 | Acc: 60.355% | Wgt Acc: 55.731% | Dur: 16.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   2.  16.   9.]
 [  0.  31.   5.   2.  11.]
 [  1.  12.  27.   3.  16.]
 [  8.   2.   6.  46.   4.]
 [ 17.  30.  35.  19. 140.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.163 | Acc: 93.875% | Wgt Acc: 96.192%
	I - Batch: 100 | Loss: 0.168 | Acc: 93.312% | Wgt Acc: 95.788%
	I - Batch: 150 | Loss: 0.167 | Acc: 93.542% | Wgt Acc: 95.855%
	I - Batch: 200 | Loss: 0.167 | Acc: 93.562% | Wgt Acc: 95.795%
I - num batch: 222
I - Train -- Loss: 0.167 | Acc: 93.544% | Wgt Acc: 95.693% | LR: 1.250000e-04 | Dur: 182.61s
I - Confusion Matrix: [row->prediction - col->label]
[[669.   0.   0.   1.  65.]
 [  0. 574.   0.   1.  36.]
 [  0.   0. 724.   1.  46.]
 [  1.   0.   1. 529.  31.]
 [ 27.   4.   9.   6. 822.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.285 | Acc: 59.961% | Wgt Acc: 55.240% | Dur: 17.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   2.   1.  20.  22.]
 [  0.  26.   9.   1.   6.]
 [  0.  13.  26.   1.   7.]
 [ 10.   8.  10.  48.   6.]
 [ 13.  29.  29.  16. 139.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.167 | Acc: 92.750% | Wgt Acc: 95.205%
	I - Batch: 100 | Loss: 0.162 | Acc: 92.750% | Wgt Acc: 95.227%
	I - Batch: 150 | Loss: 0.166 | Acc: 92.667% | Wgt Acc: 95.272%
	I - Batch: 200 | Loss: 0.172 | Acc: 92.625% | Wgt Acc: 95.194%
I - num batch: 222
I - Train -- Loss: 0.175 | Acc: 92.585% | Wgt Acc: 95.159% | LR: 1.250000e-04 | Dur: 182.74s
I - Confusion Matrix: [row->prediction - col->label]
[[668.   0.   0.   2.  79.]
 [  0. 574.   1.   2.  35.]
 [  0.   1. 725.   3.  59.]
 [  4.   0.   0. 528.  38.]
 [ 25.   3.   8.   3. 789.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.274 | Acc: 62.525% | Wgt Acc: 58.515% | Dur: 15.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   0.  15.  17.]
 [  1.  34.   8.   3.  10.]
 [  1.  10.  26.   3.   8.]
 [  7.   1.   7.  50.   5.]
 [ 12.  30.  34.  15. 140.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.183 | Acc: 92.750% | Wgt Acc: 94.557%
	I - Batch: 100 | Loss: 0.178 | Acc: 93.125% | Wgt Acc: 95.166%
	I - Batch: 150 | Loss: 0.171 | Acc: 93.667% | Wgt Acc: 95.636%
	I - Batch: 200 | Loss: 0.165 | Acc: 93.781% | Wgt Acc: 95.883%
I - num batch: 222
I - Train -- Loss: 0.163 | Acc: 93.882% | Wgt Acc: 95.949% | LR: 1.250000e-04 | Dur: 193.10s
I - Confusion Matrix: [row->prediction - col->label]
[[674.   0.   0.   3.  56.]
 [  0. 570.   0.   0.  39.]
 [  0.   2. 727.   0.  47.]
 [  3.   1.   1. 531.  30.]
 [ 20.   5.   6.   4. 828.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.196 | Acc: 62.919% | Wgt Acc: 56.878% | Dur: 19.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   1.   0.  17.   9.]
 [  0.  27.   5.   0.   6.]
 [  1.  11.  25.   1.   5.]
 [ 13.   1.   8.  53.   3.]
 [ 17.  38.  37.  15. 157.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.150 | Acc: 94.500% | Wgt Acc: 96.206%
	I - Batch: 100 | Loss: 0.159 | Acc: 93.625% | Wgt Acc: 95.623%
	I - Batch: 150 | Loss: 0.159 | Acc: 94.125% | Wgt Acc: 95.982%
	I - Batch: 200 | Loss: 0.167 | Acc: 93.875% | Wgt Acc: 95.789%
I - num batch: 222
I - Train -- Loss: 0.167 | Acc: 93.882% | Wgt Acc: 95.813% | LR: 1.250000e-04 | Dur: 245.26s
I - Confusion Matrix: [row->prediction - col->label]
[[672.   0.   0.   1.  53.]
 [  0. 573.   0.   2.  31.]
 [  0.   0. 723.   1.  41.]
 [  0.   0.   0. 526.  39.]
 [ 25.   5.  11.   8. 836.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.250 | Acc: 66.075% | Wgt Acc: 62.172% | Dur: 28.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   1.  11.  12.]
 [  0.  30.   8.   1.   6.]
 [  0.  14.  31.   2.   9.]
 [ 10.   3.   8.  61.   7.]
 [ 11.  27.  27.  11. 146.]]

I - Local maximum validation set accuracy:  66.07

I - Validation set results: 
[14-1-2-3.07][50-3-4-0.03][124-2-2-2.15][127-0-0-6.17][443-2-2-1.60][567-0-0-2.73][573-1-1-0.30][615-0-0-2.79][695-1-2-4.09][722-3-3-4.01]
[826-0-0-1.27][878-0-0-2.84][1103-0-0-2.30][1212-3-4-0.69][1368-0-0-6.93][2181-2-3-2.36][2476-2-2-1.20][2721-2-4-2.40][2818-1-4--0.55][2886-2-4-1.75]
[3231-2-2-5.12][3333-2-1-1.66][3482-2-4-2.60][3536-3-0-1.19][3625-1-1-4.66][3909-0-0-2.36][4035-0-0-4.53][4140-0-0-2.11][4214-1-3-3.15][4346-1-0-1.64]
[4581-2-2-2.36][4708-3-4--0.61][4838-3-4-1.39][4845-1-4-0.06][4868-0-0-3.77][4939-0-4-2.27][4984-2-4-1.12][5078-1-4-1.87][5396-0-0-8.06][5479-1-1-4.99]
[5717-0-0-5.71][5843-1-1-0.88][5949-3-3-3.95][5987-2-4-3.03][6014-3-3-3.39][6033-3-3-1.46][6313-0-3-2.42][6421-3-2-1.09][6500-1-2-0.52][6583-3-3-1.86]
[6683-3-3-2.27][6825-2-1-1.44][6998-3-0-1.34][7049-3-3-1.31][7517-1-1-4.97][7521-1-0--0.17][7528-1-3-0.77][7949-1-2-2.90][8135-1-4-0.78][8185-3-0-4.65]
[8269-3-1-0.65][8273-3-3-1.83][8543-3-3-4.57][8666-1-4-0.27][8672-0-0-3.08][8903-1-1-2.29][9001-2-1-4.45][9036-2-4-2.38][9281-3-3-2.54][9300-2-2-3.02]
[9571-0-0-2.74][9617-1-4-1.90][9644-2-4-1.18][9705-2-4-2.20][9801-0-0-2.01][9803-3-3-1.93][9865-3-3-5.19][9896-2-4-3.67][10314-1-4-0.73][10337-3-3-4.10]
[10403-0-4-0.91][10653-2-4-1.37][10704-2-1-0.17][10719-1-1-0.94][10727-1-4-2.99][10836-0-0-9.77][10969-2-3-1.20][11042-0-0-2.51][11088-1-1-2.69][11322-0-0-1.44]
[11398-2-2-4.98][11499-0-0-1.89][11502-3-3-1.67][11512-3-3-1.20][11608-1-1-1.76][11610-0-0-1.45][11692-0-3-4.51][11905-0-0-1.75][11993-1-1-0.81][12002-2-1--0.06]
[12052-0-0-3.97][12201-0-3-4.37][12235-2-4-2.34][12320-1-4-3.46][12377-2-4-3.30][12398-2-3-3.00][12503-1-4--0.92][12617-0-3-0.81][12685-3-3-0.59][12738-2-4-1.44]
[12742-2-2-3.70][12823-0-0-4.48][13110-1-2-1.59][13240-3-0-5.43][13253-1-4-3.05][13273-0-0-8.79][13634-1-4-1.33][13763-2-4-0.22][13905-3-0-0.44][14060-2-1-2.22]
[14065-3-3-4.45][14147-3-3-1.97][14595-2-4-1.82][14687-2-2-3.73][14788-2-2-3.46][14869-1-1-1.67][14872-3-4-2.09][14877-1-1-1.70][14927-0-3-2.45][15066-0-0-5.65]
[15175-1-4-3.15][15178-2-3-3.29][15375-3-3-2.49][15389-3-3-3.98][15568-2-4-2.37][15675-3-3-3.49][15869-1-0-1.23][16207-3-3-0.79][16236-0-0-0.81][16302-3-3-2.48]
[16331-2-2-6.82][16381-0-3-2.93][16488-1-1-4.52][16495-0-0-1.84][16650-0-0-5.65][16719-1-4-1.04][16801-0-0-5.37][16828-0-0-2.41][17137-3-3-0.27][17245-1-4-2.51]
[17278-3-0-1.42][17282-0-0-1.13][17311-2-2-3.79][17336-2-2-2.46][17608-3-3-5.18][17627-0-0-3.36][17877-3-0-1.71][17924-1-2-0.67][17984-3-3-3.04][18211-0-0-2.28]
[18276-3-3-2.66][18287-1-4-0.60][18394-0-0-5.75][18428-0-0-4.65][18442-0-3-5.18][18478-3-0-4.42][18607-0-0-5.04][18616-0-4-0.96][18663-0-0-3.31][18718-0-0-5.19]
[18766-2-2-3.28][18824-2-4-1.69][18890-3-3-1.03][18930-3-4-4.89][18938-3-3-1.81][19817-1-4-1.38][19839-0-4-2.50][19930-3-3-4.18][19944-0-4-2.66][20036-2-2-3.33]
[20101-3-3-2.68][20474-1-2--0.20][20547-3-3-2.22][20929-2-2-5.36][21245-1-2-2.61][21257-3-3-0.39][21293-1-1-3.89][21316-1-1-1.14][21384-1-2-0.57][21448-1-2-1.16]
[21483-0-0-5.73][21487-2-2-1.77][21714-0-0-4.56][21943-3-4-1.03][21947-0-0-3.24][21948-0-0-7.22][21965-2-2-3.62][21998-1-1-1.61][22025-0-4-2.72][22228-3-3-3.74]
[22446-1-1-0.73][22494-3-3-3.74][22757-0-0-5.52][22811-3-3-4.49][22976-3-3-1.02][22985-3-3-4.40][23014-0-0-6.21][23112-1-1-0.63][23144-3-3-5.21][23168-2-3-0.97]
[23219-0-0-0.97][23363-3-3-2.08][23470-0-4-1.10][23486-2-2-1.02][23497-0-3-5.35][23516-0-0-4.50][23690-1-4-1.30][23921-2-4-1.52][23936-1-2-1.50][24040-3-4-0.96]
[24111-1-4-2.08][24182-0-0-6.86][24238-3-3-3.86][24290-2-4-1.73][24345-0-4-0.83][24364-1-4-0.83][24427-3-0-1.88][24477-2-4-3.12][24495-2-4-2.01][24893-2-2-1.81]
[25012-1-2-1.34][25121-2-4-3.03][25165-3-3-3.41][25183-0-0-2.43][25297-3-3-4.64][25398-0-0-3.27][25574-2-2-0.75][25644-1-1-4.77][25718-1-4-0.23][25774-2-4-1.61]
[26032-3-3-1.38][26051-3-3-6.27][26120-0-0-3.18][26321-1-1--0.02][26732-1-1-1.61][26784-3-3-6.54][26827-3-3-1.82][26833-0-3-3.61][26838-2-1-0.81][26860-1-4-0.59]
[26948-0-0-3.80][27049-3-2-0.85][27098-1-4-1.11][27526-0-0-5.06][27639-3-3-2.75][27698-3-3-2.13][27772-0-0-5.48][27890-1-1-0.94][28040-0-0-3.14][28503-2-2-3.37]
[28577-1-1-4.10][28959-0-0-5.06][29198-3-4-0.94][29777-0-0-7.76][29877-2-2-2.22][30035-1-1-1.94][30098-0-3-1.13][30326-1-1-5.38][30572-2-3-1.24][30716-0-4-2.98]
[30806-2-4-0.60][30906-1-1-3.51][31007-0-0-0.28][31181-3-3-3.10][31238-0-0-1.52][31347-0-0-6.32][31422-2-2-2.80][31429-3-3-0.61][31431-0-0-6.51][31432-1-1-2.42]
[31477-0-0-4.39][31524-1-1-0.96][31597-1-4-0.28][31619-1-0-2.14][31701-0-0-1.59][31755-0-0-7.81][31854-3-3-1.71][32074-1-3-0.56][32078-3-3-3.36][32111-1-1-3.52]
[32127-1-4-1.61][32140-3-3-3.98][32263-2-4-0.45][32365-0-0-4.40][32411-2-3-4.98][32429-3-3-4.24][32473-3-3-4.01][32574-3-0-3.64][32584-0-4-0.52][32622-0-4-1.08]
[32858-3-3-3.21][32969-3-3-3.15][33016-2-2-3.26][33031-1-1-0.89][33035-2-2-2.32][33133-2-2-4.44][33173-2-2-0.50][33175-3-4-1.14][33306-3-4--0.18][33309-2-2--0.01]
[33474-0-0-0.40][33478-2-0-0.59][33618-1-4-1.83][33712-0-0-2.10][33782-2-4-2.87][33914-3-3-3.20][34076-3-0-2.47][34112-2-1-1.86][34138-2-3-0.94][34239-1-2-0.41]
[34364-2-2-2.89][34617-1-4-1.16][34751-3-3-3.78][34783-2-2-1.91][35015-3-3-2.07][35018-1-2-2.19][35288-2-4-0.14][0-4-4-1.51][1-4-0-1.65][2-4-4-2.27]
[3-4-4-0.69][4-4-4-2.46][5-4-4-0.75][6-4-4-2.85][7-4-4-4.49][8-4-4-1.06][9-4-4-1.42][10-4-4-4.64][11-4-4-3.16][12-4-4-0.31]
[14-4-4-0.17][15-4-3-2.42][16-4-4-1.99][17-4-4-1.80][18-4-4-3.84][19-4-3-2.07][20-4-0-1.14][21-4-4-0.38][22-4-4-2.28][23-4-4-1.95]
[24-4-4-4.42][25-4-4-1.06][26-4-4-1.06][27-4-2-3.07][28-4-4-2.48][29-4-4-0.78][30-4-0-3.00][31-4-4-1.24][32-4-4-3.03][33-4-4-0.76]
[34-4-4-1.85][35-4-4-1.00][37-4-4-0.57][39-4-4-0.66][40-4-4-1.30][41-4-0-3.91][42-4-4-2.64][43-4-4-1.33][45-4-3-1.38][46-4-4-4.51]
[47-4-4-2.21][48-4-1-2.25][51-4-4-4.01][52-4-4-2.60][53-4-4-0.74][54-4-4-2.56][55-4-4-1.98][56-4-4-0.85][57-4-0-2.23][58-4-2-1.31]
[59-4-0-4.04][60-4-4-1.77][61-4-4-2.67][62-4-4-0.54][63-4-2-1.78][64-4-2-2.47][65-4-4-4.19][66-4-4-1.07][67-4-4-1.76][68-4-1-0.78]
[69-4-4--0.18][70-4-4-2.57][72-4-4-3.15][73-4-1-2.39][74-4-4-2.28][75-4-4-0.38][77-4-4-4.17][78-4-4--0.26][79-4-4-3.15][80-4-4-2.42]
[81-4-4-3.32][82-4-4-0.72][83-4-4-0.96][84-4-4-2.82][85-4-4-4.11][86-4-4-3.79][87-4-0-2.25][88-4-4-3.43][89-4-3-0.14][90-4-4-1.04]
[91-4-4-2.58][92-4-4-0.91][93-4-4-0.95][94-4-4-1.49][95-4-4-0.93][96-4-4-2.83][97-4-4-4.09][98-4-2-3.95][99-4-4-1.52][100-4-4-3.86]
[101-4-4-4.05][102-4-4-3.10][103-4-4-0.28][104-4-4-3.53][105-4-4-1.25][106-4-4-2.74][107-4-4-3.92][108-4-4-2.44][109-4-4-0.72][110-4-4-1.90]
[111-4-0-2.94][112-4-4-1.95][113-4-4-0.98][114-4-3-2.27][115-4-4-1.45][116-4-4-2.22][117-4-4-3.82][119-4-4-1.89][121-4-4-1.62][122-4-4-0.77]
[124-4-4-1.19][125-4-4-2.75][126-4-4-4.28][127-4-1-2.13][128-4-4-1.60][129-4-2-1.74][130-4-4-1.70][131-4-3-0.83][132-4-4-1.06][133-4-0-3.70]
[135-4-4-3.23][136-4-1-0.44][137-4-4-0.95][138-4-4-3.31][139-4-4-3.99][140-4-4-1.47][141-4-0-2.44][142-4-4-1.80][143-4-4-2.93][144-4-4-3.11]
[145-4-1-3.97][148-4-0-5.63][149-4-4-2.55][150-4-4-1.66][151-4-4-2.28][152-4-4-1.45][153-4-4-1.94][154-4-4-4.29][155-4-4-4.02][156-4-0-0.77]
[157-4-4-1.30][158-4-4-1.57][160-4-4-1.71][161-4-2--0.03][162-4-4-1.99][164-4-4-1.88][165-4-4-1.90][167-4-4-1.85][168-4-4-1.70][170-4-4-2.22]
[171-4-4-3.36][172-4-4-3.65][173-4-4-4.57][174-4-4-1.27][175-4-4-3.47][177-4-4-3.17][178-4-4-1.27][179-4-4-2.09][180-4-4-1.62][181-4-4-1.05]
[182-4-3-0.86][183-4-4-2.17][184-4-2-2.41][186-4-4-0.82][187-4-4-0.44][188-4-4-0.99][189-4-4-2.26][190-4-4-0.53][191-4-4-3.12][192-4-4-4.23]
[193-4-2-3.51][194-4-4-0.19][195-4-4-1.31][196-4-4-1.15][197-4-4-2.12][198-4-4-3.42][199-4-4-2.79]
---------------------------
I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 94.250% | Wgt Acc: 96.137%
	I - Batch: 100 | Loss: 0.146 | Acc: 94.438% | Wgt Acc: 96.368%
	I - Batch: 150 | Loss: 0.149 | Acc: 94.458% | Wgt Acc: 96.410%
	I - Batch: 200 | Loss: 0.151 | Acc: 94.562% | Wgt Acc: 96.446%
I - num batch: 222
I - Train -- Loss: 0.150 | Acc: 94.559% | Wgt Acc: 96.512% | LR: 1.250000e-04 | Dur: 265.98s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   0.   0.   1.  54.]
 [  0. 577.   0.   1.  27.]
 [  0.   0. 724.   0.  45.]
 [  2.   0.   0. 531.  32.]
 [ 15.   1.  10.   5. 842.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.237 | Acc: 64.694% | Wgt Acc: 59.334% | Dur: 36.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   2.  13.   8
 [  0.  29.   3.   3.   3.]
 [  1.  15.  32.   4.  12.]
 [ 10.   4.   6.  52.   4.]
 [ 15.  28.  32.  14. 153.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.169 | Acc: 94.000% | Wgt Acc: 96.058%
	I - Batch: 100 | Loss: 0.156 | Acc: 94.312% | Wgt Acc: 96.449%
	I - Batch: 150 | Loss: 0.154 | Acc: 94.292% | Wgt Acc: 96.192%
I - num batch: 222
I - Train -- Loss: 0.155 | Acc: 94.108% | Wgt Acc: 96.174% | LR: 1.250000e-04 | Dur: 255.66s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   0.   1.   2.  78.]
 [  0. 575.   0.   0.  22.]
 [  0.   0. 726.   0.  43.]
 [  2.   0.   1. 528.  27.]
 [ 16.   3.   6.   8. 830.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.189 | Acc: 63.708% | Wgt Acc: 57.969% | Dur: 31.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   1.  16.   8.]
 [  0.  30.  10.   5.   8.]
 [  0.  16.  34.   3.  11.]
 [  9.   2.   7.  44.   1.]
 [ 16.  28.  23.  18. 152.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.151 | Acc: 94.125% | Wgt Acc: 96.436%
	I - Batch: 100 | Loss: 0.145 | Acc: 94.375% | Wgt Acc: 96.445%
	I - Batch: 150 | Loss: 0.146 | Acc: 94.417% | Wgt Acc: 96.429%
	I - Batch: 200 | Loss: 0.147 | Acc: 94.312% | Wgt Acc: 96.331%
I - num batch: 222
I - Train -- Loss: 0.150 | Acc: 94.164% | Wgt Acc: 96.189% | LR: 1.250000e-04 | Dur: 252.12s
I - Confusion Matrix: [row->prediction - col->label]
[[675.   0.   0.   3.  58.]
 [  0. 575.   0.   1.  34.]
 [  1.   0. 729.   2.  41.]
 [  1.   0.   0. 528.  34.]
 [ 20.   3.   5.   4. 833.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.218 | Acc: 62.722% | Wgt Acc: 57.424% | Dur: 32.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   1.   2.  11.   7.]
 [  0.  32.   8.   5.   8.]
 [  0.  14.  28.   4.  11.]
 [ 10.   1.   5.  46.   5.]
 [ 15.  30.  32.  20. 149.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.126 | Acc: 95.250% | Wgt Acc: 97.064%
                                                                  	I - Batch: 100 | Loss: 0.147 | Acc: 94.312% | Wgt Acc: 96.528%
	I - Batch: 150 | Loss: 0.140 | Acc: 94.667% | Wgt Acc: 96.759%
	I - Batch: 200 | Loss: 0.144 | Acc: 94.500% | Wgt Acc: 96.551%
I - num batch: 222
I - Train -- Loss: 0.146 | Acc: 94.333% | Wgt Acc: 96.407% | LR: 1.250000e-04 | Dur: 248.78s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   0.   0.   1.  62.]
 [  0. 575.   1.   1.  30.]
 [  0.   0. 725.   0.  41.]
 [  0.   0.   0. 533.  34.]
 [ 17.   3.   8.   3. 833.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.300 | Acc: 60.947% | Wgt Acc: 55.076% | Dur: 28.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   3.   3.  27.  17.]
 [  0.  28.   6.   2.   3.]
 [  0.  12.  22.   0.  10.]
 [  7.   1.   6.  43.   1.]
 [ 14.  34.  38.  14. 149.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 94.250% | Wgt Acc: 96.482%
	I - Batch: 100 | Loss: 0.156 | Acc: 93.750% | Wgt Acc: 95.934%
	I - Batch: 150 | Loss: 0.152 | Acc: 93.875% | Wgt Acc: 96.028%
	I - Batch: 200 | Loss: 0.149 | Acc: 94.250% | Wgt Acc: 96.228%
I - num batch: 222
I - Train -- Loss: 0.146 | Acc: 94.531% | Wgt Acc: 96.400% | LR: 1.250000e-04 | Dur: 259.21s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   0.   0.   3.  63.]
 [  0. 574.   0.   1.  24.]
 [  0.   0. 726.   0.  38.]
 [  2.   1.   0. 529.  30.]
 [ 16.   3.   8.   5. 845.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.232 | Acc: 63.708% | Wgt Acc: 59.061% | Dur: 23.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   1.   3.  17.  12.]
 [  0.  31.   7.   0.   6.]
 [  0.  15.  27.   0.  11.]
 [  9.   2.   9.  53.   4.]
 [ 14.  29.  29.  16. 147.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.126 | Acc: 95.125% | Wgt Acc: 96.882%
	I - Batch: 100 | Loss: 0.123 | Acc: 95.438% | Wgt Acc: 97.047%
	I - Batch: 150 | Loss: 0.135 | Acc: 94.875% | Wgt Acc: 96.610%
	I - Batch: 200 | Loss: 0.138 | Acc: 94.656% | Wgt Acc: 96.456%
I - num batch: 222
I - Train -- Loss: 0.140 | Acc: 94.474% | Wgt Acc: 96.347% | LR: 1.250000e-04 | Dur: 198.73s
I - Confusion Matrix: [row->prediction - col->label]
[[675.   0.   0.   0.  60.]
 [  0. 572.   0.   1.  23.]
 [  0.   1. 730.   2.  40.]
 [  1.   1.   0. 530.  33.]
 [ 21.   4.   4.   5. 844.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.232 | Acc: 62.919% | Wgt Acc: 57.369% | Dur: 17.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   2.   2.  15.   9.]
 [  0.  28.   9.   1.   7.]
 [  0.  14.  24.   1.   9.]
 [  8.   2.   7.  49.   4.]
 [ 13.  32.  33.  20. 151.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.145 | Acc: 94.125% | Wgt Acc: 96.178%
	I - Batch: 100 | Loss: 0.145 | Acc: 94.438% | Wgt Acc: 96.231%
	I - Batch: 150 | Loss: 0.148 | Acc: 94.375% | Wgt Acc: 96.084%
	I - Batch: 200 | Loss: 0.145 | Acc: 94.469% | Wgt Acc: 96.244%
I - num batch: 222
I - Train -- Loss: 0.149 | Acc: 94.361% | Wgt Acc: 96.152% | LR: 1.250000e-04 | Dur: 203.05s
I - Confusion Matrix: [row->prediction - col->label]
[[673.   0.   0.   1.  56.]
 [  0. 572.   0.   1.  23.]
 [  0.   0. 729.   0.  45.]
 [  3.   0.   2. 526.  29.]
 [ 21.   6.   3.  10. 847.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.301 | Acc: 61.736% | Wgt Acc: 55.349% | Dur: 19.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   3.   5.  29.  13.]
 [  0.  32.   4.   1.   6.]
 [  0.  10.  26.   1.   5.]
 [  5.   2.   7.  34.   4.]
 [ 14.  31.  33.  21. 152.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.151 | Acc: 93.625% | Wgt Acc: 95.567%
	I - Batch: 100 | Loss: 0.144 | Acc: 94.375% | Wgt Acc: 96.290%
	I - Batch: 150 | Loss: 0.155 | Acc: 94.000% | Wgt Acc: 96.013%
	I - Batch: 200 | Loss: 0.157 | Acc: 93.719% | Wgt Acc: 95.767%
I - num batch: 222
I - Train -- Loss: 0.154 | Acc: 93.910% | Wgt Acc: 95.926% | LR: 1.250000e-04 | Dur: 193.96s
I - Confusion Matrix: [row->prediction - col->label]
[[676.   0.   0.   2.  53.]
 [  0. 573.   0.   1.  32.]
 [  0.   0. 718.   1.  50.]
 [  1.   1.   1. 531.  32.]
 [ 20.   4.  15.   3. 833.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.258 | Acc: 62.327% | Wgt Acc: 56.004% | Dur: 17.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   0.  15.   5.]
 [  1.  31.   8.   4.   6.]
 [  0.  15.  28.   6.  10.]
 [  9.   3.   6.  41.   4.]
 [ 17.  27.  33.  20. 155.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.123 | Acc: 94.500% | Wgt Acc: 96.742%
	I - Batch: 100 | Loss: 0.119 | Acc: 95.188% | Wgt Acc: 96.996%
	I - Batch: 150 | Loss: 0.118 | Acc: 95.250% | Wgt Acc: 97.039%
	I - Batch: 200 | Loss: 0.119 | Acc: 95.500% | Wgt Acc: 97.242%
I - num batch: 208
I - Train -- Loss: 0.118 | Acc: 95.583% | Wgt Acc: 97.303% | LR: 1.250000e-04 | Dur: 179.85s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   1.  34.]
 [  0. 577.   0.   0.  21.]
 [  0.   0. 728.   0.  37.]
 [  0.   0.   0. 532.  32.]
 [ 10.   1.   6.   5. 657.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.205 | Acc: 61.933% | Wgt Acc: 55.950% | Dur: 17.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  16.   8.]
 [  0.  30.   6.   4.   6.]
 [  0.  11.  23.   2.   8.]
 [ 13.   2.   6.  47.   4.]
 [ 15.  33.  38.  17. 154.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.112 | Acc: 96.375% | Wgt Acc: 97.786%
	I - Batch: 100 | Loss: 0.124 | Acc: 95.938% | Wgt Acc: 97.278%
	I - Batch: 150 | Loss: 0.129 | Acc: 95.750% | Wgt Acc: 97.196%
	I - Batch: 200 | Loss: 0.133 | Acc: 95.500% | Wgt Acc: 96.981%
I - num batch: 222
I - Train -- Loss: 0.134 | Acc: 95.574% | Wgt Acc: 97.038% | LR: 1.250000e-04 | Dur: 197.34s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   0.   0.   2.  50.]
 [  0. 575.   2.   0.  15.]
 [  0.   1. 728.   2.  27.]
 [  1.   0.   0. 531.  30.]
 [ 18.   2.   4.   3. 878.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.238 | Acc: 61.341% | Wgt Acc: 55.349% | Dur: 19.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 54.   0.   1.  13.   5.]
 [  0.  30.   5.   3.   7.]
 [  2.  12.  31.   2.  14.]
 [  8.   2.   3.  44.   2.]
 [ 24.  34.  35.  24. 152.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.112 | Acc: 95.500% | Wgt Acc: 97.175%
	I - Batch: 100 | Loss: 0.119 | Acc: 95.562% | Wgt Acc: 97.103%
	I - Batch: 150 | Loss: 0.120 | Acc: 95.542% | Wgt Acc: 97.100%
	I - Batch: 200 | Loss: 0.130 | Acc: 95.000% | Wgt Acc: 96.780%
I - num batch: 222
I - Train -- Loss: 0.131 | Acc: 94.982% | Wgt Acc: 96.768% | LR: 1.250000e-04 | Dur: 201.88s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   0.   0.   2.  52.]
 [  0. 577.   0.   1.  24.]
 [  0.   0. 724.   0.  36.]
 [  2.   0.   1. 531.  33.]
 [ 13.   1.   9.   4. 855.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.291 | Acc: 60.947% | Wgt Acc: 54.312% | Dur: 22.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 55.   2.   1.  12.   8.]
 [  0.  25.   2.   1.   6.]
 [  0.  12.  27.   2.   7.]
 [ 12.   1.   6.  46.   3.]
 [ 21.  38.  39.  25. 156.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.134 | Acc: 96.000% | Wgt Acc: 97.403%
	I - Batch: 100 | Loss: 0.133 | Acc: 95.500% | Wgt Acc: 97.263%
	I - Batch: 150 | Loss: 0.139 | Acc: 95.083% | Wgt Acc: 96.918%
	I - Batch: 200 | Loss: 0.135 | Acc: 95.375% | Wgt Acc: 97.027%
I - num batch: 222
I - Train -- Loss: 0.133 | Acc: 95.405% | Wgt Acc: 97.069% | LR: 1.250000e-04 | Dur: 193.14s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   1.  55.]
 [  0. 575.   0.   0.  16.]
 [  0.   0. 726.   0.  40.]
 [  0.   0.   1. 533.  24.]
 [ 12.   3.   7.   4. 865.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.213 | Acc: 63.511% | Wgt Acc: 59.170% | Dur: 18.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   2.  10.  11.]
 [  1.  34.   8.   4.   8.]
 [  0.  12.  32.   3.  13.]
 [ 13.   2.   8.  52.   3.]
 [ 15.  27.  25.  17. 145.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.141 | Acc: 94.250% | Wgt Acc: 96.177%
	I - Batch: 100 | Loss: 0.136 | Acc: 94.875% | Wgt Acc: 96.633%
	I - Batch: 150 | Loss: 0.134 | Acc: 94.958% | Wgt Acc: 96.698%
	I - Batch: 200 | Loss: 0.129 | Acc: 95.250% | Wgt Acc: 96.915%
I - num batch: 222
I - Train -- Loss: 0.130 | Acc: 95.179% | Wgt Acc: 96.881% | LR: 1.250000e-04 | Dur: 199.53s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   2.  50.]
 [  0. 576.   1.   0.  20.]
 [  0.   0. 727.   0.  47.]
 [  0.   0.   0. 529.  23.]
 [ 13.   2.   6.   7. 860.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.314 | Acc: 61.538% | Wgt Acc: 54.039% | Dur: 19.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 50.   0.   1.   9.   3.]
 [  1.  29.   8.   4.   5.]
 [  1.  16.  28.   3.   6.]
 [  6.   0.   4.  41.   2.]
 [ 30.  33.  34.  29. 164.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.126 | Acc: 95.625% | Wgt Acc: 97.066%
	I - Batch: 100 | Loss: 0.130 | Acc: 95.188% | Wgt Acc: 96.886%
	I - Batch: 150 | Loss: 0.131 | Acc: 95.042% | Wgt Acc: 96.785%
	I - Batch: 200 | Loss: 0.131 | Acc: 95.188% | Wgt Acc: 96.852%
I - num batch: 222
I - Train -- Loss: 0.133 | Acc: 95.207% | Wgt Acc: 96.881% | LR: 1.250000e-04 | Dur: 195.24s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   0.   0.   1.  49.]
 [  0. 576.   0.   0.  21.]
 [  0.   0. 727.   1.  34.]
 [  2.   1.   0. 531.  33.]
 [ 15.   1.   7.   5. 863.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.302 | Acc: 61.736% | Wgt Acc: 56.277% | Dur: 17.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   1.   1.  22.  16.]
 [  0.  28.   5.   1.   3.]
 [  0.  11.  24.   2.  12.]
 [  7.   2.   8.  45.   2.]
 [ 12.  36.  37.  16. 147.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 96.875% | Wgt Acc: 98.235%
	I - Batch: 100 | Loss: 0.131 | Acc: 95.250% | Wgt Acc: 97.156%
	I - Batch: 150 | Loss: 0.130 | Acc: 95.458% | Wgt Acc: 97.233%
	I - Batch: 200 | Loss: 0.131 | Acc: 95.125% | Wgt Acc: 96.916%
I - num batch: 222
I - Train -- Loss: 0.129 | Acc: 95.207% | Wgt Acc: 96.948% | LR: 1.250000e-04 | Dur: 199.21s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   1.  68.]
 [  0. 575.   0.   1.  21.]
 [  0.   0. 729.   0.  33.]
 [  1.   0.   1. 533.  19.]
 [ 15.   3.   4.   3. 859.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.229 | Acc: 62.327% | Wgt Acc: 57.915% | Dur: 26.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   1.  14.  10.]
 [  0.  27.   5.   2.   5.]
 [  0.  15.  32.   0.  15.]
 [ 13.   3.  11.  56.   7.]
 [ 17.  31.  26.  14. 143.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.109 | Acc: 96.500% | Wgt Acc: 97.910%
	I - Batch: 100 | Loss: 0.130 | Acc: 95.562% | Wgt Acc: 97.108%
	I - Batch: 150 | Loss: 0.133 | Acc: 95.000% | Wgt Acc: 96.679%
	I - Batch: 200 | Loss: 0.128 | Acc: 94.938% | Wgt Acc: 96.648%
I - num batch: 222
I - Train -- Loss: 0.129 | Acc: 94.897% | Wgt Acc: 96.648% | LR: 1.250000e-04 | Dur: 242.64s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   0.   0.   1.  51.]
 [  0. 572.   0.   1.  22.]
 [  0.   1. 729.   0.  39.]
 [  0.   1.   1. 532.  33.]
 [ 19.   4.   4.   4. 855.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.319 | Acc: 61.933% | Wgt Acc: 56.550% | Dur: 28.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 53.   3.   3.   8.   8.]
 [  0.  23.   5.   3.   4.]
 [  1.  15.  28.   2.  12.]
 [ 13.   6.   8.  59.   5.]
 [ 21.  31.  31.  14. 151.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 96.875% | Wgt Acc: 97.896%
	I - Batch: 100 | Loss: 0.103 | Acc: 96.875% | Wgt Acc: 97.887%
	I - Batch: 150 | Loss: 0.113 | Acc: 96.208% | Wgt Acc: 97.487%
	I - Batch: 200 | Loss: 0.120 | Acc: 95.594% | Wgt Acc: 97.008%
I - num batch: 222
I - Train -- Loss: 0.120 | Acc: 95.546% | Wgt Acc: 96.971% | LR: 1.250000e-04 | Dur: 229.05s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   0.   0.   2.  44.]
 [  0. 575.   0.   1.  20.]
 [  0.   1. 725.   2.  27.]
 [  0.   0.   1. 528.  30.]
 [ 15.   2.   8.   5. 879.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.369 | Acc: 59.763% | Wgt Acc: 52.948% | Dur: 23.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 50.   2.   1.   9.   5.]
 [  0.  27.   5.   3.   9.]
 [  0.  13.  30.   3.  10.]
 [ 12.   2.   7.  41.   1.]
 [ 26.  34.  32.  30. 155.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.106 | Acc: 95.875% | Wgt Acc: 97.471%
	I - Batch: 100 | Loss: 0.119 | Acc: 95.625% | Wgt Acc: 97.050%
	I - Batch: 150 | Loss: 0.113 | Acc: 95.875% | Wgt Acc: 97.219%
	I - Batch: 200 | Loss: 0.116 | Acc: 95.781% | Wgt Acc: 97.200%
I - num batch: 222
I - Train -- Loss: 0.116 | Acc: 95.771% | Wgt Acc: 97.219% | LR: 1.250000e-04 | Dur: 225.62s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   0.   0.   1.  37.]
 [  0. 577.   0.   0.  17.]
 [  0.   0. 728.   0.  30.]
 [  0.   0.   1. 531.  35.]
 [ 17.   1.   5.   6. 881.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.359 | Acc: 63.314% | Wgt Acc: 57.478% | Dur: 26.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   1.   2.  18.  12.]
 [  0.  30.   6.   3.   3.]
 [  0.  10.  24.   3.   8.]
 [  7.   2.   7.  47.   3.]
 [ 15.  35.  36.  15. 154.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.109 | Acc: 95.625% | Wgt Acc: 97.154%
	I - Batch: 100 | Loss: 0.106 | Acc: 96.125% | Wgt Acc: 97.579%
	I - Batch: 150 | Loss: 0.106 | Acc: 96.042% | Wgt Acc: 97.401%
	I - Batch: 200 | Loss: 0.107 | Acc: 96.031% | Wgt Acc: 97.419%
I - num batch: 222
I - Train -- Loss: 0.110 | Acc: 95.912% | Wgt Acc: 97.354% | LR: 1.250000e-04 | Dur: 221.88s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   1.  48.]
 [  0. 575.   0.   0.  23.]
 [  0.   0. 727.   0.  28.]
 [  1.   0.   1. 533.  19.]
 [ 11.   3.   6.   4. 882.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.391 | Acc: 60.750% | Wgt Acc: 52.838% | Dur: 20.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   4.  23.   9.]
 [  0.  30.   2.   1.   2.]
 [  0.   7.  20.   2.   5.]
 [  6.   2.   2.  34.   0.]
 [ 22.  35.  47.  26. 164.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.104 | Acc: 96.750% | Wgt Acc: 97.877%
	I - Batch: 100 | Loss: 0.103 | Acc: 96.562% | Wgt Acc: 97.803%
	I - Batch: 150 | Loss: 0.106 | Acc: 96.167% | Wgt Acc: 97.440%
	I - Batch: 200 | Loss: 0.105 | Acc: 96.406% | Wgt Acc: 97.600%
I - num batch: 222
I - Train -- Loss: 0.104 | Acc: 96.391% | Wgt Acc: 97.587% | LR: 1.250000e-04 | Dur: 201.21s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   1.  35.]
 [  0. 576.   0.   1.  20.]
 [  0.   0. 731.   0.  28.]
 [  1.   0.   0. 531.  17.]
 [ 15.   2.   3.   5. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.332 | Acc: 63.116% | Wgt Acc: 56.823% | Dur: 17.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 73.   1.   2.  20.  13.]
 [  0.  24.   3.   2.   4.]
 [  0.  10.  21.   1.   2.]
 [  6.   2.   9.  47.   6.]
 [  9.  41.  40.  16. 155.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.105 | Acc: 96.000% | Wgt Acc: 97.427%
	I - Batch: 100 | Loss: 0.109 | Acc: 95.875% | Wgt Acc: 97.336%
	I - Batch: 150 | Loss: 0.117 | Acc: 95.792% | Wgt Acc: 97.232%
	I - Batch: 200 | Loss: 0.112 | Acc: 96.000% | Wgt Acc: 97.427%
I - num batch: 222
I - Train -- Loss: 0.109 | Acc: 96.166% | Wgt Acc: 97.565% | LR: 1.250000e-04 | Dur: 194.40s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   1.   1.  44.]
 [  0. 574.   0.   1.  17.]
 [  0.   1. 732.   0.  30.]
 [  0.   0.   0. 534.  23.]
 [ 12.   3.   1.   2. 886.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.370 | Acc: 60.552% | Wgt Acc: 53.821% | Dur: 18.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   1.  13.   9.]
 [  0.  24.   3.   0.   5.]
 [  0.   8.  21.   0.   7.]
 [  9.   1.   9.  46.   3.]
 [ 19.  44.  41.  27. 156.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.112 | Acc: 95.750% | Wgt Acc: 97.261%
	I - Batch: 100 | Loss: 0.111 | Acc: 95.312% | Wgt Acc: 96.900%
	I - Batch: 150 | Loss: 0.117 | Acc: 95.375% | Wgt Acc: 96.984%
	I - Batch: 200 | Loss: 0.112 | Acc: 95.531% | Wgt Acc: 97.085%
I - num batch: 222
I - Train -- Loss: 0.112 | Acc: 95.630% | Wgt Acc: 97.121% | LR: 1.250000e-04 | Dur: 200.75s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   1.  46.]
 [  0. 575.   0.   1.  20.]
 [  0.   1. 731.   0.  29.]
 [  1.   0.   0. 528.  30.]
 [ 13.   2.   3.   8. 875.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.251 | Acc: 61.933% | Wgt Acc: 56.987% | Dur: 17.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   2.   2.  15.   7.]
 [  0.  29.   9.   4.   6.]
 [  0.  19.  31.   3.  18.]
 [  9.   1.   4.  51.   3.]
 [ 22.  27.  29.  13. 146.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 96.750% | Wgt Acc: 98.151%
	I - Batch: 100 | Loss: 0.097 | Acc: 95.938% | Wgt Acc: 97.673%
	I - Batch: 150 | Loss: 0.104 | Acc: 95.750% | Wgt Acc: 97.466%
	I - Batch: 200 | Loss: 0.106 | Acc: 95.688% | Wgt Acc: 97.391%
I - num batch: 222
I - Train -- Loss: 0.107 | Acc: 95.686% | Wgt Acc: 97.369% | LR: 1.250000e-04 | Dur: 196.10s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  42.]
 [  0. 576.   0.   0.  26.]
 [  0.   0. 729.   0.  33.]
 [  1.   0.   1. 534.  33.]
 [  7.   2.   4.   3. 866.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.287 | Acc: 63.314% | Wgt Acc: 56.441% | Dur: 17.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   1.  17.   9.]
 [  1.  28.   4.   1.   5.]
 [  0.  11.  24.   1.   4.]
 [  5.   2.   5.  44.   1.]
 [ 18.  35.  41.  23. 161.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.119 | Acc: 96.000% | Wgt Acc: 97.523%
	I - Batch: 100 | Loss: 0.107 | Acc: 96.438% | Wgt Acc: 97.802%
	I - Batch: 150 | Loss: 0.107 | Acc: 96.500% | Wgt Acc: 97.844%
	I - Batch: 200 | Loss: 0.112 | Acc: 96.125% | Wgt Acc: 97.596%
I - num batch: 222
I - Train -- Loss: 0.113 | Acc: 96.109% | Wgt Acc: 97.572% | LR: 1.250000e-04 | Dur: 203.10s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   0.  52.]
 [  0. 576.   1.   0.  18.]
 [  0.   0. 731.   0.  25.]
 [  1.   0.   0. 535.  22.]
 [ 12.   2.   2.   3. 883.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.314 | Acc: 62.919% | Wgt Acc: 57.915% | Dur: 18.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   1.   0.  17.  13.]
 [  0.  30.   6.   0.   7.]
 [  0.   8.  26.   2.   6.]
 [ 12.   6.  12.  53.   5.]
 [ 15.  33.  31.  14. 149.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 96.500% | Wgt Acc: 97.605%
	I - Batch: 100 | Loss: 0.111 | Acc: 96.062% | Wgt Acc: 97.506%
	I - Batch: 150 | Loss: 0.105 | Acc: 96.375% | Wgt Acc: 97.716%
	I - Batch: 200 | Loss: 0.104 | Acc: 96.219% | Wgt Acc: 97.608%
I - num batch: 222
I - Train -- Loss: 0.105 | Acc: 96.307% | Wgt Acc: 97.662% | LR: 1.250000e-04 | Dur: 195.47s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   1.  41.]
 [  0. 576.   0.   1.  17.]
 [  0.   0. 729.   0.  27.]
 [  2.   0.   0. 535.  24.]
 [ 10.   2.   5.   1. 891.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.332 | Acc: 61.736% | Wgt Acc: 55.677% | Dur: 17.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   4.  22.  14.]
 [  0.  25.   6.   0.   3.]
 [  0.  10.  25.   0.   6.]
 [ 10.   4.  11.  47.   5.]
 [ 14.  37.  29.  17. 152.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.101 | Acc: 95.625% | Wgt Acc: 97.309%
	I - Batch: 100 | Loss: 0.108 | Acc: 95.438% | Wgt Acc: 97.069%
	I - Batch: 150 | Loss: 0.107 | Acc: 95.792% | Wgt Acc: 97.259%
	I - Batch: 200 | Loss: 0.105 | Acc: 95.906% | Wgt Acc: 97.360%
I - num batch: 222
I - Train -- Loss: 0.106 | Acc: 95.940% | Wgt Acc: 97.339% | LR: 1.250000e-04 | Dur: 196.82s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   2.  40.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 729.   1.  36.]
 [  1.   0.   0. 529.  27.]
 [ 12.   1.   5.   6. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.341 | Acc: 62.722% | Wgt Acc: 56.059% | Dur: 17.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   2.   2.  12.   6.]
 [  0.  27.   5.   0.   3.]
 [  1.  11.  24.   2.   9.]
 [  7.   1.   5.  48.   2.]
 [ 21.  37.  39.  24. 160.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.093 | Acc: 97.000% | Wgt Acc: 97.913%
	I - Batch: 100 | Loss: 0.096 | Acc: 96.625% | Wgt Acc: 97.643%
	I - Batch: 150 | Loss: 0.103 | Acc: 96.542% | Wgt Acc: 97.740%
	I - Batch: 200 | Loss: 0.101 | Acc: 96.656% | Wgt Acc: 97.861%
I - num batch: 222
I - Train -- Loss: 0.102 | Acc: 96.476% | Wgt Acc: 97.715% | LR: 1.250000e-04 | Dur: 194.61s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   1.  33.]
 [  0. 577.   1.   0.  18.]
 [  0.   0. 729.   0.  29.]
 [  1.   0.   0. 533.  21.]
 [ 12.   1.   4.   4. 899.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.365 | Acc: 63.116% | Wgt Acc: 55.895% | Dur: 17.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   1.   2.  14.   6.]
 [  0.  22.   3.   1.   3.]
 [  0.  14.  23.   0.   5.]
 [  6.   1.  10.  48.   3.]
 [ 18.  40.  37.  23. 163.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.083 | Acc: 97.500% | Wgt Acc: 98.581%
	I - Batch: 100 | Loss: 0.090 | Acc: 97.062% | Wgt Acc: 98.143%
	I - Batch: 150 | Loss: 0.094 | Acc: 96.833% | Wgt Acc: 98.060%
	I - Batch: 200 | Loss: 0.099 | Acc: 96.625% | Wgt Acc: 97.963%
I - num batch: 222
I - Train -- Loss: 0.102 | Acc: 96.363% | Wgt Acc: 97.745% | LR: 1.250000e-04 | Dur: 198.98s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   1.  43.]
 [  0. 577.   0.   0.  17.]
 [  0.   0. 731.   0.  24.]
 [  0.   0.   0. 533.  27.]
 [  9.   1.   3.   4. 889.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.220 | Acc: 62.525% | Wgt Acc: 57.151% | Dur: 17.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   1.   2.  12.   9.]
 [  1.  28.   4.   4.   5.]
 [  0.  13.  32.   1.  12.]
 [  9.   0.   3.  49.   5.]
 [ 19.  36.  34.  20. 149.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 97.375% | Wgt Acc: 98.344%
	I - Batch: 100 | Loss: 0.093 | Acc: 96.062% | Wgt Acc: 97.527%
	I - Batch: 150 | Loss: 0.098 | Acc: 96.083% | Wgt Acc: 97.425%
	I - Batch: 200 | Loss: 0.093 | Acc: 96.531% | Wgt Acc: 97.730%
I - num batch: 222
I - Train -- Loss: 0.094 | Acc: 96.532% | Wgt Acc: 97.753% | LR: 1.250000e-04 | Dur: 194.78s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   0.  50.]
 [  0. 575.   0.   0.  14.]
 [  0.   0. 734.   0.  17.]
 [  1.   0.   0. 534.  19.]
 [ 15.   3.   0.   4. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.370 | Acc: 62.130% | Wgt Acc: 55.459% | Dur: 17.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   1.   2.  15.   5.]
 [  0.  30.   4.   3.   5.]
 [  0.  11.  30.   1.  11.]
 [  2.   0.   7.  38.   3.]
 [ 25.  36.  32.  29. 156.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.102 | Acc: 96.375% | Wgt Acc: 97.764%
	I - Batch: 100 | Loss: 0.102 | Acc: 96.438% | Wgt Acc: 97.848%
	I - Batch: 150 | Loss: 0.095 | Acc: 96.792% | Wgt Acc: 98.095%
	I - Batch: 200 | Loss: 0.096 | Acc: 96.688% | Wgt Acc: 98.065%
I - num batch: 222
I - Train -- Loss: 0.096 | Acc: 96.701% | Wgt Acc: 98.061% | LR: 1.250000e-04 | Dur: 196.62s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  43.]
 [  0. 578.   1.   0.  21.]
 [  0.   0. 733.   0.  25.]
 [  0.   0.   0. 536.  17.]
 [  8.   0.   0.   2. 894.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.388 | Acc: 62.919% | Wgt Acc: 56.332% | Dur: 17.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   2.  21.  15.]
 [  0.  22.   2.   2.   1.]
 [  0.   7.  19.   0.   3.]
 [  6.   1.   9.  50.   3.]
 [ 12.  44.  43.  13. 158.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 102
I - Training: 
