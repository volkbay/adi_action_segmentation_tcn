Sun Oct  2 12:41:24 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.25, 0.26, 0.18, 0.24, 0.07], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 5, 'doubleClasses': [1, 2], 'loadData2memory': True, 'multiplyData': True, 'tossFirstLastFrames': True}, 'dataPath': '/data/processed/Kinetics/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 6, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 25, 'validationAccThr': 65, 'weightDecay': 0.01}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Number of frames greater than dataset description, tossed data with #frames =  964
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  16040
I - Label distribution: [1862. 1838. 2638. 1894. 7808.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Tossed a data with insufficient frame number.
I - Test set length:  3805
I - Label distribution: [ 526.  726.  778.  567. 1208.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([ 4231,  9625,  7052,  7474,  7843,  5239, 15912, 11936,  4230, 10650,
        12336,  9010,   794,  4114,  3159, 16011])
I - Initializing model TCNv6
I - Number of Model Parameters: 646479
I - Model output shape:  torch.Size([3, 16, 5, 16])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv6                                    [3, 16, 5, 16]            --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─ReLU: 2-62                        [16, 64, 32, 32]          --
│    └─Empty: 2-63                       [16, 64, 32, 32]          --
│    └─Clamp: 2-64                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
│    └─OutputScale: 2-67                 --                        --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64, 64, 3, 3]            --
│    └─Empty: 2-70                       [64]                      --
│    └─Empty: 2-71                       [64]                      --
│    └─BatchNorm2d: 2-72                 [16, 64, 32, 32]          --
│    └─Scaler: 2-73                      [16, 64, 32, 32]          --
│    └─ReLU: 2-74                        [16, 64, 32, 32]          --
│    └─Empty: 2-75                       [16, 64, 32, 32]          --
│    └─Clamp: 2-76                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-77                   [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─Empty: 2-79                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-80          --                        --
│    └─One: 2-81                         [1]                       --
│    └─OutputScale: 2-82                 --                        --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64, 64, 3, 3]            --
│    └─Empty: 2-85                       [64]                      --
│    └─Empty: 2-86                       [64]                      --
│    └─BatchNorm2d: 2-87                 [16, 64, 16, 16]          --
│    └─Scaler: 2-88                      [16, 64, 16, 16]          --
│    └─ReLU: 2-89                        [16, 64, 16, 16]          --
│    └─Empty: 2-90                       [16, 64, 16, 16]          --
│    └─Clamp: 2-91                       [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-93          --                        --
│    └─One: 2-94                         [1]                       --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [64, 64, 3, 3]            --
│    └─Empty: 2-97                       [64, 64, 3, 3]            --
│    └─Empty: 2-98                       [64]                      --
│    └─Empty: 2-99                       [64]                      --
│    └─BatchNorm2d: 2-100                [16, 64, 16, 16]          --
│    └─Scaler: 2-101                     [16, 64, 16, 16]          --
│    └─ReLU: 2-102                       [16, 64, 16, 16]          --
│    └─Empty: 2-103                      [16, 64, 16, 16]          --
│    └─Clamp: 2-104                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-105                  [16, 64, 8, 8]            --
│    └─Empty: 2-106                      [16, 64, 8, 8]            --
│    └─Empty: 2-107                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-108         --                        --
│    └─One: 2-109                        [1]                       --
│    └─OutputScale: 2-110                --                        --
│    └─Empty: 2-111                      [64, 64, 3, 3]            --
│    └─Empty: 2-112                      [64, 64, 3, 3]            --
│    └─Empty: 2-113                      [64]                      --
│    └─Empty: 2-114                      [64]                      --
│    └─BatchNorm2d: 2-115                [16, 64, 8, 8]            --
│    └─Scaler: 2-116                     [16, 64, 8, 8]            --
│    └─ReLU: 2-117                       [16, 64, 8, 8]            --
│    └─Empty: 2-118                      [16, 64, 8, 8]            --
│    └─Clamp: 2-119                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-120         --                        --
│    └─One: 2-121                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-123                --                        --
│    └─Empty: 2-124                      [64, 64, 1, 1]            --
│    └─Empty: 2-125                      [64, 64, 1, 1]            --
│    └─Empty: 2-126                      [64]                      --
│    └─Empty: 2-127                      [64]                      --
│    └─BatchNorm2d: 2-128                [16, 64, 8, 8]            --
│    └─Scaler: 2-129                     [16, 64, 8, 8]            --
│    └─ReLU: 2-130                       [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Clamp: 2-132                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-133                  [16, 64, 8, 8]            --
│    └─Empty: 2-134                      [16, 64, 8, 8]            --
│    └─Empty: 2-135                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-136         --                        --
│    └─One: 2-137                        [1]                       --
│    └─OutputScale: 2-138                --                        --
│    └─Empty: 2-139                      [64, 64, 3, 3]            --
│    └─Empty: 2-140                      [64, 64, 3, 3]            --
│    └─Empty: 2-141                      [64]                      --
│    └─Empty: 2-142                      [64]                      --
│    └─BatchNorm2d: 2-143                [16, 64, 8, 8]            --
│    └─Scaler: 2-144                     [16, 64, 8, 8]            --
│    └─ReLU: 2-145                       [16, 64, 8, 8]            --
│    └─Empty: 2-146                      [16, 64, 8, 8]            --
│    └─Clamp: 2-147                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-148                  [16, 64, 4, 4]            --
│    └─Empty: 2-149                      [16, 64, 4, 4]            --
│    └─Empty: 2-150                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-151         --                        --
│    └─One: 2-152                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-154                --                        --
│    └─Empty: 2-155                      [64, 64, 3, 3]            --
│    └─Empty: 2-156                      [64, 64, 3, 3]            --
│    └─Empty: 2-157                      [64]                      --
│    └─Empty: 2-158                      [64]                      --
│    └─BatchNorm2d: 2-159                [16, 64, 4, 4]            --
│    └─Scaler: 2-160                     [16, 64, 4, 4]            --
│    └─ReLU: 2-161                       [16, 64, 4, 4]            --
│    └─Empty: 2-162                      [16, 64, 4, 4]            --
│    └─Clamp: 2-163                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-164         --                        --
│    └─One: 2-165                        [1]                       --
│    └─OutputScale: 2-166                --                        --
│    └─Empty: 2-167                      [64, 64, 1, 1]            --
│    └─Empty: 2-168                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-170                      [64]                      --
│    └─Empty: 2-171                      [64]                      --
│    └─BatchNorm2d: 2-172                [16, 64, 4, 4]            --
│    └─Scaler: 2-173                     [16, 64, 4, 4]            --
│    └─ReLU: 2-174                       [16, 64, 4, 4]            --
│    └─Empty: 2-175                      [16, 64, 4, 4]            --
│    └─Clamp: 2-176                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-177                  [16, 64, 4, 4]            --
│    └─Empty: 2-178                      [16, 64, 4, 4]            --
│    └─Empty: 2-179                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-180         --                        --
│    └─One: 2-181                        [1]                       --
│    └─OutputScale: 2-182                --                        --
│    └─Empty: 2-183                      [64, 64, 3, 3]            --
│    └─Empty: 2-184                      [64, 64, 3, 3]            --
│    └─Empty: 2-185                      [64]                      --
│    └─Empty: 2-186                      [64]                      --
│    └─BatchNorm2d: 2-187                [16, 64, 4, 4]            --
│    └─Scaler: 2-188                     [16, 64, 4, 4]            --
│    └─ReLU: 2-189                       [16, 64, 4, 4]            --
│    └─Empty: 2-190                      [16, 64, 4, 4]            --
│    └─Clamp: 2-191                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-192                  [16, 64, 2, 2]            --
│    └─Empty: 2-193                      [16, 64, 2, 2]            --
│    └─Empty: 2-194                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-195         --                        --
│    └─One: 2-196                        [1]                       --
│    └─OutputScale: 2-197                --                        --
│    └─Empty: 2-198                      [64, 64, 1, 1]            --
│    └─Empty: 2-199                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-201                      [64]                      --
│    └─Empty: 2-202                      [64]                      --
│    └─BatchNorm2d: 2-203                [16, 64, 2, 2]            --
│    └─Scaler: 2-204                     [16, 64, 2, 2]            --
│    └─ReLU: 2-205                       [16, 64, 2, 2]            --
│    └─Empty: 2-206                      [16, 64, 2, 2]            --
│    └─Clamp: 2-207                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-208         --                        --
│    └─One: 2-209                        [1]                       --
│    └─OutputScale: 2-210                --                        --
│    └─Empty: 2-211                      [64, 64, 1, 1]            --
│    └─Empty: 2-212                      [64, 64, 1, 1]            --
│    └─Empty: 2-213                      [64]                      --
│    └─Empty: 2-214                      [64]                      --
│    └─BatchNorm2d: 2-215                [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-217                     [16, 64, 2, 2]            --
│    └─ReLU: 2-218                       [16, 64, 2, 2]            --
│    └─Empty: 2-219                      [16, 64, 2, 2]            --
│    └─Clamp: 2-220                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-221                  [16, 64, 2, 2]            --
│    └─Empty: 2-222                      [16, 64, 2, 2]            --
│    └─Empty: 2-223                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-224         --                        --
│    └─One: 2-225                        [1]                       --
│    └─OutputScale: 2-226                --                        --
│    └─Empty: 2-227                      [64, 64, 3, 3]            --
│    └─Empty: 2-228                      [64, 64, 3, 3]            --
│    └─Empty: 2-229                      [64]                      --
│    └─Empty: 2-230                      [64]                      --
│    └─BatchNorm2d: 2-231                [16, 64, 2, 2]            --
│    └─Scaler: 2-232                     [16, 64, 2, 2]            --
│    └─ReLU: 2-233                       [16, 64, 2, 2]            --
│    └─Empty: 2-234                      [16, 64, 2, 2]            --
│    └─Clamp: 2-235                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-236         --                        --
│    └─One: 2-237                        [1]                       --
│    └─OutputScale: 2-238                --                        --
│    └─Empty: 2-239                      [64, 48, 1, 1]            --
│    └─Empty: 2-240                      [64, 48, 1, 1]            --
│    └─Empty: 2-241                      [64]                      --
│    └─Empty: 2-242                      [64]                      --
│    └─BatchNorm2d: 2-243                [16, 64, 64, 64]          --
│    └─Scaler: 2-244                     [16, 64, 64, 64]          --
│    └─ReLU: 2-245                       [16, 64, 64, 64]          --
│    └─Empty: 2-246                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-248                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-249         --                        --
│    └─One: 2-250                        [1]                       --
│    └─OutputScale: 2-251                --                        --
│    └─Empty: 2-252                      [64, 64, 3, 3]            --
│    └─Empty: 2-253                      [64, 64, 3, 3]            --
│    └─Empty: 2-254                      [64]                      --
│    └─Empty: 2-255                      [64]                      --
│    └─BatchNorm2d: 2-256                [16, 64, 64, 64]          --
│    └─Scaler: 2-257                     [16, 64, 64, 64]          --
│    └─ReLU: 2-258                       [16, 64, 64, 64]          --
│    └─Empty: 2-259                      [16, 64, 64, 64]          --
│    └─Clamp: 2-260                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-261         --                        --
│    └─One: 2-262                        [1]                       --
│    └─OutputScale: 2-263                --                        --
│    └─Empty: 2-264                      [64, 64, 1, 1]            --
│    └─Empty: 2-265                      [64, 64, 1, 1]            --
│    └─Empty: 2-266                      [64]                      --
│    └─Empty: 2-267                      [64]                      --
│    └─BatchNorm2d: 2-268                [16, 64, 64, 64]          --
│    └─Scaler: 2-269                     [16, 64, 64, 64]          --
│    └─ReLU: 2-270                       [16, 64, 64, 64]          --
│    └─Empty: 2-271                      [16, 64, 64, 64]          --
│    └─Clamp: 2-272                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-273         --                        --
│    └─One: 2-274                        [1]                       --
│    └─OutputScale: 2-275                --                        --
│    └─Empty: 2-276                      [64, 64, 3, 3]            --
│    └─Empty: 2-277                      [64, 64, 3, 3]            --
│    └─Empty: 2-278                      [64]                      --
│    └─Empty: 2-279                      [64]                      --
│    └─BatchNorm2d: 2-280                [16, 64, 64, 64]          --
│    └─Scaler: 2-281                     [16, 64, 64, 64]          --
│    └─ReLU: 2-282                       [16, 64, 64, 64]          --
│    └─Empty: 2-283                      [16, 64, 64, 64]          --
│    └─Clamp: 2-284                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-285                  [16, 64, 32, 32]          --
│    └─Empty: 2-286                      [16, 64, 32, 32]          --
│    └─Empty: 2-287                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-288         --                        --
│    └─One: 2-289                        [1]                       --
│    └─OutputScale: 2-290                --                        --
│    └─Empty: 2-291                      [64, 64, 3, 3]            --
│    └─Empty: 2-292                      [64, 64, 3, 3]            --
│    └─Empty: 2-293                      [64]                      --
│    └─Empty: 2-294                      [64]                      --
│    └─BatchNorm2d: 2-295                [16, 64, 32, 32]          --
│    └─Scaler: 2-296                     [16, 64, 32, 32]          --
│    └─ReLU: 2-297                       [16, 64, 32, 32]          --
│    └─Empty: 2-298                      [16, 64, 32, 32]          --
│    └─Clamp: 2-299                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-300         --                        --
│    └─One: 2-301                        [1]                       --
│    └─OutputScale: 2-302                --                        --
│    └─Empty: 2-303                      [64, 64, 3, 3]            --
│    └─Empty: 2-304                      [64, 64, 3, 3]            --
│    └─Empty: 2-305                      [64]                      --
│    └─Empty: 2-306                      [64]                      --
│    └─BatchNorm2d: 2-307                [16, 64, 32, 32]          --
│    └─Scaler: 2-308                     [16, 64, 32, 32]          --
│    └─ReLU: 2-309                       [16, 64, 32, 32]          --
│    └─Empty: 2-310                      [16, 64, 32, 32]          --
│    └─Clamp: 2-311                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-312                  [16, 64, 16, 16]          --
│    └─Empty: 2-313                      [16, 64, 16, 16]          --
│    └─Empty: 2-314                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-315         --                        --
│    └─One: 2-316                        [1]                       --
│    └─OutputScale: 2-317                --                        --
│    └─Empty: 2-318                      [64, 64, 3, 3]            --
│    └─Empty: 2-319                      [64, 64, 3, 3]            --
│    └─Empty: 2-320                      [64]                      --
│    └─Empty: 2-321                      [64]                      --
│    └─BatchNorm2d: 2-322                [16, 64, 16, 16]          --
│    └─Scaler: 2-323                     [16, 64, 16, 16]          --
│    └─ReLU: 2-324                       [16, 64, 16, 16]          --
│    └─Empty: 2-325                      [16, 64, 16, 16]          --
│    └─Clamp: 2-326                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-327         --                        --
│    └─One: 2-328                        [1]                       --
│    └─OutputScale: 2-329                --                        --
│    └─Empty: 2-330                      [64, 64, 3, 3]            --
│    └─Empty: 2-331                      [64, 64, 3, 3]            --
│    └─Empty: 2-332                      [64]                      --
│    └─Empty: 2-333                      [64]                      --
│    └─BatchNorm2d: 2-334                [16, 64, 16, 16]          --
│    └─Scaler: 2-335                     [16, 64, 16, 16]          --
│    └─ReLU: 2-336                       [16, 64, 16, 16]          --
│    └─Empty: 2-337                      [16, 64, 16, 16]          --
│    └─Clamp: 2-338                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-339                  [16, 64, 8, 8]            --
│    └─Empty: 2-340                      [16, 64, 8, 8]            --
│    └─Empty: 2-341                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-342         --                        --
│    └─One: 2-343                        [1]                       --
│    └─OutputScale: 2-344                --                        --
│    └─Empty: 2-345                      [64, 64, 3, 3]            --
│    └─Empty: 2-346                      [64, 64, 3, 3]            --
│    └─Empty: 2-347                      [64]                      --
│    └─Empty: 2-348                      [64]                      --
│    └─BatchNorm2d: 2-349                [16, 64, 8, 8]            --
│    └─Scaler: 2-350                     [16, 64, 8, 8]            --
│    └─ReLU: 2-351                       [16, 64, 8, 8]            --
│    └─Empty: 2-352                      [16, 64, 8, 8]            --
│    └─Clamp: 2-353                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-354         --                        --
│    └─One: 2-355                        [1]                       --
│    └─OutputScale: 2-356                --                        --
│    └─Empty: 2-357                      [64, 64, 1, 1]            --
│    └─Empty: 2-358                      [64, 64, 1, 1]            --
│    └─Empty: 2-359                      [64]                      --
│    └─Empty: 2-360                      [64]                      --
│    └─BatchNorm2d: 2-361                [16, 64, 8, 8]            --
│    └─Scaler: 2-362                     [16, 64, 8, 8]            --
│    └─ReLU: 2-363                       [16, 64, 8, 8]            --
│    └─Empty: 2-364                      [16, 64, 8, 8]            --
│    └─Clamp: 2-365                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-366                  [16, 64, 8, 8]            --
│    └─Empty: 2-367                      [16, 64, 8, 8]            --
│    └─Empty: 2-368                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-369         --                        --
│    └─One: 2-370                        [1]                       --
│    └─OutputScale: 2-371                --                        --
│    └─Empty: 2-372                      [64, 64, 3, 3]            --
│    └─Empty: 2-373                      [64, 64, 3, 3]            --
│    └─Empty: 2-374                      [64]                      --
│    └─Empty: 2-375                      [64]                      --
│    └─BatchNorm2d: 2-376                [16, 64, 8, 8]            --
│    └─Scaler: 2-377                     [16, 64, 8, 8]            --
│    └─ReLU: 2-378                       [16, 64, 8, 8]            --
│    └─Empty: 2-379                      [16, 64, 8, 8]            --
│    └─Clamp: 2-380                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-381                  [16, 64, 4, 4]            --
│    └─Empty: 2-382                      [16, 64, 4, 4]            --
│    └─Empty: 2-383                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-384         --                        --
│    └─One: 2-385                        [1]                       --
│    └─OutputScale: 2-386                --                        --
│    └─Empty: 2-387                      [64, 64, 3, 3]            --
│    └─Empty: 2-388                      [64, 64, 3, 3]            --
│    └─Empty: 2-389                      [64]                      --
│    └─Empty: 2-390                      [64]                      --
│    └─BatchNorm2d: 2-391                [16, 64, 4, 4]            --
│    └─Scaler: 2-392                     [16, 64, 4, 4]            --
│    └─ReLU: 2-393                       [16, 64, 4, 4]            --
│    └─Empty: 2-394                      [16, 64, 4, 4]            --
│    └─Clamp: 2-395                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-396         --                        --
│    └─One: 2-397                        [1]                       --
│    └─OutputScale: 2-398                --                        --
│    └─Empty: 2-399                      [64, 64, 1, 1]            --
│    └─Empty: 2-400                      [64, 64, 1, 1]            --
│    └─Empty: 2-401                      [64]                      --
│    └─Empty: 2-402                      [64]                      --
│    └─BatchNorm2d: 2-403                [16, 64, 4, 4]            --
│    └─Scaler: 2-404                     [16, 64, 4, 4]            --
│    └─ReLU: 2-405                       [16, 64, 4, 4]            --
│    └─Empty: 2-406                      [16, 64, 4, 4]            --
│    └─Clamp: 2-407                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-408                  [16, 64, 4, 4]            --
│    └─Empty: 2-409                      [16, 64, 4, 4]            --
│    └─Empty: 2-410                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-411         --                        --
│    └─One: 2-412                        [1]                       --
│    └─OutputScale: 2-413                --                        --
│    └─Empty: 2-414                      [64, 64, 3, 3]            --
│    └─Empty: 2-415                      [64, 64, 3, 3]            --
│    └─Empty: 2-416                      [64]                      --
│    └─Empty: 2-417                      [64]                      --
│    └─BatchNorm2d: 2-418                [16, 64, 4, 4]            --
│    └─Scaler: 2-419                     [16, 64, 4, 4]            --
│    └─ReLU: 2-420                       [16, 64, 4, 4]            --
│    └─Empty: 2-421                      [16, 64, 4, 4]            --
│    └─Clamp: 2-422                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-423                  [16, 64, 2, 2]            --
│    └─Empty: 2-424                      [16, 64, 2, 2]            --
│    └─Empty: 2-425                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-426         --                        --
│    └─One: 2-427                        [1]                       --
│    └─OutputScale: 2-428                --                        --
│    └─Empty: 2-429                      [64, 64, 1, 1]            --
│    └─Empty: 2-430                      [64, 64, 1, 1]            --
│    └─Empty: 2-431                      [64]                      --
│    └─Empty: 2-432                      [64]                      --
│    └─BatchNorm2d: 2-433                [16, 64, 2, 2]            --
│    └─Scaler: 2-434                     [16, 64, 2, 2]            --
│    └─ReLU: 2-435                       [16, 64, 2, 2]            --
│    └─Empty: 2-436                      [16, 64, 2, 2]            --
│    └─Clamp: 2-437                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-438         --                        --
│    └─One: 2-439                        [1]                       --
│    └─OutputScale: 2-440                --                        --
│    └─Empty: 2-441                      [64, 64, 1, 1]            --
│    └─Empty: 2-442                      [64, 64, 1, 1]            --
│    └─Empty: 2-443                      [64]                      --
│    └─Empty: 2-444                      [64]                      --
│    └─BatchNorm2d: 2-445                [16, 64, 2, 2]            --
│    └─Scaler: 2-446                     [16, 64, 2, 2]            --
│    └─ReLU: 2-447                       [16, 64, 2, 2]            --
│    └─Empty: 2-448                      [16, 64, 2, 2]            --
│    └─Clamp: 2-449                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-450                  [16, 64, 2, 2]            --
│    └─Empty: 2-451                      [16, 64, 2, 2]            --
│    └─Empty: 2-452                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-453         --                        --
│    └─One: 2-454                        [1]                       --
│    └─OutputScale: 2-455                --                        --
│    └─Empty: 2-456                      [64, 64, 3, 3]            --
│    └─Empty: 2-457                      [64, 64, 3, 3]            --
│    └─Empty: 2-458                      [64]                      --
│    └─Empty: 2-459                      [64]                      --
│    └─BatchNorm2d: 2-460                [16, 64, 2, 2]            --
│    └─Scaler: 2-461                     [16, 64, 2, 2]            --
│    └─ReLU: 2-462                       [16, 64, 2, 2]            --
│    └─Empty: 2-463                      [16, 64, 2, 2]            --
│    └─Clamp: 2-464                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-465         --                        --
│    └─One: 2-466                        [1]                       --
│    └─OutputScale: 2-467                --                        --
│    └─Empty: 2-468                      [64, 48, 1, 1]            --
│    └─Empty: 2-469                      [64, 48, 1, 1]            --
│    └─Empty: 2-470                      [64]                      --
│    └─Empty: 2-471                      [64]                      --
│    └─BatchNorm2d: 2-472                [16, 64, 64, 64]          --
│    └─Scaler: 2-473                     [16, 64, 64, 64]          --
│    └─ReLU: 2-474                       [16, 64, 64, 64]          --
│    └─Empty: 2-475                      [16, 64, 64, 64]          --
│    └─Clamp: 2-476                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-477         --                        --
│    └─One: 2-478                        [1]                       --
│    └─OutputScale: 2-479                --                        --
│    └─Empty: 2-480                      [64, 64, 3, 3]            --
│    └─Empty: 2-481                      [64, 64, 3, 3]            --
│    └─Empty: 2-482                      [64]                      --
│    └─Empty: 2-483                      [64]                      --
│    └─BatchNorm2d: 2-484                [16, 64, 64, 64]          --
│    └─Scaler: 2-485                     [16, 64, 64, 64]          --
│    └─ReLU: 2-486                       [16, 64, 64, 64]          --
│    └─Empty: 2-487                      [16, 64, 64, 64]          --
│    └─Clamp: 2-488                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-489         --                        --
│    └─One: 2-490                        [1]                       --
│    └─OutputScale: 2-491                --                        --
│    └─Empty: 2-492                      [64, 64, 1, 1]            --
│    └─Empty: 2-493                      [64, 64, 1, 1]            --
│    └─Empty: 2-494                      [64]                      --
│    └─Empty: 2-495                      [64]                      --
│    └─BatchNorm2d: 2-496                [16, 64, 64, 64]          --
│    └─Scaler: 2-497                     [16, 64, 64, 64]          --
│    └─ReLU: 2-498                       [16, 64, 64, 64]          --
│    └─Empty: 2-499                      [16, 64, 64, 64]          --
│    └─Clamp: 2-500                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-501         --                        --
│    └─One: 2-502                        [1]                       --
│    └─OutputScale: 2-503                --                        --
│    └─Empty: 2-504                      [64, 64, 3, 3]            --
│    └─Empty: 2-505                      [64, 64, 3, 3]            --
│    └─Empty: 2-506                      [64]                      --
│    └─Empty: 2-507                      [64]                      --
│    └─BatchNorm2d: 2-508                [16, 64, 64, 64]          --
│    └─Scaler: 2-509                     [16, 64, 64, 64]          --
│    └─ReLU: 2-510                       [16, 64, 64, 64]          --
│    └─Empty: 2-511                      [16, 64, 64, 64]          --
│    └─Clamp: 2-512                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-513                  [16, 64, 32, 32]          --
│    └─Empty: 2-514                      [16, 64, 32, 32]          --
│    └─Empty: 2-515                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-516         --                        --
│    └─One: 2-517                        [1]                       --
│    └─OutputScale: 2-518                --                        --
│    └─Empty: 2-519                      [64, 64, 3, 3]            --
│    └─Empty: 2-520                      [64, 64, 3, 3]            --
│    └─Empty: 2-521                      [64]                      --
│    └─Empty: 2-522                      [64]                      --
│    └─BatchNorm2d: 2-523                [16, 64, 32, 32]          --
│    └─Scaler: 2-524                     [16, 64, 32, 32]          --
│    └─ReLU: 2-525                       [16, 64, 32, 32]          --
│    └─Empty: 2-526                      [16, 64, 32, 32]          --
│    └─Clamp: 2-527                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-528         --                        --
│    └─One: 2-529                        [1]                       --
│    └─OutputScale: 2-530                --                        --
│    └─Empty: 2-531                      [64, 64, 3, 3]            --
│    └─Empty: 2-532                      [64, 64, 3, 3]            --
│    └─Empty: 2-533                      [64]                      --
│    └─Empty: 2-534                      [64]                      --
│    └─BatchNorm2d: 2-535                [16, 64, 32, 32]          --
│    └─Scaler: 2-536                     [16, 64, 32, 32]          --
│    └─ReLU: 2-537                       [16, 64, 32, 32]          --
│    └─Empty: 2-538                      [16, 64, 32, 32]          --
│    └─Clamp: 2-539                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-540                  [16, 64, 16, 16]          --
│    └─Empty: 2-541                      [16, 64, 16, 16]          --
│    └─Empty: 2-542                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-543         --                        --
│    └─One: 2-544                        [1]                       --
│    └─OutputScale: 2-545                --                        --
│    └─Empty: 2-546                      [64, 64, 3, 3]            --
│    └─Empty: 2-547                      [64, 64, 3, 3]            --
│    └─Empty: 2-548                      [64]                      --
│    └─Empty: 2-549                      [64]                      --
│    └─BatchNorm2d: 2-550                [16, 64, 16, 16]          --
│    └─Scaler: 2-551                     [16, 64, 16, 16]          --
│    └─ReLU: 2-552                       [16, 64, 16, 16]          --
│    └─Empty: 2-553                      [16, 64, 16, 16]          --
│    └─Clamp: 2-554                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-555         --                        --
│    └─One: 2-556                        [1]                       --
│    └─OutputScale: 2-557                --                        --
│    └─Empty: 2-558                      [64, 64, 3, 3]            --
│    └─Empty: 2-559                      [64, 64, 3, 3]            --
│    └─Empty: 2-560                      [64]                      --
│    └─Empty: 2-561                      [64]                      --
│    └─BatchNorm2d: 2-562                [16, 64, 16, 16]          --
│    └─Scaler: 2-563                     [16, 64, 16, 16]          --
│    └─ReLU: 2-564                       [16, 64, 16, 16]          --
│    └─Empty: 2-565                      [16, 64, 16, 16]          --
│    └─Clamp: 2-566                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-567                  [16, 64, 8, 8]            --
│    └─Empty: 2-568                      [16, 64, 8, 8]            --
│    └─Empty: 2-569                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-570         --                        --
│    └─One: 2-571                        [1]                       --
│    └─OutputScale: 2-572                --                        --
│    └─Empty: 2-573                      [64, 64, 3, 3]            --
│    └─Empty: 2-574                      [64, 64, 3, 3]            --
│    └─Empty: 2-575                      [64]                      --
│    └─Empty: 2-576                      [64]                      --
│    └─BatchNorm2d: 2-577                [16, 64, 8, 8]            --
│    └─Scaler: 2-578                     [16, 64, 8, 8]            --
│    └─ReLU: 2-579                       [16, 64, 8, 8]            --
│    └─Empty: 2-580                      [16, 64, 8, 8]            --
│    └─Clamp: 2-581                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-582         --                        --
│    └─One: 2-583                        [1]                       --
│    └─OutputScale: 2-584                --                        --
│    └─Empty: 2-585                      [64, 64, 1, 1]            --
│    └─Empty: 2-586                      [64, 64, 1, 1]            --
│    └─Empty: 2-587                      [64]                      --
│    └─Empty: 2-588                      [64]                      --
│    └─BatchNorm2d: 2-589                [16, 64, 8, 8]            --
│    └─Scaler: 2-590                     [16, 64, 8, 8]            --
│    └─ReLU: 2-591                       [16, 64, 8, 8]            --
│    └─Empty: 2-592                      [16, 64, 8, 8]            --
│    └─Clamp: 2-593                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-594                  [16, 64, 8, 8]            --
│    └─Empty: 2-595                      [16, 64, 8, 8]            --
│    └─Empty: 2-596                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-597         --                        --
│    └─One: 2-598                        [1]                       --
│    └─OutputScale: 2-599                --                        --
│    └─Empty: 2-600                      [64, 64, 3, 3]            --
│    └─Empty: 2-601                      [64, 64, 3, 3]            --
│    └─Empty: 2-602                      [64]                      --
│    └─Empty: 2-603                      [64]                      --
│    └─BatchNorm2d: 2-604                [16, 64, 8, 8]            --
│    └─Scaler: 2-605                     [16, 64, 8, 8]            --
│    └─ReLU: 2-606                       [16, 64, 8, 8]            --
│    └─Empty: 2-607                      [16, 64, 8, 8]            --
│    └─Clamp: 2-608                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-609                  [16, 64, 4, 4]            --
│    └─Empty: 2-610                      [16, 64, 4, 4]            --
│    └─Empty: 2-611                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-612         --                        --
│    └─One: 2-613                        [1]                       --
│    └─OutputScale: 2-614                --                        --
│    └─Empty: 2-615                      [64, 64, 3, 3]            --
│    └─Empty: 2-616                      [64, 64, 3, 3]            --
│    └─Empty: 2-617                      [64]                      --
│    └─Empty: 2-618                      [64]                      --
│    └─BatchNorm2d: 2-619                [16, 64, 4, 4]            --
│    └─Scaler: 2-620                     [16, 64, 4, 4]            --
│    └─ReLU: 2-621                       [16, 64, 4, 4]            --
│    └─Empty: 2-622                      [16, 64, 4, 4]            --
│    └─Clamp: 2-623                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-624         --                        --
│    └─One: 2-625                        [1]                       --
│    └─OutputScale: 2-626                --                        --
│    └─Empty: 2-627                      [64, 64, 1, 1]            --
│    └─Empty: 2-628                      [64, 64, 1, 1]            --
│    └─Empty: 2-629                      [64]                      --
│    └─Empty: 2-630                      [64]                      --
│    └─BatchNorm2d: 2-631                [16, 64, 4, 4]            --
│    └─Scaler: 2-632                     [16, 64, 4, 4]            --
│    └─ReLU: 2-633                       [16, 64, 4, 4]            --
│    └─Empty: 2-634                      [16, 64, 4, 4]            --
│    └─Clamp: 2-635                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-636                  [16, 64, 4, 4]            --
│    └─Empty: 2-637                      [16, 64, 4, 4]            --
│    └─Empty: 2-638                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-639         --                        --
│    └─One: 2-640                        [1]                       --
│    └─OutputScale: 2-641                --                        --
│    └─Empty: 2-642                      [64, 64, 3, 3]            --
│    └─Empty: 2-643                      [64, 64, 3, 3]            --
│    └─Empty: 2-644                      [64]                      --
│    └─Empty: 2-645                      [64]                      --
│    └─BatchNorm2d: 2-646                [16, 64, 4, 4]            --
│    └─Scaler: 2-647                     [16, 64, 4, 4]            --
│    └─ReLU: 2-648                       [16, 64, 4, 4]            --
│    └─Empty: 2-649                      [16, 64, 4, 4]            --
│    └─Clamp: 2-650                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-651                  [16, 64, 2, 2]            --
│    └─Empty: 2-652                      [16, 64, 2, 2]            --
│    └─Empty: 2-653                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-654         --                        --
│    └─One: 2-655                        [1]                       --
│    └─OutputScale: 2-656                --                        --
│    └─Empty: 2-657                      [64, 64, 1, 1]            --
│    └─Empty: 2-658                      [64, 64, 1, 1]            --
│    └─Empty: 2-659                      [64]                      --
│    └─Empty: 2-660                      [64]                      --
│    └─BatchNorm2d: 2-661                [16, 64, 2, 2]            --
│    └─Scaler: 2-662                     [16, 64, 2, 2]            --
│    └─ReLU: 2-663                       [16, 64, 2, 2]            --
│    └─Empty: 2-664                      [16, 64, 2, 2]            --
│    └─Clamp: 2-665                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-666         --                        --
│    └─One: 2-667                        [1]                       --
│    └─OutputScale: 2-668                --                        --
│    └─Empty: 2-669                      [64, 64, 1, 1]            --
│    └─Empty: 2-670                      [64, 64, 1, 1]            --
│    └─Empty: 2-671                      [64]                      --
│    └─Empty: 2-672                      [64]                      --
│    └─BatchNorm2d: 2-673                [16, 64, 2, 2]            --
│    └─Scaler: 2-674                     [16, 64, 2, 2]            --
│    └─ReLU: 2-675                       [16, 64, 2, 2]            --
│    └─Empty: 2-676                      [16, 64, 2, 2]            --
│    └─Clamp: 2-677                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-678                  [16, 64, 2, 2]            --
│    └─Empty: 2-679                      [16, 64, 2, 2]            --
│    └─Empty: 2-680                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-681         --                        --
│    └─One: 2-682                        [1]                       --
│    └─OutputScale: 2-683                --                        --
│    └─Empty: 2-684                      [64, 64, 3, 3]            --
│    └─Empty: 2-685                      [64, 64, 3, 3]            --
│    └─Empty: 2-686                      [64]                      --
│    └─Empty: 2-687                      [64]                      --
│    └─BatchNorm2d: 2-688                [16, 64, 2, 2]            --
│    └─Scaler: 2-689                     [16, 64, 2, 2]            --
│    └─ReLU: 2-690                       [16, 64, 2, 2]            --
│    └─Empty: 2-691                      [16, 64, 2, 2]            --
│    └─Clamp: 2-692                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-693         --                        --
│    └─One: 2-694                        [1]                       --
│    └─OutputScale: 2-695                --                        --
│    └─Empty: 2-696                      [64, 48, 1, 1]            --
│    └─Empty: 2-697                      [64, 48, 1, 1]            --
│    └─Empty: 2-698                      [64]                      --
│    └─Empty: 2-699                      [64]                      --
│    └─BatchNorm2d: 2-700                [16, 64, 64, 64]          --
│    └─Scaler: 2-701                     [16, 64, 64, 64]          --
│    └─ReLU: 2-702                       [16, 64, 64, 64]          --
│    └─Empty: 2-703                      [16, 64, 64, 64]          --
│    └─Clamp: 2-704                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-705         --                        --
│    └─One: 2-706                        [1]                       --
│    └─OutputScale: 2-707                --                        --
│    └─Empty: 2-708                      [64, 64, 3, 3]            --
│    └─Empty: 2-709                      [64, 64, 3, 3]            --
│    └─Empty: 2-710                      [64]                      --
│    └─Empty: 2-711                      [64]                      --
│    └─BatchNorm2d: 2-712                [16, 64, 64, 64]          --
│    └─Scaler: 2-713                     [16, 64, 64, 64]          --
│    └─ReLU: 2-714                       [16, 64, 64, 64]          --
│    └─Empty: 2-715                      [16, 64, 64, 64]          --
│    └─Clamp: 2-716                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-717         --                        --
│    └─One: 2-718                        [1]                       --
│    └─OutputScale: 2-719                --                        --
│    └─Empty: 2-720                      [64, 64, 1, 1]            --
│    └─Empty: 2-721                      [64, 64, 1, 1]            --
│    └─Empty: 2-722                      [64]                      --
│    └─Empty: 2-723                      [64]                      --
│    └─BatchNorm2d: 2-724                [16, 64, 64, 64]          --
│    └─Scaler: 2-725                     [16, 64, 64, 64]          --
│    └─ReLU: 2-726                       [16, 64, 64, 64]          --
│    └─Empty: 2-727                      [16, 64, 64, 64]          --
│    └─Clamp: 2-728                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-729         --                        --
│    └─One: 2-730                        [1]                       --
│    └─OutputScale: 2-731                --                        --
│    └─Empty: 2-732                      [64, 64, 3, 3]            --
│    └─Empty: 2-733                      [64, 64, 3, 3]            --
│    └─Empty: 2-734                      [64]                      --
│    └─Empty: 2-735                      [64]                      --
│    └─BatchNorm2d: 2-736                [16, 64, 64, 64]          --
│    └─Scaler: 2-737                     [16, 64, 64, 64]          --
│    └─ReLU: 2-738                       [16, 64, 64, 64]          --
│    └─Empty: 2-739                      [16, 64, 64, 64]          --
│    └─Clamp: 2-740                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-741                  [16, 64, 32, 32]          --
│    └─Empty: 2-742                      [16, 64, 32, 32]          --
│    └─Empty: 2-743                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-744         --                        --
│    └─One: 2-745                        [1]                       --
│    └─OutputScale: 2-746                --                        --
│    └─Empty: 2-747                      [64, 64, 3, 3]            --
│    └─Empty: 2-748                      [64, 64, 3, 3]            --
│    └─Empty: 2-749                      [64]                      --
│    └─Empty: 2-750                      [64]                      --
│    └─BatchNorm2d: 2-751                [16, 64, 32, 32]          --
│    └─Scaler: 2-752                     [16, 64, 32, 32]          --
│    └─ReLU: 2-753                       [16, 64, 32, 32]          --
│    └─Empty: 2-754                      [16, 64, 32, 32]          --
│    └─Clamp: 2-755                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-756         --                        --
│    └─One: 2-757                        [1]                       --
│    └─OutputScale: 2-758                --                        --
│    └─Empty: 2-759                      [64, 64, 3, 3]            --
│    └─Empty: 2-760                      [64, 64, 3, 3]            --
│    └─Empty: 2-761                      [64]                      --
│    └─Empty: 2-762                      [64]                      --
│    └─BatchNorm2d: 2-763                [16, 64, 32, 32]          --
│    └─Scaler: 2-764                     [16, 64, 32, 32]          --
│    └─ReLU: 2-765                       [16, 64, 32, 32]          --
│    └─Empty: 2-766                      [16, 64, 32, 32]          --
│    └─Clamp: 2-767                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-768                  [16, 64, 16, 16]          --
│    └─Empty: 2-769                      [16, 64, 16, 16]          --
│    └─Empty: 2-770                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-771         --                        --
│    └─One: 2-772                        [1]                       --
│    └─OutputScale: 2-773                --                        --
│    └─Empty: 2-774                      [64, 64, 3, 3]            --
│    └─Empty: 2-775                      [64, 64, 3, 3]            --
│    └─Empty: 2-776                      [64]                      --
│    └─Empty: 2-777                      [64]                      --
│    └─BatchNorm2d: 2-778                [16, 64, 16, 16]          --
│    └─Scaler: 2-779                     [16, 64, 16, 16]          --
│    └─ReLU: 2-780                       [16, 64, 16, 16]          --
│    └─Empty: 2-781                      [16, 64, 16, 16]          --
│    └─Clamp: 2-782                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [64, 64, 3, 3]            --
│    └─Empty: 2-787                      [64, 64, 3, 3]            --
│    └─Empty: 2-788                      [64]                      --
│    └─Empty: 2-789                      [64]                      --
│    └─BatchNorm2d: 2-790                [16, 64, 16, 16]          --
│    └─Scaler: 2-791                     [16, 64, 16, 16]          --
│    └─ReLU: 2-792                       [16, 64, 16, 16]          --
│    └─Empty: 2-793                      [16, 64, 16, 16]          --
│    └─Clamp: 2-794                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-795                  [16, 64, 8, 8]            --
│    └─Empty: 2-796                      [16, 64, 8, 8]            --
│    └─Empty: 2-797                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-798         --                        --
│    └─One: 2-799                        [1]                       --
│    └─OutputScale: 2-800                --                        --
│    └─Empty: 2-801                      [64, 64, 3, 3]            --
│    └─Empty: 2-802                      [64, 64, 3, 3]            --
│    └─Empty: 2-803                      [64]                      --
│    └─Empty: 2-804                      [64]                      --
│    └─BatchNorm2d: 2-805                [16, 64, 8, 8]            --
│    └─Scaler: 2-806                     [16, 64, 8, 8]            --
│    └─ReLU: 2-807                       [16, 64, 8, 8]            --
│    └─Empty: 2-808                      [16, 64, 8, 8]            --
│    └─Clamp: 2-809                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [64, 64, 1, 1]            --
│    └─Empty: 2-814                      [64, 64, 1, 1]            --
│    └─Empty: 2-815                      [64]                      --
│    └─Empty: 2-816                      [64]                      --
│    └─BatchNorm2d: 2-817                [16, 64, 8, 8]            --
│    └─Scaler: 2-818                     [16, 64, 8, 8]            --
│    └─ReLU: 2-819                       [16, 64, 8, 8]            --
│    └─Empty: 2-820                      [16, 64, 8, 8]            --
│    └─Clamp: 2-821                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-822                  [16, 64, 8, 8]            --
│    └─Empty: 2-823                      [16, 64, 8, 8]            --
│    └─Empty: 2-824                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-825         --                        --
│    └─One: 2-826                        [1]                       --
│    └─OutputScale: 2-827                --                        --
│    └─Empty: 2-828                      [64, 64, 3, 3]            --
│    └─Empty: 2-829                      [64, 64, 3, 3]            --
│    └─Empty: 2-830                      [64]                      --
│    └─Empty: 2-831                      [64]                      --
│    └─BatchNorm2d: 2-832                [16, 64, 8, 8]            --
│    └─Scaler: 2-833                     [16, 64, 8, 8]            --
│    └─ReLU: 2-834                       [16, 64, 8, 8]            --
│    └─Empty: 2-835                      [16, 64, 8, 8]            --
│    └─Clamp: 2-836                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-837                  [16, 64, 4, 4]            --
│    └─Empty: 2-838                      [16, 64, 4, 4]            --
│    └─Empty: 2-839                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-840         --                        --
│    └─One: 2-841                        [1]                       --
│    └─OutputScale: 2-842                --                        --
│    └─Empty: 2-843                      [64, 64, 3, 3]            --
│    └─Empty: 2-844                      [64, 64, 3, 3]            --
│    └─Empty: 2-845                      [64]                      --
│    └─Empty: 2-846                      [64]                      --
│    └─BatchNorm2d: 2-847                [16, 64, 4, 4]            --
│    └─Scaler: 2-848                     [16, 64, 4, 4]            --
│    └─ReLU: 2-849                       [16, 64, 4, 4]            --
│    └─Empty: 2-850                      [16, 64, 4, 4]            --
│    └─Clamp: 2-851                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-852         --                        --
│    └─One: 2-853                        [1]                       --
│    └─OutputScale: 2-854                --                        --
│    └─Empty: 2-855                      [64, 64, 1, 1]            --
│    └─Empty: 2-856                      [64, 64, 1, 1]            --
│    └─Empty: 2-857                      [64]                      --
│    └─Empty: 2-858                      [64]                      --
│    └─BatchNorm2d: 2-859                [16, 64, 4, 4]            --
│    └─Scaler: 2-860                     [16, 64, 4, 4]            --
│    └─ReLU: 2-861                       [16, 64, 4, 4]            --
│    └─Empty: 2-862                      [16, 64, 4, 4]            --
│    └─Clamp: 2-863                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-864                  [16, 64, 4, 4]            --
│    └─Empty: 2-865                      [16, 64, 4, 4]            --
│    └─Empty: 2-866                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-867         --                        --
│    └─One: 2-868                        [1]                       --
│    └─OutputScale: 2-869                --                        --
│    └─Empty: 2-870                      [64, 64, 3, 3]            --
│    └─Empty: 2-871                      [64, 64, 3, 3]            --
│    └─Empty: 2-872                      [64]                      --
│    └─Empty: 2-873                      [64]                      --
│    └─BatchNorm2d: 2-874                [16, 64, 4, 4]            --
│    └─Scaler: 2-875                     [16, 64, 4, 4]            --
│    └─ReLU: 2-876                       [16, 64, 4, 4]            --
│    └─Empty: 2-877                      [16, 64, 4, 4]            --
│    └─Clamp: 2-878                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-879                  [16, 64, 2, 2]            --
│    └─Empty: 2-880                      [16, 64, 2, 2]            --
│    └─Empty: 2-881                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-882         --                        --
│    └─One: 2-883                        [1]                       --
│    └─OutputScale: 2-884                --                        --
│    └─Empty: 2-885                      [64, 64, 1, 1]            --
│    └─Empty: 2-886                      [64, 64, 1, 1]            --
│    └─Empty: 2-887                      [64]                      --
│    └─Empty: 2-888                      [64]                      --
│    └─BatchNorm2d: 2-889                [16, 64, 2, 2]            --
│    └─Scaler: 2-890                     [16, 64, 2, 2]            --
│    └─ReLU: 2-891                       [16, 64, 2, 2]            --
│    └─Empty: 2-892                      [16, 64, 2, 2]            --
│    └─Clamp: 2-893                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-894         --                        --
│    └─One: 2-895                        [1]                       --
│    └─OutputScale: 2-896                --                        --
│    └─Empty: 2-897                      [64, 64, 1, 1]            --
│    └─Empty: 2-898                      [64, 64, 1, 1]            --
│    └─Empty: 2-899                      [64]                      --
│    └─Empty: 2-900                      [64]                      --
│    └─BatchNorm2d: 2-901                [16, 64, 2, 2]            --
│    └─Scaler: 2-902                     [16, 64, 2, 2]            --
│    └─ReLU: 2-903                       [16, 64, 2, 2]            --
│    └─Empty: 2-904                      [16, 64, 2, 2]            --
│    └─Clamp: 2-905                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-906                  [16, 64, 2, 2]            --
│    └─Empty: 2-907                      [16, 64, 2, 2]            --
│    └─Empty: 2-908                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-909         --                        --
│    └─One: 2-910                        [1]                       --
│    └─OutputScale: 2-911                --                        --
│    └─Empty: 2-912                      [64, 64, 3, 3]            --
│    └─Empty: 2-913                      [64, 64, 3, 3]            --
│    └─Empty: 2-914                      [64]                      --
│    └─Empty: 2-915                      [64]                      --
│    └─BatchNorm2d: 2-916                [16, 64, 2, 2]            --
│    └─Scaler: 2-917                     [16, 64, 2, 2]            --
│    └─ReLU: 2-918                       [16, 64, 2, 2]            --
│    └─Empty: 2-919                      [16, 64, 2, 2]            --
│    └─Clamp: 2-920                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [64, 48, 1, 1]            --
│    └─Empty: 2-925                      [64, 48, 1, 1]            --
│    └─Empty: 2-926                      [64]                      --
│    └─Empty: 2-927                      [64]                      --
│    └─BatchNorm2d: 2-928                [16, 64, 64, 64]          --
│    └─Scaler: 2-929                     [16, 64, 64, 64]          --
│    └─ReLU: 2-930                       [16, 64, 64, 64]          --
│    └─Empty: 2-931                      [16, 64, 64, 64]          --
│    └─Clamp: 2-932                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [64, 64, 3, 3]            --
│    └─Empty: 2-937                      [64, 64, 3, 3]            --
│    └─Empty: 2-938                      [64]                      --
│    └─Empty: 2-939                      [64]                      --
│    └─BatchNorm2d: 2-940                [16, 64, 64, 64]          --
│    └─Scaler: 2-941                     [16, 64, 64, 64]          --
│    └─ReLU: 2-942                       [16, 64, 64, 64]          --
│    └─Empty: 2-943                      [16, 64, 64, 64]          --
│    └─Clamp: 2-944                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-945         --                        --
│    └─One: 2-946                        [1]                       --
│    └─OutputScale: 2-947                --                        --
│    └─Empty: 2-948                      [64, 64, 1, 1]            --
│    └─Empty: 2-949                      [64, 64, 1, 1]            --
│    └─Empty: 2-950                      [64]                      --
│    └─Empty: 2-951                      [64]                      --
│    └─BatchNorm2d: 2-952                [16, 64, 64, 64]          --
│    └─Scaler: 2-953                     [16, 64, 64, 64]          --
│    └─ReLU: 2-954                       [16, 64, 64, 64]          --
│    └─Empty: 2-955                      [16, 64, 64, 64]          --
│    └─Clamp: 2-956                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-957         --                        --
│    └─One: 2-958                        [1]                       --
│    └─OutputScale: 2-959                --                        --
│    └─Empty: 2-960                      [64, 64, 3, 3]            --
│    └─Empty: 2-961                      [64, 64, 3, 3]            --
│    └─Empty: 2-962                      [64]                      --
│    └─Empty: 2-963                      [64]                      --
│    └─BatchNorm2d: 2-964                [16, 64, 64, 64]          --
│    └─Scaler: 2-965                     [16, 64, 64, 64]          --
│    └─ReLU: 2-966                       [16, 64, 64, 64]          --
│    └─Empty: 2-967                      [16, 64, 64, 64]          --
│    └─Clamp: 2-968                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-969                  [16, 64, 32, 32]          --
│    └─Empty: 2-970                      [16, 64, 32, 32]          --
│    └─Empty: 2-971                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-972         --                        --
│    └─One: 2-973                        [1]                       --
│    └─OutputScale: 2-974                --                        --
│    └─Empty: 2-975                      [64, 64, 3, 3]            --
│    └─Empty: 2-976                      [64, 64, 3, 3]            --
│    └─Empty: 2-977                      [64]                      --
│    └─Empty: 2-978                      [64]                      --
│    └─BatchNorm2d: 2-979                [16, 64, 32, 32]          --
│    └─Scaler: 2-980                     [16, 64, 32, 32]          --
│    └─ReLU: 2-981                       [16, 64, 32, 32]          --
│    └─Empty: 2-982                      [16, 64, 32, 32]          --
│    └─Clamp: 2-983                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-984         --                        --
│    └─One: 2-985                        [1]                       --
│    └─OutputScale: 2-986                --                        --
│    └─Empty: 2-987                      [64, 64, 3, 3]            --
│    └─Empty: 2-988                      [64, 64, 3, 3]            --
│    └─Empty: 2-989                      [64]                      --
│    └─Empty: 2-990                      [64]                      --
│    └─BatchNorm2d: 2-991                [16, 64, 32, 32]          --
│    └─Scaler: 2-992                     [16, 64, 32, 32]          --
│    └─ReLU: 2-993                       [16, 64, 32, 32]          --
│    └─Empty: 2-994                      [16, 64, 32, 32]          --
│    └─Clamp: 2-995                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-996                  [16, 64, 16, 16]          --
│    └─Empty: 2-997                      [16, 64, 16, 16]          --
│    └─Empty: 2-998                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-999         --                        --
│    └─One: 2-1000                       [1]                       --
│    └─OutputScale: 2-1001               --                        --
│    └─Empty: 2-1002                     [64, 64, 3, 3]            --
│    └─Empty: 2-1003                     [64, 64, 3, 3]            --
│    └─Empty: 2-1004                     [64]                      --
│    └─Empty: 2-1005                     [64]                      --
│    └─BatchNorm2d: 2-1006               [16, 64, 16, 16]          --
│    └─Scaler: 2-1007                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1008                      [16, 64, 16, 16]          --
│    └─Empty: 2-1009                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1010                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1011        --                        --
│    └─One: 2-1012                       [1]                       --
│    └─OutputScale: 2-1013               --                        --
│    └─Empty: 2-1014                     [64, 64, 3, 3]            --
│    └─Empty: 2-1015                     [64, 64, 3, 3]            --
│    └─Empty: 2-1016                     [64]                      --
│    └─Empty: 2-1017                     [64]                      --
│    └─BatchNorm2d: 2-1018               [16, 64, 16, 16]          --
│    └─Scaler: 2-1019                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1020                      [16, 64, 16, 16]          --
│    └─Empty: 2-1021                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1022                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1023                 [16, 64, 8, 8]            --
│    └─Empty: 2-1024                     [16, 64, 8, 8]            --
│    └─Empty: 2-1025                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1026        --                        --
│    └─One: 2-1027                       [1]                       --
│    └─OutputScale: 2-1028               --                        --
│    └─Empty: 2-1029                     [64, 64, 3, 3]            --
│    └─Empty: 2-1030                     [64, 64, 3, 3]            --
│    └─Empty: 2-1031                     [64]                      --
│    └─Empty: 2-1032                     [64]                      --
│    └─BatchNorm2d: 2-1033               [16, 64, 8, 8]            --
│    └─Scaler: 2-1034                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1035                      [16, 64, 8, 8]            --
│    └─Empty: 2-1036                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1037                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1038        --                        --
│    └─One: 2-1039                       [1]                       --
│    └─OutputScale: 2-1040               --                        --
│    └─Empty: 2-1041                     [64, 64, 1, 1]            --
│    └─Empty: 2-1042                     [64, 64, 1, 1]            --
│    └─Empty: 2-1043                     [64]                      --
│    └─Empty: 2-1044                     [64]                      --
│    └─BatchNorm2d: 2-1045               [16, 64, 8, 8]            --
│    └─Scaler: 2-1046                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1047                      [16, 64, 8, 8]            --
│    └─Empty: 2-1048                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1049                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1050                 [16, 64, 8, 8]            --
│    └─Empty: 2-1051                     [16, 64, 8, 8]            --
│    └─Empty: 2-1052                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1053        --                        --
│    └─One: 2-1054                       [1]                       --
│    └─OutputScale: 2-1055               --                        --
│    └─Empty: 2-1056                     [64, 64, 3, 3]            --
│    └─Empty: 2-1057                     [64, 64, 3, 3]            --
│    └─Empty: 2-1058                     [64]                      --
│    └─Empty: 2-1059                     [64]                      --
│    └─BatchNorm2d: 2-1060               [16, 64, 8, 8]            --
│    └─Scaler: 2-1061                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1062                      [16, 64, 8, 8]            --
│    └─Empty: 2-1063                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1064                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1065                 [16, 64, 4, 4]            --
│    └─Empty: 2-1066                     [16, 64, 4, 4]            --
│    └─Empty: 2-1067                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1068        --                        --
│    └─One: 2-1069                       [1]                       --
│    └─OutputScale: 2-1070               --                        --
│    └─Empty: 2-1071                     [64, 64, 3, 3]            --
│    └─Empty: 2-1072                     [64, 64, 3, 3]            --
│    └─Empty: 2-1073                     [64]                      --
│    └─Empty: 2-1074                     [64]                      --
│    └─BatchNorm2d: 2-1075               [16, 64, 4, 4]            --
│    └─Scaler: 2-1076                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1077                      [16, 64, 4, 4]            --
│    └─Empty: 2-1078                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1079                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1080        --                        --
│    └─One: 2-1081                       [1]                       --
│    └─OutputScale: 2-1082               --                        --
│    └─Empty: 2-1083                     [64, 64, 1, 1]            --
│    └─Empty: 2-1084                     [64, 64, 1, 1]            --
│    └─Empty: 2-1085                     [64]                      --
│    └─Empty: 2-1086                     [64]                      --
│    └─BatchNorm2d: 2-1087               [16, 64, 4, 4]            --
│    └─Scaler: 2-1088                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1089                      [16, 64, 4, 4]            --
│    └─Empty: 2-1090                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1091                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1092                 [16, 64, 4, 4]            --
│    └─Empty: 2-1093                     [16, 64, 4, 4]            --
│    └─Empty: 2-1094                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1095        --                        --
│    └─One: 2-1096                       [1]                       --
│    └─OutputScale: 2-1097               --                        --
│    └─Empty: 2-1098                     [64, 64, 3, 3]            --
│    └─Empty: 2-1099                     [64, 64, 3, 3]            --
│    └─Empty: 2-1100                     [64]                      --
│    └─Empty: 2-1101                     [64]                      --
│    └─BatchNorm2d: 2-1102               [16, 64, 4, 4]            --
│    └─Scaler: 2-1103                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1104                      [16, 64, 4, 4]            --
│    └─Empty: 2-1105                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1106                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1107                 [16, 64, 2, 2]            --
│    └─Empty: 2-1108                     [16, 64, 2, 2]            --
│    └─Empty: 2-1109                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1110        --                        --
│    └─One: 2-1111                       [1]                       --
│    └─OutputScale: 2-1112               --                        --
│    └─Empty: 2-1113                     [64, 64, 1, 1]            --
│    └─Empty: 2-1114                     [64, 64, 1, 1]            --
│    └─Empty: 2-1115                     [64]                      --
│    └─Empty: 2-1116                     [64]                      --
│    └─BatchNorm2d: 2-1117               [16, 64, 2, 2]            --
│    └─Scaler: 2-1118                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1119                      [16, 64, 2, 2]            --
│    └─Empty: 2-1120                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1121                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1122        --                        --
│    └─One: 2-1123                       [1]                       --
│    └─OutputScale: 2-1124               --                        --
│    └─Empty: 2-1125                     [64, 64, 1, 1]            --
│    └─Empty: 2-1126                     [64, 64, 1, 1]            --
│    └─Empty: 2-1127                     [64]                      --
│    └─Empty: 2-1128                     [64]                      --
│    └─BatchNorm2d: 2-1129               [16, 64, 2, 2]            --
│    └─Scaler: 2-1130                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1131                      [16, 64, 2, 2]            --
│    └─Empty: 2-1132                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1133                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1134                 [16, 64, 2, 2]            --
│    └─Empty: 2-1135                     [16, 64, 2, 2]            --
│    └─Empty: 2-1136                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1137        --                        --
│    └─One: 2-1138                       [1]                       --
│    └─OutputScale: 2-1139               --                        --
│    └─Empty: 2-1140                     [64, 64, 3, 3]            --
│    └─Empty: 2-1141                     [64, 64, 3, 3]            --
│    └─Empty: 2-1142                     [64]                      --
│    └─Empty: 2-1143                     [64]                      --
│    └─BatchNorm2d: 2-1144               [16, 64, 2, 2]            --
│    └─Scaler: 2-1145                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1146                      [16, 64, 2, 2]            --
│    └─Empty: 2-1147                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1148                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1149        --                        --
│    └─One: 2-1150                       [1]                       --
│    └─OutputScale: 2-1151               --                        --
│    └─Empty: 2-1152                     [64, 48, 1, 1]            --
│    └─Empty: 2-1153                     [64, 48, 1, 1]            --
│    └─Empty: 2-1154                     [64]                      --
│    └─Empty: 2-1155                     [64]                      --
│    └─BatchNorm2d: 2-1156               [16, 64, 64, 64]          --
│    └─Scaler: 2-1157                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1158                      [16, 64, 64, 64]          --
│    └─Empty: 2-1159                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1160                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1161        --                        --
│    └─One: 2-1162                       [1]                       --
│    └─OutputScale: 2-1163               --                        --
│    └─Empty: 2-1164                     [64, 64, 3, 3]            --
│    └─Empty: 2-1165                     [64, 64, 3, 3]            --
│    └─Empty: 2-1166                     [64]                      --
│    └─Empty: 2-1167                     [64]                      --
│    └─BatchNorm2d: 2-1168               [16, 64, 64, 64]          --
│    └─Scaler: 2-1169                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1170                      [16, 64, 64, 64]          --
│    └─Empty: 2-1171                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1172                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1173        --                        --
│    └─One: 2-1174                       [1]                       --
│    └─OutputScale: 2-1175               --                        --
│    └─Empty: 2-1176                     [64, 64, 1, 1]            --
│    └─Empty: 2-1177                     [64, 64, 1, 1]            --
│    └─Empty: 2-1178                     [64]                      --
│    └─Empty: 2-1179                     [64]                      --
│    └─BatchNorm2d: 2-1180               [16, 64, 64, 64]          --
│    └─Scaler: 2-1181                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1182                      [16, 64, 64, 64]          --
│    └─Empty: 2-1183                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1184                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1185        --                        --
│    └─One: 2-1186                       [1]                       --
│    └─OutputScale: 2-1187               --                        --
│    └─Empty: 2-1188                     [64, 64, 3, 3]            --
│    └─Empty: 2-1189                     [64, 64, 3, 3]            --
│    └─Empty: 2-1190                     [64]                      --
│    └─Empty: 2-1191                     [64]                      --
│    └─BatchNorm2d: 2-1192               [16, 64, 64, 64]          --
│    └─Scaler: 2-1193                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1194                      [16, 64, 64, 64]          --
│    └─Empty: 2-1195                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1196                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1197                 [16, 64, 32, 32]          --
│    └─Empty: 2-1198                     [16, 64, 32, 32]          --
│    └─Empty: 2-1199                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1200        --                        --
│    └─One: 2-1201                       [1]                       --
│    └─OutputScale: 2-1202               --                        --
│    └─Empty: 2-1203                     [64, 64, 3, 3]            --
│    └─Empty: 2-1204                     [64, 64, 3, 3]            --
│    └─Empty: 2-1205                     [64]                      --
│    └─Empty: 2-1206                     [64]                      --
│    └─BatchNorm2d: 2-1207               [16, 64, 32, 32]          --
│    └─Scaler: 2-1208                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1209                      [16, 64, 32, 32]          --
│    └─Empty: 2-1210                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1211                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1212        --                        --
│    └─One: 2-1213                       [1]                       --
│    └─OutputScale: 2-1214               --                        --
│    └─Empty: 2-1215                     [64, 64, 3, 3]            --
│    └─Empty: 2-1216                     [64, 64, 3, 3]            --
│    └─Empty: 2-1217                     [64]                      --
│    └─Empty: 2-1218                     [64]                      --
│    └─BatchNorm2d: 2-1219               [16, 64, 32, 32]          --
│    └─Scaler: 2-1220                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1221                      [16, 64, 32, 32]          --
│    └─Empty: 2-1222                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1223                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1224                 [16, 64, 16, 16]          --
│    └─Empty: 2-1225                     [16, 64, 16, 16]          --
│    └─Empty: 2-1226                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1227        --                        --
│    └─One: 2-1228                       [1]                       --
│    └─OutputScale: 2-1229               --                        --
│    └─Empty: 2-1230                     [64, 64, 3, 3]            --
│    └─Empty: 2-1231                     [64, 64, 3, 3]            --
│    └─Empty: 2-1232                     [64]                      --
│    └─Empty: 2-1233                     [64]                      --
│    └─BatchNorm2d: 2-1234               [16, 64, 16, 16]          --
│    └─Scaler: 2-1235                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1236                      [16, 64, 16, 16]          --
│    └─Empty: 2-1237                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1238                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1239        --                        --
│    └─One: 2-1240                       [1]                       --
│    └─OutputScale: 2-1241               --                        --
│    └─Empty: 2-1242                     [64, 64, 3, 3]            --
│    └─Empty: 2-1243                     [64, 64, 3, 3]            --
│    └─Empty: 2-1244                     [64]                      --
│    └─Empty: 2-1245                     [64]                      --
│    └─BatchNorm2d: 2-1246               [16, 64, 16, 16]          --
│    └─Scaler: 2-1247                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1248                      [16, 64, 16, 16]          --
│    └─Empty: 2-1249                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1250                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1251                 [16, 64, 8, 8]            --
│    └─Empty: 2-1252                     [16, 64, 8, 8]            --
│    └─Empty: 2-1253                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1254        --                        --
│    └─One: 2-1255                       [1]                       --
│    └─OutputScale: 2-1256               --                        --
│    └─Empty: 2-1257                     [64, 64, 3, 3]            --
│    └─Empty: 2-1258                     [64, 64, 3, 3]            --
│    └─Empty: 2-1259                     [64]                      --
│    └─Empty: 2-1260                     [64]                      --
│    └─BatchNorm2d: 2-1261               [16, 64, 8, 8]            --
│    └─Scaler: 2-1262                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1263                      [16, 64, 8, 8]            --
│    └─Empty: 2-1264                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1265                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1266        --                        --
│    └─One: 2-1267                       [1]                       --
│    └─OutputScale: 2-1268               --                        --
│    └─Empty: 2-1269                     [64, 64, 1, 1]            --
│    └─Empty: 2-1270                     [64, 64, 1, 1]            --
│    └─Empty: 2-1271                     [64]                      --
│    └─Empty: 2-1272                     [64]                      --
│    └─BatchNorm2d: 2-1273               [16, 64, 8, 8]            --
│    └─Scaler: 2-1274                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1275                      [16, 64, 8, 8]            --
│    └─Empty: 2-1276                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1277                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1278                 [16, 64, 8, 8]            --
│    └─Empty: 2-1279                     [16, 64, 8, 8]            --
│    └─Empty: 2-1280                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1281        --                        --
│    └─One: 2-1282                       [1]                       --
│    └─OutputScale: 2-1283               --                        --
│    └─Empty: 2-1284                     [64, 64, 3, 3]            --
│    └─Empty: 2-1285                     [64, 64, 3, 3]            --
│    └─Empty: 2-1286                     [64]                      --
│    └─Empty: 2-1287                     [64]                      --
│    └─BatchNorm2d: 2-1288               [16, 64, 8, 8]            --
│    └─Scaler: 2-1289                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1290                      [16, 64, 8, 8]            --
│    └─Empty: 2-1291                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1292                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1293                 [16, 64, 4, 4]            --
│    └─Empty: 2-1294                     [16, 64, 4, 4]            --
│    └─Empty: 2-1295                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1296        --                        --
│    └─One: 2-1297                       [1]                       --
│    └─OutputScale: 2-1298               --                        --
│    └─Empty: 2-1299                     [64, 64, 3, 3]            --
│    └─Empty: 2-1300                     [64, 64, 3, 3]            --
│    └─Empty: 2-1301                     [64]                      --
│    └─Empty: 2-1302                     [64]                      --
│    └─BatchNorm2d: 2-1303               [16, 64, 4, 4]            --
│    └─Scaler: 2-1304                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1305                      [16, 64, 4, 4]            --
│    └─Empty: 2-1306                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1307                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1308        --                        --
│    └─One: 2-1309                       [1]                       --
│    └─OutputScale: 2-1310               --                        --
│    └─Empty: 2-1311                     [64, 64, 1, 1]            --
│    └─Empty: 2-1312                     [64, 64, 1, 1]            --
│    └─Empty: 2-1313                     [64]                      --
│    └─Empty: 2-1314                     [64]                      --
│    └─BatchNorm2d: 2-1315               [16, 64, 4, 4]            --
│    └─Scaler: 2-1316                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1317                      [16, 64, 4, 4]            --
│    └─Empty: 2-1318                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1319                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1320                 [16, 64, 4, 4]            --
│    └─Empty: 2-1321                     [16, 64, 4, 4]            --
│    └─Empty: 2-1322                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1323        --                        --
│    └─One: 2-1324                       [1]                       --
│    └─OutputScale: 2-1325               --                        --
│    └─Empty: 2-1326                     [64, 64, 3, 3]            --
│    └─Empty: 2-1327                     [64, 64, 3, 3]            --
│    └─Empty: 2-1328                     [64]                      --
│    └─Empty: 2-1329                     [64]                      --
│    └─BatchNorm2d: 2-1330               [16, 64, 4, 4]            --
│    └─Scaler: 2-1331                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1332                      [16, 64, 4, 4]            --
│    └─Empty: 2-1333                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1334                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1335                 [16, 64, 2, 2]            --
│    └─Empty: 2-1336                     [16, 64, 2, 2]            --
│    └─Empty: 2-1337                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1338        --                        --
│    └─One: 2-1339                       [1]                       --
│    └─OutputScale: 2-1340               --                        --
│    └─Empty: 2-1341                     [64, 64, 1, 1]            --
│    └─Empty: 2-1342                     [64, 64, 1, 1]            --
│    └─Empty: 2-1343                     [64]                      --
│    └─Empty: 2-1344                     [64]                      --
│    └─BatchNorm2d: 2-1345               [16, 64, 2, 2]            --
│    └─Scaler: 2-1346                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1347                      [16, 64, 2, 2]            --
│    └─Empty: 2-1348                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1349                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1350        --                        --
│    └─One: 2-1351                       [1]                       --
│    └─OutputScale: 2-1352               --                        --
│    └─Empty: 2-1353                     [64, 64, 1, 1]            --
│    └─Empty: 2-1354                     [64, 64, 1, 1]            --
│    └─Empty: 2-1355                     [64]                      --
│    └─Empty: 2-1356                     [64]                      --
│    └─BatchNorm2d: 2-1357               [16, 64, 2, 2]            --
│    └─Scaler: 2-1358                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1359                      [16, 64, 2, 2]            --
│    └─Empty: 2-1360                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1361                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1362                 [16, 64, 2, 2]            --
│    └─Empty: 2-1363                     [16, 64, 2, 2]            --
│    └─Empty: 2-1364                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1365        --                        --
│    └─One: 2-1366                       [1]                       --
│    └─OutputScale: 2-1367               --                        --
│    └─Empty: 2-1368                     [64, 64, 3, 3]            --
│    └─Empty: 2-1369                     [64, 64, 3, 3]            --
│    └─Empty: 2-1370                     [64]                      --
│    └─Empty: 2-1371                     [64]                      --
│    └─BatchNorm2d: 2-1372               [16, 64, 2, 2]            --
│    └─Scaler: 2-1373                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1374                      [16, 64, 2, 2]            --
│    └─Empty: 2-1375                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1376                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1377        --                        --
│    └─One: 2-1378                       [1]                       --
│    └─OutputScale: 2-1379               --                        --
│    └─Empty: 2-1380                     [64, 48, 1, 1]            --
│    └─Empty: 2-1381                     [64, 48, 1, 1]            --
│    └─Empty: 2-1382                     [64]                      --
│    └─Empty: 2-1383                     [64]                      --
│    └─BatchNorm2d: 2-1384               [16, 64, 64, 64]          --
│    └─Scaler: 2-1385                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1386                      [16, 64, 64, 64]          --
│    └─Empty: 2-1387                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1388                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1389        --                        --
│    └─One: 2-1390                       [1]                       --
│    └─OutputScale: 2-1391               --                        --
│    └─Empty: 2-1392                     [64, 64, 3, 3]            --
│    └─Empty: 2-1393                     [64, 64, 3, 3]            --
│    └─Empty: 2-1394                     [64]                      --
│    └─Empty: 2-1395                     [64]                      --
│    └─BatchNorm2d: 2-1396               [16, 64, 64, 64]          --
│    └─Scaler: 2-1397                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1398                      [16, 64, 64, 64]          --
│    └─Empty: 2-1399                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1400                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1401        --                        --
│    └─One: 2-1402                       [1]                       --
│    └─OutputScale: 2-1403               --                        --
│    └─Empty: 2-1404                     [64, 64, 1, 1]            --
│    └─Empty: 2-1405                     [64, 64, 1, 1]            --
│    └─Empty: 2-1406                     [64]                      --
│    └─Empty: 2-1407                     [64]                      --
│    └─BatchNorm2d: 2-1408               [16, 64, 64, 64]          --
│    └─Scaler: 2-1409                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1410                      [16, 64, 64, 64]          --
│    └─Empty: 2-1411                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1412                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1413        --                        --
│    └─One: 2-1414                       [1]                       --
│    └─OutputScale: 2-1415               --                        --
│    └─Empty: 2-1416                     [64, 64, 3, 3]            --
│    └─Empty: 2-1417                     [64, 64, 3, 3]            --
│    └─Empty: 2-1418                     [64]                      --
│    └─Empty: 2-1419                     [64]                      --
│    └─BatchNorm2d: 2-1420               [16, 64, 64, 64]          --
│    └─Scaler: 2-1421                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1422                      [16, 64, 64, 64]          --
│    └─Empty: 2-1423                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1424                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1425                 [16, 64, 32, 32]          --
│    └─Empty: 2-1426                     [16, 64, 32, 32]          --
│    └─Empty: 2-1427                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1428        --                        --
│    └─One: 2-1429                       [1]                       --
│    └─OutputScale: 2-1430               --                        --
│    └─Empty: 2-1431                     [64, 64, 3, 3]            --
│    └─Empty: 2-1432                     [64, 64, 3, 3]            --
│    └─Empty: 2-1433                     [64]                      --
│    └─Empty: 2-1434                     [64]                      --
│    └─BatchNorm2d: 2-1435               [16, 64, 32, 32]          --
│    └─Scaler: 2-1436                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1437                      [16, 64, 32, 32]          --
│    └─Empty: 2-1438                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1439                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1440        --                        --
│    └─One: 2-1441                       [1]                       --
│    └─OutputScale: 2-1442               --                        --
│    └─Empty: 2-1443                     [64, 64, 3, 3]            --
│    └─Empty: 2-1444                     [64, 64, 3, 3]            --
│    └─Empty: 2-1445                     [64]                      --
│    └─Empty: 2-1446                     [64]                      --
│    └─BatchNorm2d: 2-1447               [16, 64, 32, 32]          --
│    └─Scaler: 2-1448                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1449                      [16, 64, 32, 32]          --
│    └─Empty: 2-1450                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1451                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1452                 [16, 64, 16, 16]          --
│    └─Empty: 2-1453                     [16, 64, 16, 16]          --
│    └─Empty: 2-1454                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1455        --                        --
│    └─One: 2-1456                       [1]                       --
│    └─OutputScale: 2-1457               --                        --
│    └─Empty: 2-1458                     [64, 64, 3, 3]            --
│    └─Empty: 2-1459                     [64, 64, 3, 3]            --
│    └─Empty: 2-1460                     [64]                      --
│    └─Empty: 2-1461                     [64]                      --
│    └─BatchNorm2d: 2-1462               [16, 64, 16, 16]          --
│    └─Scaler: 2-1463                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1464                      [16, 64, 16, 16]          --
│    └─Empty: 2-1465                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1466                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1467        --                        --
│    └─One: 2-1468                       [1]                       --
│    └─OutputScale: 2-1469               --                        --
│    └─Empty: 2-1470                     [64, 64, 3, 3]            --
│    └─Empty: 2-1471                     [64, 64, 3, 3]            --
│    └─Empty: 2-1472                     [64]                      --
│    └─Empty: 2-1473                     [64]                      --
│    └─BatchNorm2d: 2-1474               [16, 64, 16, 16]          --
│    └─Scaler: 2-1475                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1476                      [16, 64, 16, 16]          --
│    └─Empty: 2-1477                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1478                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1479                 [16, 64, 8, 8]            --
│    └─Empty: 2-1480                     [16, 64, 8, 8]            --
│    └─Empty: 2-1481                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1482        --                        --
│    └─One: 2-1483                       [1]                       --
│    └─OutputScale: 2-1484               --                        --
│    └─Empty: 2-1485                     [64, 64, 3, 3]            --
│    └─Empty: 2-1486                     [64, 64, 3, 3]            --
│    └─Empty: 2-1487                     [64]                      --
│    └─Empty: 2-1488                     [64]                      --
│    └─BatchNorm2d: 2-1489               [16, 64, 8, 8]            --
│    └─Scaler: 2-1490                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1491                      [16, 64, 8, 8]            --
│    └─Empty: 2-1492                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1493                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1494        --                        --
│    └─One: 2-1495                       [1]                       --
│    └─OutputScale: 2-1496               --                        --
│    └─Empty: 2-1497                     [64, 64, 1, 1]            --
│    └─Empty: 2-1498                     [64, 64, 1, 1]            --
│    └─Empty: 2-1499                     [64]                      --
│    └─Empty: 2-1500                     [64]                      --
│    └─BatchNorm2d: 2-1501               [16, 64, 8, 8]            --
│    └─Scaler: 2-1502                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1503                      [16, 64, 8, 8]            --
│    └─Empty: 2-1504                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1505                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1506                 [16, 64, 8, 8]            --
│    └─Empty: 2-1507                     [16, 64, 8, 8]            --
│    └─Empty: 2-1508                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1509        --                        --
│    └─One: 2-1510                       [1]                       --
│    └─OutputScale: 2-1511               --                        --
│    └─Empty: 2-1512                     [64, 64, 3, 3]            --
│    └─Empty: 2-1513                     [64, 64, 3, 3]            --
│    └─Empty: 2-1514                     [64]                      --
│    └─Empty: 2-1515                     [64]                      --
│    └─BatchNorm2d: 2-1516               [16, 64, 8, 8]            --
│    └─Scaler: 2-1517                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1518                      [16, 64, 8, 8]            --
│    └─Empty: 2-1519                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1520                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1521                 [16, 64, 4, 4]            --
│    └─Empty: 2-1522                     [16, 64, 4, 4]            --
│    └─Empty: 2-1523                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1524        --                        --
│    └─One: 2-1525                       [1]                       --
│    └─OutputScale: 2-1526               --                        --
│    └─Empty: 2-1527                     [64, 64, 3, 3]            --
│    └─Empty: 2-1528                     [64, 64, 3, 3]            --
│    └─Empty: 2-1529                     [64]                      --
│    └─Empty: 2-1530                     [64]                      --
│    └─BatchNorm2d: 2-1531               [16, 64, 4, 4]            --
│    └─Scaler: 2-1532                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1533                      [16, 64, 4, 4]            --
│    └─Empty: 2-1534                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1535                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1536        --                        --
│    └─One: 2-1537                       [1]                       --
│    └─OutputScale: 2-1538               --                        --
│    └─Empty: 2-1539                     [64, 64, 1, 1]            --
│    └─Empty: 2-1540                     [64, 64, 1, 1]            --
│    └─Empty: 2-1541                     [64]                      --
│    └─Empty: 2-1542                     [64]                      --
│    └─BatchNorm2d: 2-1543               [16, 64, 4, 4]            --
│    └─Scaler: 2-1544                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1545                      [16, 64, 4, 4]            --
│    └─Empty: 2-1546                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1547                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1548                 [16, 64, 4, 4]            --
│    └─Empty: 2-1549                     [16, 64, 4, 4]            --
│    └─Empty: 2-1550                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1551        --                        --
│    └─One: 2-1552                       [1]                       --
│    └─OutputScale: 2-1553               --                        --
│    └─Empty: 2-1554                     [64, 64, 3, 3]            --
│    └─Empty: 2-1555                     [64, 64, 3, 3]            --
│    └─Empty: 2-1556                     [64]                      --
│    └─Empty: 2-1557                     [64]                      --
│    └─BatchNorm2d: 2-1558               [16, 64, 4, 4]            --
│    └─Scaler: 2-1559                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1560                      [16, 64, 4, 4]            --
│    └─Empty: 2-1561                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1562                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1563                 [16, 64, 2, 2]            --
│    └─Empty: 2-1564                     [16, 64, 2, 2]            --
│    └─Empty: 2-1565                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1566        --                        --
│    └─One: 2-1567                       [1]                       --
│    └─OutputScale: 2-1568               --                        --
│    └─Empty: 2-1569                     [64, 64, 1, 1]            --
│    └─Empty: 2-1570                     [64, 64, 1, 1]            --
│    └─Empty: 2-1571                     [64]                      --
│    └─Empty: 2-1572                     [64]                      --
│    └─BatchNorm2d: 2-1573               [16, 64, 2, 2]            --
│    └─Scaler: 2-1574                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1575                      [16, 64, 2, 2]            --
│    └─Empty: 2-1576                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1577                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1578        --                        --
│    └─One: 2-1579                       [1]                       --
│    └─OutputScale: 2-1580               --                        --
│    └─Empty: 2-1581                     [64, 64, 1, 1]            --
│    └─Empty: 2-1582                     [64, 64, 1, 1]            --
│    └─Empty: 2-1583                     [64]                      --
│    └─Empty: 2-1584                     [64]                      --
│    └─BatchNorm2d: 2-1585               [16, 64, 2, 2]            --
│    └─Scaler: 2-1586                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1587                      [16, 64, 2, 2]            --
│    └─Empty: 2-1588                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1589                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1590                 [16, 64, 2, 2]            --
│    └─Empty: 2-1591                     [16, 64, 2, 2]            --
│    └─Empty: 2-1592                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1593        --                        --
│    └─One: 2-1594                       [1]                       --
│    └─OutputScale: 2-1595               --                        --
│    └─Empty: 2-1596                     [64, 64, 3, 3]            --
│    └─Empty: 2-1597                     [64, 64, 3, 3]            --
│    └─Empty: 2-1598                     [64]                      --
│    └─Empty: 2-1599                     [64]                      --
│    └─BatchNorm2d: 2-1600               [16, 64, 2, 2]            --
│    └─Scaler: 2-1601                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1602                      [16, 64, 2, 2]            --
│    └─Empty: 2-1603                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1604                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1605        --                        --
│    └─One: 2-1606                       [1]                       --
│    └─OutputScale: 2-1607               --                        --
│    └─Empty: 2-1608                     [64, 48, 1, 1]            --
│    └─Empty: 2-1609                     [64, 48, 1, 1]            --
│    └─Empty: 2-1610                     [64]                      --
│    └─Empty: 2-1611                     [64]                      --
│    └─BatchNorm2d: 2-1612               [16, 64, 64, 64]          --
│    └─Scaler: 2-1613                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1614                      [16, 64, 64, 64]          --
│    └─Empty: 2-1615                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1616                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1617        --                        --
│    └─One: 2-1618                       [1]                       --
│    └─OutputScale: 2-1619               --                        --
│    └─Empty: 2-1620                     [64, 64, 3, 3]            --
│    └─Empty: 2-1621                     [64, 64, 3, 3]            --
│    └─Empty: 2-1622                     [64]                      --
│    └─Empty: 2-1623                     [64]                      --
│    └─BatchNorm2d: 2-1624               [16, 64, 64, 64]          --
│    └─Scaler: 2-1625                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1626                      [16, 64, 64, 64]          --
│    └─Empty: 2-1627                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1628                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [64, 64, 1, 1]            --
│    └─Empty: 2-1633                     [64, 64, 1, 1]            --
│    └─Empty: 2-1634                     [64]                      --
│    └─Empty: 2-1635                     [64]                      --
│    └─BatchNorm2d: 2-1636               [16, 64, 64, 64]          --
│    └─Scaler: 2-1637                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1638                      [16, 64, 64, 64]          --
│    └─Empty: 2-1639                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1640                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [64, 64, 3, 3]            --
│    └─Empty: 2-1645                     [64, 64, 3, 3]            --
│    └─Empty: 2-1646                     [64]                      --
│    └─Empty: 2-1647                     [64]                      --
│    └─BatchNorm2d: 2-1648               [16, 64, 64, 64]          --
│    └─Scaler: 2-1649                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1650                      [16, 64, 64, 64]          --
│    └─Empty: 2-1651                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1652                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1653                 [16, 64, 32, 32]          --
│    └─Empty: 2-1654                     [16, 64, 32, 32]          --
│    └─Empty: 2-1655                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [64, 64, 3, 3]            --
│    └─Empty: 2-1660                     [64, 64, 3, 3]            --
│    └─Empty: 2-1661                     [64]                      --
│    └─Empty: 2-1662                     [64]                      --
│    └─BatchNorm2d: 2-1663               [16, 64, 32, 32]          --
│    └─Scaler: 2-1664                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1665                      [16, 64, 32, 32]          --
│    └─Empty: 2-1666                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1667                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1668        --                        --
│    └─One: 2-1669                       [1]                       --
│    └─OutputScale: 2-1670               --                        --
│    └─Empty: 2-1671                     [64, 64, 3, 3]            --
│    └─Empty: 2-1672                     [64, 64, 3, 3]            --
│    └─Empty: 2-1673                     [64]                      --
│    └─Empty: 2-1674                     [64]                      --
│    └─BatchNorm2d: 2-1675               [16, 64, 32, 32]          --
│    └─Scaler: 2-1676                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1677                      [16, 64, 32, 32]          --
│    └─Empty: 2-1678                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1679                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1680                 [16, 64, 16, 16]          --
│    └─Empty: 2-1681                     [16, 64, 16, 16]          --
│    └─Empty: 2-1682                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [64, 64, 3, 3]            --
│    └─Empty: 2-1687                     [64, 64, 3, 3]            --
│    └─Empty: 2-1688                     [64]                      --
│    └─Empty: 2-1689                     [64]                      --
│    └─BatchNorm2d: 2-1690               [16, 64, 16, 16]          --
│    └─Scaler: 2-1691                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1692                      [16, 64, 16, 16]          --
│    └─Empty: 2-1693                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1694                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1695        --                        --
│    └─One: 2-1696                       [1]                       --
│    └─OutputScale: 2-1697               --                        --
│    └─Empty: 2-1698                     [64, 64, 3, 3]            --
│    └─Empty: 2-1699                     [64, 64, 3, 3]            --
│    └─Empty: 2-1700                     [64]                      --
│    └─Empty: 2-1701                     [64]                      --
│    └─BatchNorm2d: 2-1702               [16, 64, 16, 16]          --
│    └─Scaler: 2-1703                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1704                      [16, 64, 16, 16]          --
│    └─Empty: 2-1705                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1706                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1707                 [16, 64, 8, 8]            --
│    └─Empty: 2-1708                     [16, 64, 8, 8]            --
│    └─Empty: 2-1709                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [64, 64, 3, 3]            --
│    └─Empty: 2-1714                     [64, 64, 3, 3]            --
│    └─Empty: 2-1715                     [64]                      --
│    └─Empty: 2-1716                     [64]                      --
│    └─BatchNorm2d: 2-1717               [16, 64, 8, 8]            --
│    └─Scaler: 2-1718                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1719                      [16, 64, 8, 8]            --
│    └─Empty: 2-1720                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1721                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1722        --                        --
│    └─One: 2-1723                       [1]                       --
│    └─OutputScale: 2-1724               --                        --
│    └─Empty: 2-1725                     [64, 64, 1, 1]            --
│    └─Empty: 2-1726                     [64, 64, 1, 1]            --
│    └─Empty: 2-1727                     [64]                      --
│    └─Empty: 2-1728                     [64]                      --
│    └─BatchNorm2d: 2-1729               [16, 64, 8, 8]            --
│    └─Scaler: 2-1730                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1731                      [16, 64, 8, 8]            --
│    └─Empty: 2-1732                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1733                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1734                 [16, 64, 8, 8]            --
│    └─Empty: 2-1735                     [16, 64, 8, 8]            --
│    └─Empty: 2-1736                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1737        --                        --
│    └─One: 2-1738                       [1]                       --
│    └─OutputScale: 2-1739               --                        --
│    └─Empty: 2-1740                     [64, 64, 3, 3]            --
│    └─Empty: 2-1741                     [64, 64, 3, 3]            --
│    └─Empty: 2-1742                     [64]                      --
│    └─Empty: 2-1743                     [64]                      --
│    └─BatchNorm2d: 2-1744               [16, 64, 8, 8]            --
│    └─Scaler: 2-1745                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1746                      [16, 64, 8, 8]            --
│    └─Empty: 2-1747                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1748                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1749                 [16, 64, 4, 4]            --
│    └─Empty: 2-1750                     [16, 64, 4, 4]            --
│    └─Empty: 2-1751                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1752        --                        --
│    └─One: 2-1753                       [1]                       --
│    └─OutputScale: 2-1754               --                        --
│    └─Empty: 2-1755                     [64, 64, 3, 3]            --
│    └─Empty: 2-1756                     [64, 64, 3, 3]            --
│    └─Empty: 2-1757                     [64]                      --
│    └─Empty: 2-1758                     [64]                      --
│    └─BatchNorm2d: 2-1759               [16, 64, 4, 4]            --
│    └─Scaler: 2-1760                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1761                      [16, 64, 4, 4]            --
│    └─Empty: 2-1762                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1763                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1764        --                        --
│    └─One: 2-1765                       [1]                       --
│    └─OutputScale: 2-1766               --                        --
│    └─Empty: 2-1767                     [64, 64, 1, 1]            --
│    └─Empty: 2-1768                     [64, 64, 1, 1]            --
│    └─Empty: 2-1769                     [64]                      --
│    └─Empty: 2-1770                     [64]                      --
│    └─BatchNorm2d: 2-1771               [16, 64, 4, 4]            --
│    └─Scaler: 2-1772                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1773                      [16, 64, 4, 4]            --
│    └─Empty: 2-1774                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1775                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1776                 [16, 64, 4, 4]            --
│    └─Empty: 2-1777                     [16, 64, 4, 4]            --
│    └─Empty: 2-1778                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1779        --                        --
│    └─One: 2-1780                       [1]                       --
│    └─OutputScale: 2-1781               --                        --
│    └─Empty: 2-1782                     [64, 64, 3, 3]            --
│    └─Empty: 2-1783                     [64, 64, 3, 3]            --
│    └─Empty: 2-1784                     [64]                      --
│    └─Empty: 2-1785                     [64]                      --
│    └─BatchNorm2d: 2-1786               [16, 64, 4, 4]            --
│    └─Scaler: 2-1787                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1788                      [16, 64, 4, 4]            --
│    └─Empty: 2-1789                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1790                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1791                 [16, 64, 2, 2]            --
│    └─Empty: 2-1792                     [16, 64, 2, 2]            --
│    └─Empty: 2-1793                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1794        --                        --
│    └─One: 2-1795                       [1]                       --
│    └─OutputScale: 2-1796               --                        --
│    └─Empty: 2-1797                     [64, 64, 1, 1]            --
│    └─Empty: 2-1798                     [64, 64, 1, 1]            --
│    └─Empty: 2-1799                     [64]                      --
│    └─Empty: 2-1800                     [64]                      --
│    └─BatchNorm2d: 2-1801               [16, 64, 2, 2]            --
│    └─Scaler: 2-1802                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1803                      [16, 64, 2, 2]            --
│    └─Empty: 2-1804                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1805                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1806        --                        --
│    └─One: 2-1807                       [1]                       --
│    └─OutputScale: 2-1808               --                        --
│    └─Empty: 2-1809                     [64, 64, 1, 1]            --
│    └─Empty: 2-1810                     [64, 64, 1, 1]            --
│    └─Empty: 2-1811                     [64]                      --
│    └─Empty: 2-1812                     [64]                      --
│    └─BatchNorm2d: 2-1813               [16, 64, 2, 2]            --
│    └─Scaler: 2-1814                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1815                      [16, 64, 2, 2]            --
│    └─Empty: 2-1816                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1817                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1818                 [16, 64, 2, 2]            --
│    └─Empty: 2-1819                     [16, 64, 2, 2]            --
│    └─Empty: 2-1820                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [64, 64, 3, 3]            --
│    └─Empty: 2-1825                     [64, 64, 3, 3]            --
│    └─Empty: 2-1826                     [64]                      --
│    └─Empty: 2-1827                     [64]                      --
│    └─BatchNorm2d: 2-1828               [16, 64, 2, 2]            --
│    └─Scaler: 2-1829                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1830                      [16, 64, 2, 2]            --
│    └─Empty: 2-1831                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1832                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1833        --                        --
│    └─One: 2-1834                       [1]                       --
│    └─OutputScale: 2-1835               --                        --
│    └─Empty: 2-1836                     [64, 48, 1, 1]            --
│    └─Empty: 2-1837                     [64, 48, 1, 1]            --
│    └─Empty: 2-1838                     [64]                      --
│    └─Empty: 2-1839                     [64]                      --
│    └─BatchNorm2d: 2-1840               [16, 64, 64, 64]          --
│    └─Scaler: 2-1841                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1842                      [16, 64, 64, 64]          --
│    └─Empty: 2-1843                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1844                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1845        --                        --
│    └─One: 2-1846                       [1]                       --
│    └─OutputScale: 2-1847               --                        --
│    └─Empty: 2-1848                     [64, 64, 3, 3]            --
│    └─Empty: 2-1849                     [64, 64, 3, 3]            --
│    └─Empty: 2-1850                     [64]                      --
│    └─Empty: 2-1851                     [64]                      --
│    └─BatchNorm2d: 2-1852               [16, 64, 64, 64]          --
│    └─Scaler: 2-1853                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1854                      [16, 64, 64, 64]          --
│    └─Empty: 2-1855                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1856                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1857        --                        --
│    └─One: 2-1858                       [1]                       --
│    └─OutputScale: 2-1859               --                        --
│    └─Empty: 2-1860                     [64, 64, 1, 1]            --
│    └─Empty: 2-1861                     [64, 64, 1, 1]            --
│    └─Empty: 2-1862                     [64]                      --
│    └─Empty: 2-1863                     [64]                      --
│    └─BatchNorm2d: 2-1864               [16, 64, 64, 64]          --
│    └─Scaler: 2-1865                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1866                      [16, 64, 64, 64]          --
│    └─Empty: 2-1867                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1868                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1869        --                        --
│    └─One: 2-1870                       [1]                       --
│    └─OutputScale: 2-1871               --                        --
│    └─Empty: 2-1872                     [64, 64, 3, 3]            --
│    └─Empty: 2-1873                     [64, 64, 3, 3]            --
│    └─Empty: 2-1874                     [64]                      --
│    └─Empty: 2-1875                     [64]                      --
│    └─BatchNorm2d: 2-1876               [16, 64, 64, 64]          --
│    └─Scaler: 2-1877                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1878                      [16, 64, 64, 64]          --
│    └─Empty: 2-1879                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1880                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1881                 [16, 64, 32, 32]          --
│    └─Empty: 2-1882                     [16, 64, 32, 32]          --
│    └─Empty: 2-1883                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1884        --                        --
│    └─One: 2-1885                       [1]                       --
│    └─OutputScale: 2-1886               --                        --
│    └─Empty: 2-1887                     [64, 64, 3, 3]            --
│    └─Empty: 2-1888                     [64, 64, 3, 3]            --
│    └─Empty: 2-1889                     [64]                      --
│    └─Empty: 2-1890                     [64]                      --
│    └─BatchNorm2d: 2-1891               [16, 64, 32, 32]          --
│    └─Scaler: 2-1892                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1893                      [16, 64, 32, 32]          --
│    └─Empty: 2-1894                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1895                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1896        --                        --
│    └─One: 2-1897                       [1]                       --
│    └─OutputScale: 2-1898               --                        --
│    └─Empty: 2-1899                     [64, 64, 3, 3]            --
│    └─Empty: 2-1900                     [64, 64, 3, 3]            --
│    └─Empty: 2-1901                     [64]                      --
│    └─Empty: 2-1902                     [64]                      --
│    └─BatchNorm2d: 2-1903               [16, 64, 32, 32]          --
│    └─Scaler: 2-1904                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1905                      [16, 64, 32, 32]          --
│    └─Empty: 2-1906                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1907                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1908                 [16, 64, 16, 16]          --
│    └─Empty: 2-1909                     [16, 64, 16, 16]          --
│    └─Empty: 2-1910                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1911        --                        --
│    └─One: 2-1912                       [1]                       --
│    └─OutputScale: 2-1913               --                        --
│    └─Empty: 2-1914                     [64, 64, 3, 3]            --
│    └─Empty: 2-1915                     [64, 64, 3, 3]            --
│    └─Empty: 2-1916                     [64]                      --
│    └─Empty: 2-1917                     [64]                      --
│    └─BatchNorm2d: 2-1918               [16, 64, 16, 16]          --
│    └─Scaler: 2-1919                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1920                      [16, 64, 16, 16]          --
│    └─Empty: 2-1921                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1922                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1923        --                        --
│    └─One: 2-1924                       [1]                       --
│    └─OutputScale: 2-1925               --                        --
│    └─Empty: 2-1926                     [64, 64, 3, 3]            --
│    └─Empty: 2-1927                     [64, 64, 3, 3]            --
│    └─Empty: 2-1928                     [64]                      --
│    └─Empty: 2-1929                     [64]                      --
│    └─BatchNorm2d: 2-1930               [16, 64, 16, 16]          --
│    └─Scaler: 2-1931                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1932                      [16, 64, 16, 16]          --
│    └─Empty: 2-1933                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1934                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1935                 [16, 64, 8, 8]            --
│    └─Empty: 2-1936                     [16, 64, 8, 8]            --
│    └─Empty: 2-1937                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1938        --                        --
│    └─One: 2-1939                       [1]                       --
│    └─OutputScale: 2-1940               --                        --
│    └─Empty: 2-1941                     [64, 64, 3, 3]            --
│    └─Empty: 2-1942                     [64, 64, 3, 3]            --
│    └─Empty: 2-1943                     [64]                      --
│    └─Empty: 2-1944                     [64]                      --
│    └─BatchNorm2d: 2-1945               [16, 64, 8, 8]            --
│    └─Scaler: 2-1946                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1947                      [16, 64, 8, 8]            --
│    └─Empty: 2-1948                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1949                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1950        --                        --
│    └─One: 2-1951                       [1]                       --
│    └─OutputScale: 2-1952               --                        --
│    └─Empty: 2-1953                     [64, 64, 1, 1]            --
│    └─Empty: 2-1954                     [64, 64, 1, 1]            --
│    └─Empty: 2-1955                     [64]                      --
│    └─Empty: 2-1956                     [64]                      --
│    └─BatchNorm2d: 2-1957               [16, 64, 8, 8]            --
│    └─Scaler: 2-1958                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1959                      [16, 64, 8, 8]            --
│    └─Empty: 2-1960                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1961                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1962                 [16, 64, 8, 8]            --
│    └─Empty: 2-1963                     [16, 64, 8, 8]            --
│    └─Empty: 2-1964                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1965        --                        --
│    └─One: 2-1966                       [1]                       --
│    └─OutputScale: 2-1967               --                        --
│    └─Empty: 2-1968                     [64, 64, 3, 3]            --
│    └─Empty: 2-1969                     [64, 64, 3, 3]            --
│    └─Empty: 2-1970                     [64]                      --
│    └─Empty: 2-1971                     [64]                      --
│    └─BatchNorm2d: 2-1972               [16, 64, 8, 8]            --
│    └─Scaler: 2-1973                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1974                      [16, 64, 8, 8]            --
│    └─Empty: 2-1975                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1976                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1977                 [16, 64, 4, 4]            --
│    └─Empty: 2-1978                     [16, 64, 4, 4]            --
│    └─Empty: 2-1979                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1980        --                        --
│    └─One: 2-1981                       [1]                       --
│    └─OutputScale: 2-1982               --                        --
│    └─Empty: 2-1983                     [64, 64, 3, 3]            --
│    └─Empty: 2-1984                     [64, 64, 3, 3]            --
│    └─Empty: 2-1985                     [64]                      --
│    └─Empty: 2-1986                     [64]                      --
│    └─BatchNorm2d: 2-1987               [16, 64, 4, 4]            --
│    └─Scaler: 2-1988                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1989                      [16, 64, 4, 4]            --
│    └─Empty: 2-1990                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1991                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1992        --                        --
│    └─One: 2-1993                       [1]                       --
│    └─OutputScale: 2-1994               --                        --
│    └─Empty: 2-1995                     [64, 64, 1, 1]            --
│    └─Empty: 2-1996                     [64, 64, 1, 1]            --
│    └─Empty: 2-1997                     [64]                      --
│    └─Empty: 2-1998                     [64]                      --
│    └─BatchNorm2d: 2-1999               [16, 64, 4, 4]            --
│    └─Scaler: 2-2000                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2001                      [16, 64, 4, 4]            --
│    └─Empty: 2-2002                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2003                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2004                 [16, 64, 4, 4]            --
│    └─Empty: 2-2005                     [16, 64, 4, 4]            --
│    └─Empty: 2-2006                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2007        --                        --
│    └─One: 2-2008                       [1]                       --
│    └─OutputScale: 2-2009               --                        --
│    └─Empty: 2-2010                     [64, 64, 3, 3]            --
│    └─Empty: 2-2011                     [64, 64, 3, 3]            --
│    └─Empty: 2-2012                     [64]                      --
│    └─Empty: 2-2013                     [64]                      --
│    └─BatchNorm2d: 2-2014               [16, 64, 4, 4]            --
│    └─Scaler: 2-2015                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2016                      [16, 64, 4, 4]            --
│    └─Empty: 2-2017                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2018                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2019                 [16, 64, 2, 2]            --
│    └─Empty: 2-2020                     [16, 64, 2, 2]            --
│    └─Empty: 2-2021                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2022        --                        --
│    └─One: 2-2023                       [1]                       --
│    └─OutputScale: 2-2024               --                        --
│    └─Empty: 2-2025                     [64, 64, 1, 1]            --
│    └─Empty: 2-2026                     [64, 64, 1, 1]            --
│    └─Empty: 2-2027                     [64]                      --
│    └─Empty: 2-2028                     [64]                      --
│    └─BatchNorm2d: 2-2029               [16, 64, 2, 2]            --
│    └─Scaler: 2-2030                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2031                      [16, 64, 2, 2]            --
│    └─Empty: 2-2032                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2033                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2034        --                        --
│    └─One: 2-2035                       [1]                       --
│    └─OutputScale: 2-2036               --                        --
│    └─Empty: 2-2037                     [64, 64, 1, 1]            --
│    └─Empty: 2-2038                     [64, 64, 1, 1]            --
│    └─Empty: 2-2039                     [64]                      --
│    └─Empty: 2-2040                     [64]                      --
│    └─BatchNorm2d: 2-2041               [16, 64, 2, 2]            --
│    └─Scaler: 2-2042                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2043                      [16, 64, 2, 2]            --
│    └─Empty: 2-2044                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2045                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2046                 [16, 64, 2, 2]            --
│    └─Empty: 2-2047                     [16, 64, 2, 2]            --
│    └─Empty: 2-2048                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2049        --                        --
│    └─One: 2-2050                       [1]                       --
│    └─OutputScale: 2-2051               --                        --
│    └─Empty: 2-2052                     [64, 64, 3, 3]            --
│    └─Empty: 2-2053                     [64, 64, 3, 3]            --
│    └─Empty: 2-2054                     [64]                      --
│    └─Empty: 2-2055                     [64]                      --
│    └─BatchNorm2d: 2-2056               [16, 64, 2, 2]            --
│    └─Scaler: 2-2057                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2058                      [16, 64, 2, 2]            --
│    └─Empty: 2-2059                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2060                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2061        --                        --
│    └─One: 2-2062                       [1]                       --
│    └─OutputScale: 2-2063               --                        --
│    └─Empty: 2-2064                     [64, 48, 1, 1]            --
│    └─Empty: 2-2065                     [64, 48, 1, 1]            --
│    └─Empty: 2-2066                     [64]                      --
│    └─Empty: 2-2067                     [64]                      --
│    └─BatchNorm2d: 2-2068               [16, 64, 64, 64]          --
│    └─Scaler: 2-2069                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2070                      [16, 64, 64, 64]          --
│    └─Empty: 2-2071                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2072                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2073        --                        --
│    └─One: 2-2074                       [1]                       --
│    └─OutputScale: 2-2075               --                        --
│    └─Empty: 2-2076                     [64, 64, 3, 3]            --
│    └─Empty: 2-2077                     [64, 64, 3, 3]            --
│    └─Empty: 2-2078                     [64]                      --
│    └─Empty: 2-2079                     [64]                      --
│    └─BatchNorm2d: 2-2080               [16, 64, 64, 64]          --
│    └─Scaler: 2-2081                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2082                      [16, 64, 64, 64]          --
│    └─Empty: 2-2083                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2084                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2085        --                        --
│    └─One: 2-2086                       [1]                       --
│    └─OutputScale: 2-2087               --                        --
│    └─Empty: 2-2088                     [64, 64, 1, 1]            --
│    └─Empty: 2-2089                     [64, 64, 1, 1]            --
│    └─Empty: 2-2090                     [64]                      --
│    └─Empty: 2-2091                     [64]                      --
│    └─BatchNorm2d: 2-2092               [16, 64, 64, 64]          --
│    └─Scaler: 2-2093                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2094                      [16, 64, 64, 64]          --
│    └─Empty: 2-2095                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2096                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2097        --                        --
│    └─One: 2-2098                       [1]                       --
│    └─OutputScale: 2-2099               --                        --
│    └─Empty: 2-2100                     [64, 64, 3, 3]            --
│    └─Empty: 2-2101                     [64, 64, 3, 3]            --
│    └─Empty: 2-2102                     [64]                      --
│    └─Empty: 2-2103                     [64]                      --
│    └─BatchNorm2d: 2-2104               [16, 64, 64, 64]          --
│    └─Scaler: 2-2105                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2106                      [16, 64, 64, 64]          --
│    └─Empty: 2-2107                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2108                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2109                 [16, 64, 32, 32]          --
│    └─Empty: 2-2110                     [16, 64, 32, 32]          --
│    └─Empty: 2-2111                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2112        --                        --
│    └─One: 2-2113                       [1]                       --
│    └─OutputScale: 2-2114               --                        --
│    └─Empty: 2-2115                     [64, 64, 3, 3]            --
│    └─Empty: 2-2116                     [64, 64, 3, 3]            --
│    └─Empty: 2-2117                     [64]                      --
│    └─Empty: 2-2118                     [64]                      --
│    └─BatchNorm2d: 2-2119               [16, 64, 32, 32]          --
│    └─Scaler: 2-2120                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2121                      [16, 64, 32, 32]          --
│    └─Empty: 2-2122                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2123                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2124        --                        --
│    └─One: 2-2125                       [1]                       --
│    └─OutputScale: 2-2126               --                        --
│    └─Empty: 2-2127                     [64, 64, 3, 3]            --
│    └─Empty: 2-2128                     [64, 64, 3, 3]            --
│    └─Empty: 2-2129                     [64]                      --
│    └─Empty: 2-2130                     [64]                      --
│    └─BatchNorm2d: 2-2131               [16, 64, 32, 32]          --
│    └─Scaler: 2-2132                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2133                      [16, 64, 32, 32]          --
│    └─Empty: 2-2134                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2135                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2136                 [16, 64, 16, 16]          --
│    └─Empty: 2-2137                     [16, 64, 16, 16]          --
│    └─Empty: 2-2138                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2139        --                        --
│    └─One: 2-2140                       [1]                       --
│    └─OutputScale: 2-2141               --                        --
│    └─Empty: 2-2142                     [64, 64, 3, 3]            --
│    └─Empty: 2-2143                     [64, 64, 3, 3]            --
│    └─Empty: 2-2144                     [64]                      --
│    └─Empty: 2-2145                     [64]                      --
│    └─BatchNorm2d: 2-2146               [16, 64, 16, 16]          --
│    └─Scaler: 2-2147                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2148                      [16, 64, 16, 16]          --
│    └─Empty: 2-2149                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2150                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2151        --                        --
│    └─One: 2-2152                       [1]                       --
│    └─OutputScale: 2-2153               --                        --
│    └─Empty: 2-2154                     [64, 64, 3, 3]            --
│    └─Empty: 2-2155                     [64, 64, 3, 3]            --
│    └─Empty: 2-2156                     [64]                      --
│    └─Empty: 2-2157                     [64]                      --
│    └─BatchNorm2d: 2-2158               [16, 64, 16, 16]          --
│    └─Scaler: 2-2159                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2160                      [16, 64, 16, 16]          --
│    └─Empty: 2-2161                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2162                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2163                 [16, 64, 8, 8]            --
│    └─Empty: 2-2164                     [16, 64, 8, 8]            --
│    └─Empty: 2-2165                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2166        --                        --
│    └─One: 2-2167                       [1]                       --
│    └─OutputScale: 2-2168               --                        --
│    └─Empty: 2-2169                     [64, 64, 3, 3]            --
│    └─Empty: 2-2170                     [64, 64, 3, 3]            --
│    └─Empty: 2-2171                     [64]                      --
│    └─Empty: 2-2172                     [64]                      --
│    └─BatchNorm2d: 2-2173               [16, 64, 8, 8]            --
│    └─Scaler: 2-2174                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2175                      [16, 64, 8, 8]            --
│    └─Empty: 2-2176                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2177                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2178        --                        --
│    └─One: 2-2179                       [1]                       --
│    └─OutputScale: 2-2180               --                        --
│    └─Empty: 2-2181                     [64, 64, 1, 1]            --
│    └─Empty: 2-2182                     [64, 64, 1, 1]            --
│    └─Empty: 2-2183                     [64]                      --
│    └─Empty: 2-2184                     [64]                      --
│    └─BatchNorm2d: 2-2185               [16, 64, 8, 8]            --
│    └─Scaler: 2-2186                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2187                      [16, 64, 8, 8]            --
│    └─Empty: 2-2188                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2189                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2190                 [16, 64, 8, 8]            --
│    └─Empty: 2-2191                     [16, 64, 8, 8]            --
│    └─Empty: 2-2192                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2193        --                        --
│    └─One: 2-2194                       [1]                       --
│    └─OutputScale: 2-2195               --                        --
│    └─Empty: 2-2196                     [64, 64, 3, 3]            --
│    └─Empty: 2-2197                     [64, 64, 3, 3]            --
│    └─Empty: 2-2198                     [64]                      --
│    └─Empty: 2-2199                     [64]                      --
│    └─BatchNorm2d: 2-2200               [16, 64, 8, 8]            --
│    └─Scaler: 2-2201                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2202                      [16, 64, 8, 8]            --
│    └─Empty: 2-2203                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2204                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2205                 [16, 64, 4, 4]            --
│    └─Empty: 2-2206                     [16, 64, 4, 4]            --
│    └─Empty: 2-2207                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2208        --                        --
│    └─One: 2-2209                       [1]                       --
│    └─OutputScale: 2-2210               --                        --
│    └─Empty: 2-2211                     [64, 64, 3, 3]            --
│    └─Empty: 2-2212                     [64, 64, 3, 3]            --
│    └─Empty: 2-2213                     [64]                      --
│    └─Empty: 2-2214                     [64]                      --
│    └─BatchNorm2d: 2-2215               [16, 64, 4, 4]            --
│    └─Scaler: 2-2216                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2217                      [16, 64, 4, 4]            --
│    └─Empty: 2-2218                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2219                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2220        --                        --
│    └─One: 2-2221                       [1]                       --
│    └─OutputScale: 2-2222               --                        --
│    └─Empty: 2-2223                     [64, 64, 1, 1]            --
│    └─Empty: 2-2224                     [64, 64, 1, 1]            --
│    └─Empty: 2-2225                     [64]                      --
│    └─Empty: 2-2226                     [64]                      --
│    └─BatchNorm2d: 2-2227               [16, 64, 4, 4]            --
│    └─Scaler: 2-2228                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2229                      [16, 64, 4, 4]            --
│    └─Empty: 2-2230                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2231                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2232                 [16, 64, 4, 4]            --
│    └─Empty: 2-2233                     [16, 64, 4, 4]            --
│    └─Empty: 2-2234                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2235        --                        --
│    └─One: 2-2236                       [1]                       --
│    └─OutputScale: 2-2237               --                        --
│    └─Empty: 2-2238                     [64, 64, 3, 3]            --
│    └─Empty: 2-2239                     [64, 64, 3, 3]            --
│    └─Empty: 2-2240                     [64]                      --
│    └─Empty: 2-2241                     [64]                      --
│    └─BatchNorm2d: 2-2242               [16, 64, 4, 4]            --
│    └─Scaler: 2-2243                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2244                      [16, 64, 4, 4]            --
│    └─Empty: 2-2245                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2246                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2247                 [16, 64, 2, 2]            --
│    └─Empty: 2-2248                     [16, 64, 2, 2]            --
│    └─Empty: 2-2249                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2250        --                        --
│    └─One: 2-2251                       [1]                       --
│    └─OutputScale: 2-2252               --                        --
│    └─Empty: 2-2253                     [64, 64, 1, 1]            --
│    └─Empty: 2-2254                     [64, 64, 1, 1]            --
│    └─Empty: 2-2255                     [64]                      --
│    └─Empty: 2-2256                     [64]                      --
│    └─BatchNorm2d: 2-2257               [16, 64, 2, 2]            --
│    └─Scaler: 2-2258                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2259                      [16, 64, 2, 2]            --
│    └─Empty: 2-2260                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2261                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2262        --                        --
│    └─One: 2-2263                       [1]                       --
│    └─OutputScale: 2-2264               --                        --
│    └─Empty: 2-2265                     [64, 64, 1, 1]            --
│    └─Empty: 2-2266                     [64, 64, 1, 1]            --
│    └─Empty: 2-2267                     [64]                      --
│    └─Empty: 2-2268                     [64]                      --
│    └─BatchNorm2d: 2-2269               [16, 64, 2, 2]            --
│    └─Scaler: 2-2270                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2271                      [16, 64, 2, 2]            --
│    └─Empty: 2-2272                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2273                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2274                 [16, 64, 2, 2]            --
│    └─Empty: 2-2275                     [16, 64, 2, 2]            --
│    └─Empty: 2-2276                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2277        --                        --
│    └─One: 2-2278                       [1]                       --
│    └─OutputScale: 2-2279               --                        --
│    └─Empty: 2-2280                     [64, 64, 3, 3]            --
│    └─Empty: 2-2281                     [64, 64, 3, 3]            --
│    └─Empty: 2-2282                     [64]                      --
│    └─Empty: 2-2283                     [64]                      --
│    └─BatchNorm2d: 2-2284               [16, 64, 2, 2]            --
│    └─Scaler: 2-2285                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2286                      [16, 64, 2, 2]            --
│    └─Empty: 2-2287                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2288                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2289        --                        --
│    └─One: 2-2290                       [1]                       --
│    └─OutputScale: 2-2291               --                        --
│    └─Empty: 2-2292                     [64, 48, 1, 1]            --
│    └─Empty: 2-2293                     [64, 48, 1, 1]            --
│    └─Empty: 2-2294                     [64]                      --
│    └─Empty: 2-2295                     [64]                      --
│    └─BatchNorm2d: 2-2296               [16, 64, 64, 64]          --
│    └─Scaler: 2-2297                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2298                      [16, 64, 64, 64]          --
│    └─Empty: 2-2299                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2300                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2301        --                        --
│    └─One: 2-2302                       [1]                       --
│    └─OutputScale: 2-2303               --                        --
│    └─Empty: 2-2304                     [64, 64, 3, 3]            --
│    └─Empty: 2-2305                     [64, 64, 3, 3]            --
│    └─Empty: 2-2306                     [64]                      --
│    └─Empty: 2-2307                     [64]                      --
│    └─BatchNorm2d: 2-2308               [16, 64, 64, 64]          --
│    └─Scaler: 2-2309                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2310                      [16, 64, 64, 64]          --
│    └─Empty: 2-2311                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2312                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2313        --                        --
│    └─One: 2-2314                       [1]                       --
│    └─OutputScale: 2-2315               --                        --
│    └─Empty: 2-2316                     [64, 64, 1, 1]            --
│    └─Empty: 2-2317                     [64, 64, 1, 1]            --
│    └─Empty: 2-2318                     [64]                      --
│    └─Empty: 2-2319                     [64]                      --
│    └─BatchNorm2d: 2-2320               [16, 64, 64, 64]          --
│    └─Scaler: 2-2321                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2322                      [16, 64, 64, 64]          --
│    └─Empty: 2-2323                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2324                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2325        --                        --
│    └─One: 2-2326                       [1]                       --
│    └─OutputScale: 2-2327               --                        --
│    └─Empty: 2-2328                     [64, 64, 3, 3]            --
│    └─Empty: 2-2329                     [64, 64, 3, 3]            --
│    └─Empty: 2-2330                     [64]                      --
│    └─Empty: 2-2331                     [64]                      --
│    └─BatchNorm2d: 2-2332               [16, 64, 64, 64]          --
│    └─Scaler: 2-2333                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2334                      [16, 64, 64, 64]          --
│    └─Empty: 2-2335                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2336                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2337                 [16, 64, 32, 32]          --
│    └─Empty: 2-2338                     [16, 64, 32, 32]          --
│    └─Empty: 2-2339                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2340        --                        --
│    └─One: 2-2341                       [1]                       --
│    └─OutputScale: 2-2342               --                        --
│    └─Empty: 2-2343                     [64, 64, 3, 3]            --
│    └─Empty: 2-2344                     [64, 64, 3, 3]            --
│    └─Empty: 2-2345                     [64]                      --
│    └─Empty: 2-2346                     [64]                      --
│    └─BatchNorm2d: 2-2347               [16, 64, 32, 32]          --
│    └─Scaler: 2-2348                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2349                      [16, 64, 32, 32]          --
│    └─Empty: 2-2350                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2351                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2352        --                        --
│    └─One: 2-2353                       [1]                       --
│    └─OutputScale: 2-2354               --                        --
│    └─Empty: 2-2355                     [64, 64, 3, 3]            --
│    └─Empty: 2-2356                     [64, 64, 3, 3]            --
│    └─Empty: 2-2357                     [64]                      --
│    └─Empty: 2-2358                     [64]                      --
│    └─BatchNorm2d: 2-2359               [16, 64, 32, 32]          --
│    └─Scaler: 2-2360                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2361                      [16, 64, 32, 32]          --
│    └─Empty: 2-2362                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2363                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2364                 [16, 64, 16, 16]          --
│    └─Empty: 2-2365                     [16, 64, 16, 16]          --
│    └─Empty: 2-2366                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2367        --                        --
│    └─One: 2-2368                       [1]                       --
│    └─OutputScale: 2-2369               --                        --
│    └─Empty: 2-2370                     [64, 64, 3, 3]            --
│    └─Empty: 2-2371                     [64, 64, 3, 3]            --
│    └─Empty: 2-2372                     [64]                      --
│    └─Empty: 2-2373                     [64]                      --
│    └─BatchNorm2d: 2-2374               [16, 64, 16, 16]          --
│    └─Scaler: 2-2375                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2376                      [16, 64, 16, 16]          --
│    └─Empty: 2-2377                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2378                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2379        --                        --
│    └─One: 2-2380                       [1]                       --
│    └─OutputScale: 2-2381               --                        --
│    └─Empty: 2-2382                     [64, 64, 3, 3]            --
│    └─Empty: 2-2383                     [64, 64, 3, 3]            --
│    └─Empty: 2-2384                     [64]                      --
│    └─Empty: 2-2385                     [64]                      --
│    └─BatchNorm2d: 2-2386               [16, 64, 16, 16]          --
│    └─Scaler: 2-2387                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2388                      [16, 64, 16, 16]          --
│    └─Empty: 2-2389                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2390                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2391                 [16, 64, 8, 8]            --
│    └─Empty: 2-2392                     [16, 64, 8, 8]            --
│    └─Empty: 2-2393                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2394        --                        --
│    └─One: 2-2395                       [1]                       --
│    └─OutputScale: 2-2396               --                        --
│    └─Empty: 2-2397                     [64, 64, 3, 3]            --
│    └─Empty: 2-2398                     [64, 64, 3, 3]            --
│    └─Empty: 2-2399                     [64]                      --
│    └─Empty: 2-2400                     [64]                      --
│    └─BatchNorm2d: 2-2401               [16, 64, 8, 8]            --
│    └─Scaler: 2-2402                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2403                      [16, 64, 8, 8]            --
│    └─Empty: 2-2404                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2405                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2406        --                        --
│    └─One: 2-2407                       [1]                       --
│    └─OutputScale: 2-2408               --                        --
│    └─Empty: 2-2409                     [64, 64, 1, 1]            --
│    └─Empty: 2-2410                     [64, 64, 1, 1]            --
│    └─Empty: 2-2411                     [64]                      --
│    └─Empty: 2-2412                     [64]                      --
│    └─BatchNorm2d: 2-2413               [16, 64, 8, 8]            --
│    └─Scaler: 2-2414                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2415                      [16, 64, 8, 8]            --
│    └─Empty: 2-2416                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2417                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2418                 [16, 64, 8, 8]            --
│    └─Empty: 2-2419                     [16, 64, 8, 8]            --
│    └─Empty: 2-2420                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2421        --                        --
│    └─One: 2-2422                       [1]                       --
│    └─OutputScale: 2-2423               --                        --
│    └─Empty: 2-2424                     [64, 64, 3, 3]            --
│    └─Empty: 2-2425                     [64, 64, 3, 3]            --
│    └─Empty: 2-2426                     [64]                      --
│    └─Empty: 2-2427                     [64]                      --
│    └─BatchNorm2d: 2-2428               [16, 64, 8, 8]            --
│    └─Scaler: 2-2429                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2430                      [16, 64, 8, 8]            --
│    └─Empty: 2-2431                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2432                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2433                 [16, 64, 4, 4]            --
│    └─Empty: 2-2434                     [16, 64, 4, 4]            --
│    └─Empty: 2-2435                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2436        --                        --
│    └─One: 2-2437                       [1]                       --
│    └─OutputScale: 2-2438               --                        --
│    └─Empty: 2-2439                     [64, 64, 3, 3]            --
│    └─Empty: 2-2440                     [64, 64, 3, 3]            --
│    └─Empty: 2-2441                     [64]                      --
│    └─Empty: 2-2442                     [64]                      --
│    └─BatchNorm2d: 2-2443               [16, 64, 4, 4]            --
│    └─Scaler: 2-2444                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2445                      [16, 64, 4, 4]            --
│    └─Empty: 2-2446                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2447                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2448        --                        --
│    └─One: 2-2449                       [1]                       --
│    └─OutputScale: 2-2450               --                        --
│    └─Empty: 2-2451                     [64, 64, 1, 1]            --
│    └─Empty: 2-2452                     [64, 64, 1, 1]            --
│    └─Empty: 2-2453                     [64]                      --
│    └─Empty: 2-2454                     [64]                      --
│    └─BatchNorm2d: 2-2455               [16, 64, 4, 4]            --
│    └─Scaler: 2-2456                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2457                      [16, 64, 4, 4]            --
│    └─Empty: 2-2458                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2459                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2460                 [16, 64, 4, 4]            --
│    └─Empty: 2-2461                     [16, 64, 4, 4]            --
│    └─Empty: 2-2462                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2463        --                        --
│    └─One: 2-2464                       [1]                       --
│    └─OutputScale: 2-2465               --                        --
│    └─Empty: 2-2466                     [64, 64, 3, 3]            --
│    └─Empty: 2-2467                     [64, 64, 3, 3]            --
│    └─Empty: 2-2468                     [64]                      --
│    └─Empty: 2-2469                     [64]                      --
│    └─BatchNorm2d: 2-2470               [16, 64, 4, 4]            --
│    └─Scaler: 2-2471                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2472                      [16, 64, 4, 4]            --
│    └─Empty: 2-2473                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2474                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2475                 [16, 64, 2, 2]            --
│    └─Empty: 2-2476                     [16, 64, 2, 2]            --
│    └─Empty: 2-2477                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2478        --                        --
│    └─One: 2-2479                       [1]                       --
│    └─OutputScale: 2-2480               --                        --
│    └─Empty: 2-2481                     [64, 64, 1, 1]            --
│    └─Empty: 2-2482                     [64, 64, 1, 1]            --
│    └─Empty: 2-2483                     [64]                      --
│    └─Empty: 2-2484                     [64]                      --
│    └─BatchNorm2d: 2-2485               [16, 64, 2, 2]            --
│    └─Scaler: 2-2486                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2487                      [16, 64, 2, 2]            --
│    └─Empty: 2-2488                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2489                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2490        --                        --
│    └─One: 2-2491                       [1]                       --
│    └─OutputScale: 2-2492               --                        --
│    └─Empty: 2-2493                     [64, 64, 1, 1]            --
│    └─Empty: 2-2494                     [64, 64, 1, 1]            --
│    └─Empty: 2-2495                     [64]                      --
│    └─Empty: 2-2496                     [64]                      --
│    └─BatchNorm2d: 2-2497               [16, 64, 2, 2]            --
│    └─Scaler: 2-2498                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2499                      [16, 64, 2, 2]            --
│    └─Empty: 2-2500                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2501                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2502                 [16, 64, 2, 2]            --
│    └─Empty: 2-2503                     [16, 64, 2, 2]            --
│    └─Empty: 2-2504                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2505        --                        --
│    └─One: 2-2506                       [1]                       --
│    └─OutputScale: 2-2507               --                        --
│    └─Empty: 2-2508                     [64, 64, 3, 3]            --
│    └─Empty: 2-2509                     [64, 64, 3, 3]            --
│    └─Empty: 2-2510                     [64]                      --
│    └─Empty: 2-2511                     [64]                      --
│    └─BatchNorm2d: 2-2512               [16, 64, 2, 2]            --
│    └─Scaler: 2-2513                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2514                      [16, 64, 2, 2]            --
│    └─Empty: 2-2515                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2516                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2517        --                        --
│    └─One: 2-2518                       [1]                       --
│    └─OutputScale: 2-2519               --                        --
│    └─Empty: 2-2520                     [64, 48, 1, 1]            --
│    └─Empty: 2-2521                     [64, 48, 1, 1]            --
│    └─Empty: 2-2522                     [64]                      --
│    └─Empty: 2-2523                     [64]                      --
│    └─BatchNorm2d: 2-2524               [16, 64, 64, 64]          --
│    └─Scaler: 2-2525                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2526                      [16, 64, 64, 64]          --
│    └─Empty: 2-2527                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2528                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2529        --                        --
│    └─One: 2-2530                       [1]                       --
│    └─OutputScale: 2-2531               --                        --
│    └─Empty: 2-2532                     [64, 64, 3, 3]            --
│    └─Empty: 2-2533                     [64, 64, 3, 3]            --
│    └─Empty: 2-2534                     [64]                      --
│    └─Empty: 2-2535                     [64]                      --
│    └─BatchNorm2d: 2-2536               [16, 64, 64, 64]          --
│    └─Scaler: 2-2537                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2538                      [16, 64, 64, 64]          --
│    └─Empty: 2-2539                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2540                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2541        --                        --
│    └─One: 2-2542                       [1]                       --
│    └─OutputScale: 2-2543               --                        --
│    └─Empty: 2-2544                     [64, 64, 1, 1]            --
│    └─Empty: 2-2545                     [64, 64, 1, 1]            --
│    └─Empty: 2-2546                     [64]                      --
│    └─Empty: 2-2547                     [64]                      --
│    └─BatchNorm2d: 2-2548               [16, 64, 64, 64]          --
│    └─Scaler: 2-2549                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2550                      [16, 64, 64, 64]          --
│    └─Empty: 2-2551                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2552                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2553        --                        --
│    └─One: 2-2554                       [1]                       --
│    └─OutputScale: 2-2555               --                        --
│    └─Empty: 2-2556                     [64, 64, 3, 3]            --
│    └─Empty: 2-2557                     [64, 64, 3, 3]            --
│    └─Empty: 2-2558                     [64]                      --
│    └─Empty: 2-2559                     [64]                      --
│    └─BatchNorm2d: 2-2560               [16, 64, 64, 64]          --
│    └─Scaler: 2-2561                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2562                      [16, 64, 64, 64]          --
│    └─Empty: 2-2563                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2564                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2565                 [16, 64, 32, 32]          --
│    └─Empty: 2-2566                     [16, 64, 32, 32]          --
│    └─Empty: 2-2567                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2568        --                        --
│    └─One: 2-2569                       [1]                       --
│    └─OutputScale: 2-2570               --                        --
│    └─Empty: 2-2571                     [64, 64, 3, 3]            --
│    └─Empty: 2-2572                     [64, 64, 3, 3]            --
│    └─Empty: 2-2573                     [64]                      --
│    └─Empty: 2-2574                     [64]                      --
│    └─BatchNorm2d: 2-2575               [16, 64, 32, 32]          --
│    └─Scaler: 2-2576                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2577                      [16, 64, 32, 32]          --
│    └─Empty: 2-2578                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2579                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2580        --                        --
│    └─One: 2-2581                       [1]                       --
│    └─OutputScale: 2-2582               --                        --
│    └─Empty: 2-2583                     [64, 64, 3, 3]            --
│    └─Empty: 2-2584                     [64, 64, 3, 3]            --
│    └─Empty: 2-2585                     [64]                      --
│    └─Empty: 2-2586                     [64]                      --
│    └─BatchNorm2d: 2-2587               [16, 64, 32, 32]          --
│    └─Scaler: 2-2588                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2589                      [16, 64, 32, 32]          --
│    └─Empty: 2-2590                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2591                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2592                 [16, 64, 16, 16]          --
│    └─Empty: 2-2593                     [16, 64, 16, 16]          --
│    └─Empty: 2-2594                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2595        --                        --
│    └─One: 2-2596                       [1]                       --
│    └─OutputScale: 2-2597               --                        --
│    └─Empty: 2-2598                     [64, 64, 3, 3]            --
│    └─Empty: 2-2599                     [64, 64, 3, 3]            --
│    └─Empty: 2-2600                     [64]                      --
│    └─Empty: 2-2601                     [64]                      --
│    └─BatchNorm2d: 2-2602               [16, 64, 16, 16]          --
│    └─Scaler: 2-2603                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2604                      [16, 64, 16, 16]          --
│    └─Empty: 2-2605                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2606                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2607        --                        --
│    └─One: 2-2608                       [1]                       --
│    └─OutputScale: 2-2609               --                        --
│    └─Empty: 2-2610                     [64, 64, 3, 3]            --
│    └─Empty: 2-2611                     [64, 64, 3, 3]            --
│    └─Empty: 2-2612                     [64]                      --
│    └─Empty: 2-2613                     [64]                      --
│    └─BatchNorm2d: 2-2614               [16, 64, 16, 16]          --
│    └─Scaler: 2-2615                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2616                      [16, 64, 16, 16]          --
│    └─Empty: 2-2617                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2618                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2619                 [16, 64, 8, 8]            --
│    └─Empty: 2-2620                     [16, 64, 8, 8]            --
│    └─Empty: 2-2621                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2622        --                        --
│    └─One: 2-2623                       [1]                       --
│    └─OutputScale: 2-2624               --                        --
│    └─Empty: 2-2625                     [64, 64, 3, 3]            --
│    └─Empty: 2-2626                     [64, 64, 3, 3]            --
│    └─Empty: 2-2627                     [64]                      --
│    └─Empty: 2-2628                     [64]                      --
│    └─BatchNorm2d: 2-2629               [16, 64, 8, 8]            --
│    └─Scaler: 2-2630                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2631                      [16, 64, 8, 8]            --
│    └─Empty: 2-2632                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2633                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2634        --                        --
│    └─One: 2-2635                       [1]                       --
│    └─OutputScale: 2-2636               --                        --
│    └─Empty: 2-2637                     [64, 64, 1, 1]            --
│    └─Empty: 2-2638                     [64, 64, 1, 1]            --
│    └─Empty: 2-2639                     [64]                      --
│    └─Empty: 2-2640                     [64]                      --
│    └─BatchNorm2d: 2-2641               [16, 64, 8, 8]            --
│    └─Scaler: 2-2642                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2643                      [16, 64, 8, 8]            --
│    └─Empty: 2-2644                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2645                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2646                 [16, 64, 8, 8]            --
│    └─Empty: 2-2647                     [16, 64, 8, 8]            --
│    └─Empty: 2-2648                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2649        --                        --
│    └─One: 2-2650                       [1]                       --
│    └─OutputScale: 2-2651               --                        --
│    └─Empty: 2-2652                     [64, 64, 3, 3]            --
│    └─Empty: 2-2653                     [64, 64, 3, 3]            --
│    └─Empty: 2-2654                     [64]                      --
│    └─Empty: 2-2655                     [64]                      --
│    └─BatchNorm2d: 2-2656               [16, 64, 8, 8]            --
│    └─Scaler: 2-2657                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2658                      [16, 64, 8, 8]            --
│    └─Empty: 2-2659                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2660                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2661                 [16, 64, 4, 4]            --
│    └─Empty: 2-2662                     [16, 64, 4, 4]            --
│    └─Empty: 2-2663                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2664        --                        --
│    └─One: 2-2665                       [1]                       --
│    └─OutputScale: 2-2666               --                        --
│    └─Empty: 2-2667                     [64, 64, 3, 3]            --
│    └─Empty: 2-2668                     [64, 64, 3, 3]            --
│    └─Empty: 2-2669                     [64]                      --
│    └─Empty: 2-2670                     [64]                      --
│    └─BatchNorm2d: 2-2671               [16, 64, 4, 4]            --
│    └─Scaler: 2-2672                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2673                      [16, 64, 4, 4]            --
│    └─Empty: 2-2674                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2675                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2676        --                        --
│    └─One: 2-2677                       [1]                       --
│    └─OutputScale: 2-2678               --                        --
│    └─Empty: 2-2679                     [64, 64, 1, 1]            --
│    └─Empty: 2-2680                     [64, 64, 1, 1]            --
│    └─Empty: 2-2681                     [64]                      --
│    └─Empty: 2-2682                     [64]                      --
│    └─BatchNorm2d: 2-2683               [16, 64, 4, 4]            --
│    └─Scaler: 2-2684                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2685                      [16, 64, 4, 4]            --
│    └─Empty: 2-2686                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2687                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2688                 [16, 64, 4, 4]            --
│    └─Empty: 2-2689                     [16, 64, 4, 4]            --
│    └─Empty: 2-2690                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2691        --                        --
│    └─One: 2-2692                       [1]                       --
│    └─OutputScale: 2-2693               --                        --
│    └─Empty: 2-2694                     [64, 64, 3, 3]            --
│    └─Empty: 2-2695                     [64, 64, 3, 3]            --
│    └─Empty: 2-2696                     [64]                      --
│    └─Empty: 2-2697                     [64]                      --
│    └─BatchNorm2d: 2-2698               [16, 64, 4, 4]            --
│    └─Scaler: 2-2699                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2700                      [16, 64, 4, 4]            --
│    └─Empty: 2-2701                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2702                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2703                 [16, 64, 2, 2]            --
│    └─Empty: 2-2704                     [16, 64, 2, 2]            --
│    └─Empty: 2-2705                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2706        --                        --
│    └─One: 2-2707                       [1]                       --
│    └─OutputScale: 2-2708               --                        --
│    └─Empty: 2-2709                     [64, 64, 1, 1]            --
│    └─Empty: 2-2710                     [64, 64, 1, 1]            --
│    └─Empty: 2-2711                     [64]                      --
│    └─Empty: 2-2712                     [64]                      --
│    └─BatchNorm2d: 2-2713               [16, 64, 2, 2]            --
│    └─Scaler: 2-2714                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2715                      [16, 64, 2, 2]            --
│    └─Empty: 2-2716                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2717                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2718        --                        --
│    └─One: 2-2719                       [1]                       --
│    └─OutputScale: 2-2720               --                        --
│    └─Empty: 2-2721                     [64, 64, 1, 1]            --
│    └─Empty: 2-2722                     [64, 64, 1, 1]            --
│    └─Empty: 2-2723                     [64]                      --
│    └─Empty: 2-2724                     [64]                      --
│    └─BatchNorm2d: 2-2725               [16, 64, 2, 2]            --
│    └─Scaler: 2-2726                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2727                      [16, 64, 2, 2]            --
│    └─Empty: 2-2728                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2729                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2730                 [16, 64, 2, 2]            --
│    └─Empty: 2-2731                     [16, 64, 2, 2]            --
│    └─Empty: 2-2732                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2733        --                        --
│    └─One: 2-2734                       [1]                       --
│    └─OutputScale: 2-2735               --                        --
│    └─Empty: 2-2736                     [64, 64, 3, 3]            --
│    └─Empty: 2-2737                     [64, 64, 3, 3]            --
│    └─Empty: 2-2738                     [64]                      --
│    └─Empty: 2-2739                     [64]                      --
│    └─BatchNorm2d: 2-2740               [16, 64, 2, 2]            --
│    └─Scaler: 2-2741                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2742                      [16, 64, 2, 2]            --
│    └─Empty: 2-2743                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2744                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2745        --                        --
│    └─One: 2-2746                       [1]                       --
│    └─OutputScale: 2-2747               --                        --
│    └─Empty: 2-2748                     [64, 48, 1, 1]            --
│    └─Empty: 2-2749                     [64, 48, 1, 1]            --
│    └─Empty: 2-2750                     [64]                      --
│    └─Empty: 2-2751                     [64]                      --
│    └─BatchNorm2d: 2-2752               [16, 64, 64, 64]          --
│    └─Scaler: 2-2753                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2754                      [16, 64, 64, 64]          --
│    └─Empty: 2-2755                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2756                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2757        --                        --
│    └─One: 2-2758                       [1]                       --
│    └─OutputScale: 2-2759               --                        --
│    └─Empty: 2-2760                     [64, 64, 3, 3]            --
│    └─Empty: 2-2761                     [64, 64, 3, 3]            --
│    └─Empty: 2-2762                     [64]                      --
│    └─Empty: 2-2763                     [64]                      --
│    └─BatchNorm2d: 2-2764               [16, 64, 64, 64]          --
│    └─Scaler: 2-2765                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2766                      [16, 64, 64, 64]          --
│    └─Empty: 2-2767                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2768                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2769        --                        --
│    └─One: 2-2770                       [1]                       --
│    └─OutputScale: 2-2771               --                        --
│    └─Empty: 2-2772                     [64, 64, 1, 1]            --
│    └─Empty: 2-2773                     [64, 64, 1, 1]            --
│    └─Empty: 2-2774                     [64]                      --
│    └─Empty: 2-2775                     [64]                      --
│    └─BatchNorm2d: 2-2776               [16, 64, 64, 64]          --
│    └─Scaler: 2-2777                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2778                      [16, 64, 64, 64]          --
│    └─Empty: 2-2779                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2780                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2781        --                        --
│    └─One: 2-2782                       [1]                       --
│    └─OutputScale: 2-2783               --                        --
│    └─Empty: 2-2784                     [64, 64, 3, 3]            --
│    └─Empty: 2-2785                     [64, 64, 3, 3]            --
│    └─Empty: 2-2786                     [64]                      --
│    └─Empty: 2-2787                     [64]                      --
│    └─BatchNorm2d: 2-2788               [16, 64, 64, 64]          --
│    └─Scaler: 2-2789                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2790                      [16, 64, 64, 64]          --
│    └─Empty: 2-2791                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2792                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2793                 [16, 64, 32, 32]          --
│    └─Empty: 2-2794                     [16, 64, 32, 32]          --
│    └─Empty: 2-2795                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2796        --                        --
│    └─One: 2-2797                       [1]                       --
│    └─OutputScale: 2-2798               --                        --
│    └─Empty: 2-2799                     [64, 64, 3, 3]            --
│    └─Empty: 2-2800                     [64, 64, 3, 3]            --
│    └─Empty: 2-2801                     [64]                      --
│    └─Empty: 2-2802                     [64]                      --
│    └─BatchNorm2d: 2-2803               [16, 64, 32, 32]          --
│    └─Scaler: 2-2804                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2805                      [16, 64, 32, 32]          --
│    └─Empty: 2-2806                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2807                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2808        --                        --
│    └─One: 2-2809                       [1]                       --
│    └─OutputScale: 2-2810               --                        --
│    └─Empty: 2-2811                     [64, 64, 3, 3]            --
│    └─Empty: 2-2812                     [64, 64, 3, 3]            --
│    └─Empty: 2-2813                     [64]                      --
│    └─Empty: 2-2814                     [64]                      --
│    └─BatchNorm2d: 2-2815               [16, 64, 32, 32]          --
│    └─Scaler: 2-2816                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2817                      [16, 64, 32, 32]          --
│    └─Empty: 2-2818                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2819                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2820                 [16, 64, 16, 16]          --
│    └─Empty: 2-2821                     [16, 64, 16, 16]          --
│    └─Empty: 2-2822                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2823        --                        --
│    └─One: 2-2824                       [1]                       --
│    └─OutputScale: 2-2825               --                        --
│    └─Empty: 2-2826                     [64, 64, 3, 3]            --
│    └─Empty: 2-2827                     [64, 64, 3, 3]            --
│    └─Empty: 2-2828                     [64]                      --
│    └─Empty: 2-2829                     [64]                      --
│    └─BatchNorm2d: 2-2830               [16, 64, 16, 16]          --
│    └─Scaler: 2-2831                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2832                      [16, 64, 16, 16]          --
│    └─Empty: 2-2833                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2834                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2835        --                        --
│    └─One: 2-2836                       [1]                       --
│    └─OutputScale: 2-2837               --                        --
│    └─Empty: 2-2838                     [64, 64, 3, 3]            --
│    └─Empty: 2-2839                     [64, 64, 3, 3]            --
│    └─Empty: 2-2840                     [64]                      --
│    └─Empty: 2-2841                     [64]                      --
│    └─BatchNorm2d: 2-2842               [16, 64, 16, 16]          --
│    └─Scaler: 2-2843                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2844                      [16, 64, 16, 16]          --
│    └─Empty: 2-2845                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2846                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2847                 [16, 64, 8, 8]            --
│    └─Empty: 2-2848                     [16, 64, 8, 8]            --
│    └─Empty: 2-2849                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2850        --                        --
│    └─One: 2-2851                       [1]                       --
│    └─OutputScale: 2-2852               --                        --
│    └─Empty: 2-2853                     [64, 64, 3, 3]            --
│    └─Empty: 2-2854                     [64, 64, 3, 3]            --
│    └─Empty: 2-2855                     [64]                      --
│    └─Empty: 2-2856                     [64]                      --
│    └─BatchNorm2d: 2-2857               [16, 64, 8, 8]            --
│    └─Scaler: 2-2858                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2859                      [16, 64, 8, 8]            --
│    └─Empty: 2-2860                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2861                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2862        --                        --
│    └─One: 2-2863                       [1]                       --
│    └─OutputScale: 2-2864               --                        --
│    └─Empty: 2-2865                     [64, 64, 1, 1]            --
│    └─Empty: 2-2866                     [64, 64, 1, 1]            --
│    └─Empty: 2-2867                     [64]                      --
│    └─Empty: 2-2868                     [64]                      --
│    └─BatchNorm2d: 2-2869               [16, 64, 8, 8]            --
│    └─Scaler: 2-2870                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2871                      [16, 64, 8, 8]            --
│    └─Empty: 2-2872                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2873                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2874                 [16, 64, 8, 8]            --
│    └─Empty: 2-2875                     [16, 64, 8, 8]            --
│    └─Empty: 2-2876                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2877        --                        --
│    └─One: 2-2878                       [1]                       --
│    └─OutputScale: 2-2879               --                        --
│    └─Empty: 2-2880                     [64, 64, 3, 3]            --
│    └─Empty: 2-2881                     [64, 64, 3, 3]            --
│    └─Empty: 2-2882                     [64]                      --
│    └─Empty: 2-2883                     [64]                      --
│    └─BatchNorm2d: 2-2884               [16, 64, 8, 8]            --
│    └─Scaler: 2-2885                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2886                      [16, 64, 8, 8]            --
│    └─Empty: 2-2887                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2888                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2889                 [16, 64, 4, 4]            --
│    └─Empty: 2-2890                     [16, 64, 4, 4]            --
│    └─Empty: 2-2891                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2892        --                        --
│    └─One: 2-2893                       [1]                       --
│    └─OutputScale: 2-2894               --                        --
│    └─Empty: 2-2895                     [64, 64, 3, 3]            --
│    └─Empty: 2-2896                     [64, 64, 3, 3]            --
│    └─Empty: 2-2897                     [64]                      --
│    └─Empty: 2-2898                     [64]                      --
│    └─BatchNorm2d: 2-2899               [16, 64, 4, 4]            --
│    └─Scaler: 2-2900                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2901                      [16, 64, 4, 4]            --
│    └─Empty: 2-2902                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2903                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2904        --                        --
│    └─One: 2-2905                       [1]                       --
│    └─OutputScale: 2-2906               --                        --
│    └─Empty: 2-2907                     [64, 64, 1, 1]            --
│    └─Empty: 2-2908                     [64, 64, 1, 1]            --
│    └─Empty: 2-2909                     [64]                      --
│    └─Empty: 2-2910                     [64]                      --
│    └─BatchNorm2d: 2-2911               [16, 64, 4, 4]            --
│    └─Scaler: 2-2912                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2913                      [16, 64, 4, 4]            --
│    └─Empty: 2-2914                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2915                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2916                 [16, 64, 4, 4]            --
│    └─Empty: 2-2917                     [16, 64, 4, 4]            --
│    └─Empty: 2-2918                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2919        --                        --
│    └─One: 2-2920                       [1]                       --
│    └─OutputScale: 2-2921               --                        --
│    └─Empty: 2-2922                     [64, 64, 3, 3]            --
│    └─Empty: 2-2923                     [64, 64, 3, 3]            --
│    └─Empty: 2-2924                     [64]                      --
│    └─Empty: 2-2925                     [64]                      --
│    └─BatchNorm2d: 2-2926               [16, 64, 4, 4]            --
│    └─Scaler: 2-2927                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2928                      [16, 64, 4, 4]            --
│    └─Empty: 2-2929                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2930                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2931                 [16, 64, 2, 2]            --
│    └─Empty: 2-2932                     [16, 64, 2, 2]            --
│    └─Empty: 2-2933                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2934        --                        --
│    └─One: 2-2935                       [1]                       --
│    └─OutputScale: 2-2936               --                        --
│    └─Empty: 2-2937                     [64, 64, 1, 1]            --
│    └─Empty: 2-2938                     [64, 64, 1, 1]            --
│    └─Empty: 2-2939                     [64]                      --
│    └─Empty: 2-2940                     [64]                      --
│    └─BatchNorm2d: 2-2941               [16, 64, 2, 2]            --
│    └─Scaler: 2-2942                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2943                      [16, 64, 2, 2]            --
│    └─Empty: 2-2944                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2945                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2946        --                        --
│    └─One: 2-2947                       [1]                       --
│    └─OutputScale: 2-2948               --                        --
│    └─Empty: 2-2949                     [64, 64, 1, 1]            --
│    └─Empty: 2-2950                     [64, 64, 1, 1]            --
│    └─Empty: 2-2951                     [64]                      --
│    └─Empty: 2-2952                     [64]                      --
│    └─BatchNorm2d: 2-2953               [16, 64, 2, 2]            --
│    └─Scaler: 2-2954                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2955                      [16, 64, 2, 2]            --
│    └─Empty: 2-2956                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2957                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2958                 [16, 64, 2, 2]            --
│    └─Empty: 2-2959                     [16, 64, 2, 2]            --
│    └─Empty: 2-2960                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2961        --                        --
│    └─One: 2-2962                       [1]                       --
│    └─OutputScale: 2-2963               --                        --
│    └─Empty: 2-2964                     [64, 64, 3, 3]            --
│    └─Empty: 2-2965                     [64, 64, 3, 3]            --
│    └─Empty: 2-2966                     [64]                      --
│    └─Empty: 2-2967                     [64]                      --
│    └─BatchNorm2d: 2-2968               [16, 64, 2, 2]            --
│    └─Scaler: 2-2969                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2970                      [16, 64, 2, 2]            --
│    └─Empty: 2-2971                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2972                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2973        --                        --
│    └─One: 2-2974                       [1]                       --
│    └─OutputScale: 2-2975               --                        --
│    └─Empty: 2-2976                     [64, 48, 1, 1]            --
│    └─Empty: 2-2977                     [64, 48, 1, 1]            --
│    └─Empty: 2-2978                     [64]                      --
│    └─Empty: 2-2979                     [64]                      --
│    └─BatchNorm2d: 2-2980               [16, 64, 64, 64]          --
│    └─Scaler: 2-2981                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2982                      [16, 64, 64, 64]          --
│    └─Empty: 2-2983                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2984                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2985        --                        --
│    └─One: 2-2986                       [1]                       --
│    └─OutputScale: 2-2987               --                        --
│    └─Empty: 2-2988                     [64, 64, 3, 3]            --
│    └─Empty: 2-2989                     [64, 64, 3, 3]            --
│    └─Empty: 2-2990                     [64]                      --
│    └─Empty: 2-2991                     [64]                      --
│    └─BatchNorm2d: 2-2992               [16, 64, 64, 64]          --
│    └─Scaler: 2-2993                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2994                      [16, 64, 64, 64]          --
│    └─Empty: 2-2995                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2996                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2997        --                        --
│    └─One: 2-2998                       [1]                       --
│    └─OutputScale: 2-2999               --                        --
│    └─Empty: 2-3000                     [64, 64, 1, 1]            --
│    └─Empty: 2-3001                     [64, 64, 1, 1]            --
│    └─Empty: 2-3002                     [64]                      --
│    └─Empty: 2-3003                     [64]                      --
│    └─BatchNorm2d: 2-3004               [16, 64, 64, 64]          --
│    └─Scaler: 2-3005                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3006                      [16, 64, 64, 64]          --
│    └─Empty: 2-3007                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3008                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3009        --                        --
│    └─One: 2-3010                       [1]                       --
│    └─OutputScale: 2-3011               --                        --
│    └─Empty: 2-3012                     [64, 64, 3, 3]            --
│    └─Empty: 2-3013                     [64, 64, 3, 3]            --
│    └─Empty: 2-3014                     [64]                      --
│    └─Empty: 2-3015                     [64]                      --
│    └─BatchNorm2d: 2-3016               [16, 64, 64, 64]          --
│    └─Scaler: 2-3017                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3018                      [16, 64, 64, 64]          --
│    └─Empty: 2-3019                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3020                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3021                 [16, 64, 32, 32]          --
│    └─Empty: 2-3022                     [16, 64, 32, 32]          --
│    └─Empty: 2-3023                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3024        --                        --
│    └─One: 2-3025                       [1]                       --
│    └─OutputScale: 2-3026               --                        --
│    └─Empty: 2-3027                     [64, 64, 3, 3]            --
│    └─Empty: 2-3028                     [64, 64, 3, 3]            --
│    └─Empty: 2-3029                     [64]                      --
│    └─Empty: 2-3030                     [64]                      --
│    └─BatchNorm2d: 2-3031               [16, 64, 32, 32]          --
│    └─Scaler: 2-3032                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3033                      [16, 64, 32, 32]          --
│    └─Empty: 2-3034                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3035                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3036        --                        --
│    └─One: 2-3037                       [1]                       --
│    └─OutputScale: 2-3038               --                        --
│    └─Empty: 2-3039                     [64, 64, 3, 3]            --
│    └─Empty: 2-3040                     [64, 64, 3, 3]            --
│    └─Empty: 2-3041                     [64]                      --
│    └─Empty: 2-3042                     [64]                      --
│    └─BatchNorm2d: 2-3043               [16, 64, 32, 32]          --
│    └─Scaler: 2-3044                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3045                      [16, 64, 32, 32]          --
│    └─Empty: 2-3046                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3047                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3048                 [16, 64, 16, 16]          --
│    └─Empty: 2-3049                     [16, 64, 16, 16]          --
│    └─Empty: 2-3050                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3051        --                        --
│    └─One: 2-3052                       [1]                       --
│    └─OutputScale: 2-3053               --                        --
│    └─Empty: 2-3054                     [64, 64, 3, 3]            --
│    └─Empty: 2-3055                     [64, 64, 3, 3]            --
│    └─Empty: 2-3056                     [64]                      --
│    └─Empty: 2-3057                     [64]                      --
│    └─BatchNorm2d: 2-3058               [16, 64, 16, 16]          --
│    └─Scaler: 2-3059                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3060                      [16, 64, 16, 16]          --
│    └─Empty: 2-3061                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3062                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3063        --                        --
│    └─One: 2-3064                       [1]                       --
│    └─OutputScale: 2-3065               --                        --
│    └─Empty: 2-3066                     [64, 64, 3, 3]            --
│    └─Empty: 2-3067                     [64, 64, 3, 3]            --
│    └─Empty: 2-3068                     [64]                      --
│    └─Empty: 2-3069                     [64]                      --
│    └─BatchNorm2d: 2-3070               [16, 64, 16, 16]          --
│    └─Scaler: 2-3071                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3072                      [16, 64, 16, 16]          --
│    └─Empty: 2-3073                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3074                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3075                 [16, 64, 8, 8]            --
│    └─Empty: 2-3076                     [16, 64, 8, 8]            --
│    └─Empty: 2-3077                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3078        --                        --
│    └─One: 2-3079                       [1]                       --
│    └─OutputScale: 2-3080               --                        --
│    └─Empty: 2-3081                     [64, 64, 3, 3]            --
│    └─Empty: 2-3082                     [64, 64, 3, 3]            --
│    └─Empty: 2-3083                     [64]                      --
│    └─Empty: 2-3084                     [64]                      --
│    └─BatchNorm2d: 2-3085               [16, 64, 8, 8]            --
│    └─Scaler: 2-3086                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3087                      [16, 64, 8, 8]            --
│    └─Empty: 2-3088                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3089                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3090        --                        --
│    └─One: 2-3091                       [1]                       --
│    └─OutputScale: 2-3092               --                        --
│    └─Empty: 2-3093                     [64, 64, 1, 1]            --
│    └─Empty: 2-3094                     [64, 64, 1, 1]            --
│    └─Empty: 2-3095                     [64]                      --
│    └─Empty: 2-3096                     [64]                      --
│    └─BatchNorm2d: 2-3097               [16, 64, 8, 8]            --
│    └─Scaler: 2-3098                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3099                      [16, 64, 8, 8]            --
│    └─Empty: 2-3100                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3101                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3102                 [16, 64, 8, 8]            --
│    └─Empty: 2-3103                     [16, 64, 8, 8]            --
│    └─Empty: 2-3104                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3105        --                        --
│    └─One: 2-3106                       [1]                       --
│    └─OutputScale: 2-3107               --                        --
│    └─Empty: 2-3108                     [64, 64, 3, 3]            --
│    └─Empty: 2-3109                     [64, 64, 3, 3]            --
│    └─Empty: 2-3110                     [64]                      --
│    └─Empty: 2-3111                     [64]                      --
│    └─BatchNorm2d: 2-3112               [16, 64, 8, 8]            --
│    └─Scaler: 2-3113                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3114                      [16, 64, 8, 8]            --
│    └─Empty: 2-3115                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3116                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3117                 [16, 64, 4, 4]            --
│    └─Empty: 2-3118                     [16, 64, 4, 4]            --
│    └─Empty: 2-3119                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3120        --                        --
│    └─One: 2-3121                       [1]                       --
│    └─OutputScale: 2-3122               --                        --
│    └─Empty: 2-3123                     [64, 64, 3, 3]            --
│    └─Empty: 2-3124                     [64, 64, 3, 3]            --
│    └─Empty: 2-3125                     [64]                      --
│    └─Empty: 2-3126                     [64]                      --
│    └─BatchNorm2d: 2-3127               [16, 64, 4, 4]            --
│    └─Scaler: 2-3128                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3129                      [16, 64, 4, 4]            --
│    └─Empty: 2-3130                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3131                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3132        --                        --
│    └─One: 2-3133                       [1]                       --
│    └─OutputScale: 2-3134               --                        --
│    └─Empty: 2-3135                     [64, 64, 1, 1]            --
│    └─Empty: 2-3136                     [64, 64, 1, 1]            --
│    └─Empty: 2-3137                     [64]                      --
│    └─Empty: 2-3138                     [64]                      --
│    └─BatchNorm2d: 2-3139               [16, 64, 4, 4]            --
│    └─Scaler: 2-3140                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3141                      [16, 64, 4, 4]            --
│    └─Empty: 2-3142                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3143                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3144                 [16, 64, 4, 4]            --
│    └─Empty: 2-3145                     [16, 64, 4, 4]            --
│    └─Empty: 2-3146                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3147        --                        --
│    └─One: 2-3148                       [1]                       --
│    └─OutputScale: 2-3149               --                        --
│    └─Empty: 2-3150                     [64, 64, 3, 3]            --
│    └─Empty: 2-3151                     [64, 64, 3, 3]            --
│    └─Empty: 2-3152                     [64]                      --
│    └─Empty: 2-3153                     [64]                      --
│    └─BatchNorm2d: 2-3154               [16, 64, 4, 4]            --
│    └─Scaler: 2-3155                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3156                      [16, 64, 4, 4]            --
│    └─Empty: 2-3157                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3158                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3159                 [16, 64, 2, 2]            --
│    └─Empty: 2-3160                     [16, 64, 2, 2]            --
│    └─Empty: 2-3161                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3162        --                        --
│    └─One: 2-3163                       [1]                       --
│    └─OutputScale: 2-3164               --                        --
│    └─Empty: 2-3165                     [64, 64, 1, 1]            --
│    └─Empty: 2-3166                     [64, 64, 1, 1]            --
│    └─Empty: 2-3167                     [64]                      --
│    └─Empty: 2-3168                     [64]                      --
│    └─BatchNorm2d: 2-3169               [16, 64, 2, 2]            --
│    └─Scaler: 2-3170                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3171                      [16, 64, 2, 2]            --
│    └─Empty: 2-3172                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3173                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3174        --                        --
│    └─One: 2-3175                       [1]                       --
│    └─OutputScale: 2-3176               --                        --
│    └─Empty: 2-3177                     [64, 64, 1, 1]            --
│    └─Empty: 2-3178                     [64, 64, 1, 1]            --
│    └─Empty: 2-3179                     [64]                      --
│    └─Empty: 2-3180                     [64]                      --
│    └─BatchNorm2d: 2-3181               [16, 64, 2, 2]            --
│    └─Scaler: 2-3182                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3183                      [16, 64, 2, 2]            --
│    └─Empty: 2-3184                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3185                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3186                 [16, 64, 2, 2]            --
│    └─Empty: 2-3187                     [16, 64, 2, 2]            --
│    └─Empty: 2-3188                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3189        --                        --
│    └─One: 2-3190                       [1]                       --
│    └─OutputScale: 2-3191               --                        --
│    └─Empty: 2-3192                     [64, 64, 3, 3]            --
│    └─Empty: 2-3193                     [64, 64, 3, 3]            --
│    └─Empty: 2-3194                     [64]                      --
│    └─Empty: 2-3195                     [64]                      --
│    └─BatchNorm2d: 2-3196               [16, 64, 2, 2]            --
│    └─Scaler: 2-3197                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3198                      [16, 64, 2, 2]            --
│    └─Empty: 2-3199                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3200                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3201        --                        --
│    └─One: 2-3202                       [1]                       --
│    └─OutputScale: 2-3203               --                        --
│    └─Empty: 2-3204                     [64, 48, 1, 1]            --
│    └─Empty: 2-3205                     [64, 48, 1, 1]            --
│    └─Empty: 2-3206                     [64]                      --
│    └─Empty: 2-3207                     [64]                      --
│    └─BatchNorm2d: 2-3208               [16, 64, 64, 64]          --
│    └─Scaler: 2-3209                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3210                      [16, 64, 64, 64]          --
│    └─Empty: 2-3211                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3212                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3213        --                        --
│    └─One: 2-3214                       [1]                       --
│    └─OutputScale: 2-3215               --                        --
│    └─Empty: 2-3216                     [64, 64, 3, 3]            --
│    └─Empty: 2-3217                     [64, 64, 3, 3]            --
│    └─Empty: 2-3218                     [64]                      --
│    └─Empty: 2-3219                     [64]                      --
│    └─BatchNorm2d: 2-3220               [16, 64, 64, 64]          --
│    └─Scaler: 2-3221                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3222                      [16, 64, 64, 64]          --
│    └─Empty: 2-3223                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3224                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3225        --                        --
│    └─One: 2-3226                       [1]                       --
│    └─OutputScale: 2-3227               --                        --
│    └─Empty: 2-3228                     [64, 64, 1, 1]            --
│    └─Empty: 2-3229                     [64, 64, 1, 1]            --
│    └─Empty: 2-3230                     [64]                      --
│    └─Empty: 2-3231                     [64]                      --
│    └─BatchNorm2d: 2-3232               [16, 64, 64, 64]          --
│    └─Scaler: 2-3233                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3234                      [16, 64, 64, 64]          --
│    └─Empty: 2-3235                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3236                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3237        --                        --
│    └─One: 2-3238                       [1]                       --
│    └─OutputScale: 2-3239               --                        --
│    └─Empty: 2-3240                     [64, 64, 3, 3]            --
│    └─Empty: 2-3241                     [64, 64, 3, 3]            --
│    └─Empty: 2-3242                     [64]                      --
│    └─Empty: 2-3243                     [64]                      --
│    └─BatchNorm2d: 2-3244               [16, 64, 64, 64]          --
│    └─Scaler: 2-3245                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3246                      [16, 64, 64, 64]          --
│    └─Empty: 2-3247                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3248                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3249                 [16, 64, 32, 32]          --
│    └─Empty: 2-3250                     [16, 64, 32, 32]          --
│    └─Empty: 2-3251                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3252        --                        --
│    └─One: 2-3253                       [1]                       --
│    └─OutputScale: 2-3254               --                        --
│    └─Empty: 2-3255                     [64, 64, 3, 3]            --
│    └─Empty: 2-3256                     [64, 64, 3, 3]            --
│    └─Empty: 2-3257                     [64]                      --
│    └─Empty: 2-3258                     [64]                      --
│    └─BatchNorm2d: 2-3259               [16, 64, 32, 32]          --
│    └─Scaler: 2-3260                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3261                      [16, 64, 32, 32]          --
│    └─Empty: 2-3262                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3263                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3264        --                        --
│    └─One: 2-3265                       [1]                       --
│    └─OutputScale: 2-3266               --                        --
│    └─Empty: 2-3267                     [64, 64, 3, 3]            --
│    └─Empty: 2-3268                     [64, 64, 3, 3]            --
│    └─Empty: 2-3269                     [64]                      --
│    └─Empty: 2-3270                     [64]                      --
│    └─BatchNorm2d: 2-3271               [16, 64, 32, 32]          --
│    └─Scaler: 2-3272                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3273                      [16, 64, 32, 32]          --
│    └─Empty: 2-3274                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3275                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3276                 [16, 64, 16, 16]          --
│    └─Empty: 2-3277                     [16, 64, 16, 16]          --
│    └─Empty: 2-3278                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3279        --                        --
│    └─One: 2-3280                       [1]                       --
│    └─OutputScale: 2-3281               --                        --
│    └─Empty: 2-3282                     [64, 64, 3, 3]            --
│    └─Empty: 2-3283                     [64, 64, 3, 3]            --
│    └─Empty: 2-3284                     [64]                      --
│    └─Empty: 2-3285                     [64]                      --
│    └─BatchNorm2d: 2-3286               [16, 64, 16, 16]          --
│    └─Scaler: 2-3287                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3288                      [16, 64, 16, 16]          --
│    └─Empty: 2-3289                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3290                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3291        --                        --
│    └─One: 2-3292                       [1]                       --
│    └─OutputScale: 2-3293               --                        --
│    └─Empty: 2-3294                     [64, 64, 3, 3]            --
│    └─Empty: 2-3295                     [64, 64, 3, 3]            --
│    └─Empty: 2-3296                     [64]                      --
│    └─Empty: 2-3297                     [64]                      --
│    └─BatchNorm2d: 2-3298               [16, 64, 16, 16]          --
│    └─Scaler: 2-3299                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3300                      [16, 64, 16, 16]          --
│    └─Empty: 2-3301                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3302                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3303                 [16, 64, 8, 8]            --
│    └─Empty: 2-3304                     [16, 64, 8, 8]            --
│    └─Empty: 2-3305                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3306        --                        --
│    └─One: 2-3307                       [1]                       --
│    └─OutputScale: 2-3308               --                        --
│    └─Empty: 2-3309                     [64, 64, 3, 3]            --
│    └─Empty: 2-3310                     [64, 64, 3, 3]            --
│    └─Empty: 2-3311                     [64]                      --
│    └─Empty: 2-3312                     [64]                      --
│    └─BatchNorm2d: 2-3313               [16, 64, 8, 8]            --
│    └─Scaler: 2-3314                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3315                      [16, 64, 8, 8]            --
│    └─Empty: 2-3316                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3317                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3318        --                        --
│    └─One: 2-3319                       [1]                       --
│    └─OutputScale: 2-3320               --                        --
│    └─Empty: 2-3321                     [64, 64, 1, 1]            --
│    └─Empty: 2-3322                     [64, 64, 1, 1]            --
│    └─Empty: 2-3323                     [64]                      --
│    └─Empty: 2-3324                     [64]                      --
│    └─BatchNorm2d: 2-3325               [16, 64, 8, 8]            --
│    └─Scaler: 2-3326                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3327                      [16, 64, 8, 8]            --
│    └─Empty: 2-3328                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3329                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3330                 [16, 64, 8, 8]            --
│    └─Empty: 2-3331                     [16, 64, 8, 8]            --
│    └─Empty: 2-3332                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3333        --                        --
│    └─One: 2-3334                       [1]                       --
│    └─OutputScale: 2-3335               --                        --
│    └─Empty: 2-3336                     [64, 64, 3, 3]            --
│    └─Empty: 2-3337                     [64, 64, 3, 3]            --
│    └─Empty: 2-3338                     [64]                      --
│    └─Empty: 2-3339                     [64]                      --
│    └─BatchNorm2d: 2-3340               [16, 64, 8, 8]            --
│    └─Scaler: 2-3341                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3342                      [16, 64, 8, 8]            --
│    └─Empty: 2-3343                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3344                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3345                 [16, 64, 4, 4]            --
│    └─Empty: 2-3346                     [16, 64, 4, 4]            --
│    └─Empty: 2-3347                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3348        --                        --
│    └─One: 2-3349                       [1]                       --
│    └─OutputScale: 2-3350               --                        --
│    └─Empty: 2-3351                     [64, 64, 3, 3]            --
│    └─Empty: 2-3352                     [64, 64, 3, 3]            --
│    └─Empty: 2-3353                     [64]                      --
│    └─Empty: 2-3354                     [64]                      --
│    └─BatchNorm2d: 2-3355               [16, 64, 4, 4]            --
│    └─Scaler: 2-3356                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3357                      [16, 64, 4, 4]            --
│    └─Empty: 2-3358                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3359                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3360        --                        --
│    └─One: 2-3361                       [1]                       --
│    └─OutputScale: 2-3362               --                        --
│    └─Empty: 2-3363                     [64, 64, 1, 1]            --
│    └─Empty: 2-3364                     [64, 64, 1, 1]            --
│    └─Empty: 2-3365                     [64]                      --
│    └─Empty: 2-3366                     [64]                      --
│    └─BatchNorm2d: 2-3367               [16, 64, 4, 4]            --
│    └─Scaler: 2-3368                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3369                      [16, 64, 4, 4]            --
│    └─Empty: 2-3370                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3371                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3372                 [16, 64, 4, 4]            --
│    └─Empty: 2-3373                     [16, 64, 4, 4]            --
│    └─Empty: 2-3374                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3375        --                        --
│    └─One: 2-3376                       [1]                       --
│    └─OutputScale: 2-3377               --                        --
│    └─Empty: 2-3378                     [64, 64, 3, 3]            --
│    └─Empty: 2-3379                     [64, 64, 3, 3]            --
│    └─Empty: 2-3380                     [64]                      --
│    └─Empty: 2-3381                     [64]                      --
│    └─BatchNorm2d: 2-3382               [16, 64, 4, 4]            --
│    └─Scaler: 2-3383                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3384                      [16, 64, 4, 4]            --
│    └─Empty: 2-3385                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3386                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3387                 [16, 64, 2, 2]            --
│    └─Empty: 2-3388                     [16, 64, 2, 2]            --
│    └─Empty: 2-3389                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3390        --                        --
│    └─One: 2-3391                       [1]                       --
│    └─OutputScale: 2-3392               --                        --
│    └─Empty: 2-3393                     [64, 64, 1, 1]            --
│    └─Empty: 2-3394                     [64, 64, 1, 1]            --
│    └─Empty: 2-3395                     [64]                      --
│    └─Empty: 2-3396                     [64]                      --
│    └─BatchNorm2d: 2-3397               [16, 64, 2, 2]            --
│    └─Scaler: 2-3398                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3399                      [16, 64, 2, 2]            --
│    └─Empty: 2-3400                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3401                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3402        --                        --
│    └─One: 2-3403                       [1]                       --
│    └─OutputScale: 2-3404               --                        --
│    └─Empty: 2-3405                     [64, 64, 1, 1]            --
│    └─Empty: 2-3406                     [64, 64, 1, 1]            --
│    └─Empty: 2-3407                     [64]                      --
│    └─Empty: 2-3408                     [64]                      --
│    └─BatchNorm2d: 2-3409               [16, 64, 2, 2]            --
│    └─Scaler: 2-3410                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3411                      [16, 64, 2, 2]            --
│    └─Empty: 2-3412                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3413                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3414                 [16, 64, 2, 2]            --
│    └─Empty: 2-3415                     [16, 64, 2, 2]            --
│    └─Empty: 2-3416                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3417        --                        --
│    └─One: 2-3418                       [1]                       --
│    └─OutputScale: 2-3419               --                        --
│    └─Empty: 2-3420                     [64, 64, 3, 3]            --
│    └─Empty: 2-3421                     [64, 64, 3, 3]            --
│    └─Empty: 2-3422                     [64]                      --
│    └─Empty: 2-3423                     [64]                      --
│    └─BatchNorm2d: 2-3424               [16, 64, 2, 2]            --
│    └─Scaler: 2-3425                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3426                      [16, 64, 2, 2]            --
│    └─Empty: 2-3427                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3428                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3429        --                        --
│    └─One: 2-3430                       [1]                       --
│    └─OutputScale: 2-3431               --                        --
│    └─Empty: 2-3432                     [64, 48, 1, 1]            --
│    └─Empty: 2-3433                     [64, 48, 1, 1]            --
│    └─Empty: 2-3434                     [64]                      --
│    └─Empty: 2-3435                     [64]                      --
│    └─BatchNorm2d: 2-3436               [16, 64, 64, 64]          --
│    └─Scaler: 2-3437                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3438                      [16, 64, 64, 64]          --
│    └─Empty: 2-3439                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3440                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3441        --                        --
│    └─One: 2-3442                       [1]                       --
│    └─OutputScale: 2-3443               --                        --
│    └─Empty: 2-3444                     [64, 64, 3, 3]            --
│    └─Empty: 2-3445                     [64, 64, 3, 3]            --
│    └─Empty: 2-3446                     [64]                      --
│    └─Empty: 2-3447                     [64]                      --
│    └─BatchNorm2d: 2-3448               [16, 64, 64, 64]          --
│    └─Scaler: 2-3449                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3450                      [16, 64, 64, 64]          --
│    └─Empty: 2-3451                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3452                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3453        --                        --
│    └─One: 2-3454                       [1]                       --
│    └─OutputScale: 2-3455               --                        --
│    └─Empty: 2-3456                     [64, 64, 1, 1]            --
│    └─Empty: 2-3457                     [64, 64, 1, 1]            --
│    └─Empty: 2-3458                     [64]                      --
│    └─Empty: 2-3459                     [64]                      --
│    └─BatchNorm2d: 2-3460               [16, 64, 64, 64]          --
│    └─Scaler: 2-3461                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3462                      [16, 64, 64, 64]          --
│    └─Empty: 2-3463                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3464                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3465        --                        --
│    └─One: 2-3466                       [1]                       --
│    └─OutputScale: 2-3467               --                        --
│    └─Empty: 2-3468                     [64, 64, 3, 3]            --
│    └─Empty: 2-3469                     [64, 64, 3, 3]            --
│    └─Empty: 2-3470                     [64]                      --
│    └─Empty: 2-3471                     [64]                      --
│    └─BatchNorm2d: 2-3472               [16, 64, 64, 64]          --
│    └─Scaler: 2-3473                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3474                      [16, 64, 64, 64]          --
│    └─Empty: 2-3475                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3476                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3477                 [16, 64, 32, 32]          --
│    └─Empty: 2-3478                     [16, 64, 32, 32]          --
│    └─Empty: 2-3479                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3480        --                        --
│    └─One: 2-3481                       [1]                       --
│    └─OutputScale: 2-3482               --                        --
│    └─Empty: 2-3483                     [64, 64, 3, 3]            --
│    └─Empty: 2-3484                     [64, 64, 3, 3]            --
│    └─Empty: 2-3485                     [64]                      --
│    └─Empty: 2-3486                     [64]                      --
│    └─BatchNorm2d: 2-3487               [16, 64, 32, 32]          --
│    └─Scaler: 2-3488                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─Empty: 2-3490                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3491                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3492        --                        --
│    └─One: 2-3493                       [1]                       --
│    └─OutputScale: 2-3494               --                        --
│    └─Empty: 2-3495                     [64, 64, 3, 3]            --
│    └─Empty: 2-3496                     [64, 64, 3, 3]            --
│    └─Empty: 2-3497                     [64]                      --
│    └─Empty: 2-3498                     [64]                      --
│    └─BatchNorm2d: 2-3499               [16, 64, 32, 32]          --
│    └─Scaler: 2-3500                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3501                      [16, 64, 32, 32]          --
│    └─Empty: 2-3502                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3503                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3504                 [16, 64, 16, 16]          --
│    └─Empty: 2-3505                     [16, 64, 16, 16]          --
│    └─Empty: 2-3506                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3507        --                        --
│    └─One: 2-3508                       [1]                       --
│    └─OutputScale: 2-3509               --                        --
│    └─Empty: 2-3510                     [64, 64, 3, 3]            --
│    └─Empty: 2-3511                     [64, 64, 3, 3]            --
│    └─Empty: 2-3512                     [64]                      --
│    └─Empty: 2-3513                     [64]                      --
│    └─BatchNorm2d: 2-3514               [16, 64, 16, 16]          --
│    └─Scaler: 2-3515                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
│    └─Empty: 2-3517                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3518                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3519        --                        --
│    └─One: 2-3520                       [1]                       --
│    └─OutputScale: 2-3521               --                        --
│    └─Empty: 2-3522                     [64, 64, 3, 3]            --
│    └─Empty: 2-3523                     [64, 64, 3, 3]            --
│    └─Empty: 2-3524                     [64]                      --
│    └─Empty: 2-3525                     [64]                      --
│    └─BatchNorm2d: 2-3526               [16, 64, 16, 16]          --
│    └─Scaler: 2-3527                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3528                      [16, 64, 16, 16]          --
│    └─Empty: 2-3529                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3530                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3531                 [16, 64, 8, 8]            --
│    └─Empty: 2-3532                     [16, 64, 8, 8]            --
│    └─Empty: 2-3533                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3534        --                        --
│    └─One: 2-3535                       [1]                       --
│    └─OutputScale: 2-3536               --                        --
│    └─Empty: 2-3537                     [64, 64, 3, 3]            --
│    └─Empty: 2-3538                     [64, 64, 3, 3]            --
│    └─Empty: 2-3539                     [64]                      --
│    └─Empty: 2-3540                     [64]                      --
│    └─BatchNorm2d: 2-3541               [16, 64, 8, 8]            --
│    └─Scaler: 2-3542                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
│    └─Empty: 2-3544                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3545                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3546        --                        --
│    └─One: 2-3547                       [1]                       --
│    └─OutputScale: 2-3548               --                        --
│    └─Empty: 2-3549                     [64, 64, 1, 1]            --
│    └─Empty: 2-3550                     [64, 64, 1, 1]            --
│    └─Empty: 2-3551                     [64]                      --
│    └─Empty: 2-3552                     [64]                      --
│    └─BatchNorm2d: 2-3553               [16, 64, 8, 8]            --
│    └─Scaler: 2-3554                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3555                      [16, 64, 8, 8]            --
│    └─Empty: 2-3556                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3557                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3558                 [16, 64, 8, 8]            --
│    └─Empty: 2-3559                     [16, 64, 8, 8]            --
│    └─Empty: 2-3560                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3561        --                        --
│    └─One: 2-3562                       [1]                       --
│    └─OutputScale: 2-3563               --                        --
│    └─Empty: 2-3564                     [64, 64, 3, 3]            --
│    └─Empty: 2-3565                     [64, 64, 3, 3]            --
│    └─Empty: 2-3566                     [64]                      --
│    └─Empty: 2-3567                     [64]                      --
│    └─BatchNorm2d: 2-3568               [16, 64, 8, 8]            --
│    └─Scaler: 2-3569                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
│    └─Empty: 2-3571                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3572                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3573                 [16, 64, 4, 4]            --
│    └─Empty: 2-3574                     [16, 64, 4, 4]            --
│    └─Empty: 2-3575                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3576        --                        --
│    └─One: 2-3577                       [1]                       --
│    └─OutputScale: 2-3578               --                        --
│    └─Empty: 2-3579                     [64, 64, 3, 3]            --
│    └─Empty: 2-3580                     [64, 64, 3, 3]            --
│    └─Empty: 2-3581                     [64]                      --
│    └─Empty: 2-3582                     [64]                      --
│    └─BatchNorm2d: 2-3583               [16, 64, 4, 4]            --
│    └─Scaler: 2-3584                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
│    └─Empty: 2-3586                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3587                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3588        --                        --
│    └─One: 2-3589                       [1]                       --
│    └─OutputScale: 2-3590               --                        --
│    └─Empty: 2-3591                     [64, 64, 1, 1]            --
│    └─Empty: 2-3592                     [64, 64, 1, 1]            --
│    └─Empty: 2-3593                     [64]                      --
│    └─Empty: 2-3594                     [64]                      --
│    └─BatchNorm2d: 2-3595               [16, 64, 4, 4]            --
│    └─Scaler: 2-3596                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3597                      [16, 64, 4, 4]            --
│    └─Empty: 2-3598                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3599                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3600                 [16, 64, 4, 4]            --
│    └─Empty: 2-3601                     [16, 64, 4, 4]            --
│    └─Empty: 2-3602                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3603        --                        --
│    └─One: 2-3604                       [1]                       --
│    └─OutputScale: 2-3605               --                        --
│    └─Empty: 2-3606                     [64, 64, 3, 3]            --
│    └─Empty: 2-3607                     [64, 64, 3, 3]            --
│    └─Empty: 2-3608                     [64]                      --
│    └─Empty: 2-3609                     [64]                      --
│    └─BatchNorm2d: 2-3610               [16, 64, 4, 4]            --
│    └─Scaler: 2-3611                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
│    └─Empty: 2-3613                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3614                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3615                 [16, 64, 2, 2]            --
│    └─Empty: 2-3616                     [16, 64, 2, 2]            --
│    └─Empty: 2-3617                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3618        --                        --
│    └─One: 2-3619                       [1]                       --
│    └─OutputScale: 2-3620               --                        --
│    └─Empty: 2-3621                     [64, 64, 1, 1]            --
│    └─Empty: 2-3622                     [64, 64, 1, 1]            --
│    └─Empty: 2-3623                     [64]                      --
│    └─Empty: 2-3624                     [64]                      --
│    └─BatchNorm2d: 2-3625               [16, 64, 2, 2]            --
│    └─Scaler: 2-3626                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
│    └─Empty: 2-3628                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3629                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3630        --                        --
│    └─One: 2-3631                       [1]                       --
│    └─OutputScale: 2-3632               --                        --
│    └─Empty: 2-3633                     [64, 64, 1, 1]            --
│    └─Empty: 2-3634                     [64, 64, 1, 1]            --
│    └─Empty: 2-3635                     [64]                      --
│    └─Empty: 2-3636                     [64]                      --
│    └─BatchNorm2d: 2-3637               [16, 64, 2, 2]            --
│    └─Scaler: 2-3638                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3639                      [16, 64, 2, 2]            --
│    └─Empty: 2-3640                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3641                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3642                 [16, 64, 2, 2]            --
│    └─Empty: 2-3643                     [16, 64, 2, 2]            --
│    └─Empty: 2-3644                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3645        --                        --
│    └─One: 2-3646                       [1]                       --
│    └─OutputScale: 2-3647               --                        --
│    └─Empty: 2-3648                     [64, 64, 3, 3]            --
│    └─Empty: 2-3649                     [64, 64, 3, 3]            --
│    └─Empty: 2-3650                     [64]                      --
│    └─Empty: 2-3651                     [64]                      --
│    └─BatchNorm2d: 2-3652               [16, 64, 2, 2]            --
│    └─Scaler: 2-3653                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
│    └─Empty: 2-3655                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3656                     [16, 64, 2, 2]            --
├─Conv1d: 1-273                          [16, 64, 16]              16,454
│    └─OutputShiftSqueeze: 2-3657        --                        --
│    └─One: 2-3658                       [1]                       --
│    └─OutputScale: 2-3659               --                        --
│    └─Empty: 2-3660                     [64, 256, 1]              --
│    └─Empty: 2-3661                     [64, 256, 1]              --
│    └─Empty: 2-3662                     [64]                      --
│    └─Empty: 2-3663                     [64]                      --
│    └─Scaler: 2-3664                    [16, 64, 16]              --
│    └─Empty: 2-3665                     [16, 64, 16]              --
│    └─Empty: 2-3666                     [16, 64, 16]              --
│    └─Clamp: 2-3667                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3668        --                        --
│    └─One: 2-3669                       [1]                       --
│    └─OutputScale: 2-3670               --                        --
│    └─Empty: 2-3671                     [64, 64, 3]               --
│    └─Empty: 2-3672                     [64, 64, 3]               --
│    └─Empty: 2-3673                     [64]                      --
│    └─Empty: 2-3674                     [64]                      --
│    └─BatchNorm1d: 2-3675               [16, 64, 16]              --
│    └─Scaler: 2-3676                    [16, 64, 16]              --
│    └─ReLU: 2-3677                      [16, 64, 16]              --
│    └─Empty: 2-3678                     [16, 64, 16]              --
│    └─Clamp: 2-3679                     [16, 64, 16]              --
├─Conv1d: 1-275                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3680        --                        --
│    └─One: 2-3681                       [1]                       --
│    └─OutputScale: 2-3682               --                        --
│    └─Empty: 2-3683                     [64, 64, 1]               --
│    └─Empty: 2-3684                     [64, 64, 1]               --
│    └─Empty: 2-3685                     [64]                      --
│    └─Empty: 2-3686                     [64]                      --
│    └─Scaler: 2-3687                    [16, 64, 16]              --
│    └─Empty: 2-3688                     [16, 64, 16]              --
│    └─Empty: 2-3689                     [16, 64, 16]              --
│    └─Clamp: 2-3690                     [16, 64, 16]              --
├─Dropout: 1-276                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-277               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3691        --                        --
│    └─One: 2-3692                       [1]                       --
│    └─OutputScale: 2-3693               --                        --
│    └─Empty: 2-3694                     [64, 64, 3]               --
│    └─Empty: 2-3695                     [64, 64, 3]               --
│    └─Empty: 2-3696                     [64]                      --
│    └─Empty: 2-3697                     [64]                      --
│    └─BatchNorm1d: 2-3698               [16, 64, 16]              --
│    └─Scaler: 2-3699                    [16, 64, 16]              --
│    └─ReLU: 2-3700                      [16, 64, 16]              --
│    └─Empty: 2-3701                     [16, 64, 16]              --
│    └─Clamp: 2-3702                     [16, 64, 16]              --
├─Conv1d: 1-278                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3703        --                        --
│    └─One: 2-3704                       [1]                       --
│    └─OutputScale: 2-3705               --                        --
│    └─Empty: 2-3706                     [64, 64, 1]               --
│    └─Empty: 2-3707                     [64, 64, 1]               --
│    └─Empty: 2-3708                     [64]                      --
│    └─Empty: 2-3709                     [64]                      --
│    └─Scaler: 2-3710                    [16, 64, 16]              --
│    └─Empty: 2-3711                     [16, 64, 16]              --
│    └─Empty: 2-3712                     [16, 64, 16]              --
│    └─Clamp: 2-3713                     [16, 64, 16]              --
├─Dropout: 1-279                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-280               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3714        --                        --
│    └─One: 2-3715                       [1]                       --
│    └─OutputScale: 2-3716               --                        --
│    └─Empty: 2-3717                     [64, 64, 3]               --
│    └─Empty: 2-3718                     [64, 64, 3]               --
│    └─Empty: 2-3719                     [64]                      --
│    └─Empty: 2-3720                     [64]                      --
│    └─BatchNorm1d: 2-3721               [16, 64, 16]              --
│    └─Scaler: 2-3722                    [16, 64, 16]              --
│    └─ReLU: 2-3723                      [16, 64, 16]              --
│    └─Empty: 2-3724                     [16, 64, 16]              --
│    └─Clamp: 2-3725                     [16, 64, 16]              --
├─Conv1d: 1-281                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3726        --                        --
│    └─One: 2-3727                       [1]                       --
│    └─OutputScale: 2-3728               --                        --
│    └─Empty: 2-3729                     [64, 64, 1]               --
│    └─Empty: 2-3730                     [64, 64, 1]               --
│    └─Empty: 2-3731                     [64]                      --
│    └─Empty: 2-3732                     [64]                      --
│    └─Scaler: 2-3733                    [16, 64, 16]              --
│    └─Empty: 2-3734                     [16, 64, 16]              --
│    └─Empty: 2-3735                     [16, 64, 16]              --
│    └─Clamp: 2-3736                     [16, 64, 16]              --
├─Dropout: 1-282                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-283               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3737        --                        --
│    └─One: 2-3738                       [1]                       --
│    └─OutputScale: 2-3739               --                        --
│    └─Empty: 2-3740                     [64, 64, 3]               --
│    └─Empty: 2-3741                     [64, 64, 3]               --
│    └─Empty: 2-3742                     [64]                      --
│    └─Empty: 2-3743                     [64]                      --
│    └─BatchNorm1d: 2-3744               [16, 64, 16]              --
│    └─Scaler: 2-3745                    [16, 64, 16]              --
│    └─ReLU: 2-3746                      [16, 64, 16]              --
│    └─Empty: 2-3747                     [16, 64, 16]              --
│    └─Clamp: 2-3748                     [16, 64, 16]              --
├─Conv1d: 1-284                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3749        --                        --
│    └─One: 2-3750                       [1]                       --
│    └─OutputScale: 2-3751               --                        --
│    └─Empty: 2-3752                     [64, 64, 1]               --
│    └─Empty: 2-3753                     [64, 64, 1]               --
│    └─Empty: 2-3754                     [64]                      --
│    └─Empty: 2-3755                     [64]                      --
│    └─Scaler: 2-3756                    [16, 64, 16]              --
│    └─Empty: 2-3757                     [16, 64, 16]              --
│    └─Empty: 2-3758                     [16, 64, 16]              --
│    └─Clamp: 2-3759                     [16, 64, 16]              --
├─Dropout: 1-285                         [16, 64, 16]              --
├─Conv1d: 1-286                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3760        --                        --
│    └─One: 2-3761                       [1]                       --
│    └─OutputScale: 2-3762               --                        --
│    └─Empty: 2-3763                     [5, 64, 1]                --
│    └─Empty: 2-3764                     [5, 64, 1]                --
│    └─Empty: 2-3765                     [5]                       --
│    └─Empty: 2-3766                     [5]                       --
│    └─Scaler: 2-3767                    [16, 5, 16]               --
│    └─Empty: 2-3768                     [16, 5, 16]               --
│    └─Empty: 2-3769                     [16, 5, 16]               --
│    └─Clamp: 2-3770                     [16, 5, 16]               --
├─Conv1d: 1-287                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3771        --                        --
│    └─One: 2-3772                       [1]                       --
│    └─OutputScale: 2-3773               --                        --
│    └─Empty: 2-3774                     [64, 5, 1]                --
│    └─Empty: 2-3775                     [64, 5, 1]                --
│    └─Empty: 2-3776                     [64]                      --
│    └─Empty: 2-3777                     [64]                      --
│    └─Scaler: 2-3778                    [16, 64, 16]              --
│    └─Empty: 2-3779                     [16, 64, 16]              --
│    └─Empty: 2-3780                     [16, 64, 16]              --
│    └─Clamp: 2-3781                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-288               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3782        --                        --
│    └─One: 2-3783                       [1]                       --
│    └─OutputScale: 2-3784               --                        --
│    └─Empty: 2-3785                     [64, 64, 3]               --
│    └─Empty: 2-3786                     [64, 64, 3]               --
│    └─Empty: 2-3787                     [64]                      --
│    └─Empty: 2-3788                     [64]                      --
│    └─BatchNorm1d: 2-3789               [16, 64, 16]              --
│    └─Scaler: 2-3790                    [16, 64, 16]              --
│    └─ReLU: 2-3791                      [16, 64, 16]              --
│    └─Empty: 2-3792                     [16, 64, 16]              --
│    └─Clamp: 2-3793                     [16, 64, 16]              --
├─Conv1d: 1-289                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3794        --                        --
│    └─One: 2-3795                       [1]                       --
│    └─OutputScale: 2-3796               --                        --
│    └─Empty: 2-3797                     [64, 64, 1]               --
│    └─Empty: 2-3798                     [64, 64, 1]               --
│    └─Empty: 2-3799                     [64]                      --
│    └─Empty: 2-3800                     [64]                      --
│    └─Scaler: 2-3801                    [16, 64, 16]              --
│    └─Empty: 2-3802                     [16, 64, 16]              --
│    └─Empty: 2-3803                     [16, 64, 16]              --
│    └─Clamp: 2-3804                     [16, 64, 16]              --
├─Dropout: 1-290                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-291               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3805        --                        --
│    └─One: 2-3806                       [1]                       --
│    └─OutputScale: 2-3807               --                        --
│    └─Empty: 2-3808                     [64, 64, 3]               --
│    └─Empty: 2-3809                     [64, 64, 3]               --
│    └─Empty: 2-3810                     [64]                      --
│    └─Empty: 2-3811                     [64]                      --
│    └─BatchNorm1d: 2-3812               [16, 64, 16]              --
│    └─Scaler: 2-3813                    [16, 64, 16]              --
│    └─ReLU: 2-3814                      [16, 64, 16]              --
│    └─Empty: 2-3815                     [16, 64, 16]              --
│    └─Clamp: 2-3816                     [16, 64, 16]              --
├─Conv1d: 1-292                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3817        --                        --
│    └─One: 2-3818                       [1]                       --
│    └─OutputScale: 2-3819               --                        --
│    └─Empty: 2-3820                     [64, 64, 1]               --
│    └─Empty: 2-3821                     [64, 64, 1]               --
│    └─Empty: 2-3822                     [64]                      --
│    └─Empty: 2-3823                     [64]                      --
│    └─Scaler: 2-3824                    [16, 64, 16]              --
│    └─Empty: 2-3825                     [16, 64, 16]              --
│    └─Empty: 2-3826                     [16, 64, 16]              --
│    └─Clamp: 2-3827                     [16, 64, 16]              --
├─Dropout: 1-293                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-294               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3828        --                        --
│    └─One: 2-3829                       [1]                       --
│    └─OutputScale: 2-3830               --                        --
│    └─Empty: 2-3831                     [64, 64, 3]               --
│    └─Empty: 2-3832                     [64, 64, 3]               --
│    └─Empty: 2-3833                     [64]                      --
│    └─Empty: 2-3834                     [64]                      --
│    └─BatchNorm1d: 2-3835               [16, 64, 16]              --
│    └─Scaler: 2-3836                    [16, 64, 16]              --
│    └─ReLU: 2-3837                      [16, 64, 16]              --
│    └─Empty: 2-3838                     [16, 64, 16]              --
│    └─Clamp: 2-3839                     [16, 64, 16]              --
├─Conv1d: 1-295                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3840        --                        --
│    └─One: 2-3841                       [1]                       --
│    └─OutputScale: 2-3842               --                        --
│    └─Empty: 2-3843                     [64, 64, 1]               --
│    └─Empty: 2-3844                     [64, 64, 1]               --
│    └─Empty: 2-3845                     [64]                      --
│    └─Empty: 2-3846                     [64]                      --
│    └─Scaler: 2-3847                    [16, 64, 16]              --
│    └─Empty: 2-3848                     [16, 64, 16]              --
│    └─Empty: 2-3849                     [16, 64, 16]              --
│    └─Clamp: 2-3850                     [16, 64, 16]              --
├─Dropout: 1-296                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-297               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3851        --                        --
│    └─One: 2-3852                       [1]                       --
│    └─OutputScale: 2-3853               --                        --
│    └─Empty: 2-3854                     [64, 64, 3]               --
│    └─Empty: 2-3855                     [64, 64, 3]               --
│    └─Empty: 2-3856                     [64]                      --
│    └─Empty: 2-3857                     [64]                      --
│    └─BatchNorm1d: 2-3858               [16, 64, 16]              --
│    └─Scaler: 2-3859                    [16, 64, 16]              --
│    └─ReLU: 2-3860                      [16, 64, 16]              --
│    └─Empty: 2-3861                     [16, 64, 16]              --
│    └─Clamp: 2-3862                     [16, 64, 16]              --
├─Conv1d: 1-298                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3863        --                        --
│    └─One: 2-3864                       [1]                       --
│    └─OutputScale: 2-3865               --                        --
│    └─Empty: 2-3866                     [64, 64, 1]               --
│    └─Empty: 2-3867                     [64, 64, 1]               --
│    └─Empty: 2-3868                     [64]                      --
│    └─Empty: 2-3869                     [64]                      --
│    └─Scaler: 2-3870                    [16, 64, 16]              --
│    └─Empty: 2-3871                     [16, 64, 16]              --
│    └─Empty: 2-3872                     [16, 64, 16]              --
│    └─Clamp: 2-3873                     [16, 64, 16]              --
├─Dropout: 1-299                         [16, 64, 16]              --
├─Conv1d: 1-300                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3874        --                        --
│    └─One: 2-3875                       [1]                       --
│    └─OutputScale: 2-3876               --                        --
│    └─Empty: 2-3877                     [5, 64, 1]                --
│    └─Empty: 2-3878                     [5, 64, 1]                --
│    └─Empty: 2-3879                     [5]                       --
│    └─Empty: 2-3880                     [5]                       --
│    └─Scaler: 2-3881                    [16, 5, 16]               --
│    └─Empty: 2-3882                     [16, 5, 16]               --
│    └─Empty: 2-3883                     [16, 5, 16]               --
│    └─Clamp: 2-3884                     [16, 5, 16]               --
├─Conv1d: 1-301                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3885        --                        --
│    └─One: 2-3886                       [1]                       --
│    └─OutputScale: 2-3887               --                        --
│    └─Empty: 2-3888                     [64, 5, 1]                --
│    └─Empty: 2-3889                     [64, 5, 1]                --
│    └─Empty: 2-3890                     [64]                      --
│    └─Empty: 2-3891                     [64]                      --
│    └─Scaler: 2-3892                    [16, 64, 16]              --
│    └─Empty: 2-3893                     [16, 64, 16]              --
│    └─Empty: 2-3894                     [16, 64, 16]              --
│    └─Clamp: 2-3895                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-302               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3896        --                        --
│    └─One: 2-3897                       [1]                       --
│    └─OutputScale: 2-3898               --                        --
│    └─Empty: 2-3899                     [64, 64, 3]               --
│    └─Empty: 2-3900                     [64, 64, 3]               --
│    └─Empty: 2-3901                     [64]                      --
│    └─Empty: 2-3902                     [64]                      --
│    └─BatchNorm1d: 2-3903               [16, 64, 16]              --
│    └─Scaler: 2-3904                    [16, 64, 16]              --
│    └─ReLU: 2-3905                      [16, 64, 16]              --
│    └─Empty: 2-3906                     [16, 64, 16]              --
│    └─Clamp: 2-3907                     [16, 64, 16]              --
├─Conv1d: 1-303                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3908        --                        --
│    └─One: 2-3909                       [1]                       --
│    └─OutputScale: 2-3910               --                        --
│    └─Empty: 2-3911                     [64, 64, 1]               --
│    └─Empty: 2-3912                     [64, 64, 1]               --
│    └─Empty: 2-3913                     [64]                      --
│    └─Empty: 2-3914                     [64]                      --
│    └─Scaler: 2-3915                    [16, 64, 16]              --
│    └─Empty: 2-3916                     [16, 64, 16]              --
│    └─Empty: 2-3917                     [16, 64, 16]              --
│    └─Clamp: 2-3918                     [16, 64, 16]              --
├─Dropout: 1-304                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-305               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3919        --                        --
│    └─One: 2-3920                       [1]                       --
│    └─OutputScale: 2-3921               --                        --
│    └─Empty: 2-3922                     [64, 64, 3]               --
│    └─Empty: 2-3923                     [64, 64, 3]               --
│    └─Empty: 2-3924                     [64]                      --
│    └─Empty: 2-3925                     [64]                      --
│    └─BatchNorm1d: 2-3926               [16, 64, 16]              --
│    └─Scaler: 2-3927                    [16, 64, 16]              --
│    └─ReLU: 2-3928                      [16, 64, 16]              --
│    └─Empty: 2-3929                     [16, 64, 16]              --
│    └─Clamp: 2-3930                     [16, 64, 16]              --
├─Conv1d: 1-306                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3931        --                        --
│    └─One: 2-3932                       [1]                       --
│    └─OutputScale: 2-3933               --                        --
│    └─Empty: 2-3934                     [64, 64, 1]               --
│    └─Empty: 2-3935                     [64, 64, 1]               --
│    └─Empty: 2-3936                     [64]                      --
│    └─Empty: 2-3937                     [64]                      --
│    └─Scaler: 2-3938                    [16, 64, 16]              --
│    └─Empty: 2-3939                     [16, 64, 16]              --
│    └─Empty: 2-3940                     [16, 64, 16]              --
│    └─Clamp: 2-3941                     [16, 64, 16]              --
├─Dropout: 1-307                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-308               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3942        --                        --
│    └─One: 2-3943                       [1]                       --
│    └─OutputScale: 2-3944               --                        --
│    └─Empty: 2-3945                     [64, 64, 3]               --
│    └─Empty: 2-3946                     [64, 64, 3]               --
│    └─Empty: 2-3947                     [64]                      --
│    └─Empty: 2-3948                     [64]                      --
│    └─BatchNorm1d: 2-3949               [16, 64, 16]              --
│    └─Scaler: 2-3950                    [16, 64, 16]              --
│    └─ReLU: 2-3951                      [16, 64, 16]              --
│    └─Empty: 2-3952                     [16, 64, 16]              --
│    └─Clamp: 2-3953                     [16, 64, 16]              --
├─Conv1d: 1-309                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3954        --                        --
│    └─One: 2-3955                       [1]                       --
│    └─OutputScale: 2-3956               --                        --
│    └─Empty: 2-3957                     [64, 64, 1]               --
│    └─Empty: 2-3958                     [64, 64, 1]               --
│    └─Empty: 2-3959                     [64]                      --
│    └─Empty: 2-3960                     [64]                      --
│    └─Scaler: 2-3961                    [16, 64, 16]              --
│    └─Empty: 2-3962                     [16, 64, 16]              --
│    └─Empty: 2-3963                     [16, 64, 16]              --
│    └─Clamp: 2-3964                     [16, 64, 16]              --
├─Dropout: 1-310                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-311               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3965        --                        --
│    └─One: 2-3966                       [1]                       --
│    └─OutputScale: 2-3967               --                        --
│    └─Empty: 2-3968                     [64, 64, 3]               --
│    └─Empty: 2-3969                     [64, 64, 3]               --
│    └─Empty: 2-3970                     [64]                      --
│    └─Empty: 2-3971                     [64]                      --
│    └─BatchNorm1d: 2-3972               [16, 64, 16]              --
│    └─Scaler: 2-3973                    [16, 64, 16]              --
│    └─ReLU: 2-3974                      [16, 64, 16]              --
│    └─Empty: 2-3975                     [16, 64, 16]              --
│    └─Clamp: 2-3976                     [16, 64, 16]              --
├─Conv1d: 1-312                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3977        --                        --
│    └─One: 2-3978                       [1]                       --
│    └─OutputScale: 2-3979               --                        --
│    └─Empty: 2-3980                     [64, 64, 1]               --
│    └─Empty: 2-3981                     [64, 64, 1]               --
│    └─Empty: 2-3982                     [64]                      --
│    └─Empty: 2-3983                     [64]                      --
│    └─Scaler: 2-3984                    [16, 64, 16]              --
│    └─Empty: 2-3985                     [16, 64, 16]              --
│    └─Empty: 2-3986                     [16, 64, 16]              --
│    └─Clamp: 2-3987                     [16, 64, 16]              --
├─Dropout: 1-313                         [16, 64, 16]              --
├─Conv1d: 1-314                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3988        --                        --
│    └─One: 2-3989                       [1]                       --
│    └─OutputScale: 2-3990               --                        --
│    └─Empty: 2-3991                     [5, 64, 1]                --
│    └─Empty: 2-3992                     [5, 64, 1]                --
│    └─Empty: 2-3993                     [5]                       --
│    └─Empty: 2-3994                     [5]                       --
│    └─Scaler: 2-3995                    [16, 5, 16]               --
│    └─Empty: 2-3996                     [16, 5, 16]               --
│    └─Empty: 2-3997                     [16, 5, 16]               --
│    └─Clamp: 2-3998                     [16, 5, 16]               --
==========================================================================================
Total params: 646,761
Trainable params: 646,479
Non-trainable params: 282
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 4.836 | Acc: 34.250% | Wgt Acc: 20.559%
	I - Batch: 100 | Loss: 4.703 | Acc: 37.250% | Wgt Acc: 24.617%
	I - Batch: 150 | Loss: 4.561 | Acc: 38.250% | Wgt Acc: 26.841%
	I - Batch: 200 | Loss: 4.536 | Acc: 40.250% | Wgt Acc: 27.623%
	I - Batch: 250 | Loss: 4.478 | Acc: 39.100% | Wgt Acc: 28.686%
	I - Batch: 300 | Loss: 4.445 | Acc: 37.250% | Wgt Acc: 29.131%
	I - Batch: 350 | Loss: 4.421 | Acc: 36.179% | Wgt Acc: 29.428%
	I - Batch: 400 | Loss: 4.397 | Acc: 35.562% | Wgt Acc: 29.422%
	I - Batch: 450 | Loss: 4.378 | Acc: 35.861% | Wgt Acc: 30.117%
	I - Batch: 500 | Loss: 4.365 | Acc: 37.163% | Wgt Acc: 30.404%
	I - Batch: 550 | Loss: 4.365 | Acc: 38.284% | Wgt Acc: 30.581%
	I - Batch: 600 | Loss: 4.367 | Acc: 37.552% | Wgt Acc: 30.429%
	I - Batch: 650 | Loss: 4.366 | Acc: 37.721% | Wgt Acc: 30.312%
	I - Batch: 700 | Loss: 4.353 | Acc: 37.875% | Wgt Acc: 30.418%
	I - Batch: 750 | Loss: 4.349 | Acc: 37.442% | Wgt Acc: 30.423%
	I - Batch: 800 | Loss: 4.339 | Acc: 37.258% | Wgt Acc: 30.587%
	I - Batch: 850 | Loss: 4.338 | Acc: 37.809% | Wgt Acc: 30.831%
	I - Batch: 900 | Loss: 4.336 | Acc: 38.257% | Wgt Acc: 30.786%
	I - Batch: 950 | Loss: 4.335 | Acc: 38.684% | Wgt Acc: 30.823%
	I - Batch: 1000 | Loss: 4.327 | Acc: 38.606% | Wgt Acc: 30.842%
I - num batch: 1003
I - Train -- Loss: 4.326 | Acc: 38.585% | Wgt Acc: 30.839% | LR: 1.000000e-03 | Dur: 646.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 977.  143.  246.  823.  929.]
 [  75.  296.  427.   88. 1200.]
 [  53.  206.  286.   69.  796.]
 [ 322.   85.  137.  290.  543.]
 [ 435. 1108. 1542.  624. 4340.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.469 | Acc: 42.375% | Wgt Acc: 47.212%
	I - Batch: 100 | Loss: 5.450 | Acc: 37.688% | Wgt Acc: 43.688%
	I - Batch: 150 | Loss: 5.398 | Acc: 33.125% | Wgt Acc: 41.259%
	I - Batch: 200 | Loss: 5.393 | Acc: 31.219% | Wgt Acc: 40.369%
I - num batch: 238
I - Val -- Loss: 5.416 | Acc: 30.092% | Wgt Acc: 39.118% | Dur: 116.39s
I - Confusion Matrix: [row->prediction - col->label]
[[356.  42.  64. 316. 134.]
 [ 71. 584. 612. 115. 829.]
 [ 10.  14.  12.  14.  53.]
 [ 36.  20.  22.  58.  57.]
 [ 53.  66.  68.  64. 135.]]

I - Local maximum validation set accuracy:  30.09

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 4.275 | Acc: 48.750% | Wgt Acc: 33.372%
	I - Batch: 100 | Loss: 4.230 | Acc: 49.125% | Wgt Acc: 34.456%
	I - Batch: 150 | Loss: 4.220 | Acc: 48.292% | Wgt Acc: 33.678%
	I - Batch: 200 | Loss: 4.237 | Acc: 45.562% | Wgt Acc: 32.799%
	I - Batch: 250 | Loss: 4.235 | Acc: 44.875% | Wgt Acc: 32.639%
	I - Batch: 300 | Loss: 4.237 | Acc: 45.333% | Wgt Acc: 32.236%
	I - Batch: 350 | Loss: 4.240 | Acc: 43.125% | Wgt Acc: 32.081%
	I - Batch: 400 | Loss: 4.239 | Acc: 41.484% | Wgt Acc: 31.814%
	I - Batch: 450 | Loss: 4.243 | Acc: 41.042% | Wgt Acc: 31.834%
	I - Batch: 500 | Loss: 4.256 | Acc: 41.050% | Wgt Acc: 31.708%
	I - Batch: 550 | Loss: 4.246 | Acc: 41.011% | Wgt Acc: 31.995%
	I - Batch: 600 | Loss: 4.249 | Acc: 41.615% | Wgt Acc: 32.043%
	I - Batch: 650 | Loss: 4.258 | Acc: 41.587% | Wgt Acc: 31.926%
	I - Batch: 700 | Loss: 4.258 | Acc: 41.786% | Wgt Acc: 31.935%
	I - Batch: 750 | Loss: 4.253 | Acc: 41.575% | Wgt Acc: 32.060%
	I - Batch: 800 | Loss: 4.256 | Acc: 41.500% | Wgt Acc: 32.098%
	I - Batch: 850 | Loss: 4.255 | Acc: 40.882% | Wgt Acc: 32.166%
	I - Batch: 900 | Loss: 4.254 | Acc: 41.062% | Wgt Acc: 32.233%
	I - Batch: 950 | Loss: 4.253 | Acc: 41.217% | Wgt Acc: 32.204%
	I - Batch: 1000 | Loss: 4.255 | Acc: 40.550% | Wgt Acc: 32.087%
I - num batch: 1003
I - Train -- Loss: 4.256 | Acc: 40.517% | Wgt Acc: 32.076% | LR: 1.000000e-03 | Dur: 633.49s
I - Confusion Matrix: [row->prediction - col->label]
[[1120.  134.  210.  949.  867.]
 [  40.  237.  362.   51.  993.]
 [  40.  199.  289.   44.  766.]
 [ 269.   96.  141.  251.  580.]
 [ 393. 1172. 1636.  599. 4602.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.266 | Acc: 17.125% | Wgt Acc: 18.431%
	I - Batch: 100 | Loss: 5.203 | Acc: 21.688% | Wgt Acc: 19.103%
	I - Batch: 150 | Loss: 5.150 | Acc: 30.042% | Wgt Acc: 22.755%
	I - Batch: 200 | Loss: 5.143 | Acc: 34.156% | Wgt Acc: 25.233%
I - num batch: 238
I - Val -- Loss: 5.134 | Acc: 35.506% | Wgt Acc: 26.018% | Dur: 115.57s
I - Confusion Matrix: [row->prediction - col->label]
[[355.  32.  66. 351. 146.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 80.  90.  84. 110. 176.]
 [ 91. 604. 628. 106. 886.]]

I - Local maximum validation set accuracy:  35.51

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 4.338 | Acc: 31.625% | Wgt Acc: 29.697%
	I - Batch: 100 | Loss: 4.293 | Acc: 30.375% | Wgt Acc: 31.409%
	I - Batch: 150 | Loss: 4.292 | Acc: 29.333% | Wgt Acc: 32.351%
	I - Batch: 200 | Loss: 4.265 | Acc: 31.625% | Wgt Acc: 32.111%
	I - Batch: 250 | Loss: 4.278 | Acc: 34.550% | Wgt Acc: 32.153%
	I - Batch: 300 | Loss: 4.267 | Acc: 37.083% | Wgt Acc: 32.325%
	I - Batch: 350 | Loss: 4.247 | Acc: 39.125% | Wgt Acc: 32.963%
	I - Batch: 400 | Loss: 4.246 | Acc: 40.875% | Wgt Acc: 33.221%
	I - Batch: 450 | Loss: 4.254 | Acc: 40.653% | Wgt Acc: 32.872%
	I - Batch: 500 | Loss: 4.256 | Acc: 39.750% | Wgt Acc: 32.919%
	I - Batch: 550 | Loss: 4.248 | Acc: 40.795% | Wgt Acc: 33.331%
	I - Batch: 600 | Loss: 4.251 | Acc: 40.656% | Wgt Acc: 32.975%
	I - Batch: 650 | Loss: 4.258 | Acc: 40.356% | Wgt Acc: 32.580%
	I - Batch: 700 | Loss: 4.257 | Acc: 40.964% | Wgt Acc: 32.618%
	I - Batch: 750 | Loss: 4.258 | Acc: 41.000% | Wgt Acc: 32.547%
	I - Batch: 800 | Loss: 4.261 | Acc: 41.094% | Wgt Acc: 32.462%
	I - Batch: 850 | Loss: 4.256 | Acc: 40.588% | Wgt Acc: 32.508%
	I - Batch: 900 | Loss: 4.263 | Acc: 39.854% | Wgt Acc: 32.308%
	I - Batch: 950 | Loss: 4.260 | Acc: 39.414% | Wgt Acc: 32.288%
	I - Batch: 1000 | Loss: 4.264 | Acc: 39.075% | Wgt Acc: 32.145%
I - num batch: 1003
I - Train -- Loss: 4.263 | Acc: 39.071% | Wgt Acc: 32.152% | LR: 1.000000e-03 | Dur: 631.62s
I - Confusion Matrix: [row->prediction - col->label]
[[1013.  116.  209.  836.  857.]
 [  47.  378.  561.   60. 1447.]
 [  11.  125.  147.   23.  475.]
 [ 396.  121.  178.  405.  705.]
 [ 395. 1098. 1543.  570. 4324.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.036 | Acc: 2.750% | Wgt Acc: 2.902%
	I - Batch: 100 | Loss: 5.014 | Acc: 13.562% | Wgt Acc: 6.779%
	I - Batch: 150 | Loss: 4.983 | Acc: 25.792% | Wgt Acc: 11.591%
	I - Batch: 200 | Loss: 4.984 | Acc: 31.469% | Wgt Acc: 14.155%
I - num batch: 238
I - Val -- Loss: 4.985 | Acc: 33.561% | Wgt Acc: 15.007% | Dur: 116.39s
I - Confusion Matrix: [row->prediction - col->label]
[[  22.    0.    0.    9.    1.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  79.    0.    6.   52.    4.]
 [ 425.  726.  772.  506. 1203.]]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 4.294 | Acc: 31.375% | Wgt Acc: 31.347%
	I - Batch: 100 | Loss: 4.212 | Acc: 32.062% | Wgt Acc: 33.799%
	I - Batch: 150 | Loss: 4.207 | Acc: 31.708% | Wgt Acc: 33.583%
	I - Batch: 200 | Loss: 4.216 | Acc: 33.438% | Wgt Acc: 33.316%
	I - Batch: 250 | Loss: 4.209 | Acc: 36.925% | Wgt Acc: 33.675%
	I - Batch: 300 | Loss: 4.201 | Acc: 38.917% | Wgt Acc: 33.809%
	I - Batch: 350 | Loss: 4.233 | Acc: 39.911% | Wgt Acc: 33.289%
	I - Batch: 400 | Loss: 4.235 | Acc: 39.484% | Wgt Acc: 33.235%
	I - Batch: 450 | Loss: 4.230 | Acc: 38.792% | Wgt Acc: 33.141%
	I - Batch: 500 | Loss: 4.236 | Acc: 38.562% | Wgt Acc: 32.877%
	I - Batch: 550 | Loss: 4.235 | Acc: 38.739% | Wgt Acc: 32.921%
	I - Batch: 600 | Loss: 4.237 | Acc: 39.521% | Wgt Acc: 32.853%
	I - Batch: 650 | Loss: 4.241 | Acc: 40.500% | Wgt Acc: 33.025%
	I - Batch: 700 | Loss: 4.248 | Acc: 41.098% | Wgt Acc: 32.979%
	I - Batch: 750 | Loss: 4.249 | Acc: 40.750% | Wgt Acc: 32.774%
	I - Batch: 800 | Loss: 4.250 | Acc: 40.312% | Wgt Acc: 32.690%
	I - Batch: 850 | Loss: 4.251 | Acc: 39.993% | Wgt Acc: 32.687%
	I - Batch: 900 | Loss: 4.249 | Acc: 39.694% | Wgt Acc: 32.898%
	I - Batch: 950 | Loss: 4.247 | Acc: 39.513% | Wgt Acc: 32.753%
	I - Batch: 1000 | Loss: 4.248 | Acc: 39.875% | Wgt Acc: 32.703%
I - num batch: 1003
I - Train -- Loss: 4.249 | Acc: 39.844% | Wgt Acc: 32.681% | LR: 1.000000e-03 | Dur: 636.13s
I - Confusion Matrix: [row->prediction - col->label]
[[1155.  144.  278.  986. 1011.]
 [  55.  432.  640.   74. 1549.]
 [   9.   82.  120.   19.  320.]
 [ 230.   76.   98.  236.  480.]
 [ 413. 1104. 1502.  579. 4448.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.466 | Acc: 32.125% | Wgt Acc: 30.221%
	I - Batch: 100 | Loss: 5.359 | Acc: 29.500% | Wgt Acc: 27.942%
	I - Batch: 150 | Loss: 5.312 | Acc: 31.042% | Wgt Acc: 29.010%
	I - Batch: 200 | Loss: 5.285 | Acc: 31.938% | Wgt Acc: 30.274%
I - num batch: 238
I - Val -- Loss: 5.272 | Acc: 32.011% | Wgt Acc: 29.995% | Dur: 116.11s
I - Confusion Matrix: [row->prediction - col->label]
[[424. 106. 124. 437. 256.]
 [  0.   0.   0.   0.   0.]
 [  8. 284. 340.  13. 414.]
 [ 37.  60.  46.  31. 115.]
 [ 57. 276. 268.  86. 423.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 4.260 | Acc: 36.750% | Wgt Acc: 32.394%
	I - Batch: 100 | Loss: 4.252 | Acc: 32.500% | Wgt Acc: 31.944%
	I - Batch: 150 | Loss: 4.232 | Acc: 37.042% | Wgt Acc: 32.117%
	I - Batch: 200 | Loss: 4.236 | Acc: 37.250% | Wgt Acc: 31.885%
	I - Batch: 250 | Loss: 4.238 | Acc: 36.775% | Wgt Acc: 32.533%
	I - Batch: 300 | Loss: 4.230 | Acc: 38.375% | Wgt Acc: 32.414%
	I - Batch: 350 | Loss: 4.221 | Acc: 39.357% | Wgt Acc: 32.628%
	I - Batch: 400 | Loss: 4.224 | Acc: 38.625% | Wgt Acc: 32.556%
	I - Batch: 450 | Loss: 4.227 | Acc: 37.917% | Wgt Acc: 32.417%
	I - Batch: 500 | Loss: 4.228 | Acc: 38.087% | Wgt Acc: 32.264%
	I - Batch: 550 | Loss: 4.239 | Acc: 38.261% | Wgt Acc: 32.175%
	I - Batch: 600 | Loss: 4.240 | Acc: 38.438% | Wgt Acc: 32.212%
	I - Batch: 650 | Loss: 4.231 | Acc: 38.462% | Wgt Acc: 32.514%
	I - Batch: 700 | Loss: 4.235 | Acc: 38.482% | Wgt Acc: 32.710%
	I - Batch: 750 | Loss: 4.230 | Acc: 38.300% | Wgt Acc: 32.803%
	I - Batch: 800 | Loss: 4.234 | Acc: 38.703% | Wgt Acc: 32.953%
	I - Batch: 850 | Loss: 4.232 | Acc: 38.890% | Wgt Acc: 32.916%
	I - Batch: 900 | Loss: 4.235 | Acc: 39.597% | Wgt Acc: 32.957%
	I - Batch: 950 | Loss: 4.232 | Acc: 39.993% | Wgt Acc: 32.955%
	I - Batch: 1000 | Loss: 4.233 | Acc: 40.288% | Wgt Acc: 32.866%
I - num batch: 1003
I - Train -- Loss: 4.233 | Acc: 40.293% | Wgt Acc: 32.857% | LR: 1.000000e-03 | Dur: 634.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 972.  140.  186.  787.  795.]
 [  32.  248.  345.   48.  878.]
 [  29.  320.  435.   55. 1079.]
 [ 428.   77.  151.  427.  675.]
 [ 401. 1053. 1521.  577. 4381.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.130 | Acc: 2.750% | Wgt Acc: 2.881%
	I - Batch: 100 | Loss: 5.081 | Acc: 14.875% | Wgt Acc: 8.350%
	I - Batch: 150 | Loss: 5.023 | Acc: 26.875% | Wgt Acc: 13.204%
	I - Batch: 200 | Loss: 5.013 | Acc: 32.312% | Wgt Acc: 15.613%
I - num batch: 238
I - Val -- Loss: 5.009 | Acc: 34.455% | Wgt Acc: 16.508% | Dur: 114.46s
I - Confusion Matrix: [row->prediction - col->label]
[[  24.    0.    0.   20.    1.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 122.    4.   12.   96.   16.]
 [ 380.  722.  766.  451. 1191.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 4.258 | Acc: 49.375% | Wgt Acc: 33.048%
	I - Batch: 100 | Loss: 4.237 | Acc: 46.562% | Wgt Acc: 32.121%
	I - Batch: 150 | Loss: 4.240 | Acc: 42.792% | Wgt Acc: 30.634%
	I - Batch: 200 | Loss: 4.228 | Acc: 44.969% | Wgt Acc: 31.875%
	I - Batch: 250 | Loss: 4.231 | Acc: 46.050% | Wgt Acc: 32.645%
	I - Batch: 300 | Loss: 4.250 | Acc: 45.083% | Wgt Acc: 32.313%
	I - Batch: 350 | Loss: 4.238 | Acc: 44.946% | Wgt Acc: 32.544%
	I - Batch: 400 | Loss: 4.233 | Acc: 45.531% | Wgt Acc: 32.650%
	I - Batch: 450 | Loss: 4.233 | Acc: 45.333% | Wgt Acc: 32.744%
	I - Batch: 500 | Loss: 4.235 | Acc: 44.638% | Wgt Acc: 32.675%
	I - Batch: 550 | Loss: 4.238 | Acc: 45.011% | Wgt Acc: 32.615%
	I - Batch: 600 | Loss: 4.235 | Acc: 45.417% | Wgt Acc: 32.792%
	I - Batch: 650 | Loss: 4.234 | Acc: 44.798% | Wgt Acc: 32.787%
	I - Batch: 700 | Loss: 4.235 | Acc: 44.000% | Wgt Acc: 33.060%
	I - Batch: 750 | Loss: 4.231 | Acc: 43.150% | Wgt Acc: 33.204%
	I - Batch: 800 | Loss: 4.229 | Acc: 42.430% | Wgt Acc: 33.259%
	I - Batch: 850 | Loss: 4.225 | Acc: 41.735% | Wgt Acc: 33.143%
	I - Batch: 900 | Loss: 4.226 | Acc: 41.333% | Wgt Acc: 33.085%
	I - Batch: 950 | Loss: 4.235 | Acc: 40.809% | Wgt Acc: 32.864%
	I - Batch: 1000 | Loss: 4.234 | Acc: 40.388% | Wgt Acc: 32.749%
I - num batch: 1003
I - Train -- Loss: 4.234 | Acc: 40.374% | Wgt Acc: 32.769% | LR: 1.000000e-03 | Dur: 627.19s
I - Confusion Matrix: [row->prediction - col->label]
[[1039.  118.  204.  842.  855.]
 [  51.  328.  469.   69. 1172.]
 [  25.  186.  263.   32.  672.]
 [ 357.   88.  124.  360.  623.]
 [ 390. 1118. 1578.  591. 4486.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.541 | Acc: 30.750% | Wgt Acc: 33.482%
	I - Batch: 100 | Loss: 5.446 | Acc: 29.812% | Wgt Acc: 32.532%
	I - Batch: 150 | Loss: 5.355 | Acc: 28.083% | Wgt Acc: 31.370%
	I - Batch: 200 | Loss: 5.324 | Acc: 27.656% | Wgt Acc: 30.920%
I - num batch: 238
I - Val -- Loss: 5.319 | Acc: 28.384% | Wgt Acc: 31.910% | Dur: 113.81s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [ 19. 310. 380.  28. 473.]
 [  0.   0.   0.   0.   0.]
 [464. 212. 238. 487. 452.]
 [ 43. 204. 160.  52. 283.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 4.127 | Acc: 36.375% | Wgt Acc: 33.120%
	I - Batch: 100 | Loss: 4.191 | Acc: 42.688% | Wgt Acc: 33.153%
	I - Batch: 150 | Loss: 4.175 | Acc: 43.458% | Wgt Acc: 32.396%
	I - Batch: 200 | Loss: 4.181 | Acc: 44.375% | Wgt Acc: 32.567%
	I - Batch: 250 | Loss: 4.200 | Acc: 45.025% | Wgt Acc: 32.502%
	I - Batch: 300 | Loss: 4.230 | Acc: 44.750% | Wgt Acc: 32.048%
	I - Batch: 350 | Loss: 4.249 | Acc: 43.804% | Wgt Acc: 31.340%
	I - Batch: 400 | Loss: 4.262 | Acc: 42.672% | Wgt Acc: 31.155%
	I - Batch: 450 | Loss: 4.269 | Acc: 41.750% | Wgt Acc: 31.226%
	I - Batch: 500 | Loss: 4.276 | Acc: 41.237% | Wgt Acc: 31.148%
	I - Batch: 550 | Loss: 4.279 | Acc: 41.818% | Wgt Acc: 31.347%
	I - Batch: 600 | Loss: 4.269 | Acc: 42.615% | Wgt Acc: 31.657%
	I - Batch: 650 | Loss: 4.265 | Acc: 42.490% | Wgt Acc: 31.650%
	I - Batch: 700 | Loss: 4.263 | Acc: 41.732% | Wgt Acc: 31.666%
	I - Batch: 750 | Loss: 4.255 | Acc: 41.708% | Wgt Acc: 31.716%
	I - Batch: 800 | Loss: 4.256 | Acc: 41.602% | Wgt Acc: 31.638%
	I - Batch: 850 | Loss: 4.252 | Acc: 41.368% | Wgt Acc: 31.691%
	I - Batch: 900 | Loss: 4.259 | Acc: 41.347% | Wgt Acc: 31.467%
	I - Batch: 950 | Loss: 4.262 | Acc: 41.566% | Wgt Acc: 31.455%
	I - Batch: 1000 | Loss: 4.256 | Acc: 41.862% | Wgt Acc: 31.577%
I - num batch: 1003
I - Train -- Loss: 4.255 | Acc: 41.889% | Wgt Acc: 31.607% | LR: 1.000000e-03 | Dur: 625.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 918.   83.  158.  767.  622.]
 [  13.  122.  215.   18.  595.]
 [  36.  210.  337.   43.  803.]
 [ 440.  123.  172.  405.  851.]
 [ 455. 1300. 1756.  661. 4937.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.244 | Acc: 14.500% | Wgt Acc: 15.632%
	I - Batch: 100 | Loss: 5.170 | Acc: 20.062% | Wgt Acc: 17.075%
	I - Batch: 150 | Loss: 5.109 | Acc: 30.417% | Wgt Acc: 21.703%
	I - Batch: 200 | Loss: 5.092 | Acc: 35.125% | Wgt Acc: 24.391%
I - num batch: 238
I - Val -- Loss: 5.087 | Acc: 36.426% | Wgt Acc: 24.935% | Dur: 113.67s
I - Confusion Matrix: [row->prediction - col->label]
[[341.  34.  44. 334. 140.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 51.  32.  26.  67.  90.]
 [134. 660. 708. 166. 978.]]

I - Local maximum validation set accuracy:  36.43

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 4.272 | Acc: 43.250% | Wgt Acc: 32.734%
	I - Batch: 100 | Loss: 4.217 | Acc: 43.938% | Wgt Acc: 33.620%
	I - Batch: 150 | Loss: 4.193 | Acc: 38.833% | Wgt Acc: 33.302%
	I - Batch: 200 | Loss: 4.197 | Acc: 36.750% | Wgt Acc: 32.934%
	I - Batch: 250 | Loss: 4.209 | Acc: 36.825% | Wgt Acc: 32.906%
	I - Batch: 300 | Loss: 4.210 | Acc: 37.875% | Wgt Acc: 32.416%
	I - Batch: 350 | Loss: 4.235 | Acc: 39.839% | Wgt Acc: 32.606%
	I - Batch: 400 | Loss: 4.230 | Acc: 40.750% | Wgt Acc: 32.630%
	I - Batch: 450 | Loss: 4.228 | Acc: 40.222% | Wgt Acc: 32.485%
	I - Batch: 500 | Loss: 4.230 | Acc: 40.587% | Wgt Acc: 32.294%
	I - Batch: 550 | Loss: 4.222 | Acc: 40.102% | Wgt Acc: 32.241%
	I - Batch: 600 | Loss: 4.220 | Acc: 40.458% | Wgt Acc: 32.456%
	I - Batch: 650 | Loss: 4.225 | Acc: 40.538% | Wgt Acc: 32.326%
	I - Batch: 700 | Loss: 4.234 | Acc: 40.688% | Wgt Acc: 32.261%
	I - Batch: 750 | Loss: 4.234 | Acc: 40.742% | Wgt Acc: 32.083%
	I - Batch: 800 | Loss: 4.232 | Acc: 40.328% | Wgt Acc: 32.238%
	I - Batch: 850 | Loss: 4.233 | Acc: 40.353% | Wgt Acc: 32.281%
	I - Batch: 900 | Loss: 4.232 | Acc: 40.785% | Wgt Acc: 32.308%
	I - Batch: 950 | Loss: 4.226 | Acc: 41.105% | Wgt Acc: 32.378%
	I - Batch: 1000 | Loss: 4.230 | Acc: 41.344% | Wgt Acc: 32.249%
I - num batch: 1003
I - Train -- Loss: 4.230 | Acc: 41.372% | Wgt Acc: 32.266% | LR: 1.000000e-03 | Dur: 625.60s
I - Confusion Matrix: [row->prediction - col->label]
[[1044.  118.  218.  905.  886.]
 [  36.  268.  366.   47.  975.]
 [  10.  160.  231.   25.  599.]
 [ 319.   81.  129.  305.  560.]
 [ 453. 1211. 1694.  612. 4788.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.272 | Acc: 39.500% | Wgt Acc: 44.081%
	I - Batch: 100 | Loss: 5.198 | Acc: 36.938% | Wgt Acc: 40.961%
	I - Batch: 150 | Loss: 5.131 | Acc: 35.458% | Wgt Acc: 39.834%
	I - Batch: 200 | Loss: 5.124 | Acc: 34.625% | Wgt Acc: 39.370%
I - num batch: 238
I - Val -- Loss: 5.128 | Acc: 33.614% | Wgt Acc: 38.108% | Dur: 114.41s
I - Confusion Matrix: [row->prediction - col->label]
[[310.  18.  36. 299.  84.]
 [ 43. 574. 580.  94. 738.]
 [  0.   0.   0.   0.   0.]
 [ 44.  14.  14.  30.  21.]
 [129. 120. 148. 144. 365.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 4.362 | Acc: 35.000% | Wgt Acc: 31.230%
	I - Batch: 100 | Loss: 4.262 | Acc: 34.000% | Wgt Acc: 32.958%
	I - Batch: 150 | Loss: 4.265 | Acc: 37.250% | Wgt Acc: 33.462%
	I - Batch: 200 | Loss: 4.256 | Acc: 39.594% | Wgt Acc: 32.978%
	I - Batch: 250 | Loss: 4.257 | Acc: 41.375% | Wgt Acc: 32.708%
	I - Batch: 300 | Loss: 4.257 | Acc: 42.271% | Wgt Acc: 32.437%
	I - Batch: 350 | Loss: 4.270 | Acc: 42.768% | Wgt Acc: 32.326%
	I - Batch: 400 | Loss: 4.265 | Acc: 42.219% | Wgt Acc: 32.194%
	I - Batch: 450 | Loss: 4.272 | Acc: 42.000% | Wgt Acc: 31.952%
	I - Batch: 500 | Loss: 4.271 | Acc: 42.125% | Wgt Acc: 31.904%
	I - Batch: 550 | Loss: 4.260 | Acc: 41.250% | Wgt Acc: 32.026%
	I - Batch: 600 | Loss: 4.252 | Acc: 41.302% | Wgt Acc: 32.167%
	I - Batch: 650 | Loss: 4.247 | Acc: 40.865% | Wgt Acc: 32.252%
	I - Batch: 700 | Loss: 4.248 | Acc: 40.357% | Wgt Acc: 32.279%
	I - Batch: 750 | Loss: 4.243 | Acc: 40.067% | Wgt Acc: 32.326%
	I - Batch: 800 | Loss: 4.243 | Acc: 39.508% | Wgt Acc: 32.242%
	I - Batch: 850 | Loss: 4.240 | Acc: 39.184% | Wgt Acc: 32.374%
	I - Batch: 900 | Loss: 4.244 | Acc: 39.076% | Wgt Acc: 32.256%
	I - Batch: 950 | Loss: 4.245 | Acc: 39.336% | Wgt Acc: 32.203%
	I - Batch: 1000 | Loss: 4.241 | Acc: 38.987% | Wgt Acc: 32.176%
I - num batch: 1003
I - Train -- Loss: 4.241 | Acc: 38.959% | Wgt Acc: 32.169% | LR: 1.000000e-03 | Dur: 629.87s
I - Confusion Matrix: [row->prediction - col->label]
[[1120.  125.  208.  978.  986.]
 [  35.  339.  490.   66. 1249.]
 [  31.  208.  314.   38.  798.]
 [ 248.   74.  136.  237.  536.]
 [ 428. 1092. 1490.  575. 4239.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.516 | Acc: 35.000% | Wgt Acc: 32.373%
	I - Batch: 100 | Loss: 5.432 | Acc: 31.688% | Wgt Acc: 30.657%
	I - Batch: 150 | Loss: 5.370 | Acc: 30.708% | Wgt Acc: 30.970%
	I - Batch: 200 | Loss: 5.347 | Acc: 31.000% | Wgt Acc: 32.285%
I - num batch: 238
I - Val -- Loss: 5.345 | Acc: 29.855% | Wgt Acc: 31.147% | Dur: 114.73s
I - Confusion Matrix: [row->prediction - col->label]
[[429. 108. 144. 457. 280.]
 [  0.   0.   0.   0.   0.]
 [ 19. 426. 446.  34. 579.]
 [ 41.  68.  58.  37. 125.]
 [ 37. 124. 130.  39. 224.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 4.138 | Acc: 39.000% | Wgt Acc: 38.020%
	I - Batch: 100 | Loss: 4.180 | Acc: 39.938% | Wgt Acc: 35.533%
	I - Batch: 150 | Loss: 4.190 | Acc: 39.000% | Wgt Acc: 34.615%
	I - Batch: 200 | Loss: 4.198 | Acc: 38.094% | Wgt Acc: 33.646%
	I - Batch: 250 | Loss: 4.185 | Acc: 40.625% | Wgt Acc: 33.568%
	I - Batch: 300 | Loss: 4.209 | Acc: 41.688% | Wgt Acc: 33.230%
	I - Batch: 350 | Loss: 4.209 | Acc: 42.946% | Wgt Acc: 33.505%
	I - Batch: 400 | Loss: 4.211 | Acc: 43.875% | Wgt Acc: 33.669%
	I - Batch: 450 | Loss: 4.212 | Acc: 44.389% | Wgt Acc: 33.423%
	I - Batch: 500 | Loss: 4.219 | Acc: 44.825% | Wgt Acc: 33.285%
	I - Batch: 550 | Loss: 4.216 | Acc: 44.761% | Wgt Acc: 33.225%
	I - Batch: 600 | Loss: 4.219 | Acc: 45.365% | Wgt Acc: 33.482%
	I - Batch: 650 | Loss: 4.224 | Acc: 45.442% | Wgt Acc: 33.244%
	I - Batch: 700 | Loss: 4.230 | Acc: 45.464% | Wgt Acc: 33.086%
	I - Batch: 750 | Loss: 4.233 | Acc: 45.350% | Wgt Acc: 32.897%
	I - Batch: 800 | Loss: 4.236 | Acc: 44.992% | Wgt Acc: 32.867%
	I - Batch: 850 | Loss: 4.236 | Acc: 44.316% | Wgt Acc: 32.765%
	I - Batch: 900 | Loss: 4.231 | Acc: 43.417% | Wgt Acc: 32.561%
	I - Batch: 950 | Loss: 4.234 | Acc: 42.921% | Wgt Acc: 32.462%
	I - Batch: 1000 | Loss: 4.235 | Acc: 42.388% | Wgt Acc: 32.557%
I - num batch: 1003
I - Train -- Loss: 4.235 | Acc: 42.350% | Wgt Acc: 32.561% | LR: 1.000000e-03 | Dur: 630.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 969.   82.  196.  809.  753.]
 [  20.  184.  302.   33.  690.]
 [  17.  232.  314.   37.  740.]
 [ 410.  115.  161.  402.  701.]
 [ 446. 1225. 1665.  613. 4924.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.410 | Acc: 39.625% | Wgt Acc: 44.152%
	I - Batch: 100 | Loss: 5.346 | Acc: 35.125% | Wgt Acc: 41.029%
	I - Batch: 150 | Loss: 5.277 | Acc: 32.375% | Wgt Acc: 39.161%
	I - Batch: 200 | Loss: 5.259 | Acc: 31.688% | Wgt Acc: 39.348%
I - num batch: 238
I - Val -- Loss: 5.259 | Acc: 30.276% | Wgt Acc: 37.861% | Dur: 114.77s
I - Confusion Matrix: [row->prediction - col->label]
[[422.  72. 130. 419. 263.]
 [ 46. 530. 564.  81. 744.]
 [  0.   0.   0.   0.   0.]
 [  3.   0.   0.   3.   4.]
 [ 55. 124.  84.  64. 197.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 4.166 | Acc: 32.000% | Wgt Acc: 33.556%
	I - Batch: 100 | Loss: 4.254 | Acc: 33.875% | Wgt Acc: 32.547%
	I - Batch: 150 | Loss: 4.246 | Acc: 37.333% | Wgt Acc: 32.509%
	I - Batch: 200 | Loss: 4.227 | Acc: 37.656% | Wgt Acc: 32.989%
	I - Batch: 250 | Loss: 4.201 | Acc: 39.250% | Wgt Acc: 34.643%
	I - Batch: 300 | Loss: 4.186 | Acc: 38.396% | Wgt Acc: 34.916%
	I - Batch: 350 | Loss: 4.191 | Acc: 38.268% | Wgt Acc: 34.766%
	I - Batch: 400 | Loss: 4.192 | Acc: 39.297% | Wgt Acc: 34.633%
	I - Batch: 450 | Loss: 4.187 | Acc: 39.944% | Wgt Acc: 34.469%
	I - Batch: 500 | Loss: 4.185 | Acc: 40.062% | Wgt Acc: 34.231%
	I - Batch: 550 | Loss: 4.174 | Acc: 40.341% | Wgt Acc: 34.285%
	I - Batch: 600 | Loss: 4.171 | Acc: 40.250% | Wgt Acc: 34.288%
	I - Batch: 650 | Loss: 4.172 | Acc: 40.212% | Wgt Acc: 34.230%
	I - Batch: 700 | Loss: 4.168 | Acc: 40.250% | Wgt Acc: 34.267%
	I - Batch: 750 | Loss: 4.163 | Acc: 39.742% | Wgt Acc: 34.291%
	I - Batch: 800 | Loss: 4.162 | Acc: 39.711% | Wgt Acc: 34.425%
	I - Batch: 850 | Loss: 4.168 | Acc: 40.184% | Wgt Acc: 34.303%
	I - Batch: 900 | Loss: 4.172 | Acc: 40.382% | Wgt Acc: 34.193%
	I - Batch: 950 | Loss: 4.168 | Acc: 39.836% | Wgt Acc: 34.007%
	I - Batch: 1000 | Loss: 4.169 | Acc: 39.444% | Wgt Acc: 33.906%
I - num batch: 1003
I - Train -- Loss: 4.169 | Acc: 39.451% | Wgt Acc: 33.909% | LR: 5.000000e-04 | Dur: 625.54s
I - Confusion Matrix: [row->prediction - col->label]
[[1258.  129.  226. 1046. 1028.]
 [  27.  424.  593.   67. 1348.]
 [  21.  256.  382.   36.  983.]
 [ 158.   43.   82.  167.  352.]
 [ 398.  986. 1355.  578. 4097.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.151 | Acc: 8.875% | Wgt Acc: 9.262%
	I - Batch: 100 | Loss: 5.069 | Acc: 19.250% | Wgt Acc: 14.021%
	I - Batch: 150 | Loss: 4.999 | Acc: 29.500% | Wgt Acc: 18.097%
	I - Batch: 200 | Loss: 4.968 | Acc: 34.562% | Wgt Acc: 20.449%
I - num batch: 238
I - Val -- Loss: 4.954 | Acc: 36.689% | Wgt Acc: 21.890% | Dur: 114.28s
I - Confusion Matrix: [row->prediction - col->label]
[[   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 338.   34.   44.  302.  114.]
 [ 188.  692.  734.  265. 1094.]]

I - Local maximum validation set accuracy:  36.69

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 4.229 | Acc: 35.000% | Wgt Acc: 30.013%
	I - Batch: 100 | Loss: 4.202 | Acc: 38.688% | Wgt Acc: 32.009%
	I - Batch: 150 | Loss: 4.152 | Acc: 42.042% | Wgt Acc: 33.071%
	I - Batch: 200 | Loss: 4.146 | Acc: 41.656% | Wgt Acc: 33.288%
	I - Batch: 250 | Loss: 4.148 | Acc: 41.175% | Wgt Acc: 33.516%
	I - Batch: 300 | Loss: 4.164 | Acc: 41.062% | Wgt Acc: 32.887%
	I - Batch: 350 | Loss: 4.165 | Acc: 41.161% | Wgt Acc: 32.743%
	I - Batch: 400 | Loss: 4.164 | Acc: 41.000% | Wgt Acc: 33.108%
	I - Batch: 450 | Loss: 4.165 | Acc: 40.403% | Wgt Acc: 33.376%
	I - Batch: 500 | Loss: 4.166 | Acc: 40.700% | Wgt Acc: 33.479%
	I - Batch: 550 | Loss: 4.169 | Acc: 40.125% | Wgt Acc: 33.443%
	I - Batch: 600 | Loss: 4.178 | Acc: 39.958% | Wgt Acc: 33.387%
	I - Batch: 650 | Loss: 4.181 | Acc: 40.692% | Wgt Acc: 33.368%
	I - Batch: 700 | Loss: 4.177 | Acc: 40.875% | Wgt Acc: 33.448%
	I - Batch: 750 | Loss: 4.166 | Acc: 40.708% | Wgt Acc: 33.642%
	I - Batch: 800 | Loss: 4.163 | Acc: 40.211% | Wgt Acc: 33.862%
	I - Batch: 850 | Loss: 4.173 | Acc: 40.029% | Wgt Acc: 33.622%
	I - Batch: 900 | Loss: 4.173 | Acc: 40.201% | Wgt Acc: 33.620%
	I - Batch: 950 | Loss: 4.170 | Acc: 40.046% | Wgt Acc: 33.688%
	I - Batch: 1000 | Loss: 4.168 | Acc: 40.081% | Wgt Acc: 33.765%
I - num batch: 1003
I - Train -- Loss: 4.167 | Acc: 40.069% | Wgt Acc: 33.758% | LR: 5.000000e-04 | Dur: 628.09s
I - Confusion Matrix: [row->prediction - col->label]
[[1288.  129.  239. 1078. 1081.]
 [  39.  427.  641.   62. 1382.]
 [  10.  174.  233.   25.  594.]
 [ 161.   58.  101.  166.  438.]
 [ 364. 1050. 1424.  563. 4313.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.231 | Acc: 13.500% | Wgt Acc: 14.583%
	I - Batch: 100 | Loss: 5.138 | Acc: 21.750% | Wgt Acc: 17.328%
	I - Batch: 150 | Loss: 5.064 | Acc: 32.708% | Wgt Acc: 22.487%
	I - Batch: 200 | Loss: 5.034 | Acc: 37.625% | Wgt Acc: 25.068%
I - num batch: 238
I - Val -- Loss: 5.020 | Acc: 39.396% | Wgt Acc: 25.905% | Dur: 114.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 330.   22.   44.  268.   70.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  42.   20.   12.   71.   40.]
 [ 154.  684.  722.  228. 1098.]]

I - Local maximum validation set accuracy:  39.40

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 4.105 | Acc: 42.375% | Wgt Acc: 33.989%
	I - Batch: 100 | Loss: 4.154 | Acc: 45.312% | Wgt Acc: 33.711%
	I - Batch: 150 | Loss: 4.176 | Acc: 44.792% | Wgt Acc: 32.836%
	I - Batch: 200 | Loss: 4.156 | Acc: 44.406% | Wgt Acc: 33.998%
	I - Batch: 250 | Loss: 4.161 | Acc: 44.300% | Wgt Acc: 33.921%
	I - Batch: 300 | Loss: 4.159 | Acc: 43.938% | Wgt Acc: 34.002%
	I - Batch: 350 | Loss: 4.158 | Acc: 43.964% | Wgt Acc: 34.017%
	I - Batch: 400 | Loss: 4.159 | Acc: 44.672% | Wgt Acc: 34.154%
	I - Batch: 450 | Loss: 4.159 | Acc: 45.417% | Wgt Acc: 34.300%
	I - Batch: 500 | Loss: 4.166 | Acc: 45.975% | Wgt Acc: 34.199%
	I - Batch: 550 | Loss: 4.169 | Acc: 46.341% | Wgt Acc: 34.304%
	I - Batch: 600 | Loss: 4.162 | Acc: 46.312% | Wgt Acc: 34.407%
	I - Batch: 650 | Loss: 4.163 | Acc: 45.779% | Wgt Acc: 34.205%
	I - Batch: 700 | Loss: 4.162 | Acc: 45.920% | Wgt Acc: 34.091%
	I - Batch: 750 | Loss: 4.167 | Acc: 45.992% | Wgt Acc: 33.957%
	I - Batch: 800 | Loss: 4.162 | Acc: 45.797% | Wgt Acc: 34.080%
	I - Batch: 850 | Loss: 4.162 | Acc: 45.360% | Wgt Acc: 34.127%
	I - Batch: 900 | Loss: 4.163 | Acc: 45.132% | Wgt Acc: 34.212%
	I - Batch: 950 | Loss: 4.162 | Acc: 45.204% | Wgt Acc: 34.095%
	I - Batch: 1000 | Loss: 4.158 | Acc: 44.719% | Wgt Acc: 34.212%
I - num batch: 1003
I - Train -- Loss: 4.159 | Acc: 44.670% | Wgt Acc: 34.191% | LR: 5.000000e-04 | Dur: 635.79s
I - Confusion Matrix: [row->prediction - col->label]
[[1221.  101.  196.  985.  849.]
 [  19.  180.  242.   26.  564.]
 [   6.  212.  276.   23.  609.]
 [ 209.   88.  120.  243.  541.]
 [ 407. 1257. 1804.  617. 5245.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.663 | Acc: 22.500% | Wgt Acc: 24.660%
	I - Batch: 100 | Loss: 5.553 | Acc: 23.125% | Wgt Acc: 24.727%
	I - Batch: 150 | Loss: 5.467 | Acc: 24.875% | Wgt Acc: 25.883%
	I - Batch: 200 | Loss: 5.403 | Acc: 26.000% | Wgt Acc: 27.346%
I - num batch: 238
I - Val -- Loss: 5.380 | Acc: 25.729% | Wgt Acc: 26.678% | Dur: 116.34s
I - Confusion Matrix: [row->prediction - col->label]
[[458. 252. 270. 499. 482.]
 [  2. 132. 180.   3. 217.]
 [  0.   0.   0.   0.   0.]
 [ 46.  84.  94.  33. 153.]
 [ 20. 258. 234.  32. 356.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 4.208 | Acc: 44.500% | Wgt Acc: 33.932%
	I - Batch: 100 | Loss: 4.151 | Acc: 46.750% | Wgt Acc: 34.516%
	I - Batch: 150 | Loss: 4.160 | Acc: 45.750% | Wgt Acc: 32.561%
	I - Batch: 200 | Loss: 4.169 | Acc: 43.438% | Wgt Acc: 32.527%
	I - Batch: 250 | Loss: 4.155 | Acc: 42.325% | Wgt Acc: 32.599%
	I - Batch: 300 | Loss: 4.153 | Acc: 41.375% | Wgt Acc: 32.619%
	I - Batch: 350 | Loss: 4.136 | Acc: 42.304% | Wgt Acc: 33.072%
	I - Batch: 400 | Loss: 4.150 | Acc: 41.984% | Wgt Acc: 32.784%
	I - Batch: 450 | Loss: 4.148 | Acc: 41.931% | Wgt Acc: 32.449%
	I - Batch: 500 | Loss: 4.140 | Acc: 41.525% | Wgt Acc: 32.448%
	I - Batch: 550 | Loss: 4.141 | Acc: 41.864% | Wgt Acc: 32.668%
	I - Batch: 600 | Loss: 4.143 | Acc: 42.552% | Wgt Acc: 32.918%
	I - Batch: 650 | Loss: 4.144 | Acc: 42.981% | Wgt Acc: 32.982%
	I - Batch: 700 | Loss: 4.148 | Acc: 43.304% | Wgt Acc: 33.019%
	I - Batch: 750 | Loss: 4.138 | Acc: 43.133% | Wgt Acc: 33.309%
	I - Batch: 800 | Loss: 4.135 | Acc: 42.852% | Wgt Acc: 33.495%
	I - Batch: 850 | Loss: 4.141 | Acc: 42.809% | Wgt Acc: 33.626%
	I - Batch: 900 | Loss: 4.142 | Acc: 42.965% | Wgt Acc: 33.771%
	I - Batch: 950 | Loss: 4.148 | Acc: 43.112% | Wgt Acc: 33.565%
	I - Batch: 1000 | Loss: 4.148 | Acc: 43.475% | Wgt Acc: 33.645%
I - num batch: 1003
I - Train -- Loss: 4.148 | Acc: 43.510% | Wgt Acc: 33.663% | LR: 5.000000e-04 | Dur: 636.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 972.   62.  141.  789.  635.]
 [  10.  250.  345.   25.  784.]
 [  16.  183.  282.   25.  555.]
 [ 442.  115.  169.  426.  785.]
 [ 422. 1228. 1701.  629. 5049.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.289 | Acc: 19.375% | Wgt Acc: 19.078%
	I - Batch: 100 | Loss: 5.202 | Acc: 23.938% | Wgt Acc: 20.447%
	I - Batch: 150 | Loss: 5.121 | Acc: 33.125% | Wgt Acc: 24.655%
	I - Batch: 200 | Loss: 5.097 | Acc: 37.031% | Wgt Acc: 27.150%
I - num batch: 238
I - Val -- Loss: 5.081 | Acc: 38.265% | Wgt Acc: 27.641% | Dur: 116.19s
I - Confusion Matrix: [row->prediction - col->label]
[[339.  18.  58. 362. 117.]
 [  0.   0.   0.   0.   0.]
 [  2. 188. 168.   6. 123.]
 [ 48.  32.  28.  40.  59.]
 [137. 488. 524. 159. 909.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 4.099 | Acc: 45.125% | Wgt Acc: 36.136%
	I - Batch: 100 | Loss: 4.103 | Acc: 40.312% | Wgt Acc: 35.994%
	I - Batch: 150 | Loss: 4.143 | Acc: 40.625% | Wgt Acc: 35.779%
	I - Batch: 200 | Loss: 4.139 | Acc: 42.625% | Wgt Acc: 35.359%
	I - Batch: 250 | Loss: 4.140 | Acc: 43.950% | Wgt Acc: 35.017%
	I - Batch: 300 | Loss: 4.139 | Acc: 44.812% | Wgt Acc: 34.645%
	I - Batch: 350 | Loss: 4.126 | Acc: 45.589% | Wgt Acc: 34.624%
	I - Batch: 400 | Loss: 4.119 | Acc: 46.375% | Wgt Acc: 34.838%
	I - Batch: 450 | Loss: 4.113 | Acc: 46.458% | Wgt Acc: 34.343%
	I - Batch: 500 | Loss: 4.099 | Acc: 46.812% | Wgt Acc: 34.464%
	I - Batch: 550 | Loss: 4.102 | Acc: 46.773% | Wgt Acc: 34.341%
	I - Batch: 600 | Loss: 4.101 | Acc: 46.323% | Wgt Acc: 34.390%
	I - Batch: 650 | Loss: 4.103 | Acc: 45.933% | Wgt Acc: 34.494%
	I - Batch: 700 | Loss: 4.102 | Acc: 45.348% | Wgt Acc: 34.587%
	I - Batch: 750 | Loss: 4.109 | Acc: 45.058% | Wgt Acc: 34.602%
	I - Batch: 800 | Loss: 4.111 | Acc: 44.922% | Wgt Acc: 34.788%
	I - Batch: 850 | Loss: 4.115 | Acc: 45.029% | Wgt Acc: 34.902%
	I - Batch: 900 | Loss: 4.117 | Acc: 44.806% | Wgt Acc: 34.837%
	I - Batch: 950 | Loss: 4.126 | Acc: 44.757% | Wgt Acc: 34.954%
	I - Batch: 1000 | Loss: 4.125 | Acc: 44.831% | Wgt Acc: 35.063%
I - num batch: 1003
I - Train -- Loss: 4.125 | Acc: 44.850% | Wgt Acc: 35.095% | LR: 5.000000e-04 | Dur: 636.97s
I - Confusion Matrix: [row->prediction - col->label]
[[1218.   96.  193.  978.  888.]
 [   9.  235.  252.   32.  551.]
 [  17.  263.  374.   41.  721.]
 [ 223.   75.  116.  238.  519.]
 [ 395. 1169. 1703.  605. 5129.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.447 | Acc: 32.250% | Wgt Acc: 35.808%
	I - Batch: 100 | Loss: 5.337 | Acc: 33.125% | Wgt Acc: 35.659%
	I - Batch: 150 | Loss: 5.226 | Acc: 36.500% | Wgt Acc: 36.865%
	I - Batch: 200 | Loss: 5.185 | Acc: 38.062% | Wgt Acc: 37.969%
I - num batch: 238
I - Val -- Loss: 5.160 | Acc: 38.055% | Wgt Acc: 37.461% | Dur: 116.29s
I - Confusion Matrix: [row->prediction - col->label]
[[416.  56.  96. 419. 209.]
 [  6. 398. 402.  15. 351.]
 [  0.   0.   0.   0.   0.]
 [ 12.  20.  24.  19.  33.]
 [ 92. 252. 256. 114. 615.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 4.164 | Acc: 48.625% | Wgt Acc: 39.191%
	I - Batch: 100 | Loss: 4.116 | Acc: 51.188% | Wgt Acc: 39.005%
	I - Batch: 150 | Loss: 4.110 | Acc: 49.750% | Wgt Acc: 36.863%
	I - Batch: 200 | Loss: 4.108 | Acc: 49.875% | Wgt Acc: 36.435%
	I - Batch: 250 | Loss: 4.108 | Acc: 50.025% | Wgt Acc: 36.031%
	I - Batch: 300 | Loss: 4.118 | Acc: 49.562% | Wgt Acc: 35.119%
	I - Batch: 350 | Loss: 4.130 | Acc: 49.286% | Wgt Acc: 34.577%
	I - Batch: 400 | Loss: 4.131 | Acc: 49.078% | Wgt Acc: 34.484%
	I - Batch: 450 | Loss: 4.132 | Acc: 48.944% | Wgt Acc: 34.236%
	I - Batch: 500 | Loss: 4.137 | Acc: 48.862% | Wgt Acc: 34.166%
	I - Batch: 550 | Loss: 4.135 | Acc: 48.716% | Wgt Acc: 34.212%
	I - Batch: 600 | Loss: 4.135 | Acc: 48.760% | Wgt Acc: 34.195%
	I - Batch: 650 | Loss: 4.139 | Acc: 48.635% | Wgt Acc: 33.997%
	I - Batch: 700 | Loss: 4.137 | Acc: 48.509% | Wgt Acc: 33.958%
	I - Batch: 750 | Loss: 4.141 | Acc: 48.517% | Wgt Acc: 34.039%
	I - Batch: 800 | Loss: 4.139 | Acc: 48.461% | Wgt Acc: 33.990%
	I - Batch: 850 | Loss: 4.142 | Acc: 48.353% | Wgt Acc: 33.918%
	I - Batch: 900 | Loss: 4.137 | Acc: 48.292% | Wgt Acc: 33.954%
	I - Batch: 950 | Loss: 4.136 | Acc: 48.566% | Wgt Acc: 34.144%
	I - Batch: 1000 | Loss: 4.133 | Acc: 48.556% | Wgt Acc: 34.129%
I - num batch: 1003
I - Train -- Loss: 4.134 | Acc: 48.541% | Wgt Acc: 34.113% | LR: 5.000000e-04 | Dur: 638.39s
I - Confusion Matrix: [row->prediction - col->label]
[[1141.   92.  202.  885.  923.]
 [   4.   91.   98.   12.  156.]
 [   0.   20.   40.    1.   72.]
 [ 303.   69.  103.  313.  456.]
 [ 414. 1566. 2195.  683. 6201.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.571 | Acc: 15.750% | Wgt Acc: 17.100%
	I - Batch: 100 | Loss: 5.466 | Acc: 21.750% | Wgt Acc: 19.813%
	I - Batch: 150 | Loss: 5.364 | Acc: 28.917% | Wgt Acc: 23.227%
	I - Batch: 200 | Loss: 5.320 | Acc: 32.969% | Wgt Acc: 25.817%
I - num batch: 238
I - Val -- Loss: 5.310 | Acc: 33.456% | Wgt Acc: 25.754% | Dur: 116.46s
I - Confusion Matrix: [row->prediction - col->label]
[[452. 158. 174. 483. 370.]
 [  0.   0.   0.   0.   0.]
 [  0.  12.  26.   1.   7.]
 [ 13.  18.  18.  12.  48.]
 [ 61. 538. 560.  71. 783.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 4.100 | Acc: 49.000% | Wgt Acc: 33.808%
	I - Batch: 100 | Loss: 4.110 | Acc: 49.312% | Wgt Acc: 34.188%
	I - Batch: 150 | Loss: 4.125 | Acc: 48.625% | Wgt Acc: 33.062%
	I - Batch: 200 | Loss: 4.128 | Acc: 49.219% | Wgt Acc: 33.788%
	I - Batch: 250 | Loss: 4.125 | Acc: 49.275% | Wgt Acc: 33.693%
	I - Batch: 300 | Loss: 4.126 | Acc: 49.250% | Wgt Acc: 33.645%
	I - Batch: 350 | Loss: 4.133 | Acc: 48.607% | Wgt Acc: 33.373%
	I - Batch: 400 | Loss: 4.138 | Acc: 48.281% | Wgt Acc: 33.154%
	I - Batch: 450 | Loss: 4.147 | Acc: 48.486% | Wgt Acc: 33.129%
	I - Batch: 500 | Loss: 4.146 | Acc: 48.487% | Wgt Acc: 33.264%
	I - Batch: 550 | Loss: 4.138 | Acc: 47.875% | Wgt Acc: 33.308%
	I - Batch: 600 | Loss: 4.136 | Acc: 46.979% | Wgt Acc: 33.345%
	I - Batch: 650 | Loss: 4.136 | Acc: 47.038% | Wgt Acc: 33.511%
	I - Batch: 700 | Loss: 4.138 | Acc: 47.152% | Wgt Acc: 33.544%
	I - Batch: 750 | Loss: 4.135 | Acc: 47.108% | Wgt Acc: 33.728%
	I - Batch: 800 | Loss: 4.136 | Acc: 47.258% | Wgt Acc: 33.748%
	I - Batch: 850 | Loss: 4.136 | Acc: 47.228% | Wgt Acc: 33.534%
	I - Batch: 900 | Loss: 4.135 | Acc: 47.444% | Wgt Acc: 33.644%
	I - Batch: 950 | Loss: 4.131 | Acc: 47.401% | Wgt Acc: 33.535%
	I - Batch: 1000 | Loss: 4.137 | Acc: 47.538% | Wgt Acc: 33.674%
I - num batch: 1003
I - Train -- Loss: 4.136 | Acc: 47.550% | Wgt Acc: 33.690% | LR: 5.000000e-04 | Dur: 637.97s
I - Confusion Matrix: [row->prediction - col->label]
[[1260.   90.  224. 1030.  918.]
 [   7.  125.  164.   10.  352.]
 [   0.    4.    5.    0.    7.]
 [ 174.   66.   84.  177.  471.]
 [ 421. 1553. 2161.  677. 6060.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.437 | Acc: 22.000% | Wgt Acc: 24.296%
	I - Batch: 100 | Loss: 5.328 | Acc: 25.875% | Wgt Acc: 24.995%
	I - Batch: 150 | Loss: 5.237 | Acc: 33.958% | Wgt Acc: 28.722%
	I - Batch: 200 | Loss: 5.205 | Acc: 37.688% | Wgt Acc: 31.162%
I - num batch: 238
I - Val -- Loss: 5.199 | Acc: 38.739% | Wgt Acc: 31.457% | Dur: 116.13s
I - Confusion Matrix: [row->prediction - col->label]
[[396.  54.  90. 391. 199.]
 [ 15. 202. 146.  25. 132.]
 [  0.   0.   0.   0.   0.]
 [  7.   8.   6.   8.   9.]
 [108. 462. 536. 143. 868.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 4.094 | Acc: 49.000% | Wgt Acc: 33.192%
	I - Batch: 100 | Loss: 4.087 | Acc: 50.938% | Wgt Acc: 35.183%
	I - Batch: 150 | Loss: 4.139 | Acc: 49.375% | Wgt Acc: 33.397%
	I - Batch: 200 | Loss: 4.133 | Acc: 49.688% | Wgt Acc: 33.749%
	I - Batch: 250 | Loss: 4.138 | Acc: 49.275% | Wgt Acc: 33.541%
	I - Batch: 300 | Loss: 4.141 | Acc: 49.833% | Wgt Acc: 33.655%
	I - Batch: 350 | Loss: 4.137 | Acc: 49.804% | Wgt Acc: 33.822%
	I - Batch: 400 | Loss: 4.143 | Acc: 49.391% | Wgt Acc: 33.406%
	I - Batch: 450 | Loss: 4.138 | Acc: 49.222% | Wgt Acc: 33.417%
	I - Batch: 500 | Loss: 4.147 | Acc: 49.250% | Wgt Acc: 33.554%
	I - Batch: 550 | Loss: 4.155 | Acc: 49.000% | Wgt Acc: 33.321%
	I - Batch: 600 | Loss: 4.152 | Acc: 49.260% | Wgt Acc: 33.532%
	I - Batch: 650 | Loss: 4.143 | Acc: 49.375% | Wgt Acc: 33.838%
	I - Batch: 700 | Loss: 4.133 | Acc: 49.366% | Wgt Acc: 33.853%
	I - Batch: 750 | Loss: 4.135 | Acc: 49.167% | Wgt Acc: 33.584%
	I - Batch: 800 | Loss: 4.134 | Acc: 49.008% | Wgt Acc: 33.431%
	I - Batch: 850 | Loss: 4.134 | Acc: 49.154% | Wgt Acc: 33.538%
	I - Batch: 900 | Loss: 4.133 | Acc: 49.125% | Wgt Acc: 33.489%
	I - Batch: 950 | Loss: 4.134 | Acc: 49.270% | Wgt Acc: 33.547%
	I - Batch: 1000 | Loss: 4.134 | Acc: 49.275% | Wgt Acc: 33.555%
I - num batch: 1003
I - Train -- Loss: 4.134 | Acc: 49.271% | Wgt Acc: 33.546% | LR: 5.000000e-04 | Dur: 635.63s
I - Confusion Matrix: [row->prediction - col->label]
[[1316.  118.  254. 1085. 1096.]
 [   0.   10.   10.    1.    7.]
 [   0.   14.    5.    0.   14.]
 [ 101.   43.   53.  112.  231.]
 [ 445. 1653. 2316.  696. 6460.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.309 | Acc: 7.750% | Wgt Acc: 8.088%
	I - Batch: 100 | Loss: 5.222 | Acc: 18.375% | Wgt Acc: 13.131%
	I - Batch: 150 | Loss: 5.139 | Acc: 30.125% | Wgt Acc: 18.140%
	I - Batch: 200 | Loss: 5.115 | Acc: 34.938% | Wgt Acc: 20.564%
I - num batch: 238
I - Val -- Loss: 5.104 | Acc: 37.109% | Wgt Acc: 21.905% | Dur: 115.15s
I - Confusion Matrix: [row->prediction - col->label]
[[   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 304.   12.   36.  296.   92.]
 [ 222.  714.  742.  271. 1116.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 4.165 | Acc: 47.625% | Wgt Acc: 31.072%
	I - Batch: 100 | Loss: 4.140 | Acc: 48.750% | Wgt Acc: 32.912%
	I - Batch: 150 | Loss: 4.112 | Acc: 49.667% | Wgt Acc: 33.372%
	I - Batch: 200 | Loss: 4.114 | Acc: 48.688% | Wgt Acc: 32.401%
	I - Batch: 250 | Loss: 4.108 | Acc: 48.350% | Wgt Acc: 32.460%
	I - Batch: 300 | Loss: 4.097 | Acc: 48.812% | Wgt Acc: 32.933%
	I - Batch: 350 | Loss: 4.112 | Acc: 48.661% | Wgt Acc: 32.947%
	I - Batch: 400 | Loss: 4.119 | Acc: 48.797% | Wgt Acc: 32.992%
	I - Batch: 450 | Loss: 4.128 | Acc: 48.458% | Wgt Acc: 32.814%
	I - Batch: 500 | Loss: 4.128 | Acc: 48.550% | Wgt Acc: 32.933%
	I - Batch: 550 | Loss: 4.126 | Acc: 48.477% | Wgt Acc: 32.889%
	I - Batch: 600 | Loss: 4.126 | Acc: 48.573% | Wgt Acc: 33.032%
	I - Batch: 650 | Loss: 4.126 | Acc: 48.519% | Wgt Acc: 32.960%
	I - Batch: 700 | Loss: 4.125 | Acc: 48.473% | Wgt Acc: 33.007%
	I - Batch: 750 | Loss: 4.120 | Acc: 48.825% | Wgt Acc: 33.319%
	I - Batch: 800 | Loss: 4.125 | Acc: 48.883% | Wgt Acc: 33.357%
	I - Batch: 850 | Loss: 4.126 | Acc: 48.985% | Wgt Acc: 33.383%
	I - Batch: 900 | Loss: 4.130 | Acc: 48.806% | Wgt Acc: 33.286%
	I - Batch: 950 | Loss: 4.133 | Acc: 48.757% | Wgt Acc: 33.304%
	I - Batch: 1000 | Loss: 4.124 | Acc: 48.875% | Wgt Acc: 33.454%
I - num batch: 1003
I - Train -- Loss: 4.124 | Acc: 48.884% | Wgt Acc: 33.459% | LR: 5.000000e-04 | Dur: 631.45s
I - Confusion Matrix: [row->prediction - col->label]
[[1181.   91.  180.  988.  850.]
 [   1.    5.    4.    0.   15.]
 [   4.   26.   20.    2.   42.]
 [ 248.   68.  109.  264.  530.]
 [ 428. 1648. 2325.  640. 6371.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.502 | Acc: 15.625% | Wgt Acc: 16.763%
	I - Batch: 100 | Loss: 5.382 | Acc: 21.938% | Wgt Acc: 19.100%
	I - Batch: 150 | Loss: 5.269 | Acc: 30.583% | Wgt Acc: 22.714%
	I - Batch: 200 | Loss: 5.233 | Acc: 34.750% | Wgt Acc: 24.778%
I - num batch: 238
I - Val -- Loss: 5.209 | Acc: 36.662% | Wgt Acc: 26.258% | Dur: 114.99s
I - Confusion Matrix: [row->prediction - col->label]
[[295.   8.  28. 269.  49.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [148.  94. 122. 165. 224.]
 [ 83. 624. 628. 133. 935.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 4.135 | Acc: 49.875% | Wgt Acc: 33.104%
	I - Batch: 100 | Loss: 4.112 | Acc: 50.438% | Wgt Acc: 33.744%
	I - Batch: 150 | Loss: 4.122 | Acc: 49.000% | Wgt Acc: 32.445%
	I - Batch: 200 | Loss: 4.142 | Acc: 48.938% | Wgt Acc: 32.308%
	I - Batch: 250 | Loss: 4.125 | Acc: 48.800% | Wgt Acc: 32.643%
	I - Batch: 300 | Loss: 4.127 | Acc: 48.562% | Wgt Acc: 32.429%
	I - Batch: 350 | Loss: 4.117 | Acc: 49.054% | Wgt Acc: 33.024%
	I - Batch: 400 | Loss: 4.114 | Acc: 49.031% | Wgt Acc: 33.036%
	I - Batch: 450 | Loss: 4.118 | Acc: 49.000% | Wgt Acc: 33.079%
	I - Batch: 500 | Loss: 4.102 | Acc: 48.888% | Wgt Acc: 33.075%
	I - Batch: 550 | Loss: 4.100 | Acc: 48.614% | Wgt Acc: 32.961%
	I - Batch: 600 | Loss: 4.102 | Acc: 48.490% | Wgt Acc: 32.805%
	I - Batch: 650 | Loss: 4.107 | Acc: 48.269% | Wgt Acc: 32.552%
	I - Batch: 700 | Loss: 4.114 | Acc: 48.107% | Wgt Acc: 32.188%
	I - Batch: 750 | Loss: 4.106 | Acc: 48.017% | Wgt Acc: 32.288%
	I - Batch: 800 | Loss: 4.105 | Acc: 48.219% | Wgt Acc: 32.480%
	I - Batch: 850 | Loss: 4.108 | Acc: 48.265% | Wgt Acc: 32.497%
	I - Batch: 900 | Loss: 4.114 | Acc: 48.306% | Wgt Acc: 32.498%
	I - Batch: 950 | Loss: 4.110 | Acc: 48.572% | Wgt Acc: 32.768%
	I - Batch: 1000 | Loss: 4.116 | Acc: 48.612% | Wgt Acc: 32.803%
I - num batch: 1003
I - Train -- Loss: 4.116 | Acc: 48.616% | Wgt Acc: 32.802% | LR: 5.000000e-04 | Dur: 632.10s
I - Confusion Matrix: [row->prediction - col->label]
[[1006.   79.  156.  832.  744.]
 [   0.    8.   13.    1.   19.]
 [   1.   18.    8.    2.   15.]
 [ 423.   68.  123.  378.  632.]
 [ 432. 1665. 2338.  681. 6398.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.401 | Acc: 17.000% | Wgt Acc: 18.475%
	I - Batch: 100 | Loss: 5.319 | Acc: 21.812% | Wgt Acc: 20.827%
	I - Batch: 150 | Loss: 5.263 | Acc: 27.708% | Wgt Acc: 23.444%
	I - Batch: 200 | Loss: 5.219 | Acc: 31.406% | Wgt Acc: 25.751%
I - num batch: 238
I - Val -- Loss: 5.196 | Acc: 31.905% | Wgt Acc: 25.609% | Dur: 115.07s
I - Confusion Matrix: [row->prediction - col->label]
[[491. 150. 196. 498. 461.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  5.  18.  18.   6.  30.]
 [ 30. 558. 564.  63. 717.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 4.140 | Acc: 50.125% | Wgt Acc: 35.025%
	I - Batch: 100 | Loss: 4.073 | Acc: 49.875% | Wgt Acc: 34.674%
	I - Batch: 150 | Loss: 4.081 | Acc: 49.917% | Wgt Acc: 34.454%
	I - Batch: 200 | Loss: 4.064 | Acc: 49.812% | Wgt Acc: 34.722%
	I - Batch: 250 | Loss: 4.065 | Acc: 49.950% | Wgt Acc: 34.642%
	I - Batch: 300 | Loss: 4.061 | Acc: 50.104% | Wgt Acc: 34.769%
	I - Batch: 350 | Loss: 4.065 | Acc: 49.982% | Wgt Acc: 34.666%
	I - Batch: 400 | Loss: 4.062 | Acc: 49.891% | Wgt Acc: 34.576%
	I - Batch: 450 | Loss: 4.072 | Acc: 49.931% | Wgt Acc: 34.498%
	I - Batch: 500 | Loss: 4.078 | Acc: 49.913% | Wgt Acc: 34.390%
	I - Batch: 550 | Loss: 4.076 | Acc: 49.739% | Wgt Acc: 34.192%
	I - Batch: 600 | Loss: 4.073 | Acc: 49.740% | Wgt Acc: 34.157%
	I - Batch: 650 | Loss: 4.077 | Acc: 49.577% | Wgt Acc: 34.011%
	I - Batch: 700 | Loss: 4.071 | Acc: 49.580% | Wgt Acc: 34.105%
	I - Batch: 750 | Loss: 4.073 | Acc: 49.717% | Wgt Acc: 34.327%
	I - Batch: 800 | Loss: 4.070 | Acc: 49.781% | Wgt Acc: 34.300%
	I - Batch: 850 | Loss: 4.067 | Acc: 49.978% | Wgt Acc: 34.413%
	I - Batch: 900 | Loss: 4.065 | Acc: 50.174% | Wgt Acc: 34.592%
	I - Batch: 950 | Loss: 4.062 | Acc: 49.961% | Wgt Acc: 34.449%
	I - Batch: 1000 | Loss: 4.060 | Acc: 50.062% | Wgt Acc: 34.520%
I - num batch: 1003
I - Train -- Loss: 4.062 | Acc: 50.037% | Wgt Acc: 34.489% | LR: 2.500000e-04 | Dur: 631.70s
I - Confusion Matrix: [row->prediction - col->label]
[[1335.  101.  207. 1083.  931.]
 [   0.   34.   30.    0.   31.]
 [   0.    4.    6.    0.    8.]
 [ 109.   57.   95.  148.  335.]
 [ 418. 1642. 2300.  663. 6503.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.327 | Acc: 22.125% | Wgt Acc: 24.220%
	I - Batch: 100 | Loss: 5.289 | Acc: 27.625% | Wgt Acc: 26.722%
	I - Batch: 150 | Loss: 5.208 | Acc: 35.500% | Wgt Acc: 29.716%
	I - Batch: 200 | Loss: 5.174 | Acc: 39.250% | Wgt Acc: 31.905%
I - num batch: 238
I - Val -- Loss: 5.161 | Acc: 40.447% | Wgt Acc: 32.379% | Dur: 115.04s
I - Confusion Matrix: [row->prediction - col->label]
[[363.  20.  44. 319. 147.]
 [  0. 186. 154.   9.  79.]
 [  0.   0.   0.   0.   0.]
 [ 45.  20.  28.  71.  63.]
 [118. 500. 552. 168. 919.]]

I - Local maximum validation set accuracy:  40.45

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 4.138 | Acc: 47.250% | Wgt Acc: 32.187%
	I - Batch: 100 | Loss: 4.085 | Acc: 46.750% | Wgt Acc: 32.426%
	I - Batch: 150 | Loss: 4.053 | Acc: 47.625% | Wgt Acc: 32.921%
	I - Batch: 200 | Loss: 4.058 | Acc: 48.062% | Wgt Acc: 33.169%
	I - Batch: 250 | Loss: 4.054 | Acc: 47.650% | Wgt Acc: 32.867%
	I - Batch: 300 | Loss: 4.046 | Acc: 48.562% | Wgt Acc: 33.778%
	I - Batch: 350 | Loss: 4.035 | Acc: 49.304% | Wgt Acc: 34.177%
	I - Batch: 400 | Loss: 4.037 | Acc: 49.031% | Wgt Acc: 33.973%
	I - Batch: 450 | Loss: 4.035 | Acc: 49.347% | Wgt Acc: 34.357%
	I - Batch: 500 | Loss: 4.032 | Acc: 49.550% | Wgt Acc: 34.264%
	I - Batch: 550 | Loss: 4.031 | Acc: 49.682% | Wgt Acc: 34.225%
	I - Batch: 600 | Loss: 4.026 | Acc: 49.458% | Wgt Acc: 33.959%
	I - Batch: 650 | Loss: 4.028 | Acc: 49.337% | Wgt Acc: 34.001%
	I - Batch: 700 | Loss: 4.029 | Acc: 49.045% | Wgt Acc: 33.727%
	I - Batch: 750 | Loss: 4.028 | Acc: 49.175% | Wgt Acc: 33.824%
	I - Batch: 800 | Loss: 4.040 | Acc: 49.078% | Wgt Acc: 33.709%
	I - Batch: 850 | Loss: 4.034 | Acc: 49.353% | Wgt Acc: 33.931%
	I - Batch: 900 | Loss: 4.033 | Acc: 49.347% | Wgt Acc: 33.874%
	I - Batch: 950 | Loss: 4.039 | Acc: 49.342% | Wgt Acc: 33.937%
	I - Batch: 1000 | Loss: 4.040 | Acc: 49.394% | Wgt Acc: 33.952%
I - num batch: 1003
I - Train -- Loss: 4.040 | Acc: 49.377% | Wgt Acc: 33.934% | LR: 2.500000e-04 | Dur: 631.82s
I - Confusion Matrix: [row->prediction - col->label]
[[1246.   74.  170. 1040.  800.]
 [   0.   24.   26.    0.   20.]
 [   1.   17.   17.    2.    8.]
 [ 188.   68.  105.  211.  558.]
 [ 427. 1655. 2320.  641. 6422.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.340 | Acc: 13.250% | Wgt Acc: 14.349%
	I - Batch: 100 | Loss: 5.241 | Acc: 21.312% | Wgt Acc: 17.016%
	I - Batch: 150 | Loss: 5.154 | Acc: 32.708% | Wgt Acc: 22.222%
	I - Batch: 200 | Loss: 5.127 | Acc: 37.688% | Wgt Acc: 24.945%
I - num batch: 238
I - Val -- Loss: 5.117 | Acc: 39.474% | Wgt Acc: 25.816% | Dur: 115.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 350.   10.   32.  282.   71.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  23.    6.   14.   45.   30.]
 [ 153.  710.  732.  240. 1107.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 4.160 | Acc: 51.375% | Wgt Acc: 35.206%
	I - Batch: 100 | Loss: 4.163 | Acc: 49.688% | Wgt Acc: 34.063%
	I - Batch: 150 | Loss: 4.131 | Acc: 49.542% | Wgt Acc: 33.476%
	I - Batch: 200 | Loss: 4.100 | Acc: 49.156% | Wgt Acc: 33.351%
	I - Batch: 250 | Loss: 4.105 | Acc: 49.000% | Wgt Acc: 33.439%
	I - Batch: 300 | Loss: 4.093 | Acc: 49.250% | Wgt Acc: 33.928%
	I - Batch: 350 | Loss: 4.082 | Acc: 49.429% | Wgt Acc: 34.075%
	I - Batch: 400 | Loss: 4.070 | Acc: 49.906% | Wgt Acc: 34.651%
	I - Batch: 450 | Loss: 4.061 | Acc: 50.042% | Wgt Acc: 34.723%
	I - Batch: 500 | Loss: 4.063 | Acc: 49.913% | Wgt Acc: 34.598%
	I - Batch: 550 | Loss: 4.057 | Acc: 50.034% | Wgt Acc: 34.746%
	I - Batch: 600 | Loss: 4.068 | Acc: 49.708% | Wgt Acc: 34.442%
	I - Batch: 650 | Loss: 4.056 | Acc: 49.673% | Wgt Acc: 34.349%
	I - Batch: 700 | Loss: 4.059 | Acc: 49.562% | Wgt Acc: 34.299%
	I - Batch: 750 | Loss: 4.056 | Acc: 49.608% | Wgt Acc: 34.319%
	I - Batch: 800 | Loss: 4.049 | Acc: 49.836% | Wgt Acc: 34.499%
	I - Batch: 850 | Loss: 4.045 | Acc: 49.875% | Wgt Acc: 34.522%
	I - Batch: 900 | Loss: 4.045 | Acc: 49.799% | Wgt Acc: 34.453%
	I - Batch: 950 | Loss: 4.044 | Acc: 49.671% | Wgt Acc: 34.349%
	I - Batch: 1000 | Loss: 4.044 | Acc: 49.681% | Wgt Acc: 34.377%
I - num batch: 1003
I - Train -- Loss: 4.045 | Acc: 49.688% | Wgt Acc: 34.382% | LR: 2.500000e-04 | Dur: 634.47s
I - Confusion Matrix: [row->prediction - col->label]
[[1267.   73.  175. 1019.  897.]
 [   0.   33.   27.    3.   22.]
 [   0.   16.   26.    0.   16.]
 [ 168.   48.   91.  216.  445.]
 [ 427. 1668. 2319.  656. 6428.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.579 | Acc: 17.000% | Wgt Acc: 18.415%
	I - Batch: 100 | Loss: 5.474 | Acc: 21.188% | Wgt Acc: 20.187%
	I - Batch: 150 | Loss: 5.392 | Acc: 27.333% | Wgt Acc: 23.009%
	I - Batch: 200 | Loss: 5.322 | Acc: 31.250% | Wgt Acc: 25.445%
I - num batch: 238
I - Val -- Loss: 5.300 | Acc: 31.275% | Wgt Acc: 25.118% | Dur: 117.21s
I - Confusion Matrix: [row->prediction - col->label]
[[444.  92. 148. 461. 318.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 47.  88.  62.  46. 190.]
 [ 35. 546. 568.  60. 700.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 4.034 | Acc: 49.500% | Wgt Acc: 34.314%
	I - Batch: 100 | Loss: 4.026 | Acc: 49.312% | Wgt Acc: 34.129%
	I - Batch: 150 | Loss: 4.025 | Acc: 50.125% | Wgt Acc: 35.091%
	I - Batch: 200 | Loss: 4.003 | Acc: 50.344% | Wgt Acc: 35.857%
	I - Batch: 250 | Loss: 4.018 | Acc: 49.950% | Wgt Acc: 35.698%
	I - Batch: 300 | Loss: 4.029 | Acc: 49.917% | Wgt Acc: 35.529%
	I - Batch: 350 | Loss: 4.015 | Acc: 49.929% | Wgt Acc: 35.332%
	I - Batch: 400 | Loss: 4.009 | Acc: 49.828% | Wgt Acc: 34.945%
	I - Batch: 450 | Loss: 4.009 | Acc: 49.681% | Wgt Acc: 34.727%
	I - Batch: 500 | Loss: 4.013 | Acc: 49.538% | Wgt Acc: 34.644%
	I - Batch: 550 | Loss: 4.010 | Acc: 49.500% | Wgt Acc: 34.563%
	I - Batch: 600 | Loss: 4.009 | Acc: 49.406% | Wgt Acc: 34.415%
	I - Batch: 650 | Loss: 4.001 | Acc: 49.375% | Wgt Acc: 34.490%
	I - Batch: 700 | Loss: 4.004 | Acc: 49.384% | Wgt Acc: 34.383%
	I - Batch: 750 | Loss: 4.005 | Acc: 49.483% | Wgt Acc: 34.467%
	I - Batch: 800 | Loss: 4.009 | Acc: 49.547% | Wgt Acc: 34.378%
	I - Batch: 850 | Loss: 4.002 | Acc: 49.551% | Wgt Acc: 34.378%
	I - Batch: 900 | Loss: 4.007 | Acc: 49.431% | Wgt Acc: 34.148%
	I - Batch: 950 | Loss: 4.009 | Acc: 49.572% | Wgt Acc: 34.232%
	I - Batch: 1000 | Loss: 4.011 | Acc: 49.469% | Wgt Acc: 34.046%
I - num batch: 1003
I - Train -- Loss: 4.012 | Acc: 49.489% | Wgt Acc: 34.070% | LR: 2.500000e-04 | Dur: 634.23s
I - Confusion Matrix: [row->prediction - col->label]
[[1190.   60.  152. 1000.  744.]
 [   1.   38.   26.    5.   23.]
 [   2.   44.   52.    2.   40.]
 [ 262.   54.  114.  244.  587.]
 [ 407. 1642. 2294.  643. 6414.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.388 | Acc: 29.500% | Wgt Acc: 31.889%
	I - Batch: 100 | Loss: 5.322 | Acc: 31.938% | Wgt Acc: 31.606%
	I - Batch: 150 | Loss: 5.230 | Acc: 38.292% | Wgt Acc: 33.876%
	I - Batch: 200 | Loss: 5.185 | Acc: 41.750% | Wgt Acc: 35.796%
I - num batch: 238
I - Val -- Loss: 5.175 | Acc: 42.576% | Wgt Acc: 35.940% | Dur: 114.15s
I - Confusion Matrix: [row->prediction - col->label]
[[423.  40.  76. 387. 161.]
 [  0. 222. 122.   6.  58.]
 [  2.  16.  24.   1.   9.]
 [ 36.  32.  40.  61.  90.]
 [ 65. 416. 516. 112. 890.]]

I - Local maximum validation set accuracy:  42.58

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 3.940 | Acc: 48.000% | Wgt Acc: 35.321%
	I - Batch: 100 | Loss: 3.960 | Acc: 48.688% | Wgt Acc: 34.580%
	I - Batch: 150 | Loss: 4.010 | Acc: 49.167% | Wgt Acc: 34.025%
	I - Batch: 200 | Loss: 3.999 | Acc: 48.750% | Wgt Acc: 33.326%
	I - Batch: 250 | Loss: 4.011 | Acc: 48.375% | Wgt Acc: 32.629%
	I - Batch: 300 | Loss: 3.991 | Acc: 48.750% | Wgt Acc: 33.043%
	I - Batch: 350 | Loss: 3.992 | Acc: 49.018% | Wgt Acc: 33.371%
	I - Batch: 400 | Loss: 3.983 | Acc: 49.328% | Wgt Acc: 33.878%
	I - Batch: 450 | Loss: 3.981 | Acc: 49.569% | Wgt Acc: 34.148%
	I - Batch: 500 | Loss: 3.982 | Acc: 49.550% | Wgt Acc: 34.130%
	I - Batch: 550 | Loss: 3.991 | Acc: 49.852% | Wgt Acc: 34.271%
	I - Batch: 600 | Loss: 3.987 | Acc: 50.406% | Wgt Acc: 34.729%
	I - Batch: 650 | Loss: 3.992 | Acc: 50.365% | Wgt Acc: 34.672%
	I - Batch: 700 | Loss: 3.981 | Acc: 50.634% | Wgt Acc: 35.000%
	I - Batch: 750 | Loss: 3.979 | Acc: 50.600% | Wgt Acc: 34.953%
	I - Batch: 800 | Loss: 3.973 | Acc: 50.617% | Wgt Acc: 35.065%
	I - Batch: 850 | Loss: 3.971 | Acc: 50.735% | Wgt Acc: 35.311%
	I - Batch: 900 | Loss: 3.977 | Acc: 50.646% | Wgt Acc: 35.272%
	I - Batch: 950 | Loss: 3.978 | Acc: 50.599% | Wgt Acc: 35.199%
	I - Batch: 1000 | Loss: 3.982 | Acc: 50.438% | Wgt Acc: 35.039%
I - num batch: 1003
I - Train -- Loss: 3.984 | Acc: 50.430% | Wgt Acc: 35.032% | LR: 2.500000e-04 | Dur: 632.28s
I - Confusion Matrix: [row->prediction - col->label]
[[1298.   70.  173. 1052.  866.]
 [   0.   46.   49.    3.   25.]
 [   0.   49.   48.    2.   38.]
 [ 181.   37.   82.  198.  380.]
 [ 383. 1636. 2286.  639. 6499.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.537 | Acc: 20.750% | Wgt Acc: 21.144%
	I - Batch: 100 | Loss: 5.435 | Acc: 24.125% | Wgt Acc: 22.319%
	I - Batch: 150 | Loss: 5.364 | Acc: 30.333% | Wgt Acc: 25.820%
	I - Batch: 200 | Loss: 5.301 | Acc: 33.906% | Wgt Acc: 28.348%
I - num batch: 238
I - Val -- Loss: 5.281 | Acc: 33.771% | Wgt Acc: 27.920% | Dur: 115.24s
I - Confusion Matrix: [row->prediction - col->label]
[[450.  92. 180. 466. 362.]
 [  0.   0.   0.   0.   0.]
 [  1. 122. 114.   2.  48.]
 [ 36.  64.  62.  39. 116.]
 [ 39. 448. 422.  60. 682.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 3.997 | Acc: 49.375% | Wgt Acc: 34.717%
	I - Batch: 100 | Loss: 3.935 | Acc: 49.375% | Wgt Acc: 34.608%
	I - Batch: 150 | Loss: 3.943 | Acc: 49.292% | Wgt Acc: 34.307%
	I - Batch: 200 | Loss: 3.942 | Acc: 49.750% | Wgt Acc: 34.763%
	I - Batch: 250 | Loss: 3.939 | Acc: 49.800% | Wgt Acc: 34.968%
	I - Batch: 300 | Loss: 3.920 | Acc: 50.375% | Wgt Acc: 35.518%
	I - Batch: 350 | Loss: 3.920 | Acc: 50.446% | Wgt Acc: 35.501%
	I - Batch: 400 | Loss: 3.913 | Acc: 50.359% | Wgt Acc: 35.451%
	I - Batch: 450 | Loss: 3.907 | Acc: 50.569% | Wgt Acc: 35.614%
	I - Batch: 500 | Loss: 3.908 | Acc: 50.688% | Wgt Acc: 35.616%
	I - Batch: 550 | Loss: 3.907 | Acc: 50.727% | Wgt Acc: 35.655%
	I - Batch: 600 | Loss: 3.906 | Acc: 50.854% | Wgt Acc: 35.828%
	I - Batch: 650 | Loss: 3.889 | Acc: 50.817% | Wgt Acc: 35.724%
	I - Batch: 700 | Loss: 3.878 | Acc: 50.643% | Wgt Acc: 35.519%
	I - Batch: 750 | Loss: 3.877 | Acc: 50.442% | Wgt Acc: 35.408%
	I - Batch: 800 | Loss: 3.881 | Acc: 50.273% | Wgt Acc: 35.360%
	I - Batch: 850 | Loss: 3.883 | Acc: 50.154% | Wgt Acc: 35.171%
	I - Batch: 900 | Loss: 3.884 | Acc: 50.229% | Wgt Acc: 35.203%
	I - Batch: 950 | Loss: 3.885 | Acc: 50.368% | Wgt Acc: 35.264%
	I - Batch: 1000 | Loss: 3.880 | Acc: 50.531% | Wgt Acc: 35.344%
I - num batch: 1003
I - Train -- Loss: 3.881 | Acc: 50.530% | Wgt Acc: 35.319% | LR: 1.250000e-04 | Dur: 632.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 768.   25.   87.  624.  407.]
 [   2.   97.   75.    4.   51.]
 [   2.  114.  112.    4.   62.]
 [ 723.   87.  141.  695.  855.]
 [ 367. 1515. 2223.  567. 6433.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.399 | Acc: 22.375% | Wgt Acc: 23.655%
	I - Batch: 100 | Loss: 5.318 | Acc: 30.375% | Wgt Acc: 28.208%
	I - Batch: 150 | Loss: 5.218 | Acc: 38.792% | Wgt Acc: 31.409%
	I - Batch: 200 | Loss: 5.181 | Acc: 42.094% | Wgt Acc: 32.829%
I - num batch: 238
I - Val -- Loss: 5.180 | Acc: 43.311% | Wgt Acc: 33.537% | Dur: 115.21s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  3. 278. 220.   7.  82.]
 [  3.  70.  48.   4.  37.]
 [390.  20.  46. 323.  90.]
 [130. 358. 464. 233. 999.]]

I - Local maximum validation set accuracy:  43.31

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 3.791 | Acc: 51.125% | Wgt Acc: 35.710%
	I - Batch: 100 | Loss: 3.754 | Acc: 51.375% | Wgt Acc: 35.117%
	I - Batch: 150 | Loss: 3.834 | Acc: 49.792% | Wgt Acc: 34.113%
	I - Batch: 200 | Loss: 3.854 | Acc: 48.906% | Wgt Acc: 33.865%
	I - Batch: 250 | Loss: 3.857 | Acc: 48.725% | Wgt Acc: 33.708%
	I - Batch: 300 | Loss: 3.859 | Acc: 49.062% | Wgt Acc: 34.075%
	I - Batch: 350 | Loss: 3.850 | Acc: 49.429% | Wgt Acc: 34.283%
	I - Batch: 400 | Loss: 3.852 | Acc: 49.578% | Wgt Acc: 34.256%
	I - Batch: 450 | Loss: 3.852 | Acc: 49.389% | Wgt Acc: 34.008%
	I - Batch: 500 | Loss: 3.847 | Acc: 49.500% | Wgt Acc: 34.126%
	I - Batch: 550 | Loss: 3.848 | Acc: 49.534% | Wgt Acc: 34.228%
	I - Batch: 600 | Loss: 3.845 | Acc: 49.729% | Wgt Acc: 34.274%
	I - Batch: 650 | Loss: 3.841 | Acc: 49.904% | Wgt Acc: 34.637%
	I - Batch: 700 | Loss: 3.838 | Acc: 50.420% | Wgt Acc: 35.105%
	I - Batch: 750 | Loss: 3.838 | Acc: 50.233% | Wgt Acc: 34.971%
	I - Batch: 800 | Loss: 3.836 | Acc: 50.352% | Wgt Acc: 35.019%
	I - Batch: 850 | Loss: 3.839 | Acc: 50.412% | Wgt Acc: 35.072%
	I - Batch: 900 | Loss: 3.839 | Acc: 50.424% | Wgt Acc: 35.070%
	I - Batch: 950 | Loss: 3.841 | Acc: 50.408% | Wgt Acc: 35.017%
	I - Batch: 1000 | Loss: 3.843 | Acc: 50.444% | Wgt Acc: 35.008%
I - num batch: 1003
I - Train -- Loss: 3.844 | Acc: 50.436% | Wgt Acc: 34.994% | LR: 1.250000e-04 | Dur: 635.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 175.    3.    5.  108.   50.]
 [   0.  121.  105.    2.   62.]
 [   2.  165.  149.    4.   90.]
 [1313.   96.  216. 1232. 1193.]
 [ 372. 1453. 2163.  548. 6413.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.474 | Acc: 32.875% | Wgt Acc: 35.852%
	I - Batch: 100 | Loss: 5.361 | Acc: 36.688% | Wgt Acc: 36.608%
	I - Batch: 150 | Loss: 5.254 | Acc: 44.042% | Wgt Acc: 39.135%
	I - Batch: 200 | Loss: 5.206 | Acc: 46.719% | Wgt Acc: 39.710%
I - num batch: 238
I - Val -- Loss: 5.196 | Acc: 47.963% | Wgt Acc: 40.516% | Dur: 117.03s
I - Confusion Matrix: [row->prediction - col->label]
[[224.   2.   8. 143.  17.]
 [  3. 354. 246.  16.  80.]
 [  0.  40.  38.   3.  25.]
 [182.  26.  50. 214.  91.]
 [117. 304. 436. 191. 995.]]

I - Local maximum validation set accuracy:  47.96

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 3.779 | Acc: 54.875% | Wgt Acc: 38.392%
	I - Batch: 100 | Loss: 3.793 | Acc: 52.000% | Wgt Acc: 35.612%
	I - Batch: 150 | Loss: 3.793 | Acc: 50.292% | Wgt Acc: 34.070%
	I - Batch: 200 | Loss: 3.779 | Acc: 50.219% | Wgt Acc: 34.657%
	I - Batch: 250 | Loss: 3.770 | Acc: 50.125% | Wgt Acc: 34.740%
	I - Batch: 300 | Loss: 3.771 | Acc: 49.958% | Wgt Acc: 34.579%
	I - Batch: 350 | Loss: 3.780 | Acc: 50.000% | Wgt Acc: 34.727%
	I - Batch: 400 | Loss: 3.784 | Acc: 50.172% | Wgt Acc: 34.962%
	I - Batch: 450 | Loss: 3.791 | Acc: 50.194% | Wgt Acc: 35.019%
	I - Batch: 500 | Loss: 3.792 | Acc: 50.100% | Wgt Acc: 34.912%
	I - Batch: 550 | Loss: 3.796 | Acc: 49.966% | Wgt Acc: 34.869%
	I - Batch: 600 | Loss: 3.801 | Acc: 49.958% | Wgt Acc: 34.812%
	I - Batch: 650 | Loss: 3.801 | Acc: 50.154% | Wgt Acc: 34.912%
	I - Batch: 700 | Loss: 3.803 | Acc: 50.420% | Wgt Acc: 35.151%
	I - Batch: 750 | Loss: 3.798 | Acc: 50.475% | Wgt Acc: 35.224%
	I - Batch: 800 | Loss: 3.789 | Acc: 50.492% | Wgt Acc: 35.298%
	I - Batch: 850 | Loss: 3.787 | Acc: 50.537% | Wgt Acc: 35.311%
	I - Batch: 900 | Loss: 3.784 | Acc: 50.799% | Wgt Acc: 35.516%
	I - Batch: 950 | Loss: 3.788 | Acc: 50.947% | Wgt Acc: 35.726%
	I - Batch: 1000 | Loss: 3.793 | Acc: 50.962% | Wgt Acc: 35.680%
I - num batch: 1003
I - Train -- Loss: 3.793 | Acc: 50.966% | Wgt Acc: 35.679% | LR: 1.250000e-04 | Dur: 637.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 149.    5.    8.  115.   44.]
 [   2.  151.  153.    3.   62.]
 [   3.  250.  261.    9.  117.]
 [1348.   80.  200. 1216. 1187.]
 [ 360. 1352. 2016.  551. 6398.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.488 | Acc: 23.750% | Wgt Acc: 25.720%
	I - Batch: 100 | Loss: 5.358 | Acc: 31.562% | Wgt Acc: 30.480%
	I - Batch: 150 | Loss: 5.247 | Acc: 38.750% | Wgt Acc: 33.389%
	I - Batch: 200 | Loss: 5.193 | Acc: 41.469% | Wgt Acc: 33.718%
I - num batch: 238
I - Val -- Loss: 5.185 | Acc: 43.417% | Wgt Acc: 35.237% | Dur: 116.51s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  3. 308. 270.  17.  80.]
 [  0.  30.  20.   2.  19.]
 [406.  28.  64. 374. 159.]
 [117. 360. 424. 174. 950.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 3.800 | Acc: 48.625% | Wgt Acc: 33.331%
	I - Batch: 100 | Loss: 3.775 | Acc: 49.938% | Wgt Acc: 35.044%
	I - Batch: 150 | Loss: 3.764 | Acc: 50.375% | Wgt Acc: 35.081%
	I - Batch: 200 | Loss: 3.756 | Acc: 50.125% | Wgt Acc: 35.239%
	I - Batch: 250 | Loss: 3.745 | Acc: 50.550% | Wgt Acc: 35.642%
	I - Batch: 300 | Loss: 3.743 | Acc: 51.000% | Wgt Acc: 36.209%
	I - Batch: 350 | Loss: 3.756 | Acc: 50.875% | Wgt Acc: 36.133%
	I - Batch: 400 | Loss: 3.742 | Acc: 51.141% | Wgt Acc: 36.450%
	I - Batch: 450 | Loss: 3.745 | Acc: 50.958% | Wgt Acc: 36.332%
	I - Batch: 500 | Loss: 3.748 | Acc: 51.138% | Wgt Acc: 36.625%
	I - Batch: 550 | Loss: 3.743 | Acc: 51.250% | Wgt Acc: 36.659%
	I - Batch: 600 | Loss: 3.749 | Acc: 51.250% | Wgt Acc: 36.536%
	I - Batch: 650 | Loss: 3.748 | Acc: 51.288% | Wgt Acc: 36.597%
	I - Batch: 700 | Loss: 3.745 | Acc: 51.339% | Wgt Acc: 36.674%
	I - Batch: 750 | Loss: 3.747 | Acc: 51.208% | Wgt Acc: 36.542%
	I - Batch: 800 | Loss: 3.743 | Acc: 51.180% | Wgt Acc: 36.421%
	I - Batch: 850 | Loss: 3.746 | Acc: 51.132% | Wgt Acc: 36.410%
	I - Batch: 900 | Loss: 3.743 | Acc: 51.194% | Wgt Acc: 36.435%
	I - Batch: 950 | Loss: 3.750 | Acc: 51.243% | Wgt Acc: 36.405%
	I - Batch: 1000 | Loss: 3.749 | Acc: 51.413% | Wgt Acc: 36.504%
I - num batch: 1003
I - Train -- Loss: 3.749 | Acc: 51.428% | Wgt Acc: 36.522% | LR: 1.250000e-04 | Dur: 635.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 228.    5.    4.  156.   55.]
 [   3.  169.  159.    3.   71.]
 [   1.  252.  270.    9.  127.]
 [1258.   76.  182. 1196. 1169.]
 [ 372. 1336. 2023.  530. 6386.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.481 | Acc: 33.375% | Wgt Acc: 36.591%
	I - Batch: 100 | Loss: 5.389 | Acc: 36.375% | Wgt Acc: 36.637%
	I - Batch: 150 | Loss: 5.296 | Acc: 43.375% | Wgt Acc: 39.763%
	I - Batch: 200 | Loss: 5.264 | Acc: 45.531% | Wgt Acc: 39.946%
I - num batch: 238
I - Val -- Loss: 5.273 | Acc: 46.465% | Wgt Acc: 40.741% | Dur: 114.60s
I - Confusion Matrix: [row->prediction - col->label]
[[321.  18.  26. 237.  47.]
 [  9. 362. 286.  23. 114.]
 [  2.  26.  30.   3.  29.]
 [110.  12.  44. 140. 103.]
 [ 84. 308. 392. 164. 915.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 3.715 | Acc: 51.875% | Wgt Acc: 36.830%
	I - Batch: 100 | Loss: 3.702 | Acc: 51.188% | Wgt Acc: 35.844%
	I - Batch: 150 | Loss: 3.711 | Acc: 51.875% | Wgt Acc: 36.395%
	I - Batch: 200 | Loss: 3.695 | Acc: 52.625% | Wgt Acc: 37.702%
	I - Batch: 250 | Loss: 3.679 | Acc: 52.850% | Wgt Acc: 37.999%
	I - Batch: 300 | Loss: 3.689 | Acc: 52.229% | Wgt Acc: 37.278%
	I - Batch: 350 | Loss: 3.678 | Acc: 52.875% | Wgt Acc: 37.842%
	I - Batch: 400 | Loss: 3.672 | Acc: 52.844% | Wgt Acc: 38.114%
	I - Batch: 450 | Loss: 3.667 | Acc: 52.764% | Wgt Acc: 38.163%
	I - Batch: 500 | Loss: 3.673 | Acc: 52.475% | Wgt Acc: 37.938%
	I - Batch: 550 | Loss: 3.669 | Acc: 52.398% | Wgt Acc: 37.797%
	I - Batch: 600 | Loss: 3.669 | Acc: 52.448% | Wgt Acc: 37.645%
	I - Batch: 650 | Loss: 3.673 | Acc: 52.231% | Wgt Acc: 37.363%
	I - Batch: 700 | Loss: 3.674 | Acc: 52.045% | Wgt Acc: 37.158%
	I - Batch: 750 | Loss: 3.675 | Acc: 52.017% | Wgt Acc: 37.187%
	I - Batch: 800 | Loss: 3.682 | Acc: 52.047% | Wgt Acc: 37.234%
	I - Batch: 850 | Loss: 3.691 | Acc: 51.956% | Wgt Acc: 37.095%
	I - Batch: 900 | Loss: 3.694 | Acc: 51.840% | Wgt Acc: 36.962%
	I - Batch: 950 | Loss: 3.690 | Acc: 51.868% | Wgt Acc: 36.993%
	I - Batch: 1000 | Loss: 3.686 | Acc: 51.944% | Wgt Acc: 37.128%
I - num batch: 1003
I - Train -- Loss: 3.686 | Acc: 51.914% | Wgt Acc: 37.102% | LR: 1.250000e-04 | Dur: 627.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 281.    1.   18.  229.   77.]
 [   2.  230.  205.    7.   88.]
 [   4.  227.  230.    7.  112.]
 [1235.   51.  148. 1148. 1093.]
 [ 340. 1329. 2037.  503. 6438.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.524 | Acc: 29.500% | Wgt Acc: 32.069%
	I - Batch: 100 | Loss: 5.423 | Acc: 33.938% | Wgt Acc: 33.504%
	I - Batch: 150 | Loss: 5.318 | Acc: 40.833% | Wgt Acc: 35.923%
	I - Batch: 200 | Loss: 5.253 | Acc: 43.781% | Wgt Acc: 36.827%
I - num batch: 238
I - Val -- Loss: 5.231 | Acc: 45.256% | Wgt Acc: 38.253% | Dur: 114.21s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  2. 320. 246.   7.  81.]
 [  0.  26.  24.   2.  21.]
 [444.  48. 114. 450. 178.]
 [ 80. 332. 394. 108. 928.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 3.676 | Acc: 53.000% | Wgt Acc: 37.535%
	I - Batch: 100 | Loss: 3.696 | Acc: 51.750% | Wgt Acc: 36.901%
	I - Batch: 150 | Loss: 3.705 | Acc: 52.167% | Wgt Acc: 37.780%
	I - Batch: 200 | Loss: 3.690 | Acc: 52.219% | Wgt Acc: 37.686%
	I - Batch: 250 | Loss: 3.677 | Acc: 52.675% | Wgt Acc: 38.019%
	I - Batch: 300 | Loss: 3.686 | Acc: 52.958% | Wgt Acc: 38.015%
	I - Batch: 350 | Loss: 3.675 | Acc: 52.393% | Wgt Acc: 37.390%
	I - Batch: 400 | Loss: 3.677 | Acc: 52.625% | Wgt Acc: 37.758%
	I - Batch: 450 | Loss: 3.680 | Acc: 52.625% | Wgt Acc: 37.781%
	I - Batch: 500 | Loss: 3.686 | Acc: 52.475% | Wgt Acc: 37.553%
	I - Batch: 550 | Loss: 3.668 | Acc: 52.489% | Wgt Acc: 37.611%
	I - Batch: 600 | Loss: 3.666 | Acc: 52.479% | Wgt Acc: 37.720%
	I - Batch: 650 | Loss: 3.667 | Acc: 52.548% | Wgt Acc: 37.923%
	I - Batch: 700 | Loss: 3.662 | Acc: 52.652% | Wgt Acc: 37.965%
	I - Batch: 750 | Loss: 3.657 | Acc: 52.825% | Wgt Acc: 38.195%
	I - Batch: 800 | Loss: 3.649 | Acc: 52.977% | Wgt Acc: 38.382%
	I - Batch: 850 | Loss: 3.649 | Acc: 52.897% | Wgt Acc: 38.365%
	I - Batch: 900 | Loss: 3.646 | Acc: 52.986% | Wgt Acc: 38.454%
	I - Batch: 950 | Loss: 3.644 | Acc: 53.000% | Wgt Acc: 38.497%
	I - Batch: 1000 | Loss: 3.645 | Acc: 52.850% | Wgt Acc: 38.385%
I - num batch: 1003
I - Train -- Loss: 3.646 | Acc: 52.837% | Wgt Acc: 38.379% | LR: 1.250000e-04 | Dur: 627.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 264.    4.    5.  178.   66.]
 [   5.  229.  210.    4.  105.]
 [   2.  351.  341.   11.  143.]
 [1258.   52.  136. 1216. 1069.]
 [ 333. 1202. 1946.  485. 6425.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.539 | Acc: 30.750% | Wgt Acc: 32.661%
	I - Batch: 100 | Loss: 5.392 | Acc: 35.125% | Wgt Acc: 33.961%
	I - Batch: 150 | Loss: 5.287 | Acc: 42.250% | Wgt Acc: 36.644%
	I - Batch: 200 | Loss: 5.247 | Acc: 46.062% | Wgt Acc: 38.652%
I - num batch: 238
I - Val -- Loss: 5.246 | Acc: 47.280% | Wgt Acc: 39.578% | Dur: 114.67s
I - Confusion Matrix: [row->prediction - col->label]
[[238.   8.  10. 143.  21.]
 [  3. 254. 224.   3.  51.]
 [  2.  64.  52.   0.  39.]
 [192.  22.  88. 275. 117.]
 [ 91. 378. 404. 146. 980.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 3.566 | Acc: 54.750% | Wgt Acc: 39.248%
	I - Batch: 100 | Loss: 3.570 | Acc: 55.188% | Wgt Acc: 39.824%
	I - Batch: 150 | Loss: 3.579 | Acc: 54.625% | Wgt Acc: 39.709%
	I - Batch: 200 | Loss: 3.567 | Acc: 54.375% | Wgt Acc: 39.457%
	I - Batch: 250 | Loss: 3.562 | Acc: 54.375% | Wgt Acc: 39.584%
	I - Batch: 300 | Loss: 3.563 | Acc: 54.292% | Wgt Acc: 39.528%
	I - Batch: 350 | Loss: 3.562 | Acc: 54.768% | Wgt Acc: 40.308%
	I - Batch: 400 | Loss: 3.572 | Acc: 54.641% | Wgt Acc: 40.154%
	I - Batch: 450 | Loss: 3.578 | Acc: 54.167% | Wgt Acc: 39.727%
	I - Batch: 500 | Loss: 3.563 | Acc: 54.225% | Wgt Acc: 40.093%
	I - Batch: 550 | Loss: 3.562 | Acc: 54.273% | Wgt Acc: 40.187%
	I - Batch: 600 | Loss: 3.556 | Acc: 53.917% | Wgt Acc: 39.860%
	I - Batch: 650 | Loss: 3.558 | Acc: 53.654% | Wgt Acc: 39.597%
	I - Batch: 700 | Loss: 3.556 | Acc: 53.705% | Wgt Acc: 39.707%
	I - Batch: 750 | Loss: 3.558 | Acc: 53.808% | Wgt Acc: 39.899%
	I - Batch: 800 | Loss: 3.556 | Acc: 53.953% | Wgt Acc: 40.035%
	I - Batch: 850 | Loss: 3.560 | Acc: 53.875% | Wgt Acc: 39.982%
	I - Batch: 900 | Loss: 3.560 | Acc: 53.854% | Wgt Acc: 40.011%
	I - Batch: 950 | Loss: 3.557 | Acc: 54.079% | Wgt Acc: 40.258%
	I - Batch: 1000 | Loss: 3.557 | Acc: 54.038% | Wgt Acc: 40.285%
I - num batch: 1003
I - Train -- Loss: 3.557 | Acc: 54.009% | Wgt Acc: 40.254% | LR: 1.250000e-04 | Dur: 634.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 426.    6.   11.  328.  104.]
 [   3.  303.  306.    4.  122.]
 [   6.  337.  366.    5.  174.]
 [1136.   36.  130. 1135.  975.]
 [ 291. 1156. 1825.  422. 6433.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.537 | Acc: 36.500% | Wgt Acc: 39.950%
	I - Batch: 100 | Loss: 5.430 | Acc: 37.438% | Wgt Acc: 38.306%
	I - Batch: 150 | Loss: 5.320 | Acc: 44.542% | Wgt Acc: 41.413%
	I - Batch: 200 | Loss: 5.269 | Acc: 47.500% | Wgt Acc: 42.652%
I - num batch: 238
I - Val -- Loss: 5.267 | Acc: 48.226% | Wgt Acc: 42.814% | Dur: 116.21s
I - Confusion Matrix: [row->prediction - col->label]
[[262.  12.  16. 161.  21.]
 [ 12. 388. 306.  20. 122.]
 [  2.  30.  36.   6.  36.]
 [142.  38.  48. 225. 105.]
 [108. 258. 372. 155. 924.]]

I - Local maximum validation set accuracy:  48.23

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 3.407 | Acc: 57.375% | Wgt Acc: 44.243%
	I - Batch: 100 | Loss: 3.474 | Acc: 54.438% | Wgt Acc: 40.640%
	I - Batch: 150 | Loss: 3.493 | Acc: 54.583% | Wgt Acc: 40.879%
	I - Batch: 200 | Loss: 3.521 | Acc: 54.594% | Wgt Acc: 41.007%
	I - Batch: 250 | Loss: 3.513 | Acc: 54.700% | Wgt Acc: 40.718%
	I - Batch: 300 | Loss: 3.505 | Acc: 54.500% | Wgt Acc: 40.608%
	I - Batch: 350 | Loss: 3.503 | Acc: 54.679% | Wgt Acc: 41.012%
	I - Batch: 400 | Loss: 3.506 | Acc: 54.672% | Wgt Acc: 40.743%
	I - Batch: 450 | Loss: 3.511 | Acc: 54.708% | Wgt Acc: 40.580%
	I - Batch: 500 | Loss: 3.505 | Acc: 54.913% | Wgt Acc: 40.679%
	I - Batch: 550 | Loss: 3.507 | Acc: 54.761% | Wgt Acc: 40.565%
	I - Batch: 600 | Loss: 3.513 | Acc: 55.010% | Wgt Acc: 41.056%
	I - Batch: 650 | Loss: 3.514 | Acc: 54.971% | Wgt Acc: 41.139%
	I - Batch: 700 | Loss: 3.518 | Acc: 54.830% | Wgt Acc: 40.961%
	I - Batch: 750 | Loss: 3.514 | Acc: 54.775% | Wgt Acc: 40.979%
	I - Batch: 800 | Loss: 3.515 | Acc: 54.711% | Wgt Acc: 40.870%
	I - Batch: 850 | Loss: 3.516 | Acc: 54.676% | Wgt Acc: 40.862%
	I - Batch: 900 | Loss: 3.516 | Acc: 54.625% | Wgt Acc: 40.884%
	I - Batch: 950 | Loss: 3.515 | Acc: 54.684% | Wgt Acc: 41.001%
	I - Batch: 1000 | Loss: 3.517 | Acc: 54.631% | Wgt Acc: 40.987%
I - num batch: 1003
I - Train -- Loss: 3.517 | Acc: 54.632% | Wgt Acc: 40.992% | LR: 1.250000e-04 | Dur: 635.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 385.    5.   14.  270.   90.]
 [   2.  336.  349.    4.  134.]
 [   6.  415.  393.   10.  167.]
 [1165.   40.  108. 1188.  956.]
 [ 304. 1042. 1774.  422. 6461.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.653 | Acc: 32.375% | Wgt Acc: 35.515%
	I - Batch: 100 | Loss: 5.497 | Acc: 36.062% | Wgt Acc: 35.146%
	I - Batch: 150 | Loss: 5.362 | Acc: 43.917% | Wgt Acc: 38.725%
	I - Batch: 200 | Loss: 5.299 | Acc: 47.344% | Wgt Acc: 40.353%
I - num batch: 238
I - Val -- Loss: 5.292 | Acc: 49.014% | Wgt Acc: 41.623% | Dur: 116.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 230.    4.   14.  134.   16.]
 [   6.  386.  284.   21.   92.]
 [   1.   16.   16.    5.   13.]
 [ 149.   28.   60.  214.   68.]
 [ 140.  292.  404.  193. 1019.]]

I - Local maximum validation set accuracy:  49.01

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 3.504 | Acc: 51.750% | Wgt Acc: 38.925%
	I - Batch: 100 | Loss: 3.447 | Acc: 54.750% | Wgt Acc: 41.729%
	I - Batch: 150 | Loss: 3.439 | Acc: 56.042% | Wgt Acc: 42.940%
	I - Batch: 200 | Loss: 3.446 | Acc: 56.094% | Wgt Acc: 43.048%
	I - Batch: 250 | Loss: 3.443 | Acc: 55.500% | Wgt Acc: 41.686%
	I - Batch: 300 | Loss: 3.450 | Acc: 55.354% | Wgt Acc: 41.263%
	I - Batch: 350 | Loss: 3.456 | Acc: 55.571% | Wgt Acc: 41.603%
	I - Batch: 400 | Loss: 3.459 | Acc: 55.562% | Wgt Acc: 41.613%
	I - Batch: 450 | Loss: 3.466 | Acc: 55.667% | Wgt Acc: 41.507%
	I - Batch: 500 | Loss: 3.467 | Acc: 55.263% | Wgt Acc: 40.912%
	I - Batch: 550 | Loss: 3.460 | Acc: 55.318% | Wgt Acc: 41.207%
	I - Batch: 600 | Loss: 3.449 | Acc: 55.385% | Wgt Acc: 41.560%
	I - Batch: 650 | Loss: 3.447 | Acc: 55.394% | Wgt Acc: 41.640%
	I - Batch: 700 | Loss: 3.443 | Acc: 55.339% | Wgt Acc: 41.688%
	I - Batch: 750 | Loss: 3.447 | Acc: 55.383% | Wgt Acc: 41.785%
	I - Batch: 800 | Loss: 3.448 | Acc: 55.469% | Wgt Acc: 41.873%
	I - Batch: 850 | Loss: 3.456 | Acc: 55.272% | Wgt Acc: 41.717%
	I - Batch: 900 | Loss: 3.459 | Acc: 55.361% | Wgt Acc: 41.809%
	I - Batch: 950 | Loss: 3.456 | Acc: 55.250% | Wgt Acc: 41.675%
	I - Batch: 1000 | Loss: 3.460 | Acc: 55.231% | Wgt Acc: 41.736%
I - num batch: 1003
I - Train -- Loss: 3.461 | Acc: 55.212% | Wgt Acc: 41.725% | LR: 1.250000e-04 | Dur: 628.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 373.    1.   11.  248.   77.]
 [   4.  407.  418.    3.  168.]
 [   3.  361.  341.    8.  147.]
 [1207.   33.  113. 1221.  902.]
 [ 275. 1036. 1755.  414. 6514.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.733 | Acc: 25.250% | Wgt Acc: 26.786%
	I - Batch: 100 | Loss: 5.552 | Acc: 31.938% | Wgt Acc: 30.053%
	I - Batch: 150 | Loss: 5.421 | Acc: 39.375% | Wgt Acc: 33.525%
	I - Batch: 200 | Loss: 5.350 | Acc: 42.406% | Wgt Acc: 35.086%
I - num batch: 238
I - Val -- Loss: 5.337 | Acc: 43.784% | Wgt Acc: 35.944% | Dur: 113.91s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  1. 262. 248.   1.  86.]
 [  1.  46.  54.   1.  25.]
 [430.  82. 118. 426. 173.]
 [ 94. 336. 358. 139. 924.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 3.440 | Acc: 56.625% | Wgt Acc: 43.760%
	I - Batch: 100 | Loss: 3.399 | Acc: 56.562% | Wgt Acc: 43.481%
	I - Batch: 150 | Loss: 3.410 | Acc: 56.125% | Wgt Acc: 42.861%
	I - Batch: 200 | Loss: 3.411 | Acc: 55.344% | Wgt Acc: 42.206%
	I - Batch: 250 | Loss: 3.425 | Acc: 55.225% | Wgt Acc: 42.201%
	I - Batch: 300 | Loss: 3.427 | Acc: 55.188% | Wgt Acc: 42.003%
	I - Batch: 350 | Loss: 3.408 | Acc: 55.321% | Wgt Acc: 42.222%
	I - Batch: 400 | Loss: 3.403 | Acc: 55.578% | Wgt Acc: 42.656%
	I - Batch: 450 | Loss: 3.406 | Acc: 55.278% | Wgt Acc: 42.480%
	I - Batch: 500 | Loss: 3.407 | Acc: 55.138% | Wgt Acc: 42.416%
	I - Batch: 550 | Loss: 3.404 | Acc: 55.761% | Wgt Acc: 43.113%
	I - Batch: 600 | Loss: 3.408 | Acc: 55.823% | Wgt Acc: 43.157%
	I - Batch: 650 | Loss: 3.403 | Acc: 55.769% | Wgt Acc: 43.129%
	I - Batch: 700 | Loss: 3.402 | Acc: 55.929% | Wgt Acc: 43.350%
	I - Batch: 750 | Loss: 3.405 | Acc: 56.208% | Wgt Acc: 43.662%
	I - Batch: 800 | Loss: 3.406 | Acc: 56.141% | Wgt Acc: 43.638%
	I - Batch: 850 | Loss: 3.403 | Acc: 56.044% | Wgt Acc: 43.565%
	I - Batch: 900 | Loss: 3.408 | Acc: 55.861% | Wgt Acc: 43.401%
	I - Batch: 950 | Loss: 3.413 | Acc: 55.829% | Wgt Acc: 43.348%
	I - Batch: 1000 | Loss: 3.410 | Acc: 56.019% | Wgt Acc: 43.552%
I - num batch: 1003
I - Train -- Loss: 3.410 | Acc: 56.041% | Wgt Acc: 43.569% | LR: 1.250000e-04 | Dur: 625.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 362.    4.   12.  305.   97.]
 [   4.  472.  488.    7.  183.]
 [   7.  597.  594.   10.  239.]
 [1229.   25.   95. 1204.  932.]
 [ 260.  740. 1449.  368. 6357.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.630 | Acc: 31.625% | Wgt Acc: 34.362%
	I - Batch: 100 | Loss: 5.496 | Acc: 35.062% | Wgt Acc: 34.931%
	I - Batch: 150 | Loss: 5.383 | Acc: 41.125% | Wgt Acc: 37.164%
	I - Batch: 200 | Loss: 5.327 | Acc: 44.625% | Wgt Acc: 39.237%
I - num batch: 238
I - Val -- Loss: 5.333 | Acc: 45.335% | Wgt Acc: 39.579% | Dur: 114.16s
I - Confusion Matrix: [row->prediction - col->label]
[[352.  24.  58. 289.  57.]
 [  2. 286. 262.  11.  62.]
 [  0.  20.  32.   0.  21.]
 [109.  86. 104. 162. 175.]
 [ 63. 310. 322. 105. 893.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 3.382 | Acc: 55.625% | Wgt Acc: 42.122%
	I - Batch: 100 | Loss: 3.333 | Acc: 57.438% | Wgt Acc: 45.312%
	I - Batch: 150 | Loss: 3.323 | Acc: 57.375% | Wgt Acc: 45.676%
	I - Batch: 200 | Loss: 3.335 | Acc: 56.719% | Wgt Acc: 44.919%
	I - Batch: 250 | Loss: 3.335 | Acc: 57.100% | Wgt Acc: 45.324%
	I - Batch: 300 | Loss: 3.336 | Acc: 57.562% | Wgt Acc: 46.153%
	I - Batch: 350 | Loss: 3.332 | Acc: 57.821% | Wgt Acc: 46.247%
	I - Batch: 400 | Loss: 3.335 | Acc: 58.031% | Wgt Acc: 46.274%
	I - Batch: 450 | Loss: 3.340 | Acc: 57.986% | Wgt Acc: 45.934%
	I - Batch: 500 | Loss: 3.341 | Acc: 58.225% | Wgt Acc: 46.070%
	I - Batch: 550 | Loss: 3.344 | Acc: 57.966% | Wgt Acc: 45.712%
	I - Batch: 600 | Loss: 3.348 | Acc: 58.135% | Wgt Acc: 45.860%
	I - Batch: 650 | Loss: 3.354 | Acc: 58.000% | Wgt Acc: 45.602%
	I - Batch: 700 | Loss: 3.351 | Acc: 57.938% | Wgt Acc: 45.541%
	I - Batch: 750 | Loss: 3.353 | Acc: 58.092% | Wgt Acc: 45.772%
	I - Batch: 800 | Loss: 3.349 | Acc: 58.188% | Wgt Acc: 45.793%
	I - Batch: 850 | Loss: 3.353 | Acc: 58.096% | Wgt Acc: 45.740%
	I - Batch: 900 | Loss: 3.356 | Acc: 58.069% | Wgt Acc: 45.816%
	I - Batch: 950 | Loss: 3.354 | Acc: 57.987% | Wgt Acc: 45.783%
	I - Batch: 1000 | Loss: 3.361 | Acc: 57.869% | Wgt Acc: 45.651%
I - num batch: 1003
I - Train -- Loss: 3.361 | Acc: 57.843% | Wgt Acc: 45.617% | LR: 1.250000e-04 | Dur: 626.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 489.    5.   16.  362.  129.]
 [   4.  520.  473.    7.  142.]
 [   5.  604.  644.    9.  265.]
 [1108.   24.   74. 1156.  803.]
 [ 256.  685. 1431.  360. 6469.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.665 | Acc: 30.250% | Wgt Acc: 32.188%
	I - Batch: 100 | Loss: 5.571 | Acc: 31.875% | Wgt Acc: 31.656%
	I - Batch: 150 | Loss: 5.470 | Acc: 38.667% | Wgt Acc: 34.522%
	I - Batch: 200 | Loss: 5.424 | Acc: 41.812% | Wgt Acc: 36.500%
I - num batch: 238
I - Val -- Loss: 5.414 | Acc: 42.286% | Wgt Acc: 36.614% | Dur: 114.07s
I - Confusion Matrix: [row->prediction - col->label]
[[434.  68. 122. 430. 160.]
 [  0. 192. 150.   5.  28.]
 [  2.  72.  88.   0.  31.]
 [ 42.  64.  66.  73. 167.]
 [ 48. 330. 352.  59. 822.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 3.283 | Acc: 61.875% | Wgt Acc: 51.978%
	I - Batch: 100 | Loss: 3.328 | Acc: 59.625% | Wgt Acc: 48.818%
	I - Batch: 150 | Loss: 3.320 | Acc: 58.417% | Wgt Acc: 47.007%
	I - Batch: 200 | Loss: 3.314 | Acc: 58.719% | Wgt Acc: 47.320%
	I - Batch: 250 | Loss: 3.345 | Acc: 58.375% | Wgt Acc: 47.022%
	I - Batch: 300 | Loss: 3.354 | Acc: 58.438% | Wgt Acc: 46.558%
	I - Batch: 350 | Loss: 3.355 | Acc: 58.625% | Wgt Acc: 46.697%
	I - Batch: 400 | Loss: 3.362 | Acc: 58.094% | Wgt Acc: 45.905%
	I - Batch: 450 | Loss: 3.364 | Acc: 58.000% | Wgt Acc: 45.844%
	I - Batch: 500 | Loss: 3.358 | Acc: 58.150% | Wgt Acc: 45.988%
	I - Batch: 550 | Loss: 3.351 | Acc: 58.080% | Wgt Acc: 46.004%
	I - Batch: 600 | Loss: 3.350 | Acc: 58.271% | Wgt Acc: 46.215%
	I - Batch: 650 | Loss: 3.357 | Acc: 58.135% | Wgt Acc: 46.119%
	I - Batch: 700 | Loss: 3.352 | Acc: 58.250% | Wgt Acc: 46.213%
	I - Batch: 750 | Loss: 3.340 | Acc: 58.342% | Wgt Acc: 46.318%
	I - Batch: 800 | Loss: 3.340 | Acc: 58.430% | Wgt Acc: 46.355%
	I - Batch: 850 | Loss: 3.337 | Acc: 58.559% | Wgt Acc: 46.419%
	I - Batch: 900 | Loss: 3.337 | Acc: 58.389% | Wgt Acc: 46.188%
	I - Batch: 950 | Loss: 3.331 | Acc: 58.322% | Wgt Acc: 46.145%
	I - Batch: 1000 | Loss: 3.330 | Acc: 58.163% | Wgt Acc: 46.028%
I - num batch: 1003
I - Train -- Loss: 3.330 | Acc: 58.167% | Wgt Acc: 46.032% | LR: 1.250000e-04 | Dur: 627.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 491.    3.   12.  358.  116.]
 [   1.  541.  541.    6.  181.]
 [   5.  607.  630.   14.  256.]
 [1092.   19.   73. 1177.  764.]
 [ 273.  668. 1382.  339. 6491.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.722 | Acc: 27.250% | Wgt Acc: 26.557%
	I - Batch: 100 | Loss: 5.541 | Acc: 34.062% | Wgt Acc: 29.767%
	I - Batch: 150 | Loss: 5.407 | Acc: 42.458% | Wgt Acc: 33.896%
	I - Batch: 200 | Loss: 5.339 | Acc: 45.969% | Wgt Acc: 35.852%
I - num batch: 238
I - Val -- Loss: 5.352 | Acc: 47.148% | Wgt Acc: 36.460% | Dur: 113.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 321.   12.   24.  179.   29.]
 [   0.    0.    0.    0.    0.]
 [   2.  280.  230.    4.   40.]
 [ 128.   46.   72.  233.  129.]
 [  75.  388.  452.  151. 1010.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 3.229 | Acc: 57.375% | Wgt Acc: 46.720%
	I - Batch: 100 | Loss: 3.217 | Acc: 59.312% | Wgt Acc: 48.369%
	I - Batch: 150 | Loss: 3.245 | Acc: 59.292% | Wgt Acc: 47.986%
	I - Batch: 200 | Loss: 3.283 | Acc: 57.781% | Wgt Acc: 46.209%
	I - Batch: 250 | Loss: 3.288 | Acc: 58.475% | Wgt Acc: 47.258%
	I - Batch: 300 | Loss: 3.282 | Acc: 57.854% | Wgt Acc: 46.349%
	I - Batch: 350 | Loss: 3.290 | Acc: 58.071% | Wgt Acc: 46.804%
	I - Batch: 400 | Loss: 3.304 | Acc: 57.359% | Wgt Acc: 45.940%
	I - Batch: 450 | Loss: 3.302 | Acc: 57.569% | Wgt Acc: 46.188%
	I - Batch: 500 | Loss: 3.297 | Acc: 57.812% | Wgt Acc: 46.324%
	I - Batch: 550 | Loss: 3.289 | Acc: 58.125% | Wgt Acc: 46.638%
	I - Batch: 600 | Loss: 3.286 | Acc: 58.354% | Wgt Acc: 46.720%
	I - Batch: 650 | Loss: 3.286 | Acc: 58.471% | Wgt Acc: 46.995%
	I - Batch: 700 | Loss: 3.281 | Acc: 58.482% | Wgt Acc: 46.993%
	I - Batch: 750 | Loss: 3.275 | Acc: 58.792% | Wgt Acc: 47.354%
	I - Batch: 800 | Loss: 3.273 | Acc: 58.633% | Wgt Acc: 47.200%
	I - Batch: 850 | Loss: 3.280 | Acc: 58.529% | Wgt Acc: 47.129%
	I - Batch: 900 | Loss: 3.282 | Acc: 58.576% | Wgt Acc: 47.175%
	I - Batch: 950 | Loss: 3.283 | Acc: 58.539% | Wgt Acc: 47.111%
	I - Batch: 1000 | Loss: 3.284 | Acc: 58.725% | Wgt Acc: 47.462%
I - num batch: 1003
I - Train -- Loss: 3.283 | Acc: 58.747% | Wgt Acc: 47.487% | LR: 1.250000e-04 | Dur: 627.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 512.    3.   14.  324.  104.]
 [   3.  654.  689.    1.  243.]
 [   3.  535.  595.    8.  258.]
 [1109.   24.   76. 1220.  761.]
 [ 235.  622. 1264.  341. 6442.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.851 | Acc: 22.375% | Wgt Acc: 24.155%
	I - Batch: 100 | Loss: 5.613 | Acc: 31.625% | Wgt Acc: 29.048%
	I - Batch: 150 | Loss: 5.457 | Acc: 39.667% | Wgt Acc: 32.074%
	I - Batch: 200 | Loss: 5.377 | Acc: 43.656% | Wgt Acc: 34.016%
I - num batch: 238
I - Val -- Loss: 5.368 | Acc: 45.572% | Wgt Acc: 35.452% | Dur: 114.10s
I - Confusion Matrix: [row->prediction - col->label]
[[   0.    0.    0.    0.    0.]
 [   2.  272.  222.    2.   47.]
 [   0.   30.   14.    0.    6.]
 [ 394.   44.   82.  393.  100.]
 [ 130.  380.  460.  172. 1055.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 3.154 | Acc: 60.500% | Wgt Acc: 47.194%
	I - Batch: 100 | Loss: 3.170 | Acc: 60.438% | Wgt Acc: 47.799%
	I - Batch: 150 | Loss: 3.196 | Acc: 59.708% | Wgt Acc: 47.494%
	I - Batch: 200 | Loss: 3.202 | Acc: 59.250% | Wgt Acc: 46.839%
	I - Batch: 250 | Loss: 3.199 | Acc: 59.475% | Wgt Acc: 47.312%
	I - Batch: 300 | Loss: 3.203 | Acc: 59.500% | Wgt Acc: 47.539%
	I - Batch: 350 | Loss: 3.227 | Acc: 58.804% | Wgt Acc: 46.709%
	I - Batch: 400 | Loss: 3.235 | Acc: 58.734% | Wgt Acc: 46.938%
	I - Batch: 450 | Loss: 3.242 | Acc: 58.847% | Wgt Acc: 47.208%
	I - Batch: 500 | Loss: 3.242 | Acc: 58.737% | Wgt Acc: 47.008%
	I - Batch: 550 | Loss: 3.250 | Acc: 58.739% | Wgt Acc: 46.995%
	I - Batch: 600 | Loss: 3.254 | Acc: 58.667% | Wgt Acc: 47.024%
	I - Batch: 650 | Loss: 3.256 | Acc: 58.519% | Wgt Acc: 46.939%
	I - Batch: 700 | Loss: 3.251 | Acc: 58.598% | Wgt Acc: 46.981%
	I - Batch: 750 | Loss: 3.245 | Acc: 58.683% | Wgt Acc: 47.068%
	I - Batch: 800 | Loss: 3.248 | Acc: 58.438% | Wgt Acc: 46.861%
	I - Batch: 850 | Loss: 3.246 | Acc: 58.544% | Wgt Acc: 47.003%
	I - Batch: 900 | Loss: 3.247 | Acc: 58.479% | Wgt Acc: 47.022%
	I - Batch: 950 | Loss: 3.241 | Acc: 58.632% | Wgt Acc: 47.148%
	I - Batch: 1000 | Loss: 3.240 | Acc: 58.594% | Wgt Acc: 47.088%
I - num batch: 1003
I - Train -- Loss: 3.239 | Acc: 58.603% | Wgt Acc: 47.100% | LR: 1.250000e-04 | Dur: 630.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 382.    0.    7.  202.   57.]
 [   2.  621.  765.   12.  269.]
 [   2.  552.  564.    7.  198.]
 [1239.   11.   70. 1369.  820.]
 [ 237.  654. 1232.  304. 6464.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.943 | Acc: 30.125% | Wgt Acc: 32.444%
	I - Batch: 100 | Loss: 5.736 | Acc: 35.500% | Wgt Acc: 34.212%
	I - Batch: 150 | Loss: 5.557 | Acc: 42.875% | Wgt Acc: 36.750%
	I - Batch: 200 | Loss: 5.460 | Acc: 46.656% | Wgt Acc: 38.980%
I - num batch: 238
I - Val -- Loss: 5.449 | Acc: 48.279% | Wgt Acc: 40.150% | Dur: 114.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 329.    8.   14.  168.   26.]
 [   1.  188.  136.    1.   35.]
 [   0.   36.   50.    0.    7.]
 [ 112.   50.   92.  261.  131.]
 [  84.  444.  486.  137. 1009.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 3.224 | Acc: 55.375% | Wgt Acc: 42.979%
	I - Batch: 100 | Loss: 3.176 | Acc: 57.438% | Wgt Acc: 45.389%
	I - Batch: 150 | Loss: 3.225 | Acc: 58.250% | Wgt Acc: 46.391%
	I - Batch: 200 | Loss: 3.241 | Acc: 58.062% | Wgt Acc: 46.189%
	I - Batch: 250 | Loss: 3.226 | Acc: 58.475% | Wgt Acc: 46.643%
	I - Batch: 300 | Loss: 3.221 | Acc: 58.938% | Wgt Acc: 47.440%
	I - Batch: 350 | Loss: 3.217 | Acc: 59.018% | Wgt Acc: 47.591%
	I - Batch: 400 | Loss: 3.215 | Acc: 58.703% | Wgt Acc: 47.413%
	I - Batch: 450 | Loss: 3.208 | Acc: 59.139% | Wgt Acc: 47.764%
	I - Batch: 500 | Loss: 3.211 | Acc: 58.987% | Wgt Acc: 47.784%
	I - Batch: 550 | Loss: 3.217 | Acc: 58.875% | Wgt Acc: 47.566%
	I - Batch: 600 | Loss: 3.218 | Acc: 58.750% | Wgt Acc: 47.493%
	I - Batch: 650 | Loss: 3.218 | Acc: 58.933% | Wgt Acc: 47.720%
	I - Batch: 700 | Loss: 3.216 | Acc: 59.170% | Wgt Acc: 47.982%
	I - Batch: 750 | Loss: 3.217 | Acc: 59.217% | Wgt Acc: 48.026%
	I - Batch: 800 | Loss: 3.220 | Acc: 59.180% | Wgt Acc: 48.069%
	I - Batch: 850 | Loss: 3.222 | Acc: 59.162% | Wgt Acc: 48.000%
	I - Batch: 900 | Loss: 3.225 | Acc: 59.056% | Wgt Acc: 47.898%
	I - Batch: 950 | Loss: 3.224 | Acc: 58.849% | Wgt Acc: 47.695%
	I - Batch: 1000 | Loss: 3.225 | Acc: 58.862% | Wgt Acc: 47.694%
I - num batch: 1003
I - Train -- Loss: 3.224 | Acc: 58.872% | Wgt Acc: 47.703% | LR: 1.250000e-04 | Dur: 632.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 394.    2.    7.  215.   73.]
 [   4.  666.  741.    7.  262.]
 [   1.  517.  564.    3.  213.]
 [1223.   17.   65. 1374.  815.]
 [ 240.  636. 1261.  295. 6445.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.594 | Acc: 38.625% | Wgt Acc: 42.124%
	I - Batch: 100 | Loss: 5.480 | Acc: 41.938% | Wgt Acc: 42.945%
	I - Batch: 150 | Loss: 5.385 | Acc: 47.583% | Wgt Acc: 45.816%
	I - Batch: 200 | Loss: 5.339 | Acc: 49.906% | Wgt Acc: 47.076%
I - num batch: 238
I - Val -- Loss: 5.338 | Acc: 50.723% | Wgt Acc: 47.743% | Dur: 114.93s
I - Confusion Matrix: [row->prediction - col->label]
[[265.   2.  18.  84.  32.]
 [  1. 404. 344.  16. 110.]
 [  0.   8.  24.   0.  13.]
 [179.  70. 104. 370. 186.]
 [ 81. 242. 288.  97. 867.]]

I - Local maximum validation set accuracy:  50.72

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 3.157 | Acc: 64.125% | Wgt Acc: 52.695%
	I - Batch: 100 | Loss: 3.174 | Acc: 62.250% | Wgt Acc: 50.813%
	I - Batch: 150 | Loss: 3.164 | Acc: 60.625% | Wgt Acc: 48.782%
	I - Batch: 200 | Loss: 3.156 | Acc: 60.719% | Wgt Acc: 49.909%
	I - Batch: 250 | Loss: 3.150 | Acc: 61.150% | Wgt Acc: 50.257%
	I - Batch: 300 | Loss: 3.151 | Acc: 61.083% | Wgt Acc: 50.135%
	I - Batch: 350 | Loss: 3.148 | Acc: 60.893% | Wgt Acc: 49.830%
	I - Batch: 400 | Loss: 3.141 | Acc: 60.859% | Wgt Acc: 49.827%
	I - Batch: 450 | Loss: 3.138 | Acc: 61.264% | Wgt Acc: 49.973%
	I - Batch: 500 | Loss: 3.134 | Acc: 61.212% | Wgt Acc: 49.842%
	I - Batch: 550 | Loss: 3.133 | Acc: 60.989% | Wgt Acc: 49.621%
	I - Batch: 600 | Loss: 3.143 | Acc: 60.771% | Wgt Acc: 49.500%
	I - Batch: 650 | Loss: 3.150 | Acc: 60.510% | Wgt Acc: 49.242%
	I - Batch: 700 | Loss: 3.149 | Acc: 60.607% | Wgt Acc: 49.443%
	I - Batch: 750 | Loss: 3.150 | Acc: 60.542% | Wgt Acc: 49.380%
	I - Batch: 800 | Loss: 3.149 | Acc: 60.539% | Wgt Acc: 49.370%
	I - Batch: 850 | Loss: 3.154 | Acc: 60.610% | Wgt Acc: 49.575%
	I - Batch: 900 | Loss: 3.157 | Acc: 60.444% | Wgt Acc: 49.484%
	I - Batch: 950 | Loss: 3.151 | Acc: 60.612% | Wgt Acc: 49.664%
	I - Batch: 1000 | Loss: 3.144 | Acc: 60.675% | Wgt Acc: 49.664%
I - num batch: 1003
I - Train -- Loss: 3.143 | Acc: 60.698% | Wgt Acc: 49.683% | LR: 1.250000e-04 | Dur: 632.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 323.    0.    7.  118.   38.]
 [   3.  760.  816.    4.  254.]
 [   3.  531.  600.    8.  182.]
 [1297.   13.   65. 1482.  763.]
 [ 236.  534. 1150.  282. 6571.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.656 | Acc: 35.375% | Wgt Acc: 38.135%
	I - Batch: 100 | Loss: 5.509 | Acc: 39.062% | Wgt Acc: 38.692%
	I - Batch: 150 | Loss: 5.410 | Acc: 46.125% | Wgt Acc: 42.288%
	I - Batch: 200 | Loss: 5.343 | Acc: 49.312% | Wgt Acc: 44.232%
I - num batch: 238
I - Val -- Loss: 5.348 | Acc: 50.197% | Wgt Acc: 45.039% | Dur: 115.45s
I - Confusion Matrix: [row->prediction - col->label]
[[268.   0.  12.  70.  15.]
 [  1. 282. 274.  10.  48.]
 [  1.  30.  18.   4.  15.]
 [190. 106. 138. 407. 195.]
 [ 66. 308. 336.  76. 935.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 3.021 | Acc: 64.000% | Wgt Acc: 53.860%
	I - Batch: 100 | Loss: 3.041 | Acc: 62.938% | Wgt Acc: 52.526%
	I - Batch: 150 | Loss: 3.052 | Acc: 61.875% | Wgt Acc: 51.085%
	I - Batch: 200 | Loss: 3.037 | Acc: 62.188% | Wgt Acc: 51.440%
	I - Batch: 250 | Loss: 3.043 | Acc: 62.075% | Wgt Acc: 51.157%
	I - Batch: 300 | Loss: 3.080 | Acc: 61.667% | Wgt Acc: 50.451%
	I - Batch: 350 | Loss: 3.086 | Acc: 61.518% | Wgt Acc: 50.271%
	I - Batch: 400 | Loss: 3.091 | Acc: 61.359% | Wgt Acc: 50.194%
	I - Batch: 450 | Loss: 3.083 | Acc: 61.417% | Wgt Acc: 50.350%
	I - Batch: 500 | Loss: 3.076 | Acc: 61.538% | Wgt Acc: 50.600%
	I - Batch: 550 | Loss: 3.067 | Acc: 61.966% | Wgt Acc: 50.967%
	I - Batch: 600 | Loss: 3.061 | Acc: 61.938% | Wgt Acc: 50.929%
	I - Batch: 650 | Loss: 3.062 | Acc: 61.567% | Wgt Acc: 50.544%
	I - Batch: 700 | Loss: 3.060 | Acc: 61.500% | Wgt Acc: 50.668%
	I - Batch: 750 | Loss: 3.053 | Acc: 61.558% | Wgt Acc: 50.784%
	I - Batch: 800 | Loss: 3.056 | Acc: 61.398% | Wgt Acc: 50.582%
	I - Batch: 850 | Loss: 3.052 | Acc: 61.478% | Wgt Acc: 50.812%
	I - Batch: 900 | Loss: 3.054 | Acc: 61.333% | Wgt Acc: 50.614%
	I - Batch: 950 | Loss: 3.051 | Acc: 61.316% | Wgt Acc: 50.559%
	I - Batch: 1000 | Loss: 3.055 | Acc: 61.219% | Wgt Acc: 50.518%
I - num batch: 1003
I - Train -- Loss: 3.054 | Acc: 61.234% | Wgt Acc: 50.540% | LR: 1.250000e-04 | Dur: 632.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 311.    0.    3.   98.   29.]
 [   2.  813.  809.    9.  189.]
 [   2.  507.  563.    7.  163.]
 [1340.   21.   70. 1546.  838.]
 [ 207.  497. 1193.  234. 6589.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.306 | Acc: 44.750% | Wgt Acc: 48.853%
	I - Batch: 100 | Loss: 5.283 | Acc: 43.625% | Wgt Acc: 46.370%
	I - Batch: 150 | Loss: 5.255 | Acc: 47.125% | Wgt Acc: 47.797%
	I - Batch: 200 | Loss: 5.273 | Acc: 48.125% | Wgt Acc: 47.584%
I - num batch: 238
I - Val -- Loss: 5.285 | Acc: 48.857% | Wgt Acc: 48.354% | Dur: 115.39s
I - Confusion Matrix: [row->prediction - col->label]
[[176.   0.   6.  33.   6.]
 [ 11. 502. 456.  29. 230.]
 [  1.  10.  20.   2.  36.]
 [267.  58. 130. 411. 186.]
 [ 71. 156. 166.  92. 750.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 3.020 | Acc: 60.500% | Wgt Acc: 49.360%
	I - Batch: 100 | Loss: 3.017 | Acc: 60.625% | Wgt Acc: 49.990%
	I - Batch: 150 | Loss: 3.006 | Acc: 61.375% | Wgt Acc: 50.849%
	I - Batch: 200 | Loss: 2.991 | Acc: 61.531% | Wgt Acc: 50.560%
	I - Batch: 250 | Loss: 2.981 | Acc: 62.375% | Wgt Acc: 51.518%
	I - Batch: 300 | Loss: 2.956 | Acc: 62.729% | Wgt Acc: 51.996%
	I - Batch: 350 | Loss: 2.958 | Acc: 63.036% | Wgt Acc: 52.522%
	I - Batch: 400 | Loss: 2.956 | Acc: 63.188% | Wgt Acc: 52.741%
	I - Batch: 450 | Loss: 2.962 | Acc: 62.875% | Wgt Acc: 52.505%
	I - Batch: 500 | Loss: 2.970 | Acc: 62.575% | Wgt Acc: 52.244%
	I - Batch: 550 | Loss: 2.974 | Acc: 62.477% | Wgt Acc: 52.235%
	I - Batch: 600 | Loss: 2.979 | Acc: 62.458% | Wgt Acc: 52.212%
	I - Batch: 650 | Loss: 2.977 | Acc: 62.577% | Wgt Acc: 52.348%
	I - Batch: 700 | Loss: 2.977 | Acc: 62.634% | Wgt Acc: 52.387%
	I - Batch: 750 | Loss: 2.973 | Acc: 62.617% | Wgt Acc: 52.241%
	I - Batch: 800 | Loss: 2.975 | Acc: 62.516% | Wgt Acc: 52.080%
	I - Batch: 850 | Loss: 2.973 | Acc: 62.721% | Wgt Acc: 52.235%
	I - Batch: 900 | Loss: 2.975 | Acc: 62.778% | Wgt Acc: 52.278%
	I - Batch: 950 | Loss: 2.974 | Acc: 62.789% | Wgt Acc: 52.304%
	I - Batch: 1000 | Loss: 2.977 | Acc: 62.894% | Wgt Acc: 52.389%
I - num batch: 1003
I - Train -- Loss: 2.978 | Acc: 62.899% | Wgt Acc: 52.394% | LR: 1.250000e-04 | Dur: 625.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 340.    1.    1.   60.   35.]
 [   1.  785.  851.    9.  185.]
 [   2.  617.  706.    5.  184.]
 [1343.   13.   57. 1608.  754.]
 [ 176.  422. 1023.  212. 6650.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.788 | Acc: 31.375% | Wgt Acc: 33.243%
	I - Batch: 100 | Loss: 5.652 | Acc: 35.000% | Wgt Acc: 32.476%
	I - Batch: 150 | Loss: 5.498 | Acc: 42.708% | Wgt Acc: 35.306%
	I - Batch: 200 | Loss: 5.422 | Acc: 46.562% | Wgt Acc: 37.202%
I - num batch: 238
I - Val -- Loss: 5.427 | Acc: 47.832% | Wgt Acc: 37.871% | Dur: 114.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 229.    6.   12.   75.    9.]
 [   4.  234.  182.   31.   47.]
 [   2.   46.   58.   13.   16.]
 [ 132.   16.   32.  226.   63.]
 [ 159.  424.  494.  222. 1073.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 2.905 | Acc: 63.500% | Wgt Acc: 53.348%
	I - Batch: 100 | Loss: 2.930 | Acc: 63.062% | Wgt Acc: 52.664%
	I - Batch: 150 | Loss: 2.922 | Acc: 64.125% | Wgt Acc: 53.739%
	I - Batch: 200 | Loss: 2.915 | Acc: 63.719% | Wgt Acc: 53.851%
	I - Batch: 250 | Loss: 2.937 | Acc: 63.200% | Wgt Acc: 53.051%
	I - Batch: 300 | Loss: 2.942 | Acc: 63.146% | Wgt Acc: 53.190%
	I - Batch: 350 | Loss: 2.936 | Acc: 63.482% | Wgt Acc: 53.796%
	I - Batch: 400 | Loss: 2.947 | Acc: 63.156% | Wgt Acc: 53.149%
	I - Batch: 450 | Loss: 2.942 | Acc: 63.361% | Wgt Acc: 53.414%
	I - Batch: 500 | Loss: 2.930 | Acc: 63.675% | Wgt Acc: 53.777%
	I - Batch: 550 | Loss: 2.932 | Acc: 63.727% | Wgt Acc: 53.914%
	I - Batch: 600 | Loss: 2.931 | Acc: 63.906% | Wgt Acc: 54.109%
	I - Batch: 650 | Loss: 2.938 | Acc: 63.808% | Wgt Acc: 53.975%
	I - Batch: 700 | Loss: 2.939 | Acc: 63.955% | Wgt Acc: 54.078%
	I - Batch: 750 | Loss: 2.937 | Acc: 64.067% | Wgt Acc: 54.139%
	I - Batch: 800 | Loss: 2.945 | Acc: 63.898% | Wgt Acc: 53.998%
	I - Batch: 850 | Loss: 2.942 | Acc: 63.890% | Wgt Acc: 53.985%
	I - Batch: 900 | Loss: 2.938 | Acc: 64.035% | Wgt Acc: 54.187%
	I - Batch: 950 | Loss: 2.939 | Acc: 63.993% | Wgt Acc: 54.124%
	I - Batch: 1000 | Loss: 2.934 | Acc: 64.031% | Wgt Acc: 54.188%
I - num batch: 1003
I - Train -- Loss: 2.934 | Acc: 64.046% | Wgt Acc: 54.208% | LR: 1.250000e-04 | Dur: 627.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 412.    1.    4.   47.   50.]
 [   3.  846.  924.    6.  170.]
 [   2.  606.  712.    4.  188.]
 [1269.   19.   59. 1642.  739.]
 [ 176.  366.  939.  195. 6661.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.425 | Acc: 39.625% | Wgt Acc: 42.727%
	I - Batch: 100 | Loss: 5.356 | Acc: 44.938% | Wgt Acc: 45.742%
	I - Batch: 150 | Loss: 5.308 | Acc: 50.375% | Wgt Acc: 47.975%
	I - Batch: 200 | Loss: 5.288 | Acc: 52.250% | Wgt Acc: 48.553%
I - num batch: 238
I - Val -- Loss: 5.305 | Acc: 53.114% | Wgt Acc: 49.028% | Dur: 114.75s
I - Confusion Matrix: [row->prediction - col->label]
[[300.   4.  18.  87.  36.]
 [  1. 408. 354.  18.  90.]
 [  2.  70.  68.   4.  57.]
 [135.  32.  62. 314.  94.]
 [ 88. 212. 276. 144. 931.]]

I - Local maximum validation set accuracy:  53.11

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 2.855 | Acc: 67.375% | Wgt Acc: 56.855%
	I - Batch: 100 | Loss: 2.861 | Acc: 65.125% | Wgt Acc: 54.524%
	I - Batch: 150 | Loss: 2.891 | Acc: 64.042% | Wgt Acc: 54.274%
	I - Batch: 200 | Loss: 2.906 | Acc: 64.562% | Wgt Acc: 54.969%
	I - Batch: 250 | Loss: 2.876 | Acc: 65.275% | Wgt Acc: 55.790%
	I - Batch: 300 | Loss: 2.871 | Acc: 65.208% | Wgt Acc: 55.704%
	I - Batch: 350 | Loss: 2.868 | Acc: 65.661% | Wgt Acc: 56.187%
	I - Batch: 400 | Loss: 2.872 | Acc: 65.969% | Wgt Acc: 56.260%
	I - Batch: 450 | Loss: 2.868 | Acc: 65.889% | Wgt Acc: 56.176%
	I - Batch: 500 | Loss: 2.871 | Acc: 65.888% | Wgt Acc: 56.230%
	I - Batch: 550 | Loss: 2.881 | Acc: 65.545% | Wgt Acc: 55.815%
	I - Batch: 600 | Loss: 2.888 | Acc: 65.281% | Wgt Acc: 55.569%
	I - Batch: 650 | Loss: 2.894 | Acc: 65.125% | Wgt Acc: 55.355%
	I - Batch: 700 | Loss: 2.888 | Acc: 65.304% | Wgt Acc: 55.603%
	I - Batch: 750 | Loss: 2.887 | Acc: 65.467% | Wgt Acc: 55.769%
	I - Batch: 800 | Loss: 2.890 | Acc: 65.203% | Wgt Acc: 55.428%
	I - Batch: 850 | Loss: 2.888 | Acc: 65.301% | Wgt Acc: 55.685%
	I - Batch: 900 | Loss: 2.890 | Acc: 65.312% | Wgt Acc: 55.655%
	I - Batch: 950 | Loss: 2.886 | Acc: 65.388% | Wgt Acc: 55.657%
	I - Batch: 1000 | Loss: 2.884 | Acc: 65.306% | Wgt Acc: 55.593%
I - num batch: 1003
I - Train -- Loss: 2.885 | Acc: 65.268% | Wgt Acc: 55.559% | LR: 1.250000e-04 | Dur: 637.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 443.    0.    2.   49.   39.]
 [   1.  851.  971.    5.  167.]
 [   2.  703.  822.    6.  203.]
 [1221.   18.   45. 1644.  690.]
 [ 195.  266.  798.  190. 6709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.381 | Acc: 41.375% | Wgt Acc: 44.249%
	I - Batch: 100 | Loss: 5.347 | Acc: 43.438% | Wgt Acc: 43.938%
	I - Batch: 150 | Loss: 5.281 | Acc: 47.667% | Wgt Acc: 45.142%
	I - Batch: 200 | Loss: 5.261 | Acc: 49.469% | Wgt Acc: 45.316%
I - num batch: 238
I - Val -- Loss: 5.264 | Acc: 50.118% | Wgt Acc: 45.731% | Dur: 116.80s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   0.   6.  19.   6.]
 [ 10. 470. 400.  31. 157.]
 [  5.  70. 100.  17. 108.]
 [179.  12.  32. 303.  48.]
 [187. 174. 240. 197. 889.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 2.729 | Acc: 67.500% | Wgt Acc: 58.825%
	I - Batch: 100 | Loss: 2.770 | Acc: 66.625% | Wgt Acc: 58.686%
	I - Batch: 150 | Loss: 2.763 | Acc: 66.625% | Wgt Acc: 59.411%
	I - Batch: 200 | Loss: 2.759 | Acc: 67.031% | Wgt Acc: 59.847%
	I - Batch: 250 | Loss: 2.770 | Acc: 66.350% | Wgt Acc: 59.240%
	I - Batch: 300 | Loss: 2.768 | Acc: 66.271% | Wgt Acc: 59.318%
	I - Batch: 350 | Loss: 2.765 | Acc: 66.339% | Wgt Acc: 59.576%
	I - Batch: 400 | Loss: 2.772 | Acc: 66.266% | Wgt Acc: 59.667%
	I - Batch: 450 | Loss: 2.772 | Acc: 66.319% | Wgt Acc: 59.522%
	I - Batch: 500 | Loss: 2.771 | Acc: 66.350% | Wgt Acc: 59.702%
	I - Batch: 550 | Loss: 2.765 | Acc: 66.409% | Wgt Acc: 59.855%
	I - Batch: 600 | Loss: 2.765 | Acc: 66.344% | Wgt Acc: 59.681%
	I - Batch: 650 | Loss: 2.769 | Acc: 66.394% | Wgt Acc: 59.741%
	I - Batch: 700 | Loss: 2.770 | Acc: 66.473% | Wgt Acc: 59.710%
	I - Batch: 750 | Loss: 2.764 | Acc: 66.692% | Wgt Acc: 59.891%
	I - Batch: 800 | Loss: 2.763 | Acc: 66.820% | Wgt Acc: 59.985%
	I - Batch: 850 | Loss: 2.761 | Acc: 66.868% | Wgt Acc: 60.021%
	I - Batch: 900 | Loss: 2.769 | Acc: 66.653% | Wgt Acc: 59.741%
	I - Batch: 950 | Loss: 2.770 | Acc: 66.671% | Wgt Acc: 59.665%
	I - Batch: 1000 | Loss: 2.769 | Acc: 66.775% | Wgt Acc: 59.773%
I - num batch: 1003
I - Train -- Loss: 2.769 | Acc: 66.802% | Wgt Acc: 59.819% | LR: 1.250000e-04 | Dur: 638.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 491.    1.    1.   36.   65.]
 [   1. 1077. 1137.    3.  171.]
 [  11.  693. 1081.   23.  531.]
 [1178.   12.   48. 1678.  653.]
 [ 181.   55.  371.  154. 6388.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.414 | Acc: 41.500% | Wgt Acc: 44.385%
	I - Batch: 100 | Loss: 5.373 | Acc: 45.250% | Wgt Acc: 45.692%
	I - Batch: 150 | Loss: 5.330 | Acc: 49.750% | Wgt Acc: 47.143%
	I - Batch: 200 | Loss: 5.295 | Acc: 52.469% | Wgt Acc: 48.427%
I - num batch: 238
I - Val -- Loss: 5.307 | Acc: 52.852% | Wgt Acc: 48.574% | Dur: 116.76s
I - Confusion Matrix: [row->prediction - col->label]
[[257.   4.  24.  62.  13.]
 [  1. 382. 280.  19.  61.]
 [  9. 106. 126.  24. 103.]
 [148.  56.  86. 337. 122.]
 [111. 178. 262. 125. 909.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 2.694 | Acc: 70.125% | Wgt Acc: 62.070%
	I - Batch: 100 | Loss: 2.655 | Acc: 70.312% | Wgt Acc: 63.039%
	I - Batch: 150 | Loss: 2.648 | Acc: 69.417% | Wgt Acc: 61.909%
	I - Batch: 200 | Loss: 2.645 | Acc: 69.281% | Wgt Acc: 61.772%
	I - Batch: 250 | Loss: 2.651 | Acc: 69.300% | Wgt Acc: 62.177%
	I - Batch: 300 | Loss: 2.647 | Acc: 69.417% | Wgt Acc: 62.141%
	I - Batch: 350 | Loss: 2.668 | Acc: 68.768% | Wgt Acc: 61.526%
	I - Batch: 400 | Loss: 2.659 | Acc: 69.406% | Wgt Acc: 62.201%
	I - Batch: 450 | Loss: 2.667 | Acc: 69.097% | Wgt Acc: 61.756%
	I - Batch: 500 | Loss: 2.674 | Acc: 69.312% | Wgt Acc: 62.119%
	I - Batch: 550 | Loss: 2.678 | Acc: 69.295% | Wgt Acc: 62.110%
	I - Batch: 600 | Loss: 2.680 | Acc: 69.229% | Wgt Acc: 62.164%
	I - Batch: 650 | Loss: 2.673 | Acc: 69.471% | Wgt Acc: 62.409%
	I - Batch: 700 | Loss: 2.684 | Acc: 69.286% | Wgt Acc: 62.217%
	I - Batch: 750 | Loss: 2.679 | Acc: 69.525% | Wgt Acc: 62.532%
	I - Batch: 800 | Loss: 2.685 | Acc: 69.266% | Wgt Acc: 62.267%
	I - Batch: 850 | Loss: 2.690 | Acc: 69.294% | Wgt Acc: 62.276%
	I - Batch: 900 | Loss: 2.688 | Acc: 69.299% | Wgt Acc: 62.353%
	I - Batch: 950 | Loss: 2.693 | Acc: 69.283% | Wgt Acc: 62.245%
	I - Batch: 1000 | Loss: 2.691 | Acc: 69.381% | Wgt Acc: 62.333%
I - num batch: 1003
I - Train -- Loss: 2.691 | Acc: 69.383% | Wgt Acc: 62.334% | LR: 1.250000e-04 | Dur: 638.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 783.    3.    4.   57.   91.]
 [   0.  714.  687.    1.   72.]
 [   8. 1067. 1523.   26.  561.]
 [ 914.   13.   56. 1676.  651.]
 [ 157.   41.  368.  134. 6433.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.362 | Acc: 42.625% | Wgt Acc: 44.581%
	I - Batch: 100 | Loss: 5.305 | Acc: 45.188% | Wgt Acc: 45.017%
	I - Batch: 150 | Loss: 5.283 | Acc: 49.583% | Wgt Acc: 46.741%
	I - Batch: 200 | Loss: 5.271 | Acc: 52.281% | Wgt Acc: 48.134%
I - num batch: 238
I - Val -- Loss: 5.288 | Acc: 52.878% | Wgt Acc: 48.633% | Dur: 117.12s
I - Confusion Matrix: [row->prediction - col->label]
[[217.  10.   8.  31.  14.]
 [  5. 340. 250.  14.  44.]
 [ 12. 144. 148.  34.  89.]
 [189.  68. 110. 414. 168.]
 [103. 164. 262.  74. 893.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 2.640 | Acc: 70.250% | Wgt Acc: 63.134%
	I - Batch: 100 | Loss: 2.601 | Acc: 70.688% | Wgt Acc: 64.026%
	I - Batch: 150 | Loss: 2.628 | Acc: 70.625% | Wgt Acc: 64.051%
	I - Batch: 200 | Loss: 2.642 | Acc: 70.031% | Wgt Acc: 62.916%
	I - Batch: 250 | Loss: 2.633 | Acc: 69.900% | Wgt Acc: 62.847%
	I - Batch: 300 | Loss: 2.631 | Acc: 69.979% | Wgt Acc: 62.893%
	I - Batch: 350 | Loss: 2.632 | Acc: 70.179% | Wgt Acc: 63.176%
	I - Batch: 400 | Loss: 2.634 | Acc: 70.266% | Wgt Acc: 63.249%
	I - Batch: 450 | Loss: 2.624 | Acc: 70.597% | Wgt Acc: 63.642%
	I - Batch: 500 | Loss: 2.631 | Acc: 70.487% | Wgt Acc: 63.496%
	I - Batch: 550 | Loss: 2.631 | Acc: 70.318% | Wgt Acc: 63.288%
	I - Batch: 600 | Loss: 2.624 | Acc: 70.542% | Wgt Acc: 63.689%
	I - Batch: 650 | Loss: 2.626 | Acc: 70.846% | Wgt Acc: 64.000%
	I - Batch: 700 | Loss: 2.636 | Acc: 70.616% | Wgt Acc: 63.648%
	I - Batch: 750 | Loss: 2.637 | Acc: 70.575% | Wgt Acc: 63.721%
	I - Batch: 800 | Loss: 2.640 | Acc: 70.578% | Wgt Acc: 63.764%
	I - Batch: 850 | Loss: 2.644 | Acc: 70.537% | Wgt Acc: 63.785%
	I - Batch: 900 | Loss: 2.645 | Acc: 70.549% | Wgt Acc: 63.834%
	I - Batch: 950 | Loss: 2.642 | Acc: 70.724% | Wgt Acc: 63.998%
	I - Batch: 1000 | Loss: 2.644 | Acc: 70.806% | Wgt Acc: 64.053%
I - num batch: 1003
I - Train -- Loss: 2.644 | Acc: 70.792% | Wgt Acc: 64.040% | LR: 1.250000e-04 | Dur: 642.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 847.    2.    5.   59.  124.]
 [   1.  794.  793.    2.   73.]
 [   6.  992. 1479.   17.  559.]
 [ 835.    8.   39. 1697.  514.]
 [ 173.   42.  322.  119. 6538.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.459 | Acc: 38.500% | Wgt Acc: 40.580%
	I - Batch: 100 | Loss: 5.400 | Acc: 43.562% | Wgt Acc: 43.487%
	I - Batch: 150 | Loss: 5.343 | Acc: 48.792% | Wgt Acc: 45.840%
	I - Batch: 200 | Loss: 5.305 | Acc: 51.188% | Wgt Acc: 47.163%
I - num batch: 238
I - Val -- Loss: 5.317 | Acc: 51.616% | Wgt Acc: 47.511% | Dur: 117.47s
I - Confusion Matrix: [row->prediction - col->label]
[[273.  12.  46.  54.  62.]
 [  7. 318. 268.  33.  55.]
 [ 10. 154. 142.  38.  97.]
 [157.  50.  62. 358. 121.]
 [ 79. 192. 260.  84. 873.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 2.661 | Acc: 70.750% | Wgt Acc: 63.711%
	I - Batch: 100 | Loss: 2.593 | Acc: 72.812% | Wgt Acc: 66.138%
	I - Batch: 150 | Loss: 2.587 | Acc: 72.500% | Wgt Acc: 65.662%
	I - Batch: 200 | Loss: 2.580 | Acc: 72.125% | Wgt Acc: 65.001%
	I - Batch: 250 | Loss: 2.577 | Acc: 71.625% | Wgt Acc: 64.331%
	I - Batch: 300 | Loss: 2.578 | Acc: 71.188% | Wgt Acc: 63.794%
	I - Batch: 350 | Loss: 2.575 | Acc: 71.571% | Wgt Acc: 64.238%
	I - Batch: 400 | Loss: 2.575 | Acc: 71.641% | Wgt Acc: 64.406%
	I - Batch: 450 | Loss: 2.590 | Acc: 71.236% | Wgt Acc: 64.182%
	I - Batch: 500 | Loss: 2.589 | Acc: 71.325% | Wgt Acc: 64.336%
	I - Batch: 550 | Loss: 2.595 | Acc: 71.080% | Wgt Acc: 64.271%
	I - Batch: 600 | Loss: 2.593 | Acc: 70.823% | Wgt Acc: 64.074%
	I - Batch: 650 | Loss: 2.589 | Acc: 71.010% | Wgt Acc: 64.377%
	I - Batch: 700 | Loss: 2.594 | Acc: 70.759% | Wgt Acc: 64.168%
	I - Batch: 750 | Loss: 2.593 | Acc: 70.808% | Wgt Acc: 64.222%
	I - Batch: 800 | Loss: 2.592 | Acc: 70.914% | Wgt Acc: 64.487%
	I - Batch: 850 | Loss: 2.592 | Acc: 71.037% | Wgt Acc: 64.530%
	I - Batch: 900 | Loss: 2.593 | Acc: 70.972% | Wgt Acc: 64.471%
	I - Batch: 950 | Loss: 2.594 | Acc: 70.875% | Wgt Acc: 64.432%
	I - Batch: 1000 | Loss: 2.589 | Acc: 71.069% | Wgt Acc: 64.635%
I - num batch: 1003
I - Train -- Loss: 2.589 | Acc: 71.060% | Wgt Acc: 64.625% | LR: 1.250000e-04 | Dur: 628.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 879.    1.    7.   43.  142.]
 [   1.  876.  875.    6.   72.]
 [   5.  901. 1394.   22.  554.]
 [ 806.   13.   46. 1692.  483.]
 [ 171.   47.  316.  131. 6557.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.634 | Acc: 37.875% | Wgt Acc: 38.841%
	I - Batch: 100 | Loss: 5.528 | Acc: 44.000% | Wgt Acc: 42.264%
	I - Batch: 150 | Loss: 5.427 | Acc: 49.542% | Wgt Acc: 44.434%
	I - Batch: 200 | Loss: 5.384 | Acc: 52.062% | Wgt Acc: 45.501%
I - num batch: 238
I - Val -- Loss: 5.388 | Acc: 52.983% | Wgt Acc: 46.088% | Dur: 113.44s
I - Confusion Matrix: [row->prediction - col->label]
[[320.  10.  16. 115.  33.]
 [  3. 242. 186.   7.  24.]
 [  6. 170. 188.  20.  88.]
 [ 79.  60.  62. 285.  82.]
 [118. 244. 326. 140. 981.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 2.487 | Acc: 74.250% | Wgt Acc: 67.283%
	I - Batch: 100 | Loss: 2.521 | Acc: 72.625% | Wgt Acc: 65.341%
	I - Batch: 150 | Loss: 2.509 | Acc: 72.833% | Wgt Acc: 65.771%
	I - Batch: 200 | Loss: 2.505 | Acc: 72.969% | Wgt Acc: 66.229%
	I - Batch: 250 | Loss: 2.501 | Acc: 73.000% | Wgt Acc: 66.697%
	I - Batch: 300 | Loss: 2.488 | Acc: 72.875% | Wgt Acc: 66.690%
	I - Batch: 350 | Loss: 2.484 | Acc: 72.786% | Wgt Acc: 66.488%
	I - Batch: 400 | Loss: 2.486 | Acc: 72.781% | Wgt Acc: 66.531%
	I - Batch: 450 | Loss: 2.486 | Acc: 72.681% | Wgt Acc: 66.359%
	I - Batch: 500 | Loss: 2.483 | Acc: 72.513% | Wgt Acc: 66.264%
	I - Batch: 550 | Loss: 2.487 | Acc: 72.591% | Wgt Acc: 66.416%
	I - Batch: 600 | Loss: 2.492 | Acc: 72.500% | Wgt Acc: 66.306%
	I - Batch: 650 | Loss: 2.494 | Acc: 72.442% | Wgt Acc: 66.198%
	I - Batch: 700 | Loss: 2.498 | Acc: 72.420% | Wgt Acc: 66.181%
	I - Batch: 750 | Loss: 2.505 | Acc: 72.317% | Wgt Acc: 66.099%
	I - Batch: 800 | Loss: 2.504 | Acc: 72.500% | Wgt Acc: 66.325%
	I - Batch: 850 | Loss: 2.506 | Acc: 72.522% | Wgt Acc: 66.288%
	I - Batch: 900 | Loss: 2.510 | Acc: 72.431% | Wgt Acc: 66.137%
	I - Batch: 950 | Loss: 2.511 | Acc: 72.329% | Wgt Acc: 66.067%
	I - Batch: 1000 | Loss: 2.510 | Acc: 72.287% | Wgt Acc: 66.073%
I - num batch: 1003
I - Train -- Loss: 2.511 | Acc: 72.269% | Wgt Acc: 66.051% | LR: 1.250000e-04 | Dur: 620.38s
I - Confusion Matrix: [row->prediction - col->label]
[[1009.    1.    7.   30.  184.]
 [   2.  836.  920.    1.   76.]
 [  11.  948. 1388.    9.  481.]
 [ 687.   14.   36. 1726.  434.]
 [ 153.   39.  287.  128. 6633.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.719 | Acc: 33.875% | Wgt Acc: 35.466%
	I - Batch: 100 | Loss: 5.574 | Acc: 40.812% | Wgt Acc: 39.040%
	I - Batch: 150 | Loss: 5.453 | Acc: 48.083% | Wgt Acc: 42.816%
	I - Batch: 200 | Loss: 5.415 | Acc: 51.094% | Wgt Acc: 44.509%
I - num batch: 238
I - Val -- Loss: 5.417 | Acc: 51.800% | Wgt Acc: 44.784% | Dur: 113.74s
I - Confusion Matrix: [row->prediction - col->label]
[[273.  18.  20.  73.  30.]
 [  2. 232. 170.   9.  28.]
 [  9. 136. 108.  19.  42.]
 [128.  42. 108. 364. 114.]
 [114. 298. 372. 102. 994.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 2.557 | Acc: 69.875% | Wgt Acc: 64.590%
	I - Batch: 100 | Loss: 2.517 | Acc: 71.438% | Wgt Acc: 65.908%
	I - Batch: 150 | Loss: 2.491 | Acc: 72.750% | Wgt Acc: 67.088%
	I - Batch: 200 | Loss: 2.497 | Acc: 72.000% | Wgt Acc: 66.196%
	I - Batch: 250 | Loss: 2.494 | Acc: 72.350% | Wgt Acc: 66.542%
	I - Batch: 300 | Loss: 2.490 | Acc: 72.562% | Wgt Acc: 66.833%
	I - Batch: 350 | Loss: 2.476 | Acc: 72.857% | Wgt Acc: 67.203%
	I - Batch: 400 | Loss: 2.474 | Acc: 73.047% | Wgt Acc: 67.328%
	I - Batch: 450 | Loss: 2.483 | Acc: 72.778% | Wgt Acc: 66.974%
	I - Batch: 500 | Loss: 2.484 | Acc: 72.713% | Wgt Acc: 66.972%
	I - Batch: 550 | Loss: 2.488 | Acc: 72.920% | Wgt Acc: 67.371%
	I - Batch: 600 | Loss: 2.489 | Acc: 72.948% | Wgt Acc: 67.339%
	I - Batch: 650 | Loss: 2.491 | Acc: 73.240% | Wgt Acc: 67.721%
	I - Batch: 700 | Loss: 2.496 | Acc: 73.116% | Wgt Acc: 67.532%
	I - Batch: 750 | Loss: 2.490 | Acc: 73.258% | Wgt Acc: 67.599%
	I - Batch: 800 | Loss: 2.483 | Acc: 73.562% | Wgt Acc: 67.995%
	I - Batch: 850 | Loss: 2.477 | Acc: 73.647% | Wgt Acc: 68.130%
	I - Batch: 900 | Loss: 2.475 | Acc: 73.722% | Wgt Acc: 68.190%
	I - Batch: 950 | Loss: 2.479 | Acc: 73.737% | Wgt Acc: 68.213%
	I - Batch: 1000 | Loss: 2.486 | Acc: 73.481% | Wgt Acc: 67.966%
I - num batch: 1003
I - Train -- Loss: 2.486 | Acc: 73.498% | Wgt Acc: 67.980% | LR: 1.250000e-04 | Dur: 623.53s
I - Confusion Matrix: [row->prediction - col->label]
[[1060.    1.    2.   43.  191.]
 [   2.  994.  993.    0.   83.]
 [   8.  795. 1332.   12.  478.]
 [ 636.   11.   36. 1725.  378.]
 [ 156.   37.  275.  114. 6678.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.450 | Acc: 42.125% | Wgt Acc: 43.478%
	I - Batch: 100 | Loss: 5.377 | Acc: 47.000% | Wgt Acc: 45.996%
	I - Batch: 150 | Loss: 5.305 | Acc: 52.083% | Wgt Acc: 48.313%
	I - Batch: 200 | Loss: 5.269 | Acc: 54.531% | Wgt Acc: 49.896%
I - num batch: 238
I - Val -- Loss: 5.299 | Acc: 54.271% | Wgt Acc: 49.501% | Dur: 111.87s
I - Confusion Matrix: [row->prediction - col->label]
[[300.  14.  38.  68.  37.]
 [  0. 296. 204.  11.  40.]
 [ 18. 196. 204.  44. 115.]
 [107.  56.  68. 352. 103.]
 [101. 164. 264.  92. 913.]]

I - Local maximum validation set accuracy:  54.27

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 2.427 | Acc: 72.000% | Wgt Acc: 66.550%
	I - Batch: 100 | Loss: 2.446 | Acc: 73.188% | Wgt Acc: 67.123%
	I - Batch: 150 | Loss: 2.433 | Acc: 74.042% | Wgt Acc: 67.726%
	I - Batch: 200 | Loss: 2.415 | Acc: 74.750% | Wgt Acc: 69.076%
	I - Batch: 250 | Loss: 2.424 | Acc: 74.475% | Wgt Acc: 68.636%
	I - Batch: 300 | Loss: 2.417 | Acc: 74.417% | Wgt Acc: 68.743%
	I - Batch: 350 | Loss: 2.438 | Acc: 74.018% | Wgt Acc: 68.299%
	I - Batch: 400 | Loss: 2.439 | Acc: 74.141% | Wgt Acc: 68.573%
	I - Batch: 450 | Loss: 2.436 | Acc: 74.056% | Wgt Acc: 68.513%
	I - Batch: 500 | Loss: 2.436 | Acc: 74.188% | Wgt Acc: 68.557%
	I - Batch: 550 | Loss: 2.438 | Acc: 74.102% | Wgt Acc: 68.558%
	I - Batch: 600 | Loss: 2.443 | Acc: 73.990% | Wgt Acc: 68.390%
	I - Batch: 650 | Loss: 2.456 | Acc: 73.663% | Wgt Acc: 68.099%
	I - Batch: 700 | Loss: 2.466 | Acc: 73.482% | Wgt Acc: 67.922%
	I - Batch: 750 | Loss: 2.465 | Acc: 73.650% | Wgt Acc: 68.112%
	I - Batch: 800 | Loss: 2.462 | Acc: 73.750% | Wgt Acc: 68.258%
	I - Batch: 850 | Loss: 2.461 | Acc: 73.772% | Wgt Acc: 68.285%
	I - Batch: 900 | Loss: 2.458 | Acc: 73.812% | Wgt Acc: 68.271%
	I - Batch: 950 | Loss: 2.460 | Acc: 73.757% | Wgt Acc: 68.177%
	I - Batch: 1000 | Loss: 2.457 | Acc: 73.775% | Wgt Acc: 68.142%
I - num batch: 1003
I - Train -- Loss: 2.457 | Acc: 73.759% | Wgt Acc: 68.096% | LR: 1.250000e-04 | Dur: 617.64s
I - Confusion Matrix: [row->prediction - col->label]
[[1081.    4.    5.   40.  188.]
 [   2.  936.  968.    2.   59.]
 [   7.  853. 1372.   11.  461.]
 [ 614.    9.   33. 1741.  399.]
 [ 158.   36.  260.  100. 6701.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.369 | Acc: 45.000% | Wgt Acc: 47.076%
	I - Batch: 100 | Loss: 5.338 | Acc: 47.625% | Wgt Acc: 47.918%
	I - Batch: 150 | Loss: 5.300 | Acc: 52.167% | Wgt Acc: 50.318%
	I - Batch: 200 | Loss: 5.280 | Acc: 53.250% | Wgt Acc: 50.364%
I - num batch: 238
I - Val -- Loss: 5.303 | Acc: 53.403% | Wgt Acc: 50.226% | Dur: 115.29s
I - Confusion Matrix: [row->prediction - col->label]
[[294.  12.  24.  79.  32.]
 [ 10. 386. 316.  23.  95.]
 [ 14. 106. 166.  35. 114.]
 [121.  58.  54. 325. 106.]
 [ 87. 164. 218. 105. 861.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 2.468 | Acc: 73.125% | Wgt Acc: 66.359%
	I - Batch: 100 | Loss: 2.442 | Acc: 75.188% | Wgt Acc: 70.326%
	I - Batch: 150 | Loss: 2.435 | Acc: 74.500% | Wgt Acc: 68.973%
	I - Batch: 200 | Loss: 2.421 | Acc: 74.812% | Wgt Acc: 69.113%
	I - Batch: 250 | Loss: 2.421 | Acc: 75.300% | Wgt Acc: 69.743%
	I - Batch: 300 | Loss: 2.408 | Acc: 75.208% | Wgt Acc: 69.458%
	I - Batch: 350 | Loss: 2.412 | Acc: 75.143% | Wgt Acc: 69.361%
	I - Batch: 400 | Loss: 2.397 | Acc: 75.078% | Wgt Acc: 69.234%
	I - Batch: 450 | Loss: 2.402 | Acc: 74.889% | Wgt Acc: 68.937%
	I - Batch: 500 | Loss: 2.403 | Acc: 74.838% | Wgt Acc: 68.943%
	I - Batch: 550 | Loss: 2.404 | Acc: 75.023% | Wgt Acc: 69.168%
	I - Batch: 600 | Loss: 2.415 | Acc: 74.948% | Wgt Acc: 69.002%
	I - Batch: 650 | Loss: 2.419 | Acc: 75.000% | Wgt Acc: 68.990%
	I - Batch: 700 | Loss: 2.419 | Acc: 75.134% | Wgt Acc: 69.109%
	I - Batch: 750 | Loss: 2.422 | Acc: 74.975% | Wgt Acc: 69.035%
	I - Batch: 800 | Loss: 2.424 | Acc: 74.867% | Wgt Acc: 68.795%
	I - Batch: 850 | Loss: 2.423 | Acc: 74.846% | Wgt Acc: 68.798%
	I - Batch: 900 | Loss: 2.419 | Acc: 74.896% | Wgt Acc: 68.877%
	I - Batch: 950 | Loss: 2.422 | Acc: 74.803% | Wgt Acc: 68.815%
	I - Batch: 1000 | Loss: 2.424 | Acc: 74.781% | Wgt Acc: 68.788%
I - num batch: 1003
I - Train -- Loss: 2.424 | Acc: 74.763% | Wgt Acc: 68.748% | LR: 1.250000e-04 | Dur: 662.76s
I - Confusion Matrix: [row->prediction - col->label]
[[1147.    1.    3.   38.  191.]
 [   2.  874.  929.    0.   70.]
 [   3.  929. 1432.   15.  379.]
 [ 568.    7.   23. 1728.  357.]
 [ 142.   27.  251.  113. 6811.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.716 | Acc: 35.750% | Wgt Acc: 36.580%
	I - Batch: 100 | Loss: 5.583 | Acc: 41.000% | Wgt Acc: 38.435%
	I - Batch: 150 | Loss: 5.451 | Acc: 48.750% | Wgt Acc: 42.249%
	I - Batch: 200 | Loss: 5.410 | Acc: 51.875% | Wgt Acc: 43.991%
I - num batch: 238
I - Val -- Loss: 5.408 | Acc: 52.720% | Wgt Acc: 44.643% | Dur: 116.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 196.    4.   14.   25.   15.]
 [   2.  224.  154.    3.   22.]
 [   5.  142.  172.   19.   52.]
 [ 174.   62.  100.  393.   98.]
 [ 149.  294.  338.  127. 1021.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 2.409 | Acc: 75.500% | Wgt Acc: 69.653%
	I - Batch: 100 | Loss: 2.428 | Acc: 75.312% | Wgt Acc: 69.551%
	I - Batch: 150 | Loss: 2.451 | Acc: 74.917% | Wgt Acc: 68.669%
	I - Batch: 200 | Loss: 2.435 | Acc: 75.156% | Wgt Acc: 69.100%
	I - Batch: 250 | Loss: 2.432 | Acc: 75.225% | Wgt Acc: 69.402%
	I - Batch: 300 | Loss: 2.426 | Acc: 75.000% | Wgt Acc: 68.780%
	I - Batch: 350 | Loss: 2.444 | Acc: 74.482% | Wgt Acc: 68.425%
	I - Batch: 400 | Loss: 2.447 | Acc: 74.828% | Wgt Acc: 69.064%
	I - Batch: 450 | Loss: 2.446 | Acc: 75.319% | Wgt Acc: 69.748%
	I - Batch: 500 | Loss: 2.439 | Acc: 75.575% | Wgt Acc: 70.095%
	I - Batch: 550 | Loss: 2.433 | Acc: 75.773% | Wgt Acc: 70.436%
	I - Batch: 600 | Loss: 2.422 | Acc: 75.958% | Wgt Acc: 70.754%
	I - Batch: 650 | Loss: 2.415 | Acc: 76.096% | Wgt Acc: 70.940%
	I - Batch: 700 | Loss: 2.412 | Acc: 76.116% | Wgt Acc: 71.056%
	I - Batch: 750 | Loss: 2.408 | Acc: 76.033% | Wgt Acc: 71.090%
	I - Batch: 800 | Loss: 2.414 | Acc: 75.938% | Wgt Acc: 71.074%
	I - Batch: 850 | Loss: 2.415 | Acc: 75.926% | Wgt Acc: 71.095%
	I - Batch: 900 | Loss: 2.415 | Acc: 75.924% | Wgt Acc: 71.151%
	I - Batch: 950 | Loss: 2.415 | Acc: 75.934% | Wgt Acc: 71.145%
	I - Batch: 1000 | Loss: 2.417 | Acc: 75.881% | Wgt Acc: 71.237%
I - num batch: 1003
I - Train -- Loss: 2.417 | Acc: 75.854% | Wgt Acc: 71.202% | LR: 1.250000e-04 | Dur: 634.12s
I - Confusion Matrix: [row->prediction - col->label]
[[1438.    7.    9.   63.  275.]
 [   3.  889.  939.    1.   69.]
 [  12.  904. 1397.   15.  434.]
 [ 261.    7.   24. 1703.  290.]
 [ 148.   31.  269.  112. 6740.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.427 | Acc: 39.750% | Wgt Acc: 41.320%
	I - Batch: 100 | Loss: 5.354 | Acc: 44.188% | Wgt Acc: 44.236%
	I - Batch: 150 | Loss: 5.308 | Acc: 48.375% | Wgt Acc: 46.379%
	I - Batch: 200 | Loss: 5.277 | Acc: 50.719% | Wgt Acc: 48.163%
I - num batch: 238
I - Val -- Loss: 5.314 | Acc: 51.117% | Wgt Acc: 48.555% | Dur: 113.14s
I - Confusion Matrix: [row->prediction - col->label]
[[344.  42.  58.  93. 118.]
 [  2. 254. 202.  18.  45.]
 [ 18. 208. 210.  41. 129.]
 [117.  54.  84. 360. 139.]
 [ 45. 168. 224.  55. 777.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 2.342 | Acc: 75.875% | Wgt Acc: 72.579%
	I - Batch: 100 | Loss: 2.427 | Acc: 75.312% | Wgt Acc: 71.762%
	I - Batch: 150 | Loss: 2.439 | Acc: 75.167% | Wgt Acc: 71.882%
	I - Batch: 200 | Loss: 2.424 | Acc: 75.469% | Wgt Acc: 71.999%
	I - Batch: 250 | Loss: 2.436 | Acc: 75.725% | Wgt Acc: 72.380%
	I - Batch: 300 | Loss: 2.427 | Acc: 76.229% | Wgt Acc: 72.874%
	I - Batch: 350 | Loss: 2.417 | Acc: 76.125% | Wgt Acc: 72.706%
	I - Batch: 400 | Loss: 2.415 | Acc: 76.078% | Wgt Acc: 72.318%
	I - Batch: 450 | Loss: 2.415 | Acc: 76.069% | Wgt Acc: 72.303%
	I - Batch: 500 | Loss: 2.415 | Acc: 75.912% | Wgt Acc: 72.280%
	I - Batch: 550 | Loss: 2.404 | Acc: 76.136% | Wgt Acc: 72.435%
	I - Batch: 600 | Loss: 2.411 | Acc: 76.167% | Wgt Acc: 72.433%
	I - Batch: 650 | Loss: 2.410 | Acc: 76.346% | Wgt Acc: 72.605%
	I - Batch: 700 | Loss: 2.406 | Acc: 76.420% | Wgt Acc: 72.636%
	I - Batch: 750 | Loss: 2.406 | Acc: 76.408% | Wgt Acc: 72.597%
	I - Batch: 800 | Loss: 2.407 | Acc: 76.422% | Wgt Acc: 72.534%
	I - Batch: 850 | Loss: 2.407 | Acc: 76.390% | Wgt Acc: 72.420%
	I - Batch: 900 | Loss: 2.411 | Acc: 76.354% | Wgt Acc: 72.395%
	I - Batch: 950 | Loss: 2.410 | Acc: 76.322% | Wgt Acc: 72.359%
	I - Batch: 1000 | Loss: 2.411 | Acc: 76.362% | Wgt Acc: 72.370%
I - num batch: 1003
I - Train -- Loss: 2.410 | Acc: 76.378% | Wgt Acc: 72.390% | LR: 1.250000e-04 | Dur: 636.00s
I - Confusion Matrix: [row->prediction - col->label]
[[1622.    9.   10.   93.  344.]
 [   0.  854.  917.    2.   54.]
 [  13.  943. 1429.   15.  430.]
 [  97.    4.   20. 1661.  295.]
 [ 130.   28.  262.  123. 6685.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.495 | Acc: 39.125% | Wgt Acc: 40.369%
	I - Batch: 100 | Loss: 5.482 | Acc: 44.562% | Wgt Acc: 43.782%
	I - Batch: 150 | Loss: 5.393 | Acc: 50.750% | Wgt Acc: 46.814%
	I - Batch: 200 | Loss: 5.353 | Acc: 53.031% | Wgt Acc: 48.040%
I - num batch: 238
I - Val -- Loss: 5.382 | Acc: 53.167% | Wgt Acc: 47.838% | Dur: 116.01s
I - Confusion Matrix: [row->prediction - col->label]
[[400.  34.  52. 225.  79.]
 [  2. 320. 214.  11.  52.]
 [ 11. 138. 204.  26. 109.]
 [ 20.  28.  36. 170.  39.]
 [ 93. 206. 272. 135. 929.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 2.319 | Acc: 77.500% | Wgt Acc: 73.242%
	I - Batch: 100 | Loss: 2.279 | Acc: 79.625% | Wgt Acc: 75.757%
	I - Batch: 150 | Loss: 2.321 | Acc: 79.000% | Wgt Acc: 74.971%
	I - Batch: 200 | Loss: 2.299 | Acc: 79.500% | Wgt Acc: 75.524%
	I - Batch: 250 | Loss: 2.299 | Acc: 79.250% | Wgt Acc: 75.262%
	I - Batch: 300 | Loss: 2.313 | Acc: 79.000% | Wgt Acc: 75.115%
	I - Batch: 350 | Loss: 2.328 | Acc: 78.571% | Wgt Acc: 74.622%
	I - Batch: 400 | Loss: 2.323 | Acc: 78.312% | Wgt Acc: 74.298%
	I - Batch: 450 | Loss: 2.318 | Acc: 78.306% | Wgt Acc: 74.278%
	I - Batch: 500 | Loss: 2.317 | Acc: 78.275% | Wgt Acc: 74.204%
	I - Batch: 550 | Loss: 2.311 | Acc: 78.341% | Wgt Acc: 74.376%
	I - Batch: 600 | Loss: 2.308 | Acc: 78.271% | Wgt Acc: 74.305%
	I - Batch: 650 | Loss: 2.303 | Acc: 78.490% | Wgt Acc: 74.523%
	I - Batch: 700 | Loss: 2.301 | Acc: 78.625% | Wgt Acc: 74.618%
	I - Batch: 750 | Loss: 2.301 | Acc: 78.508% | Wgt Acc: 74.466%
	I - Batch: 800 | Loss: 2.300 | Acc: 78.398% | Wgt Acc: 74.379%
	I - Batch: 850 | Loss: 2.303 | Acc: 78.316% | Wgt Acc: 74.270%
	I - Batch: 900 | Loss: 2.300 | Acc: 78.417% | Wgt Acc: 74.403%
	I - Batch: 950 | Loss: 2.291 | Acc: 78.520% | Wgt Acc: 74.449%
	I - Batch: 1000 | Loss: 2.291 | Acc: 78.494% | Wgt Acc: 74.415%
I - num batch: 1003
I - Train -- Loss: 2.291 | Acc: 78.504% | Wgt Acc: 74.425% | LR: 1.250000e-04 | Dur: 637.40s
I - Confusion Matrix: [row->prediction - col->label]
[[1676.    5.   12.   57.  280.]
 [   1.  851.  936.    1.   52.]
 [  10.  955. 1473.    9.  367.]
 [  52.    5.   18. 1728.  245.]
 [ 123.   22.  199.   99. 6864.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.737 | Acc: 36.500% | Wgt Acc: 38.211%
	I - Batch: 100 | Loss: 5.604 | Acc: 44.250% | Wgt Acc: 43.213%
	I - Batch: 150 | Loss: 5.494 | Acc: 50.500% | Wgt Acc: 45.623%
	I - Batch: 200 | Loss: 5.431 | Acc: 53.562% | Wgt Acc: 47.525%
I - num batch: 238
I - Val -- Loss: 5.444 | Acc: 54.113% | Wgt Acc: 47.662% | Dur: 115.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 365.   16.   36.  111.   59.]
 [   3.  270.  174.    7.   32.]
 [   4.  102.  116.   13.   33.]
 [  57.   52.   44.  298.   74.]
 [  97.  286.  408.  138. 1010.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 2.218 | Acc: 77.875% | Wgt Acc: 75.055%
	I - Batch: 100 | Loss: 2.216 | Acc: 79.062% | Wgt Acc: 75.191%
	I - Batch: 150 | Loss: 2.201 | Acc: 79.417% | Wgt Acc: 75.352%
	I - Batch: 200 | Loss: 2.208 | Acc: 79.344% | Wgt Acc: 74.940%
	I - Batch: 250 | Loss: 2.244 | Acc: 78.600% | Wgt Acc: 74.295%
	I - Batch: 300 | Loss: 2.245 | Acc: 78.896% | Wgt Acc: 74.926%
	I - Batch: 350 | Loss: 2.252 | Acc: 78.839% | Wgt Acc: 74.917%
	I - Batch: 400 | Loss: 2.256 | Acc: 79.125% | Wgt Acc: 75.306%
	I - Batch: 450 | Loss: 2.266 | Acc: 79.069% | Wgt Acc: 75.331%
	I - Batch: 500 | Loss: 2.287 | Acc: 78.725% | Wgt Acc: 74.952%
	I - Batch: 550 | Loss: 2.303 | Acc: 78.568% | Wgt Acc: 74.689%
	I - Batch: 600 | Loss: 2.306 | Acc: 78.521% | Wgt Acc: 74.630%
	I - Batch: 650 | Loss: 2.310 | Acc: 78.423% | Wgt Acc: 74.494%
	I - Batch: 700 | Loss: 2.312 | Acc: 78.375% | Wgt Acc: 74.431%
	I - Batch: 750 | Loss: 2.313 | Acc: 78.458% | Wgt Acc: 74.450%
	I - Batch: 800 | Loss: 2.315 | Acc: 78.492% | Wgt Acc: 74.380%
	I - Batch: 850 | Loss: 2.321 | Acc: 78.279% | Wgt Acc: 74.190%
	I - Batch: 900 | Loss: 2.316 | Acc: 78.340% | Wgt Acc: 74.249%
	I - Batch: 950 | Loss: 2.313 | Acc: 78.447% | Wgt Acc: 74.321%
	I - Batch: 1000 | Loss: 2.309 | Acc: 78.525% | Wgt Acc: 74.453%
I - num batch: 1003
I - Train -- Loss: 2.309 | Acc: 78.504% | Wgt Acc: 74.444% | LR: 1.250000e-04 | Dur: 636.11s
I - Confusion Matrix: [row->prediction - col->label]
[[1666.    8.   11.   56.  307.]
 [   0.  796.  813.    0.   47.]
 [   9. 1017. 1570.   16.  379.]
 [  59.    3.   28. 1740.  255.]
 [ 128.   14.  216.   82. 6820.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.201 | Acc: 48.000% | Wgt Acc: 50.500%
	I - Batch: 100 | Loss: 5.224 | Acc: 51.188% | Wgt Acc: 52.383%
	I - Batch: 150 | Loss: 5.221 | Acc: 54.375% | Wgt Acc: 54.407%
	I - Batch: 200 | Loss: 5.221 | Acc: 56.062% | Wgt Acc: 55.200%
I - num batch: 238
I - Val -- Loss: 5.253 | Acc: 55.848% | Wgt Acc: 54.930% | Dur: 114.76s
I - Confusion Matrix: [row->prediction - col->label]
[[327.  22.  36.  58.  51.]
 [  7. 434. 314.  26.  84.]
 [ 19. 108. 190.  46. 148.]
 [105.  40.  76. 371. 122.]
 [ 68. 122. 162.  66. 803.]]

I - Local maximum validation set accuracy:  55.85

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 2.175 | Acc: 81.500% | Wgt Acc: 77.876%
	I - Batch: 100 | Loss: 2.144 | Acc: 80.250% | Wgt Acc: 75.567%
	I - Batch: 150 | Loss: 2.186 | Acc: 79.917% | Wgt Acc: 75.735%
	I - Batch: 200 | Loss: 2.187 | Acc: 80.094% | Wgt Acc: 75.980%
	I - Batch: 250 | Loss: 2.192 | Acc: 80.450% | Wgt Acc: 76.521%
	I - Batch: 300 | Loss: 2.179 | Acc: 80.792% | Wgt Acc: 76.791%
	I - Batch: 350 | Loss: 2.200 | Acc: 80.232% | Wgt Acc: 75.864%
	I - Batch: 400 | Loss: 2.208 | Acc: 80.125% | Wgt Acc: 75.780%
	I - Batch: 450 | Loss: 2.208 | Acc: 80.139% | Wgt Acc: 75.792%
	I - Batch: 500 | Loss: 2.211 | Acc: 80.062% | Wgt Acc: 75.654%
	I - Batch: 550 | Loss: 2.213 | Acc: 80.136% | Wgt Acc: 75.910%
	I - Batch: 600 | Loss: 2.205 | Acc: 80.302% | Wgt Acc: 76.080%
	I - Batch: 650 | Loss: 2.202 | Acc: 80.413% | Wgt Acc: 76.216%
	I - Batch: 700 | Loss: 2.204 | Acc: 80.411% | Wgt Acc: 76.185%
	I - Batch: 750 | Loss: 2.211 | Acc: 80.192% | Wgt Acc: 76.011%
	I - Batch: 800 | Loss: 2.208 | Acc: 80.234% | Wgt Acc: 76.021%
	I - Batch: 850 | Loss: 2.215 | Acc: 80.066% | Wgt Acc: 75.865%
	I - Batch: 900 | Loss: 2.218 | Acc: 80.035% | Wgt Acc: 75.916%
	I - Batch: 950 | Loss: 2.220 | Acc: 79.980% | Wgt Acc: 75.845%
	I - Batch: 1000 | Loss: 2.220 | Acc: 79.981% | Wgt Acc: 75.897%
I - num batch: 1003
I - Train -- Loss: 2.220 | Acc: 80.000% | Wgt Acc: 75.933% | LR: 1.250000e-04 | Dur: 633.42s
I - Confusion Matrix: [row->prediction - col->label]
[[1702.    5.    5.   34.  256.]
 [   1.  846.  895.    0.   44.]
 [   6.  970. 1553.    4.  317.]
 [  39.    4.   12. 1770.  230.]
 [ 114.   13.  173.   86. 6961.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.416 | Acc: 42.375% | Wgt Acc: 44.706%
	I - Batch: 100 | Loss: 5.405 | Acc: 46.625% | Wgt Acc: 46.535%
	I - Batch: 150 | Loss: 5.352 | Acc: 51.792% | Wgt Acc: 49.084%
	I - Batch: 200 | Loss: 5.350 | Acc: 53.438% | Wgt Acc: 49.696%
I - num batch: 238
I - Val -- Loss: 5.366 | Acc: 53.798% | Wgt Acc: 49.831% | Dur: 115.50s
I - Confusion Matrix: [row->prediction - col->label]
[[268.   2.   8.  54.  16.]
 [  4. 362. 278.  18.  59.]
 [ 17. 120. 148.  25. 120.]
 [109.  78.  98. 369. 113.]
 [128. 164. 246. 101. 900.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 2.135 | Acc: 80.875% | Wgt Acc: 77.252%
	I - Batch: 100 | Loss: 2.169 | Acc: 80.250% | Wgt Acc: 76.236%
	I - Batch: 150 | Loss: 2.179 | Acc: 80.208% | Wgt Acc: 75.946%
	I - Batch: 200 | Loss: 2.186 | Acc: 80.281% | Wgt Acc: 76.108%
	I - Batch: 250 | Loss: 2.189 | Acc: 80.175% | Wgt Acc: 76.104%
	I - Batch: 300 | Loss: 2.177 | Acc: 80.354% | Wgt Acc: 76.301%
	I - Batch: 350 | Loss: 2.174 | Acc: 80.500% | Wgt Acc: 76.336%
	I - Batch: 400 | Loss: 2.180 | Acc: 80.656% | Wgt Acc: 76.503%
	I - Batch: 450 | Loss: 2.184 | Acc: 80.597% | Wgt Acc: 76.527%
	I - Batch: 500 | Loss: 2.180 | Acc: 80.463% | Wgt Acc: 76.443%
	I - Batch: 550 | Loss: 2.175 | Acc: 80.648% | Wgt Acc: 76.633%
	I - Batch: 600 | Loss: 2.178 | Acc: 80.594% | Wgt Acc: 76.588%
	I - Batch: 650 | Loss: 2.191 | Acc: 80.163% | Wgt Acc: 76.135%
	I - Batch: 700 | Loss: 2.193 | Acc: 80.152% | Wgt Acc: 76.136%
	I - Batch: 750 | Loss: 2.205 | Acc: 79.908% | Wgt Acc: 75.845%
	I - Batch: 800 | Loss: 2.215 | Acc: 79.734% | Wgt Acc: 75.684%
	I - Batch: 850 | Loss: 2.216 | Acc: 79.654% | Wgt Acc: 75.685%
	I - Batch: 900 | Loss: 2.217 | Acc: 79.674% | Wgt Acc: 75.633%
	I - Batch: 950 | Loss: 2.214 | Acc: 79.724% | Wgt Acc: 75.728%
	I - Batch: 1000 | Loss: 2.217 | Acc: 79.725% | Wgt Acc: 75.671%
I - num batch: 1003
I - Train -- Loss: 2.217 | Acc: 79.732% | Wgt Acc: 75.675% | LR: 1.250000e-04 | Dur: 631.49s
I - Confusion Matrix: [row->prediction - col->label]
[[1704.    4.   11.   41.  245.]
 [   1.  893. 1019.    1.   46.]
 [   8.  927. 1433.    8.  301.]
 [  38.    3.   13. 1774.  231.]
 [ 111.   11.  162.   70. 6985.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.584 | Acc: 40.625% | Wgt Acc: 42.119%
	I - Batch: 100 | Loss: 5.513 | Acc: 44.125% | Wgt Acc: 42.294%
	I - Batch: 150 | Loss: 5.406 | Acc: 50.500% | Wgt Acc: 45.335%
	I - Batch: 200 | Loss: 5.371 | Acc: 53.531% | Wgt Acc: 46.770%
I - num batch: 238
I - Val -- Loss: 5.391 | Acc: 54.087% | Wgt Acc: 47.091% | Dur: 114.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 294.   10.   26.   61.   24.]
 [   1.  316.  222.   16.   43.]
 [   3.  120.  152.   25.   65.]
 [  71.   48.   46.  276.   56.]
 [ 157.  232.  332.  189. 1020.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 2.210 | Acc: 80.500% | Wgt Acc: 76.854%
	I - Batch: 100 | Loss: 2.207 | Acc: 80.875% | Wgt Acc: 76.604%
	I - Batch: 150 | Loss: 2.186 | Acc: 81.083% | Wgt Acc: 76.759%
	I - Batch: 200 | Loss: 2.188 | Acc: 80.625% | Wgt Acc: 76.284%
	I - Batch: 250 | Loss: 2.192 | Acc: 80.425% | Wgt Acc: 76.040%
	I - Batch: 300 | Loss: 2.194 | Acc: 80.250% | Wgt Acc: 75.859%
	I - Batch: 350 | Loss: 2.188 | Acc: 80.429% | Wgt Acc: 76.139%
	I - Batch: 400 | Loss: 2.199 | Acc: 80.156% | Wgt Acc: 75.959%
	I - Batch: 450 | Loss: 2.194 | Acc: 80.333% | Wgt Acc: 76.177%
	I - Batch: 500 | Loss: 2.190 | Acc: 80.475% | Wgt Acc: 76.388%
	I - Batch: 550 | Loss: 2.195 | Acc: 80.352% | Wgt Acc: 76.321%
	I - Batch: 600 | Loss: 2.211 | Acc: 80.021% | Wgt Acc: 75.945%
	I - Batch: 650 | Loss: 2.221 | Acc: 79.837% | Wgt Acc: 75.685%
	I - Batch: 700 | Loss: 2.227 | Acc: 79.804% | Wgt Acc: 75.684%
	I - Batch: 750 | Loss: 2.231 | Acc: 79.658% | Wgt Acc: 75.434%
	I - Batch: 800 | Loss: 2.230 | Acc: 79.695% | Wgt Acc: 75.548%
	I - Batch: 850 | Loss: 2.236 | Acc: 79.551% | Wgt Acc: 75.254%
	I - Batch: 900 | Loss: 2.244 | Acc: 79.201% | Wgt Acc: 74.873%
	I - Batch: 950 | Loss: 2.245 | Acc: 79.270% | Wgt Acc: 75.017%
	I - Batch: 1000 | Loss: 2.253 | Acc: 79.181% | Wgt Acc: 74.883%
I - num batch: 1003
I - Train -- Loss: 2.252 | Acc: 79.196% | Wgt Acc: 74.902% | LR: 1.250000e-04 | Dur: 630.72s
I - Confusion Matrix: [row->prediction - col->label]
[[1711.    4.   11.   63.  257.]
 [   0.  787.  870.    0.   39.]
 [   4. 1026. 1559.   13.  360.]
 [  42.    6.   17. 1729.  235.]
 [ 105.   15.  181.   89. 6917.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.357 | Acc: 42.125% | Wgt Acc: 44.554%
	I - Batch: 100 | Loss: 5.342 | Acc: 45.000% | Wgt Acc: 45.451%
	I - Batch: 150 | Loss: 5.290 | Acc: 49.333% | Wgt Acc: 47.447%
	I - Batch: 200 | Loss: 5.287 | Acc: 51.594% | Wgt Acc: 48.760%
I - num batch: 238
I - Val -- Loss: 5.334 | Acc: 51.380% | Wgt Acc: 48.223% | Dur: 114.83s
I - Confusion Matrix: [row->prediction - col->label]
[[382.  20.  52. 171.  72.]
 [  3. 378. 316.  22.  83.]
 [ 13. 128. 154.  45. 135.]
 [ 28.  40.  54. 200.  77.]
 [100. 160. 202. 129. 841.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 2.179 | Acc: 80.250% | Wgt Acc: 76.856%
	I - Batch: 100 | Loss: 2.249 | Acc: 79.500% | Wgt Acc: 74.947%
	I - Batch: 150 | Loss: 2.214 | Acc: 79.542% | Wgt Acc: 75.251%
	I - Batch: 200 | Loss: 2.188 | Acc: 80.219% | Wgt Acc: 76.083%
	I - Batch: 250 | Loss: 2.172 | Acc: 80.525% | Wgt Acc: 76.495%
	I - Batch: 300 | Loss: 2.196 | Acc: 80.396% | Wgt Acc: 76.265%
	I - Batch: 350 | Loss: 2.202 | Acc: 80.339% | Wgt Acc: 76.287%
	I - Batch: 400 | Loss: 2.216 | Acc: 80.000% | Wgt Acc: 75.715%
	I - Batch: 450 | Loss: 2.221 | Acc: 80.056% | Wgt Acc: 75.924%
	I - Batch: 500 | Loss: 2.221 | Acc: 80.000% | Wgt Acc: 75.847%
	I - Batch: 550 | Loss: 2.221 | Acc: 79.966% | Wgt Acc: 75.732%
	I - Batch: 600 | Loss: 2.218 | Acc: 80.094% | Wgt Acc: 75.890%
	I - Batch: 650 | Loss: 2.221 | Acc: 79.981% | Wgt Acc: 75.847%
	I - Batch: 700 | Loss: 2.223 | Acc: 79.759% | Wgt Acc: 75.610%
	I - Batch: 750 | Loss: 2.223 | Acc: 79.825% | Wgt Acc: 75.729%
	I - Batch: 800 | Loss: 2.225 | Acc: 79.812% | Wgt Acc: 75.671%
	I - Batch: 850 | Loss: 2.224 | Acc: 79.897% | Wgt Acc: 75.746%
	I - Batch: 900 | Loss: 2.216 | Acc: 80.028% | Wgt Acc: 75.915%
	I - Batch: 950 | Loss: 2.215 | Acc: 80.079% | Wgt Acc: 75.952%
	I - Batch: 1000 | Loss: 2.211 | Acc: 80.181% | Wgt Acc: 76.070%
I - num batch: 1003
I - Train -- Loss: 2.211 | Acc: 80.193% | Wgt Acc: 76.075% | LR: 1.250000e-04 | Dur: 630.46s
I - Confusion Matrix: [row->prediction - col->label]
[[1726.    4.   10.   37.  270.]
 [   1.  820.  861.    0.   28.]
 [   5.  993. 1581.    4.  311.]
 [  25.    9.   13. 1763.  226.]
 [ 105.   12.  173.   90. 6973.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.406 | Acc: 44.000% | Wgt Acc: 45.032%
	I - Batch: 100 | Loss: 5.344 | Acc: 46.500% | Wgt Acc: 46.102%
	I - Batch: 150 | Loss: 5.298 | Acc: 50.292% | Wgt Acc: 48.159%
	I - Batch: 200 | Loss: 5.277 | Acc: 53.094% | Wgt Acc: 49.726%
I - num batch: 238
I - Val -- Loss: 5.308 | Acc: 53.141% | Wgt Acc: 49.749% | Dur: 114.97s
I - Confusion Matrix: [row->prediction - col->label]
[[332.  18.  30.  73.  48.]
 [  1. 298. 246.  11.  48.]
 [ 13. 218. 228.  54. 162.]
 [ 87.  42.  62. 328. 114.]
 [ 93. 150. 212. 101. 836.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 2.096 | Acc: 83.375% | Wgt Acc: 77.987%
	I - Batch: 100 | Loss: 2.134 | Acc: 82.000% | Wgt Acc: 77.347%
	I - Batch: 150 | Loss: 2.165 | Acc: 80.958% | Wgt Acc: 75.911%
	I - Batch: 200 | Loss: 2.161 | Acc: 81.469% | Wgt Acc: 76.813%
	I - Batch: 250 | Loss: 2.151 | Acc: 81.200% | Wgt Acc: 76.699%
	I - Batch: 300 | Loss: 2.146 | Acc: 81.354% | Wgt Acc: 76.813%
	I - Batch: 350 | Loss: 2.149 | Acc: 81.357% | Wgt Acc: 76.765%
	I - Batch: 400 | Loss: 2.154 | Acc: 81.391% | Wgt Acc: 76.588%
	I - Batch: 450 | Loss: 2.154 | Acc: 81.403% | Wgt Acc: 76.617%
	I - Batch: 500 | Loss: 2.156 | Acc: 81.600% | Wgt Acc: 76.849%
	I - Batch: 550 | Loss: 2.161 | Acc: 81.523% | Wgt Acc: 76.857%
	I - Batch: 600 | Loss: 2.162 | Acc: 81.562% | Wgt Acc: 76.905%
	I - Batch: 650 | Loss: 2.165 | Acc: 81.558% | Wgt Acc: 76.899%
	I - Batch: 700 | Loss: 2.172 | Acc: 81.250% | Wgt Acc: 76.600%
	I - Batch: 750 | Loss: 2.176 | Acc: 81.142% | Wgt Acc: 76.479%
	I - Batch: 800 | Loss: 2.177 | Acc: 81.133% | Wgt Acc: 76.536%
	I - Batch: 850 | Loss: 2.180 | Acc: 80.949% | Wgt Acc: 76.354%
	I - Batch: 900 | Loss: 2.187 | Acc: 80.708% | Wgt Acc: 76.131%
	I - Batch: 950 | Loss: 2.189 | Acc: 80.776% | Wgt Acc: 76.213%
	I - Batch: 1000 | Loss: 2.190 | Acc: 80.787% | Wgt Acc: 76.228%
I - num batch: 1003
I - Train -- Loss: 2.189 | Acc: 80.810% | Wgt Acc: 76.255% | LR: 1.250000e-04 | Dur: 630.84s
I - Confusion Matrix: [row->prediction - col->label]
[[1715.    5.   13.   38.  235.]
 [   0.  811.  875.    0.   23.]
 [   9. 1006. 1588.    8.  272.]
 [  43.    5.   10. 1765.  195.]
 [  95.   11.  152.   83. 7083.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.772 | Acc: 33.000% | Wgt Acc: 33.743%
	I - Batch: 100 | Loss: 5.658 | Acc: 39.438% | Wgt Acc: 36.422%
	I - Batch: 150 | Loss: 5.534 | Acc: 46.833% | Wgt Acc: 39.743%
	I - Batch: 200 | Loss: 5.458 | Acc: 50.750% | Wgt Acc: 41.971%
I - num batch: 238
I - Val -- Loss: 5.470 | Acc: 51.564% | Wgt Acc: 42.512% | Dur: 114.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 336.   16.   44.  117.   35.]
 [   1.  188.  136.    2.   15.]
 [   1.  188.  150.   19.   48.]
 [  38.   24.   30.  232.   54.]
 [ 150.  310.  418.  197. 1056.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 2.154 | Acc: 83.500% | Wgt Acc: 79.204%
	I - Batch: 100 | Loss: 2.155 | Acc: 81.875% | Wgt Acc: 77.214%
	I - Batch: 150 | Loss: 2.146 | Acc: 82.542% | Wgt Acc: 78.301%
	I - Batch: 200 | Loss: 2.137 | Acc: 82.406% | Wgt Acc: 78.260%
	I - Batch: 250 | Loss: 2.127 | Acc: 82.825% | Wgt Acc: 78.660%
	I - Batch: 300 | Loss: 2.119 | Acc: 83.083% | Wgt Acc: 78.883%
	I - Batch: 350 | Loss: 2.121 | Acc: 82.929% | Wgt Acc: 78.737%
	I - Batch: 400 | Loss: 2.112 | Acc: 83.109% | Wgt Acc: 78.838%
	I - Batch: 450 | Loss: 2.112 | Acc: 82.917% | Wgt Acc: 78.592%
	I - Batch: 500 | Loss: 2.106 | Acc: 83.037% | Wgt Acc: 78.713%
	I - Batch: 550 | Loss: 2.106 | Acc: 83.125% | Wgt Acc: 78.791%
	I - Batch: 600 | Loss: 2.109 | Acc: 83.104% | Wgt Acc: 78.797%
	I - Batch: 650 | Loss: 2.104 | Acc: 83.231% | Wgt Acc: 78.985%
	I - Batch: 700 | Loss: 2.106 | Acc: 83.125% | Wgt Acc: 78.829%
	I - Batch: 750 | Loss: 2.108 | Acc: 82.975% | Wgt Acc: 78.685%
	I - Batch: 800 | Loss: 2.111 | Acc: 82.867% | Wgt Acc: 78.581%
	I - Batch: 850 | Loss: 2.115 | Acc: 82.684% | Wgt Acc: 78.370%
	I - Batch: 900 | Loss: 2.116 | Acc: 82.743% | Wgt Acc: 78.517%
	I - Batch: 950 | Loss: 2.119 | Acc: 82.697% | Wgt Acc: 78.436%
	I - Batch: 1000 | Loss: 2.119 | Acc: 82.644% | Wgt Acc: 78.356%
I - num batch: 1003
I - Train -- Loss: 2.118 | Acc: 82.662% | Wgt Acc: 78.377% | LR: 1.250000e-04 | Dur: 630.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1756.    5.    8.   15.  196.]
 [   0.  863.  833.    0.   26.]
 [   6.  960. 1647.    3.  244.]
 [  19.    1.    6. 1805.  154.]
 [  81.    9.  144.   71. 7188.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.755 | Acc: 38.500% | Wgt Acc: 38.847%
	I - Batch: 100 | Loss: 5.636 | Acc: 43.188% | Wgt Acc: 40.596%
	I - Batch: 150 | Loss: 5.501 | Acc: 49.167% | Wgt Acc: 42.972%
	I - Batch: 200 | Loss: 5.433 | Acc: 52.219% | Wgt Acc: 44.422%
I - num batch: 238
I - Val -- Loss: 5.436 | Acc: 53.298% | Wgt Acc: 45.029% | Dur: 114.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 344.   18.   32.  124.   44.]
 [   0.  184.   68.    3.   15.]
 [   7.  222.  202.   18.   54.]
 [  50.   46.   52.  268.   65.]
 [ 125.  256.  424.  154. 1030.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 2.176 | Acc: 81.125% | Wgt Acc: 75.851%
	I - Batch: 100 | Loss: 2.139 | Acc: 81.625% | Wgt Acc: 76.889%
	I - Batch: 150 | Loss: 2.105 | Acc: 82.833% | Wgt Acc: 78.495%
	I - Batch: 200 | Loss: 2.110 | Acc: 82.531% | Wgt Acc: 78.267%
	I - Batch: 250 | Loss: 2.097 | Acc: 83.000% | Wgt Acc: 78.723%
	I - Batch: 300 | Loss: 2.101 | Acc: 82.708% | Wgt Acc: 78.493%
	I - Batch: 350 | Loss: 2.093 | Acc: 82.875% | Wgt Acc: 78.628%
	I - Batch: 400 | Loss: 2.086 | Acc: 83.031% | Wgt Acc: 78.719%
	I - Batch: 450 | Loss: 2.081 | Acc: 83.306% | Wgt Acc: 78.947%
	I - Batch: 500 | Loss: 2.074 | Acc: 83.438% | Wgt Acc: 79.054%
	I - Batch: 550 | Loss: 2.078 | Acc: 83.375% | Wgt Acc: 78.921%
	I - Batch: 600 | Loss: 2.076 | Acc: 83.469% | Wgt Acc: 78.996%
	I - Batch: 650 | Loss: 2.078 | Acc: 83.365% | Wgt Acc: 78.894%
	I - Batch: 700 | Loss: 2.081 | Acc: 83.304% | Wgt Acc: 78.743%
	I - Batch: 750 | Loss: 2.097 | Acc: 82.975% | Wgt Acc: 78.395%
	I - Batch: 800 | Loss: 2.101 | Acc: 82.930% | Wgt Acc: 78.363%
	I - Batch: 850 | Loss: 2.110 | Acc: 82.721% | Wgt Acc: 78.078%
	I - Batch: 900 | Loss: 2.113 | Acc: 82.792% | Wgt Acc: 78.126%
	I - Batch: 950 | Loss: 2.112 | Acc: 82.862% | Wgt Acc: 78.221%
	I - Batch: 1000 | Loss: 2.111 | Acc: 82.894% | Wgt Acc: 78.212%
I - num batch: 1003
I - Train -- Loss: 2.111 | Acc: 82.880% | Wgt Acc: 78.199% | LR: 1.250000e-04 | Dur: 630.51s
I - Confusion Matrix: [row->prediction - col->label]
[[1752.    4.    9.   25.  187.]
 [   0.  753.  708.    0.   20.]
 [   4. 1069. 1790.    5.  229.]
 [  20.    1.   13. 1800.  173.]
 [  86.   11.  118.   64. 7199.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.534 | Acc: 40.000% | Wgt Acc: 41.450%
	I - Batch: 100 | Loss: 5.466 | Acc: 45.375% | Wgt Acc: 44.266%
	I - Batch: 150 | Loss: 5.393 | Acc: 51.208% | Wgt Acc: 47.193%
	I - Batch: 200 | Loss: 5.366 | Acc: 53.281% | Wgt Acc: 48.027%
I - num batch: 238
I - Val -- Loss: 5.384 | Acc: 54.271% | Wgt Acc: 48.668% | Dur: 114.73s
I - Confusion Matrix: [row->prediction - col->label]
[[311.  12.  32.  73.  40.]
 [  2. 282. 178.  11.  21.]
 [ 13. 150. 188.  25. 109.]
 [ 81.  58.  72. 333.  87.]
 [119. 224. 308. 125. 951.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 2.088 | Acc: 83.125% | Wgt Acc: 78.508%
	I - Batch: 100 | Loss: 2.094 | Acc: 82.875% | Wgt Acc: 78.153%
	I - Batch: 150 | Loss: 2.128 | Acc: 82.542% | Wgt Acc: 77.646%
	I - Batch: 200 | Loss: 2.118 | Acc: 82.594% | Wgt Acc: 78.177%
	I - Batch: 250 | Loss: 2.119 | Acc: 82.575% | Wgt Acc: 78.210%
	I - Batch: 300 | Loss: 2.102 | Acc: 83.167% | Wgt Acc: 78.736%
	I - Batch: 350 | Loss: 2.095 | Acc: 83.250% | Wgt Acc: 78.738%
	I - Batch: 400 | Loss: 2.095 | Acc: 83.172% | Wgt Acc: 78.628%
	I - Batch: 450 | Loss: 2.094 | Acc: 83.125% | Wgt Acc: 78.554%
	I - Batch: 500 | Loss: 2.103 | Acc: 83.125% | Wgt Acc: 78.512%
	I - Batch: 550 | Loss: 2.121 | Acc: 82.818% | Wgt Acc: 78.196%
	I - Batch: 600 | Loss: 2.119 | Acc: 82.906% | Wgt Acc: 78.409%
	I - Batch: 650 | Loss: 2.126 | Acc: 82.769% | Wgt Acc: 78.185%
	I - Batch: 700 | Loss: 2.140 | Acc: 82.482% | Wgt Acc: 78.014%
	I - Batch: 750 | Loss: 2.153 | Acc: 82.217% | Wgt Acc: 77.646%
	I - Batch: 800 | Loss: 2.165 | Acc: 81.977% | Wgt Acc: 77.503%
	I - Batch: 850 | Loss: 2.169 | Acc: 81.897% | Wgt Acc: 77.483%
	I - Batch: 900 | Loss: 2.170 | Acc: 81.875% | Wgt Acc: 77.472%
	I - Batch: 950 | Loss: 2.169 | Acc: 81.974% | Wgt Acc: 77.639%
	I - Batch: 1000 | Loss: 2.171 | Acc: 81.938% | Wgt Acc: 77.604%
I - num batch: 1003
I - Train -- Loss: 2.173 | Acc: 81.901% | Wgt Acc: 77.582% | LR: 1.250000e-04 | Dur: 628.16s
I - Confusion Matrix: [row->prediction - col->label]
[[1740.    3.   13.   46.  225.]
 [   0.  808.  728.    0.   21.]
 [   6. 1010. 1736.    6.  293.]
 [  27.    4.   10. 1763.  179.]
 [  89.   13.  151.   79. 7090.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.268 | Acc: 48.625% | Wgt Acc: 49.875%
	I - Batch: 100 | Loss: 5.301 | Acc: 49.750% | Wgt Acc: 50.815%
	I - Batch: 150 | Loss: 5.282 | Acc: 50.833% | Wgt Acc: 51.462%
	I - Batch: 200 | Loss: 5.295 | Acc: 51.188% | Wgt Acc: 51.435%
I - num batch: 238
I - Val -- Loss: 5.315 | Acc: 51.012% | Wgt Acc: 51.417% | Dur: 115.48s
I - Confusion Matrix: [row->prediction - col->label]
[[328.  26.  44.  98.  71.]
 [  2. 332. 248.   4.  55.]
 [ 13. 190. 224.  34. 214.]
 [142.  88. 150. 397. 208.]
 [ 41.  90. 112.  34. 660.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 2.142 | Acc: 82.500% | Wgt Acc: 75.899%
	I - Batch: 100 | Loss: 2.130 | Acc: 83.125% | Wgt Acc: 77.422%
	I - Batch: 150 | Loss: 2.124 | Acc: 83.458% | Wgt Acc: 78.247%
	I - Batch: 200 | Loss: 2.136 | Acc: 82.969% | Wgt Acc: 77.878%
	I - Batch: 250 | Loss: 2.136 | Acc: 83.000% | Wgt Acc: 77.877%
	I - Batch: 300 | Loss: 2.136 | Acc: 82.917% | Wgt Acc: 77.987%
	I - Batch: 350 | Loss: 2.157 | Acc: 82.286% | Wgt Acc: 77.551%
	I - Batch: 400 | Loss: 2.164 | Acc: 82.156% | Wgt Acc: 77.578%
	I - Batch: 450 | Loss: 2.163 | Acc: 82.153% | Wgt Acc: 77.724%
	I - Batch: 500 | Loss: 2.170 | Acc: 82.088% | Wgt Acc: 77.639%
	I - Batch: 550 | Loss: 2.172 | Acc: 82.136% | Wgt Acc: 77.694%
	I - Batch: 600 | Loss: 2.173 | Acc: 82.219% | Wgt Acc: 77.755%
	I - Batch: 650 | Loss: 2.174 | Acc: 82.298% | Wgt Acc: 77.914%
	I - Batch: 700 | Loss: 2.171 | Acc: 82.384% | Wgt Acc: 77.955%
	I - Batch: 750 | Loss: 2.185 | Acc: 82.250% | Wgt Acc: 77.827%
	I - Batch: 800 | Loss: 2.192 | Acc: 82.102% | Wgt Acc: 77.706%
	I - Batch: 850 | Loss: 2.195 | Acc: 81.919% | Wgt Acc: 77.465%
	I - Batch: 900 | Loss: 2.199 | Acc: 81.694% | Wgt Acc: 77.260%
	I - Batch: 950 | Loss: 2.194 | Acc: 81.816% | Wgt Acc: 77.455%
	I - Batch: 1000 | Loss: 2.193 | Acc: 81.844% | Wgt Acc: 77.458%
I - num batch: 1003
I - Train -- Loss: 2.194 | Acc: 81.827% | Wgt Acc: 77.436% | LR: 1.250000e-04 | Dur: 639.76s
I - Confusion Matrix: [row->prediction - col->label]
[[1714.    3.   12.   47.  233.]
 [   0.  731.  549.    1.   14.]
 [   8. 1085. 1884.    8.  331.]
 [  35.    3.   14. 1765.  199.]
 [ 105.   16.  179.   73. 7031.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.516 | Acc: 45.375% | Wgt Acc: 46.005%
	I - Batch: 100 | Loss: 5.474 | Acc: 45.375% | Wgt Acc: 44.104%
	I - Batch: 150 | Loss: 5.377 | Acc: 49.417% | Wgt Acc: 45.853%
	I - Batch: 200 | Loss: 5.350 | Acc: 51.688% | Wgt Acc: 47.137%
I - num batch: 238
I - Val -- Loss: 5.361 | Acc: 52.510% | Wgt Acc: 47.871% | Dur: 117.95s
I - Confusion Matrix: [row->prediction - col->label]
[[260.  20.  26.  31.  50.]
 [  0. 242. 154.   3.  25.]
 [  7. 208. 204.  33. 101.]
 [177.  94. 146. 417. 157.]
 [ 82. 162. 248.  83. 875.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 2.207 | Acc: 83.000% | Wgt Acc: 78.237%
	I - Batch: 100 | Loss: 2.168 | Acc: 82.688% | Wgt Acc: 78.183%
	I - Batch: 150 | Loss: 2.126 | Acc: 83.125% | Wgt Acc: 78.811%
	I - Batch: 200 | Loss: 2.124 | Acc: 83.438% | Wgt Acc: 79.316%
	I - Batch: 250 | Loss: 2.112 | Acc: 83.400% | Wgt Acc: 79.075%
	I - Batch: 300 | Loss: 2.116 | Acc: 83.167% | Wgt Acc: 78.836%
	I - Batch: 350 | Loss: 2.111 | Acc: 83.107% | Wgt Acc: 78.776%
	I - Batch: 400 | Loss: 2.094 | Acc: 83.438% | Wgt Acc: 79.079%
	I - Batch: 450 | Loss: 2.085 | Acc: 83.819% | Wgt Acc: 79.440%
	I - Batch: 500 | Loss: 2.080 | Acc: 83.950% | Wgt Acc: 79.463%
	I - Batch: 550 | Loss: 2.071 | Acc: 84.170% | Wgt Acc: 79.702%
	I - Batch: 600 | Loss: 2.077 | Acc: 84.031% | Wgt Acc: 79.523%
	I - Batch: 650 | Loss: 2.070 | Acc: 84.202% | Wgt Acc: 79.844%
	I - Batch: 700 | Loss: 2.070 | Acc: 84.277% | Wgt Acc: 79.892%
	I - Batch: 750 | Loss: 2.068 | Acc: 84.408% | Wgt Acc: 80.030%
	I - Batch: 800 | Loss: 2.070 | Acc: 84.281% | Wgt Acc: 79.814%
	I - Batch: 850 | Loss: 2.075 | Acc: 84.257% | Wgt Acc: 79.694%
	I - Batch: 900 | Loss: 2.086 | Acc: 84.076% | Wgt Acc: 79.494%
	I - Batch: 950 | Loss: 2.090 | Acc: 84.007% | Wgt Acc: 79.419%
	I - Batch: 1000 | Loss: 2.093 | Acc: 83.950% | Wgt Acc: 79.388%
I - num batch: 1003
I - Train -- Loss: 2.093 | Acc: 83.953% | Wgt Acc: 79.397% | LR: 1.250000e-04 | Dur: 643.33s
I - Confusion Matrix: [row->prediction - col->label]
[[1761.    3.    9.   21.  192.]
 [   0.  738.  533.    0.    9.]
 [   1. 1092. 1966.   12.  247.]
 [  22.    2.    9. 1793.  152.]
 [  78.    3.  121.   68. 7208.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.620 | Acc: 38.375% | Wgt Acc: 39.396%
	I - Batch: 100 | Loss: 5.516 | Acc: 43.562% | Wgt Acc: 42.730%
	I - Batch: 150 | Loss: 5.415 | Acc: 48.792% | Wgt Acc: 45.673%
	I - Batch: 200 | Loss: 5.382 | Acc: 51.500% | Wgt Acc: 47.621%
I - num batch: 238
I - Val -- Loss: 5.410 | Acc: 51.958% | Wgt Acc: 47.810% | Dur: 116.08s
I - Confusion Matrix: [row->prediction - col->label]
[[411.  38.  64. 179. 160.]
 [  1. 264. 170.  13.  30.]
 [ 11. 180. 216.  39.  94.]
 [ 50.  28.  28. 231.  69.]
 [ 53. 216. 300. 105. 855.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 2.037 | Acc: 84.125% | Wgt Acc: 78.892%
	I - Batch: 100 | Loss: 2.090 | Acc: 83.188% | Wgt Acc: 78.451%
	I - Batch: 150 | Loss: 2.117 | Acc: 82.750% | Wgt Acc: 77.865%
	I - Batch: 200 | Loss: 2.143 | Acc: 82.844% | Wgt Acc: 78.169%
	I - Batch: 250 | Loss: 2.155 | Acc: 82.875% | Wgt Acc: 78.353%
	I - Batch: 300 | Loss: 2.134 | Acc: 83.625% | Wgt Acc: 79.404%
	I - Batch: 350 | Loss: 2.119 | Acc: 84.054% | Wgt Acc: 80.027%
	I - Batch: 400 | Loss: 2.117 | Acc: 84.219% | Wgt Acc: 80.085%
	I - Batch: 450 | Loss: 2.113 | Acc: 84.236% | Wgt Acc: 80.075%
	I - Batch: 500 | Loss: 2.114 | Acc: 84.013% | Wgt Acc: 79.815%
	I - Batch: 550 | Loss: 2.112 | Acc: 83.841% | Wgt Acc: 79.516%
	I - Batch: 600 | Loss: 2.113 | Acc: 83.792% | Wgt Acc: 79.604%
	I - Batch: 650 | Loss: 2.112 | Acc: 83.760% | Wgt Acc: 79.537%
	I - Batch: 700 | Loss: 2.112 | Acc: 83.723% | Wgt Acc: 79.549%
	I - Batch: 750 | Loss: 2.110 | Acc: 83.833% | Wgt Acc: 79.766%
	I - Batch: 800 | Loss: 2.106 | Acc: 83.789% | Wgt Acc: 79.622%
	I - Batch: 850 | Loss: 2.105 | Acc: 83.809% | Wgt Acc: 79.652%
	I - Batch: 900 | Loss: 2.104 | Acc: 83.806% | Wgt Acc: 79.727%
	I - Batch: 950 | Loss: 2.100 | Acc: 83.954% | Wgt Acc: 79.892%
	I - Batch: 1000 | Loss: 2.097 | Acc: 83.994% | Wgt Acc: 79.919%
I - num batch: 1003
I - Train -- Loss: 2.096 | Acc: 84.015% | Wgt Acc: 79.945% | LR: 1.250000e-04 | Dur: 630.20s
I - Confusion Matrix: [row->prediction - col->label]
[[1757.    4.    7.   20.  182.]
 [   0.  786.  495.    1.   11.]
 [   7. 1043. 1982.    5.  313.]
 [  20.    3.   19. 1807.  158.]
 [  78.    2.  135.   61. 7144.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.388 | Acc: 47.125% | Wgt Acc: 45.929%
	I - Batch: 100 | Loss: 5.333 | Acc: 51.188% | Wgt Acc: 48.419%
	I - Batch: 150 | Loss: 5.297 | Acc: 53.333% | Wgt Acc: 49.311%
	I - Batch: 200 | Loss: 5.281 | Acc: 55.219% | Wgt Acc: 50.557%
I - num batch: 238
I - Val -- Loss: 5.300 | Acc: 55.217% | Wgt Acc: 50.859% | Dur: 114.88s
I - Confusion Matrix: [row->prediction - col->label]
[[340.  14.  26.  78.  37.]
 [  0. 208. 112.   3.  22.]
 [ 23. 342. 412.  45. 228.]
 [ 62.  36.  50. 313.  93.]
 [101. 126. 178. 128. 828.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 2.048 | Acc: 84.250% | Wgt Acc: 80.066%
	I - Batch: 100 | Loss: 2.067 | Acc: 83.562% | Wgt Acc: 78.409%
	I - Batch: 150 | Loss: 2.051 | Acc: 84.375% | Wgt Acc: 79.835%
	I - Batch: 200 | Loss: 2.051 | Acc: 84.938% | Wgt Acc: 80.828%
	I - Batch: 250 | Loss: 2.041 | Acc: 85.300% | Wgt Acc: 81.392%
	I - Batch: 300 | Loss: 2.060 | Acc: 84.812% | Wgt Acc: 80.594%
	I - Batch: 350 | Loss: 2.079 | Acc: 84.482% | Wgt Acc: 80.214%
	I - Batch: 400 | Loss: 2.093 | Acc: 84.094% | Wgt Acc: 79.918%
	I - Batch: 450 | Loss: 2.082 | Acc: 84.542% | Wgt Acc: 80.493%
	I - Batch: 500 | Loss: 2.075 | Acc: 84.750% | Wgt Acc: 80.629%
	I - Batch: 550 | Loss: 2.070 | Acc: 84.795% | Wgt Acc: 80.658%
	I - Batch: 600 | Loss: 2.069 | Acc: 84.854% | Wgt Acc: 80.687%
	I - Batch: 650 | Loss: 2.067 | Acc: 85.058% | Wgt Acc: 81.015%
	I - Batch: 700 | Loss: 2.069 | Acc: 84.848% | Wgt Acc: 80.797%
	I - Batch: 750 | Loss: 2.084 | Acc: 84.658% | Wgt Acc: 80.626%
	I - Batch: 800 | Loss: 2.088 | Acc: 84.539% | Wgt Acc: 80.503%
	I - Batch: 850 | Loss: 2.095 | Acc: 84.404% | Wgt Acc: 80.340%
	I - Batch: 900 | Loss: 2.104 | Acc: 84.201% | Wgt Acc: 80.136%
	I - Batch: 950 | Loss: 2.110 | Acc: 84.191% | Wgt Acc: 80.247%
	I - Batch: 1000 | Loss: 2.113 | Acc: 84.075% | Wgt Acc: 80.150%
I - num batch: 1003
I - Train -- Loss: 2.114 | Acc: 84.071% | Wgt Acc: 80.131% | LR: 1.250000e-04 | Dur: 629.82s
I - Confusion Matrix: [row->prediction - col->label]
[[1759.    4.    7.   33.  212.]
 [   0.  788.  424.    1.    7.]
 [   5. 1036. 2063.   12.  332.]
 [  23.    3.   16. 1773.  155.]
 [  75.    7.  128.   75. 7102.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.601 | Acc: 42.250% | Wgt Acc: 39.917%
	I - Batch: 100 | Loss: 5.509 | Acc: 45.688% | Wgt Acc: 41.306%
	I - Batch: 150 | Loss: 5.417 | Acc: 50.750% | Wgt Acc: 43.531%
	I - Batch: 200 | Loss: 5.372 | Acc: 53.938% | Wgt Acc: 45.868%
I - num batch: 238
I - Val -- Loss: 5.392 | Acc: 53.850% | Wgt Acc: 45.443% | Dur: 114.73s
I - Confusion Matrix: [row->prediction - col->label]
[[368.  12.  34. 133.  61.]
 [  0.  60.   2.   0.   5.]
 [ 17. 424. 434.  43. 149.]
 [ 50.  22.  40. 239.  45.]
 [ 91. 208. 268. 152. 948.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 2.143 | Acc: 83.500% | Wgt Acc: 81.275%
	I - Batch: 100 | Loss: 2.122 | Acc: 83.562% | Wgt Acc: 80.531%
	I - Batch: 150 | Loss: 2.127 | Acc: 83.500% | Wgt Acc: 80.132%
	I - Batch: 200 | Loss: 2.129 | Acc: 83.562% | Wgt Acc: 79.935%
	I - Batch: 250 | Loss: 2.123 | Acc: 83.725% | Wgt Acc: 80.258%
	I - Batch: 300 | Loss: 2.115 | Acc: 84.292% | Wgt Acc: 80.730%
	I - Batch: 350 | Loss: 2.120 | Acc: 84.268% | Wgt Acc: 80.453%
	I - Batch: 400 | Loss: 2.113 | Acc: 84.203% | Wgt Acc: 80.307%
	I - Batch: 450 | Loss: 2.112 | Acc: 84.111% | Wgt Acc: 80.169%
	I - Batch: 500 | Loss: 2.109 | Acc: 84.150% | Wgt Acc: 80.221%
	I - Batch: 550 | Loss: 2.101 | Acc: 84.420% | Wgt Acc: 80.585%
	I - Batch: 600 | Loss: 2.104 | Acc: 84.146% | Wgt Acc: 80.219%
	I - Batch: 650 | Loss: 2.103 | Acc: 84.087% | Wgt Acc: 80.124%
	I - Batch: 700 | Loss: 2.102 | Acc: 84.152% | Wgt Acc: 80.143%
	I - Batch: 750 | Loss: 2.097 | Acc: 84.175% | Wgt Acc: 80.216%
	I - Batch: 800 | Loss: 2.099 | Acc: 84.148% | Wgt Acc: 80.158%
	I - Batch: 850 | Loss: 2.099 | Acc: 84.162% | Wgt Acc: 80.107%
	I - Batch: 900 | Loss: 2.101 | Acc: 84.111% | Wgt Acc: 80.058%
	I - Batch: 950 | Loss: 2.100 | Acc: 84.270% | Wgt Acc: 80.320%
	I - Batch: 1000 | Loss: 2.097 | Acc: 84.438% | Wgt Acc: 80.512%
I - num batch: 1003
I - Train -- Loss: 2.097 | Acc: 84.426% | Wgt Acc: 80.492% | LR: 1.250000e-04 | Dur: 631.35s
I - Confusion Matrix: [row->prediction - col->label]
[[1732.    4.    9.   25.  204.]
 [   0.  795.  383.    0.   11.]
 [   9. 1031. 2092.    2.  314.]
 [  24.    2.   15. 1803.  159.]
 [  97.    6.  139.   64. 7120.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.591 | Acc: 41.500% | Wgt Acc: 39.390%
	I - Batch: 100 | Loss: 5.515 | Acc: 45.688% | Wgt Acc: 41.799%
	I - Batch: 150 | Loss: 5.433 | Acc: 49.833% | Wgt Acc: 43.748%
	I - Batch: 200 | Loss: 5.384 | Acc: 52.500% | Wgt Acc: 45.843%
I - num batch: 238
I - Val -- Loss: 5.401 | Acc: 52.247% | Wgt Acc: 45.729% | Dur: 115.63s
I - Confusion Matrix: [row->prediction - col->label]
[[308.  10.  24.  76.  40.]
 [  0. 108.   8.   2.   6.]
 [ 24. 432. 444.  77. 246.]
 [ 66.  30.  42. 279.  67.]
 [128. 146. 260. 133. 849.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 2.029 | Acc: 85.750% | Wgt Acc: 81.895%
	I - Batch: 100 | Loss: 2.034 | Acc: 84.875% | Wgt Acc: 81.016%
	I - Batch: 150 | Loss: 2.022 | Acc: 86.167% | Wgt Acc: 82.866%
	I - Batch: 200 | Loss: 2.009 | Acc: 86.719% | Wgt Acc: 83.672%
	I - Batch: 250 | Loss: 2.017 | Acc: 86.250% | Wgt Acc: 82.988%
	I - Batch: 300 | Loss: 2.016 | Acc: 86.208% | Wgt Acc: 82.840%
	I - Batch: 350 | Loss: 2.029 | Acc: 85.696% | Wgt Acc: 82.086%
	I - Batch: 400 | Loss: 2.023 | Acc: 86.172% | Wgt Acc: 82.752%
	I - Batch: 450 | Loss: 2.036 | Acc: 85.972% | Wgt Acc: 82.530%
	I - Batch: 500 | Loss: 2.044 | Acc: 85.625% | Wgt Acc: 82.248%
	I - Batch: 550 | Loss: 2.049 | Acc: 85.534% | Wgt Acc: 82.277%
	I - Batch: 600 | Loss: 2.054 | Acc: 85.521% | Wgt Acc: 82.270%
	I - Batch: 650 | Loss: 2.065 | Acc: 85.346% | Wgt Acc: 82.101%
	I - Batch: 700 | Loss: 2.068 | Acc: 85.304% | Wgt Acc: 82.112%
	I - Batch: 750 | Loss: 2.075 | Acc: 85.142% | Wgt Acc: 81.898%
	I - Batch: 800 | Loss: 2.077 | Acc: 85.320% | Wgt Acc: 82.226%
	I - Batch: 850 | Loss: 2.081 | Acc: 85.147% | Wgt Acc: 81.957%
	I - Batch: 900 | Loss: 2.080 | Acc: 85.201% | Wgt Acc: 82.036%
	I - Batch: 950 | Loss: 2.077 | Acc: 85.276% | Wgt Acc: 82.120%
	I - Batch: 1000 | Loss: 2.082 | Acc: 85.162% | Wgt Acc: 81.961%
I - num batch: 1003
I - Train -- Loss: 2.083 | Acc: 85.137% | Wgt Acc: 81.937% | LR: 1.250000e-04 | Dur: 632.78s
I - Confusion Matrix: [row->prediction - col->label]
[[1752.    4.   12.   21.  225.]
 [   0.  871.  338.    0.   11.]
 [   8.  957. 2167.    7.  353.]
 [  15.    2.    9. 1807.  160.]
 [  87.    4.  112.   59. 7059.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.644 | Acc: 43.000% | Wgt Acc: 42.505%
	I - Batch: 100 | Loss: 5.523 | Acc: 46.500% | Wgt Acc: 43.623%
	I - Batch: 150 | Loss: 5.431 | Acc: 50.708% | Wgt Acc: 44.737%
	I - Batch: 200 | Loss: 5.383 | Acc: 53.625% | Wgt Acc: 46.605%
I - num batch: 238
I - Val -- Loss: 5.404 | Acc: 54.192% | Wgt Acc: 47.129% | Dur: 114.63s
I - Confusion Matrix: [row->prediction - col->label]
[[295.   4.  16.  79.  43.]
 [  0. 202.  54.   4.  16.]
 [ 23. 278. 344.  50. 138.]
 [ 76.  36.  64. 278.  68.]
 [132. 206. 300. 156. 943.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 2.070 | Acc: 85.500% | Wgt Acc: 82.281%
	I - Batch: 100 | Loss: 2.044 | Acc: 86.812% | Wgt Acc: 83.676%
	I - Batch: 150 | Loss: 2.053 | Acc: 86.750% | Wgt Acc: 83.624%
	I - Batch: 200 | Loss: 2.040 | Acc: 86.469% | Wgt Acc: 83.210%
	I - Batch: 250 | Loss: 2.045 | Acc: 86.300% | Wgt Acc: 82.855%
	I - Batch: 300 | Loss: 2.047 | Acc: 86.042% | Wgt Acc: 82.724%
	I - Batch: 350 | Loss: 2.050 | Acc: 85.911% | Wgt Acc: 82.714%
	I - Batch: 400 | Loss: 2.040 | Acc: 86.203% | Wgt Acc: 83.075%
	I - Batch: 450 | Loss: 2.036 | Acc: 86.319% | Wgt Acc: 83.269%
	I - Batch: 500 | Loss: 2.038 | Acc: 86.250% | Wgt Acc: 83.070%
	I - Batch: 550 | Loss: 2.038 | Acc: 86.318% | Wgt Acc: 83.170%
	I - Batch: 600 | Loss: 2.040 | Acc: 86.125% | Wgt Acc: 82.909%
	I - Batch: 650 | Loss: 2.055 | Acc: 85.798% | Wgt Acc: 82.577%
	I - Batch: 700 | Loss: 2.059 | Acc: 85.634% | Wgt Acc: 82.522%
	I - Batch: 750 | Loss: 2.063 | Acc: 85.417% | Wgt Acc: 82.372%
	I - Batch: 800 | Loss: 2.068 | Acc: 85.195% | Wgt Acc: 82.080%
	I - Batch: 850 | Loss: 2.066 | Acc: 85.250% | Wgt Acc: 82.173%
	I - Batch: 900 | Loss: 2.067 | Acc: 85.243% | Wgt Acc: 82.189%
	I - Batch: 950 | Loss: 2.070 | Acc: 85.237% | Wgt Acc: 82.252%
	I - Batch: 1000 | Loss: 2.074 | Acc: 85.069% | Wgt Acc: 82.078%
I - num batch: 1003
I - Train -- Loss: 2.074 | Acc: 85.087% | Wgt Acc: 82.092% | LR: 1.250000e-04 | Dur: 629.54s
I - Confusion Matrix: [row->prediction - col->label]
[[1758.    4.   13.   23.  238.]
 [   1.  891.  321.    0.    8.]
 [   9.  935. 2165.    9.  377.]
 [  24.    5.    9. 1805.  156.]
 [  70.    3.  130.   57. 7029.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.036 | Acc: 30.875% | Wgt Acc: 30.563%
	I - Batch: 100 | Loss: 5.835 | Acc: 37.562% | Wgt Acc: 33.021%
	I - Batch: 150 | Loss: 5.660 | Acc: 45.083% | Wgt Acc: 36.230%
	I - Batch: 200 | Loss: 5.575 | Acc: 49.312% | Wgt Acc: 38.669%
I - num batch: 238
I - Val -- Loss: 5.564 | Acc: 50.618% | Wgt Acc: 39.503% | Dur: 114.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 312.    8.   30.   75.   30.]
 [   0.   98.   26.    2.    6.]
 [   4.  242.  254.   24.   66.]
 [  40.   22.   22.  185.   29.]
 [ 170.  356.  446.  281. 1077.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 2.041 | Acc: 87.875% | Wgt Acc: 83.907%
	I - Batch: 100 | Loss: 2.064 | Acc: 86.375% | Wgt Acc: 82.610%
	I - Batch: 150 | Loss: 2.077 | Acc: 85.667% | Wgt Acc: 81.852%
	I - Batch: 200 | Loss: 2.081 | Acc: 85.250% | Wgt Acc: 81.523%
	I - Batch: 250 | Loss: 2.062 | Acc: 85.900% | Wgt Acc: 82.355%
	I - Batch: 300 | Loss: 2.068 | Acc: 85.688% | Wgt Acc: 82.200%
	I - Batch: 350 | Loss: 2.066 | Acc: 85.589% | Wgt Acc: 82.160%
	I - Batch: 400 | Loss: 2.072 | Acc: 85.547% | Wgt Acc: 82.212%
	I - Batch: 450 | Loss: 2.069 | Acc: 85.653% | Wgt Acc: 82.373%
	I - Batch: 500 | Loss: 2.059 | Acc: 86.013% | Wgt Acc: 82.782%
	I - Batch: 550 | Loss: 2.057 | Acc: 86.000% | Wgt Acc: 82.772%
	I - Batch: 600 | Loss: 2.066 | Acc: 85.781% | Wgt Acc: 82.438%
	I - Batch: 650 | Loss: 2.063 | Acc: 85.894% | Wgt Acc: 82.623%
	I - Batch: 700 | Loss: 2.065 | Acc: 85.759% | Wgt Acc: 82.510%
	I - Batch: 750 | Loss: 2.060 | Acc: 85.967% | Wgt Acc: 82.770%
	I - Batch: 800 | Loss: 2.059 | Acc: 85.938% | Wgt Acc: 82.770%
	I - Batch: 850 | Loss: 2.051 | Acc: 86.022% | Wgt Acc: 82.897%
	I - Batch: 900 | Loss: 2.050 | Acc: 86.035% | Wgt Acc: 83.002%
	I - Batch: 950 | Loss: 2.043 | Acc: 86.138% | Wgt Acc: 83.103%
	I - Batch: 1000 | Loss: 2.049 | Acc: 85.987% | Wgt Acc: 82.978%
I - num batch: 1003
I - Train -- Loss: 2.049 | Acc: 85.985% | Wgt Acc: 82.964% | LR: 1.250000e-04 | Dur: 629.69s
I - Confusion Matrix: [row->prediction - col->label]
[[1746.    2.   13.    5.  161.]
 [   0.  927.  285.    1.   11.]
 [  11.  901. 2201.   11.  373.]
 [  20.    2.    4. 1819.  164.]
 [  85.    6.  135.   58. 7099.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.630 | Acc: 44.625% | Wgt Acc: 42.499%
	I - Batch: 100 | Loss: 5.546 | Acc: 47.750% | Wgt Acc: 44.923%
	I - Batch: 150 | Loss: 5.456 | Acc: 51.292% | Wgt Acc: 46.598%
	I - Batch: 200 | Loss: 5.397 | Acc: 54.188% | Wgt Acc: 48.762%
I - num batch: 238
I - Val -- Loss: 5.404 | Acc: 54.455% | Wgt Acc: 49.135% | Dur: 114.66s
I - Confusion Matrix: [row->prediction - col->label]
[[394.  14.  46. 154. 103.]
 [  0. 134.  30.   5.   9.]
 [ 12. 358. 442.  39. 166.]
 [ 59.  64.  40. 262.  90.]
 [ 61. 156. 220. 107. 840.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 2.053 | Acc: 85.500% | Wgt Acc: 83.555%
	I - Batch: 100 | Loss: 2.037 | Acc: 85.562% | Wgt Acc: 82.961%
	I - Batch: 150 | Loss: 2.004 | Acc: 86.375% | Wgt Acc: 83.158%
	I - Batch: 200 | Loss: 1.996 | Acc: 86.625% | Wgt Acc: 83.191%
	I - Batch: 250 | Loss: 1.993 | Acc: 87.025% | Wgt Acc: 83.713%
	I - Batch: 300 | Loss: 1.997 | Acc: 86.875% | Wgt Acc: 83.415%
	I - Batch: 350 | Loss: 2.004 | Acc: 86.821% | Wgt Acc: 83.606%
	I - Batch: 400 | Loss: 2.000 | Acc: 87.203% | Wgt Acc: 84.099%
	I - Batch: 450 | Loss: 1.996 | Acc: 87.278% | Wgt Acc: 84.336%
	I - Batch: 500 | Loss: 1.988 | Acc: 87.425% | Wgt Acc: 84.537%
	I - Batch: 550 | Loss: 1.998 | Acc: 87.125% | Wgt Acc: 84.160%
	I - Batch: 600 | Loss: 2.005 | Acc: 87.083% | Wgt Acc: 84.155%
	I - Batch: 650 | Loss: 2.018 | Acc: 86.673% | Wgt Acc: 83.616%
	I - Batch: 700 | Loss: 2.025 | Acc: 86.616% | Wgt Acc: 83.571%
	I - Batch: 750 | Loss: 2.037 | Acc: 86.292% | Wgt Acc: 83.372%
	I - Batch: 800 | Loss: 2.040 | Acc: 86.289% | Wgt Acc: 83.385%
	I - Batch: 850 | Loss: 2.038 | Acc: 86.287% | Wgt Acc: 83.424%
	I - Batch: 900 | Loss: 2.038 | Acc: 86.333% | Wgt Acc: 83.442%
	I - Batch: 950 | Loss: 2.039 | Acc: 86.204% | Wgt Acc: 83.261%
	I - Batch: 1000 | Loss: 2.039 | Acc: 86.213% | Wgt Acc: 83.326%
I - num batch: 1003
I - Train -- Loss: 2.040 | Acc: 86.197% | Wgt Acc: 83.300% | LR: 1.250000e-04 | Dur: 629.81s
I - Confusion Matrix: [row->prediction - col->label]
[[1770.    3.    7.   22.  225.]
 [   0.  936.  270.    1.    8.]
 [   6.  890. 2240.   10.  333.]
 [  15.    2.   11. 1792.  154.]
 [  71.    7.  110.   69. 7088.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.846 | Acc: 40.625% | Wgt Acc: 40.347%
	I - Batch: 100 | Loss: 5.731 | Acc: 43.438% | Wgt Acc: 40.101%
	I - Batch: 150 | Loss: 5.589 | Acc: 49.792% | Wgt Acc: 42.987%
	I - Batch: 200 | Loss: 5.525 | Acc: 52.969% | Wgt Acc: 44.841%
I - num batch: 238
I - Val -- Loss: 5.523 | Acc: 54.060% | Wgt Acc: 45.528% | Dur: 114.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 283.   10.   16.   59.   30.]
 [   0.  180.   28.    4.    9.]
 [  12.  248.  298.   27.   91.]
 [  80.   38.   60.  283.   65.]
 [ 151.  250.  376.  194. 1013.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 2.170 | Acc: 84.875% | Wgt Acc: 82.215%
	I - Batch: 100 | Loss: 2.077 | Acc: 86.438% | Wgt Acc: 84.206%
	I - Batch: 150 | Loss: 2.022 | Acc: 87.500% | Wgt Acc: 85.106%
	I - Batch: 200 | Loss: 2.008 | Acc: 87.719% | Wgt Acc: 85.165%
	I - Batch: 250 | Loss: 2.006 | Acc: 87.750% | Wgt Acc: 85.374%
	I - Batch: 300 | Loss: 2.007 | Acc: 87.646% | Wgt Acc: 85.152%
	I - Batch: 350 | Loss: 2.036 | Acc: 86.929% | Wgt Acc: 84.314%
	I - Batch: 400 | Loss: 2.055 | Acc: 86.547% | Wgt Acc: 83.937%
	I - Batch: 450 | Loss: 2.051 | Acc: 86.653% | Wgt Acc: 84.169%
	I - Batch: 500 | Loss: 2.041 | Acc: 86.825% | Wgt Acc: 84.352%
	I - Batch: 550 | Loss: 2.044 | Acc: 86.807% | Wgt Acc: 84.302%
	I - Batch: 600 | Loss: 2.047 | Acc: 86.719% | Wgt Acc: 84.260%
	I - Batch: 650 | Loss: 2.051 | Acc: 86.692% | Wgt Acc: 84.113%
	I - Batch: 700 | Loss: 2.055 | Acc: 86.491% | Wgt Acc: 83.815%
	I - Batch: 750 | Loss: 2.054 | Acc: 86.417% | Wgt Acc: 83.680%
	I - Batch: 800 | Loss: 2.047 | Acc: 86.656% | Wgt Acc: 84.017%
	I - Batch: 850 | Loss: 2.042 | Acc: 86.654% | Wgt Acc: 84.015%
	I - Batch: 900 | Loss: 2.039 | Acc: 86.701% | Wgt Acc: 84.069%
	I - Batch: 950 | Loss: 2.042 | Acc: 86.605% | Wgt Acc: 83.899%
	I - Batch: 1000 | Loss: 2.038 | Acc: 86.675% | Wgt Acc: 83.966%
I - num batch: 1003
I - Train -- Loss: 2.037 | Acc: 86.683% | Wgt Acc: 83.977% | LR: 1.250000e-04 | Dur: 629.85s
I - Confusion Matrix: [row->prediction - col->label]
[[1755.    6.    9.   34.  207.]
 [   0.  991.  241.    1.   11.]
 [   7.  836. 2258.    6.  334.]
 [  18.    2.    6. 1799.  155.]
 [  82.    3.  124.   54. 7101.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.541 | Acc: 48.375% | Wgt Acc: 45.847%
	I - Batch: 100 | Loss: 5.482 | Acc: 50.312% | Wgt Acc: 46.954%
	I - Batch: 150 | Loss: 5.424 | Acc: 52.875% | Wgt Acc: 47.694%
	I - Batch: 200 | Loss: 5.382 | Acc: 55.281% | Wgt Acc: 49.234%
I - num batch: 238
I - Val -- Loss: 5.398 | Acc: 55.480% | Wgt Acc: 49.634% | Dur: 115.62s
I - Confusion Matrix: [row->prediction - col->label]
[[299.   8.  18.  88.  29.]
 [  1. 184.  12.   7.  19.]
 [ 45. 366. 494.  89. 236.]
 [ 73.  32.  34. 277.  67.]
 [108. 136. 220. 106. 857.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 1.896 | Acc: 90.250% | Wgt Acc: 87.651%
	I - Batch: 100 | Loss: 1.920 | Acc: 89.062% | Wgt Acc: 86.124%
	I - Batch: 150 | Loss: 1.935 | Acc: 89.292% | Wgt Acc: 86.205%
	I - Batch: 200 | Loss: 1.924 | Acc: 89.281% | Wgt Acc: 86.243%
	I - Batch: 250 | Loss: 1.912 | Acc: 89.325% | Wgt Acc: 86.552%
	I - Batch: 300 | Loss: 1.920 | Acc: 89.250% | Wgt Acc: 86.253%
	I - Batch: 350 | Loss: 1.913 | Acc: 89.536% | Wgt Acc: 86.730%
	I - Batch: 400 | Loss: 1.925 | Acc: 89.047% | Wgt Acc: 86.254%
	I - Batch: 450 | Loss: 1.927 | Acc: 88.944% | Wgt Acc: 86.038%
	I - Batch: 500 | Loss: 1.929 | Acc: 89.062% | Wgt Acc: 86.331%
	I - Batch: 550 | Loss: 1.941 | Acc: 88.795% | Wgt Acc: 86.136%
	I - Batch: 600 | Loss: 1.941 | Acc: 88.771% | Wgt Acc: 86.180%
	I - Batch: 650 | Loss: 1.943 | Acc: 88.663% | Wgt Acc: 86.013%
	I - Batch: 700 | Loss: 1.951 | Acc: 88.473% | Wgt Acc: 85.811%
	I - Batch: 750 | Loss: 1.960 | Acc: 88.200% | Wgt Acc: 85.461%
	I - Batch: 800 | Loss: 1.962 | Acc: 88.156% | Wgt Acc: 85.498%
	I - Batch: 850 | Loss: 1.961 | Acc: 88.110% | Wgt Acc: 85.520%
	I - Batch: 900 | Loss: 1.967 | Acc: 87.965% | Wgt Acc: 85.371%
	I - Batch: 950 | Loss: 1.968 | Acc: 87.961% | Wgt Acc: 85.411%
	I - Batch: 1000 | Loss: 1.967 | Acc: 87.906% | Wgt Acc: 85.319%
I - num batch: 1003
I - Train -- Loss: 1.967 | Acc: 87.918% | Wgt Acc: 85.337% | LR: 1.250000e-04 | Dur: 629.84s
I - Confusion Matrix: [row->prediction - col->label]
[[1776.    2.    4.   10.  177.]
 [   0. 1041.  253.    0.   12.]
 [   5.  790. 2278.    6.  301.]
 [  13.    2.   12. 1820.  131.]
 [  68.    3.   91.   58. 7187.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.788 | Acc: 40.125% | Wgt Acc: 40.347%
	I - Batch: 100 | Loss: 5.672 | Acc: 42.875% | Wgt Acc: 41.433%
	I - Batch: 150 | Loss: 5.566 | Acc: 47.417% | Wgt Acc: 42.922%
	I - Batch: 200 | Loss: 5.506 | Acc: 50.531% | Wgt Acc: 44.977%
I - num batch: 238
I - Val -- Loss: 5.501 | Acc: 51.616% | Wgt Acc: 45.633% | Dur: 114.70s
I - Confusion Matrix: [row->prediction - col->label]
[[360.  36.  52. 115.  89.]
 [  0. 146.  14.   2.  12.]
 [  2. 218. 216.  14.  49.]
 [ 76.  88. 174. 335. 151.]
 [ 88. 238. 322. 101. 907.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 1.955 | Acc: 89.625% | Wgt Acc: 87.108%
	I - Batch: 100 | Loss: 1.968 | Acc: 88.812% | Wgt Acc: 85.681%
	I - Batch: 150 | Loss: 1.938 | Acc: 89.708% | Wgt Acc: 86.780%
	I - Batch: 200 | Loss: 1.980 | Acc: 87.688% | Wgt Acc: 84.914%
	I - Batch: 250 | Loss: 1.980 | Acc: 87.925% | Wgt Acc: 85.381%
	I - Batch: 300 | Loss: 1.977 | Acc: 87.583% | Wgt Acc: 84.803%
	I - Batch: 350 | Loss: 1.989 | Acc: 87.446% | Wgt Acc: 84.852%
	I - Batch: 400 | Loss: 1.990 | Acc: 87.438% | Wgt Acc: 84.891%
	I - Batch: 450 | Loss: 1.983 | Acc: 87.528% | Wgt Acc: 84.899%
	I - Batch: 500 | Loss: 1.979 | Acc: 87.763% | Wgt Acc: 85.176%
	I - Batch: 550 | Loss: 1.975 | Acc: 87.739% | Wgt Acc: 85.054%
	I - Batch: 600 | Loss: 1.979 | Acc: 87.865% | Wgt Acc: 85.185%
	I - Batch: 650 | Loss: 1.986 | Acc: 87.740% | Wgt Acc: 85.045%
	I - Batch: 700 | Loss: 1.991 | Acc: 87.598% | Wgt Acc: 84.947%
	I - Batch: 750 | Loss: 1.993 | Acc: 87.633% | Wgt Acc: 85.011%
	I - Batch: 800 | Loss: 1.988 | Acc: 87.828% | Wgt Acc: 85.184%
	I - Batch: 850 | Loss: 1.988 | Acc: 87.831% | Wgt Acc: 85.229%
	I - Batch: 900 | Loss: 1.997 | Acc: 87.646% | Wgt Acc: 85.027%
	I - Batch: 950 | Loss: 2.006 | Acc: 87.507% | Wgt Acc: 84.868%
	I - Batch: 1000 | Loss: 2.003 | Acc: 87.519% | Wgt Acc: 84.903%
I - num batch: 1003
I - Train -- Loss: 2.003 | Acc: 87.525% | Wgt Acc: 84.913% | LR: 1.250000e-04 | Dur: 629.63s
I - Confusion Matrix: [row->prediction - col->label]
[[1746.    4.    8.   18.  178.]
 [   1. 1037.  218.    0.    8.]
 [  13.  784. 2301.   10.  337.]
 [  24.    6.    7. 1807.  137.]
 [  78.    7.  104.   59. 7148.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.648 | Acc: 45.250% | Wgt Acc: 45.581%
	I - Batch: 100 | Loss: 5.570 | Acc: 48.812% | Wgt Acc: 47.923%
	I - Batch: 150 | Loss: 5.488 | Acc: 52.375% | Wgt Acc: 48.501%
	I - Batch: 200 | Loss: 5.432 | Acc: 54.781% | Wgt Acc: 49.909%
I - num batch: 238
I - Val -- Loss: 5.445 | Acc: 55.322% | Wgt Acc: 50.305% | Dur: 114.67s
I - Confusion Matrix: [row->prediction - col->label]
[[367.  26.  56. 106.  69.]
 [  0. 230.  34.   8.  27.]
 [  7. 210. 276.  30.  83.]
 [ 85.  70. 112. 324. 121.]
 [ 67. 190. 300.  99. 908.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 2.023 | Acc: 84.750% | Wgt Acc: 82.050%
	I - Batch: 100 | Loss: 2.009 | Acc: 85.625% | Wgt Acc: 82.734%
	I - Batch: 150 | Loss: 2.010 | Acc: 86.583% | Wgt Acc: 84.088%
	I - Batch: 200 | Loss: 2.047 | Acc: 85.875% | Wgt Acc: 83.001%
	I - Batch: 250 | Loss: 2.057 | Acc: 85.500% | Wgt Acc: 82.582%
	I - Batch: 300 | Loss: 2.040 | Acc: 86.000% | Wgt Acc: 83.176%
	I - Batch: 350 | Loss: 2.022 | Acc: 86.482% | Wgt Acc: 83.547%
	I - Batch: 400 | Loss: 2.043 | Acc: 86.016% | Wgt Acc: 83.269%
	I - Batch: 450 | Loss: 2.058 | Acc: 85.889% | Wgt Acc: 83.197%
	I - Batch: 500 | Loss: 2.058 | Acc: 86.025% | Wgt Acc: 83.280%
	I - Batch: 550 | Loss: 2.057 | Acc: 86.023% | Wgt Acc: 83.455%
	I - Batch: 600 | Loss: 2.059 | Acc: 86.042% | Wgt Acc: 83.410%
	I - Batch: 650 | Loss: 2.051 | Acc: 86.087% | Wgt Acc: 83.454%
	I - Batch: 700 | Loss: 2.052 | Acc: 86.071% | Wgt Acc: 83.473%
	I - Batch: 750 | Loss: 2.048 | Acc: 86.233% | Wgt Acc: 83.713%
	I - Batch: 800 | Loss: 2.048 | Acc: 86.219% | Wgt Acc: 83.650%
	I - Batch: 850 | Loss: 2.043 | Acc: 86.375% | Wgt Acc: 83.788%
	I - Batch: 900 | Loss: 2.039 | Acc: 86.431% | Wgt Acc: 83.860%
	I - Batch: 950 | Loss: 2.038 | Acc: 86.546% | Wgt Acc: 84.020%
	I - Batch: 1000 | Loss: 2.034 | Acc: 86.606% | Wgt Acc: 84.071%
I - num batch: 1003
I - Train -- Loss: 2.033 | Acc: 86.621% | Wgt Acc: 84.083% | LR: 1.250000e-04 | Dur: 629.31s
I - Confusion Matrix: [row->prediction - col->label]
[[1728.    2.    9.   35.  216.]
 [   0. 1058.  242.    0.   16.]
 [   8.  773. 2241.    9.  338.]
 [  35.    2.   10. 1783.  154.]
 [  91.    3.  136.   67. 7084.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.731 | Acc: 40.375% | Wgt Acc: 40.010%
	I - Batch: 100 | Loss: 5.595 | Acc: 46.812% | Wgt Acc: 44.003%
	I - Batch: 150 | Loss: 5.495 | Acc: 51.833% | Wgt Acc: 45.926%
	I - Batch: 200 | Loss: 5.427 | Acc: 55.594% | Wgt Acc: 48.627%
I - num batch: 238
I - Val -- Loss: 5.435 | Acc: 56.242% | Wgt Acc: 49.091% | Dur: 114.84s
I - Confusion Matrix: [row->prediction - col->label]
[[341.  22.  28.  94.  58.]
 [  1. 240.  62.  13.  25.]
 [ 12. 228. 312.  37.  85.]
 [ 56.  30.  34. 254.  47.]
 [116. 206. 342. 169. 993.]]

I - Local maximum validation set accuracy:  56.24

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 1.881 | Acc: 88.125% | Wgt Acc: 85.007%
	I - Batch: 100 | Loss: 1.896 | Acc: 88.375% | Wgt Acc: 86.294%
	I - Batch: 150 | Loss: 1.921 | Acc: 87.750% | Wgt Acc: 85.232%
	I - Batch: 200 | Loss: 1.921 | Acc: 88.594% | Wgt Acc: 86.343%
	I - Batch: 250 | Loss: 1.903 | Acc: 89.525% | Wgt Acc: 87.353%
	I - Batch: 300 | Loss: 1.904 | Acc: 89.625% | Wgt Acc: 87.635%
	I - Batch: 350 | Loss: 1.912 | Acc: 89.357% | Wgt Acc: 87.162%
	I - Batch: 400 | Loss: 1.920 | Acc: 89.250% | Wgt Acc: 86.965%
	I - Batch: 450 | Loss: 1.934 | Acc: 88.778% | Wgt Acc: 86.362%
	I - Batch: 500 | Loss: 1.932 | Acc: 88.975% | Wgt Acc: 86.698%
	I - Batch: 550 | Loss: 1.929 | Acc: 89.045% | Wgt Acc: 86.678%
	I - Batch: 600 | Loss: 1.925 | Acc: 89.125% | Wgt Acc: 86.688%
	I - Batch: 650 | Loss: 1.925 | Acc: 89.115% | Wgt Acc: 86.691%
	I - Batch: 700 | Loss: 1.929 | Acc: 88.991% | Wgt Acc: 86.552%
	I - Batch: 750 | Loss: 1.929 | Acc: 89.008% | Wgt Acc: 86.581%
	I - Batch: 800 | Loss: 1.929 | Acc: 88.922% | Wgt Acc: 86.463%
	I - Batch: 850 | Loss: 1.932 | Acc: 88.919% | Wgt Acc: 86.513%
	I - Batch: 900 | Loss: 1.934 | Acc: 88.833% | Wgt Acc: 86.376%
	I - Batch: 950 | Loss: 1.934 | Acc: 88.789% | Wgt Acc: 86.316%
	I - Batch: 1000 | Loss: 1.934 | Acc: 88.838% | Wgt Acc: 86.387%
I - num batch: 1003
I - Train -- Loss: 1.934 | Acc: 88.859% | Wgt Acc: 86.415% | LR: 1.250000e-04 | Dur: 632.99s
I - Confusion Matrix: [row->prediction - col->label]
[[1777.    4.    6.    4.  147.]
 [   0. 1068.  180.    1.    6.]
 [   7.  759. 2360.    9.  293.]
 [  11.    3.    5. 1827.  141.]
 [  67.    4.   87.   53. 7221.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.382 | Acc: 52.625% | Wgt Acc: 52.163%
	I - Batch: 100 | Loss: 5.373 | Acc: 55.188% | Wgt Acc: 53.978%
	I - Batch: 150 | Loss: 5.326 | Acc: 58.250% | Wgt Acc: 55.133%
	I - Batch: 200 | Loss: 5.300 | Acc: 60.312% | Wgt Acc: 56.420%
I - num batch: 238
I - Val -- Loss: 5.319 | Acc: 60.368% | Wgt Acc: 56.341% | Dur: 115.24s
I - Confusion Matrix: [row->prediction - col->label]
[[334.  12.  14.  81.  38.]
 [  6. 354.  66.  14.  38.]
 [ 24. 214. 426.  47. 169.]
 [ 58.  32.  48. 286.  66.]
 [104. 114. 224. 139. 897.]]

I - Local maximum validation set accuracy:  60.37

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 1.886 | Acc: 90.250% | Wgt Acc: 88.071%
	I - Batch: 100 | Loss: 1.890 | Acc: 89.562% | Wgt Acc: 87.542%
	I - Batch: 150 | Loss: 1.882 | Acc: 89.667% | Wgt Acc: 87.636%
	I - Batch: 200 | Loss: 1.888 | Acc: 89.438% | Wgt Acc: 87.391%
	I - Batch: 250 | Loss: 1.893 | Acc: 89.275% | Wgt Acc: 86.958%
	I - Batch: 300 | Loss: 1.894 | Acc: 89.188% | Wgt Acc: 86.509%
	I - Batch: 350 | Loss: 1.889 | Acc: 89.321% | Wgt Acc: 86.762%
	I - Batch: 400 | Loss: 1.878 | Acc: 89.766% | Wgt Acc: 87.342%
	I - Batch: 450 | Loss: 1.879 | Acc: 89.569% | Wgt Acc: 87.117%
	I - Batch: 500 | Loss: 1.879 | Acc: 89.700% | Wgt Acc: 87.283%
	I - Batch: 550 | Loss: 1.881 | Acc: 89.636% | Wgt Acc: 87.142%
	I - Batch: 600 | Loss: 1.885 | Acc: 89.521% | Wgt Acc: 87.115%
	I - Batch: 650 | Loss: 1.885 | Acc: 89.558% | Wgt Acc: 87.100%
	I - Batch: 700 | Loss: 1.884 | Acc: 89.625% | Wgt Acc: 87.108%
	I - Batch: 750 | Loss: 1.885 | Acc: 89.542% | Wgt Acc: 86.939%
	I - Batch: 800 | Loss: 1.887 | Acc: 89.398% | Wgt Acc: 86.722%
	I - Batch: 850 | Loss: 1.891 | Acc: 89.478% | Wgt Acc: 86.849%
	I - Batch: 900 | Loss: 1.895 | Acc: 89.396% | Wgt Acc: 86.790%
	I - Batch: 950 | Loss: 1.896 | Acc: 89.388% | Wgt Acc: 86.747%
	I - Batch: 1000 | Loss: 1.896 | Acc: 89.438% | Wgt Acc: 86.767%
I - num batch: 1003
I - Train -- Loss: 1.897 | Acc: 89.414% | Wgt Acc: 86.732% | LR: 1.250000e-04 | Dur: 629.79s
I - Confusion Matrix: [row->prediction - col->label]
[[1786.    2.    7.    5.  145.]
 [   0. 1066.  191.    0.   14.]
 [   4.  759. 2354.    7.  244.]
 [   5.    3.    8. 1832.  101.]
 [  67.    8.   78.   50. 7304.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.739 | Acc: 41.875% | Wgt Acc: 40.635%
	I - Batch: 100 | Loss: 5.622 | Acc: 46.375% | Wgt Acc: 43.060%
	I - Batch: 150 | Loss: 5.515 | Acc: 51.333% | Wgt Acc: 45.051%
	I - Batch: 200 | Loss: 5.450 | Acc: 54.625% | Wgt Acc: 47.170%
I - num batch: 238
I - Val -- Loss: 5.451 | Acc: 55.322% | Wgt Acc: 47.680% | Dur: 114.68s
I - Confusion Matrix: [row->prediction - col->label]
[[306.  22.  32.  85.  31.]
 [  0. 176.  16.   4.  13.]
 [  8. 270. 356.  37.  91.]
 [ 65.  46.  68. 292.  98.]
 [147. 212. 306. 149. 975.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 1.921 | Acc: 90.875% | Wgt Acc: 89.280%
	I - Batch: 100 | Loss: 1.918 | Acc: 89.938% | Wgt Acc: 88.676%
	I - Batch: 150 | Loss: 1.911 | Acc: 89.917% | Wgt Acc: 88.472%
	I - Batch: 200 | Loss: 1.916 | Acc: 89.281% | Wgt Acc: 87.463%
	I - Batch: 250 | Loss: 1.907 | Acc: 89.425% | Wgt Acc: 87.522%
	I - Batch: 300 | Loss: 1.897 | Acc: 89.438% | Wgt Acc: 87.315%
	I - Batch: 350 | Loss: 1.891 | Acc: 89.839% | Wgt Acc: 87.805%
	I - Batch: 400 | Loss: 1.883 | Acc: 90.078% | Wgt Acc: 88.029%
	I - Batch: 450 | Loss: 1.879 | Acc: 89.972% | Wgt Acc: 87.659%
	I - Batch: 500 | Loss: 1.873 | Acc: 90.075% | Wgt Acc: 87.723%
	I - Batch: 550 | Loss: 1.875 | Acc: 90.091% | Wgt Acc: 87.791%
	I - Batch: 600 | Loss: 1.871 | Acc: 90.115% | Wgt Acc: 87.738%
	I - Batch: 650 | Loss: 1.872 | Acc: 90.067% | Wgt Acc: 87.643%
	I - Batch: 700 | Loss: 1.871 | Acc: 90.125% | Wgt Acc: 87.732%
	I - Batch: 750 | Loss: 1.871 | Acc: 90.217% | Wgt Acc: 87.890%
	I - Batch: 800 | Loss: 1.873 | Acc: 90.195% | Wgt Acc: 87.852%
	I - Batch: 850 | Loss: 1.877 | Acc: 90.140% | Wgt Acc: 87.850%
	I - Batch: 900 | Loss: 1.879 | Acc: 90.021% | Wgt Acc: 87.761%
	I - Batch: 950 | Loss: 1.878 | Acc: 90.000% | Wgt Acc: 87.731%
	I - Batch: 1000 | Loss: 1.883 | Acc: 89.975% | Wgt Acc: 87.745%
I - num batch: 1003
I - Train -- Loss: 1.883 | Acc: 89.963% | Wgt Acc: 87.727% | LR: 1.250000e-04 | Dur: 627.99s
I - Confusion Matrix: [row->prediction - col->label]
[[1792.    5.    2.    9.  138.]
 [   0. 1119.  145.    0.   16.]
 [   8.  710. 2414.    2.  267.]
 [   8.    1.    8. 1833.  115.]
 [  54.    3.   69.   50. 7272.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.643 | Acc: 44.875% | Wgt Acc: 44.499%
	I - Batch: 100 | Loss: 5.533 | Acc: 49.750% | Wgt Acc: 48.068%
	I - Batch: 150 | Loss: 5.436 | Acc: 54.083% | Wgt Acc: 50.006%
	I - Batch: 200 | Loss: 5.386 | Acc: 56.562% | Wgt Acc: 51.551%
I - num batch: 238
I - Val -- Loss: 5.386 | Acc: 57.109% | Wgt Acc: 52.087% | Dur: 114.34s
I - Confusion Matrix: [row->prediction - col->label]
[[324.  16.  34.  65.  53.]
 [  4. 236.  38.   9.  20.]
 [ 16. 218. 352.  30. 110.]
 [101.  56.  66. 357. 121.]
 [ 81. 200. 288. 106. 904.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 2.047 | Acc: 88.625% | Wgt Acc: 86.604%
	I - Batch: 100 | Loss: 2.004 | Acc: 88.875% | Wgt Acc: 86.189%
	I - Batch: 150 | Loss: 1.967 | Acc: 89.250% | Wgt Acc: 86.953%
	I - Batch: 200 | Loss: 1.966 | Acc: 88.938% | Wgt Acc: 86.305%
	I - Batch: 250 | Loss: 1.966 | Acc: 88.875% | Wgt Acc: 86.165%
	I - Batch: 300 | Loss: 1.969 | Acc: 88.583% | Wgt Acc: 85.760%
	I - Batch: 350 | Loss: 1.977 | Acc: 88.304% | Wgt Acc: 85.490%
	I - Batch: 400 | Loss: 1.970 | Acc: 88.672% | Wgt Acc: 85.959%
	I - Batch: 450 | Loss: 1.961 | Acc: 88.917% | Wgt Acc: 86.215%
	I - Batch: 500 | Loss: 1.955 | Acc: 89.050% | Wgt Acc: 86.406%
	I - Batch: 550 | Loss: 1.955 | Acc: 89.023% | Wgt Acc: 86.377%
	I - Batch: 600 | Loss: 1.953 | Acc: 89.094% | Wgt Acc: 86.528%
	I - Batch: 650 | Loss: 1.946 | Acc: 89.173% | Wgt Acc: 86.595%
	I - Batch: 700 | Loss: 1.941 | Acc: 89.250% | Wgt Acc: 86.752%
	I - Batch: 750 | Loss: 1.944 | Acc: 89.100% | Wgt Acc: 86.589%
	I - Batch: 800 | Loss: 1.943 | Acc: 89.164% | Wgt Acc: 86.669%
	I - Batch: 850 | Loss: 1.939 | Acc: 89.235% | Wgt Acc: 86.723%
	I - Batch: 900 | Loss: 1.935 | Acc: 89.271% | Wgt Acc: 86.753%
	I - Batch: 950 | Loss: 1.928 | Acc: 89.434% | Wgt Acc: 86.924%
	I - Batch: 1000 | Loss: 1.924 | Acc: 89.588% | Wgt Acc: 87.147%
I - num batch: 1003
I - Train -- Loss: 1.924 | Acc: 89.576% | Wgt Acc: 87.132% | LR: 1.250000e-04 | Dur: 628.84s
I - Confusion Matrix: [row->prediction - col->label]
[[1770.    2.    6.   17.  164.]
 [   0. 1119.  142.    0.    7.]
 [   8.  708. 2394.    8.  230.]
 [  19.    2.   14. 1810.  132.]
 [  65.    7.   82.   59. 7275.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.504 | Acc: 48.875% | Wgt Acc: 48.815%
	I - Batch: 100 | Loss: 5.471 | Acc: 51.250% | Wgt Acc: 49.810%
	I - Batch: 150 | Loss: 5.416 | Acc: 54.250% | Wgt Acc: 51.146%
	I - Batch: 200 | Loss: 5.372 | Acc: 57.719% | Wgt Acc: 53.401%
I - num batch: 238
I - Val -- Loss: 5.391 | Acc: 58.003% | Wgt Acc: 53.281% | Dur: 114.38s
I - Confusion Matrix: [row->prediction - col->label]
[[369.  16.  34. 120.  62.]
 [  0. 326. 114.  10.  34.]
 [ 18. 190. 356.  42. 134.]
 [ 27.  34.  34. 240.  62.]
 [112. 160. 240. 155. 916.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 1.910 | Acc: 90.000% | Wgt Acc: 87.802%
	I - Batch: 100 | Loss: 1.892 | Acc: 90.062% | Wgt Acc: 87.596%
	I - Batch: 150 | Loss: 1.883 | Acc: 89.917% | Wgt Acc: 87.054%
	I - Batch: 200 | Loss: 1.867 | Acc: 90.188% | Wgt Acc: 87.607%
	I - Batch: 250 | Loss: 1.866 | Acc: 90.050% | Wgt Acc: 87.626%
	I - Batch: 300 | Loss: 1.861 | Acc: 90.458% | Wgt Acc: 88.130%
	I - Batch: 350 | Loss: 1.867 | Acc: 90.321% | Wgt Acc: 87.812%
	I - Batch: 400 | Loss: 1.871 | Acc: 90.562% | Wgt Acc: 88.020%
	I - Batch: 450 | Loss: 1.882 | Acc: 90.333% | Wgt Acc: 87.837%
	I - Batch: 500 | Loss: 1.875 | Acc: 90.612% | Wgt Acc: 88.114%
	I - Batch: 550 | Loss: 1.872 | Acc: 90.705% | Wgt Acc: 88.201%
	I - Batch: 600 | Loss: 1.878 | Acc: 90.573% | Wgt Acc: 88.054%
	I - Batch: 650 | Loss: 1.882 | Acc: 90.385% | Wgt Acc: 87.859%
	I - Batch: 700 | Loss: 1.885 | Acc: 90.375% | Wgt Acc: 87.873%
	I - Batch: 750 | Loss: 1.883 | Acc: 90.425% | Wgt Acc: 87.963%
	I - Batch: 800 | Loss: 1.882 | Acc: 90.359% | Wgt Acc: 87.928%
	I - Batch: 850 | Loss: 1.881 | Acc: 90.426% | Wgt Acc: 88.057%
	I - Batch: 900 | Loss: 1.882 | Acc: 90.340% | Wgt Acc: 87.967%
	I - Batch: 950 | Loss: 1.883 | Acc: 90.289% | Wgt Acc: 87.934%
	I - Batch: 1000 | Loss: 1.881 | Acc: 90.331% | Wgt Acc: 87.930%
I - num batch: 1003
I - Train -- Loss: 1.880 | Acc: 90.318% | Wgt Acc: 87.918% | LR: 1.250000e-04 | Dur: 628.35s
I - Confusion Matrix: [row->prediction - col->label]
[[1779.    6.    6.   12.  158.]
 [   0. 1136.  143.    0.   10.]
 [   3.  691. 2424.    6.  218.]
 [  11.    1.   13. 1825.   99.]
 [  69.    4.   52.   51. 7323.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.734 | Acc: 42.250% | Wgt Acc: 41.657%
	I - Batch: 100 | Loss: 5.618 | Acc: 45.250% | Wgt Acc: 43.470%
	I - Batch: 150 | Loss: 5.511 | Acc: 49.625% | Wgt Acc: 44.911%
	I - Batch: 200 | Loss: 5.451 | Acc: 53.250% | Wgt Acc: 47.532%
I - num batch: 238
I - Val -- Loss: 5.474 | Acc: 53.482% | Wgt Acc: 47.304% | Dur: 114.35s
I - Confusion Matrix: [row->prediction - col->label]
[[427.  42.  86. 214. 135.]
 [  0. 166.  20.   4.  12.]
 [  6. 258. 314.  32.  81.]
 [ 26.  52.  70. 216.  68.]
 [ 67. 208. 288. 101. 912.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 1.850 | Acc: 91.625% | Wgt Acc: 88.637%
	I - Batch: 100 | Loss: 1.877 | Acc: 90.438% | Wgt Acc: 87.074%
	I - Batch: 150 | Loss: 1.852 | Acc: 91.208% | Wgt Acc: 88.502%
	I - Batch: 200 | Loss: 1.858 | Acc: 91.031% | Wgt Acc: 88.375%
	I - Batch: 250 | Loss: 1.837 | Acc: 91.625% | Wgt Acc: 89.152%
	I - Batch: 300 | Loss: 1.823 | Acc: 91.938% | Wgt Acc: 89.500%
	I - Batch: 350 | Loss: 1.827 | Acc: 91.554% | Wgt Acc: 89.050%
	I - Batch: 400 | Loss: 1.846 | Acc: 91.312% | Wgt Acc: 88.854%
	I - Batch: 450 | Loss: 1.855 | Acc: 91.083% | Wgt Acc: 88.577%
	I - Batch: 500 | Loss: 1.844 | Acc: 91.263% | Wgt Acc: 88.888%
	I - Batch: 550 | Loss: 1.851 | Acc: 91.068% | Wgt Acc: 88.785%
	I - Batch: 600 | Loss: 1.852 | Acc: 91.083% | Wgt Acc: 88.811%
	I - Batch: 650 | Loss: 1.853 | Acc: 91.029% | Wgt Acc: 88.712%
	I - Batch: 700 | Loss: 1.854 | Acc: 91.054% | Wgt Acc: 88.790%
	I - Batch: 750 | Loss: 1.852 | Acc: 91.058% | Wgt Acc: 88.807%
	I - Batch: 800 | Loss: 1.864 | Acc: 90.766% | Wgt Acc: 88.450%
	I - Batch: 850 | Loss: 1.866 | Acc: 90.831% | Wgt Acc: 88.543%
	I - Batch: 900 | Loss: 1.869 | Acc: 90.819% | Wgt Acc: 88.515%
	I - Batch: 950 | Loss: 1.871 | Acc: 90.763% | Wgt Acc: 88.444%
	I - Batch: 1000 | Loss: 1.875 | Acc: 90.638% | Wgt Acc: 88.314%
I - num batch: 1003
I - Train -- Loss: 1.877 | Acc: 90.580% | Wgt Acc: 88.222% | LR: 1.250000e-04 | Dur: 635.35s
I - Confusion Matrix: [row->prediction - col->label]
[[1785.    5.   12.   11.  143.]
 [   0. 1151.  135.    0.   12.]
 [   7.  679. 2419.    4.  199.]
 [  10.    2.    8. 1831.  111.]
 [  60.    1.   64.   48. 7343.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.563 | Acc: 47.500% | Wgt Acc: 44.619%
	I - Batch: 100 | Loss: 5.500 | Acc: 51.000% | Wgt Acc: 48.257%
	I - Batch: 150 | Loss: 5.457 | Acc: 52.875% | Wgt Acc: 49.043%
	I - Batch: 200 | Loss: 5.421 | Acc: 54.750% | Wgt Acc: 50.128%
I - num batch: 238
I - Val -- Loss: 5.417 | Acc: 55.322% | Wgt Acc: 50.872% | Dur: 116.99s
I - Confusion Matrix: [row->prediction - col->label]
[[309.   8.  30.  50.  41.]
 [  0. 142.   6.   5.  10.]
 [ 19. 384. 524.  65. 262.]
 [111.  50.  70. 346. 111.]
 [ 87. 142. 148. 101. 784.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 1.838 | Acc: 91.625% | Wgt Acc: 90.224%
	I - Batch: 100 | Loss: 1.854 | Acc: 90.375% | Wgt Acc: 88.859%
	I - Batch: 150 | Loss: 1.870 | Acc: 90.125% | Wgt Acc: 88.225%
	I - Batch: 200 | Loss: 1.882 | Acc: 90.156% | Wgt Acc: 88.097%
	I - Batch: 250 | Loss: 1.878 | Acc: 90.300% | Wgt Acc: 88.232%
	I - Batch: 300 | Loss: 1.865 | Acc: 90.896% | Wgt Acc: 89.125%
	I - Batch: 350 | Loss: 1.866 | Acc: 90.946% | Wgt Acc: 88.987%
	I - Batch: 400 | Loss: 1.874 | Acc: 90.766% | Wgt Acc: 88.772%
	I - Batch: 450 | Loss: 1.866 | Acc: 91.056% | Wgt Acc: 89.202%
	I - Batch: 500 | Loss: 1.862 | Acc: 91.188% | Wgt Acc: 89.346%
	I - Batch: 550 | Loss: 1.862 | Acc: 91.068% | Wgt Acc: 89.088%
	I - Batch: 600 | Loss: 1.863 | Acc: 91.177% | Wgt Acc: 89.199%
	I - Batch: 650 | Loss: 1.859 | Acc: 91.173% | Wgt Acc: 89.119%
	I - Batch: 700 | Loss: 1.867 | Acc: 90.938% | Wgt Acc: 88.838%
	I - Batch: 750 | Loss: 1.865 | Acc: 91.033% | Wgt Acc: 88.965%
	I - Batch: 800 | Loss: 1.867 | Acc: 90.883% | Wgt Acc: 88.786%
	I - Batch: 850 | Loss: 1.871 | Acc: 90.772% | Wgt Acc: 88.558%
	I - Batch: 900 | Loss: 1.868 | Acc: 90.868% | Wgt Acc: 88.623%
	I - Batch: 950 | Loss: 1.866 | Acc: 90.849% | Wgt Acc: 88.624%
	I - Batch: 1000 | Loss: 1.870 | Acc: 90.688% | Wgt Acc: 88.426%
I - num batch: 1003
I - Train -- Loss: 1.870 | Acc: 90.680% | Wgt Acc: 88.413% | LR: 1.250000e-04 | Dur: 636.61s
I - Confusion Matrix: [row->prediction - col->label]
[[1796.    4.    5.   19.  138.]
 [   0. 1161.  135.    0.    6.]
 [   4.  659. 2425.    5.  198.]
 [  15.    5.    5. 1825.  128.]
 [  47.    9.   68.   45. 7338.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.500 | Acc: 48.500% | Wgt Acc: 47.445%
	I - Batch: 100 | Loss: 5.472 | Acc: 50.188% | Wgt Acc: 48.864%
	I - Batch: 150 | Loss: 5.410 | Acc: 54.042% | Wgt Acc: 50.901%
	I - Batch: 200 | Loss: 5.376 | Acc: 56.281% | Wgt Acc: 52.563%
I - num batch: 238
I - Val -- Loss: 5.377 | Acc: 56.137% | Wgt Acc: 52.661% | Dur: 115.47s
I - Confusion Matrix: [row->prediction - col->label]
[[322.  16.  38.  57.  49.]
 [  1. 218.  40.   6.  21.]
 [ 21. 278. 396.  39. 171.]
 [122.  62. 100. 389. 156.]
 [ 60. 152. 204.  76. 811.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 1.899 | Acc: 90.125% | Wgt Acc: 88.241%
	I - Batch: 100 | Loss: 1.862 | Acc: 91.375% | Wgt Acc: 89.321%
	I - Batch: 150 | Loss: 1.841 | Acc: 91.875% | Wgt Acc: 89.831%
	I - Batch: 200 | Loss: 1.824 | Acc: 92.094% | Wgt Acc: 90.113%
	I - Batch: 250 | Loss: 1.827 | Acc: 92.000% | Wgt Acc: 89.768%
	I - Batch: 300 | Loss: 1.830 | Acc: 91.625% | Wgt Acc: 89.365%
	I - Batch: 350 | Loss: 1.829 | Acc: 91.768% | Wgt Acc: 89.512%
	I - Batch: 400 | Loss: 1.827 | Acc: 91.812% | Wgt Acc: 89.533%
	I - Batch: 450 | Loss: 1.830 | Acc: 91.708% | Wgt Acc: 89.347%
	I - Batch: 500 | Loss: 1.824 | Acc: 91.925% | Wgt Acc: 89.581%
	I - Batch: 550 | Loss: 1.823 | Acc: 91.898% | Wgt Acc: 89.454%
	I - Batch: 600 | Loss: 1.825 | Acc: 91.771% | Wgt Acc: 89.232%
	I - Batch: 650 | Loss: 1.823 | Acc: 91.750% | Wgt Acc: 89.158%
	I - Batch: 700 | Loss: 1.822 | Acc: 91.759% | Wgt Acc: 89.164%
	I - Batch: 750 | Loss: 1.820 | Acc: 91.792% | Wgt Acc: 89.296%
	I - Batch: 800 | Loss: 1.826 | Acc: 91.562% | Wgt Acc: 89.003%
	I - Batch: 850 | Loss: 1.825 | Acc: 91.647% | Wgt Acc: 89.184%
	I - Batch: 900 | Loss: 1.825 | Acc: 91.576% | Wgt Acc: 89.093%
	I - Batch: 950 | Loss: 1.830 | Acc: 91.467% | Wgt Acc: 88.955%
	I - Batch: 1000 | Loss: 1.831 | Acc: 91.381% | Wgt Acc: 88.859%
I - num batch: 1003
I - Train -- Loss: 1.831 | Acc: 91.390% | Wgt Acc: 88.870% | LR: 1.250000e-04 | Dur: 633.04s
I - Confusion Matrix: [row->prediction - col->label]
[[1801.    4.    6.    6.  124.]
 [   0. 1136.  110.    0.    8.]
 [   4.  693. 2460.    4.  162.]
 [   6.    2.    5. 1843.   95.]
 [  51.    3.   57.   41. 7419.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.010 | Acc: 36.000% | Wgt Acc: 36.846%
	I - Batch: 100 | Loss: 5.796 | Acc: 43.000% | Wgt Acc: 41.330%
	I - Batch: 150 | Loss: 5.632 | Acc: 49.833% | Wgt Acc: 44.257%
	I - Batch: 200 | Loss: 5.563 | Acc: 52.906% | Wgt Acc: 45.742%
I - num batch: 238
I - Val -- Loss: 5.553 | Acc: 54.428% | Wgt Acc: 46.831% | Dur: 114.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 327.   18.   40.   78.   44.]
 [   3.  232.   58.    7.   16.]
 [   9.  136.  194.   17.   45.]
 [  54.   44.   34.  292.   77.]
 [ 133.  296.  452.  173. 1026.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 1.867 | Acc: 91.000% | Wgt Acc: 88.557%
	I - Batch: 100 | Loss: 1.872 | Acc: 91.438% | Wgt Acc: 89.358%
	I - Batch: 150 | Loss: 1.859 | Acc: 91.417% | Wgt Acc: 89.069%
	I - Batch: 200 | Loss: 1.858 | Acc: 91.219% | Wgt Acc: 89.062%
	I - Batch: 250 | Loss: 1.855 | Acc: 91.300% | Wgt Acc: 89.003%
	I - Batch: 300 | Loss: 1.839 | Acc: 91.562% | Wgt Acc: 89.172%
	I - Batch: 350 | Loss: 1.843 | Acc: 91.357% | Wgt Acc: 88.979%
	I - Batch: 400 | Loss: 1.837 | Acc: 91.422% | Wgt Acc: 89.026%
	I - Batch: 450 | Loss: 1.833 | Acc: 91.736% | Wgt Acc: 89.497%
	I - Batch: 500 | Loss: 1.824 | Acc: 91.900% | Wgt Acc: 89.650%
	I - Batch: 550 | Loss: 1.823 | Acc: 91.955% | Wgt Acc: 89.689%
	I - Batch: 600 | Loss: 1.824 | Acc: 91.885% | Wgt Acc: 89.621%
	I - Batch: 650 | Loss: 1.823 | Acc: 91.827% | Wgt Acc: 89.514%
	I - Batch: 700 | Loss: 1.821 | Acc: 91.982% | Wgt Acc: 89.742%
	I - Batch: 750 | Loss: 1.824 | Acc: 91.908% | Wgt Acc: 89.680%
	I - Batch: 800 | Loss: 1.825 | Acc: 91.930% | Wgt Acc: 89.766%
	I - Batch: 850 | Loss: 1.824 | Acc: 91.838% | Wgt Acc: 89.689%
	I - Batch: 900 | Loss: 1.826 | Acc: 91.826% | Wgt Acc: 89.675%
	I - Batch: 950 | Loss: 1.825 | Acc: 91.855% | Wgt Acc: 89.690%
	I - Batch: 1000 | Loss: 1.822 | Acc: 91.875% | Wgt Acc: 89.655%
I - num batch: 1003
I - Train -- Loss: 1.823 | Acc: 91.858% | Wgt Acc: 89.652% | LR: 1.250000e-04 | Dur: 627.58s
I - Confusion Matrix: [row->prediction - col->label]
[[1812.    3.    5.    3.  102.]
 [   0. 1186.   90.    0.    7.]
 [   5.  644. 2480.    7.  194.]
 [   5.    3.    7. 1843.   92.]
 [  40.    2.   56.   41. 7413.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.430 | Acc: 50.250% | Wgt Acc: 50.652%
	I - Batch: 100 | Loss: 5.425 | Acc: 52.938% | Wgt Acc: 52.410%
	I - Batch: 150 | Loss: 5.359 | Acc: 55.417% | Wgt Acc: 52.714%
	I - Batch: 200 | Loss: 5.345 | Acc: 57.250% | Wgt Acc: 53.593%
I - num batch: 238
I - Val -- Loss: 5.362 | Acc: 57.293% | Wgt Acc: 53.690% | Dur: 113.09s
I - Confusion Matrix: [row->prediction - col->label]
[[337.  18.  32.  71.  46.]
 [  0. 308. 110.  12.  44.]
 [ 14. 182. 312.  27. 130.]
 [ 77.  54.  80. 350. 115.]
 [ 98. 164. 244. 107. 873.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 1.814 | Acc: 91.875% | Wgt Acc: 89.550%
	I - Batch: 100 | Loss: 1.807 | Acc: 91.562% | Wgt Acc: 88.802%
	I - Batch: 150 | Loss: 1.779 | Acc: 92.458% | Wgt Acc: 90.143%
	I - Batch: 200 | Loss: 1.785 | Acc: 92.375% | Wgt Acc: 90.003%
	I - Batch: 250 | Loss: 1.800 | Acc: 91.850% | Wgt Acc: 89.409%
	I - Batch: 300 | Loss: 1.802 | Acc: 91.812% | Wgt Acc: 89.342%
	I - Batch: 350 | Loss: 1.804 | Acc: 91.964% | Wgt Acc: 89.521%
	I - Batch: 400 | Loss: 1.808 | Acc: 91.938% | Wgt Acc: 89.512%
	I - Batch: 450 | Loss: 1.796 | Acc: 92.375% | Wgt Acc: 90.131%
	I - Batch: 500 | Loss: 1.797 | Acc: 92.400% | Wgt Acc: 90.099%
	I - Batch: 550 | Loss: 1.802 | Acc: 92.409% | Wgt Acc: 90.150%
	I - Batch: 600 | Loss: 1.802 | Acc: 92.490% | Wgt Acc: 90.278%
	I - Batch: 650 | Loss: 1.795 | Acc: 92.538% | Wgt Acc: 90.315%
	I - Batch: 700 | Loss: 1.798 | Acc: 92.304% | Wgt Acc: 90.039%
	I - Batch: 750 | Loss: 1.799 | Acc: 92.233% | Wgt Acc: 89.935%
	I - Batch: 800 | Loss: 1.798 | Acc: 92.203% | Wgt Acc: 89.919%
	I - Batch: 850 | Loss: 1.801 | Acc: 92.081% | Wgt Acc: 89.749%
	I - Batch: 900 | Loss: 1.804 | Acc: 92.076% | Wgt Acc: 89.756%
	I - Batch: 950 | Loss: 1.803 | Acc: 92.099% | Wgt Acc: 89.725%
	I - Batch: 1000 | Loss: 1.805 | Acc: 92.100% | Wgt Acc: 89.791%
I - num batch: 1003
I - Train -- Loss: 1.805 | Acc: 92.101% | Wgt Acc: 89.798% | LR: 1.250000e-04 | Dur: 632.83s
I - Confusion Matrix: [row->prediction - col->label]
[[1798.    4.    6.    5.  109.]
 [   0. 1202.  103.    0.    6.]
 [   6.  628. 2481.    2.  159.]
 [   7.    2.    2. 1844.   86.]
 [  51.    2.   46.   43. 7448.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.808 | Acc: 40.125% | Wgt Acc: 39.483%
	I - Batch: 100 | Loss: 5.676 | Acc: 44.625% | Wgt Acc: 41.572%
	I - Batch: 150 | Loss: 5.540 | Acc: 50.125% | Wgt Acc: 43.208%
	I - Batch: 200 | Loss: 5.462 | Acc: 53.594% | Wgt Acc: 45.369%
I - num batch: 238
I - Val -- Loss: 5.459 | Acc: 54.008% | Wgt Acc: 45.547% | Dur: 116.62s
I - Confusion Matrix: [row->prediction - col->label]
[[290.  12.  40.  65.  33.]
 [  0. 184.  18.   3.   7.]
 [ 10. 228. 330.  32. 112.]
 [ 56.  38.  50. 252.  57.]
 [170. 264. 340. 215. 999.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 1.818 | Acc: 92.500% | Wgt Acc: 90.154%
	I - Batch: 100 | Loss: 1.773 | Acc: 93.250% | Wgt Acc: 90.835%
	I - Batch: 150 | Loss: 1.766 | Acc: 93.042% | Wgt Acc: 90.730%
	I - Batch: 200 | Loss: 1.772 | Acc: 93.125% | Wgt Acc: 90.865%
	I - Batch: 250 | Loss: 1.802 | Acc: 92.550% | Wgt Acc: 90.127%
	I - Batch: 300 | Loss: 1.798 | Acc: 92.667% | Wgt Acc: 90.365%
	I - Batch: 350 | Loss: 1.801 | Acc: 92.554% | Wgt Acc: 90.118%
	I - Batch: 400 | Loss: 1.797 | Acc: 92.797% | Wgt Acc: 90.380%
	I - Batch: 450 | Loss: 1.795 | Acc: 92.792% | Wgt Acc: 90.269%
	I - Batch: 500 | Loss: 1.791 | Acc: 92.912% | Wgt Acc: 90.519%
	I - Batch: 550 | Loss: 1.785 | Acc: 93.011% | Wgt Acc: 90.584%
	I - Batch: 600 | Loss: 1.782 | Acc: 93.083% | Wgt Acc: 90.637%
	I - Batch: 650 | Loss: 1.787 | Acc: 93.038% | Wgt Acc: 90.642%
	I - Batch: 700 | Loss: 1.790 | Acc: 92.991% | Wgt Acc: 90.569%
	I - Batch: 750 | Loss: 1.796 | Acc: 92.992% | Wgt Acc: 90.558%
	I - Batch: 800 | Loss: 1.798 | Acc: 92.945% | Wgt Acc: 90.541%
	I - Batch: 850 | Loss: 1.798 | Acc: 93.029% | Wgt Acc: 90.685%
	I - Batch: 900 | Loss: 1.799 | Acc: 92.986% | Wgt Acc: 90.688%
	I - Batch: 950 | Loss: 1.800 | Acc: 93.086% | Wgt Acc: 90.892%
	I - Batch: 1000 | Loss: 1.794 | Acc: 93.250% | Wgt Acc: 91.172%
I - num batch: 1003
I - Train -- Loss: 1.794 | Acc: 93.261% | Wgt Acc: 91.186% | LR: 1.250000e-04 | Dur: 619.57s
I - Confusion Matrix: [row->prediction - col->label]
[[1816.    4.    3.    7.   97.]
 [   0. 1292.   89.    1.   10.]
 [   4.  535. 2500.    6.  106.]
 [   5.    1.    5. 1833.   77.]
 [  37.    6.   41.   47. 7518.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.617 | Acc: 44.500% | Wgt Acc: 45.027%
	I - Batch: 100 | Loss: 5.506 | Acc: 48.812% | Wgt Acc: 47.381%
	I - Batch: 150 | Loss: 5.430 | Acc: 53.458% | Wgt Acc: 49.099%
	I - Batch: 200 | Loss: 5.398 | Acc: 55.500% | Wgt Acc: 49.920%
I - num batch: 238
I - Val -- Loss: 5.410 | Acc: 56.189% | Wgt Acc: 50.339% | Dur: 113.00s
I - Confusion Matrix: [row->prediction - col->label]
[[298.  18.  24.  64.  37.]
 [  2. 344. 132.  16.  37.]
 [ 12. 114. 238.  38.  89.]
 [ 72.  38.  46. 282.  69.]
 [142. 212. 338. 167. 976.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 1.781 | Acc: 96.250% | Wgt Acc: 95.695%
	I - Batch: 100 | Loss: 1.774 | Acc: 95.062% | Wgt Acc: 94.858%
	I - Batch: 150 | Loss: 1.762 | Acc: 94.750% | Wgt Acc: 94.756%
	I - Batch: 200 | Loss: 1.753 | Acc: 94.938% | Wgt Acc: 94.911%
	I - Batch: 250 | Loss: 1.749 | Acc: 94.975% | Wgt Acc: 95.024%
	I - Batch: 300 | Loss: 1.743 | Acc: 95.104% | Wgt Acc: 95.290%
	I - Batch: 350 | Loss: 1.740 | Acc: 95.286% | Wgt Acc: 95.497%
	I - Batch: 400 | Loss: 1.739 | Acc: 95.344% | Wgt Acc: 95.563%
	I - Batch: 450 | Loss: 1.737 | Acc: 95.486% | Wgt Acc: 95.628%
	I - Batch: 500 | Loss: 1.735 | Acc: 95.412% | Wgt Acc: 95.611%
	I - Batch: 550 | Loss: 1.747 | Acc: 95.216% | Wgt Acc: 95.403%
	I - Batch: 600 | Loss: 1.752 | Acc: 95.104% | Wgt Acc: 95.224%
	I - Batch: 650 | Loss: 1.772 | Acc: 94.596% | Wgt Acc: 94.657%
	I - Batch: 700 | Loss: 1.778 | Acc: 94.509% | Wgt Acc: 94.578%
	I - Batch: 750 | Loss: 1.781 | Acc: 94.433% | Wgt Acc: 94.503%
	I - Batch: 800 | Loss: 1.788 | Acc: 94.266% | Wgt Acc: 94.320%
	I - Batch: 850 | Loss: 1.786 | Acc: 94.243% | Wgt Acc: 94.365%
	I - Batch: 900 | Loss: 1.785 | Acc: 94.215% | Wgt Acc: 94.349%
	I - Batch: 950 | Loss: 1.787 | Acc: 94.118% | Wgt Acc: 94.276%
	I - Batch: 1000 | Loss: 1.785 | Acc: 94.138% | Wgt Acc: 94.275%
I - num batch: 1003
I - Train -- Loss: 1.784 | Acc: 94.152% | Wgt Acc: 94.291% | LR: 1.250000e-04 | Dur: 632.76s
I - Confusion Matrix: [row->prediction - col->label]
[[1796.    4.    7.   10.  134.]
 [   3. 1742.  228.    6.   51.]
 [   2.   81. 2338.    9.  154.]
 [   8.    3.    9. 1839.   82.]
 [  53.    8.   56.   30. 7387.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.903 | Acc: 40.500% | Wgt Acc: 39.874%
	I - Batch: 100 | Loss: 5.715 | Acc: 46.062% | Wgt Acc: 43.319%
	I - Batch: 150 | Loss: 5.596 | Acc: 50.042% | Wgt Acc: 44.016%
	I - Batch: 200 | Loss: 5.509 | Acc: 53.656% | Wgt Acc: 46.279%
I - num batch: 238
I - Val -- Loss: 5.497 | Acc: 54.481% | Wgt Acc: 46.559% | Dur: 115.71s
I - Confusion Matrix: [row->prediction - col->label]
[[279.  16.  40.  56.  36.]
 [  5. 212.  34.   5.  24.]
 [  6. 210. 306.  31.  77.]
 [ 87.  28.  40. 281.  76.]
 [149. 260. 358. 194. 995.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 1.679 | Acc: 95.250% | Wgt Acc: 95.226%
	I - Batch: 100 | Loss: 1.741 | Acc: 94.688% | Wgt Acc: 94.461%
	I - Batch: 150 | Loss: 1.756 | Acc: 94.417% | Wgt Acc: 94.378%
	I - Batch: 200 | Loss: 1.783 | Acc: 94.250% | Wgt Acc: 94.203%
	I - Batch: 250 | Loss: 1.786 | Acc: 94.100% | Wgt Acc: 94.278%
	I - Batch: 300 | Loss: 1.795 | Acc: 93.771% | Wgt Acc: 93.977%
	I - Batch: 350 | Loss: 1.801 | Acc: 93.482% | Wgt Acc: 93.770%
	I - Batch: 400 | Loss: 1.793 | Acc: 93.406% | Wgt Acc: 93.835%
	I - Batch: 450 | Loss: 1.780 | Acc: 93.528% | Wgt Acc: 94.004%
	I - Batch: 500 | Loss: 1.784 | Acc: 93.425% | Wgt Acc: 93.986%
	I - Batch: 550 | Loss: 1.788 | Acc: 93.364% | Wgt Acc: 93.949%
	I - Batch: 600 | Loss: 1.790 | Acc: 93.406% | Wgt Acc: 93.950%
	I - Batch: 650 | Loss: 1.792 | Acc: 93.317% | Wgt Acc: 93.878%
	I - Batch: 700 | Loss: 1.793 | Acc: 93.339% | Wgt Acc: 93.840%
	I - Batch: 750 | Loss: 1.796 | Acc: 93.250% | Wgt Acc: 93.737%
	I - Batch: 800 | Loss: 1.791 | Acc: 93.297% | Wgt Acc: 93.777%
	I - Batch: 850 | Loss: 1.787 | Acc: 93.368% | Wgt Acc: 93.854%
	I - Batch: 900 | Loss: 1.786 | Acc: 93.361% | Wgt Acc: 93.835%
	I - Batch: 950 | Loss: 1.781 | Acc: 93.461% | Wgt Acc: 93.903%
	I - Batch: 1000 | Loss: 1.782 | Acc: 93.369% | Wgt Acc: 93.832%
I - num batch: 1003
I - Train -- Loss: 1.781 | Acc: 93.379% | Wgt Acc: 93.844% | LR: 1.250000e-04 | Dur: 633.08s
I - Confusion Matrix: [row->prediction - col->label]
[[1786.    4.   11.   21.  149.]
 [   0. 1729.  138.    1.   69.]
 [   3.   94. 2410.    9.  217.]
 [  19.    3.    9. 1805.  125.]
 [  54.    8.   70.   58. 7248.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.719 | Acc: 42.500% | Wgt Acc: 42.483%
	I - Batch: 100 | Loss: 5.624 | Acc: 46.688% | Wgt Acc: 45.117%
	I - Batch: 150 | Loss: 5.511 | Acc: 50.917% | Wgt Acc: 46.242%
	I - Batch: 200 | Loss: 5.417 | Acc: 55.188% | Wgt Acc: 49.224%
I - num batch: 238
I - Val -- Loss: 5.434 | Acc: 55.979% | Wgt Acc: 49.562% | Dur: 116.60s
I - Confusion Matrix: [row->prediction - col->label]
[[364.  20.  42. 113.  73.]
 [  1. 322.  64.  18.  56.]
 [  6. 154. 312.  23.  81.]
 [ 22.  22.  28. 161.  27.]
 [133. 208. 332. 252. 971.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 1.736 | Acc: 94.125% | Wgt Acc: 94.097%
	I - Batch: 100 | Loss: 1.710 | Acc: 94.438% | Wgt Acc: 94.747%
	I - Batch: 150 | Loss: 1.743 | Acc: 93.750% | Wgt Acc: 94.065%
	I - Batch: 200 | Loss: 1.771 | Acc: 93.500% | Wgt Acc: 93.715%
	I - Batch: 250 | Loss: 1.775 | Acc: 93.350% | Wgt Acc: 93.736%
	I - Batch: 300 | Loss: 1.776 | Acc: 93.125% | Wgt Acc: 93.486%
	I - Batch: 350 | Loss: 1.783 | Acc: 93.161% | Wgt Acc: 93.498%
	I - Batch: 400 | Loss: 1.782 | Acc: 93.250% | Wgt Acc: 93.530%
	I - Batch: 450 | Loss: 1.782 | Acc: 93.125% | Wgt Acc: 93.493%
	I - Batch: 500 | Loss: 1.776 | Acc: 93.350% | Wgt Acc: 93.631%
	I - Batch: 550 | Loss: 1.772 | Acc: 93.455% | Wgt Acc: 93.739%
	I - Batch: 600 | Loss: 1.773 | Acc: 93.479% | Wgt Acc: 93.746%
	I - Batch: 650 | Loss: 1.766 | Acc: 93.663% | Wgt Acc: 93.912%
	I - Batch: 700 | Loss: 1.783 | Acc: 93.420% | Wgt Acc: 93.557%
	I - Batch: 750 | Loss: 1.798 | Acc: 93.117% | Wgt Acc: 93.224%
	I - Batch: 800 | Loss: 1.799 | Acc: 93.094% | Wgt Acc: 93.263%
	I - Batch: 850 | Loss: 1.799 | Acc: 93.074% | Wgt Acc: 93.256%
	I - Batch: 900 | Loss: 1.798 | Acc: 93.083% | Wgt Acc: 93.285%
	I - Batch: 950 | Loss: 1.800 | Acc: 93.020% | Wgt Acc: 93.225%
	I - Batch: 1000 | Loss: 1.802 | Acc: 92.944% | Wgt Acc: 93.152%
I - num batch: 1003
I - Train -- Loss: 1.802 | Acc: 92.949% | Wgt Acc: 93.162% | LR: 1.250000e-04 | Dur: 637.90s
I - Confusion Matrix: [row->prediction - col->label]
[[1751.    8.    8.   46.  171.]
 [   3. 1711.  112.    0.   57.]
 [   6.   98. 2434.    6.  178.]
 [  27.    2.   15. 1778.  167.]
 [  75.   19.   69.   64. 7235.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.531 | Acc: 48.875% | Wgt Acc: 48.761%
	I - Batch: 100 | Loss: 5.478 | Acc: 49.812% | Wgt Acc: 49.418%
	I - Batch: 150 | Loss: 5.423 | Acc: 52.417% | Wgt Acc: 50.340%
	I - Batch: 200 | Loss: 5.382 | Acc: 55.219% | Wgt Acc: 52.184%
I - num batch: 238
I - Val -- Loss: 5.393 | Acc: 55.164% | Wgt Acc: 51.847% | Dur: 116.63s
I - Confusion Matrix: [row->prediction - col->label]
[[415.  26.  70. 156.  98.]
 [  4. 250.  60.  33.  82.]
 [  8. 184. 324.  29.  88.]
 [ 49.  58.  50. 284. 114.]
 [ 50. 208. 274.  65. 826.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 1.803 | Acc: 92.875% | Wgt Acc: 93.304%
	I - Batch: 100 | Loss: 1.750 | Acc: 93.875% | Wgt Acc: 93.931%
	I - Batch: 150 | Loss: 1.713 | Acc: 94.750% | Wgt Acc: 94.890%
	I - Batch: 200 | Loss: 1.714 | Acc: 94.781% | Wgt Acc: 94.947%
	I - Batch: 250 | Loss: 1.737 | Acc: 94.375% | Wgt Acc: 94.375%
	I - Batch: 300 | Loss: 1.739 | Acc: 94.312% | Wgt Acc: 94.262%
	I - Batch: 350 | Loss: 1.735 | Acc: 94.482% | Wgt Acc: 94.409%
	I - Batch: 400 | Loss: 1.726 | Acc: 94.703% | Wgt Acc: 94.681%
	I - Batch: 450 | Loss: 1.730 | Acc: 94.431% | Wgt Acc: 94.436%
	I - Batch: 500 | Loss: 1.732 | Acc: 94.312% | Wgt Acc: 94.396%
	I - Batch: 550 | Loss: 1.724 | Acc: 94.432% | Wgt Acc: 94.513%
	I - Batch: 600 | Loss: 1.724 | Acc: 94.438% | Wgt Acc: 94.535%
	I - Batch: 650 | Loss: 1.726 | Acc: 94.317% | Wgt Acc: 94.388%
	I - Batch: 700 | Loss: 1.723 | Acc: 94.339% | Wgt Acc: 94.420%
	I - Batch: 750 | Loss: 1.714 | Acc: 94.425% | Wgt Acc: 94.544%
	I - Batch: 800 | Loss: 1.705 | Acc: 94.555% | Wgt Acc: 94.678%
	I - Batch: 850 | Loss: 1.699 | Acc: 94.632% | Wgt Acc: 94.785%
	I - Batch: 900 | Loss: 1.692 | Acc: 94.715% | Wgt Acc: 94.865%
	I - Batch: 950 | Loss: 1.692 | Acc: 94.724% | Wgt Acc: 94.867%
	I - Batch: 1000 | Loss: 1.691 | Acc: 94.675% | Wgt Acc: 94.840%
I - num batch: 1003
I - Train -- Loss: 1.691 | Acc: 94.670% | Wgt Acc: 94.831% | LR: 1.250000e-04 | Dur: 637.65s
I - Confusion Matrix: [row->prediction - col->label]
[[1768.    2.    6.   23.  140.]
 [   3. 1738.   97.    0.   29.]
 [   7.   83. 2483.    8.  154.]
 [  15.    4.    8. 1822.  111.]
 [  69.   11.   44.   41. 7374.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.673 | Acc: 45.625% | Wgt Acc: 45.282%
	I - Batch: 100 | Loss: 5.543 | Acc: 49.188% | Wgt Acc: 47.464%
	I - Batch: 150 | Loss: 5.461 | Acc: 53.083% | Wgt Acc: 48.703%
	I - Batch: 200 | Loss: 5.418 | Acc: 55.906% | Wgt Acc: 50.263%
I - num batch: 238
I - Val -- Loss: 5.418 | Acc: 56.373% | Wgt Acc: 50.620% | Dur: 116.59s
I - Confusion Matrix: [row->prediction - col->label]
[[269.  14.  36.  60.  37.]
 [  1. 254.  34.  10.  27.]
 [  9. 194. 358.  36. 104.]
 [122.  56.  84. 344. 120.]
 [125. 208. 266. 117. 920.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 1.585 | Acc: 95.625% | Wgt Acc: 96.599%
	I - Batch: 100 | Loss: 1.554 | Acc: 96.688% | Wgt Acc: 97.196%
	I - Batch: 150 | Loss: 1.562 | Acc: 96.292% | Wgt Acc: 96.937%
	I - Batch: 200 | Loss: 1.571 | Acc: 96.062% | Wgt Acc: 96.477%
	I - Batch: 250 | Loss: 1.573 | Acc: 96.150% | Wgt Acc: 96.527%
	I - Batch: 300 | Loss: 1.571 | Acc: 96.250% | Wgt Acc: 96.546%
	I - Batch: 350 | Loss: 1.570 | Acc: 96.286% | Wgt Acc: 96.555%
	I - Batch: 400 | Loss: 1.561 | Acc: 96.422% | Wgt Acc: 96.694%
	I - Batch: 450 | Loss: 1.560 | Acc: 96.417% | Wgt Acc: 96.713%
	I - Batch: 500 | Loss: 1.558 | Acc: 96.513% | Wgt Acc: 96.769%
	I - Batch: 550 | Loss: 1.558 | Acc: 96.523% | Wgt Acc: 96.817%
	I - Batch: 600 | Loss: 1.557 | Acc: 96.479% | Wgt Acc: 96.813%
	I - Batch: 650 | Loss: 1.556 | Acc: 96.490% | Wgt Acc: 96.831%
	I - Batch: 700 | Loss: 1.551 | Acc: 96.589% | Wgt Acc: 96.902%
	I - Batch: 750 | Loss: 1.548 | Acc: 96.625% | Wgt Acc: 96.941%
	I - Batch: 800 | Loss: 1.548 | Acc: 96.648% | Wgt Acc: 96.917%
	I - Batch: 850 | Loss: 1.549 | Acc: 96.662% | Wgt Acc: 96.874%
	I - Batch: 900 | Loss: 1.549 | Acc: 96.632% | Wgt Acc: 96.848%
	I - Batch: 950 | Loss: 1.552 | Acc: 96.579% | Wgt Acc: 96.801%
	I - Batch: 1000 | Loss: 1.551 | Acc: 96.575% | Wgt Acc: 96.828%
I - num batch: 1003
I - Train -- Loss: 1.552 | Acc: 96.565% | Wgt Acc: 96.820% | LR: 1.250000e-04 | Dur: 637.67s
I - Confusion Matrix: [row->prediction - col->label]
[[1804.    5.    4.    9.  107.]
 [   2. 1788.   49.    0.   17.]
 [   4.   38. 2540.    4.  112.]
 [  10.    1.    6. 1849.   64.]
 [  42.    6.   39.   32. 7508.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.642 | Acc: 46.875% | Wgt Acc: 47.005%
	I - Batch: 100 | Loss: 5.533 | Acc: 49.062% | Wgt Acc: 48.940%
	I - Batch: 150 | Loss: 5.449 | Acc: 51.833% | Wgt Acc: 49.227%
	I - Batch: 200 | Loss: 5.382 | Acc: 54.875% | Wgt Acc: 51.443%
I - num batch: 238
I - Val -- Loss: 5.395 | Acc: 55.164% | Wgt Acc: 51.849% | Dur: 116.26s
I - Confusion Matrix: [row->prediction - col->label]
[[420.  48.  94. 185. 170.]
 [  2. 262.  46.  10.  23.]
 [  6. 120. 306.  27.  67.]
 [ 53.  70.  72. 277. 114.]
 [ 45. 226. 260.  68. 834.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 1.606 | Acc: 95.125% | Wgt Acc: 95.052%
	I - Batch: 100 | Loss: 1.615 | Acc: 95.062% | Wgt Acc: 94.882%
	I - Batch: 150 | Loss: 1.600 | Acc: 95.458% | Wgt Acc: 95.588%
	I - Batch: 200 | Loss: 1.598 | Acc: 95.500% | Wgt Acc: 95.596%
	I - Batch: 250 | Loss: 1.594 | Acc: 95.600% | Wgt Acc: 95.674%
	I - Batch: 300 | Loss: 1.589 | Acc: 95.667% | Wgt Acc: 95.794%
	I - Batch: 350 | Loss: 1.584 | Acc: 95.804% | Wgt Acc: 95.952%
	I - Batch: 400 | Loss: 1.570 | Acc: 96.047% | Wgt Acc: 96.215%
	I - Batch: 450 | Loss: 1.577 | Acc: 96.014% | Wgt Acc: 96.177%
	I - Batch: 500 | Loss: 1.576 | Acc: 95.925% | Wgt Acc: 96.150%
	I - Batch: 550 | Loss: 1.573 | Acc: 96.057% | Wgt Acc: 96.234%
	I - Batch: 600 | Loss: 1.571 | Acc: 96.094% | Wgt Acc: 96.287%
	I - Batch: 650 | Loss: 1.570 | Acc: 96.192% | Wgt Acc: 96.370%
	I - Batch: 700 | Loss: 1.572 | Acc: 96.116% | Wgt Acc: 96.292%
	I - Batch: 750 | Loss: 1.574 | Acc: 96.083% | Wgt Acc: 96.298%
	I - Batch: 800 | Loss: 1.575 | Acc: 96.062% | Wgt Acc: 96.289%
	I - Batch: 850 | Loss: 1.569 | Acc: 96.184% | Wgt Acc: 96.408%
	I - Batch: 900 | Loss: 1.564 | Acc: 96.285% | Wgt Acc: 96.518%
	I - Batch: 950 | Loss: 1.559 | Acc: 96.322% | Wgt Acc: 96.601%
	I - Batch: 1000 | Loss: 1.558 | Acc: 96.331% | Wgt Acc: 96.646%
I - num batch: 1003
I - Train -- Loss: 1.557 | Acc: 96.340% | Wgt Acc: 96.654% | LR: 1.250000e-04 | Dur: 635.70s
I - Confusion Matrix: [row->prediction - col->label]
[[1808.    3.    7.   11.  112.]
 [   1. 1786.   46.    1.   23.]
 [   5.   35. 2542.    4.  122.]
 [   7.    1.    4. 1837.   71.]
 [  41.   13.   39.   41. 7480.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.037 | Acc: 36.625% | Wgt Acc: 36.281%
	I - Batch: 100 | Loss: 5.797 | Acc: 42.125% | Wgt Acc: 39.019%
	I - Batch: 150 | Loss: 5.641 | Acc: 48.417% | Wgt Acc: 41.742%
	I - Batch: 200 | Loss: 5.531 | Acc: 53.344% | Wgt Acc: 45.282%
I - num batch: 238
I - Val -- Loss: 5.534 | Acc: 54.192% | Wgt Acc: 45.624% | Dur: 114.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 344.   12.   46.   88.   63.]
 [   0.  170.   14.    6.   14.]
 [   9.  158.  280.   23.   59.]
 [  50.   32.   30.  243.   47.]
 [ 123.  354.  408.  207. 1025.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 1.466 | Acc: 98.125% | Wgt Acc: 98.217%
	I - Batch: 100 | Loss: 1.494 | Acc: 97.875% | Wgt Acc: 97.851%
	I - Batch: 150 | Loss: 1.493 | Acc: 97.542% | Wgt Acc: 97.696%
	I - Batch: 200 | Loss: 1.510 | Acc: 97.250% | Wgt Acc: 97.369%
	I - Batch: 250 | Loss: 1.521 | Acc: 97.100% | Wgt Acc: 97.189%
	I - Batch: 300 | Loss: 1.524 | Acc: 97.083% | Wgt Acc: 97.246%
	I - Batch: 350 | Loss: 1.519 | Acc: 97.161% | Wgt Acc: 97.298%
	I - Batch: 400 | Loss: 1.518 | Acc: 97.156% | Wgt Acc: 97.332%
	I - Batch: 450 | Loss: 1.519 | Acc: 97.153% | Wgt Acc: 97.367%
	I - Batch: 500 | Loss: 1.515 | Acc: 97.225% | Wgt Acc: 97.439%
	I - Batch: 550 | Loss: 1.508 | Acc: 97.318% | Wgt Acc: 97.543%
	I - Batch: 600 | Loss: 1.505 | Acc: 97.385% | Wgt Acc: 97.604%
	I - Batch: 650 | Loss: 1.504 | Acc: 97.385% | Wgt Acc: 97.609%
	I - Batch: 700 | Loss: 1.500 | Acc: 97.384% | Wgt Acc: 97.664%
	I - Batch: 750 | Loss: 1.499 | Acc: 97.358% | Wgt Acc: 97.669%
	I - Batch: 800 | Loss: 1.499 | Acc: 97.383% | Wgt Acc: 97.712%
	I - Batch: 850 | Loss: 1.498 | Acc: 97.390% | Wgt Acc: 97.732%
	I - Batch: 900 | Loss: 1.499 | Acc: 97.347% | Wgt Acc: 97.713%
	I - Batch: 950 | Loss: 1.497 | Acc: 97.421% | Wgt Acc: 97.771%
	I - Batch: 1000 | Loss: 1.497 | Acc: 97.419% | Wgt Acc: 97.764%
I - num batch: 1003
I - Train -- Loss: 1.498 | Acc: 97.413% | Wgt Acc: 97.752% | LR: 1.250000e-04 | Dur: 627.42s
I - Confusion Matrix: [row->prediction - col->label]
[[1824.    4.    5.    6.  101.]
 [   0. 1805.   17.    0.   13.]
 [   3.   22. 2584.    2.   87.]
 [   3.    1.    2. 1857.   52.]
 [  32.    6.   30.   29. 7555.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.735 | Acc: 46.000% | Wgt Acc: 44.581%
	I - Batch: 100 | Loss: 5.590 | Acc: 48.375% | Wgt Acc: 45.707%
	I - Batch: 150 | Loss: 5.503 | Acc: 51.958% | Wgt Acc: 47.000%
	I - Batch: 200 | Loss: 5.431 | Acc: 55.625% | Wgt Acc: 49.345%
I - num batch: 238
I - Val -- Loss: 5.426 | Acc: 56.189% | Wgt Acc: 49.803% | Dur: 114.26s
I - Confusion Matrix: [row->prediction - col->label]
[[318.   4.  24.  75.  37.]
 [  0. 244.  40.  12.  25.]
 [ 24. 234. 436.  51. 183.]
 [ 40.  40.  32. 223.  46.]
 [144. 204. 246. 206. 917.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 1.504 | Acc: 97.375% | Wgt Acc: 97.588%
	I - Batch: 100 | Loss: 1.462 | Acc: 98.000% | Wgt Acc: 98.378%
	I - Batch: 150 | Loss: 1.482 | Acc: 97.667% | Wgt Acc: 97.849%
	I - Batch: 200 | Loss: 1.484 | Acc: 97.750% | Wgt Acc: 97.841%
	I - Batch: 250 | Loss: 1.479 | Acc: 97.900% | Wgt Acc: 98.009%
	I - Batch: 300 | Loss: 1.474 | Acc: 98.000% | Wgt Acc: 98.145%
	I - Batch: 350 | Loss: 1.475 | Acc: 97.982% | Wgt Acc: 98.175%
	I - Batch: 400 | Loss: 1.480 | Acc: 97.906% | Wgt Acc: 98.097%
	I - Batch: 450 | Loss: 1.497 | Acc: 97.486% | Wgt Acc: 97.732%
	I - Batch: 500 | Loss: 1.516 | Acc: 97.150% | Wgt Acc: 97.446%
	I - Batch: 550 | Loss: 1.530 | Acc: 96.864% | Wgt Acc: 97.207%
	I - Batch: 600 | Loss: 1.541 | Acc: 96.677% | Wgt Acc: 97.043%
	I - Batch: 650 | Loss: 1.545 | Acc: 96.606% | Wgt Acc: 97.007%
	I - Batch: 700 | Loss: 1.543 | Acc: 96.661% | Wgt Acc: 97.044%
	I - Batch: 750 | Loss: 1.548 | Acc: 96.525% | Wgt Acc: 96.925%
	I - Batch: 800 | Loss: 1.551 | Acc: 96.445% | Wgt Acc: 96.831%
	I - Batch: 850 | Loss: 1.555 | Acc: 96.353% | Wgt Acc: 96.759%
	I - Batch: 900 | Loss: 1.554 | Acc: 96.389% | Wgt Acc: 96.786%
	I - Batch: 950 | Loss: 1.561 | Acc: 96.211% | Wgt Acc: 96.623%
	I - Batch: 1000 | Loss: 1.565 | Acc: 96.119% | Wgt Acc: 96.517%
I - num batch: 1003
I - Train -- Loss: 1.565 | Acc: 96.116% | Wgt Acc: 96.512% | LR: 1.250000e-04 | Dur: 629.59s
I - Confusion Matrix: [row->prediction - col->label]
[[1809.    7.    6.    9.  109.]
 [   1. 1778.   51.    0.   29.]
 [   5.   43. 2535.    4.  112.]
 [  11.    1.    5. 1844.  107.]
 [  36.    9.   41.   37. 7451.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.933 | Acc: 37.625% | Wgt Acc: 38.488%
	I - Batch: 100 | Loss: 5.748 | Acc: 43.562% | Wgt Acc: 41.648%
	I - Batch: 150 | Loss: 5.597 | Acc: 49.708% | Wgt Acc: 44.170%
	I - Batch: 200 | Loss: 5.499 | Acc: 54.031% | Wgt Acc: 47.238%
I - num batch: 238
I - Val -- Loss: 5.500 | Acc: 54.901% | Wgt Acc: 47.700% | Dur: 114.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 373.   18.   54.  122.   83.]
 [   0.  232.   12.    6.   23.]
 [   4.  102.  226.   21.   44.]
 [  49.   36.   40.  250.   50.]
 [ 100.  338.  446.  168. 1008.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 1.519 | Acc: 97.125% | Wgt Acc: 97.652%
	I - Batch: 100 | Loss: 1.492 | Acc: 97.312% | Wgt Acc: 98.015%
	I - Batch: 150 | Loss: 1.504 | Acc: 97.375% | Wgt Acc: 97.799%
	I - Batch: 200 | Loss: 1.514 | Acc: 97.031% | Wgt Acc: 97.480%
	I - Batch: 250 | Loss: 1.524 | Acc: 96.775% | Wgt Acc: 97.258%
	I - Batch: 300 | Loss: 1.549 | Acc: 96.354% | Wgt Acc: 96.708%
	I - Batch: 350 | Loss: 1.547 | Acc: 96.464% | Wgt Acc: 96.830%
	I - Batch: 400 | Loss: 1.561 | Acc: 96.156% | Wgt Acc: 96.624%
	I - Batch: 450 | Loss: 1.569 | Acc: 96.014% | Wgt Acc: 96.525%
	I - Batch: 500 | Loss: 1.571 | Acc: 95.950% | Wgt Acc: 96.483%
	I - Batch: 550 | Loss: 1.568 | Acc: 96.068% | Wgt Acc: 96.534%
	I - Batch: 600 | Loss: 1.566 | Acc: 96.125% | Wgt Acc: 96.570%
	I - Batch: 650 | Loss: 1.563 | Acc: 96.173% | Wgt Acc: 96.620%
	I - Batch: 700 | Loss: 1.562 | Acc: 96.152% | Wgt Acc: 96.594%
	I - Batch: 750 | Loss: 1.562 | Acc: 96.083% | Wgt Acc: 96.553%
	I - Batch: 800 | Loss: 1.559 | Acc: 96.125% | Wgt Acc: 96.594%
	I - Batch: 850 | Loss: 1.553 | Acc: 96.235% | Wgt Acc: 96.682%
	I - Batch: 900 | Loss: 1.549 | Acc: 96.333% | Wgt Acc: 96.758%
	I - Batch: 950 | Loss: 1.547 | Acc: 96.368% | Wgt Acc: 96.784%
	I - Batch: 1000 | Loss: 1.545 | Acc: 96.406% | Wgt Acc: 96.830%
I - num batch: 1003
I - Train -- Loss: 1.545 | Acc: 96.409% | Wgt Acc: 96.834% | LR: 1.250000e-04 | Dur: 630.83s
I - Confusion Matrix: [row->prediction - col->label]
[[1800.    5.    7.    7.  135.]
 [   0. 1794.   29.    0.   27.]
 [   1.   29. 2566.    3.   91.]
 [   5.    1.    5. 1842.   93.]
 [  56.    9.   31.   42. 7462.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.823 | Acc: 43.250% | Wgt Acc: 43.054%
	I - Batch: 100 | Loss: 5.660 | Acc: 48.500% | Wgt Acc: 46.137%
	I - Batch: 150 | Loss: 5.533 | Acc: 52.750% | Wgt Acc: 47.449%
	I - Batch: 200 | Loss: 5.433 | Acc: 56.969% | Wgt Acc: 50.345%
I - num batch: 238
I - Val -- Loss: 5.431 | Acc: 57.057% | Wgt Acc: 49.924% | Dur: 117.16s
I - Confusion Matrix: [row->prediction - col->label]
[[317.  10.  34.  78.  33.]
 [  1. 258.  26.   9.  33.]
 [ 10. 178. 352.  33. 106.]
 [ 49.  26.  44. 254.  46.]
 [149. 254. 322. 193. 990.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 1.469 | Acc: 98.125% | Wgt Acc: 98.329%
	I - Batch: 100 | Loss: 1.448 | Acc: 98.250% | Wgt Acc: 98.556%
	I - Batch: 150 | Loss: 1.448 | Acc: 98.042% | Wgt Acc: 98.495%
	I - Batch: 200 | Loss: 1.449 | Acc: 98.000% | Wgt Acc: 98.388%
	I - Batch: 250 | Loss: 1.446 | Acc: 98.125% | Wgt Acc: 98.519%
	I - Batch: 300 | Loss: 1.443 | Acc: 98.188% | Wgt Acc: 98.579%
	I - Batch: 350 | Loss: 1.451 | Acc: 98.125% | Wgt Acc: 98.440%
	I - Batch: 400 | Loss: 1.453 | Acc: 98.047% | Wgt Acc: 98.374%
	I - Batch: 450 | Loss: 1.455 | Acc: 98.097% | Wgt Acc: 98.441%
	I - Batch: 500 | Loss: 1.460 | Acc: 98.025% | Wgt Acc: 98.304%
	I - Batch: 550 | Loss: 1.464 | Acc: 97.909% | Wgt Acc: 98.202%
