Fri Oct 28 13:44:18 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.23, 0.24, 0.23, 0.25, 0.1], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'singleBackgroundPath': 'new_background', 'singleBackgroundPickle': True, 'tossFirstLastFrames': True}, 'dataPath': '/data_ssd/processed/kinetics400/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'lastLayerInitUniform': False, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 70.80867850098619, 'maxValidationTrainNo': 61, 'modelVersion': 19, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 62, 'validationAccThr': 70, 'warmStartConfig': {'checkpointFile': './sav/model17_trainNo60_at_epoch_197_with_acc_71_60_checkpoint.pth.tar', 'checkpointModelNo': 17, 'freezeSpatialCNN': True, 'warmStartFlag': True}, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Train set length:  3547
I - Label distribution: [ 697.  578.  734.  538. 1000.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test
I - Loading file: dataset_test_background00_no_samples180.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/test/new_background
I - New label distribution: [ 88.  78.  75.  86. 180.]

I - Test set length:  507
I - Label distribution: [ 88.  78.  75.  86. 180.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([   604,  84249,   8554,     62,   1063,  59310,    977,  44141,  15174,
         85978,  92582,   1060,    262,  93315, 191918,    918])
I - Initializing model TCNv19
I - Number of Model Parameters: 1292325
I - Warm start initiated
I - Initializing model TCNv17
I - Warm Start: Missing Keys ['tcn0.output_shift', 'tcn0.weight_bits', 'tcn0.bias_bits', 'tcn0.quantize_activation', 'tcn0.adjust_output_shift', 'tcn0.shift_quantile', 'tcn0.op.weight', 'tcn0.op.bias', 'tcn1.output_shift', 'tcn1.weight_bits', 'tcn1.bias_bits', 'tcn1.quantize_activation', 'tcn1.adjust_output_shift', 'tcn1.shift_quantile', 'tcn1.op.weight', 'tcn1.op.bias']
I - Warm Start: Unexpected Keys ['fc.output_shift', 'fc.weight_bits', 'fc.bias_bits', 'fc.quantize_activation', 'fc.adjust_output_shift', 'fc.shift_quantile', 'fc.op.weight']
I - Freezing common parameters of models 19 and 17
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv19                                   [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 128, 64, 64]         6
│    └─ReLU: 2-1722                      [16, 128, 64, 64]         --
│    └─Conv2d: 2-2                       --                        (6,272)
│    └─BatchNorm2d: 2-1720               [16, 128, 64, 64]         --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-1721                    [16, 128, 64, 64]         --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [128, 48, 1, 1]           --
│    └─Empty: 2-9                        [128, 48, 1, 1]           --
│    └─Empty: 2-10                       [128]                     --
│    └─Empty: 2-11                       [128]                     --
│    └─BatchNorm2d: 2-12                 [16, 128, 64, 64]         --
│    └─Scaler: 2-13                      [16, 128, 64, 64]         --
│    └─ReLU: 2-14                        [16, 128, 64, 64]         --
│    └─Empty: 2-15                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-173        [16, 128, 32, 32]         (recursive)
│    └─ReLU: 2-1737                      [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-1725                 [16, 128, 32, 32]         --
│    └─Conv2d: 2-18                      --                        (147,584)
│    └─BatchNorm2d: 2-1735               [16, 128, 32, 32]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-20                       [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-3          [16, 128, 32, 32]         147,590
│    └─Scaler: 2-1736                    [16, 128, 32, 32]         --
│    └─MaxPool2d: 2-22                   [16, 128, 32, 32]         --
│    └─Empty: 2-23                       [16, 128, 32, 32]         --
│    └─Empty: 2-24                       [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [128, 128, 3, 3]          --
│    └─Empty: 2-29                       [128, 128, 3, 3]          --
│    └─Empty: 2-30                       [128]                     --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1752                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1740                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-33                      --                        (147,584)
│    └─BatchNorm2d: 2-1750               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-35                       [128]                     --
│    └─BatchNorm2d: 2-36                 [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1751                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-38                      [16, 128, 32, 32]         --
│    └─ReLU: 2-39                        [16, 128, 32, 32]         --
│    └─Empty: 2-40                       [16, 128, 32, 32]         --
│    └─Clamp: 2-41                       [16, 128, 32, 32]         --
├─Dropout2d: 1-5                         [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-6          [16, 128, 16, 16]         131,078
│    └─MaxPool2d: 2-42                   [16, 128, 16, 16]         --
│    └─Empty: 2-1741                     [16, 128, 16, 16]         --
│    └─Empty: 2-1742                     [16, 128, 16, 16]         --
│    └─Empty: 2-45                       [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1764                      [16, 128, 16, 16]         --
│    └─Conv2d: 2-47                      --                        (16,512)
│    └─BatchNorm2d: 2-1762               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-49                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-50          --                        --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1763                    [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-52                         [1]                       --
│    └─OutputScale: 2-53                 --                        --
│    └─Empty: 2-54                       [128, 128, 3, 3]          --
│    └─Empty: 2-55                       [128, 128, 3, 3]          --
│    └─Empty: 2-56                       [128]                     --
│    └─Empty: 2-57                       [128]                     --
│    └─BatchNorm2d: 2-58                 [16, 128, 16, 16]         --
│    └─Scaler: 2-59                      [16, 128, 16, 16]         --
│    └─ReLU: 2-60                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─ReLU: 2-1779                      [16, 128, 16, 16]         --
│    └─MaxPool2d: 2-1767                 [16, 128, 16, 16]         --
│    └─Conv2d: 2-63                      --                        (147,584)
│    └─BatchNorm2d: 2-1777               [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-65                       [16, 128, 16, 16]         --
│    └─Clamp: 2-66                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1778                    [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-8                 [16, 128, 16, 16]         16,518
│    └─OutputShiftSqueeze: 2-68          --                        --
│    └─One: 2-69                         [1]                       --
│    └─OutputScale: 2-70                 --                        --
│    └─Empty: 2-71                       [128, 128, 1, 1]          --
│    └─Empty: 2-72                       [128, 128, 1, 1]          --
│    └─Empty: 2-73                       [128]                     --
│    └─Empty: 2-74                       [128]                     --
│    └─BatchNorm2d: 2-75                 [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 8, 8]           (recursive)
│    └─ReLU: 2-1794                      [16, 128, 8, 8]           --
│    └─MaxPool2d: 2-1782                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-78                      --                        (147,584)
│    └─BatchNorm2d: 2-1792               [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-80                      [16, 128, 16, 16]         --
│    └─ReLU: 2-81                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1793                    [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-83                       [16, 128, 16, 16]         --
│    └─Clamp: 2-84                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-10         [16, 128, 16, 16]         145,526
│    └─MaxPool2d: 2-85                   [16, 128, 16, 16]         --
│    └─Empty: 2-86                       [16, 128, 16, 16]         --
│    └─Empty: 2-87                       [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-88          --                        --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1783                     [16, 128, 8, 8]           --
│    └─Empty: 2-1784                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─One: 2-91                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1806                      [16, 16, 8, 8]            --
│    └─Conv2d: 2-93                      --                        (2,064)
│    └─BatchNorm2d: 2-1804               [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [128, 128, 3, 3]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1805                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-98                       [128, 128, 3, 3]          --
│    └─Empty: 2-99                       [128]                     --
│    └─Empty: 2-100                      [128]                     --
│    └─BatchNorm2d: 2-101                [16, 128, 16, 16]         --
│    └─Scaler: 2-102                     [16, 128, 16, 16]         --
│    └─ReLU: 2-103                       [16, 128, 16, 16]         --
│    └─Empty: 2-104                      [16, 128, 16, 16]         --
│    └─Clamp: 2-105                      [16, 128, 16, 16]         --
├─Dropout2d: 1-11                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 16, 8, 8]            (recursive)
│    └─ReLU: 2-1821                      [16, 16, 8, 8]            --
│    └─MaxPool2d: 2-1809                 [16, 128, 8, 8]           --
│    └─Conv2d: 2-108                     --                        (18,448)
│    └─BatchNorm2d: 2-1819               [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-13         [16, 128, 8, 8]           147,590
│    └─MaxPool2d: 2-110                  [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1820                    [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-112                      [16, 128, 8, 8]           --
│    └─Empty: 2-113                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-114         --                        --
│    └─One: 2-115                        [1]                       --
│    └─OutputScale: 2-116                --                        --
│    └─Empty: 2-117                      [128, 128, 3, 3]          --
│    └─Empty: 2-118                      [128, 128, 3, 3]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1810                     [16, 128, 8, 8]           --
│    └─Empty: 2-1811                     [16, 128, 8, 8]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-121                      [128]                     --
│    └─Empty: 2-122                      [128]                     --
│    └─BatchNorm2d: 2-123                [16, 128, 8, 8]           --
│    └─Scaler: 2-124                     [16, 128, 8, 8]           --
│    └─ReLU: 2-125                       [16, 128, 8, 8]           --
│    └─Empty: 2-126                      [16, 128, 8, 8]           --
│    └─Clamp: 2-127                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-14                [16, 16, 8, 8]            2,070
├─Conv1d: 1                              --                        --
│    └─Scaler: 2-1831                    [16, 128, 12]             --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-129         --                        --
│    └─One: 2-130                        [1]                       --
│    └─OutputScale: 2-131                --                        --
│    └─Empty: 2-132                      [16, 128, 1, 1]           --
│    └─Empty: 2-133                      [16, 128, 1, 1]           --
│    └─Empty: 2-134                      [16]                      --
│    └─Empty: 2-135                      [16]                      --
│    └─BatchNorm2d: 2-136                [16, 16, 8, 8]            --
│    └─Scaler: 2-137                     [16, 16, 8, 8]            --
├─Conv1d: 1-184                          [16, 5, 8]                (recursive)
│    └─Empty: 2-1843                     [16, 5, 8]                --
│    └─Conv1d: 2-139                     --                        3,205
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-140                       [16, 16, 8, 8]            --
│    └─Empty: 2-141                      [16, 16, 8, 8]            --
├─Conv1d: 1                              --                        --
│    └─Scaler: 2-1842                    [16, 5, 8]                --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-143                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-16         [16, 16, 8, 8]            18,454
│    └─MaxPool2d: 2-144                  [16, 128, 8, 8]           --
│    └─Empty: 2-145                      [16, 128, 8, 8]           --
│    └─Empty: 2-146                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-147         --                        --
│    └─One: 2-148                        [1]                       --
│    └─OutputScale: 2-149                --                        --
│    └─Empty: 2-150                      [16, 128, 3, 3]           --
│    └─Empty: 2-151                      [16, 128, 3, 3]           --
│    └─Empty: 2-152                      [16]                      --
│    └─Empty: 2-153                      [16]                      --
│    └─BatchNorm2d: 2-154                [16, 16, 8, 8]            --
│    └─Scaler: 2-155                     [16, 16, 8, 8]            --
│    └─ReLU: 2-156                       [16, 16, 8, 8]            --
│    └─Empty: 2-157                      [16, 16, 8, 8]            --
│    └─Clamp: 2-158                      [16, 16, 8, 8]            --
├─Dropout2d: 1-17                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-18                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-159         --                        --
│    └─One: 2-160                        [1]                       --
│    └─OutputScale: 2-161                --                        --
│    └─Empty: 2-162                      [128, 48, 1, 1]           --
│    └─Empty: 2-163                      [128, 48, 1, 1]           --
│    └─Empty: 2-164                      [128]                     --
│    └─Empty: 2-165                      [128]                     --
│    └─BatchNorm2d: 2-166                [16, 128, 64, 64]         --
│    └─Scaler: 2-167                     [16, 128, 64, 64]         --
│    └─ReLU: 2-168                       [16, 128, 64, 64]         --
│    └─Empty: 2-169                      [16, 128, 64, 64]         --
│    └─Clamp: 2-170                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-19         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-171                  [16, 128, 32, 32]         --
│    └─Empty: 2-172                      [16, 128, 32, 32]         --
│    └─Empty: 2-173                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-174         --                        --
│    └─One: 2-175                        [1]                       --
│    └─OutputScale: 2-176                --                        --
│    └─Empty: 2-177                      [128, 128, 3, 3]          --
│    └─Empty: 2-178                      [128, 128, 3, 3]          --
│    └─Empty: 2-179                      [128]                     --
│    └─Empty: 2-180                      [128]                     --
│    └─BatchNorm2d: 2-181                [16, 128, 32, 32]         --
│    └─Scaler: 2-182                     [16, 128, 32, 32]         --
│    └─ReLU: 2-183                       [16, 128, 32, 32]         --
│    └─Empty: 2-184                      [16, 128, 32, 32]         --
│    └─Clamp: 2-185                      [16, 128, 32, 32]         --
├─Dropout2d: 1-20                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-21         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-186                  [16, 128, 16, 16]         --
│    └─Empty: 2-187                      [16, 128, 16, 16]         --
│    └─Empty: 2-188                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-189         --                        --
│    └─One: 2-190                        [1]                       --
│    └─OutputScale: 2-191                --                        --
│    └─Empty: 2-192                      [128, 128, 3, 3]          --
│    └─Empty: 2-193                      [128, 128, 3, 3]          --
│    └─Empty: 2-194                      [128]                     --
│    └─Empty: 2-195                      [128]                     --
│    └─BatchNorm2d: 2-196                [16, 128, 16, 16]         --
│    └─Scaler: 2-197                     [16, 128, 16, 16]         --
│    └─ReLU: 2-198                       [16, 128, 16, 16]         --
│    └─Empty: 2-199                      [16, 128, 16, 16]         --
│    └─Clamp: 2-200                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-22                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-201         --                        --
│    └─One: 2-202                        [1]                       --
│    └─OutputScale: 2-203                --                        --
│    └─Empty: 2-204                      [128, 128, 1, 1]          --
│    └─Empty: 2-205                      [128, 128, 1, 1]          --
│    └─Empty: 2-206                      [128]                     --
│    └─Empty: 2-207                      [128]                     --
│    └─BatchNorm2d: 2-208                [16, 128, 16, 16]         --
│    └─Scaler: 2-209                     [16, 128, 16, 16]         --
│    └─ReLU: 2-210                       [16, 128, 16, 16]         --
│    └─Empty: 2-211                      [16, 128, 16, 16]         --
│    └─Clamp: 2-212                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-213                  [16, 128, 16, 16]         --
│    └─Empty: 2-214                      [16, 128, 16, 16]         --
│    └─Empty: 2-215                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-216         --                        --
│    └─One: 2-217                        [1]                       --
│    └─OutputScale: 2-218                --                        --
│    └─Empty: 2-219                      [128, 128, 3, 3]          --
│    └─Empty: 2-220                      [128, 128, 3, 3]          --
│    └─Empty: 2-221                      [128]                     --
│    └─Empty: 2-222                      [128]                     --
│    └─BatchNorm2d: 2-223                [16, 128, 16, 16]         --
│    └─Scaler: 2-224                     [16, 128, 16, 16]         --
│    └─ReLU: 2-225                       [16, 128, 16, 16]         --
│    └─Empty: 2-226                      [16, 128, 16, 16]         --
│    └─Clamp: 2-227                      [16, 128, 16, 16]         --
├─Dropout2d: 1-24                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-228                  [16, 128, 8, 8]           --
│    └─Empty: 2-229                      [16, 128, 8, 8]           --
│    └─Empty: 2-230                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-231         --                        --
│    └─One: 2-232                        [1]                       --
│    └─OutputScale: 2-233                --                        --
│    └─Empty: 2-234                      [128, 128, 3, 3]          --
│    └─Empty: 2-235                      [128, 128, 3, 3]          --
│    └─Empty: 2-236                      [128]                     --
│    └─Empty: 2-237                      [128]                     --
│    └─BatchNorm2d: 2-238                [16, 128, 8, 8]           --
│    └─Scaler: 2-239                     [16, 128, 8, 8]           --
│    └─ReLU: 2-240                       [16, 128, 8, 8]           --
│    └─Empty: 2-241                      [16, 128, 8, 8]           --
│    └─Clamp: 2-242                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-26                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-243         --                        --
│    └─One: 2-244                        [1]                       --
│    └─OutputScale: 2-245                --                        --
│    └─Empty: 2-246                      [16, 128, 1, 1]           --
│    └─Empty: 2-247                      [16, 128, 1, 1]           --
│    └─Empty: 2-248                      [16]                      --
│    └─Empty: 2-249                      [16]                      --
│    └─BatchNorm2d: 2-250                [16, 16, 8, 8]            --
│    └─Scaler: 2-251                     [16, 16, 8, 8]            --
│    └─ReLU: 2-252                       [16, 16, 8, 8]            --
│    └─Empty: 2-253                      [16, 16, 8, 8]            --
│    └─Clamp: 2-254                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-27         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-255                  [16, 128, 8, 8]           --
│    └─Empty: 2-256                      [16, 128, 8, 8]           --
│    └─Empty: 2-257                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-258         --                        --
│    └─One: 2-259                        [1]                       --
│    └─OutputScale: 2-260                --                        --
│    └─Empty: 2-261                      [16, 128, 3, 3]           --
│    └─Empty: 2-262                      [16, 128, 3, 3]           --
│    └─Empty: 2-263                      [16]                      --
│    └─Empty: 2-264                      [16]                      --
│    └─BatchNorm2d: 2-265                [16, 16, 8, 8]            --
│    └─Scaler: 2-266                     [16, 16, 8, 8]            --
│    └─ReLU: 2-267                       [16, 16, 8, 8]            --
│    └─Empty: 2-268                      [16, 16, 8, 8]            --
│    └─Clamp: 2-269                      [16, 16, 8, 8]            --
├─Dropout2d: 1-28                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-29                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-270         --                        --
│    └─One: 2-271                        [1]                       --
│    └─OutputScale: 2-272                --                        --
│    └─Empty: 2-273                      [128, 48, 1, 1]           --
│    └─Empty: 2-274                      [128, 48, 1, 1]           --
│    └─Empty: 2-275                      [128]                     --
│    └─Empty: 2-276                      [128]                     --
│    └─BatchNorm2d: 2-277                [16, 128, 64, 64]         --
│    └─Scaler: 2-278                     [16, 128, 64, 64]         --
│    └─ReLU: 2-279                       [16, 128, 64, 64]         --
│    └─Empty: 2-280                      [16, 128, 64, 64]         --
│    └─Clamp: 2-281                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-30         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-282                  [16, 128, 32, 32]         --
│    └─Empty: 2-283                      [16, 128, 32, 32]         --
│    └─Empty: 2-284                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-285         --                        --
│    └─One: 2-286                        [1]                       --
│    └─OutputScale: 2-287                --                        --
│    └─Empty: 2-288                      [128, 128, 3, 3]          --
│    └─Empty: 2-289                      [128, 128, 3, 3]          --
│    └─Empty: 2-290                      [128]                     --
│    └─Empty: 2-291                      [128]                     --
│    └─BatchNorm2d: 2-292                [16, 128, 32, 32]         --
│    └─Scaler: 2-293                     [16, 128, 32, 32]         --
│    └─ReLU: 2-294                       [16, 128, 32, 32]         --
│    └─Empty: 2-295                      [16, 128, 32, 32]         --
│    └─Clamp: 2-296                      [16, 128, 32, 32]         --
├─Dropout2d: 1-31                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-297                  [16, 128, 16, 16]         --
│    └─Empty: 2-298                      [16, 128, 16, 16]         --
│    └─Empty: 2-299                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-300         --                        --
│    └─One: 2-301                        [1]                       --
│    └─OutputScale: 2-302                --                        --
│    └─Empty: 2-303                      [128, 128, 3, 3]          --
│    └─Empty: 2-304                      [128, 128, 3, 3]          --
│    └─Empty: 2-305                      [128]                     --
│    └─Empty: 2-306                      [128]                     --
│    └─BatchNorm2d: 2-307                [16, 128, 16, 16]         --
│    └─Scaler: 2-308                     [16, 128, 16, 16]         --
│    └─ReLU: 2-309                       [16, 128, 16, 16]         --
│    └─Empty: 2-310                      [16, 128, 16, 16]         --
│    └─Clamp: 2-311                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-33                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-312         --                        --
│    └─One: 2-313                        [1]                       --
│    └─OutputScale: 2-314                --                        --
│    └─Empty: 2-315                      [128, 128, 1, 1]          --
│    └─Empty: 2-316                      [128, 128, 1, 1]          --
│    └─Empty: 2-317                      [128]                     --
│    └─Empty: 2-318                      [128]                     --
│    └─BatchNorm2d: 2-319                [16, 128, 16, 16]         --
│    └─Scaler: 2-320                     [16, 128, 16, 16]         --
│    └─ReLU: 2-321                       [16, 128, 16, 16]         --
│    └─Empty: 2-322                      [16, 128, 16, 16]         --
│    └─Clamp: 2-323                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-324                  [16, 128, 16, 16]         --
│    └─Empty: 2-325                      [16, 128, 16, 16]         --
│    └─Empty: 2-326                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-327         --                        --
│    └─One: 2-328                        [1]                       --
│    └─OutputScale: 2-329                --                        --
│    └─Empty: 2-330                      [128, 128, 3, 3]          --
│    └─Empty: 2-331                      [128, 128, 3, 3]          --
│    └─Empty: 2-332                      [128]                     --
│    └─Empty: 2-333                      [128]                     --
│    └─BatchNorm2d: 2-334                [16, 128, 16, 16]         --
│    └─Scaler: 2-335                     [16, 128, 16, 16]         --
│    └─ReLU: 2-336                       [16, 128, 16, 16]         --
│    └─Empty: 2-337                      [16, 128, 16, 16]         --
│    └─Clamp: 2-338                      [16, 128, 16, 16]         --
├─Dropout2d: 1-35                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-36         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-339                  [16, 128, 8, 8]           --
│    └─Empty: 2-340                      [16, 128, 8, 8]           --
│    └─Empty: 2-341                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-342         --                        --
│    └─One: 2-343                        [1]                       --
│    └─OutputScale: 2-344                --                        --
│    └─Empty: 2-345                      [128, 128, 3, 3]          --
│    └─Empty: 2-346                      [128, 128, 3, 3]          --
│    └─Empty: 2-347                      [128]                     --
│    └─Empty: 2-348                      [128]                     --
│    └─BatchNorm2d: 2-349                [16, 128, 8, 8]           --
│    └─Scaler: 2-350                     [16, 128, 8, 8]           --
│    └─ReLU: 2-351                       [16, 128, 8, 8]           --
│    └─Empty: 2-352                      [16, 128, 8, 8]           --
│    └─Clamp: 2-353                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-37                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-354         --                        --
│    └─One: 2-355                        [1]                       --
│    └─OutputScale: 2-356                --                        --
│    └─Empty: 2-357                      [16, 128, 1, 1]           --
│    └─Empty: 2-358                      [16, 128, 1, 1]           --
│    └─Empty: 2-359                      [16]                      --
│    └─Empty: 2-360                      [16]                      --
│    └─BatchNorm2d: 2-361                [16, 16, 8, 8]            --
│    └─Scaler: 2-362                     [16, 16, 8, 8]            --
│    └─ReLU: 2-363                       [16, 16, 8, 8]            --
│    └─Empty: 2-364                      [16, 16, 8, 8]            --
│    └─Clamp: 2-365                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-38         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-366                  [16, 128, 8, 8]           --
│    └─Empty: 2-367                      [16, 128, 8, 8]           --
│    └─Empty: 2-368                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-369         --                        --
│    └─One: 2-370                        [1]                       --
│    └─OutputScale: 2-371                --                        --
│    └─Empty: 2-372                      [16, 128, 3, 3]           --
│    └─Empty: 2-373                      [16, 128, 3, 3]           --
│    └─Empty: 2-374                      [16]                      --
│    └─Empty: 2-375                      [16]                      --
│    └─BatchNorm2d: 2-376                [16, 16, 8, 8]            --
│    └─Scaler: 2-377                     [16, 16, 8, 8]            --
│    └─ReLU: 2-378                       [16, 16, 8, 8]            --
│    └─Empty: 2-379                      [16, 16, 8, 8]            --
│    └─Clamp: 2-380                      [16, 16, 8, 8]            --
├─Dropout2d: 1-39                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-40                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-381         --                        --
│    └─One: 2-382                        [1]                       --
│    └─OutputScale: 2-383                --                        --
│    └─Empty: 2-384                      [128, 48, 1, 1]           --
│    └─Empty: 2-385                      [128, 48, 1, 1]           --
│    └─Empty: 2-386                      [128]                     --
│    └─Empty: 2-387                      [128]                     --
│    └─BatchNorm2d: 2-388                [16, 128, 64, 64]         --
│    └─Scaler: 2-389                     [16, 128, 64, 64]         --
│    └─ReLU: 2-390                       [16, 128, 64, 64]         --
│    └─Empty: 2-391                      [16, 128, 64, 64]         --
│    └─Clamp: 2-392                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-393                  [16, 128, 32, 32]         --
│    └─Empty: 2-394                      [16, 128, 32, 32]         --
│    └─Empty: 2-395                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-396         --                        --
│    └─One: 2-397                        [1]                       --
│    └─OutputScale: 2-398                --                        --
│    └─Empty: 2-399                      [128, 128, 3, 3]          --
│    └─Empty: 2-400                      [128, 128, 3, 3]          --
│    └─Empty: 2-401                      [128]                     --
│    └─Empty: 2-402                      [128]                     --
│    └─BatchNorm2d: 2-403                [16, 128, 32, 32]         --
│    └─Scaler: 2-404                     [16, 128, 32, 32]         --
│    └─ReLU: 2-405                       [16, 128, 32, 32]         --
│    └─Empty: 2-406                      [16, 128, 32, 32]         --
│    └─Clamp: 2-407                      [16, 128, 32, 32]         --
├─Dropout2d: 1-42                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-408                  [16, 128, 16, 16]         --
│    └─Empty: 2-409                      [16, 128, 16, 16]         --
│    └─Empty: 2-410                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-411         --                        --
│    └─One: 2-412                        [1]                       --
│    └─OutputScale: 2-413                --                        --
│    └─Empty: 2-414                      [128, 128, 3, 3]          --
│    └─Empty: 2-415                      [128, 128, 3, 3]          --
│    └─Empty: 2-416                      [128]                     --
│    └─Empty: 2-417                      [128]                     --
│    └─BatchNorm2d: 2-418                [16, 128, 16, 16]         --
│    └─Scaler: 2-419                     [16, 128, 16, 16]         --
│    └─ReLU: 2-420                       [16, 128, 16, 16]         --
│    └─Empty: 2-421                      [16, 128, 16, 16]         --
│    └─Clamp: 2-422                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-44                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-423         --                        --
│    └─One: 2-424                        [1]                       --
│    └─OutputScale: 2-425                --                        --
│    └─Empty: 2-426                      [128, 128, 1, 1]          --
│    └─Empty: 2-427                      [128, 128, 1, 1]          --
│    └─Empty: 2-428                      [128]                     --
│    └─Empty: 2-429                      [128]                     --
│    └─BatchNorm2d: 2-430                [16, 128, 16, 16]         --
│    └─Scaler: 2-431                     [16, 128, 16, 16]         --
│    └─ReLU: 2-432                       [16, 128, 16, 16]         --
│    └─Empty: 2-433                      [16, 128, 16, 16]         --
│    └─Clamp: 2-434                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-435                  [16, 128, 16, 16]         --
│    └─Empty: 2-436                      [16, 128, 16, 16]         --
│    └─Empty: 2-437                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-438         --                        --
│    └─One: 2-439                        [1]                       --
│    └─OutputScale: 2-440                --                        --
│    └─Empty: 2-441                      [128, 128, 3, 3]          --
│    └─Empty: 2-442                      [128, 128, 3, 3]          --
│    └─Empty: 2-443                      [128]                     --
│    └─Empty: 2-444                      [128]                     --
│    └─BatchNorm2d: 2-445                [16, 128, 16, 16]         --
│    └─Scaler: 2-446                     [16, 128, 16, 16]         --
│    └─ReLU: 2-447                       [16, 128, 16, 16]         --
│    └─Empty: 2-448                      [16, 128, 16, 16]         --
│    └─Clamp: 2-449                      [16, 128, 16, 16]         --
├─Dropout2d: 1-46                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-450                  [16, 128, 8, 8]           --
│    └─Empty: 2-451                      [16, 128, 8, 8]           --
│    └─Empty: 2-452                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-453         --                        --
│    └─One: 2-454                        [1]                       --
│    └─OutputScale: 2-455                --                        --
│    └─Empty: 2-456                      [128, 128, 3, 3]          --
│    └─Empty: 2-457                      [128, 128, 3, 3]          --
│    └─Empty: 2-458                      [128]                     --
│    └─Empty: 2-459                      [128]                     --
│    └─BatchNorm2d: 2-460                [16, 128, 8, 8]           --
│    └─Scaler: 2-461                     [16, 128, 8, 8]           --
│    └─ReLU: 2-462                       [16, 128, 8, 8]           --
│    └─Empty: 2-463                      [16, 128, 8, 8]           --
│    └─Clamp: 2-464                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-48                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-465         --                        --
│    └─One: 2-466                        [1]                       --
│    └─OutputScale: 2-467                --                        --
│    └─Empty: 2-468                      [16, 128, 1, 1]           --
│    └─Empty: 2-469                      [16, 128, 1, 1]           --
│    └─Empty: 2-470                      [16]                      --
│    └─Empty: 2-471                      [16]                      --
│    └─BatchNorm2d: 2-472                [16, 16, 8, 8]            --
│    └─Scaler: 2-473                     [16, 16, 8, 8]            --
│    └─ReLU: 2-474                       [16, 16, 8, 8]            --
│    └─Empty: 2-475                      [16, 16, 8, 8]            --
│    └─Clamp: 2-476                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-477                  [16, 128, 8, 8]           --
│    └─Empty: 2-478                      [16, 128, 8, 8]           --
│    └─Empty: 2-479                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-480         --                        --
│    └─One: 2-481                        [1]                       --
│    └─OutputScale: 2-482                --                        --
│    └─Empty: 2-483                      [16, 128, 3, 3]           --
│    └─Empty: 2-484                      [16, 128, 3, 3]           --
│    └─Empty: 2-485                      [16]                      --
│    └─Empty: 2-486                      [16]                      --
│    └─BatchNorm2d: 2-487                [16, 16, 8, 8]            --
│    └─Scaler: 2-488                     [16, 16, 8, 8]            --
│    └─ReLU: 2-489                       [16, 16, 8, 8]            --
│    └─Empty: 2-490                      [16, 16, 8, 8]            --
│    └─Clamp: 2-491                      [16, 16, 8, 8]            --
├─Dropout2d: 1-50                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-51                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-492         --                        --
│    └─One: 2-493                        [1]                       --
│    └─OutputScale: 2-494                --                        --
│    └─Empty: 2-495                      [128, 48, 1, 1]           --
│    └─Empty: 2-496                      [128, 48, 1, 1]           --
│    └─Empty: 2-497                      [128]                     --
│    └─Empty: 2-498                      [128]                     --
│    └─BatchNorm2d: 2-499                [16, 128, 64, 64]         --
│    └─Scaler: 2-500                     [16, 128, 64, 64]         --
│    └─ReLU: 2-501                       [16, 128, 64, 64]         --
│    └─Empty: 2-502                      [16, 128, 64, 64]         --
│    └─Clamp: 2-503                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-52         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-504                  [16, 128, 32, 32]         --
│    └─Empty: 2-505                      [16, 128, 32, 32]         --
│    └─Empty: 2-506                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-507         --                        --
│    └─One: 2-508                        [1]                       --
│    └─OutputScale: 2-509                --                        --
│    └─Empty: 2-510                      [128, 128, 3, 3]          --
│    └─Empty: 2-511                      [128, 128, 3, 3]          --
│    └─Empty: 2-512                      [128]                     --
│    └─Empty: 2-513                      [128]                     --
│    └─BatchNorm2d: 2-514                [16, 128, 32, 32]         --
│    └─Scaler: 2-515                     [16, 128, 32, 32]         --
│    └─ReLU: 2-516                       [16, 128, 32, 32]         --
│    └─Empty: 2-517                      [16, 128, 32, 32]         --
│    └─Clamp: 2-518                      [16, 128, 32, 32]         --
├─Dropout2d: 1-53                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-54         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-519                  [16, 128, 16, 16]         --
│    └─Empty: 2-520                      [16, 128, 16, 16]         --
│    └─Empty: 2-521                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-522         --                        --
│    └─One: 2-523                        [1]                       --
│    └─OutputScale: 2-524                --                        --
│    └─Empty: 2-525                      [128, 128, 3, 3]          --
│    └─Empty: 2-526                      [128, 128, 3, 3]          --
│    └─Empty: 2-527                      [128]                     --
│    └─Empty: 2-528                      [128]                     --
│    └─BatchNorm2d: 2-529                [16, 128, 16, 16]         --
│    └─Scaler: 2-530                     [16, 128, 16, 16]         --
│    └─ReLU: 2-531                       [16, 128, 16, 16]         --
│    └─Empty: 2-532                      [16, 128, 16, 16]         --
│    └─Clamp: 2-533                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-55                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-534         --                        --
│    └─One: 2-535                        [1]                       --
│    └─OutputScale: 2-536                --                        --
│    └─Empty: 2-537                      [128, 128, 1, 1]          --
│    └─Empty: 2-538                      [128, 128, 1, 1]          --
│    └─Empty: 2-539                      [128]                     --
│    └─Empty: 2-540                      [128]                     --
│    └─BatchNorm2d: 2-541                [16, 128, 16, 16]         --
│    └─Scaler: 2-542                     [16, 128, 16, 16]         --
│    └─ReLU: 2-543                       [16, 128, 16, 16]         --
│    └─Empty: 2-544                      [16, 128, 16, 16]         --
│    └─Clamp: 2-545                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-546                  [16, 128, 16, 16]         --
│    └─Empty: 2-547                      [16, 128, 16, 16]         --
│    └─Empty: 2-548                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-549         --                        --
│    └─One: 2-550                        [1]                       --
│    └─OutputScale: 2-551                --                        --
│    └─Empty: 2-552                      [128, 128, 3, 3]          --
│    └─Empty: 2-553                      [128, 128, 3, 3]          --
│    └─Empty: 2-554                      [128]                     --
│    └─Empty: 2-555                      [128]                     --
│    └─BatchNorm2d: 2-556                [16, 128, 16, 16]         --
│    └─Scaler: 2-557                     [16, 128, 16, 16]         --
│    └─ReLU: 2-558                       [16, 128, 16, 16]         --
│    └─Empty: 2-559                      [16, 128, 16, 16]         --
│    └─Clamp: 2-560                      [16, 128, 16, 16]         --
├─Dropout2d: 1-57                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-561                  [16, 128, 8, 8]           --
│    └─Empty: 2-562                      [16, 128, 8, 8]           --
│    └─Empty: 2-563                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-564         --                        --
│    └─One: 2-565                        [1]                       --
│    └─OutputScale: 2-566                --                        --
│    └─Empty: 2-567                      [128, 128, 3, 3]          --
│    └─Empty: 2-568                      [128, 128, 3, 3]          --
│    └─Empty: 2-569                      [128]                     --
│    └─Empty: 2-570                      [128]                     --
│    └─BatchNorm2d: 2-571                [16, 128, 8, 8]           --
│    └─Scaler: 2-572                     [16, 128, 8, 8]           --
│    └─ReLU: 2-573                       [16, 128, 8, 8]           --
│    └─Empty: 2-574                      [16, 128, 8, 8]           --
│    └─Clamp: 2-575                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-59                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-576         --                        --
│    └─One: 2-577                        [1]                       --
│    └─OutputScale: 2-578                --                        --
│    └─Empty: 2-579                      [16, 128, 1, 1]           --
│    └─Empty: 2-580                      [16, 128, 1, 1]           --
│    └─Empty: 2-581                      [16]                      --
│    └─Empty: 2-582                      [16]                      --
│    └─BatchNorm2d: 2-583                [16, 16, 8, 8]            --
│    └─Scaler: 2-584                     [16, 16, 8, 8]            --
│    └─ReLU: 2-585                       [16, 16, 8, 8]            --
│    └─Empty: 2-586                      [16, 16, 8, 8]            --
│    └─Clamp: 2-587                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-588                  [16, 128, 8, 8]           --
│    └─Empty: 2-589                      [16, 128, 8, 8]           --
│    └─Empty: 2-590                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-591         --                        --
│    └─One: 2-592                        [1]                       --
│    └─OutputScale: 2-593                --                        --
│    └─Empty: 2-594                      [16, 128, 3, 3]           --
│    └─Empty: 2-595                      [16, 128, 3, 3]           --
│    └─Empty: 2-596                      [16]                      --
│    └─Empty: 2-597                      [16]                      --
│    └─BatchNorm2d: 2-598                [16, 16, 8, 8]            --
│    └─Scaler: 2-599                     [16, 16, 8, 8]            --
│    └─ReLU: 2-600                       [16, 16, 8, 8]            --
│    └─Empty: 2-601                      [16, 16, 8, 8]            --
│    └─Clamp: 2-602                      [16, 16, 8, 8]            --
├─Dropout2d: 1-61                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-62                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-603         --                        --
│    └─One: 2-604                        [1]                       --
│    └─OutputScale: 2-605                --                        --
│    └─Empty: 2-606                      [128, 48, 1, 1]           --
│    └─Empty: 2-607                      [128, 48, 1, 1]           --
│    └─Empty: 2-608                      [128]                     --
│    └─Empty: 2-609                      [128]                     --
│    └─BatchNorm2d: 2-610                [16, 128, 64, 64]         --
│    └─Scaler: 2-611                     [16, 128, 64, 64]         --
│    └─ReLU: 2-612                       [16, 128, 64, 64]         --
│    └─Empty: 2-613                      [16, 128, 64, 64]         --
│    └─Clamp: 2-614                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-615                  [16, 128, 32, 32]         --
│    └─Empty: 2-616                      [16, 128, 32, 32]         --
│    └─Empty: 2-617                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-618         --                        --
│    └─One: 2-619                        [1]                       --
│    └─OutputScale: 2-620                --                        --
│    └─Empty: 2-621                      [128, 128, 3, 3]          --
│    └─Empty: 2-622                      [128, 128, 3, 3]          --
│    └─Empty: 2-623                      [128]                     --
│    └─Empty: 2-624                      [128]                     --
│    └─BatchNorm2d: 2-625                [16, 128, 32, 32]         --
│    └─Scaler: 2-626                     [16, 128, 32, 32]         --
│    └─ReLU: 2-627                       [16, 128, 32, 32]         --
│    └─Empty: 2-628                      [16, 128, 32, 32]         --
│    └─Clamp: 2-629                      [16, 128, 32, 32]         --
├─Dropout2d: 1-64                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-630                  [16, 128, 16, 16]         --
│    └─Empty: 2-631                      [16, 128, 16, 16]         --
│    └─Empty: 2-632                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-633         --                        --
│    └─One: 2-634                        [1]                       --
│    └─OutputScale: 2-635                --                        --
│    └─Empty: 2-636                      [128, 128, 3, 3]          --
│    └─Empty: 2-637                      [128, 128, 3, 3]          --
│    └─Empty: 2-638                      [128]                     --
│    └─Empty: 2-639                      [128]                     --
│    └─BatchNorm2d: 2-640                [16, 128, 16, 16]         --
│    └─Scaler: 2-641                     [16, 128, 16, 16]         --
│    └─ReLU: 2-642                       [16, 128, 16, 16]         --
│    └─Empty: 2-643                      [16, 128, 16, 16]         --
│    └─Clamp: 2-644                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-66                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-645         --                        --
│    └─One: 2-646                        [1]                       --
│    └─OutputScale: 2-647                --                        --
│    └─Empty: 2-648                      [128, 128, 1, 1]          --
│    └─Empty: 2-649                      [128, 128, 1, 1]          --
│    └─Empty: 2-650                      [128]                     --
│    └─Empty: 2-651                      [128]                     --
│    └─BatchNorm2d: 2-652                [16, 128, 16, 16]         --
│    └─Scaler: 2-653                     [16, 128, 16, 16]         --
│    └─ReLU: 2-654                       [16, 128, 16, 16]         --
│    └─Empty: 2-655                      [16, 128, 16, 16]         --
│    └─Clamp: 2-656                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-67         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-657                  [16, 128, 16, 16]         --
│    └─Empty: 2-658                      [16, 128, 16, 16]         --
│    └─Empty: 2-659                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-660         --                        --
│    └─One: 2-661                        [1]                       --
│    └─OutputScale: 2-662                --                        --
│    └─Empty: 2-663                      [128, 128, 3, 3]          --
│    └─Empty: 2-664                      [128, 128, 3, 3]          --
│    └─Empty: 2-665                      [128]                     --
│    └─Empty: 2-666                      [128]                     --
│    └─BatchNorm2d: 2-667                [16, 128, 16, 16]         --
│    └─Scaler: 2-668                     [16, 128, 16, 16]         --
│    └─ReLU: 2-669                       [16, 128, 16, 16]         --
│    └─Empty: 2-670                      [16, 128, 16, 16]         --
│    └─Clamp: 2-671                      [16, 128, 16, 16]         --
├─Dropout2d: 1-68                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-69         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-672                  [16, 128, 8, 8]           --
│    └─Empty: 2-673                      [16, 128, 8, 8]           --
│    └─Empty: 2-674                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-675         --                        --
│    └─One: 2-676                        [1]                       --
│    └─OutputScale: 2-677                --                        --
│    └─Empty: 2-678                      [128, 128, 3, 3]          --
│    └─Empty: 2-679                      [128, 128, 3, 3]          --
│    └─Empty: 2-680                      [128]                     --
│    └─Empty: 2-681                      [128]                     --
│    └─BatchNorm2d: 2-682                [16, 128, 8, 8]           --
│    └─Scaler: 2-683                     [16, 128, 8, 8]           --
│    └─ReLU: 2-684                       [16, 128, 8, 8]           --
│    └─Empty: 2-685                      [16, 128, 8, 8]           --
│    └─Clamp: 2-686                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-70                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-687         --                        --
│    └─One: 2-688                        [1]                       --
│    └─OutputScale: 2-689                --                        --
│    └─Empty: 2-690                      [16, 128, 1, 1]           --
│    └─Empty: 2-691                      [16, 128, 1, 1]           --
│    └─Empty: 2-692                      [16]                      --
│    └─Empty: 2-693                      [16]                      --
│    └─BatchNorm2d: 2-694                [16, 16, 8, 8]            --
│    └─Scaler: 2-695                     [16, 16, 8, 8]            --
│    └─ReLU: 2-696                       [16, 16, 8, 8]            --
│    └─Empty: 2-697                      [16, 16, 8, 8]            --
│    └─Clamp: 2-698                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-71         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-699                  [16, 128, 8, 8]           --
│    └─Empty: 2-700                      [16, 128, 8, 8]           --
│    └─Empty: 2-701                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-702         --                        --
│    └─One: 2-703                        [1]                       --
│    └─OutputScale: 2-704                --                        --
│    └─Empty: 2-705                      [16, 128, 3, 3]           --
│    └─Empty: 2-706                      [16, 128, 3, 3]           --
│    └─Empty: 2-707                      [16]                      --
│    └─Empty: 2-708                      [16]                      --
│    └─BatchNorm2d: 2-709                [16, 16, 8, 8]            --
│    └─Scaler: 2-710                     [16, 16, 8, 8]            --
│    └─ReLU: 2-711                       [16, 16, 8, 8]            --
│    └─Empty: 2-712                      [16, 16, 8, 8]            --
│    └─Clamp: 2-713                      [16, 16, 8, 8]            --
├─Dropout2d: 1-72                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-73                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-714         --                        --
│    └─One: 2-715                        [1]                       --
│    └─OutputScale: 2-716                --                        --
│    └─Empty: 2-717                      [128, 48, 1, 1]           --
│    └─Empty: 2-718                      [128, 48, 1, 1]           --
│    └─Empty: 2-719                      [128]                     --
│    └─Empty: 2-720                      [128]                     --
│    └─BatchNorm2d: 2-721                [16, 128, 64, 64]         --
│    └─Scaler: 2-722                     [16, 128, 64, 64]         --
│    └─ReLU: 2-723                       [16, 128, 64, 64]         --
│    └─Empty: 2-724                      [16, 128, 64, 64]         --
│    └─Clamp: 2-725                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-74         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-726                  [16, 128, 32, 32]         --
│    └─Empty: 2-727                      [16, 128, 32, 32]         --
│    └─Empty: 2-728                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-729         --                        --
│    └─One: 2-730                        [1]                       --
│    └─OutputScale: 2-731                --                        --
│    └─Empty: 2-732                      [128, 128, 3, 3]          --
│    └─Empty: 2-733                      [128, 128, 3, 3]          --
│    └─Empty: 2-734                      [128]                     --
│    └─Empty: 2-735                      [128]                     --
│    └─BatchNorm2d: 2-736                [16, 128, 32, 32]         --
│    └─Scaler: 2-737                     [16, 128, 32, 32]         --
│    └─ReLU: 2-738                       [16, 128, 32, 32]         --
│    └─Empty: 2-739                      [16, 128, 32, 32]         --
│    └─Clamp: 2-740                      [16, 128, 32, 32]         --
├─Dropout2d: 1-75                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-76         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-741                  [16, 128, 16, 16]         --
│    └─Empty: 2-742                      [16, 128, 16, 16]         --
│    └─Empty: 2-743                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-744         --                        --
│    └─One: 2-745                        [1]                       --
│    └─OutputScale: 2-746                --                        --
│    └─Empty: 2-747                      [128, 128, 3, 3]          --
│    └─Empty: 2-748                      [128, 128, 3, 3]          --
│    └─Empty: 2-749                      [128]                     --
│    └─Empty: 2-750                      [128]                     --
│    └─BatchNorm2d: 2-751                [16, 128, 16, 16]         --
│    └─Scaler: 2-752                     [16, 128, 16, 16]         --
│    └─ReLU: 2-753                       [16, 128, 16, 16]         --
│    └─Empty: 2-754                      [16, 128, 16, 16]         --
│    └─Clamp: 2-755                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-77                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-756         --                        --
│    └─One: 2-757                        [1]                       --
│    └─OutputScale: 2-758                --                        --
│    └─Empty: 2-759                      [128, 128, 1, 1]          --
│    └─Empty: 2-760                      [128, 128, 1, 1]          --
│    └─Empty: 2-761                      [128]                     --
│    └─Empty: 2-762                      [128]                     --
│    └─BatchNorm2d: 2-763                [16, 128, 16, 16]         --
│    └─Scaler: 2-764                     [16, 128, 16, 16]         --
│    └─ReLU: 2-765                       [16, 128, 16, 16]         --
│    └─Empty: 2-766                      [16, 128, 16, 16]         --
│    └─Clamp: 2-767                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-78         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-768                  [16, 128, 16, 16]         --
│    └─Empty: 2-769                      [16, 128, 16, 16]         --
│    └─Empty: 2-770                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-771         --                        --
│    └─One: 2-772                        [1]                       --
│    └─OutputScale: 2-773                --                        --
│    └─Empty: 2-774                      [128, 128, 3, 3]          --
│    └─Empty: 2-775                      [128, 128, 3, 3]          --
│    └─Empty: 2-776                      [128]                     --
│    └─Empty: 2-777                      [128]                     --
│    └─BatchNorm2d: 2-778                [16, 128, 16, 16]         --
│    └─Scaler: 2-779                     [16, 128, 16, 16]         --
│    └─ReLU: 2-780                       [16, 128, 16, 16]         --
│    └─Empty: 2-781                      [16, 128, 16, 16]         --
│    └─Clamp: 2-782                      [16, 128, 16, 16]         --
├─Dropout2d: 1-79                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-783                  [16, 128, 8, 8]           --
│    └─Empty: 2-784                      [16, 128, 8, 8]           --
│    └─Empty: 2-785                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-786         --                        --
│    └─One: 2-787                        [1]                       --
│    └─OutputScale: 2-788                --                        --
│    └─Empty: 2-789                      [128, 128, 3, 3]          --
│    └─Empty: 2-790                      [128, 128, 3, 3]          --
│    └─Empty: 2-791                      [128]                     --
│    └─Empty: 2-792                      [128]                     --
│    └─BatchNorm2d: 2-793                [16, 128, 8, 8]           --
│    └─Scaler: 2-794                     [16, 128, 8, 8]           --
│    └─ReLU: 2-795                       [16, 128, 8, 8]           --
│    └─Empty: 2-796                      [16, 128, 8, 8]           --
│    └─Clamp: 2-797                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-81                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-798         --                        --
│    └─One: 2-799                        [1]                       --
│    └─OutputScale: 2-800                --                        --
│    └─Empty: 2-801                      [16, 128, 1, 1]           --
│    └─Empty: 2-802                      [16, 128, 1, 1]           --
│    └─Empty: 2-803                      [16]                      --
│    └─Empty: 2-804                      [16]                      --
│    └─BatchNorm2d: 2-805                [16, 16, 8, 8]            --
│    └─Scaler: 2-806                     [16, 16, 8, 8]            --
│    └─ReLU: 2-807                       [16, 16, 8, 8]            --
│    └─Empty: 2-808                      [16, 16, 8, 8]            --
│    └─Clamp: 2-809                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-810                  [16, 128, 8, 8]           --
│    └─Empty: 2-811                      [16, 128, 8, 8]           --
│    └─Empty: 2-812                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-813         --                        --
│    └─One: 2-814                        [1]                       --
│    └─OutputScale: 2-815                --                        --
│    └─Empty: 2-816                      [16, 128, 3, 3]           --
│    └─Empty: 2-817                      [16, 128, 3, 3]           --
│    └─Empty: 2-818                      [16]                      --
│    └─Empty: 2-819                      [16]                      --
│    └─BatchNorm2d: 2-820                [16, 16, 8, 8]            --
│    └─Scaler: 2-821                     [16, 16, 8, 8]            --
│    └─ReLU: 2-822                       [16, 16, 8, 8]            --
│    └─Empty: 2-823                      [16, 16, 8, 8]            --
│    └─Clamp: 2-824                      [16, 16, 8, 8]            --
├─Dropout2d: 1-83                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-84                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-825         --                        --
│    └─One: 2-826                        [1]                       --
│    └─OutputScale: 2-827                --                        --
│    └─Empty: 2-828                      [128, 48, 1, 1]           --
│    └─Empty: 2-829                      [128, 48, 1, 1]           --
│    └─Empty: 2-830                      [128]                     --
│    └─Empty: 2-831                      [128]                     --
│    └─BatchNorm2d: 2-832                [16, 128, 64, 64]         --
│    └─Scaler: 2-833                     [16, 128, 64, 64]         --
│    └─ReLU: 2-834                       [16, 128, 64, 64]         --
│    └─Empty: 2-835                      [16, 128, 64, 64]         --
│    └─Clamp: 2-836                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-837                  [16, 128, 32, 32]         --
│    └─Empty: 2-838                      [16, 128, 32, 32]         --
│    └─Empty: 2-839                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-840         --                        --
│    └─One: 2-841                        [1]                       --
│    └─OutputScale: 2-842                --                        --
│    └─Empty: 2-843                      [128, 128, 3, 3]          --
│    └─Empty: 2-844                      [128, 128, 3, 3]          --
│    └─Empty: 2-845                      [128]                     --
│    └─Empty: 2-846                      [128]                     --
│    └─BatchNorm2d: 2-847                [16, 128, 32, 32]         --
│    └─Scaler: 2-848                     [16, 128, 32, 32]         --
│    └─ReLU: 2-849                       [16, 128, 32, 32]         --
│    └─Empty: 2-850                      [16, 128, 32, 32]         --
│    └─Clamp: 2-851                      [16, 128, 32, 32]         --
├─Dropout2d: 1-86                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-87         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-852                  [16, 128, 16, 16]         --
│    └─Empty: 2-853                      [16, 128, 16, 16]         --
│    └─Empty: 2-854                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-855         --                        --
│    └─One: 2-856                        [1]                       --
│    └─OutputScale: 2-857                --                        --
│    └─Empty: 2-858                      [128, 128, 3, 3]          --
│    └─Empty: 2-859                      [128, 128, 3, 3]          --
│    └─Empty: 2-860                      [128]                     --
│    └─Empty: 2-861                      [128]                     --
│    └─BatchNorm2d: 2-862                [16, 128, 16, 16]         --
│    └─Scaler: 2-863                     [16, 128, 16, 16]         --
│    └─ReLU: 2-864                       [16, 128, 16, 16]         --
│    └─Empty: 2-865                      [16, 128, 16, 16]         --
│    └─Clamp: 2-866                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-88                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-867         --                        --
│    └─One: 2-868                        [1]                       --
│    └─OutputScale: 2-869                --                        --
│    └─Empty: 2-870                      [128, 128, 1, 1]          --
│    └─Empty: 2-871                      [128, 128, 1, 1]          --
│    └─Empty: 2-872                      [128]                     --
│    └─Empty: 2-873                      [128]                     --
│    └─BatchNorm2d: 2-874                [16, 128, 16, 16]         --
│    └─Scaler: 2-875                     [16, 128, 16, 16]         --
│    └─ReLU: 2-876                       [16, 128, 16, 16]         --
│    └─Empty: 2-877                      [16, 128, 16, 16]         --
│    └─Clamp: 2-878                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-879                  [16, 128, 16, 16]         --
│    └─Empty: 2-880                      [16, 128, 16, 16]         --
│    └─Empty: 2-881                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-882         --                        --
│    └─One: 2-883                        [1]                       --
│    └─OutputScale: 2-884                --                        --
│    └─Empty: 2-885                      [128, 128, 3, 3]          --
│    └─Empty: 2-886                      [128, 128, 3, 3]          --
│    └─Empty: 2-887                      [128]                     --
│    └─Empty: 2-888                      [128]                     --
│    └─BatchNorm2d: 2-889                [16, 128, 16, 16]         --
│    └─Scaler: 2-890                     [16, 128, 16, 16]         --
│    └─ReLU: 2-891                       [16, 128, 16, 16]         --
│    └─Empty: 2-892                      [16, 128, 16, 16]         --
│    └─Clamp: 2-893                      [16, 128, 16, 16]         --
├─Dropout2d: 1-90                        [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-91         [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-894                  [16, 128, 8, 8]           --
│    └─Empty: 2-895                      [16, 128, 8, 8]           --
│    └─Empty: 2-896                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-897         --                        --
│    └─One: 2-898                        [1]                       --
│    └─OutputScale: 2-899                --                        --
│    └─Empty: 2-900                      [128, 128, 3, 3]          --
│    └─Empty: 2-901                      [128, 128, 3, 3]          --
│    └─Empty: 2-902                      [128]                     --
│    └─Empty: 2-903                      [128]                     --
│    └─BatchNorm2d: 2-904                [16, 128, 8, 8]           --
│    └─Scaler: 2-905                     [16, 128, 8, 8]           --
│    └─ReLU: 2-906                       [16, 128, 8, 8]           --
│    └─Empty: 2-907                      [16, 128, 8, 8]           --
│    └─Clamp: 2-908                      [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-92                [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-909         --                        --
│    └─One: 2-910                        [1]                       --
│    └─OutputScale: 2-911                --                        --
│    └─Empty: 2-912                      [16, 128, 1, 1]           --
│    └─Empty: 2-913                      [16, 128, 1, 1]           --
│    └─Empty: 2-914                      [16]                      --
│    └─Empty: 2-915                      [16]                      --
│    └─BatchNorm2d: 2-916                [16, 16, 8, 8]            --
│    └─Scaler: 2-917                     [16, 16, 8, 8]            --
│    └─ReLU: 2-918                       [16, 16, 8, 8]            --
│    └─Empty: 2-919                      [16, 16, 8, 8]            --
│    └─Clamp: 2-920                      [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-93         [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-921                  [16, 128, 8, 8]           --
│    └─Empty: 2-922                      [16, 128, 8, 8]           --
│    └─Empty: 2-923                      [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-924         --                        --
│    └─One: 2-925                        [1]                       --
│    └─OutputScale: 2-926                --                        --
│    └─Empty: 2-927                      [16, 128, 3, 3]           --
│    └─Empty: 2-928                      [16, 128, 3, 3]           --
│    └─Empty: 2-929                      [16]                      --
│    └─Empty: 2-930                      [16]                      --
│    └─BatchNorm2d: 2-931                [16, 16, 8, 8]            --
│    └─Scaler: 2-932                     [16, 16, 8, 8]            --
│    └─ReLU: 2-933                       [16, 16, 8, 8]            --
│    └─Empty: 2-934                      [16, 16, 8, 8]            --
│    └─Clamp: 2-935                      [16, 16, 8, 8]            --
├─Dropout2d: 1-94                        [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-936         --                        --
│    └─One: 2-937                        [1]                       --
│    └─OutputScale: 2-938                --                        --
│    └─Empty: 2-939                      [128, 48, 1, 1]           --
│    └─Empty: 2-940                      [128, 48, 1, 1]           --
│    └─Empty: 2-941                      [128]                     --
│    └─Empty: 2-942                      [128]                     --
│    └─BatchNorm2d: 2-943                [16, 128, 64, 64]         --
│    └─Scaler: 2-944                     [16, 128, 64, 64]         --
│    └─ReLU: 2-945                       [16, 128, 64, 64]         --
│    └─Empty: 2-946                      [16, 128, 64, 64]         --
│    └─Clamp: 2-947                      [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-948                  [16, 128, 32, 32]         --
│    └─Empty: 2-949                      [16, 128, 32, 32]         --
│    └─Empty: 2-950                      [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-951         --                        --
│    └─One: 2-952                        [1]                       --
│    └─OutputScale: 2-953                --                        --
│    └─Empty: 2-954                      [128, 128, 3, 3]          --
│    └─Empty: 2-955                      [128, 128, 3, 3]          --
│    └─Empty: 2-956                      [128]                     --
│    └─Empty: 2-957                      [128]                     --
│    └─BatchNorm2d: 2-958                [16, 128, 32, 32]         --
│    └─Scaler: 2-959                     [16, 128, 32, 32]         --
│    └─ReLU: 2-960                       [16, 128, 32, 32]         --
│    └─Empty: 2-961                      [16, 128, 32, 32]         --
│    └─Clamp: 2-962                      [16, 128, 32, 32]         --
├─Dropout2d: 1-97                        [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-98         [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-963                  [16, 128, 16, 16]         --
│    └─Empty: 2-964                      [16, 128, 16, 16]         --
│    └─Empty: 2-965                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-966         --                        --
│    └─One: 2-967                        [1]                       --
│    └─OutputScale: 2-968                --                        --
│    └─Empty: 2-969                      [128, 128, 3, 3]          --
│    └─Empty: 2-970                      [128, 128, 3, 3]          --
│    └─Empty: 2-971                      [128]                     --
│    └─Empty: 2-972                      [128]                     --
│    └─BatchNorm2d: 2-973                [16, 128, 16, 16]         --
│    └─Scaler: 2-974                     [16, 128, 16, 16]         --
│    └─ReLU: 2-975                       [16, 128, 16, 16]         --
│    └─Empty: 2-976                      [16, 128, 16, 16]         --
│    └─Clamp: 2-977                      [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-99                [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-978         --                        --
│    └─One: 2-979                        [1]                       --
│    └─OutputScale: 2-980                --                        --
│    └─Empty: 2-981                      [128, 128, 1, 1]          --
│    └─Empty: 2-982                      [128, 128, 1, 1]          --
│    └─Empty: 2-983                      [128]                     --
│    └─Empty: 2-984                      [128]                     --
│    └─BatchNorm2d: 2-985                [16, 128, 16, 16]         --
│    └─Scaler: 2-986                     [16, 128, 16, 16]         --
│    └─ReLU: 2-987                       [16, 128, 16, 16]         --
│    └─Empty: 2-988                      [16, 128, 16, 16]         --
│    └─Clamp: 2-989                      [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-990                  [16, 128, 16, 16]         --
│    └─Empty: 2-991                      [16, 128, 16, 16]         --
│    └─Empty: 2-992                      [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-993         --                        --
│    └─One: 2-994                        [1]                       --
│    └─OutputScale: 2-995                --                        --
│    └─Empty: 2-996                      [128, 128, 3, 3]          --
│    └─Empty: 2-997                      [128, 128, 3, 3]          --
│    └─Empty: 2-998                      [128]                     --
│    └─Empty: 2-999                      [128]                     --
│    └─BatchNorm2d: 2-1000               [16, 128, 16, 16]         --
│    └─Scaler: 2-1001                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1002                      [16, 128, 16, 16]         --
│    └─Empty: 2-1003                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1004                     [16, 128, 16, 16]         --
├─Dropout2d: 1-101                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1005                 [16, 128, 8, 8]           --
│    └─Empty: 2-1006                     [16, 128, 8, 8]           --
│    └─Empty: 2-1007                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1008        --                        --
│    └─One: 2-1009                       [1]                       --
│    └─OutputScale: 2-1010               --                        --
│    └─Empty: 2-1011                     [128, 128, 3, 3]          --
│    └─Empty: 2-1012                     [128, 128, 3, 3]          --
│    └─Empty: 2-1013                     [128]                     --
│    └─Empty: 2-1014                     [128]                     --
│    └─BatchNorm2d: 2-1015               [16, 128, 8, 8]           --
│    └─Scaler: 2-1016                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1017                      [16, 128, 8, 8]           --
│    └─Empty: 2-1018                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1019                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-103               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1020        --                        --
│    └─One: 2-1021                       [1]                       --
│    └─OutputScale: 2-1022               --                        --
│    └─Empty: 2-1023                     [16, 128, 1, 1]           --
│    └─Empty: 2-1024                     [16, 128, 1, 1]           --
│    └─Empty: 2-1025                     [16]                      --
│    └─Empty: 2-1026                     [16]                      --
│    └─BatchNorm2d: 2-1027               [16, 16, 8, 8]            --
│    └─Scaler: 2-1028                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1029                      [16, 16, 8, 8]            --
│    └─Empty: 2-1030                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1031                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-104        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1032                 [16, 128, 8, 8]           --
│    └─Empty: 2-1033                     [16, 128, 8, 8]           --
│    └─Empty: 2-1034                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1035        --                        --
│    └─One: 2-1036                       [1]                       --
│    └─OutputScale: 2-1037               --                        --
│    └─Empty: 2-1038                     [16, 128, 3, 3]           --
│    └─Empty: 2-1039                     [16, 128, 3, 3]           --
│    └─Empty: 2-1040                     [16]                      --
│    └─Empty: 2-1041                     [16]                      --
│    └─BatchNorm2d: 2-1042               [16, 16, 8, 8]            --
│    └─Scaler: 2-1043                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1044                      [16, 16, 8, 8]            --
│    └─Empty: 2-1045                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1046                     [16, 16, 8, 8]            --
├─Dropout2d: 1-105                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-106               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1047        --                        --
│    └─One: 2-1048                       [1]                       --
│    └─OutputScale: 2-1049               --                        --
│    └─Empty: 2-1050                     [128, 48, 1, 1]           --
│    └─Empty: 2-1051                     [128, 48, 1, 1]           --
│    └─Empty: 2-1052                     [128]                     --
│    └─Empty: 2-1053                     [128]                     --
│    └─BatchNorm2d: 2-1054               [16, 128, 64, 64]         --
│    └─Scaler: 2-1055                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1056                      [16, 128, 64, 64]         --
│    └─Empty: 2-1057                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1058                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1059                 [16, 128, 32, 32]         --
│    └─Empty: 2-1060                     [16, 128, 32, 32]         --
│    └─Empty: 2-1061                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1062        --                        --
│    └─One: 2-1063                       [1]                       --
│    └─OutputScale: 2-1064               --                        --
│    └─Empty: 2-1065                     [128, 128, 3, 3]          --
│    └─Empty: 2-1066                     [128, 128, 3, 3]          --
│    └─Empty: 2-1067                     [128]                     --
│    └─Empty: 2-1068                     [128]                     --
│    └─BatchNorm2d: 2-1069               [16, 128, 32, 32]         --
│    └─Scaler: 2-1070                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1071                      [16, 128, 32, 32]         --
│    └─Empty: 2-1072                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1073                     [16, 128, 32, 32]         --
├─Dropout2d: 1-108                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1074                 [16, 128, 16, 16]         --
│    └─Empty: 2-1075                     [16, 128, 16, 16]         --
│    └─Empty: 2-1076                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1077        --                        --
│    └─One: 2-1078                       [1]                       --
│    └─OutputScale: 2-1079               --                        --
│    └─Empty: 2-1080                     [128, 128, 3, 3]          --
│    └─Empty: 2-1081                     [128, 128, 3, 3]          --
│    └─Empty: 2-1082                     [128]                     --
│    └─Empty: 2-1083                     [128]                     --
│    └─BatchNorm2d: 2-1084               [16, 128, 16, 16]         --
│    └─Scaler: 2-1085                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1086                      [16, 128, 16, 16]         --
│    └─Empty: 2-1087                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1088                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-110               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1089        --                        --
│    └─One: 2-1090                       [1]                       --
│    └─OutputScale: 2-1091               --                        --
│    └─Empty: 2-1092                     [128, 128, 1, 1]          --
│    └─Empty: 2-1093                     [128, 128, 1, 1]          --
│    └─Empty: 2-1094                     [128]                     --
│    └─Empty: 2-1095                     [128]                     --
│    └─BatchNorm2d: 2-1096               [16, 128, 16, 16]         --
│    └─Scaler: 2-1097                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1098                      [16, 128, 16, 16]         --
│    └─Empty: 2-1099                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1100                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1101                 [16, 128, 16, 16]         --
│    └─Empty: 2-1102                     [16, 128, 16, 16]         --
│    └─Empty: 2-1103                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1104        --                        --
│    └─One: 2-1105                       [1]                       --
│    └─OutputScale: 2-1106               --                        --
│    └─Empty: 2-1107                     [128, 128, 3, 3]          --
│    └─Empty: 2-1108                     [128, 128, 3, 3]          --
│    └─Empty: 2-1109                     [128]                     --
│    └─Empty: 2-1110                     [128]                     --
│    └─BatchNorm2d: 2-1111               [16, 128, 16, 16]         --
│    └─Scaler: 2-1112                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1113                      [16, 128, 16, 16]         --
│    └─Empty: 2-1114                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1115                     [16, 128, 16, 16]         --
├─Dropout2d: 1-112                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1116                 [16, 128, 8, 8]           --
│    └─Empty: 2-1117                     [16, 128, 8, 8]           --
│    └─Empty: 2-1118                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1119        --                        --
│    └─One: 2-1120                       [1]                       --
│    └─OutputScale: 2-1121               --                        --
│    └─Empty: 2-1122                     [128, 128, 3, 3]          --
│    └─Empty: 2-1123                     [128, 128, 3, 3]          --
│    └─Empty: 2-1124                     [128]                     --
│    └─Empty: 2-1125                     [128]                     --
│    └─BatchNorm2d: 2-1126               [16, 128, 8, 8]           --
│    └─Scaler: 2-1127                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1128                      [16, 128, 8, 8]           --
│    └─Empty: 2-1129                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1130                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-114               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1131        --                        --
│    └─One: 2-1132                       [1]                       --
│    └─OutputScale: 2-1133               --                        --
│    └─Empty: 2-1134                     [16, 128, 1, 1]           --
│    └─Empty: 2-1135                     [16, 128, 1, 1]           --
│    └─Empty: 2-1136                     [16]                      --
│    └─Empty: 2-1137                     [16]                      --
│    └─BatchNorm2d: 2-1138               [16, 16, 8, 8]            --
│    └─Scaler: 2-1139                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1140                      [16, 16, 8, 8]            --
│    └─Empty: 2-1141                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1142                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-115        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1143                 [16, 128, 8, 8]           --
│    └─Empty: 2-1144                     [16, 128, 8, 8]           --
│    └─Empty: 2-1145                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1146        --                        --
│    └─One: 2-1147                       [1]                       --
│    └─OutputScale: 2-1148               --                        --
│    └─Empty: 2-1149                     [16, 128, 3, 3]           --
│    └─Empty: 2-1150                     [16, 128, 3, 3]           --
│    └─Empty: 2-1151                     [16]                      --
│    └─Empty: 2-1152                     [16]                      --
│    └─BatchNorm2d: 2-1153               [16, 16, 8, 8]            --
│    └─Scaler: 2-1154                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1155                      [16, 16, 8, 8]            --
│    └─Empty: 2-1156                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1157                     [16, 16, 8, 8]            --
├─Dropout2d: 1-116                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-117               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1158        --                        --
│    └─One: 2-1159                       [1]                       --
│    └─OutputScale: 2-1160               --                        --
│    └─Empty: 2-1161                     [128, 48, 1, 1]           --
│    └─Empty: 2-1162                     [128, 48, 1, 1]           --
│    └─Empty: 2-1163                     [128]                     --
│    └─Empty: 2-1164                     [128]                     --
│    └─BatchNorm2d: 2-1165               [16, 128, 64, 64]         --
│    └─Scaler: 2-1166                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1167                      [16, 128, 64, 64]         --
│    └─Empty: 2-1168                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1169                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-118        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1170                 [16, 128, 32, 32]         --
│    └─Empty: 2-1171                     [16, 128, 32, 32]         --
│    └─Empty: 2-1172                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1173        --                        --
│    └─One: 2-1174                       [1]                       --
│    └─OutputScale: 2-1175               --                        --
│    └─Empty: 2-1176                     [128, 128, 3, 3]          --
│    └─Empty: 2-1177                     [128, 128, 3, 3]          --
│    └─Empty: 2-1178                     [128]                     --
│    └─Empty: 2-1179                     [128]                     --
│    └─BatchNorm2d: 2-1180               [16, 128, 32, 32]         --
│    └─Scaler: 2-1181                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1182                      [16, 128, 32, 32]         --
│    └─Empty: 2-1183                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1184                     [16, 128, 32, 32]         --
├─Dropout2d: 1-119                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-120        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1185                 [16, 128, 16, 16]         --
│    └─Empty: 2-1186                     [16, 128, 16, 16]         --
│    └─Empty: 2-1187                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1188        --                        --
│    └─One: 2-1189                       [1]                       --
│    └─OutputScale: 2-1190               --                        --
│    └─Empty: 2-1191                     [128, 128, 3, 3]          --
│    └─Empty: 2-1192                     [128, 128, 3, 3]          --
│    └─Empty: 2-1193                     [128]                     --
│    └─Empty: 2-1194                     [128]                     --
│    └─BatchNorm2d: 2-1195               [16, 128, 16, 16]         --
│    └─Scaler: 2-1196                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1197                      [16, 128, 16, 16]         --
│    └─Empty: 2-1198                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1199                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-121               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1200        --                        --
│    └─One: 2-1201                       [1]                       --
│    └─OutputScale: 2-1202               --                        --
│    └─Empty: 2-1203                     [128, 128, 1, 1]          --
│    └─Empty: 2-1204                     [128, 128, 1, 1]          --
│    └─Empty: 2-1205                     [128]                     --
│    └─Empty: 2-1206                     [128]                     --
│    └─BatchNorm2d: 2-1207               [16, 128, 16, 16]         --
│    └─Scaler: 2-1208                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1209                      [16, 128, 16, 16]         --
│    └─Empty: 2-1210                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1211                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-122        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1212                 [16, 128, 16, 16]         --
│    └─Empty: 2-1213                     [16, 128, 16, 16]         --
│    └─Empty: 2-1214                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1215        --                        --
│    └─One: 2-1216                       [1]                       --
│    └─OutputScale: 2-1217               --                        --
│    └─Empty: 2-1218                     [128, 128, 3, 3]          --
│    └─Empty: 2-1219                     [128, 128, 3, 3]          --
│    └─Empty: 2-1220                     [128]                     --
│    └─Empty: 2-1221                     [128]                     --
│    └─BatchNorm2d: 2-1222               [16, 128, 16, 16]         --
│    └─Scaler: 2-1223                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1224                      [16, 128, 16, 16]         --
│    └─Empty: 2-1225                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1226                     [16, 128, 16, 16]         --
├─Dropout2d: 1-123                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1227                 [16, 128, 8, 8]           --
│    └─Empty: 2-1228                     [16, 128, 8, 8]           --
│    └─Empty: 2-1229                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1230        --                        --
│    └─One: 2-1231                       [1]                       --
│    └─OutputScale: 2-1232               --                        --
│    └─Empty: 2-1233                     [128, 128, 3, 3]          --
│    └─Empty: 2-1234                     [128, 128, 3, 3]          --
│    └─Empty: 2-1235                     [128]                     --
│    └─Empty: 2-1236                     [128]                     --
│    └─BatchNorm2d: 2-1237               [16, 128, 8, 8]           --
│    └─Scaler: 2-1238                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1239                      [16, 128, 8, 8]           --
│    └─Empty: 2-1240                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1241                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-125               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1242        --                        --
│    └─One: 2-1243                       [1]                       --
│    └─OutputScale: 2-1244               --                        --
│    └─Empty: 2-1245                     [16, 128, 1, 1]           --
│    └─Empty: 2-1246                     [16, 128, 1, 1]           --
│    └─Empty: 2-1247                     [16]                      --
│    └─Empty: 2-1248                     [16]                      --
│    └─BatchNorm2d: 2-1249               [16, 16, 8, 8]            --
│    └─Scaler: 2-1250                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1251                      [16, 16, 8, 8]            --
│    └─Empty: 2-1252                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1253                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1254                 [16, 128, 8, 8]           --
│    └─Empty: 2-1255                     [16, 128, 8, 8]           --
│    └─Empty: 2-1256                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1257        --                        --
│    └─One: 2-1258                       [1]                       --
│    └─OutputScale: 2-1259               --                        --
│    └─Empty: 2-1260                     [16, 128, 3, 3]           --
│    └─Empty: 2-1261                     [16, 128, 3, 3]           --
│    └─Empty: 2-1262                     [16]                      --
│    └─Empty: 2-1263                     [16]                      --
│    └─BatchNorm2d: 2-1264               [16, 16, 8, 8]            --
│    └─Scaler: 2-1265                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1266                      [16, 16, 8, 8]            --
│    └─Empty: 2-1267                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1268                     [16, 16, 8, 8]            --
├─Dropout2d: 1-127                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-128               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1269        --                        --
│    └─One: 2-1270                       [1]                       --
│    └─OutputScale: 2-1271               --                        --
│    └─Empty: 2-1272                     [128, 48, 1, 1]           --
│    └─Empty: 2-1273                     [128, 48, 1, 1]           --
│    └─Empty: 2-1274                     [128]                     --
│    └─Empty: 2-1275                     [128]                     --
│    └─BatchNorm2d: 2-1276               [16, 128, 64, 64]         --
│    └─Scaler: 2-1277                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1278                      [16, 128, 64, 64]         --
│    └─Empty: 2-1279                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1280                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1281                 [16, 128, 32, 32]         --
│    └─Empty: 2-1282                     [16, 128, 32, 32]         --
│    └─Empty: 2-1283                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1284        --                        --
│    └─One: 2-1285                       [1]                       --
│    └─OutputScale: 2-1286               --                        --
│    └─Empty: 2-1287                     [128, 128, 3, 3]          --
│    └─Empty: 2-1288                     [128, 128, 3, 3]          --
│    └─Empty: 2-1289                     [128]                     --
│    └─Empty: 2-1290                     [128]                     --
│    └─BatchNorm2d: 2-1291               [16, 128, 32, 32]         --
│    └─Scaler: 2-1292                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1293                      [16, 128, 32, 32]         --
│    └─Empty: 2-1294                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1295                     [16, 128, 32, 32]         --
├─Dropout2d: 1-130                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1296                 [16, 128, 16, 16]         --
│    └─Empty: 2-1297                     [16, 128, 16, 16]         --
│    └─Empty: 2-1298                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1299        --                        --
│    └─One: 2-1300                       [1]                       --
│    └─OutputScale: 2-1301               --                        --
│    └─Empty: 2-1302                     [128, 128, 3, 3]          --
│    └─Empty: 2-1303                     [128, 128, 3, 3]          --
│    └─Empty: 2-1304                     [128]                     --
│    └─Empty: 2-1305                     [128]                     --
│    └─BatchNorm2d: 2-1306               [16, 128, 16, 16]         --
│    └─Scaler: 2-1307                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1308                      [16, 128, 16, 16]         --
│    └─Empty: 2-1309                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1310                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-132               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1311        --                        --
│    └─One: 2-1312                       [1]                       --
│    └─OutputScale: 2-1313               --                        --
│    └─Empty: 2-1314                     [128, 128, 1, 1]          --
│    └─Empty: 2-1315                     [128, 128, 1, 1]          --
│    └─Empty: 2-1316                     [128]                     --
│    └─Empty: 2-1317                     [128]                     --
│    └─BatchNorm2d: 2-1318               [16, 128, 16, 16]         --
│    └─Scaler: 2-1319                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1320                      [16, 128, 16, 16]         --
│    └─Empty: 2-1321                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1322                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1323                 [16, 128, 16, 16]         --
│    └─Empty: 2-1324                     [16, 128, 16, 16]         --
│    └─Empty: 2-1325                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1326        --                        --
│    └─One: 2-1327                       [1]                       --
│    └─OutputScale: 2-1328               --                        --
│    └─Empty: 2-1329                     [128, 128, 3, 3]          --
│    └─Empty: 2-1330                     [128, 128, 3, 3]          --
│    └─Empty: 2-1331                     [128]                     --
│    └─Empty: 2-1332                     [128]                     --
│    └─BatchNorm2d: 2-1333               [16, 128, 16, 16]         --
│    └─Scaler: 2-1334                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1335                      [16, 128, 16, 16]         --
│    └─Empty: 2-1336                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1337                     [16, 128, 16, 16]         --
├─Dropout2d: 1-134                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-135        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1338                 [16, 128, 8, 8]           --
│    └─Empty: 2-1339                     [16, 128, 8, 8]           --
│    └─Empty: 2-1340                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1341        --                        --
│    └─One: 2-1342                       [1]                       --
│    └─OutputScale: 2-1343               --                        --
│    └─Empty: 2-1344                     [128, 128, 3, 3]          --
│    └─Empty: 2-1345                     [128, 128, 3, 3]          --
│    └─Empty: 2-1346                     [128]                     --
│    └─Empty: 2-1347                     [128]                     --
│    └─BatchNorm2d: 2-1348               [16, 128, 8, 8]           --
│    └─Scaler: 2-1349                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1350                      [16, 128, 8, 8]           --
│    └─Empty: 2-1351                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1352                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-136               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1353        --                        --
│    └─One: 2-1354                       [1]                       --
│    └─OutputScale: 2-1355               --                        --
│    └─Empty: 2-1356                     [16, 128, 1, 1]           --
│    └─Empty: 2-1357                     [16, 128, 1, 1]           --
│    └─Empty: 2-1358                     [16]                      --
│    └─Empty: 2-1359                     [16]                      --
│    └─BatchNorm2d: 2-1360               [16, 16, 8, 8]            --
│    └─Scaler: 2-1361                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1362                      [16, 16, 8, 8]            --
│    └─Empty: 2-1363                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1364                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-137        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1365                 [16, 128, 8, 8]           --
│    └─Empty: 2-1366                     [16, 128, 8, 8]           --
│    └─Empty: 2-1367                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1368        --                        --
│    └─One: 2-1369                       [1]                       --
│    └─OutputScale: 2-1370               --                        --
│    └─Empty: 2-1371                     [16, 128, 3, 3]           --
│    └─Empty: 2-1372                     [16, 128, 3, 3]           --
│    └─Empty: 2-1373                     [16]                      --
│    └─Empty: 2-1374                     [16]                      --
│    └─BatchNorm2d: 2-1375               [16, 16, 8, 8]            --
│    └─Scaler: 2-1376                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1377                      [16, 16, 8, 8]            --
│    └─Empty: 2-1378                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1379                     [16, 16, 8, 8]            --
├─Dropout2d: 1-138                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-139               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1380        --                        --
│    └─One: 2-1381                       [1]                       --
│    └─OutputScale: 2-1382               --                        --
│    └─Empty: 2-1383                     [128, 48, 1, 1]           --
│    └─Empty: 2-1384                     [128, 48, 1, 1]           --
│    └─Empty: 2-1385                     [128]                     --
│    └─Empty: 2-1386                     [128]                     --
│    └─BatchNorm2d: 2-1387               [16, 128, 64, 64]         --
│    └─Scaler: 2-1388                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1389                      [16, 128, 64, 64]         --
│    └─Empty: 2-1390                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1391                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-140        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1392                 [16, 128, 32, 32]         --
│    └─Empty: 2-1393                     [16, 128, 32, 32]         --
│    └─Empty: 2-1394                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1395        --                        --
│    └─One: 2-1396                       [1]                       --
│    └─OutputScale: 2-1397               --                        --
│    └─Empty: 2-1398                     [128, 128, 3, 3]          --
│    └─Empty: 2-1399                     [128, 128, 3, 3]          --
│    └─Empty: 2-1400                     [128]                     --
│    └─Empty: 2-1401                     [128]                     --
│    └─BatchNorm2d: 2-1402               [16, 128, 32, 32]         --
│    └─Scaler: 2-1403                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1404                      [16, 128, 32, 32]         --
│    └─Empty: 2-1405                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1406                     [16, 128, 32, 32]         --
├─Dropout2d: 1-141                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-142        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1407                 [16, 128, 16, 16]         --
│    └─Empty: 2-1408                     [16, 128, 16, 16]         --
│    └─Empty: 2-1409                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1410        --                        --
│    └─One: 2-1411                       [1]                       --
│    └─OutputScale: 2-1412               --                        --
│    └─Empty: 2-1413                     [128, 128, 3, 3]          --
│    └─Empty: 2-1414                     [128, 128, 3, 3]          --
│    └─Empty: 2-1415                     [128]                     --
│    └─Empty: 2-1416                     [128]                     --
│    └─BatchNorm2d: 2-1417               [16, 128, 16, 16]         --
│    └─Scaler: 2-1418                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1419                      [16, 128, 16, 16]         --
│    └─Empty: 2-1420                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1421                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-143               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1422        --                        --
│    └─One: 2-1423                       [1]                       --
│    └─OutputScale: 2-1424               --                        --
│    └─Empty: 2-1425                     [128, 128, 1, 1]          --
│    └─Empty: 2-1426                     [128, 128, 1, 1]          --
│    └─Empty: 2-1427                     [128]                     --
│    └─Empty: 2-1428                     [128]                     --
│    └─BatchNorm2d: 2-1429               [16, 128, 16, 16]         --
│    └─Scaler: 2-1430                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1431                      [16, 128, 16, 16]         --
│    └─Empty: 2-1432                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1433                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-144        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1434                 [16, 128, 16, 16]         --
│    └─Empty: 2-1435                     [16, 128, 16, 16]         --
│    └─Empty: 2-1436                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1437        --                        --
│    └─One: 2-1438                       [1]                       --
│    └─OutputScale: 2-1439               --                        --
│    └─Empty: 2-1440                     [128, 128, 3, 3]          --
│    └─Empty: 2-1441                     [128, 128, 3, 3]          --
│    └─Empty: 2-1442                     [128]                     --
│    └─Empty: 2-1443                     [128]                     --
│    └─BatchNorm2d: 2-1444               [16, 128, 16, 16]         --
│    └─Scaler: 2-1445                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1446                      [16, 128, 16, 16]         --
│    └─Empty: 2-1447                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1448                     [16, 128, 16, 16]         --
├─Dropout2d: 1-145                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-146        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1449                 [16, 128, 8, 8]           --
│    └─Empty: 2-1450                     [16, 128, 8, 8]           --
│    └─Empty: 2-1451                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1452        --                        --
│    └─One: 2-1453                       [1]                       --
│    └─OutputScale: 2-1454               --                        --
│    └─Empty: 2-1455                     [128, 128, 3, 3]          --
│    └─Empty: 2-1456                     [128, 128, 3, 3]          --
│    └─Empty: 2-1457                     [128]                     --
│    └─Empty: 2-1458                     [128]                     --
│    └─BatchNorm2d: 2-1459               [16, 128, 8, 8]           --
│    └─Scaler: 2-1460                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1461                      [16, 128, 8, 8]           --
│    └─Empty: 2-1462                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1463                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-147               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1464        --                        --
│    └─One: 2-1465                       [1]                       --
│    └─OutputScale: 2-1466               --                        --
│    └─Empty: 2-1467                     [16, 128, 1, 1]           --
│    └─Empty: 2-1468                     [16, 128, 1, 1]           --
│    └─Empty: 2-1469                     [16]                      --
│    └─Empty: 2-1470                     [16]                      --
│    └─BatchNorm2d: 2-1471               [16, 16, 8, 8]            --
│    └─Scaler: 2-1472                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1473                      [16, 16, 8, 8]            --
│    └─Empty: 2-1474                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1475                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1476                 [16, 128, 8, 8]           --
│    └─Empty: 2-1477                     [16, 128, 8, 8]           --
│    └─Empty: 2-1478                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1479        --                        --
│    └─One: 2-1480                       [1]                       --
│    └─OutputScale: 2-1481               --                        --
│    └─Empty: 2-1482                     [16, 128, 3, 3]           --
│    └─Empty: 2-1483                     [16, 128, 3, 3]           --
│    └─Empty: 2-1484                     [16]                      --
│    └─Empty: 2-1485                     [16]                      --
│    └─BatchNorm2d: 2-1486               [16, 16, 8, 8]            --
│    └─Scaler: 2-1487                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1488                      [16, 16, 8, 8]            --
│    └─Empty: 2-1489                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1490                     [16, 16, 8, 8]            --
├─Dropout2d: 1-149                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-150               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1491        --                        --
│    └─One: 2-1492                       [1]                       --
│    └─OutputScale: 2-1493               --                        --
│    └─Empty: 2-1494                     [128, 48, 1, 1]           --
│    └─Empty: 2-1495                     [128, 48, 1, 1]           --
│    └─Empty: 2-1496                     [128]                     --
│    └─Empty: 2-1497                     [128]                     --
│    └─BatchNorm2d: 2-1498               [16, 128, 64, 64]         --
│    └─Scaler: 2-1499                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1500                      [16, 128, 64, 64]         --
│    └─Empty: 2-1501                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1502                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1503                 [16, 128, 32, 32]         --
│    └─Empty: 2-1504                     [16, 128, 32, 32]         --
│    └─Empty: 2-1505                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1506        --                        --
│    └─One: 2-1507                       [1]                       --
│    └─OutputScale: 2-1508               --                        --
│    └─Empty: 2-1509                     [128, 128, 3, 3]          --
│    └─Empty: 2-1510                     [128, 128, 3, 3]          --
│    └─Empty: 2-1511                     [128]                     --
│    └─Empty: 2-1512                     [128]                     --
│    └─BatchNorm2d: 2-1513               [16, 128, 32, 32]         --
│    └─Scaler: 2-1514                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1515                      [16, 128, 32, 32]         --
│    └─Empty: 2-1516                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1517                     [16, 128, 32, 32]         --
├─Dropout2d: 1-152                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1518                 [16, 128, 16, 16]         --
│    └─Empty: 2-1519                     [16, 128, 16, 16]         --
│    └─Empty: 2-1520                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1521        --                        --
│    └─One: 2-1522                       [1]                       --
│    └─OutputScale: 2-1523               --                        --
│    └─Empty: 2-1524                     [128, 128, 3, 3]          --
│    └─Empty: 2-1525                     [128, 128, 3, 3]          --
│    └─Empty: 2-1526                     [128]                     --
│    └─Empty: 2-1527                     [128]                     --
│    └─BatchNorm2d: 2-1528               [16, 128, 16, 16]         --
│    └─Scaler: 2-1529                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1530                      [16, 128, 16, 16]         --
│    └─Empty: 2-1531                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1532                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-154               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1533        --                        --
│    └─One: 2-1534                       [1]                       --
│    └─OutputScale: 2-1535               --                        --
│    └─Empty: 2-1536                     [128, 128, 1, 1]          --
│    └─Empty: 2-1537                     [128, 128, 1, 1]          --
│    └─Empty: 2-1538                     [128]                     --
│    └─Empty: 2-1539                     [128]                     --
│    └─BatchNorm2d: 2-1540               [16, 128, 16, 16]         --
│    └─Scaler: 2-1541                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1542                      [16, 128, 16, 16]         --
│    └─Empty: 2-1543                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1544                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-155        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1545                 [16, 128, 16, 16]         --
│    └─Empty: 2-1546                     [16, 128, 16, 16]         --
│    └─Empty: 2-1547                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1548        --                        --
│    └─One: 2-1549                       [1]                       --
│    └─OutputScale: 2-1550               --                        --
│    └─Empty: 2-1551                     [128, 128, 3, 3]          --
│    └─Empty: 2-1552                     [128, 128, 3, 3]          --
│    └─Empty: 2-1553                     [128]                     --
│    └─Empty: 2-1554                     [128]                     --
│    └─BatchNorm2d: 2-1555               [16, 128, 16, 16]         --
│    └─Scaler: 2-1556                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1557                      [16, 128, 16, 16]         --
│    └─Empty: 2-1558                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1559                     [16, 128, 16, 16]         --
├─Dropout2d: 1-156                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-157        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1560                 [16, 128, 8, 8]           --
│    └─Empty: 2-1561                     [16, 128, 8, 8]           --
│    └─Empty: 2-1562                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1563        --                        --
│    └─One: 2-1564                       [1]                       --
│    └─OutputScale: 2-1565               --                        --
│    └─Empty: 2-1566                     [128, 128, 3, 3]          --
│    └─Empty: 2-1567                     [128, 128, 3, 3]          --
│    └─Empty: 2-1568                     [128]                     --
│    └─Empty: 2-1569                     [128]                     --
│    └─BatchNorm2d: 2-1570               [16, 128, 8, 8]           --
│    └─Scaler: 2-1571                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1572                      [16, 128, 8, 8]           --
│    └─Empty: 2-1573                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1574                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-158               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1575        --                        --
│    └─One: 2-1576                       [1]                       --
│    └─OutputScale: 2-1577               --                        --
│    └─Empty: 2-1578                     [16, 128, 1, 1]           --
│    └─Empty: 2-1579                     [16, 128, 1, 1]           --
│    └─Empty: 2-1580                     [16]                      --
│    └─Empty: 2-1581                     [16]                      --
│    └─BatchNorm2d: 2-1582               [16, 16, 8, 8]            --
│    └─Scaler: 2-1583                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1584                      [16, 16, 8, 8]            --
│    └─Empty: 2-1585                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1586                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-159        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1587                 [16, 128, 8, 8]           --
│    └─Empty: 2-1588                     [16, 128, 8, 8]           --
│    └─Empty: 2-1589                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1590        --                        --
│    └─One: 2-1591                       [1]                       --
│    └─OutputScale: 2-1592               --                        --
│    └─Empty: 2-1593                     [16, 128, 3, 3]           --
│    └─Empty: 2-1594                     [16, 128, 3, 3]           --
│    └─Empty: 2-1595                     [16]                      --
│    └─Empty: 2-1596                     [16]                      --
│    └─BatchNorm2d: 2-1597               [16, 16, 8, 8]            --
│    └─Scaler: 2-1598                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1599                      [16, 16, 8, 8]            --
│    └─Empty: 2-1600                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1601                     [16, 16, 8, 8]            --
├─Dropout2d: 1-160                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-161               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1602        --                        --
│    └─One: 2-1603                       [1]                       --
│    └─OutputScale: 2-1604               --                        --
│    └─Empty: 2-1605                     [128, 48, 1, 1]           --
│    └─Empty: 2-1606                     [128, 48, 1, 1]           --
│    └─Empty: 2-1607                     [128]                     --
│    └─Empty: 2-1608                     [128]                     --
│    └─BatchNorm2d: 2-1609               [16, 128, 64, 64]         --
│    └─Scaler: 2-1610                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1611                      [16, 128, 64, 64]         --
│    └─Empty: 2-1612                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1613                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1614                 [16, 128, 32, 32]         --
│    └─Empty: 2-1615                     [16, 128, 32, 32]         --
│    └─Empty: 2-1616                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1617        --                        --
│    └─One: 2-1618                       [1]                       --
│    └─OutputScale: 2-1619               --                        --
│    └─Empty: 2-1620                     [128, 128, 3, 3]          --
│    └─Empty: 2-1621                     [128, 128, 3, 3]          --
│    └─Empty: 2-1622                     [128]                     --
│    └─Empty: 2-1623                     [128]                     --
│    └─BatchNorm2d: 2-1624               [16, 128, 32, 32]         --
│    └─Scaler: 2-1625                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1626                      [16, 128, 32, 32]         --
│    └─Empty: 2-1627                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1628                     [16, 128, 32, 32]         --
├─Dropout2d: 1-163                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1629                 [16, 128, 16, 16]         --
│    └─Empty: 2-1630                     [16, 128, 16, 16]         --
│    └─Empty: 2-1631                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1632        --                        --
│    └─One: 2-1633                       [1]                       --
│    └─OutputScale: 2-1634               --                        --
│    └─Empty: 2-1635                     [128, 128, 3, 3]          --
│    └─Empty: 2-1636                     [128, 128, 3, 3]          --
│    └─Empty: 2-1637                     [128]                     --
│    └─Empty: 2-1638                     [128]                     --
│    └─BatchNorm2d: 2-1639               [16, 128, 16, 16]         --
│    └─Scaler: 2-1640                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1641                      [16, 128, 16, 16]         --
│    └─Empty: 2-1642                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1643                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-165               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1644        --                        --
│    └─One: 2-1645                       [1]                       --
│    └─OutputScale: 2-1646               --                        --
│    └─Empty: 2-1647                     [128, 128, 1, 1]          --
│    └─Empty: 2-1648                     [128, 128, 1, 1]          --
│    └─Empty: 2-1649                     [128]                     --
│    └─Empty: 2-1650                     [128]                     --
│    └─BatchNorm2d: 2-1651               [16, 128, 16, 16]         --
│    └─Scaler: 2-1652                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1653                      [16, 128, 16, 16]         --
│    └─Empty: 2-1654                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1655                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-166        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1656                 [16, 128, 16, 16]         --
│    └─Empty: 2-1657                     [16, 128, 16, 16]         --
│    └─Empty: 2-1658                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1659        --                        --
│    └─One: 2-1660                       [1]                       --
│    └─OutputScale: 2-1661               --                        --
│    └─Empty: 2-1662                     [128, 128, 3, 3]          --
│    └─Empty: 2-1663                     [128, 128, 3, 3]          --
│    └─Empty: 2-1664                     [128]                     --
│    └─Empty: 2-1665                     [128]                     --
│    └─BatchNorm2d: 2-1666               [16, 128, 16, 16]         --
│    └─Scaler: 2-1667                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1668                      [16, 128, 16, 16]         --
│    └─Empty: 2-1669                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1670                     [16, 128, 16, 16]         --
├─Dropout2d: 1-167                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1671                 [16, 128, 8, 8]           --
│    └─Empty: 2-1672                     [16, 128, 8, 8]           --
│    └─Empty: 2-1673                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1674        --                        --
│    └─One: 2-1675                       [1]                       --
│    └─OutputScale: 2-1676               --                        --
│    └─Empty: 2-1677                     [128, 128, 3, 3]          --
│    └─Empty: 2-1678                     [128, 128, 3, 3]          --
│    └─Empty: 2-1679                     [128]                     --
│    └─Empty: 2-1680                     [128]                     --
│    └─BatchNorm2d: 2-1681               [16, 128, 8, 8]           --
│    └─Scaler: 2-1682                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1683                      [16, 128, 8, 8]           --
│    └─Empty: 2-1684                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1685                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-169               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1686        --                        --
│    └─One: 2-1687                       [1]                       --
│    └─OutputScale: 2-1688               --                        --
│    └─Empty: 2-1689                     [16, 128, 1, 1]           --
│    └─Empty: 2-1690                     [16, 128, 1, 1]           --
│    └─Empty: 2-1691                     [16]                      --
│    └─Empty: 2-1692                     [16]                      --
│    └─BatchNorm2d: 2-1693               [16, 16, 8, 8]            --
│    └─Scaler: 2-1694                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1695                      [16, 16, 8, 8]            --
│    └─Empty: 2-1696                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1697                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1698                 [16, 128, 8, 8]           --
│    └─Empty: 2-1699                     [16, 128, 8, 8]           --
│    └─Empty: 2-1700                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1701        --                        --
│    └─One: 2-1702                       [1]                       --
│    └─OutputScale: 2-1703               --                        --
│    └─Empty: 2-1704                     [16, 128, 3, 3]           --
│    └─Empty: 2-1705                     [16, 128, 3, 3]           --
│    └─Empty: 2-1706                     [16]                      --
│    └─Empty: 2-1707                     [16]                      --
│    └─BatchNorm2d: 2-1708               [16, 16, 8, 8]            --
│    └─Scaler: 2-1709                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1710                      [16, 16, 8, 8]            --
│    └─Empty: 2-1711                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1712                     [16, 16, 8, 8]            --
├─Dropout2d: 1-171                       [16, 16, 8, 8]            --
├─FusedConv2dBNReLU: 1-172               [16, 128, 64, 64]         (recursive)
│    └─OutputShiftSqueeze: 2-1713        --                        --
│    └─One: 2-1714                       [1]                       --
│    └─OutputScale: 2-1715               --                        --
│    └─Empty: 2-1716                     [128, 48, 1, 1]           --
│    └─Empty: 2-1717                     [128, 48, 1, 1]           --
│    └─Empty: 2-1718                     [128]                     --
│    └─Empty: 2-1719                     [128]                     --
│    └─BatchNorm2d: 2-1720               [16, 128, 64, 64]         --
│    └─Scaler: 2-1721                    [16, 128, 64, 64]         --
│    └─ReLU: 2-1722                      [16, 128, 64, 64]         --
│    └─Empty: 2-1723                     [16, 128, 64, 64]         --
│    └─Clamp: 2-1724                     [16, 128, 64, 64]         --
├─FusedMaxPoolConv2dBNReLU: 1-173        [16, 128, 32, 32]         (recursive)
│    └─MaxPool2d: 2-1725                 [16, 128, 32, 32]         --
│    └─Empty: 2-1726                     [16, 128, 32, 32]         --
│    └─Empty: 2-1727                     [16, 128, 32, 32]         --
│    └─OutputShiftSqueeze: 2-1728        --                        --
│    └─One: 2-1729                       [1]                       --
│    └─OutputScale: 2-1730               --                        --
│    └─Empty: 2-1731                     [128, 128, 3, 3]          --
│    └─Empty: 2-1732                     [128, 128, 3, 3]          --
│    └─Empty: 2-1733                     [128]                     --
│    └─Empty: 2-1734                     [128]                     --
│    └─BatchNorm2d: 2-1735               [16, 128, 32, 32]         --
│    └─Scaler: 2-1736                    [16, 128, 32, 32]         --
│    └─ReLU: 2-1737                      [16, 128, 32, 32]         --
│    └─Empty: 2-1738                     [16, 128, 32, 32]         --
│    └─Clamp: 2-1739                     [16, 128, 32, 32]         --
├─Dropout2d: 1-174                       [16, 128, 32, 32]         --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1740                 [16, 128, 16, 16]         --
│    └─Empty: 2-1741                     [16, 128, 16, 16]         --
│    └─Empty: 2-1742                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1743        --                        --
│    └─One: 2-1744                       [1]                       --
│    └─OutputScale: 2-1745               --                        --
│    └─Empty: 2-1746                     [128, 128, 3, 3]          --
│    └─Empty: 2-1747                     [128, 128, 3, 3]          --
│    └─Empty: 2-1748                     [128]                     --
│    └─Empty: 2-1749                     [128]                     --
│    └─BatchNorm2d: 2-1750               [16, 128, 16, 16]         --
│    └─Scaler: 2-1751                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1752                      [16, 128, 16, 16]         --
│    └─Empty: 2-1753                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1754                     [16, 128, 16, 16]         --
├─FusedConv2dBNReLU: 1-176               [16, 128, 16, 16]         (recursive)
│    └─OutputShiftSqueeze: 2-1755        --                        --
│    └─One: 2-1756                       [1]                       --
│    └─OutputScale: 2-1757               --                        --
│    └─Empty: 2-1758                     [128, 128, 1, 1]          --
│    └─Empty: 2-1759                     [128, 128, 1, 1]          --
│    └─Empty: 2-1760                     [128]                     --
│    └─Empty: 2-1761                     [128]                     --
│    └─BatchNorm2d: 2-1762               [16, 128, 16, 16]         --
│    └─Scaler: 2-1763                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1764                      [16, 128, 16, 16]         --
│    └─Empty: 2-1765                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1766                     [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 128, 16, 16]         (recursive)
│    └─MaxPool2d: 2-1767                 [16, 128, 16, 16]         --
│    └─Empty: 2-1768                     [16, 128, 16, 16]         --
│    └─Empty: 2-1769                     [16, 128, 16, 16]         --
│    └─OutputShiftSqueeze: 2-1770        --                        --
│    └─One: 2-1771                       [1]                       --
│    └─OutputScale: 2-1772               --                        --
│    └─Empty: 2-1773                     [128, 128, 3, 3]          --
│    └─Empty: 2-1774                     [128, 128, 3, 3]          --
│    └─Empty: 2-1775                     [128]                     --
│    └─Empty: 2-1776                     [128]                     --
│    └─BatchNorm2d: 2-1777               [16, 128, 16, 16]         --
│    └─Scaler: 2-1778                    [16, 128, 16, 16]         --
│    └─ReLU: 2-1779                      [16, 128, 16, 16]         --
│    └─Empty: 2-1780                     [16, 128, 16, 16]         --
│    └─Clamp: 2-1781                     [16, 128, 16, 16]         --
├─Dropout2d: 1-178                       [16, 128, 16, 16]         --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 128, 8, 8]           (recursive)
│    └─MaxPool2d: 2-1782                 [16, 128, 8, 8]           --
│    └─Empty: 2-1783                     [16, 128, 8, 8]           --
│    └─Empty: 2-1784                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1785        --                        --
│    └─One: 2-1786                       [1]                       --
│    └─OutputScale: 2-1787               --                        --
│    └─Empty: 2-1788                     [128, 128, 3, 3]          --
│    └─Empty: 2-1789                     [128, 128, 3, 3]          --
│    └─Empty: 2-1790                     [128]                     --
│    └─Empty: 2-1791                     [128]                     --
│    └─BatchNorm2d: 2-1792               [16, 128, 8, 8]           --
│    └─Scaler: 2-1793                    [16, 128, 8, 8]           --
│    └─ReLU: 2-1794                      [16, 128, 8, 8]           --
│    └─Empty: 2-1795                     [16, 128, 8, 8]           --
│    └─Clamp: 2-1796                     [16, 128, 8, 8]           --
├─FusedConv2dBNReLU: 1-180               [16, 16, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1797        --                        --
│    └─One: 2-1798                       [1]                       --
│    └─OutputScale: 2-1799               --                        --
│    └─Empty: 2-1800                     [16, 128, 1, 1]           --
│    └─Empty: 2-1801                     [16, 128, 1, 1]           --
│    └─Empty: 2-1802                     [16]                      --
│    └─Empty: 2-1803                     [16]                      --
│    └─BatchNorm2d: 2-1804               [16, 16, 8, 8]            --
│    └─Scaler: 2-1805                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1806                      [16, 16, 8, 8]            --
│    └─Empty: 2-1807                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1808                     [16, 16, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 16, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1809                 [16, 128, 8, 8]           --
│    └─Empty: 2-1810                     [16, 128, 8, 8]           --
│    └─Empty: 2-1811                     [16, 128, 8, 8]           --
│    └─OutputShiftSqueeze: 2-1812        --                        --
│    └─One: 2-1813                       [1]                       --
│    └─OutputScale: 2-1814               --                        --
│    └─Empty: 2-1815                     [16, 128, 3, 3]           --
│    └─Empty: 2-1816                     [16, 128, 3, 3]           --
│    └─Empty: 2-1817                     [16]                      --
│    └─Empty: 2-1818                     [16]                      --
│    └─BatchNorm2d: 2-1819               [16, 16, 8, 8]            --
│    └─Scaler: 2-1820                    [16, 16, 8, 8]            --
│    └─ReLU: 2-1821                      [16, 16, 8, 8]            --
│    └─Empty: 2-1822                     [16, 16, 8, 8]            --
│    └─Clamp: 2-1823                     [16, 16, 8, 8]            --
├─Dropout2d: 1-182                       [16, 16, 8, 8]            --
├─Conv1d: 1-183                          [16, 128, 12]             655,494
│    └─OutputShiftSqueeze: 2-1824        --                        --
│    └─One: 2-1825                       [1]                       --
│    └─OutputScale: 2-1826               --                        --
│    └─Empty: 2-1827                     [128, 1024, 5]            --
│    └─Empty: 2-1828                     [128, 1024, 5]            --
│    └─Empty: 2-1829                     [128]                     --
│    └─Empty: 2-1830                     [128]                     --
│    └─Scaler: 2-1831                    [16, 128, 12]             --
│    └─Empty: 2-1832                     [16, 128, 12]             --
│    └─Empty: 2-1833                     [16, 128, 12]             --
│    └─Clamp: 2-1834                     [16, 128, 12]             --
├─Conv1d: 1-184                          [16, 5, 8]                (recursive)
│    └─OutputShiftSqueeze: 2-1835        --                        --
│    └─One: 2-1836                       [1]                       --
│    └─OutputScale: 2-1837               --                        --
│    └─Empty: 2-1838                     [5, 128, 5]               --
│    └─Empty: 2-1839                     [5, 128, 5]               --
│    └─Empty: 2-1840                     [5]                       --
│    └─Empty: 2-1841                     [5]                       --
│    └─Scaler: 2-1842                    [16, 5, 8]                --
│    └─Empty: 2-1843                     [16, 5, 8]                --
│    └─Empty: 2-1844                     [16, 5, 8]                --
│    └─Clamp: 2-1845                     [16, 5, 8]                --
==========================================================================================
Total params: 1,292,385
Trainable params: 658,693
Non-trainable params: 633,692
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 2.55
Estimated Total Size (MB): 203.87
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 0.690 | Acc: 86.000% | Wgt Acc: 89.481%
	I - Batch: 100 | Loss: 0.625 | Acc: 88.375% | Wgt Acc: 91.665%
	I - Batch: 150 | Loss: 0.591 | Acc: 90.667% | Wgt Acc: 93.367%
	I - Batch: 200 | Loss: 0.573 | Acc: 91.562% | Wgt Acc: 94.056%
I - num batch: 222
I - Train -- Loss: 0.566 | Acc: 91.965% | Wgt Acc: 94.404% | LR: 1.000000e-03 | Dur: 101.05s
I - Confusion Matrix: [row->prediction - col->label]
[[673.   6.   4.  12.  78.]
 [  2. 562.   1.   1.  34.]
 [  1.   3. 721.   3.  55.]
 [  5.   2.   1. 513.  40.]
 [ 16.   5.   7.   9. 793.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.055 | Acc: 64.892% | Wgt Acc: 62.428% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   4.   5.  28.  21.]
 [  0.  39.   3.   2.   5.]
 [  0.  20.  49.   4.  21.]
 [  3.   2.   7.  36.   2.]
 [ 11.  13.  11.  16. 131.]]

I - Local maximum validation set accuracy:  64.89

I - Validation set results: 
[14-1-2-0.99][50-3-0--0.33][124-2-4-0.50][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.99][615-0-0-0.99][695-1-2-0.99][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.87][1212-3-0--0.72][1368-0-0-0.99][2181-2-3--0.47][2476-2-2-0.99][2721-2-2-0.99][2818-1-1-0.99][2886-2-4-0.40]
[3231-2-2-0.99][3333-2-2-0.25][3482-2-2-0.99][3536-3-4--0.12][3625-1-2-0.98][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.99][4346-1-0-0.17]
[4581-2-2-0.99][4708-3-4-0.99][4838-3-4--0.69][4845-1-4--0.27][4868-0-0-0.99][4939-0-4--0.71][4984-2-2-0.99][5078-1-4-0.38][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1--0.83][5949-3-0-0.44][5987-2-4-0.71][6014-3-1-0.16][6033-3-4--0.12][6313-0-0-0.99][6421-3-3-0.99][6500-1-1-0.87][6583-3-3-0.99]
[6683-3-0-0.99][6825-2-1-0.99][6998-3-0-0.30][7049-3-3-0.99][7517-1-2-0.64][7521-1-1-0.99][7528-1-1-0.86][7949-1-2-0.99][8135-1-1--0.35][8185-3-0-0.99]
[8269-3-1-0.20][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.99][9001-2-2-0.99][9036-2-2-0.99][9281-3-0-0.38][9300-2-2-0.99]
[9571-0-0-0.82][9617-1-1-0.99][9644-2-2-0.99][9705-2-4--0.10][9801-0-0-0.11][9803-3-3-0.33][9865-3-3-0.99][9896-2-4-0.96][10314-1-2--0.75][10337-3-3-0.99]
[10403-0-0-0.99][10653-2-4-0.12][10704-2-2-0.99][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.80][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.99][11499-0-0-0.99][11502-3-0-0.48][11512-3-3-0.99][11608-1-2-0.12][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-0-0.54]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-2-0.99][12320-1-4-0.99][12377-2-2-0.99][12398-2-0-0.99][12503-1-2-0.99][12617-0-0-0.69][12685-3-4-0.19][12738-2-2--0.56]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.99][13240-3-0-0.86][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.35][13763-2-3-0.22][13905-3-0-0.99][14060-2-4-0.99]
[14065-3-0-0.99][14147-3-3-0.99][14595-2-2-0.84][14687-2-2-0.99][14788-2-2-0.99][14869-1-1-0.40][14872-3-4-0.99][14877-1-1-0.99][14927-0-0-0.99][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.99][15375-3-0-0.99][15389-3-3-0.91][15568-2-1-0.84][15675-3-3-0.99][15869-1-0-0.99][16207-3-0-0.99][16236-0-0-0.99][16302-3-2-0.99]
[16331-2-2-0.99][16381-0-3-0.05][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.99][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.99][17245-1-2-0.27]
[17278-3-0--0.07][17282-0-0-0.99][17311-2-2-0.99][17336-2-1-0.90][17608-3-3-0.99][17627-0-0-0.99][17877-3-0-0.99][17924-1-2-0.96][17984-3-0-0.99][18211-0-0-0.87]
[18276-3-3-0.87][18287-1-1-0.64][18394-0-0-0.99][18428-0-0-0.18][18442-0-3-0.99][18478-3-3-0.77][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.87][18938-3-0-0.54][19817-1-2-0.96][19839-0-0-0.67][19930-3-0-0.27][19944-0-4-0.99][20036-2-2-0.99]
[20101-3-3-0.99][20474-1-2-0.92][20547-3-0-0.68][20929-2-2-0.99][21245-1-2-0.98][21257-3-2--0.31][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-0-0.99][21943-3-4-0.99][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-2-0.77][22985-3-3-0.88][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0--0.16]
[23219-0-0-0.99][23363-3-3-0.99][23470-0-0-0.99][23486-2-2-0.99][23497-0-0-0.99][23516-0-0-0.99][23690-1-3-0.99][23921-2-2-0.99][23936-1-0-0.99][24040-3-4-0.95]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.98][24345-0-0-0.99][24364-1-2-0.99][24427-3-0-0.99][24477-2-2-0.99][24495-2-4-0.99][24893-2-2-0.28]
[25012-1-2--0.45][25121-2-2-0.99][25165-3-3-0.99][25183-0-4-0.78][25297-3-3-0.99][25398-0-0-0.99][25574-2-2-0.99][25644-1-2-0.99][25718-1-4--0.31][25774-2-2-0.30]
[26032-3-3-0.94][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.99][26732-1-1-0.95][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.49][26838-2-2-0.35][26860-1-4-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.99][27526-0-0-0.36][27639-3-4-0.87][27698-3-0-0.99][27772-0-0-0.99][27890-1-1-0.85][28040-0-4-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-2-0.99][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.99][30716-0-4-0.99]
[30806-2-2-0.99][30906-1-1-0.99][31007-0-0-0.76][31181-3-4--0.18][31238-0-0-0.99][31347-0-0-0.99][31422-2-2-0.92][31429-3-2-0.14][31431-0-0-0.94][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-2--0.58][31597-1-1-0.99][31619-1-4-0.99][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.40][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-4-0.92][32140-3-3-0.99][32263-2-2--0.01][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.99][32473-3-3-0.87][32574-3-0-0.99][32584-0-4-0.99][32622-0-4-0.94]
[32858-3-0-0.99][32969-3-3-0.99][33016-2-2-0.99][33031-1-3-0.99][33035-2-2-0.91][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.75]
[33474-0-4-0.17][33478-2-0-0.99][33618-1-4-0.99][33712-0-0-0.99][33782-2-4-0.99][33914-3-4-0.68][34076-3-4-0.99][34112-2-2-0.99][34138-2-3--0.36][34239-1-1-0.09]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-0-0.99][34783-2-2-0.76][35015-3-4-0.99][35018-1-1-0.43][35288-2-2-0.74][0-4-4-0.93][1-4-4-0.99][2-4-4-0.74]
[3-4-2-0.94][4-4-0-0.99][5-4-0-0.10][6-4-4-0.99][7-4-4-0.99][8-4-4-0.82][9-4-0-0.99][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-2--0.28][17-4-4-0.61][18-4-4-0.99][19-4-0-0.36][20-4-4-0.99][21-4-2-0.99][22-4-4-0.99][23-4-4-0.35]
[24-4-4-0.99][25-4-4-0.99][26-4-0-0.74][27-4-4-0.99][28-4-4-0.99][29-4-2-0.55][30-4-4-0.99][31-4-4-0.99][32-4-4-0.99][33-4-2-0.72]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.99][40-4-4-0.72][41-4-4-0.71][42-4-2-0.93][43-4-4-0.99][45-4-4-0.56][46-4-4-0.99]
[47-4-4-0.99][48-4-2-0.99][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-4-0.50][57-4-0-0.81][58-4-2-0.99]
[59-4-0-0.99][60-4-4-0.96][61-4-4-0.99][62-4-4-0.99][63-4-4-0.73][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-1-0.13]
[69-4-0-0.26][70-4-4-0.99][72-4-1-0.99][73-4-1-0.92][74-4-4-0.99][75-4-0-0.31][77-4-4-0.99][78-4-0-0.49][79-4-4-0.99][80-4-4-0.99]
[81-4-2-0.59][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-2-0.73][87-4-4-0.99][88-4-4-0.99][89-4-0-0.44][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-0-0.94][94-4-4-0.99][95-4-4--0.11][96-4-4-0.99][97-4-4-0.99][98-4-2-0.99][99-4-4-0.94][100-4-4-0.99]
[101-4-4-0.99][102-4-2-0.99][103-4-4-0.61][104-4-4-0.99][105-4-4-0.99][106-4-4-0.99][107-4-4-0.54][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.99][113-4-4-0.32][114-4-2-0.59][115-4-4-0.81][116-4-0-0.40][117-4-4-0.99][119-4-4-0.99][121-4-4-0.89][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.99][128-4-4-0.23][129-4-4-0.99][130-4-4-0.99][131-4-2-0.90][132-4-4-0.85][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-1-0.99][141-4-4-0.76][142-4-4-0.90][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.41][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.96]
[157-4-0-0.99][158-4-4-0.67][160-4-2-0.99][161-4-4-0.94][162-4-4-0.20][164-4-2-0.99][165-4-4-0.99][167-4-0-0.99][168-4-2-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.99][175-4-4-0.99][177-4-4-0.99][178-4-2-0.91][179-4-4-0.99][180-4-4-0.99][181-4-4-0.99]
[182-4-3-0.99][183-4-4-0.99][184-4-4-0.99][186-4-4-0.99][187-4-4-0.66][188-4-4-0.99][189-4-2-0.52][190-4-0-0.01][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.79][194-4-4-0.62][195-4-0-0.99][196-4-4-0.99][197-4-4-0.92][198-4-4-0.99][199-4-2-0.89]
---------------------------
I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 0.528 | Acc: 93.750% | Wgt Acc: 95.574%
	I - Batch: 100 | Loss: 0.518 | Acc: 94.312% | Wgt Acc: 96.133%
	I - Batch: 150 | Loss: 0.517 | Acc: 94.667% | Wgt Acc: 96.418%
	I - Batch: 200 | Loss: 0.517 | Acc: 94.438% | Wgt Acc: 96.288%
I - num batch: 222
I - Train -- Loss: 0.515 | Acc: 94.531% | Wgt Acc: 96.362% | LR: 1.000000e-03 | Dur: 104.45s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   3.  49.]
 [  2. 568.   2.   0.  26.]
 [  0.   2. 725.   0.  39.]
 [  3.   0.   0. 528.  35.]
 [ 11.   8.   7.   7. 851.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.037 | Acc: 65.286% | Wgt Acc: 58.468% | Dur: 18.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   7.   3.  15.   8.]
 [  0.  35.   2.   0.   1.]
 [  0.   8.  26.   2.   3.]
 [  4.   1.   5.  40.   4.]
 [ 18.  27.  39.  29. 164.]]

I - Local maximum validation set accuracy:  65.29

I - Validation set results: 
[14-1-2-0.41][50-3-4-0.99][124-2-4-0.99][127-0-0-0.99][443-2-4-0.03][567-0-0-0.99][573-1-1-0.99][615-0-0-0.99][695-1-2-0.99][722-3-0-0.87]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.93][1212-3-4-0.99][1368-0-0-0.99][2181-2-3-0.57][2476-2-2-0.99][2721-2-4-0.99][2818-1-1-0.99][2886-2-4-0.99]
[3231-2-2-0.99][3333-2-4-0.93][3482-2-4-0.99][3536-3-4-0.85][3625-1-1-0.83][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.67][4346-1-0--0.76]
[4581-2-4-0.51][4708-3-4-0.99][4838-3-4-0.93][4845-1-4-0.99][4868-0-0-0.99][4939-0-4-0.99][4984-2-2-0.81][5078-1-4-0.96][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.17][5949-3-4-0.99][5987-2-4-0.99][6014-3-3-0.99][6033-3-4-0.36][6313-0-0-0.76][6421-3-2-0.78][6500-1-4-0.99][6583-3-3-0.99]
[6683-3-3-0.17][6825-2-1-0.99][6998-3-4-0.25][7049-3-3-0.70][7517-1-1-0.55][7521-1-1-0.99][7528-1-1--0.10][7949-1-2-0.99][8135-1-0-0.00][8185-3-0-0.99]
[8269-3-4-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.08][9001-2-2-0.99][9036-2-2-0.99][9281-3-0-0.99][9300-2-2-0.99]
[9571-0-4-0.65][9617-1-4-0.48][9644-2-2-0.99][9705-2-4-0.99][9801-0-4-0.46][9803-3-3-0.13][9865-3-3-0.99][9896-2-4-0.99][10314-1-4-0.99][10337-3-3-0.99]
[10403-0-4-0.99][10653-2-4-0.99][10704-2-4-0.99][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.96][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0-0.99][11502-3-3-0.06][11512-3-3-0.99][11608-1-1-0.61][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-0-0.99]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-2-0.99][12320-1-4-0.99][12377-2-4-0.99][12398-2-3-0.69][12503-1-2-0.99][12617-0-0-0.99][12685-3-4-0.99][12738-2-4-0.54]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.90][13240-3-4-0.98][13253-1-0-0.98][13273-0-0-0.99][13634-1-4-0.95][13763-2-3--0.06][13905-3-4-0.02][14060-2-4-0.99]
[14065-3-4-0.21][14147-3-3-0.99][14595-2-2-0.99][14687-2-2-0.99][14788-2-4-0.81][14869-1-4-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-3-0.72][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-4-0.95][15375-3-0-0.99][15389-3-3-0.99][15568-2-4-0.99][15675-3-3-0.99][15869-1-0-0.99][16207-3-0-0.79][16236-0-0-0.99][16302-3-2-0.52]
[16331-2-2-0.99][16381-0-4-0.95][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.61][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.90][17245-1-4-0.74]
[17278-3-4--0.05][17282-0-0-0.99][17311-2-2-0.99][17336-2-1-0.94][17608-3-3-0.99][17627-0-4-0.99][17877-3-4-0.99][17924-1-4-0.99][17984-3-0-0.76][18211-0-3-0.82]
[18276-3-0-0.75][18287-1-4-0.88][18394-0-0-0.99][18428-0-0-0.99][18442-0-3-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.99][18938-3-4-0.66][19817-1-2-0.99][19839-0-0-0.80][19930-3-3-0.99][19944-0-4-0.99][20036-2-2-0.99]
[20101-3-3-0.99][20474-1-1-0.24][20547-3-4-0.99][20929-2-2-0.99][21245-1-2-0.95][21257-3-4-0.97][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-4-0.25][21714-0-0-0.99][21943-3-4-0.99][21947-0-4-0.99][21948-0-0-0.99][21965-2-2-0.79][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.57][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.40]
[23219-0-4-0.98][23363-3-3-0.99][23470-0-0-0.56][23486-2-4-0.99][23497-0-3-0.99][23516-0-0-0.99][23690-1-4-0.51][23921-2-4-0.99][23936-1-0-0.99][24040-3-4-0.99]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.76][24364-1-4-0.26][24427-3-0-0.99][24477-2-4-0.99][24495-2-4-0.99][24893-2-4-0.61]
[25012-1-4-0.99][25121-2-2-0.99][25165-3-3-0.99][25183-0-0-0.72][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.99][25644-1-1-0.34][25718-1-4-0.99][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.99][26732-1-1--0.03][26784-3-3-0.99][26827-3-3-0.99][26833-0-0-0.99][26838-2-4--0.03][26860-1-4-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0--0.22][27526-0-0-0.99][27639-3-3-0.99][27698-3-0-0.99][27772-0-0-0.99][27890-1-1-0.87][28040-0-0-0.26][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-4-0.35][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-4-0.33][30716-0-4-0.99]
[30806-2-2-0.70][30906-1-1-0.99][31007-0-4-0.68][31181-3-4-0.99][31238-0-0-0.79][31347-0-0-0.99][31422-2-4-0.99][31429-3-4-0.13][31431-0-0-0.99][31432-1-1-0.99]
[31477-0-0-0.79][31524-1-4--0.97][31597-1-4-0.88][31619-1-0--0.03][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.96][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-4-0.76][32140-3-3-0.99][32263-2-0-0.62][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.86][32473-3-3-0.78][32574-3-0-0.96][32584-0-4-0.99][32622-0-4-0.99]
[32858-3-0-0.76][32969-3-3-0.99][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.93][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-4-0.91]
[33474-0-4-0.35][33478-2-4-0.98][33618-1-4-0.99][33712-0-4-0.99][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.99][34112-2-2-0.99][34138-2-4-0.98][34239-1-1-0.99]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-0-0.76][34783-2-4-0.70][35015-3-4-0.99][35018-1-4-0.99][35288-2-4-0.36][0-4-4-0.99][1-4-4-0.99][2-4-0-0.88]
[3-4-4-0.99][4-4-4-0.99][5-4-2--0.15][6-4-4-0.61][7-4-0-0.99][8-4-4-0.99][9-4-4-0.99][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-4-0.99][17-4-4-0.99][18-4-4-0.99][19-4-4-0.99][20-4-4-0.99][21-4-4-0.99][22-4-4-0.99][23-4-4-0.99]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.79][27-4-4-0.99][28-4-4-0.99][29-4-4-0.89][30-4-4-0.72][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.99][40-4-4-0.99][41-4-4-0.99][42-4-4-0.97][43-4-4-0.99][45-4-4-0.99][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.98][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-4-0.65][57-4-3-0.99][58-4-4-0.90]
[59-4-4-0.99][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.99][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-4-0.99]
[69-4-4-0.66][70-4-4-0.99][72-4-4-0.99][73-4-4-0.87][74-4-4-0.99][75-4-3--0.21][77-4-4-0.99][78-4-4-0.99][79-4-4-0.99][80-4-4-0.99]
[81-4-2-0.60][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.99][87-4-4-0.99][88-4-4-0.99][89-4-4-0.99][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-4-0.93][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-4-0.99][99-4-4-0.99][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.99][104-4-4-0.99][105-4-4-0.99][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.99][113-4-4-0.99][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.99][128-4-4-0.99][129-4-4-0.99][130-4-4-0.99][131-4-4-0.73][132-4-4-0.99][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-4-0.99][141-4-4-0.99][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.99]
[157-4-4-0.96][158-4-4-0.99][160-4-4-0.99][161-4-4-0.99][162-4-4-0.99][164-4-4-0.99][165-4-4-0.99][167-4-0-0.99][168-4-4-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-4-0.47][175-4-4-0.99][177-4-4-0.99][178-4-4-0.99][179-4-4-0.92][180-4-4-0.99][181-4-4-0.99]
[182-4-3-0.99][183-4-4-0.99][184-4-4-0.99][186-4-4-0.99][187-4-4-0.90][188-4-4-0.99][189-4-0--0.36][190-4-4--0.16][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.98][194-4-4-0.81][195-4-0-0.67][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-4-0.54]
---------------------------
I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.496 | Acc: 96.000% | Wgt Acc: 97.358%
	I - Batch: 100 | Loss: 0.505 | Acc: 94.688% | Wgt Acc: 96.557%
	I - Batch: 150 | Loss: 0.506 | Acc: 94.667% | Wgt Acc: 96.490%
	I - Batch: 200 | Loss: 0.502 | Acc: 95.125% | Wgt Acc: 96.807%
I - num batch: 222
I - Train -- Loss: 0.501 | Acc: 95.066% | Wgt Acc: 96.778% | LR: 1.000000e-03 | Dur: 101.34s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   1.   1.   1.  47.]
 [  0. 573.   1.   1.  15.]
 [  0.   0. 728.   0.  38.]
 [  0.   0.   0. 531.  37.]
 [ 20.   4.   4.   5. 863.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.073 | Acc: 64.892% | Wgt Acc: 58.635% | Dur: 14.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  11.   4.]
 [  0.  38.   4.   1.   6.]
 [  0.   7.  20.   0.   3.]
 [ 11.   4.  11.  50.   6.]
 [ 17.  27.  38.  24. 161.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.484 | Acc: 96.375% | Wgt Acc: 97.577%
	I - Batch: 100 | Loss: 0.490 | Acc: 96.375% | Wgt Acc: 97.669%
	I - Batch: 150 | Loss: 0.494 | Acc: 96.000% | Wgt Acc: 97.393%
	I - Batch: 200 | Loss: 0.496 | Acc: 95.875% | Wgt Acc: 97.332%
I - num batch: 222
I - Train -- Loss: 0.496 | Acc: 95.799% | Wgt Acc: 97.276% | LR: 1.000000e-03 | Dur: 100.28s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   1.   2.   2.  39.]
 [  0. 570.   1.   0.  17.]
 [  0.   1. 725.   0.  33.]
 [  1.   0.   0. 532.  29.]
 [  7.   6.   6.   4. 882.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.071 | Acc: 65.089% | Wgt Acc: 58.385% | Dur: 13.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   1.  14.   6.]
 [  3.  47.  11.   7.   9.]
 [  0.   4.  25.   0.   1.]
 [  5.   1.   3.  35.   1.]
 [ 20.  24.  35.  30. 163.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 95.625% | Wgt Acc: 97.419%
	I - Batch: 100 | Loss: 0.499 | Acc: 95.188% | Wgt Acc: 96.819%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.333% | Wgt Acc: 97.038%
	I - Batch: 200 | Loss: 0.499 | Acc: 95.031% | Wgt Acc: 96.823%
I - num batch: 222
I - Train -- Loss: 0.498 | Acc: 95.151% | Wgt Acc: 96.910% | LR: 1.000000e-03 | Dur: 100.77s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   1.   0.   2.  60.]
 [  0. 571.   1.   0.  23.]
 [  0.   3. 726.   0.  27.]
 [  2.   0.   1. 531.  29.]
 [  9.   3.   6.   5. 861.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.092 | Acc: 64.892% | Wgt Acc: 57.392% | Dur: 14.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 52.   3.   1.   4.   1.]
 [  0.  34.   3.   0.   5.]
 [  0.   5.  22.   0.   1.]
 [ 13.   3.   9.  51.   3.]
 [ 23.  33.  40.  31. 170.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.504 | Acc: 95.125% | Wgt Acc: 96.855%
	I - Batch: 100 | Loss: 0.492 | Acc: 95.688% | Wgt Acc: 97.238%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.417% | Wgt Acc: 97.008%
	I - Batch: 200 | Loss: 0.498 | Acc: 95.344% | Wgt Acc: 96.924%
I - num batch: 222
I - Train -- Loss: 0.498 | Acc: 95.405% | Wgt Acc: 96.963% | LR: 1.000000e-03 | Dur: 106.41s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   2.  38.]
 [  0. 574.   2.   0.  21.]
 [  0.   0. 723.   0.  31.]
 [  3.   0.   0. 529.  36.]
 [ 10.   4.   9.   7. 874.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 67.258% | Wgt Acc: 61.676% | Dur: 15.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   3.   0.   9.   6.]
 [  0.  40.   3.   0.   6.]
 [  0.   8.  28.   0.   6.]
 [  7.   1.   8.  50.   2.]
 [ 18.  26.  36.  27. 160.]]

I - Local maximum validation set accuracy:  67.26

I - Validation set results: 
[14-1-2-0.99][50-3-4-0.99][124-2-4-0.99][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.99][615-0-0-0.99][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.99][1212-3-4-0.99][1368-0-0-0.99][2181-2-3--0.04][2476-2-2-0.99][2721-2-2-0.99][2818-1-1-0.99][2886-2-4-0.97]
[3231-2-2-0.99][3333-2-2-0.84][3482-2-2-0.99][3536-3-4-0.64][3625-1-1-0.73][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.99][4346-1-4-0.77]
[4581-2-4-0.99][4708-3-4-0.99][4838-3-4-0.32][4845-1-4-0.99][4868-0-0-0.99][4939-0-4-0.99][4984-2-3-0.53][5078-1-4-0.99][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.97][5949-3-4-0.85][5987-2-4-0.99][6014-3-3-0.32][6033-3-4-0.95][6313-0-0-0.99][6421-3-3-0.99][6500-1-1-0.99][6583-3-3-0.99]
[6683-3-3-0.97][6825-2-1-0.99][6998-3-4--0.20][7049-3-3-0.99][7517-1-1-0.99][7521-1-1-0.99][7528-1-1-0.99][7949-1-2-0.99][8135-1-4-0.99][8185-3-0-0.99]
[8269-3-4-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-1--0.07][9001-2-4-0.99][9036-2-2-0.99][9281-3-4-0.99][9300-2-2-0.99]
[9571-0-4-0.99][9617-1-4-0.99][9644-2-4-0.71][9705-2-4-0.99][9801-0-3-0.89][9803-3-3-0.99][9865-3-3-0.99][9896-2-4-0.97][10314-1-4-0.99][10337-3-3-0.99]
[10403-0-4-0.99][10653-2-4-0.99][10704-2-4-0.99][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.99][11499-0-0-0.99][11502-3-4-0.99][11512-3-3-0.99][11608-1-4-0.49][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-2-0.41]
[12052-0-0-0.99][12201-0-0-0.44][12235-2-4-0.99][12320-1-4-0.99][12377-2-4-0.99][12398-2-4-0.99][12503-1-4-0.99][12617-0-4-0.57][12685-3-4-0.99][12738-2-4-0.99]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.99][13240-3-4-0.97][13253-1-1-0.87][13273-0-0-0.99][13634-1-4-0.77][13763-2-3-0.99][13905-3-0-0.36][14060-2-4-0.99]
[14065-3-0-0.99][14147-3-3-0.99][14595-2-2-0.99][14687-2-2-0.99][14788-2-2-0.99][14869-1-1-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-3-0.82][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.99][15375-3-3-0.68][15389-3-3-0.99][15568-2-4-0.99][15675-3-3-0.99][15869-1-0-0.19][16207-3-4-0.97][16236-0-0-0.99][16302-3-3-0.99]
[16331-2-2-0.99][16381-0-3-0.84][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.94][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.99][17245-1-4-0.99]
[17278-3-4-0.79][17282-0-0-0.99][17311-2-2-0.99][17336-2-4--0.13][17608-3-3-0.99][17627-0-0-0.99][17877-3-4-0.99][17924-1-4-0.87][17984-3-3-0.99][18211-0-3-0.99]
[18276-3-3-0.99][18287-1-4-0.45][18394-0-0-0.99][18428-0-0-0.99][18442-0-3-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.99][18938-3-4--0.05][19817-1-2-0.72][19839-0-4-0.99][19930-3-3-0.99][19944-0-4-0.99][20036-2-2-0.99]
[20101-3-3-0.31][20474-1-1-0.45][20547-3-4-0.99][20929-2-2-0.60][21245-1-4--0.49][21257-3-3-0.87][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-0-0.99][21943-3-4-0.99][21947-0-4-0.99][21948-0-0-0.99][21965-2-4-0.95][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.99][22985-3-0-0.63][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.99]
[23219-0-0-0.57][23363-3-3-0.99][23470-0-0-0.71][23486-2-4-0.99][23497-0-3-0.92][23516-0-0-0.99][23690-1-2-0.99][23921-2-1-0.99][23936-1-0-0.99][24040-3-4-0.82]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-4-0.99][24345-0-0-0.99][24364-1-2-0.50][24427-3-0-0.99][24477-2-4-0.99][24495-2-4-0.99][24893-2-4-0.92]
[25012-1-4-0.99][25121-2-2-0.99][25165-3-3-0.99][25183-0-4-0.64][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.99][25644-1-2-0.99][25718-1-4-0.99][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.99][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.12][26838-2-4-0.91][26860-1-4-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0--0.36][27526-0-4-0.72][27639-3-3-0.99][27698-3-0-0.45][27772-0-0-0.99][27890-1-1-0.99][28040-0-4-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-1--0.52][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.88][30716-0-4-0.99]
[30806-2-2-0.99][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.58][31238-0-0-0.51][31347-0-0-0.99][31422-2-4-0.99][31429-3-3-0.99][31431-0-0-0.99][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-1--0.10][31597-1-1-0.98][31619-1-4-0.99][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.99][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-4-0.92][32140-3-3-0.99][32263-2-4-0.99][32365-0-0-0.99][32411-2-3-0.99][32429-3-3-0.90][32473-3-3-0.99][32574-3-3-0.99][32584-0-4-0.99][32622-0-4-0.99]
[32858-3-3-0.99][32969-3-3-0.99][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.89][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.99]
[33474-0-4-0.99][33478-2-4-0.98][33618-1-4-0.99][33712-0-4-0.81][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.99][34112-2-2-0.99][34138-2-3-0.98][34239-1-1-0.99]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-0-0.99][34783-2-4-0.91][35015-3-4-0.99][35018-1-1-0.55][35288-2-4-0.96][0-4-4-0.99][1-4-4-0.99][2-4-4-0.99]
[3-4-4-0.99][4-4-4-0.99][5-4-4--0.17][6-4-0-0.99][7-4-0-0.99][8-4-4-0.99][9-4-4-0.99][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-4-0.99][17-4-4-0.99][18-4-4-0.99][19-4-4-0.99][20-4-4-0.99][21-4-4-0.99][22-4-4-0.99][23-4-4-0.99]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.98][27-4-4-0.99][28-4-4-0.99][29-4-4-0.70][30-4-4-0.99][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.94][40-4-4-0.99][41-4-4-0.99][42-4-4-0.82][43-4-4-0.99][45-4-2-0.39][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.99][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-1-0.99][57-4-4-0.99][58-4-2-0.99]
[59-4-4-0.99][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.99][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-4-0.94]
[69-4-4-0.99][70-4-4-0.99][72-4-1-0.99][73-4-1-0.99][74-4-4-0.99][75-4-3-0.99][77-4-4-0.99][78-4-4-0.99][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.99][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.99][87-4-4-0.99][88-4-4-0.99][89-4-4-0.78][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-4-0.99][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-2-0.99][99-4-4-0.99][100-4-4-0.73]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.99][104-4-4-0.99][105-4-4-0.99][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-2-0.71][113-4-4-0.99][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.99][128-4-4-0.99][129-4-4-0.99][130-4-4-0.99][131-4-4-0.99][132-4-4-0.99][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-1-0.99][141-4-4-0.99][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.99]
[157-4-4-0.99][158-4-4-0.99][160-4-4-0.99][161-4-4-0.99][162-4-4-0.99][164-4-4-0.99][165-4-4-0.99][167-4-0-0.99][168-4-4-0.96][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-4-0.99][175-4-4-0.99][177-4-4-0.99][178-4-4-0.99][179-4-4-0.99][180-4-4-0.99][181-4-4-0.79]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.99][186-4-4-0.99][187-4-4-0.99][188-4-4-0.99][189-4-1--0.29][190-4-4-0.99][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.63][194-4-4-0.68][195-4-4-0.99][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-2-0.99]
---------------------------
I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.509 | Acc: 94.500% | Wgt Acc: 96.612%
	I - Batch: 100 | Loss: 0.508 | Acc: 94.312% | Wgt Acc: 96.247%
	I - Batch: 150 | Loss: 0.501 | Acc: 94.917% | Wgt Acc: 96.676%
	I - Batch: 200 | Loss: 0.497 | Acc: 95.219% | Wgt Acc: 96.817%
I - num batch: 222
I - Train -- Loss: 0.498 | Acc: 95.123% | Wgt Acc: 96.747% | LR: 1.000000e-03 | Dur: 110.78s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   2.  38.]
 [  2. 571.   0.   1.  25.]
 [  0.   0. 725.   1.  28.]
 [  1.   2.   0. 524.  42.]
 [  7.   5.   9.  10. 867.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.101 | Acc: 63.905% | Wgt Acc: 56.807% | Dur: 17.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   8.   1.  11.   5.]
 [  0.  30.   1.   0.   2.]
 [  0.   7.  19.   0.   1.]
 [  9.   1.  12.  50.   7.]
 [ 19.  32.  42.  25. 165.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 96.125% | Wgt Acc: 96.991%
	I - Batch: 100 | Loss: 0.484 | Acc: 96.125% | Wgt Acc: 97.430%
	I - Batch: 150 | Loss: 0.487 | Acc: 96.042% | Wgt Acc: 97.336%
	I - Batch: 200 | Loss: 0.489 | Acc: 95.781% | Wgt Acc: 97.171%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 95.686% | Wgt Acc: 97.100% | LR: 1.000000e-03 | Dur: 120.82s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   1.   0.   6.  39.]
 [  1. 572.   0.   0.  25.]
 [  0.   0. 729.   1.  26.]
 [  1.   0.   0. 528.  26.]
 [ 14.   5.   5.   3. 884.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.037 | Acc: 68.639% | Wgt Acc: 63.034% | Dur: 18.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   2.  14.   8.]
 [  0.  45.   9.   4.   6.]
 [  0.   7.  26.   1.   1.]
 [  5.   2.   7.  45.   3.]
 [ 13.  19.  31.  22. 162.]]

I - Local maximum validation set accuracy:  68.64

I - Validation set results: 
[14-1-4-0.84][50-3-0-0.99][124-2-4-0.99][127-0-0-0.99][443-2-2--0.14][567-0-0-0.99][573-1-1-0.99][615-0-0-0.99][695-1-2-0.99][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.99][1212-3-4-0.99][1368-0-0-0.99][2181-2-1--0.96][2476-2-2-0.99][2721-2-4-0.80][2818-1-1-0.99][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-2-0.72][3482-2-4-0.99][3536-3-4-0.99][3625-1-1-0.82][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.99][4346-1-0-0.11]
[4581-2-1-0.98][4708-3-4-0.99][4838-3-3-0.81][4845-1-4-0.99][4868-0-0-0.99][4939-0-4-0.90][4984-2-3--0.10][5078-1-4-0.99][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-4-0.39][5949-3-4-0.92][5987-2-4-0.99][6014-3-3-0.99][6033-3-4-0.99][6313-0-0-0.99][6421-3-3-0.99][6500-1-1-0.99][6583-3-3-0.99]
[6683-3-3-0.44][6825-2-1-0.99][6998-3-4-0.22][7049-3-3-0.99][7517-1-1-0.99][7521-1-1-0.92][7528-1-1-0.87][7949-1-2-0.99][8135-1-0-0.74][8185-3-0-0.99]
[8269-3-1-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-1-0.99][9001-2-4-0.99][9036-2-2-0.99][9281-3-3-0.64][9300-2-2-0.99]
[9571-0-4-0.91][9617-1-4-0.99][9644-2-2-0.99][9705-2-4-0.58][9801-0-3-0.99][9803-3-3-0.99][9865-3-3-0.99][9896-2-4-0.99][10314-1-4-0.99][10337-3-3-0.99]
[10403-0-4-0.99][10653-2-4-0.95][10704-2-2-0.83][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.60][11499-0-0-0.99][11502-3-4-0.82][11512-3-3-0.99][11608-1-1-0.96][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-0-0.88]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-4-0.99][12320-1-4-0.99][12377-2-4-0.99][12398-2-4-0.99][12503-1-4-0.99][12617-0-0-0.99][12685-3-4-0.99][12738-2-4-0.99]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.59][13240-3-0-0.99][13253-1-0-0.98][13273-0-0-0.99][13634-1-1-0.33][13763-2-3-0.99][13905-3-0-0.99][14060-2-4-0.99]
[14065-3-0-0.99][14147-3-3-0.99][14595-2-1-0.20][14687-2-2-0.99][14788-2-2-0.99][14869-1-1-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.98][15375-3-3-0.17][15389-3-3-0.99][15568-2-4-0.60][15675-3-3-0.99][15869-1-0-0.65][16207-3-0-0.00][16236-0-0-0.99][16302-3-2-0.38]
[16331-2-2-0.99][16381-0-3-0.97][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.61][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.99][17245-1-4-0.46]
[17278-3-1-0.66][17282-0-0-0.99][17311-2-2-0.99][17336-2-1-0.99][17608-3-3-0.99][17627-0-4-0.81][17877-3-4-0.99][17924-1-4-0.78][17984-3-3-0.99][18211-0-0-0.94]
[18276-3-3-0.74][18287-1-1-0.99][18394-0-0-0.99][18428-0-0-0.82][18442-0-3-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.99][18938-3-1--0.15][19817-1-1-0.86][19839-0-4-0.97][19930-3-3-0.99][19944-0-0-0.74][20036-2-2-0.99]
[20101-3-4-0.84][20474-1-1-0.57][20547-3-4-0.99][20929-2-2-0.99][21245-1-4-0.76][21257-3-4--0.47][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-0-0.99][21943-3-4-0.99][21947-0-0-0.79][21948-0-0-0.99][21965-2-4-0.70][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.99][22985-3-0-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.58]
[23219-0-0-0.99][23363-3-3--0.00][23470-0-0-0.99][23486-2-4-0.57][23497-0-3-0.99][23516-0-0-0.99][23690-1-2-0.99][23921-2-4-0.98][23936-1-0-0.99][24040-3-4-0.99]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.99][24364-1-2-0.99][24427-3-0-0.99][24477-2-4-0.99][24495-2-4-0.99][24893-2-4-0.99]
[25012-1-1-0.99][25121-2-4-0.85][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.99][25644-1-1-0.74][25718-1-1-0.92][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.99][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.99][26833-0-0-0.99][26838-2-2-0.30][26860-1-4-0.70]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-1-0.83][27526-0-0-0.77][27639-3-3-0.99][27698-3-0-0.99][27772-0-0-0.99][27890-1-1-0.99][28040-0-4-0.55][28503-2-4-0.76]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-1-0.41][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.24][30716-0-4-0.99]
[30806-2-2-0.99][30906-1-1-0.99][31007-0-0-0.99][31181-3-4-0.98][31238-0-0-0.37][31347-0-0-0.99][31422-2-4-0.80][31429-3-1--0.05][31431-0-0-0.85][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-1-0.31][31597-1-1-0.99][31619-1-4-0.99][31701-0-4-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-3-0.88][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-2-0.18][32140-3-3-0.99][32263-2-4-0.99][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.99][32473-3-3-0.99][32574-3-3-0.99][32584-0-4-0.99][32622-0-4-0.99]
[32858-3-3-0.86][32969-3-3-0.90][33016-2-2-0.99][33031-1-3-0.99][33035-2-4-0.99][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.99]
[33474-0-0-0.99][33478-2-4-0.86][33618-1-4-0.99][33712-0-0-0.99][33782-2-4-0.99][33914-3-3-0.81][34076-3-4-0.99][34112-2-2-0.99][34138-2-3-0.99][34239-1-1-0.87]
[34364-2-2-0.99][34617-1-4-0.18][34751-3-0-0.99][34783-2-1-0.99][35015-3-4-0.99][35018-1-4-0.79][35288-2-1-0.39][0-4-4-0.99][1-4-4-0.99][2-4-4-0.99]
[3-4-4-0.99][4-4-4-0.99][5-4-2-0.14][6-4-4-0.99][7-4-4-0.99][8-4-4-0.99][9-4-4--0.04][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-0-0.53][16-4-4-0.99][17-4-4-0.99][18-4-4-0.99][19-4-4-0.99][20-4-4-0.99][21-4-4-0.57][22-4-4-0.99][23-4-4-0.99]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.99][27-4-4-0.99][28-4-4-0.99][29-4-4-0.86][30-4-4-0.99][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.43][40-4-4-0.99][41-4-4-0.99][42-4-4-0.99][43-4-4-0.99][45-4-4-0.13][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.96][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-1-0.99][57-4-3-0.99][58-4-4-0.67]
[59-4-4-0.99][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.99][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-4-0.88]
[69-4-4--0.09][70-4-4-0.99][72-4-1-0.99][73-4-4-0.95][74-4-4-0.99][75-4-3-0.96][77-4-4-0.99][78-4-4-0.99][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.99][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.99][87-4-4-0.99][88-4-4-0.99][89-4-4-0.99][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-4-0.95][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-4-0.89][99-4-4-0.99][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.99][103-4-0-0.99][104-4-4-0.99][105-4-4-0.99][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.99][113-4-4-0.99][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-1--0.12][128-4-4-0.99][129-4-4-0.73][130-4-4-0.99][131-4-4-0.99][132-4-0-0.55][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-4-0.70][141-4-4-0.99][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-0-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.99]
[157-4-4-0.99][158-4-4-0.99][160-4-4-0.59][161-4-1-0.88][162-4-4-0.99][164-4-4-0.99][165-4-4-0.99][167-4-0-0.99][168-4-4-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-4-0.99][175-4-4-0.99][177-4-4-0.99][178-4-4-0.85][179-4-4-0.99][180-4-4-0.99][181-4-4-0.99]
[182-4-3-0.99][183-4-4-0.99][184-4-4-0.99][186-4-4-0.99][187-4-4-0.99][188-4-4-0.99][189-4-1-0.74][190-4-4-0.99][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.99][194-4-4--0.15][195-4-0-0.94][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-4-0.03]
---------------------------
I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.495 | Acc: 96.500% | Wgt Acc: 97.633%
	I - Batch: 100 | Loss: 0.490 | Acc: 96.438% | Wgt Acc: 97.460%
	I - Batch: 150 | Loss: 0.486 | Acc: 96.417% | Wgt Acc: 97.500%
	I - Batch: 200 | Loss: 0.489 | Acc: 96.188% | Wgt Acc: 97.322%
I - num batch: 222
I - Train -- Loss: 0.489 | Acc: 96.307% | Wgt Acc: 97.399% | LR: 1.000000e-03 | Dur: 111.48s
I - Confusion Matrix: [row->prediction - col->label]
[[683.   0.   0.   2.  31.]
 [  1. 575.   0.   0.  19.]
 [  0.   1. 723.   0.  19.]
 [  3.   0.   0. 528.  24.]
 [ 10.   2.  11.   8. 907.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 68.639% | Wgt Acc: 63.463% | Dur: 18.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   2.   9.   5.]
 [  0.  46.   7.   1.   7.]
 [  0.   5.  30.   0.   2.]
 [ 12.   1.   9.  52.   6.]
 [ 16.  22.  27.  24. 160.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 95.875% | Wgt Acc: 97.275%
	I - Batch: 100 | Loss: 0.502 | Acc: 94.500% | Wgt Acc: 96.364%
	I - Batch: 150 | Loss: 0.505 | Acc: 94.208% | Wgt Acc: 96.139%
	I - Batch: 200 | Loss: 0.502 | Acc: 94.500% | Wgt Acc: 96.297%
I - num batch: 222
I - Train -- Loss: 0.502 | Acc: 94.390% | Wgt Acc: 96.214% | LR: 1.000000e-03 | Dur: 110.84s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   1.   0.   1.  44.]
 [  0. 572.   1.   0.  26.]
 [  0.   0. 720.   2.  47.]
 [  1.   0.   0. 525.  33.]
 [ 15.   5.  13.  10. 850.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.045 | Acc: 66.469% | Wgt Acc: 59.461% | Dur: 15.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   2.   7.   4.]
 [  0.  31.   2.   0.   1.]
 [  0.   7.  20.   0.   1.]
 [ 10.   5.  12.  53.   5.]
 [ 14.  30.  39.  26. 169.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.486 | Acc: 96.125% | Wgt Acc: 97.569%
	I - Batch: 100 | Loss: 0.486 | Acc: 96.312% | Wgt Acc: 97.526%
	I - Batch: 150 | Loss: 0.485 | Acc: 96.083% | Wgt Acc: 97.409%
	I - Batch: 200 | Loss: 0.483 | Acc: 96.250% | Wgt Acc: 97.531%
I - num batch: 222
I - Train -- Loss: 0.483 | Acc: 96.250% | Wgt Acc: 97.446% | LR: 5.000000e-04 | Dur: 110.44s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   1.   1.  28.]
 [  0. 574.   1.   0.  20.]
 [  0.   0. 725.   0.  28.]
 [  4.   0.   0. 529.  23.]
 [  8.   4.   7.   8. 901.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 68.639% | Wgt Acc: 63.337% | Dur: 17.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   0.   8.   6.]
 [  0.  39.   4.   1.   3.]
 [  1.  12.  33.   0.   4.]
 [ 12.   2.  10.  56.   6.]
 [ 16.  22.  28.  21. 161.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 96.625% | Wgt Acc: 97.940%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.125% | Wgt Acc: 98.190%
	I - Batch: 150 | Loss: 0.478 | Acc: 96.625% | Wgt Acc: 97.790%
	I - Batch: 200 | Loss: 0.478 | Acc: 96.781% | Wgt Acc: 97.932%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 96.786% | Wgt Acc: 97.948% | LR: 5.000000e-04 | Dur: 112.90s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  35.]
 [  0. 573.   0.   0.  15.]
 [  0.   0. 731.   0.  18.]
 [  0.   1.   0. 533.  24.]
 [  9.   4.   3.   5. 908.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.042 | Acc: 66.667% | Wgt Acc: 60.673% | Dur: 15.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   3.   2.  11.   5.]
 [  0.  37.   4.   0.   4.]
 [  0.  11.  31.   0.   5.]
 [ 14.   2.   8.  51.   4.]
 [ 17.  25.  30.  24. 162.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.497 | Acc: 95.250% | Wgt Acc: 97.076%
	I - Batch: 100 | Loss: 0.491 | Acc: 95.500% | Wgt Acc: 97.084%
	I - Batch: 150 | Loss: 0.493 | Acc: 95.208% | Wgt Acc: 96.981%
	I - Batch: 200 | Loss: 0.489 | Acc: 95.656% | Wgt Acc: 97.241%
I - num batch: 222
I - Train -- Loss: 0.489 | Acc: 95.658% | Wgt Acc: 97.204% | LR: 5.000000e-04 | Dur: 110.43s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   0.  32.]
 [  0. 573.   0.   1.  21.]
 [  0.   0. 729.   0.  39.]
 [  1.   1.   0. 530.  31.]
 [ 12.   4.   5.   7. 877.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 69.231% | Wgt Acc: 63.139% | Dur: 15.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   5.   2.  11.   4.]
 [  0.  40.   3.   0.   7.]
 [  0.   9.  32.   0.   2.]
 [  3.   1.   5.  44.   1.]
 [ 16.  23.  33.  31. 166.]]

I - Local maximum validation set accuracy:  69.23

I - Validation set results: 
[14-1-2-0.79][50-3-4-0.99][124-2-4-0.99][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.96][615-0-0-0.99][695-1-2-0.99][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.99][1212-3-4-0.99][1368-0-0-0.99][2181-2-4-0.26][2476-2-2-0.99][2721-2-2-0.99][2818-1-1-0.99][2886-2-4-0.96]
[3231-2-2-0.99][3333-2-2-0.55][3482-2-2-0.99][3536-3-4-0.99][3625-1-1-0.87][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.99][4346-1-4-0.96]
[4581-2-4-0.87][4708-3-4-0.99][4838-3-4-0.98][4845-1-4-0.99][4868-0-0-0.99][4939-0-4-0.99][4984-2-4-0.98][5078-1-0-0.93][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-4-0.91][5949-3-4-0.99][5987-2-4-0.99][6014-3-3-0.99][6033-3-4-0.99][6313-0-0-0.99][6421-3-3-0.99][6500-1-1-0.84][6583-3-3-0.99]
[6683-3-3-0.59][6825-2-1-0.99][6998-3-4-0.29][7049-3-3-0.99][7517-1-1-0.99][7521-1-4-0.99][7528-1-1-0.93][7949-1-2-0.99][8135-1-1-0.28][8185-3-0-0.99]
[8269-3-4-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.99][9001-2-4-0.96][9036-2-2-0.99][9281-3-4-0.56][9300-2-2-0.99]
[9571-0-4-0.99][9617-1-1-0.99][9644-2-2-0.99][9705-2-4-0.99][9801-0-4-0.99][9803-3-3-0.99][9865-3-3-0.90][9896-2-4-0.96][10314-1-4-0.99][10337-3-3-0.99]
[10403-0-4-0.99][10653-2-4-0.99][10704-2-2-0.93][10719-1-1-0.99][10727-1-4-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0-0.99][11502-3-4-0.99][11512-3-3-0.99][11608-1-1-0.09][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-0-0.99]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-4-0.99][12320-1-4-0.99][12377-2-4-0.99][12398-2-4-0.99][12503-1-4-0.99][12617-0-0-0.81][12685-3-4-0.99][12738-2-4-0.99]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-4-0.98][13240-3-4-0.51][13253-1-0-0.84][13273-0-0-0.99][13634-1-4-0.65][13763-2-2-0.99][13905-3-3-0.40][14060-2-4-0.99]
[14065-3-0-0.98][14147-3-3-0.99][14595-2-4-0.99][14687-2-2-0.99][14788-2-2-0.99][14869-1-1-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-0-0.84][15066-0-0-0.99]
[15175-1-1-0.99][15178-2-3-0.99][15375-3-0-0.99][15389-3-3-0.96][15568-2-4-0.99][15675-3-3-0.99][15869-1-0-0.50][16207-3-0-0.99][16236-0-0-0.99][16302-3-3-0.99]
[16331-2-2-0.99][16381-0-3-0.82][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.99][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.98][17245-1-4-0.99]
[17278-3-0-0.29][17282-0-0-0.99][17311-2-2-0.99][17336-2-1-0.99][17608-3-3-0.99][17627-0-0-0.99][17877-3-4-0.99][17924-1-2-0.94][17984-3-3-0.99][18211-0-3-0.93]
[18276-3-3-0.98][18287-1-1-0.99][18394-0-0-0.99][18428-0-0-0.99][18442-0-0-0.53][18478-3-4-0.57][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.99][18938-3-4-0.95][19817-1-2-0.69][19839-0-4-0.87][19930-3-3-0.99][19944-0-0-0.99][20036-2-2-0.99]
[20101-3-4-0.86][20474-1-2-0.78][20547-3-4-0.99][20929-2-2-0.91][21245-1-4-0.90][21257-3-4-0.87][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-4-0.89][21714-0-4-0.99][21943-3-4-0.99][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.95][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.39][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.99][22985-3-3-0.98][23014-0-0-0.76][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.99]
[23219-0-0-0.98][23363-3-3-0.99][23470-0-0-0.73][23486-2-4-0.99][23497-0-3-0.99][23516-0-0-0.99][23690-1-4-0.99][23921-2-4-0.99][23936-1-0-0.99][24040-3-4-0.99]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.99][24364-1-1-0.77][24427-3-4-0.99][24477-2-4-0.99][24495-2-4-0.99][24893-2-4-0.99]
[25012-1-1-0.99][25121-2-2-0.99][25165-3-3-0.99][25183-0-4-0.71][25297-3-3-0.99][25398-0-0-0.99][25574-2-2-0.99][25644-1-2-0.99][25718-1-4-0.90][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.95][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.99][26833-0-0-0.95][26838-2-4-0.99][26860-1-4-0.98]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.99][27526-0-0-0.99][27639-3-3-0.99][27698-3-0-0.76][27772-0-0-0.99][27890-1-1-0.99][28040-0-4-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-1-0.81][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.63][30716-0-4-0.99]
[30806-2-2-0.89][30906-1-1-0.99][31007-0-0-0.99][31181-3-4-0.99][31238-0-0-0.95][31347-0-0-0.99][31422-2-4-0.99][31429-3-3-0.99][31431-0-0-0.73][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-4-0.29][31597-1-1-0.99][31619-1-4-0.99][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.99][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-2-0.59][32140-3-3-0.99][32263-2-4-0.99][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.78][32473-3-3-0.99][32574-3-3-0.99][32584-0-4-0.99][32622-0-4-0.99]
[32858-3-4-0.98][32969-3-0-0.99][33016-2-2-0.99][33031-1-3-0.99][33035-2-2-0.77][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.99]
[33474-0-4-0.87][33478-2-4-0.99][33618-1-4-0.99][33712-0-4-0.99][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.99][34112-2-2-0.99][34138-2-3-0.84][34239-1-1-0.99]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-3-0.84][34783-2-4-0.99][35015-3-4-0.99][35018-1-4-0.89][35288-2-4-0.94][0-4-4-0.99][1-4-4-0.99][2-4-4-0.99]
[3-4-4-0.99][4-4-4-0.99][5-4-1-0.60][6-4-4-0.99][7-4-4-0.99][8-4-4-0.99][9-4-4-0.99][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-4-0.99][17-4-4-0.99][18-4-4-0.99][19-4-4-0.99][20-4-4-0.99][21-4-2-0.99][22-4-4-0.99][23-4-4-0.99]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.99][27-4-4-0.99][28-4-4-0.99][29-4-4-0.99][30-4-4-0.99][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.99][40-4-4-0.99][41-4-4-0.99][42-4-4-0.99][43-4-4-0.99][45-4-4-0.99][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.67][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-1-0.89][57-4-4-0.99][58-4-4-0.99]
[59-4-4-0.79][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.99][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-4-0.67]
[69-4-4-0.99][70-4-4-0.99][72-4-1-0.67][73-4-1-0.99][74-4-4-0.99][75-4-4-0.89][77-4-4-0.99][78-4-4-0.99][79-4-4-0.99][80-4-4-0.99]
[81-4-4-0.99][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.99][87-4-4-0.99][88-4-4-0.99][89-4-0-0.97][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-4-0.42][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-4-0.99][99-4-4-0.99][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.99][104-4-4-0.99][105-4-4-0.98][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.99][113-4-4-0.99][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.99][128-4-4-0.46][129-4-1-0.92][130-4-4-0.99][131-4-4-0.99][132-4-4-0.70][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.99][138-4-4-0.99][139-4-4-0.99][140-4-1-0.99][141-4-4-0.99][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-4-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.99]
[157-4-4--0.03][158-4-4-0.99][160-4-4-0.99][161-4-4-0.99][162-4-4-0.99][164-4-4-0.99][165-4-4-0.99][167-4-4-0.99][168-4-4-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.99][175-4-4-0.99][177-4-4-0.99][178-4-4-0.99][179-4-4-0.99][180-4-4-0.99][181-4-4-0.99]
[182-4-4-0.99][183-4-4-0.99][184-4-4-0.99][186-4-4-0.99][187-4-4-0.99][188-4-4-0.99][189-4-4-0.53][190-4-4-0.69][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.96][194-4-4-0.99][195-4-4-0.99][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-4-0.99]
---------------------------
I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.250% | Wgt Acc: 97.461%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.125% | Wgt Acc: 97.360%
	I - Batch: 150 | Loss: 0.481 | Acc: 96.167% | Wgt Acc: 97.406%
	I - Batch: 200 | Loss: 0.483 | Acc: 95.969% | Wgt Acc: 97.315%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 95.856% | Wgt Acc: 97.271% | LR: 5.000000e-04 | Dur: 112.38s
I - Confusion Matrix: [row->prediction - col->label]
[[681.   0.   0.   0.  41.]
 [  0. 576.   0.   0.  15.]
 [  0.   0. 727.   0.  28.]
 [  1.   0.   0. 530.  30.]
 [ 15.   2.   7.   8. 886.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.063 | Acc: 64.103% | Wgt Acc: 56.859% | Dur: 16.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 50.   4.   1.   5.   3.]
 [  0.  34.   3.   0.   3.]
 [  0.   9.  22.   0.   2.]
 [ 13.   1.   7.  52.   5.]
 [ 25.  30.  42.  29. 167.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.485 | Acc: 96.500% | Wgt Acc: 97.635%
	I - Batch: 100 | Loss: 0.493 | Acc: 95.562% | Wgt Acc: 97.070%
	I - Batch: 150 | Loss: 0.495 | Acc: 95.500% | Wgt Acc: 96.979%
	I - Batch: 200 | Loss: 0.491 | Acc: 95.781% | Wgt Acc: 97.163%
I - num batch: 222
I - Train -- Loss: 0.491 | Acc: 95.743% | Wgt Acc: 97.141% | LR: 5.000000e-04 | Dur: 105.02s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   0.   0.   1.  35.]
 [  1. 573.   1.   0.  33.]
 [  0.   1. 726.   0.  27.]
 [  0.   0.   0. 532.  19.]
 [ 17.   4.   7.   5. 886.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 65.878% | Wgt Acc: 59.032% | Dur: 14.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   1.  14.   6.]
 [  0.  36.   2.   0.   5.]
 [  0.   5.  19.   0.   2.]
 [  4.   2.   5.  45.   1.]
 [ 16.  30.  48.  27. 166.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 96.625% | Wgt Acc: 98.033%
	I - Batch: 100 | Loss: 0.477 | Acc: 96.688% | Wgt Acc: 97.958%
	I - Batch: 150 | Loss: 0.477 | Acc: 96.750% | Wgt Acc: 98.004%
	I - Batch: 200 | Loss: 0.478 | Acc: 96.750% | Wgt Acc: 97.946%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 96.786% | Wgt Acc: 97.961% | LR: 5.000000e-04 | Dur: 101.37s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   1.  33.]
 [  0. 577.   0.   1.  11.]
 [  0.   0. 732.   0.  25.]
 [  1.   0.   1. 529.  24.]
 [  8.   1.   1.   7. 907.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.034 | Acc: 67.456% | Wgt Acc: 61.237% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   3.   2.  11.   6.]
 [  0.  40.   4.   1.   2.]
 [  0.  11.  26.   0.   3.]
 [ 11.   2.   8.  50.   4.]
 [ 16.  22.  35.  24. 165.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.466%
	I - Batch: 100 | Loss: 0.481 | Acc: 96.250% | Wgt Acc: 97.433%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.292% | Wgt Acc: 97.590%
	I - Batch: 200 | Loss: 0.482 | Acc: 96.250% | Wgt Acc: 97.483%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 96.307% | Wgt Acc: 97.535% | LR: 5.000000e-04 | Dur: 110.59s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   1.   0.   1.  40.]
 [  0. 574.   0.   0.  14.]
 [  0.   1. 727.   0.  28.]
 [  1.   0.   0. 531.  18.]
 [ 12.   2.   7.   6. 900.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.030 | Acc: 68.047% | Wgt Acc: 62.460% | Dur: 15.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  14.   7.]
 [  0.  40.   3.   1.   3.]
 [  1.   8.  30.   0.   7.]
 [  7.   1.   7.  48.   2.]
 [ 14.  27.  34.  23. 161.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.496 | Acc: 94.875% | Wgt Acc: 96.958%
	I - Batch: 100 | Loss: 0.490 | Acc: 95.500% | Wgt Acc: 97.178%
	I - Batch: 150 | Loss: 0.487 | Acc: 95.750% | Wgt Acc: 97.304%
	I - Batch: 200 | Loss: 0.484 | Acc: 95.938% | Wgt Acc: 97.449%
I - num batch: 222
I - Train -- Loss: 0.484 | Acc: 95.912% | Wgt Acc: 97.429% | LR: 5.000000e-04 | Dur: 102.94s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   1.  36.]
 [  0. 574.   0.   0.  23.]
 [  0.   0. 729.   0.  34.]
 [  1.   0.   0. 531.  26.]
 [  9.   4.   5.   6. 881.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 68.245% | Wgt Acc: 62.689% | Dur: 13.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   2.   2.   9.   5.]
 [  0.  44.   2.   1.   6.]
 [  0.  10.  32.   1.   4.]
 [ 14.   1.   9.  52.   3.]
 [ 18.  21.  30.  23. 162.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.482 | Acc: 96.500% | Wgt Acc: 97.628%
	I - Batch: 100 | Loss: 0.482 | Acc: 96.125% | Wgt Acc: 97.535%
	I - Batch: 150 | Loss: 0.482 | Acc: 96.292% | Wgt Acc: 97.564%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.594% | Wgt Acc: 97.771%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.589% | Wgt Acc: 97.759% | LR: 5.000000e-04 | Dur: 103.62s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  39.]
 [  0. 574.   0.   0.  12.]
 [  0.   0. 726.   0.  20.]
 [  0.   0.   0. 527.  24.]
 [  3.   4.   8.  11. 905.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.069 | Acc: 65.680% | Wgt Acc: 59.001% | Dur: 16.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   1.  12.   5.]
 [  0.  33.   3.   0.   5.]
 [  0.   8.  25.   0.   2.]
 [ 12.   1.   8.  50.   3.]
 [ 16.  35.  38.  24. 165.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 94.500% | Wgt Acc: 96.462%
	I - Batch: 100 | Loss: 0.490 | Acc: 95.250% | Wgt Acc: 96.770%
	I - Batch: 150 | Loss: 0.487 | Acc: 95.583% | Wgt Acc: 97.040%
	I - Batch: 200 | Loss: 0.483 | Acc: 95.906% | Wgt Acc: 97.273%
I - num batch: 222
I - Train -- Loss: 0.482 | Acc: 95.968% | Wgt Acc: 97.332% | LR: 5.000000e-04 | Dur: 103.20s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   1.  42.]
 [  0. 571.   2.   0.  21.]
 [  0.   2. 722.   0.  26.]
 [  0.   0.   1. 534.  21.]
 [ 10.   5.   9.   3. 890.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.068 | Acc: 65.089% | Wgt Acc: 58.113% | Dur: 14.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   2.   1.  14.   3.]
 [  0.  34.   3.   1.   6.]
 [  0.   6.  21.   0.   1.]
 [ 10.   5.   7.  48.   4.]
 [ 17.  31.  43.  23. 166.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 96.875% | Wgt Acc: 97.834%
	I - Batch: 100 | Loss: 0.479 | Acc: 96.625% | Wgt Acc: 97.891%
	I - Batch: 150 | Loss: 0.475 | Acc: 96.917% | Wgt Acc: 98.112%
	I - Batch: 200 | Loss: 0.477 | Acc: 96.719% | Wgt Acc: 97.855%
I - num batch: 222
I - Train -- Loss: 0.478 | Acc: 96.589% | Wgt Acc: 97.755% | LR: 2.500000e-04 | Dur: 104.87s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   0.   0.   1.  35.]
 [  0. 576.   1.   0.  14.]
 [  1.   0. 729.   0.  25.]
 [  0.   0.   0. 531.  20.]
 [ 12.   2.   4.   6. 906.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.034 | Acc: 66.864% | Wgt Acc: 60.318% | Dur: 16.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   1.   3.  11.   4.]
 [  0.  32.   4.   1.   2.]
 [  0.  12.  30.   0.   5.]
 [  9.   1.   8.  51.   3.]
 [ 19.  32.  30.  23. 166.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 96.125% | Wgt Acc: 97.613%
	I - Batch: 100 | Loss: 0.476 | Acc: 96.375% | Wgt Acc: 97.750%
	I - Batch: 150 | Loss: 0.479 | Acc: 96.208% | Wgt Acc: 97.692%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.312% | Wgt Acc: 97.745%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.307% | Wgt Acc: 97.730% | LR: 2.500000e-04 | Dur: 102.56s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  44.]
 [  0. 573.   0.   0.  23.]
 [  0.   1. 729.   0.  22.]
 [  1.   0.   0. 535.  21.]
 [  7.   4.   5.   3. 890.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.004 | Acc: 68.047% | Wgt Acc: 62.877% | Dur: 14.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   1.  15.   5.]
 [  0.  39.   3.   0.   6.]
 [  1.   8.  34.   1.   4.]
 [  9.   4.   9.  49.   7.]
 [ 13.  23.  28.  21. 158.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.750% | Wgt Acc: 97.911%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.438% | Wgt Acc: 98.320%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.248%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.219% | Wgt Acc: 98.152%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.181% | Wgt Acc: 98.136% | LR: 2.500000e-04 | Dur: 101.36s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   0.  21.]
 [  0. 574.   0.   0.  19.]
 [  0.   0. 730.   0.  14.]
 [  0.   0.   0. 535.  23.]
 [ 12.   4.   4.   3. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 66.272% | Wgt Acc: 59.628% | Dur: 14.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   2.   9.   8.]
 [  0.  35.   3.   0.   1.]
 [  0.   5.  20.   0.   0.]
 [ 10.   3.   6.  51.   5.]
 [ 14.  33.  44.  26. 166.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 98.441%
	I - Batch: 100 | Loss: 0.478 | Acc: 97.000% | Wgt Acc: 98.061%
	I - Batch: 150 | Loss: 0.480 | Acc: 96.750% | Wgt Acc: 97.860%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.719% | Wgt Acc: 97.799%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.701% | Wgt Acc: 97.772% | LR: 2.500000e-04 | Dur: 103.92s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   1.   1.  33.]
 [  0. 574.   0.   0.  14.]
 [  0.   0. 725.   0.  21.]
 [  1.   0.   0. 531.  20.]
 [  8.   4.   8.   6. 912.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.456% | Wgt Acc: 62.449% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   4.   3.  19.  12.]
 [  0.  39.   3.   1.   6.]
 [  0.   7.  27.   0.   2.]
 [  6.   2.  10.  50.   4.]
 [ 12.  26.  32.  16. 156.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.000% | Wgt Acc: 97.939%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.125% | Wgt Acc: 98.140%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.000% | Wgt Acc: 98.096%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.031% | Wgt Acc: 98.064%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.068% | Wgt Acc: 98.085% | LR: 2.500000e-04 | Dur: 106.65s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   2.  31.]
 [  0. 575.   0.   0.   8.]
 [  0.   0. 729.   0.  20.]
 [  1.   0.   0. 530.  23.]
 [  5.   3.   5.   6. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.007 | Acc: 69.428% | Wgt Acc: 64.246% | Dur: 15.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   0.  11.   4.]
 [  0.  42.   3.   0.   6.]
 [  0.   6.  30.   1.   4.]
 [  7.   2.   7.  52.   5.]
 [ 14.  24.  35.  22. 161.]]

I - Local maximum validation set accuracy:  69.43

I - Validation set results: 
[14-1-2--0.02][50-3-4-0.99][124-2-4-0.97][127-0-0-0.99][443-2-2-0.72][567-0-0-0.99][573-1-1-0.99][615-0-0-0.81][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-4-0.99][1212-3-4-0.93][1368-0-0-0.99][2181-2-4--0.12][2476-2-2-0.99][2721-2-4-0.99][2818-1-1-0.99][2886-2-1-0.85]
[3231-2-2-0.99][3333-2-2-0.50][3482-2-2-0.49][3536-3-4-0.99][3625-1-1-0.78][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.99][4214-1-4-0.99][4346-1-4-0.66]
[4581-2-4-0.99][4708-3-4-0.99][4838-3-3-0.99][4845-1-4-0.99][4868-0-0-0.99][4939-0-4-0.99][4984-2-3-0.74][5078-1-0-0.99][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.99][5949-3-3-0.54][5987-2-4-0.99][6014-3-3-0.99][6033-3-4-0.99][6313-0-0-0.99][6421-3-3-0.99][6500-1-1-0.66][6583-3-3-0.99]
[6683-3-3-0.99][6825-2-1-0.99][6998-3-3-0.34][7049-3-3-0.99][7517-1-1-0.99][7521-1-4-0.99][7528-1-1-0.78][7949-1-2-0.99][8135-1-4-0.96][8185-3-0-0.99]
[8269-3-2-0.68][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.26][8903-1-2-0.99][9001-2-4-0.70][9036-2-2-0.99][9281-3-4-0.01][9300-2-2-0.99]
[9571-0-4-0.64][9617-1-4-0.99][9644-2-2-0.99][9705-2-4-0.94][9801-0-3-0.59][9803-3-3-0.89][9865-3-3-0.99][9896-2-4-0.99][10314-1-4-0.99][10337-3-3-0.99]
[10403-0-4-0.99][10653-2-4-0.99][10704-2-4-0.99][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.99][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-4-0.99][11499-0-0-0.99][11502-3-4-0.60][11512-3-3-0.99][11608-1-4--0.05][11610-0-0-0.99][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-2-0.23]
[12052-0-0-0.99][12201-0-0-0.88][12235-2-2-0.99][12320-1-4-0.99][12377-2-4-0.99][12398-2-4-0.94][12503-1-4-0.99][12617-0-0-0.93][12685-3-4-0.99][12738-2-4-0.99]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.99][13240-3-3-0.93][13253-1-1-0.35][13273-0-0-0.99][13634-1-1-0.27][13763-2-3-0.99][13905-3-3-0.34][14060-2-4-0.99]
[14065-3-0-0.96][14147-3-3-0.99][14595-2-4-0.90][14687-2-2-0.99][14788-2-2-0.99][14869-1-1-0.99][14872-3-4-0.99][14877-1-1-0.99][14927-0-3-0.89][15066-0-0-0.99]
[15175-1-4-0.99][15178-2-3-0.75][15375-3-0-0.99][15389-3-3-0.99][15568-2-4-0.99][15675-3-3-0.99][15869-1-0-0.99][16207-3-0-0.99][16236-0-0-0.99][16302-3-3-0.65]
[16331-2-2-0.99][16381-0-3-0.99][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-4-0.99][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.99][17245-1-4-0.99]
[17278-3-4-0.34][17282-0-0-0.99][17311-2-2-0.99][17336-2-1--0.27][17608-3-3-0.99][17627-0-4-0.99][17877-3-4-0.99][17924-1-4-0.99][17984-3-3-0.99][18211-0-3-0.77]
[18276-3-3-0.99][18287-1-1-0.99][18394-0-0-0.99][18428-0-0-0.52][18442-0-3-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.99][18824-2-4-0.99][18890-3-3-0.99][18930-3-4-0.99][18938-3-4-0.97][19817-1-1-0.99][19839-0-4-0.99][19930-3-3-0.99][19944-0-4-0.99][20036-2-2-0.99]
[20101-3-3-0.99][20474-1-2-0.85][20547-3-4-0.99][20929-2-2-0.99][21245-1-4-0.88][21257-3-3--0.31][21293-1-1-0.99][21316-1-1-0.99][21384-1-1-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.63][21714-0-0-0.99][21943-3-4-0.99][21947-0-0-0.99][21948-0-0-0.99][21965-2-4-0.68][21998-1-1-0.99][22025-0-4-0.99][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-3-0.70][22757-0-0-0.99][22811-3-3-0.99][22976-3-4-0.53][22985-3-0-0.80][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-4-0.95]
[23219-0-0-0.89][23363-3-3-0.99][23470-0-0-0.99][23486-2-4-0.99][23497-0-3-0.98][23516-0-0-0.99][23690-1-3-0.95][23921-2-4-0.99][23936-1-0-0.99][24040-3-4-0.51]
[24111-1-4-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-4-0.99][24345-0-0-0.99][24364-1-1-0.75][24427-3-0-0.99][24477-2-4-0.99][24495-2-4-0.99][24893-2-4-0.87]
[25012-1-4-0.98][25121-2-2-0.99][25165-3-3-0.99][25183-0-4-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-4-0.99][25644-1-1-0.76][25718-1-4-0.99][25774-2-4-0.99]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-4-0.99][26321-1-1-0.99][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-4-0.83][26860-1-4-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0-0.99][27526-0-0-0.95][27639-3-3-0.99][27698-3-0-0.99][27772-0-0-0.99][27890-1-1-0.99][28040-0-4-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-4-0.99][29777-0-0-0.99][29877-2-3-0.81][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.08][30716-0-4-0.99]
[30806-2-2-0.93][30906-1-1-0.99][31007-0-0-0.99][31181-3-4-0.99][31238-0-0-0.99][31347-0-0-0.99][31422-2-4-0.99][31429-3-3-0.99][31431-0-0-0.99][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-4-0.73][31597-1-1-0.86][31619-1-4-0.99][31701-0-0-0.99][31755-0-0-0.99][31854-3-3-0.99][32074-1-1-0.99][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-4-0.76][32140-3-3-0.99][32263-2-4-0.99][32365-0-0-0.99][32411-2-3-0.99][32429-3-0-0.99][32473-3-3-0.99][32574-3-3-0.99][32584-0-4-0.99][32622-0-4-0.99]
[32858-3-3-0.78][32969-3-3-0.99][33016-2-2-0.99][33031-1-3-0.99][33035-2-2-0.70][33133-2-2-0.99][33173-2-2-0.99][33175-3-4-0.99][33306-3-3-0.99][33309-2-3-0.99]
[33474-0-0-0.99][33478-2-2-0.21][33618-1-4-0.99][33712-0-0-0.87][33782-2-4-0.99][33914-3-3-0.99][34076-3-4-0.99][34112-2-2-0.99][34138-2-4-0.30][34239-1-1-0.83]
[34364-2-2-0.99][34617-1-4-0.99][34751-3-0-0.99][34783-2-4-0.99][35015-3-4-0.99][35018-1-1-0.64][35288-2-4-0.42][0-4-4-0.99][1-4-4-0.99][2-4-4-0.99]
[3-4-4-0.99][4-4-4-0.91][5-4-1-0.58][6-4-4-0.99][7-4-4-0.98][8-4-4-0.99][9-4-4-0.99][10-4-4-0.99][11-4-4-0.99][12-4-4-0.99]
[14-4-4-0.99][15-4-3-0.99][16-4-4-0.99][17-4-4-0.99][18-4-4-0.99][19-4-4-0.99][20-4-4-0.99][21-4-4-0.99][22-4-4-0.99][23-4-4-0.99]
[24-4-4-0.99][25-4-4-0.99][26-4-4-0.99][27-4-4-0.99][28-4-4-0.99][29-4-1-0.62][30-4-4-0.99][31-4-4-0.99][32-4-4-0.99][33-4-4-0.99]
[34-4-4-0.99][35-4-4-0.99][37-4-4-0.99][39-4-0-0.99][40-4-4-0.99][41-4-4-0.99][42-4-4-0.99][43-4-4-0.95][45-4-2-0.77][46-4-4-0.99]
[47-4-4-0.99][48-4-4-0.61][51-4-4-0.99][52-4-4-0.99][53-4-4-0.99][54-4-4-0.99][55-4-4-0.99][56-4-4-0.99][57-4-4-0.99][58-4-4-0.77]
[59-4-0-0.95][60-4-4-0.99][61-4-4-0.99][62-4-4-0.99][63-4-4-0.99][64-4-4-0.99][65-4-4-0.99][66-4-4-0.99][67-4-4-0.99][68-4-4-0.83]
[69-4-4-0.99][70-4-4-0.99][72-4-1-0.96][73-4-1-0.99][74-4-4-0.99][75-4-3-0.97][77-4-4-0.99][78-4-4-0.99][79-4-4-0.99][80-4-4-0.99]
[81-4-1-0.29][82-4-4-0.99][83-4-4-0.99][84-4-4-0.99][85-4-4-0.99][86-4-4-0.99][87-4-4-0.99][88-4-4-0.99][89-4-4-0.75][90-4-4-0.99]
[91-4-4-0.99][92-4-4-0.99][93-4-3-0.89][94-4-4-0.99][95-4-4-0.99][96-4-4-0.99][97-4-4-0.99][98-4-4-0.65][99-4-4-0.99][100-4-4-0.99]
[101-4-4-0.99][102-4-4-0.99][103-4-4-0.78][104-4-4-0.99][105-4-4-0.82][106-4-4-0.99][107-4-4-0.99][108-4-4-0.99][109-4-4-0.99][110-4-4-0.99]
[111-4-0-0.99][112-4-4-0.99][113-4-4-0.95][114-4-4-0.99][115-4-4-0.99][116-4-4-0.99][117-4-4-0.99][119-4-4-0.99][121-4-4-0.99][122-4-4-0.99]
[124-4-4-0.99][125-4-4-0.99][126-4-4-0.99][127-4-2-0.95][128-4-4-0.98][129-4-4-0.57][130-4-4-0.75][131-4-4-0.99][132-4-4-0.99][133-4-4-0.99]
[135-4-4-0.99][136-4-4-0.99][137-4-4-0.88][138-4-4-0.99][139-4-4-0.99][140-4-4-0.99][141-4-3-0.63][142-4-4-0.99][143-4-4-0.99][144-4-4-0.99]
[145-4-4-0.99][148-4-4-0.99][149-4-4-0.99][150-4-4-0.99][151-4-4-0.99][152-4-4-0.99][153-4-4-0.99][154-4-4-0.99][155-4-4-0.99][156-4-4-0.99]
[157-4-4-0.98][158-4-4-0.99][160-4-2-0.98][161-4-4-0.99][162-4-4-0.60][164-4-4-0.99][165-4-4-0.99][167-4-4-0.70][168-4-4-0.99][170-4-4-0.99]
[171-4-4-0.99][172-4-4-0.99][173-4-4-0.99][174-4-0-0.91][175-4-4-0.99][177-4-4-0.99][178-4-4-0.99][179-4-4-0.99][180-4-4-0.99][181-4-3-0.76]
[182-4-4-0.64][183-4-4-0.99][184-4-4-0.99][186-4-4-0.58][187-4-4-0.99][188-4-4-0.99][189-4-4--0.18][190-4-4-0.99][191-4-4-0.99][192-4-4-0.99]
[193-4-1-0.99][194-4-4-0.98][195-4-4-0.99][196-4-4-0.99][197-4-4-0.99][198-4-4-0.99][199-4-2-0.96]
---------------------------
I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 95.875% | Wgt Acc: 97.230%
	I - Batch: 100 | Loss: 0.485 | Acc: 96.188% | Wgt Acc: 97.556%
	I - Batch: 150 | Loss: 0.483 | Acc: 96.375% | Wgt Acc: 97.660%
	I - Batch: 200 | Loss: 0.480 | Acc: 96.562% | Wgt Acc: 97.823%
I - num batch: 222
I - Train -- Loss: 0.480 | Acc: 96.617% | Wgt Acc: 97.853% | LR: 1.250000e-04 | Dur: 107.36s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   0.   0.   0.  25.]
 [  0. 577.   0.   1.  19.]
 [  1.   0. 728.   0.  32.]
 [  1.   0.   0. 534.  21.]
 [ 10.   1.   6.   3. 903.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.083 | Acc: 65.680% | Wgt Acc: 58.740% | Dur: 15.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  13.   7.]
 [  0.  31.   2.   0.   3.]
 [  0.   8.  26.   1.   2.]
 [  6.   1.   6.  45.   2.]
 [ 17.  34.  39.  27. 166.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.625% | Wgt Acc: 98.989%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.938% | Wgt Acc: 98.653%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.583% | Wgt Acc: 98.540%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.646%
I - num batch: 208
I - Train -- Loss: 0.468 | Acc: 97.686% | Wgt Acc: 98.586% | LR: 1.250000e-04 | Dur: 100.12s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  20.]
 [  0. 574.   0.   0.  16.]
 [  0.   0. 733.   0.  15.]
 [  2.   0.   0. 535.  12.]
 [  4.   4.   1.   3. 718.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.011 | Acc: 67.850% | Wgt Acc: 62.094% | Dur: 15.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  14.   4.]
 [  0.  39.   4.   1.   7.]
 [  0.  10.  29.   0.   1.]
 [ 10.   1.   8.  49.   6.]
 [ 13.  24.  32.  22. 162.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 96.500% | Wgt Acc: 97.732%
	I - Batch: 100 | Loss: 0.474 | Acc: 96.750% | Wgt Acc: 97.929%
	I - Batch: 150 | Loss: 0.474 | Acc: 96.708% | Wgt Acc: 97.908%
	I - Batch: 200 | Loss: 0.473 | Acc: 96.844% | Wgt Acc: 97.974%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.012% | Wgt Acc: 98.102% | LR: 1.250000e-04 | Dur: 107.60s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   1.   0.   0.  33.]
 [  0. 573.   0.   0.  14.]
 [  0.   0. 733.   0.  16.]
 [  0.   0.   0. 534.  23.]
 [ 10.   4.   1.   4. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 68.836% | Wgt Acc: 62.052% | Dur: 16.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   2.  11.   5.]
 [  0.  34.   3.   0.   3.]
 [  0.   9.  35.   1.   0.]
 [  5.   2.   4.  44.   2.]
 [ 17.  28.  31.  30. 170.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.875% | Wgt Acc: 97.881%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.438% | Wgt Acc: 98.313%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.458% | Wgt Acc: 98.344%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.406% | Wgt Acc: 98.346%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.463% | Wgt Acc: 98.367% | LR: 1.250000e-04 | Dur: 112.56s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   1.  25.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 732.   0.  12.]
 [  0.   0.   0. 532.  23.]
 [  9.   1.   2.   5. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 68.442% | Wgt Acc: 62.324% | Dur: 17.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   3.   1.  10.   4.]
 [  0.  42.   4.   1.   4.]
 [  0.   6.  26.   0.   2.]
 [  9.   4.   8.  50.   4.]
 [ 16.  23.  36.  25. 166.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 98.169%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.562% | Wgt Acc: 98.367%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.500% | Wgt Acc: 98.359%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.562% | Wgt Acc: 98.448%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.575% | Wgt Acc: 98.485% | LR: 1.250000e-04 | Dur: 108.47s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  25.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 732.   0.  16.]
 [  0.   0.   0. 534.  19.]
 [  8.   1.   2.   4. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.043 | Acc: 66.272% | Wgt Acc: 60.025% | Dur: 17.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   1.  10.   8.]
 [  0.  34.   3.   1.   3.]
 [  0.   8.  23.   0.   1.]
 [  7.   1.   8.  51.   5.]
 [ 16.  31.  40.  24. 163.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.625% | Wgt Acc: 98.553%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.699%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 98.419%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.344% | Wgt Acc: 98.423%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.237% | Wgt Acc: 98.336% | LR: 1.250000e-04 | Dur: 110.32s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  28.]
 [  0. 575.   0.   0.  12.]
 [  0.   0. 731.   0.  22.]
 [  1.   0.   0. 536.  22.]
 [  5.   3.   3.   2. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.030 | Acc: 67.850% | Wgt Acc: 61.352% | Dur: 16.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   6.   2.  16.   4.]
 [  0.  33.   2.   0.   1.]
 [  0.   9.  28.   0.   2.]
 [  7.   6.   8.  49.   6.]
 [ 14.  24.  35.  21. 167.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.125% | Wgt Acc: 98.191%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.062% | Wgt Acc: 98.164%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.000% | Wgt Acc: 98.050%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.156% | Wgt Acc: 98.187%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.181% | Wgt Acc: 98.202% | LR: 1.250000e-04 | Dur: 108.73s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  30.]
 [  0. 576.   0.   0.   8.]
 [  0.   0. 733.   0.  19.]
 [  0.   0.   0. 531.  24.]
 [  9.   2.   1.   7. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 65.680% | Wgt Acc: 59.586% | Dur: 15.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   1.  14.   6.]
 [  0.  41.   3.   2.   7.]
 [  0.   8.  23.   1.   2.]
 [  8.   2.   9.  48.   4.]
 [ 20.  24.  39.  21. 161.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 98.326%
	I - Batch: 100 | Loss: 0.466 | Acc: 97.812% | Wgt Acc: 98.730%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.833% | Wgt Acc: 98.650%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.781% | Wgt Acc: 98.623%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.745% | Wgt Acc: 98.571% | LR: 1.250000e-04 | Dur: 105.68s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   1.   0.  19.]
 [  0. 575.   0.   0.   9.]
 [  0.   0. 728.   0.  23.]
 [  0.   1.   0. 535.  14.]
 [  3.   2.   5.   3. 935.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 66.469% | Wgt Acc: 60.339% | Dur: 15.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   3.   1.  16.   7.]
 [  0.  36.   4.   1.   5.]
 [  0.   6.  22.   0.   1.]
 [  5.   4.   8.  47.   5.]
 [ 13.  29.  40.  22. 162.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 96.875% | Wgt Acc: 98.086%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.062% | Wgt Acc: 98.143%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.333% | Wgt Acc: 98.314%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.656% | Wgt Acc: 98.492%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.547% | Wgt Acc: 98.430% | LR: 1.250000e-04 | Dur: 108.43s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  30.]
 [  0. 576.   0.   0.   7.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 533.  15.]
 [  7.   2.   3.   5. 930.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.054 | Acc: 66.667% | Wgt Acc: 59.628% | Dur: 17.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   2.  13.   4.]
 [  0.  34.   1.   0.   1.]
 [  0.   9.  22.   0.   1.]
 [  9.   2.   8.  48.   5.]
 [ 14.  30.  42.  25. 169.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.750% | Wgt Acc: 98.361%
	I - Batch: 100 | Loss: 0.466 | Acc: 97.938% | Wgt Acc: 98.612%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.958% | Wgt Acc: 98.658%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.812% | Wgt Acc: 98.552%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.773% | Wgt Acc: 98.524% | LR: 1.250000e-04 | Dur: 109.02s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   1.   0.   0.  15.]
 [  0. 575.   0.   0.  17.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 533.  11.]
 [  7.   2.   3.   5. 939.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.065 | Acc: 65.483% | Wgt Acc: 58.500% | Dur: 15.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   4.   1.   8.   4.]
 [  0.  38.   4.   0.   3.]
 [  0.   6.  21.   0.   2.]
 [ 10.   1.   6.  48.   4.]
 [ 20.  29.  43.  30. 167.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 98.750% | Wgt Acc: 99.025%
	I - Batch: 100 | Loss: 0.461 | Acc: 98.562% | Wgt Acc: 99.053%
	I - Batch: 150 | Loss: 0.463 | Acc: 98.333% | Wgt Acc: 98.895%
	I - Batch: 200 | Loss: 0.464 | Acc: 98.219% | Wgt Acc: 98.839%
I - num batch: 222
I - Train -- Loss: 0.464 | Acc: 98.139% | Wgt Acc: 98.827% | LR: 1.250000e-04 | Dur: 107.94s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  18.]
 [  0. 576.   0.   0.   3.]
 [  0.   1. 731.   0.  17.]
 [  0.   0.   0. 535.  16.]
 [  4.   1.   3.   3. 946.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.031 | Acc: 66.864% | Wgt Acc: 60.077% | Dur: 17.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 54.   2.   0.   7.   3.]
 [  0.  39.   3.   0.   5.]
 [  0.   5.  29.   0.   0.]
 [ 13.   2.   9.  49.   4.]
 [ 21.  30.  34.  30. 168.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 96.750% | Wgt Acc: 97.916%
	I - Batch: 100 | Loss: 0.473 | Acc: 96.812% | Wgt Acc: 97.959%
	I - Batch: 150 | Loss: 0.474 | Acc: 96.833% | Wgt Acc: 97.949%
	I - Batch: 200 | Loss: 0.474 | Acc: 96.844% | Wgt Acc: 97.935%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.068% | Wgt Acc: 98.076% | LR: 1.250000e-04 | Dur: 109.70s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   1.   2.  25.]
 [  0. 576.   1.   0.  16.]
 [  0.   0. 729.   0.  25.]
 [  1.   0.   0. 533.  15.]
 [ 10.   2.   3.   3. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.088 | Acc: 64.694% | Wgt Acc: 56.922% | Dur: 15.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   1.  15.   4.]
 [  0.  34.   2.   1.   4.]
 [  0.   7.  18.   0.   0.]
 [  4.   1.   5.  40.   2.]
 [ 18.  33.  49.  30. 170.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.750% | Wgt Acc: 98.432%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.000% | Wgt Acc: 98.012%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.208% | Wgt Acc: 98.159%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.531% | Wgt Acc: 98.411%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.604% | Wgt Acc: 98.444% | LR: 1.250000e-04 | Dur: 113.00s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  25.]
 [  0. 575.   1.   0.   8.]
 [  0.   1. 730.   0.  20.]
 [  0.   0.   0. 535.  14.]
 [  8.   2.   3.   3. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.456% | Wgt Acc: 61.206% | Dur: 16.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   3.  11.   6.]
 [  0.  35.   2.   1.   3.]
 [  0.  12.  29.   0.   2.]
 [ 10.   3.   7.  51.   4.]
 [ 16.  25.  34.  23. 165.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.750% | Wgt Acc: 98.416%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.243%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.292% | Wgt Acc: 98.211%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.156% | Wgt Acc: 98.126%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.181% | Wgt Acc: 98.145% | LR: 1.250000e-04 | Dur: 107.70s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   1.   0.  25.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 728.   0.  20.]
 [  1.   0.   0. 530.  22.]
 [  6.   1.   5.   8. 922.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.042 | Acc: 66.864% | Wgt Acc: 59.785% | Dur: 16.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   2.   8.   3.]
 [  0.  32.   2.   0.   4.]
 [  0.   9.  31.   0.   3.]
 [  7.   2.   4.  45.   1.]
 [ 19.  33.  36.  33. 169.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.875% | Wgt Acc: 98.588%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.812% | Wgt Acc: 98.554%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.208% | Wgt Acc: 98.095%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.375% | Wgt Acc: 98.215%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.519% | Wgt Acc: 98.317% | LR: 1.250000e-04 | Dur: 109.89s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   2.  24.]
 [  0. 576.   0.   0.  16.]
 [  0.   0. 729.   0.  13.]
 [  0.   0.   0. 531.  13.]
 [  8.   2.   4.   5. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.038 | Acc: 67.258% | Wgt Acc: 60.244% | Dur: 15.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   2.   2.   8.   3.]
 [  0.  35.   2.   0.   2.]
 [  1.   9.  30.   0.   0.]
 [ 11.   1.   6.  49.   5.]
 [ 19.  31.  35.  29. 170.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 98.338%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.312% | Wgt Acc: 98.352%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.167% | Wgt Acc: 98.289%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.094% | Wgt Acc: 98.293%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.181% | Wgt Acc: 98.304% | LR: 1.250000e-04 | Dur: 109.45s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  30.]
 [  0. 575.   0.   0.  16.]
 [  0.   0. 733.   0.  20.]
 [  0.   0.   0. 535.  20.]
 [  7.   3.   1.   3. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.040 | Acc: 67.258% | Wgt Acc: 60.652% | Dur: 14.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   0.  14.   8.]
 [  0.  37.   4.   0.   3.]
 [  0.   7.  24.   0.   0.]
 [  6.   2.   8.  48.   2.]
 [ 17.  29.  39.  24. 167.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.250% | Wgt Acc: 98.951%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.750% | Wgt Acc: 98.555%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.333% | Wgt Acc: 98.280%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 98.198%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.293% | Wgt Acc: 98.205% | LR: 1.250000e-04 | Dur: 107.60s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  28.]
 [  0. 575.   0.   0.  12.]
 [  0.   0. 729.   0.  18.]
 [  0.   0.   0. 532.  16.]
 [  8.   3.   5.   6. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.043 | Acc: 66.667% | Wgt Acc: 59.618% | Dur: 18.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   0.   9.   3.]
 [  0.  33.   3.   0.   4.]
 [  0.  12.  29.   1.   2.]
 [  9.   1.   5.  48.   2.]
 [ 20.  29.  38.  28. 169.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 98.183%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.438% | Wgt Acc: 98.380%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.458% | Wgt Acc: 98.321%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.312% | Wgt Acc: 98.253%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.434% | Wgt Acc: 98.356% | LR: 1.250000e-04 | Dur: 109.76s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  32.]
 [  0. 575.   0.   0.  11.]
 [  0.   0. 733.   1.  12.]
 [  0.   0.   0. 534.  18.]
 [ 10.   3.   1.   3. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 66.469% | Wgt Acc: 59.273% | Dur: 15.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   4.   1.   9.   4.]
 [  0.  34.   3.   1.   2.]
 [  0.  12.  25.   0.   0.]
 [ 10.   2.   5.  49.   4.]
 [ 19.  26.  41.  27. 170.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.462 | Acc: 98.500% | Wgt Acc: 98.908%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.875% | Wgt Acc: 98.530%
	I - Batch: 150 | Loss: 0.465 | Acc: 98.000% | Wgt Acc: 98.667%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.812% | Wgt Acc: 98.550%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.829% | Wgt Acc: 98.555% | LR: 1.250000e-04 | Dur: 110.91s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  21.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 730.   0.  12.]
 [  1.   0.   0. 533.  15.]
 [  7.   1.   4.   5. 941.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 68.442% | Wgt Acc: 62.783% | Dur: 16.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   6.   2.   8.   3.]
 [  0.  37.   4.   1.   5.]
 [  0.   8.  30.   0.   4.]
 [ 11.   2.   6.  55.   5.]
 [ 15.  25.  33.  22. 163.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.000% | Wgt Acc: 98.275%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.438% | Wgt Acc: 98.504%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.375% | Wgt Acc: 98.513%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.344% | Wgt Acc: 98.447%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.406% | Wgt Acc: 98.481% | LR: 1.250000e-04 | Dur: 106.79s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 536.  22.]
 [  6.   0.   3.   2. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.011 | Acc: 67.258% | Wgt Acc: 61.425% | Dur: 15.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   1.  12.   3.]
 [  0.  36.   4.   0.   5.]
 [  0.  11.  30.   1.   6.]
 [ 11.   2.   8.  53.   4.]
 [ 17.  26.  32.  20. 162.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.125% | Wgt Acc: 98.216%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.125% | Wgt Acc: 98.254%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.500% | Wgt Acc: 98.489%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 98.431%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.575% | Wgt Acc: 98.529% | LR: 1.250000e-04 | Dur: 107.72s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  22.]
 [  0. 578.   0.   0.   8.]
 [  0.   0. 732.   0.  19.]
 [  1.   0.   0. 536.  24.]
 [  8.   0.   2.   2. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 66.469% | Wgt Acc: 59.012% | Dur: 14.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   2.   1.   8.   2.]
 [  0.  35.   5.   1.   3.]
 [  0.   6.  25.   1.   0.]
 [ 13.   2.   5.  49.   3.]
 [ 19.  33.  39.  27. 172.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 97.875% | Wgt Acc: 98.675%
	I - Batch: 100 | Loss: 0.464 | Acc: 98.125% | Wgt Acc: 98.752%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.517%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.562% | Wgt Acc: 98.423%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.632% | Wgt Acc: 98.454% | LR: 1.250000e-04 | Dur: 110.75s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   1.   0.   0.  25.]
 [  0. 572.   0.   0.  11.]
 [  0.   0. 732.   0.  17.]
 [  0.   0.   0. 535.  13.]
 [  7.   5.   2.   3. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 65.878% | Wgt Acc: 59.252% | Dur: 19.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   2.  13.   5.]
 [  0.  37.   3.   0.   6.]
 [  0.   5.  27.   1.   3.]
 [  7.   2.   7.  42.   2.]
 [ 17.  29.  36.  30. 164.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 97.250% | Wgt Acc: 98.180%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.188% | Wgt Acc: 98.237%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.583% | Wgt Acc: 98.519%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.595%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.575% | Wgt Acc: 98.525% | LR: 1.250000e-04 | Dur: 110.74s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  24.]
 [  0. 575.   0.   0.   8.]
 [  0.   0. 730.   0.  21.]
 [  0.   0.   0. 536.  20.]
 [  4.   3.   4.   2. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 65.483% | Wgt Acc: 58.813% | Dur: 16.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   1.  14.   8.]
 [  0.  33.   2.   1.   4.]
 [  0.  10.  26.   0.   1.]
 [ 11.   2.   7.  46.   3.]
 [ 14.  29.  39.  25. 164.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.703%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.250% | Wgt Acc: 98.278%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.625% | Wgt Acc: 98.517%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.312% | Wgt Acc: 98.324%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.293% | Wgt Acc: 98.304% | LR: 1.250000e-04 | Dur: 112.19s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   1.  36.]
 [  0. 576.   0.   0.  10.]
 [  0.   0. 731.   0.  19.]
 [  0.   0.   0. 534.  14.]
 [  8.   2.   2.   3. 921.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 66.469% | Wgt Acc: 59.597% | Dur: 17.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   4.   1.   8.   4.]
 [  0.  31.   2.   0.   1.]
 [  0.   6.  26.   0.   2.]
 [ 13.   2.   7.  53.   5.]
 [ 16.  35.  39.  25. 168.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 98.612%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.250% | Wgt Acc: 98.195%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.542% | Wgt Acc: 98.444%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.355%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.434% | Wgt Acc: 98.374% | LR: 1.250000e-04 | Dur: 108.26s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  28.]
 [  1. 577.   0.   0.  11.]
 [  0.   0. 733.   0.  14.]
 [  1.   0.   0. 533.  21.]
 [  8.   1.   1.   5. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.036 | Acc: 66.075% | Wgt Acc: 59.430% | Dur: 16.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   2.   2.  12.   3.]
 [  0.  45.   4.   1.   4.]
 [  0.   3.  20.   0.   0.]
 [ 10.   1.   6.  48.   7.]
 [ 22.  27.  43.  25. 166.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.250% | Wgt Acc: 98.331%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.294%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.042% | Wgt Acc: 98.149%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.031% | Wgt Acc: 98.091%
I - num batch: 222
I - Train -- Loss: 0.474 | Acc: 97.040% | Wgt Acc: 98.112% | LR: 1.250000e-04 | Dur: 105.32s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  31.]
 [  0. 576.   0.   0.  13.]
 [  0.   0. 732.   0.  16.]
 [  2.   0.   0. 531.  25.]
 [  7.   2.   2.   7. 915.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.040 | Acc: 66.075% | Wgt Acc: 59.941% | Dur: 14.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   3.  12.   9.]
 [  0.  36.   2.   0.   0.]
 [  0.   8.  23.   0.   3.]
 [  6.   3.  10.  51.   6.]
 [ 19.  27.  37.  23. 162.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 98.125% | Wgt Acc: 98.990%
	I - Batch: 100 | Loss: 0.463 | Acc: 98.312% | Wgt Acc: 99.030%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.958% | Wgt Acc: 98.800%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.656% | Wgt Acc: 98.578%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.632% | Wgt Acc: 98.572% | LR: 1.250000e-04 | Dur: 107.45s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   1.  29.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 731.   0.  12.]
 [  0.   0.   0. 535.  19.]
 [  5.   1.   3.   2. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 66.272% | Wgt Acc: 59.743% | Dur: 15.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   0.   1.   7.   4.]
 [  0.  37.   3.   0.   4.]
 [  0.  12.  28.   0.   3.]
 [  9.   1.   6.  49.   4.]
 [ 22.  28.  37.  30. 165.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 98.250% | Wgt Acc: 98.769%
	I - Batch: 100 | Loss: 0.461 | Acc: 98.250% | Wgt Acc: 98.907%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.833% | Wgt Acc: 98.617%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.562% | Wgt Acc: 98.363%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.406% | Wgt Acc: 98.301% | LR: 1.250000e-04 | Dur: 108.87s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  23.]
 [  0. 577.   1.   0.   6.]
 [  0.   0. 728.   0.  25.]
 [  2.   0.   0. 532.  18.]
 [  5.   1.   5.   6. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.060 | Acc: 66.469% | Wgt Acc: 60.652% | Dur: 14.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   0.  12.   9.]
 [  0.  30.   3.   0.   2.]
 [  0.   8.  30.   2.   3.]
 [  8.   3.   9.  52.   6.]
 [ 15.  33.  33.  20. 160.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.000% | Wgt Acc: 98.207%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.240%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.750% | Wgt Acc: 98.564%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.562% | Wgt Acc: 98.453%
I - num batch: 208
I - Train -- Loss: 0.468 | Acc: 97.446% | Wgt Acc: 98.391% | LR: 1.250000e-04 | Dur: 102.09s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  20.]
 [  0. 575.   0.   0.  12.]
 [  1.   0. 733.   1.  20.]
 [  0.   0.   0. 534.  15.]
 [  9.   3.   1.   3. 714.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.016 | Acc: 67.850% | Wgt Acc: 62.177% | Dur: 14.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   3.  10.   6.]
 [  0.  41.   2.   1.   4.]
 [  0.   6.  29.   1.   4.]
 [ 12.   1.   6.  52.   4.]
 [ 16.  26.  35.  22. 162.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 98.000% | Wgt Acc: 98.746%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.438% | Wgt Acc: 98.444%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.417% | Wgt Acc: 98.436%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.344% | Wgt Acc: 98.363%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.237% | Wgt Acc: 98.338% | LR: 1.250000e-04 | Dur: 113.64s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  34.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 731.   0.  23.]
 [  0.   0.   0. 536.  15.]
 [  8.   1.   3.   2. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 66.667% | Wgt Acc: 61.059% | Dur: 17.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   6.   1.  14.   9.]
 [  0.  39.   2.   0.   5.]
 [  0.   6.  24.   0.   3.]
 [  6.   3.   6.  49.   4.]
 [ 15.  24.  42.  23. 159.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.500% | Wgt Acc: 98.305%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.562% | Wgt Acc: 98.389%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.458% | Wgt Acc: 98.376%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.344% | Wgt Acc: 98.274%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.434% | Wgt Acc: 98.297% | LR: 1.250000e-04 | Dur: 108.00s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  27.]
 [  0. 575.   0.   0.  13.]
 [  0.   0. 729.   0.  16.]
 [  1.   0.   0. 533.  14.]
 [  7.   3.   5.   5. 930.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.041 | Acc: 66.075% | Wgt Acc: 59.053% | Dur: 15.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   0.  14.   5.]
 [  0.  39.   6.   1.   4.]
 [  0.   3.  22.   1.   1.]
 [  8.   2.   6.  46.   2.]
 [ 20.  31.  41.  24. 168.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 96.875% | Wgt Acc: 97.968%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.562% | Wgt Acc: 98.427%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.542% | Wgt Acc: 98.422%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.377%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.434% | Wgt Acc: 98.358% | LR: 1.250000e-04 | Dur: 115.23s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  24.]
 [  0. 577.   0.   0.   6.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 534.  25.]
 [ 10.   1.   3.   4. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.032 | Acc: 67.258% | Wgt Acc: 60.882% | Dur: 18.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   1.  10.   5.]
 [  0.  37.   2.   0.   4.]
 [  0.   8.  29.   1.   3.]
 [  6.   1.   4.  46.   3.]
 [ 18.  30.  39.  29. 165.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 97.000% | Wgt Acc: 98.300%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.688% | Wgt Acc: 98.704%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.667% | Wgt Acc: 98.661%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.500% | Wgt Acc: 98.550%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.632% | Wgt Acc: 98.637% | LR: 1.250000e-04 | Dur: 110.49s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  31.]
 [  0. 578.   0.   0.  11.]
 [  0.   0. 733.   0.  21.]
 [  0.   0.   0. 538.  12.]
 [  8.   0.   1.   0. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 67.456% | Wgt Acc: 61.404% | Dur: 17.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  14.   5.]
 [  0.  43.   4.   1.   4.]
 [  0.   6.  20.   0.   1.]
 [ 10.   1.   9.  50.   6.]
 [ 13.  24.  40.  21. 164.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.875% | Wgt Acc: 98.761%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.562% | Wgt Acc: 98.436%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.583% | Wgt Acc: 98.466%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 98.390%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.378% | Wgt Acc: 98.354% | LR: 1.250000e-04 | Dur: 106.64s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   1.   0.  28.]
 [  0. 575.   0.   0.  14.]
 [  0.   0. 730.   0.  16.]
 [  0.   0.   0. 537.  18.]
 [  9.   3.   3.   1. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.035 | Acc: 65.286% | Wgt Acc: 58.803% | Dur: 15.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   2.   9.   6.]
 [  0.  34.   3.   1.   3.]
 [  0.   8.  26.   1.   4.]
 [ 12.   4.   8.  50.   4.]
 [ 18.  30.  36.  25. 163.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.000% | Wgt Acc: 98.032%
	I - Batch: 100 | Loss: 0.475 | Acc: 96.750% | Wgt Acc: 97.886%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.125% | Wgt Acc: 98.151%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.156% | Wgt Acc: 98.183%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.181% | Wgt Acc: 98.213% | LR: 1.250000e-04 | Dur: 107.83s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   0.  30.]
 [  0. 576.   0.   0.  14.]
 [  0.   0. 728.   0.  20.]
 [  0.   0.   0. 535.  17.]
 [  8.   2.   5.   3. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.032 | Acc: 67.456% | Wgt Acc: 60.788% | Dur: 14.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   1.  10.   4.]
 [  0.  38.   4.   1.   3.]
 [  0.   7.  25.   0.   2.]
 [  8.   1.   7.  49.   3.]
 [ 18.  29.  38.  26. 168.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.460 | Acc: 98.125% | Wgt Acc: 98.960%
	I - Batch: 100 | Loss: 0.464 | Acc: 98.062% | Wgt Acc: 98.895%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.875% | Wgt Acc: 98.674%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.625% | Wgt Acc: 98.485%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.406% | Wgt Acc: 98.348% | LR: 1.250000e-04 | Dur: 111.16s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  26.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 727.   0.  18.]
 [  1.   0.   0. 535.  15.]
 [  7.   0.   7.   3. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.071 | Acc: 64.497% | Wgt Acc: 57.194% | Dur: 19.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 55.   2.   0.   7.   4.]
 [  0.  28.   2.   0.   2.]
 [  0.  14.  29.   0.   5.]
 [  7.   2.   5.  48.   2.]
 [ 26.  32.  39.  31. 167.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.346%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.812% | Wgt Acc: 98.644%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.625% | Wgt Acc: 98.490%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.719% | Wgt Acc: 98.594%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.660% | Wgt Acc: 98.532% | LR: 1.250000e-04 | Dur: 107.82s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  20.]
 [  0. 576.   0.   0.  20.]
 [  0.   0. 730.   0.  17.]
 [  0.   0.   0. 536.  11.]
 [  7.   2.   4.   2. 932.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 66.272% | Wgt Acc: 61.122% | Dur: 14.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   1.  11.   9.]
 [  0.  39.   3.   2.   8.]
 [  0.   9.  27.   0.   4.]
 [  8.   2.   7.  49.   4.]
 [ 14.  23.  37.  24. 155.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.458 | Acc: 98.375% | Wgt Acc: 99.010%
	I - Batch: 100 | Loss: 0.458 | Acc: 98.562% | Wgt Acc: 99.014%
	I - Batch: 150 | Loss: 0.462 | Acc: 98.167% | Wgt Acc: 98.730%
	I - Batch: 200 | Loss: 0.463 | Acc: 98.062% | Wgt Acc: 98.590%
I - num batch: 222
I - Train -- Loss: 0.463 | Acc: 98.027% | Wgt Acc: 98.615% | LR: 1.250000e-04 | Dur: 109.61s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  17.]
 [  0. 577.   0.   0.   5.]
 [  0.   0. 730.   0.  15.]
 [  0.   0.   0. 532.  13.]
 [  9.   1.   4.   6. 950.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.046 | Acc: 66.272% | Wgt Acc: 59.555% | Dur: 15.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   3.   1.  11.   5.]
 [  0.  38.   2.   0.   3.]
 [  0.   7.  25.   0.   1.]
 [ 11.   1.   8.  46.   5.]
 [ 16.  29.  39.  29. 166.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.625% | Wgt Acc: 98.384%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.500% | Wgt Acc: 98.399%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.250% | Wgt Acc: 98.247%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.188% | Wgt Acc: 98.241%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.350% | Wgt Acc: 98.337% | LR: 1.250000e-04 | Dur: 107.93s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  27.]
 [  0. 575.   0.   0.  13.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 536.  19.]
 [  9.   3.   3.   2. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.052 | Acc: 66.075% | Wgt Acc: 60.579% | Dur: 19.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   1.  11.   9.]
 [  0.  34.   2.   1.   4.]
 [  0.  10.  30.   0.   4.]
 [  7.   3.   7.  50.   6.]
 [ 17.  27.  35.  24. 157.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 98.000% | Wgt Acc: 98.745%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.812% | Wgt Acc: 98.687%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.416%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.438% | Wgt Acc: 98.449%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.491% | Wgt Acc: 98.485% | LR: 1.250000e-04 | Dur: 107.11s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  30.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 728.   0.  15.]
 [  0.   0.   0. 536.  19.]
 [  4.   1.   6.   2. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.058 | Acc: 65.089% | Wgt Acc: 57.852% | Dur: 15.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   2.   1.  14.   5.]
 [  0.  30.   3.   0.   3.]
 [  0.   9.  26.   0.   2.]
 [  7.   1.   4.  44.   3.]
 [ 18.  36.  41.  28. 167.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 98.381%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 98.321%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.000% | Wgt Acc: 98.155%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.219% | Wgt Acc: 98.297%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.181% | Wgt Acc: 98.267% | LR: 1.250000e-04 | Dur: 120.42s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  24.]
 [  0. 575.   0.   0.  15.]
 [  0.   0. 733.   0.  25.]
 [  0.   0.   0. 535.  20.]
 [  9.   3.   1.   3. 916.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.021 | Acc: 67.258% | Wgt Acc: 61.404% | Dur: 18.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   1.  10.   5.]
 [  0.  38.   3.   1.   6.]
 [  0.  10.  28.   0.   3.]
 [ 11.   1.   9.  51.   4.]
 [ 15.  26.  34.  24. 162.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.375% | Wgt Acc: 98.536%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.688% | Wgt Acc: 98.527%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.708% | Wgt Acc: 98.587%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.531% | Wgt Acc: 98.500%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.660% | Wgt Acc: 98.586% | LR: 1.250000e-04 | Dur: 116.88s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  22.]
 [  0. 577.   0.   0.  12.]
 [  0.   0. 731.   0.  22.]
 [  0.   0.   0. 535.  15.]
 [  5.   1.   3.   3. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.071 | Acc: 64.694% | Wgt Acc: 56.723% | Dur: 16.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   2.   1.   6.   2.]
 [  0.  31.   2.   0.   3.]
 [  0.   8.  23.   0.   1.]
 [  8.   2.   3.  45.   2.]
 [ 23.  35.  46.  35. 172.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 96.375% | Wgt Acc: 97.767%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.312% | Wgt Acc: 98.403%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.333% | Wgt Acc: 98.234%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.219% | Wgt Acc: 98.196%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.068% | Wgt Acc: 98.112% | LR: 1.250000e-04 | Dur: 112.84s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   1.   0.  24.]
 [  0. 575.   0.   0.  15.]
 [  0.   0. 731.   0.  22.]
 [  0.   0.   0. 533.  22.]
 [ 10.   3.   2.   5. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.033 | Acc: 66.272% | Wgt Acc: 60.046% | Dur: 15.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   5.   2.  12.   5.]
 [  0.  40.   3.   2.   7.]
 [  0.   6.  23.   0.   2.]
 [  8.   2.   6.  49.   3.]
 [ 19.  25.  41.  23. 163.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.125% | Wgt Acc: 98.201%
	I - Batch: 100 | Loss: 0.473 | Acc: 96.938% | Wgt Acc: 97.948%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.208% | Wgt Acc: 98.136%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.156% | Wgt Acc: 98.119%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.209% | Wgt Acc: 98.150% | LR: 1.250000e-04 | Dur: 112.04s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   0.  24.]
 [  0. 574.   0.   0.  11.]
 [  0.   0. 729.   0.  27.]
 [  0.   0.   0. 535.  14.]
 [ 11.   4.   5.   3. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 66.667% | Wgt Acc: 60.819% | Dur: 17.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   6.   1.  17.  11.]
 [  0.  39.   1.   1.   3.]
 [  0.   8.  27.   0.   1.]
 [  4.   1.   7.  44.   5.]
 [ 16.  24.  39.  24. 160.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 97.750% | Wgt Acc: 98.693%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.312% | Wgt Acc: 98.158%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.000% | Wgt Acc: 98.080%
	I - Batch: 200 | Loss: 0.476 | Acc: 96.750% | Wgt Acc: 97.886%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 96.786% | Wgt Acc: 97.911% | LR: 1.250000e-04 | Dur: 115.36s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   1.  36.]
 [  0. 575.   0.   0.  14.]
 [  0.   0. 729.   0.  21.]
 [  0.   0.   1. 532.  19.]
 [ 10.   3.   4.   5. 910.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.063 | Acc: 65.089% | Wgt Acc: 58.061% | Dur: 19.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   4.   1.  16.   5.]
 [  0.  31.   2.   0.   2.]
 [  0.   6.  24.   1.   1.]
 [  9.   3.   6.  47.   6.]
 [ 17.  34.  42.  22. 166.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.500% | Wgt Acc: 98.473%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.812% | Wgt Acc: 98.720%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.792% | Wgt Acc: 98.691%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.750% | Wgt Acc: 98.613%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.773% | Wgt Acc: 98.649% | LR: 1.250000e-04 | Dur: 114.44s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  26.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 729.   0.  17.]
 [  1.   0.   0. 537.  10.]
 [  4.   1.   5.   1. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.096 | Acc: 64.892% | Wgt Acc: 57.215% | Dur: 15.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   3.   0.  11.   3.]
 [  0.  31.   1.   1.   3.]
 [  0.   9.  23.   1.   1.]
 [  7.   3.   4.  44.   3.]
 [ 20.  32.  47.  29. 170.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 96.875% | Wgt Acc: 98.146%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.062% | Wgt Acc: 98.143%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.312%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.344% | Wgt Acc: 98.396%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.293% | Wgt Acc: 98.319% | LR: 1.250000e-04 | Dur: 110.53s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  32.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 732.   0.  21.]
 [  0.   0.   0. 532.  16.]
 [  7.   1.   2.   6. 920.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.043 | Acc: 64.694% | Wgt Acc: 58.165% | Dur: 18.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   5.   1.  14.   5.]
 [  0.  33.   2.   0.   4.]
 [  0.   9.  24.   0.   3.]
 [ 11.   1.  10.  48.   6.]
 [ 16.  30.  38.  24. 162.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.125% | Wgt Acc: 98.368%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.125% | Wgt Acc: 98.275%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.583% | Wgt Acc: 98.549%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.432%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.434% | Wgt Acc: 98.427% | LR: 1.250000e-04 | Dur: 112.28s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   1.   1.  26.]
 [  0. 577.   0.   0.   8.]
 [  0.   0. 731.   0.  19.]
 [  0.   0.   0. 532.  24.]
 [  4.   1.   2.   5. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 67.850% | Wgt Acc: 61.080% | Dur: 15.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   1.  11.   5.]
 [  0.  33.   2.   1.   2.]
 [  0.   8.  27.   0.   0.]
 [ 10.   2.   8.  49.   4.]
 [ 12.  31.  37.  25. 169.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.750% | Wgt Acc: 98.436%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.125% | Wgt Acc: 98.062%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.000% | Wgt Acc: 98.057%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 98.387%
I - num batch: 222
I - Train -- Loss: 0.473 | Acc: 97.265% | Wgt Acc: 98.270% | LR: 1.250000e-04 | Dur: 115.73s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  34.]
 [  0. 575.   0.   0.   8.]
 [  0.   0. 730.   0.  22.]
 [  0.   0.   0. 534.  15.]
 [  7.   3.   4.   4. 921.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.020 | Acc: 67.850% | Wgt Acc: 62.062% | Dur: 15.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   1.   9.   5.]
 [  0.  39.   4.   0.   4.]
 [  0.  11.  30.   1.   3.]
 [ 11.   2.   8.  54.   5.]
 [ 19.  24.  32.  22. 163.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.000% | Wgt Acc: 98.740%
	I - Batch: 100 | Loss: 0.468 | Acc: 98.000% | Wgt Acc: 98.727%
	I - Batch: 150 | Loss: 0.465 | Acc: 98.083% | Wgt Acc: 98.804%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.651%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.886% | Wgt Acc: 98.682% | LR: 1.250000e-04 | Dur: 110.17s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  26.]
 [  0. 577.   0.   0.   5.]
 [  0.   1. 730.   0.  18.]
 [  0.   0.   0. 535.  13.]
 [  5.   0.   4.   3. 938.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.054 | Acc: 66.469% | Wgt Acc: 59.262% | Dur: 18.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   0.   9.   2.]
 [  0.  35.   1.   1.   4.]
 [  0.   8.  26.   0.   1.]
 [ 13.   3.   6.  48.   3.]
 [ 17.  30.  42.  28. 170.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 98.181%
	I - Batch: 100 | Loss: 0.475 | Acc: 96.875% | Wgt Acc: 97.898%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.083% | Wgt Acc: 98.040%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.188% | Wgt Acc: 98.169%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.350% | Wgt Acc: 98.274% | LR: 1.250000e-04 | Dur: 113.87s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  30.]
 [  0. 576.   0.   0.  11.]
 [  0.   0. 731.   0.  18.]
 [  1.   0.   0. 533.  15.]
 [  9.   2.   3.   5. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.058 | Acc: 66.667% | Wgt Acc: 59.492% | Dur: 16.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   3.   0.  12.   1.]
 [  1.  42.   4.   1.   4.]
 [  0.   5.  24.   0.   3.]
 [  8.   1.   4.  44.   2.]
 [ 21.  27.  43.  29. 170.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.375% | Wgt Acc: 98.579%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.250% | Wgt Acc: 98.219%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.292% | Wgt Acc: 98.211%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.406% | Wgt Acc: 98.356%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.406% | Wgt Acc: 98.331% | LR: 1.250000e-04 | Dur: 113.74s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  21.]
 [  0. 576.   0.   0.  11.]
 [  0.   0. 731.   1.  16.]
 [  2.   0.   0. 530.  26.]
 [  3.   2.   3.   7. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.035 | Acc: 67.061% | Wgt Acc: 60.913% | Dur: 18.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   6.   1.  16.   6.]
 [  0.  41.   4.   1.   3.]
 [  0.   8.  28.   0.   4.]
 [  6.   3.   6.  44.   4.]
 [ 18.  20.  36.  25. 163.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 98.176%
	I - Batch: 100 | Loss: 0.476 | Acc: 97.125% | Wgt Acc: 98.320%
	I - Batch: 150 | Loss: 0.474 | Acc: 97.167% | Wgt Acc: 98.271%
	I - Batch: 200 | Loss: 0.475 | Acc: 96.969% | Wgt Acc: 98.164%
I - num batch: 222
I - Train -- Loss: 0.475 | Acc: 97.012% | Wgt Acc: 98.162% | LR: 1.250000e-04 | Dur: 110.67s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  32.]
 [  0. 576.   0.   0.  15.]
 [  0.   0. 731.   0.  20.]
 [  0.   0.   0. 534.  22.]
 [  8.   2.   3.   3. 911.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.040 | Acc: 66.864% | Wgt Acc: 60.004% | Dur: 15.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   2.  13.   5.]
 [  0.  40.   3.   1.   3.]
 [  0.   4.  28.   0.   2.]
 [  9.   1.   6.  45.   2.]
 [ 21.  31.  36.  27. 168.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.000% | Wgt Acc: 98.174%
	I - Batch: 100 | Loss: 0.475 | Acc: 96.750% | Wgt Acc: 98.057%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.042% | Wgt Acc: 98.147%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.250% | Wgt Acc: 98.309%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.237% | Wgt Acc: 98.313% | LR: 1.250000e-04 | Dur: 115.40s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   0.  31.]
 [  0. 578.   0.   0.  13.]
 [  0.   0. 732.   0.  16.]
 [  0.   0.   0. 533.  23.]
 [  8.   0.   1.   5. 917.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.060 | Acc: 65.878% | Wgt Acc: 58.949% | Dur: 18.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   2.  11.   6.]
 [  0.  35.   2.   1.   2.]
 [  1.   5.  20.   0.   2.]
 [  8.   3.   8.  48.   3.]
 [ 15.  31.  43.  26. 167.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 98.000% | Wgt Acc: 98.747%
	I - Batch: 100 | Loss: 0.466 | Acc: 98.125% | Wgt Acc: 98.830%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.625% | Wgt Acc: 98.542%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.469% | Wgt Acc: 98.418%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.491% | Wgt Acc: 98.441% | LR: 1.250000e-04 | Dur: 109.64s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  27.]
 [  0. 576.   0.   0.   9.]
 [  0.   1. 731.   0.  14.]
 [  0.   0.   0. 534.  24.]
 [  6.   1.   3.   4. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.031 | Acc: 68.442% | Wgt Acc: 61.321% | Dur: 18.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   1.   2.  10.   2.]
 [  0.  37.   4.   0.   3.]
 [  0.  10.  29.   0.   0.]
 [  9.   1.   5.  50.   2.]
 [ 21.  29.  35.  26. 173.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.125% | Wgt Acc: 98.180%
	I - Batch: 100 | Loss: 0.463 | Acc: 97.438% | Wgt Acc: 98.386%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.458% | Wgt Acc: 98.344%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.469% | Wgt Acc: 98.385%
I - num batch: 208
I - Train -- Loss: 0.466 | Acc: 97.536% | Wgt Acc: 98.433% | LR: 1.250000e-04 | Dur: 98.84s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  19.]
 [  0. 576.   0.   0.  11.]
 [  0.   0. 731.   0.  19.]
 [  0.   0.   0. 533.  15.]
 [  8.   2.   3.   4. 717.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 66.469% | Wgt Acc: 59.994% | Dur: 14.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   3.   2.  13.   6.]
 [  0.  36.   4.   0.   4.]
 [  0.   7.  22.   0.   1.]
 [  9.   5.   9.  50.   4.]
 [ 15.  27.  38.  23. 165.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.250% | Wgt Acc: 98.292%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.438% | Wgt Acc: 98.463%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.292% | Wgt Acc: 98.290%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.219% | Wgt Acc: 98.230%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.209% | Wgt Acc: 98.202% | LR: 1.250000e-04 | Dur: 111.40s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  31.]
 [  0. 575.   0.   0.  10.]
 [  0.   0. 730.   0.  21.]
 [  0.   0.   0. 533.  17.]
 [  8.   3.   4.   5. 921.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.037 | Acc: 67.653% | Wgt Acc: 61.007% | Dur: 16.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   1.  15.   5.]
 [  0.  37.   3.   0.   3.]
 [  0.   9.  31.   0.   3.]
 [  7.   2.   3.  42.   2.]
 [ 15.  25.  37.  29. 167.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.875% | Wgt Acc: 98.589%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.812% | Wgt Acc: 98.519%
	I - Batch: 150 | Loss: 0.467 | Acc: 98.000% | Wgt Acc: 98.702%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.969% | Wgt Acc: 98.740%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.886% | Wgt Acc: 98.682% | LR: 1.250000e-04 | Dur: 109.28s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   1.  18.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 732.   0.  18.]
 [  0.   0.   0. 535.  12.]
 [  7.   1.   2.   2. 938.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.036 | Acc: 66.667% | Wgt Acc: 60.474% | Dur: 16.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   2.   9.   4.]
 [  0.  42.   4.   1.   5.]
 [  0.   5.  20.   0.   2.]
 [ 10.   2.  11.  52.   5.]
 [ 18.  25.  38.  24. 164.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 97.625% | Wgt Acc: 98.550%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.312% | Wgt Acc: 98.333%
	I - Batch: 150 | Loss: 0.472 | Acc: 96.917% | Wgt Acc: 97.919%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.250% | Wgt Acc: 98.173%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.181% | Wgt Acc: 98.126% | LR: 1.250000e-04 | Dur: 115.88s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   1.   0.  30.]
 [  0. 575.   0.   0.   9.]
 [  0.   0. 729.   0.  18.]
 [  0.   0.   0. 531.  20.]
 [  8.   3.   4.   7. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 65.680% | Wgt Acc: 60.025% | Dur: 16.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   5.   3.  11.   7.]
 [  0.  36.   4.   0.   1.]
 [  0.   9.  24.   1.   4.]
 [  8.   6.  11.  52.  10.]
 [ 17.  22.  33.  22. 158.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.375% | Wgt Acc: 98.174%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.688% | Wgt Acc: 98.487%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.606%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.500% | Wgt Acc: 98.461%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.604% | Wgt Acc: 98.521% | LR: 1.250000e-04 | Dur: 107.93s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   1.   0.  22.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 730.   0.  21.]
 [  0.   0.   0. 535.  15.]
 [  6.   1.   3.   3. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.018 | Acc: 68.245% | Wgt Acc: 62.042% | Dur: 15.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   4.   1.   8.   2.]
 [  0.  43.   3.   0.   3.]
 [  0.   8.  25.   1.   4.]
 [ 11.   2.   8.  54.   4.]
 [ 20.  21.  38.  23. 167.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 96.375% | Wgt Acc: 97.718%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.000% | Wgt Acc: 98.090%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.242%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.337%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.293% | Wgt Acc: 98.266% | LR: 1.250000e-04 | Dur: 108.09s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  23.]
 [  1. 575.   0.   0.  14.]
 [  1.   0. 731.   0.  17.]
 [  0.   0.   0. 534.  23.]
 [  7.   3.   3.   4. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.059 | Acc: 65.286% | Wgt Acc: 57.580% | Dur: 16.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   2.   7.   2.]
 [  0.  33.   2.   0.   3.]
 [  0.  10.  23.   0.   1.]
 [ 10.   1.   4.  44.   3.]
 [ 18.  30.  44.  35. 171.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 98.375%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.312% | Wgt Acc: 98.202%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.187%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.469% | Wgt Acc: 98.313%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.434% | Wgt Acc: 98.319% | LR: 1.250000e-04 | Dur: 108.55s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  27.]
 [  0. 575.   0.   0.   9.]
 [  0.   0. 729.   0.  21.]
 [  0.   0.   0. 534.  14.]
 [  8.   3.   5.   4. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 67.456% | Wgt Acc: 62.365% | Dur: 14.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   5.   1.  10.   8.]
 [  1.  42.   4.   3.   8.]
 [  0.   9.  27.   1.   3.]
 [ 11.   2.   7.  51.   4.]
 [ 11.  20.  36.  21. 157.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.476 | Acc: 96.875% | Wgt Acc: 98.244%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 98.552%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.417% | Wgt Acc: 98.465%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.562% | Wgt Acc: 98.509%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.600% | LR: 1.250000e-04 | Dur: 109.87s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  23.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 732.   0.  16.]
 [  1.   0.   0. 535.  17.]
 [  5.   1.   2.   3. 930.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.048 | Acc: 66.667% | Wgt Acc: 60.109% | Dur: 18.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 52.   3.   0.   8.   2.]
 [  0.  37.   1.   0.   5.]
 [  0.  10.  33.   1.   3.]
 [ 13.   1.   6.  50.   4.]
 [ 23.  27.  35.  27. 166.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.875% | Wgt Acc: 98.395%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.469%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.333% | Wgt Acc: 98.216%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.531% | Wgt Acc: 98.428%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.547% | Wgt Acc: 98.451% | LR: 1.250000e-04 | Dur: 109.27s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  23.]
 [  0. 576.   0.   0.  17.]
 [  0.   0. 730.   0.  18.]
 [  0.   0.   0. 534.  13.]
 [  6.   2.   4.   4. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.046 | Acc: 67.653% | Wgt Acc: 60.819% | Dur: 15.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   2.  10.   5.]
 [  0.  39.   4.   2.   2.]
 [  0.   5.  22.   0.   2.]
 [  4.   1.   4.  45.   2.]
 [ 16.  28.  43.  29. 169.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.457 | Acc: 98.125% | Wgt Acc: 98.727%
	I - Batch: 100 | Loss: 0.460 | Acc: 98.250% | Wgt Acc: 98.815%
	I - Batch: 150 | Loss: 0.462 | Acc: 98.125% | Wgt Acc: 98.793%
	I - Batch: 200 | Loss: 0.463 | Acc: 98.000% | Wgt Acc: 98.736%
I - num batch: 222
I - Train -- Loss: 0.464 | Acc: 98.027% | Wgt Acc: 98.737% | LR: 1.250000e-04 | Dur: 106.31s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  21.]
 [  0. 577.   0.   0.   6.]
 [  0.   0. 730.   0.  15.]
 [  0.   0.   0. 536.  14.]
 [  7.   1.   4.   2. 944.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.036 | Acc: 66.667% | Wgt Acc: 60.579% | Dur: 15.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   3.   2.  14.   4.]
 [  0.  38.   3.   1.   5.]
 [  1.   7.  28.   0.   3.]
 [  7.   1.   8.  46.   6.]
 [ 16.  29.  34.  25. 162.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 97.250% | Wgt Acc: 98.249%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.500% | Wgt Acc: 98.381%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.458% | Wgt Acc: 98.276%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.344% | Wgt Acc: 98.245%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.434% | Wgt Acc: 98.256% | LR: 1.250000e-04 | Dur: 107.54s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  25.]
 [  0. 572.   0.   0.   8.]
 [  0.   0. 729.   0.  18.]
 [  0.   0.   0. 533.  17.]
 [  7.   6.   5.   5. 932.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.005 | Acc: 69.428% | Wgt Acc: 63.369% | Dur: 17.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   2.  11.   4.]
 [  0.  44.   3.   1.   3.]
 [  0.   7.  31.   1.   2.]
 [  8.   1.   6.  48.   4.]
 [ 18.  23.  33.  25. 167.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.469 | Acc: 97.375% | Wgt Acc: 98.083%
	I - Batch: 100 | Loss: 0.466 | Acc: 97.750% | Wgt Acc: 98.523%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.667% | Wgt Acc: 98.517%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.562% | Wgt Acc: 98.454%
I - num batch: 222
I - Train -- Loss: 0.466 | Acc: 97.632% | Wgt Acc: 98.518% | LR: 1.250000e-04 | Dur: 105.88s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  24.]
 [  0. 576.   0.   0.  17.]
 [  0.   0. 730.   0.  12.]
 [  1.   0.   0. 536.  16.]
 [  6.   2.   4.   2. 931.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 68.047% | Wgt Acc: 61.185% | Dur: 14.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   2.   1.   7.   1.]
 [  0.  40.   4.   1.   3.]
 [  0.   7.  23.   0.   1.]
 [  8.   2.   8.  52.   4.]
 [ 21.  27.  39.  26. 171.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.500% | Wgt Acc: 98.193%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 98.368%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.542% | Wgt Acc: 98.309%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.340%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.434% | Wgt Acc: 98.293% | LR: 1.250000e-04 | Dur: 101.69s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   1.   0.   0.  22.]
 [  0. 572.   0.   0.  13.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 533.  17.]
 [  7.   5.   3.   5. 930.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.035 | Acc: 66.864% | Wgt Acc: 60.945% | Dur: 15.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   3.  11.   8.]
 [  0.  38.   3.   0.   4.]
 [  0.  10.  24.   0.   1.]
 [  9.   2.   9.  52.   5.]
 [ 16.  24.  36.  23. 162.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.000% | Wgt Acc: 98.151%
	I - Batch: 100 | Loss: 0.471 | Acc: 96.938% | Wgt Acc: 98.020%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.273%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.156% | Wgt Acc: 98.173%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.153% | Wgt Acc: 98.192% | LR: 1.250000e-04 | Dur: 103.69s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  37.]
 [  0. 575.   0.   0.  17.]
 [  0.   0. 733.   0.  14.]
 [  0.   0.   0. 533.  14.]
 [ 10.   3.   1.   5. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.042 | Acc: 66.272% | Wgt Acc: 59.524% | Dur: 16.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   4.   2.  11.   5.]
 [  0.  33.   3.   1.   2.]
 [  0.  13.  26.   0.   5.]
 [  8.   1.   3.  47.   2.]
 [ 16.  27.  41.  27. 166.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 98.000% | Wgt Acc: 98.738%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.688% | Wgt Acc: 98.524%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.583% | Wgt Acc: 98.442%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 98.330%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.378% | Wgt Acc: 98.299% | LR: 1.250000e-04 | Dur: 101.40s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  24.]
 [  1. 576.   0.   1.  14.]
 [  0.   0. 731.   0.  16.]
 [  0.   0.   0. 530.  20.]
 [  5.   2.   3.   7. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.049 | Acc: 66.272% | Wgt Acc: 59.576% | Dur: 16.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   2.  13.   5.]
 [  0.  32.   2.   0.   0.]
 [  0.  11.  24.   0.   2.]
 [ 11.   1.   7.  50.   7.]
 [ 13.  29.  40.  23. 166.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.500% | Wgt Acc: 98.401%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.625% | Wgt Acc: 98.501%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.583% | Wgt Acc: 98.529%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.500% | Wgt Acc: 98.428%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.491% | Wgt Acc: 98.414% | LR: 1.250000e-04 | Dur: 100.56s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  23.]
 [  0. 576.   0.   0.  12.]
 [  0.   0. 731.   0.  23.]
 [  0.   0.   0. 531.  15.]
 [  4.   2.   3.   7. 927.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.010 | Acc: 67.456% | Wgt Acc: 61.770% | Dur: 16.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   5.   2.  14.   5.]
 [  0.  37.   3.   1.   4.]
 [  0.  10.  25.   0.   4.]
 [  9.   2.   5.  51.   6.]
 [ 11.  24.  40.  20. 161.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 98.125% | Wgt Acc: 98.872%
	I - Batch: 100 | Loss: 0.467 | Acc: 98.000% | Wgt Acc: 98.677%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.548%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.844% | Wgt Acc: 98.560%
I - num batch: 222
I - Train -- Loss: 0.466 | Acc: 97.998% | Wgt Acc: 98.674% | LR: 1.250000e-04 | Dur: 101.90s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  29.]
 [  0. 577.   0.   0.   4.]
 [  1.   0. 731.   0.  11.]
 [  0.   0.   0. 532.  11.]
 [  5.   1.   3.   6. 945.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.069 | Acc: 66.864% | Wgt Acc: 59.252% | Dur: 14.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   1.   7.   1.]
 [  0.  29.   2.   0.   2.]
 [  0.  14.  32.   0.   2.]
 [  4.   2.   3.  47.   2.]
 [ 26.  31.  37.  32. 173.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 96.875% | Wgt Acc: 97.979%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.250% | Wgt Acc: 98.171%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.406%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.481%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.604% | Wgt Acc: 98.430% | LR: 1.250000e-04 | Dur: 103.50s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   1.  23.]
 [  0. 576.   0.   0.   8.]
 [  0.   0. 730.   0.  21.]
 [  0.   0.   0. 536.  14.]
 [ 11.   2.   4.   1. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.047 | Acc: 66.075% | Wgt Acc: 59.367% | Dur: 16.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   2.  18.   8.]
 [  0.  30.   2.   0.   1.]
 [  0.  10.  28.   1.   3.]
 [  5.   1.   5.  46.   3.]
 [ 17.  33.  38.  21. 165.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.500% | Wgt Acc: 98.657%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.438% | Wgt Acc: 98.525%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.333% | Wgt Acc: 98.438%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.219% | Wgt Acc: 98.355%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.265% | Wgt Acc: 98.408% | LR: 1.250000e-04 | Dur: 100.19s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  29.]
 [  0. 577.   0.   0.  13.]
 [  0.   0. 730.   0.  21.]
 [  2.   0.   0. 536.  23.]
 [  2.   1.   4.   2. 914.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.039 | Acc: 68.047% | Wgt Acc: 61.874% | Dur: 14.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   5.   2.  11.   4.]
 [  0.  32.   2.   0.   4.]
 [  0.  13.  28.   1.   4.]
 [  5.   1.   7.  50.   3.]
 [ 13.  27.  36.  24. 165.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 97.875% | Wgt Acc: 98.756%
	I - Batch: 100 | Loss: 0.464 | Acc: 97.688% | Wgt Acc: 98.626%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.667% | Wgt Acc: 98.511%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.469% | Wgt Acc: 98.405%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.547% | Wgt Acc: 98.474% | LR: 1.250000e-04 | Dur: 100.76s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  23.]
 [  0. 577.   0.   0.  14.]
 [  0.   0. 730.   1.  15.]
 [  0.   0.   0. 535.  20.]
 [  7.   1.   4.   2. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.056 | Acc: 65.483% | Wgt Acc: 58.834% | Dur: 18.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   5.   2.  15.   6.]
 [  0.  31.   3.   1.   4.]
 [  0.   6.  22.   0.   3.]
 [  7.   2.   7.  48.   3.]
 [ 14.  34.  41.  22. 164.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.875% | Wgt Acc: 97.904%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 98.457%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.542% | Wgt Acc: 98.386%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.594% | Wgt Acc: 98.459%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.632% | Wgt Acc: 98.511% | LR: 1.250000e-04 | Dur: 102.17s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  31.]
 [  0. 575.   0.   0.  12.]
 [  0.   0. 733.   0.  14.]
 [  0.   0.   0. 534.  12.]
 [  7.   3.   1.   4. 931.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.078 | Acc: 65.680% | Wgt Acc: 58.301% | Dur: 13.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   4.   1.   8.   4.]
 [  0.  25.   1.   0.   1.]
 [  0.  11.  27.   1.   1.]
 [ 10.   2.  10.  53.   4.]
 [ 20.  36.  36.  24. 170.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.750% | Wgt Acc: 97.926%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.483%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.125% | Wgt Acc: 98.213%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.188% | Wgt Acc: 98.283%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.293% | Wgt Acc: 98.364% | LR: 1.250000e-04 | Dur: 108.00s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  24.]
 [  0. 575.   0.   0.  13.]
 [  0.   0. 731.   0.  22.]
 [  0.   0.   0. 536.  23.]
 [  6.   3.   3.   2. 918.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.029 | Acc: 67.456% | Wgt Acc: 61.613% | Dur: 19.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   1.  10.   8.]
 [  0.  39.   2.   2.   4.]
 [  0.   5.  25.   0.   3.]
 [  6.   2.   8.  49.   3.]
 [ 15.  28.  39.  25. 162.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.750% | Wgt Acc: 98.511%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.688% | Wgt Acc: 98.522%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.542% | Wgt Acc: 98.410%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.656% | Wgt Acc: 98.491%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.491% | Wgt Acc: 98.442% | LR: 1.250000e-04 | Dur: 111.76s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  31.]
 [  0. 575.   0.   0.  10.]
 [  0.   0. 733.   0.  13.]
 [  0.   0.   0. 535.  20.]
 [  8.   3.   1.   3. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.045 | Acc: 66.272% | Wgt Acc: 58.907% | Dur: 23.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   2.  16.   5.]
 [  0.  34.   2.   1.   2.]
 [  0.  10.  23.   0.   2.]
 [  6.   1.   3.  43.   1.]
 [ 16.  31.  45.  26. 170.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 96.875% | Wgt Acc: 97.760%
	I - Batch: 100 | Loss: 0.476 | Acc: 96.750% | Wgt Acc: 97.943%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.208% | Wgt Acc: 98.278%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.406% | Wgt Acc: 98.395%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.406% | Wgt Acc: 98.383% | LR: 1.250000e-04 | Dur: 103.90s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  29.]
 [  0. 576.   0.   0.  10.]
 [  0.   0. 732.   0.  20.]
 [  0.   0.   0. 535.  17.]
 [  9.   2.   2.   3. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.080 | Acc: 65.483% | Wgt Acc: 57.716% | Dur: 14.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   1.   9.   4.]
 [  0.  32.   1.   1.   0.]
 [  0.  10.  22.   1.   0.]
 [  8.   1.   7.  46.   4.]
 [ 20.  32.  44.  29. 172.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.528%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.438% | Wgt Acc: 98.445%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 98.480%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.562% | Wgt Acc: 98.461%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.491% | Wgt Acc: 98.441% | LR: 1.250000e-04 | Dur: 103.99s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  32.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 732.   0.  12.]
 [  0.   0.   0. 533.  15.]
 [  8.   0.   2.   5. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.078 | Acc: 64.300% | Wgt Acc: 56.744% | Dur: 16.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   4.   2.  15.   8.]
 [  0.  35.   3.   0.   4.]
 [  0.   6.  23.   0.   0.]
 [  7.   2.   5.  41.   0.]
 [ 22.  31.  42.  30. 168.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.750% | Wgt Acc: 98.592%
	I - Batch: 100 | Loss: 0.474 | Acc: 97.500% | Wgt Acc: 98.378%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.417% | Wgt Acc: 98.312%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.594% | Wgt Acc: 98.376%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.547% | Wgt Acc: 98.351% | LR: 1.250000e-04 | Dur: 101.66s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  19.]
 [  0. 575.   0.   0.  12.]
 [  0.   0. 729.   0.  16.]
 [  0.   0.   0. 532.  19.]
 [  7.   3.   5.   6. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.046 | Acc: 65.483% | Wgt Acc: 58.259% | Dur: 14.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   1.  14.   4.]
 [  0.  36.   3.   1.   4.]
 [  0.   6.  21.   0.   2.]
 [  5.   1.   5.  44.   2.]
 [ 20.  31.  45.  27. 168.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.374%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.375% | Wgt Acc: 98.376%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.375% | Wgt Acc: 98.418%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.438% | Wgt Acc: 98.471%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.378% | Wgt Acc: 98.445% | LR: 1.250000e-04 | Dur: 102.32s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  26.]
 [  0. 574.   0.   0.  14.]
 [  0.   0. 732.   0.  23.]
 [  0.   0.   0. 537.  18.]
 [  5.   4.   2.   1. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.063 | Acc: 65.089% | Wgt Acc: 57.528% | Dur: 14.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   2.   2.  14.   3.]
 [  0.  36.   3.   1.   3.]
 [  0.   8.  21.   0.   1.]
 [ 10.   1.   5.  45.   3.]
 [ 20.  31.  44.  26. 170.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.418%
	I - Batch: 100 | Loss: 0.466 | Acc: 97.500% | Wgt Acc: 98.367%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.292% | Wgt Acc: 98.235%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.281% | Wgt Acc: 98.273%
I - num batch: 208
I - Train -- Loss: 0.468 | Acc: 97.266% | Wgt Acc: 98.259% | LR: 1.250000e-04 | Dur: 93.44s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  19.]
 [  0. 575.   0.   0.  16.]
 [  0.   0. 728.   0.  17.]
 [  0.   0.   0. 532.  19.]
 [  5.   3.   6.   6. 710.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.057 | Acc: 66.469% | Wgt Acc: 60.130% | Dur: 14.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   3.  11.   5.]
 [  0.  40.   4.   1.   4.]
 [  0.   6.  21.   1.   1.]
 [  6.   2.   8.  48.   6.]
 [ 18.  25.  39.  25. 164.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 98.000% | Wgt Acc: 98.840%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.750% | Wgt Acc: 98.625%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.875% | Wgt Acc: 98.738%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.812% | Wgt Acc: 98.668%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.546% | LR: 1.250000e-04 | Dur: 108.25s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  24.]
 [  0. 576.   0.   0.   7.]
 [  0.   0. 732.   0.  16.]
 [  0.   0.   0. 536.  20.]
 [  9.   2.   2.   2. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.034 | Acc: 66.272% | Wgt Acc: 59.973% | Dur: 20.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   4.   2.   6.   3.]
 [  0.  36.   2.   1.   5.]
 [  0.   9.  26.   0.   2.]
 [ 14.   2.  10.  54.   6.]
 [ 18.  27.  35.  25. 164.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.462 | Acc: 97.750% | Wgt Acc: 98.675%
	I - Batch: 100 | Loss: 0.465 | Acc: 97.688% | Wgt Acc: 98.562%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.417% | Wgt Acc: 98.310%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.312% | Wgt Acc: 98.232%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.265% | Wgt Acc: 98.190% | LR: 1.250000e-04 | Dur: 98.68s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  26.]
 [  0. 575.   0.   0.  10.]
 [  0.   0. 731.   0.  18.]
 [  0.   0.   0. 532.  21.]
 [ 10.   3.   3.   6. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 69.034% | Wgt Acc: 63.703% | Dur: 13.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   2.  13.   6.]
 [  0.  48.   4.   1.   7.]
 [  0.   6.  29.   2.   1.]
 [  7.   2.   9.  46.   5.]
 [ 15.  17.  31.  24. 161.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 97.750% | Wgt Acc: 98.599%
	I - Batch: 100 | Loss: 0.465 | Acc: 97.625% | Wgt Acc: 98.458%
	I - Batch: 150 | Loss: 0.466 | Acc: 97.792% | Wgt Acc: 98.599%
	I - Batch: 200 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.689%
I - num batch: 222
I - Train -- Loss: 0.465 | Acc: 97.857% | Wgt Acc: 98.684% | LR: 1.250000e-04 | Dur: 100.15s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  25.]
 [  0. 576.   0.   0.   9.]
 [  0.   0. 732.   0.  14.]
 [  0.   0.   0. 535.  16.]
 [  5.   2.   2.   3. 936.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.047 | Acc: 66.864% | Wgt Acc: 60.213% | Dur: 13.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   3.   2.  12.   3.]
 [  0.  33.   2.   0.   4.]
 [  0.  13.  29.   0.   2.]
 [ 12.   6.  10.  52.   4.]
 [ 18.  23.  32.  22. 167.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 97.875% | Wgt Acc: 98.864%
	I - Batch: 100 | Loss: 0.461 | Acc: 98.125% | Wgt Acc: 98.928%
	I - Batch: 150 | Loss: 0.461 | Acc: 98.125% | Wgt Acc: 98.941%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.562% | Wgt Acc: 98.559%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.519% | Wgt Acc: 98.516% | LR: 1.250000e-04 | Dur: 97.89s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  27.]
 [  0. 576.   0.   0.   8.]
 [  0.   0. 732.   0.  25.]
 [  0.   0.   0. 536.  16.]
 [  6.   2.   2.   2. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.084 | Acc: 65.286% | Wgt Acc: 58.103% | Dur: 13.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   3.   2.   9.   4.]
 [  0.  39.   3.   1.   5.]
 [  0.   5.  25.   0.   1.]
 [  7.   2.   5.  40.   3.]
 [ 21.  29.  40.  36. 167.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.701%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.562% | Wgt Acc: 98.577%
	I - Batch: 150 | Loss: 0.472 | Acc: 97.333% | Wgt Acc: 98.406%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.406% | Wgt Acc: 98.391%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.463% | Wgt Acc: 98.430% | LR: 1.250000e-04 | Dur: 98.72s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   1.   0.  28.]
 [  0. 574.   0.   0.  16.]
 [  0.   0. 732.   0.  13.]
 [  0.   0.   0. 536.  18.]
 [  7.   4.   1.   2. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.042 | Acc: 67.258% | Wgt Acc: 60.495% | Dur: 14.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   2.  10.   3.]
 [  0.  39.   2.   0.   4.]
 [  0.   9.  29.   1.   2.]
 [ 11.   1.   7.  46.   3.]
 [ 18.  26.  35.  29. 168.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.389%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.297%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.417% | Wgt Acc: 98.299%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.594% | Wgt Acc: 98.461%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.522% | LR: 1.250000e-04 | Dur: 99.25s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  25.]
 [  0. 576.   0.   0.  14.]
 [  0.   0. 729.   0.  19.]
 [  1.   0.   0. 534.   8.]
 [  4.   2.   5.   4. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.074 | Acc: 63.708% | Wgt Acc: 56.253% | Dur: 14.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   1.  15.   5.]
 [  0.  31.   3.   1.   3.]
 [  0.  11.  25.   1.   5.]
 [  8.   2.   6.  41.   1.]
 [ 20.  32.  40.  28. 166.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 98.000% | Wgt Acc: 98.893%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.688% | Wgt Acc: 98.616%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.725%
	I - Batch: 200 | Loss: 0.465 | Acc: 97.938% | Wgt Acc: 98.746%
I - num batch: 222
I - Train -- Loss: 0.465 | Acc: 97.829% | Wgt Acc: 98.670% | LR: 1.250000e-04 | Dur: 100.91s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  18.]
 [  0. 578.   0.   0.  14.]
 [  0.   0. 731.   0.  17.]
 [  0.   0.   0. 534.  16.]
 [  5.   0.   3.   4. 935.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.025 | Acc: 67.456% | Wgt Acc: 60.756% | Dur: 16.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   5.   1.  12.   3.]
 [  0.  39.   3.   0.   1.]
 [  0.   8.  25.   1.   2.]
 [ 11.   2.   7.  47.   6.]
 [ 14.  24.  39.  26. 168.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.375% | Wgt Acc: 98.259%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.562% | Wgt Acc: 98.338%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.583% | Wgt Acc: 98.383%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.719% | Wgt Acc: 98.487%
I - num batch: 222
I - Train -- Loss: 0.466 | Acc: 97.857% | Wgt Acc: 98.572% | LR: 1.250000e-04 | Dur: 101.57s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   1.  19.]
 [  0. 575.   0.   0.  14.]
 [  0.   0. 729.   0.  12.]
 [  0.   0.   0. 535.  13.]
 [  7.   3.   5.   2. 942.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.041 | Acc: 67.258% | Wgt Acc: 60.861% | Dur: 15.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   3.   1.  12.   3.]
 [  0.  38.   2.   1.   4.]
 [  0.   7.  24.   0.   2.]
 [  8.   1.   7.  51.   5.]
 [ 18.  29.  41.  22. 166.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.455 | Acc: 98.375% | Wgt Acc: 98.869%
	I - Batch: 100 | Loss: 0.458 | Acc: 98.312% | Wgt Acc: 98.818%
	I - Batch: 150 | Loss: 0.462 | Acc: 98.000% | Wgt Acc: 98.619%
	I - Batch: 200 | Loss: 0.461 | Acc: 98.031% | Wgt Acc: 98.712%
I - num batch: 222
I - Train -- Loss: 0.462 | Acc: 98.027% | Wgt Acc: 98.720% | LR: 1.250000e-04 | Dur: 100.78s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  20.]
 [  0. 574.   0.   0.  11.]
 [  0.   0. 728.   0.  12.]
 [  0.   0.   0. 538.  12.]
 [  5.   4.   6.   0. 945.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.008 | Acc: 68.245% | Wgt Acc: 63.034% | Dur: 14.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   3.   2.  14.   5.]
 [  0.  39.   2.   0.   6.]
 [  0.  14.  36.   2.   8.]
 [  5.   1.   6.  45.   3.]
 [ 15.  21.  29.  25. 158.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.479 | Acc: 96.125% | Wgt Acc: 97.635%
	I - Batch: 100 | Loss: 0.474 | Acc: 96.688% | Wgt Acc: 97.963%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.208% | Wgt Acc: 98.281%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.219% | Wgt Acc: 98.254%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.209% | Wgt Acc: 98.246% | LR: 1.250000e-04 | Dur: 103.31s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  33.]
 [  0. 576.   0.   0.  12.]
 [  0.   0. 731.   0.  22.]
 [  0.   0.   0. 535.  14.]
 [ 10.   2.   3.   3. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.028 | Acc: 68.245% | Wgt Acc: 61.916% | Dur: 14.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   6.   2.  12.   4.]
 [  0.  35.   3.   0.   3.]
 [  0.  10.  29.   0.   3.]
 [ 10.   3.   8.  52.   3.]
 [ 15.  24.  33.  22. 167.]]

I - Loading file: dataset_cls4_background10_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.751%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.562% | Wgt Acc: 98.366%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.295%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.719% | Wgt Acc: 98.496%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.773% | Wgt Acc: 98.521% | LR: 1.250000e-04 | Dur: 103.48s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   1.  20.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 732.   0.  13.]
 [  0.   0.   0. 531.  17.]
 [  8.   1.   2.   6. 939.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.060 | Acc: 66.469% | Wgt Acc: 59.221% | Dur: 14.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   3.   3.  13.   2.]
 [  0.  41.   3.   1.   6.]
 [  0.   5.  22.   0.   0.]
 [  8.   2.   5.  43.   2.]
 [ 19.  27.  42.  29. 170.]]

I - Loading file: dataset_cls4_background11_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 96.750% | Wgt Acc: 97.942%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.375% | Wgt Acc: 98.372%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.375% | Wgt Acc: 98.383%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.531% | Wgt Acc: 98.426%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.406% | Wgt Acc: 98.337% | LR: 1.250000e-04 | Dur: 101.22s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  23.]
 [  0. 576.   0.   0.  11.]
 [  0.   0. 730.   0.  20.]
 [  1.   0.   0. 532.  20.]
 [  5.   2.   4.   6. 926.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.041 | Acc: 66.667% | Wgt Acc: 59.889% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   4.   1.  13.   5.]
 [  0.  39.   2.   0.   1.]
 [  0.   9.  26.   0.   3.]
 [  8.   1.   6.  45.   4.]
 [ 19.  25.  40.  28. 167.]]

I - Loading file: dataset_cls4_background12_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.000% | Wgt Acc: 98.212%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.510%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.750% | Wgt Acc: 98.681%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.594% | Wgt Acc: 98.518%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.716% | Wgt Acc: 98.569% | LR: 1.250000e-04 | Dur: 101.18s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  22.]
 [  0. 575.   0.   0.   9.]
 [  0.   0. 733.   0.  18.]
 [  1.   0.   0. 533.  18.]
 [  4.   3.   1.   5. 933.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.051 | Acc: 66.864% | Wgt Acc: 59.962% | Dur: 14.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   3.   2.  13.   3.]
 [  0.  36.   5.   0.   3.]
 [  0.  10.  25.   0.   2.]
 [  7.   3.   8.  45.   4.]
 [ 16.  26.  35.  28. 168.]]

I - Loading file: dataset_cls4_background13_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.500% | Wgt Acc: 98.555%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.562% | Wgt Acc: 98.500%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.250% | Wgt Acc: 98.279%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.250% | Wgt Acc: 98.348%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.265% | Wgt Acc: 98.304% | LR: 1.250000e-04 | Dur: 103.19s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   1.  25.]
 [  0. 575.   0.   0.  14.]
 [  0.   1. 733.   0.  19.]
 [  1.   0.   0. 533.  23.]
 [  6.   2.   1.   4. 919.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.014 | Acc: 68.245% | Wgt Acc: 61.718% | Dur: 17.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   2.   1.  11.   5.]
 [  0.  37.   3.   0.   4.]
 [  0.   5.  27.   0.   0.]
 [  6.   1.   6.  48.   3.]
 [ 16.  33.  38.  27. 168.]]

I - Loading file: dataset_cls4_background14_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.125% | Wgt Acc: 98.203%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.500% | Wgt Acc: 98.383%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 98.565%
	I - Batch: 200 | Loss: 0.471 | Acc: 97.500% | Wgt Acc: 98.366%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.463% | Wgt Acc: 98.331% | LR: 1.250000e-04 | Dur: 102.60s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  26.]
 [  0. 574.   0.   0.  11.]
 [  0.   0. 729.   0.  22.]
 [  0.   0.   0. 534.  11.]
 [  7.   4.   5.   4. 930.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.002 | Acc: 68.836% | Wgt Acc: 64.183% | Dur: 14.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   5.   2.  13.   5.]
 [  0.  44.   5.   1.   9.]
 [  0.   7.  35.   1.   6.]
 [  9.   3.   9.  50.   4.]
 [ 15.  19.  24.  21. 156.]]

I - Loading file: dataset_cls4_background15_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.750% | Wgt Acc: 98.524%
	I - Batch: 100 | Loss: 0.475 | Acc: 97.438% | Wgt Acc: 98.155%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.708% | Wgt Acc: 98.432%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.812% | Wgt Acc: 98.575%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.829% | Wgt Acc: 98.556% | LR: 1.250000e-04 | Dur: 101.25s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  20.]
 [  0. 574.   0.   0.   5.]
 [  0.   0. 731.   0.  20.]
 [  0.   0.   0. 535.  14.]
 [  8.   4.   3.   3. 941.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.017 | Acc: 67.258% | Wgt Acc: 60.370% | Dur: 15.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   0.   9.   1.]
 [  0.  38.   5.   0.   6.]
 [  0.  12.  27.   1.   1.]
 [  7.   1.   5.  47.   3.]
 [ 21.  25.  38.  29. 169.]]

I - Loading file: dataset_cls4_background16_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.750% | Wgt Acc: 98.512%
	I - Batch: 100 | Loss: 0.465 | Acc: 97.750% | Wgt Acc: 98.691%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.500% | Wgt Acc: 98.485%
	I - Batch: 200 | Loss: 0.468 | Acc: 97.531% | Wgt Acc: 98.507%
I - num batch: 222
I - Train -- Loss: 0.468 | Acc: 97.519% | Wgt Acc: 98.444% | LR: 1.250000e-04 | Dur: 102.98s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  26.]
 [  0. 577.   0.   1.  13.]
 [  1.   0. 728.   0.  18.]
 [  1.   0.   0. 536.  15.]
 [  5.   1.   6.   1. 928.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.074 | Acc: 65.089% | Wgt Acc: 57.820% | Dur: 14.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 57.   2.   1.   7.   4.]
 [  0.  32.   2.   0.   2.]
 [  0.   9.  25.   0.   3.]
 [  8.   2.   6.  48.   3.]
 [ 23.  33.  41.  31. 168.]]

I - Loading file: dataset_cls4_background17_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.250% | Wgt Acc: 98.363%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.312% | Wgt Acc: 98.343%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.125% | Wgt Acc: 98.291%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.125% | Wgt Acc: 98.247%
I - num batch: 222
I - Train -- Loss: 0.471 | Acc: 97.068% | Wgt Acc: 98.230% | LR: 1.250000e-04 | Dur: 104.44s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   0.  32.]
 [  0. 574.   0.   0.  12.]
 [  0.   0. 730.   0.  24.]
 [  0.   0.   0. 536.  21.]
 [  5.   4.   4.   2. 911.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.096 | Acc: 62.722% | Wgt Acc: 53.976% | Dur: 14.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 51.   1.   1.   9.   2.]
 [  0.  29.   2.   0.   1.]
 [  0.  10.  29.   1.   3.]
 [  4.   1.   2.  36.   1.]
 [ 33.  37.  41.  40. 173.]]

I - Loading file: dataset_cls4_background18_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.471 | Acc: 97.375% | Wgt Acc: 98.454%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.188% | Wgt Acc: 98.113%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.333% | Wgt Acc: 98.289%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.406% | Wgt Acc: 98.329%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.406% | Wgt Acc: 98.361% | LR: 1.250000e-04 | Dur: 103.71s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  22.]
 [  0. 576.   0.   0.  13.]
 [  0.   0. 729.   0.  20.]
 [  0.   0.   0. 534.  20.]
 [  6.   2.   5.   4. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.032 | Acc: 66.864% | Wgt Acc: 60.600% | Dur: 15.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 63.   4.   2.  12.   6.]
 [  0.  35.   3.   0.   2.]
 [  0.   8.  27.   0.   2.]
 [  8.   2.   7.  50.   6.]
 [ 17.  29.  36.  24. 164.]]

I - Loading file: dataset_cls4_background19_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 97.375% | Wgt Acc: 98.250%
	I - Batch: 100 | Loss: 0.470 | Acc: 97.562% | Wgt Acc: 98.565%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.417% | Wgt Acc: 98.438%
	I - Batch: 200 | Loss: 0.472 | Acc: 97.281% | Wgt Acc: 98.283%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.293% | Wgt Acc: 98.283% | LR: 1.250000e-04 | Dur: 106.86s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  26.]
 [  0. 578.   0.   0.  15.]
 [  0.   0. 730.   0.  14.]
 [  0.   0.   0. 532.  23.]
 [  8.   0.   4.   6. 922.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.076 | Acc: 65.286% | Wgt Acc: 58.165% | Dur: 14.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   5.   0.  13.   5.]
 [  0.  33.   3.   1.   3.]
 [  0.   9.  25.   0.   1.]
 [ 10.   2.   5.  46.   4.]
 [ 18.  29.  42.  26. 167.]]

I - Loading file: dataset_cls4_background20_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.496%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.812% | Wgt Acc: 98.470%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.606%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.656% | Wgt Acc: 98.468%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.632% | Wgt Acc: 98.491% | LR: 1.250000e-04 | Dur: 101.83s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  17.]
 [  1. 574.   0.   0.  10.]
 [  0.   0. 732.   0.  22.]
 [  0.   0.   0. 534.  19.]
 [  5.   4.   2.   4. 932.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.022 | Acc: 68.442% | Wgt Acc: 61.989% | Dur: 14.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   0.   6.   4.]
 [  0.  36.   5.   0.   2.]
 [  0.  11.  33.   0.   2.]
 [  9.   3.   6.  50.   4.]
 [ 19.  26.  31.  30. 168.]]

I - Loading file: dataset_cls4_background21_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 98.375% | Wgt Acc: 99.023%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.750% | Wgt Acc: 98.573%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.458% | Wgt Acc: 98.429%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.438% | Wgt Acc: 98.440%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.463% | Wgt Acc: 98.424% | LR: 1.250000e-04 | Dur: 104.45s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   0.   0.   0.  30.]
 [  0. 578.   0.   0.  18.]
 [  0.   0. 732.   0.  15.]
 [  0.   0.   0. 532.  12.]
 [  7.   0.   2.   6. 925.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.026 | Acc: 67.850% | Wgt Acc: 61.665% | Dur: 14.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   4.   2.  14.   6.]
 [  0.  39.   3.   1.   3.]
 [  0.   9.  26.   0.   0.]
 [  6.   1.  10.  48.   6.]
 [ 16.  25.  34.  23. 165.]]

I - Loading file: dataset_cls4_background22_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.684%
	I - Batch: 100 | Loss: 0.467 | Acc: 97.938% | Wgt Acc: 98.659%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.875% | Wgt Acc: 98.640%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.688% | Wgt Acc: 98.492%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.801% | Wgt Acc: 98.543% | LR: 1.250000e-04 | Dur: 103.22s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  17.]
 [  0. 575.   0.   1.   8.]
 [  0.   0. 728.   0.  18.]
 [  1.   0.   0. 535.  17.]
 [  5.   3.   6.   2. 940.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.053 | Acc: 67.258% | Wgt Acc: 60.976% | Dur: 15.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   4.   1.   9.   3.]
 [  0.  38.   1.   0.   5.]
 [  0.   5.  28.   0.   3.]
 [ 11.   3.  10.  50.   4.]
 [ 17.  28.  35.  27. 165.]]

I - Loading file: dataset_cls4_background23_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 97.250% | Wgt Acc: 97.923%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 98.208%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.292% | Wgt Acc: 98.067%
	I - Batch: 200 | Loss: 0.473 | Acc: 97.188% | Wgt Acc: 97.968%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.209% | Wgt Acc: 98.039% | LR: 1.250000e-04 | Dur: 104.51s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   0.   0.   0.  31.]
 [  0. 577.   0.   0.   8.]
 [  0.   0. 729.   0.  17.]
 [  1.   0.   0. 527.  15.]
 [ 10.   1.   5.  11. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.088 | Acc: 64.497% | Wgt Acc: 57.026% | Dur: 14.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 65.   4.   2.  14.   7.]
 [  0.  34.   3.   0.   4.]
 [  0.   8.  24.   0.   1.]
 [  5.   2.   2.  37.   1.]
 [ 18.  30.  44.  35. 167.]]

I - Loading file: dataset_cls4_background24_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 97.875% | Wgt Acc: 98.671%
	I - Batch: 100 | Loss: 0.472 | Acc: 97.062% | Wgt Acc: 98.186%
	I - Batch: 150 | Loss: 0.473 | Acc: 97.083% | Wgt Acc: 98.091%
	I - Batch: 200 | Loss: 0.474 | Acc: 97.094% | Wgt Acc: 98.118%
I - num batch: 222
I - Train -- Loss: 0.472 | Acc: 97.265% | Wgt Acc: 98.232% | LR: 1.250000e-04 | Dur: 106.74s
I - Confusion Matrix: [row->prediction - col->label]
[[687.   0.   0.   0.  33.]
 [  0. 574.   0.   0.  13.]
 [  0.   0. 732.   0.  14.]
 [  0.   0.   0. 534.  17.]
 [ 10.   4.   2.   4. 923.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.047 | Acc: 67.850% | Wgt Acc: 60.474% | Dur: 14.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   2.   0.   9.   3.]
 [  0.  37.   3.   0.   2.]
 [  0.   9.  26.   0.   0.]
 [  7.   1.   4.  44.   2.]
 [ 17.  29.  42.  33. 173.]]

I - Loading file: dataset_cls4_background25_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 98.000% | Wgt Acc: 98.595%
	I - Batch: 100 | Loss: 0.473 | Acc: 97.438% | Wgt Acc: 98.284%
	I - Batch: 150 | Loss: 0.471 | Acc: 97.458% | Wgt Acc: 98.342%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.625% | Wgt Acc: 98.457%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.632% | Wgt Acc: 98.494% | LR: 1.250000e-04 | Dur: 101.14s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  28.]
 [  0. 576.   0.   0.   8.]
 [  0.   0. 732.   0.  16.]
 [  1.   0.   0. 534.  16.]
 [  7.   2.   2.   4. 932.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.088 | Acc: 65.286% | Wgt Acc: 57.747% | Dur: 14.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 60.   2.   2.  11.   3.]
 [  0.  36.   2.   1.   3.]
 [  0.   6.  21.   0.   1.]
 [  5.   1.   4.  44.   3.]
 [ 23.  33.  46.  30. 170.]]

I - Loading file: dataset_cls4_background26_no_samples781.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [697. 578. 734. 538. 781.]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.459 | Acc: 98.625% | Wgt Acc: 99.247%
	I - Batch: 100 | Loss: 0.461 | Acc: 98.562% | Wgt Acc: 99.217%
	I - Batch: 150 | Loss: 0.460 | Acc: 98.458% | Wgt Acc: 99.196%
	I - Batch: 200 | Loss: 0.461 | Acc: 98.344% | Wgt Acc: 99.066%
I - num batch: 208
I - Train -- Loss: 0.462 | Acc: 98.317% | Wgt Acc: 99.037% | LR: 1.250000e-04 | Dur: 95.54s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   0.   0.   0.  12.]
 [  0. 576.   0.   1.   8.]
 [  0.   0. 732.   0.  14.]
 [  0.   0.   0. 537.  15.]
 [  2.   2.   2.   0. 732.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.054 | Acc: 65.483% | Wgt Acc: 58.218% | Dur: 14.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   1.  10.   4.]
 [  0.  32.   1.   0.   3.]
 [  0.   9.  26.   0.   3.]
 [  8.   2.   6.  44.   2.]
 [ 18.  33.  41.  32. 168.]]

I - Loading file: dataset_cls4_background00_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 97.625% | Wgt Acc: 98.294%
	I - Batch: 100 | Loss: 0.471 | Acc: 97.438% | Wgt Acc: 98.229%
	I - Batch: 150 | Loss: 0.470 | Acc: 97.542% | Wgt Acc: 98.381%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.469% | Wgt Acc: 98.327%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.434% | Wgt Acc: 98.311% | LR: 1.250000e-04 | Dur: 107.04s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   2.  25.]
 [  0. 576.   0.   0.   7.]
 [  0.   0. 732.   0.  22.]
 [  0.   0.   0. 531.  17.]
 [  9.   2.   2.   5. 929.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.080 | Acc: 65.089% | Wgt Acc: 57.695% | Dur: 15.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 62.   2.   3.  13.   4.]
 [  0.  30.   2.   0.   2.]
 [  0.  12.  27.   1.   1.]
 [  6.   2.   6.  43.   5.]
 [ 20.  32.  37.  29. 168.]]

I - Loading file: dataset_cls4_background01_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.465 | Acc: 97.625% | Wgt Acc: 98.337%
	I - Batch: 100 | Loss: 0.461 | Acc: 98.062% | Wgt Acc: 98.791%
	I - Batch: 150 | Loss: 0.462 | Acc: 97.917% | Wgt Acc: 98.804%
	I - Batch: 200 | Loss: 0.465 | Acc: 97.719% | Wgt Acc: 98.610%
I - num batch: 222
I - Train -- Loss: 0.465 | Acc: 97.716% | Wgt Acc: 98.612% | LR: 1.250000e-04 | Dur: 103.93s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  18.]
 [  0. 577.   0.   0.  11.]
 [  0.   0. 733.   0.  19.]
 [  0.   0.   0. 534.  21.]
 [  6.   1.   1.   4. 931.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.067 | Acc: 64.892% | Wgt Acc: 58.134% | Dur: 14.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   3.   2.  11.   4.]
 [  0.  39.   4.   0.   4.]
 [  0.   8.  25.   0.   3.]
 [  9.   1.   5.  45.   5.]
 [ 23.  27.  39.  30. 164.]]

I - Loading file: dataset_cls4_background02_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 97.500% | Wgt Acc: 98.474%
	I - Batch: 100 | Loss: 0.468 | Acc: 97.625% | Wgt Acc: 98.493%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.292% | Wgt Acc: 98.263%
	I - Batch: 200 | Loss: 0.470 | Acc: 97.219% | Wgt Acc: 98.240%
I - num batch: 222
I - Train -- Loss: 0.470 | Acc: 97.265% | Wgt Acc: 98.294% | LR: 1.250000e-04 | Dur: 100.86s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   0.   0.   0.  30.]
 [  0. 577.   0.   0.   6.]
 [  0.   0. 730.   0.  25.]
 [  1.   0.   0. 535.  19.]
 [  8.   1.   4.   3. 920.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.055 | Acc: 66.864% | Wgt Acc: 60.286% | Dur: 14.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 67.   4.   1.  15.   7.]
 [  0.  37.   4.   1.   3.]
 [  0.   8.  22.   0.   1.]
 [  8.   2.   6.  47.   3.]
 [ 13.  27.  42.  23. 166.]]

I - Loading file: dataset_cls4_background03_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.470 | Acc: 97.125% | Wgt Acc: 98.227%
	I - Batch: 100 | Loss: 0.469 | Acc: 97.438% | Wgt Acc: 98.443%
	I - Batch: 150 | Loss: 0.469 | Acc: 97.500% | Wgt Acc: 98.473%
	I - Batch: 200 | Loss: 0.469 | Acc: 97.375% | Wgt Acc: 98.391%
I - num batch: 222
I - Train -- Loss: 0.469 | Acc: 97.463% | Wgt Acc: 98.445% | LR: 1.250000e-04 | Dur: 101.79s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  26.]
 [  0. 576.   0.   0.   9.]
 [  0.   0. 732.   0.  22.]
 [  0.   0.   0. 534.  19.]
 [  6.   2.   2.   4. 924.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 66.667% | Wgt Acc: 60.683% | Dur: 15.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   5.   2.  12.   7.]
 [  1.  45.   4.   1.   8.]
 [  0.   4.  25.   0.   2.]
 [  5.   1.   3.  41.   2.]
 [ 16.  23.  41.  32. 161.]]

I - Loading file: dataset_cls4_background04_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 97.625% | Wgt Acc: 98.422%
	I - Batch: 100 | Loss: 0.465 | Acc: 97.938% | Wgt Acc: 98.654%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.917% | Wgt Acc: 98.629%
	I - Batch: 200 | Loss: 0.467 | Acc: 97.688% | Wgt Acc: 98.531%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.773% | Wgt Acc: 98.545% | LR: 1.250000e-04 | Dur: 101.45s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   0.  26.]
 [  0. 575.   0.   0.   9.]
 [  0.   0. 730.   0.   8.]
 [  0.   0.   1. 534.  19.]
 [  6.   3.   3.   4. 938.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.013 | Acc: 68.836% | Wgt Acc: 63.149% | Dur: 14.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   6.   1.  10.   3.]
 [  0.  41.   4.   1.   5.]
 [  0.   6.  26.   0.   2.]
 [  9.   1.   7.  54.   6.]
 [ 15.  24.  37.  21. 164.]]

I - Loading file: dataset_cls4_background05_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 98.250% | Wgt Acc: 98.950%
	I - Batch: 100 | Loss: 0.468 | Acc: 98.062% | Wgt Acc: 98.790%
	I - Batch: 150 | Loss: 0.468 | Acc: 97.917% | Wgt Acc: 98.707%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.906% | Wgt Acc: 98.745%
I - num batch: 222
I - Train -- Loss: 0.467 | Acc: 97.857% | Wgt Acc: 98.721% | LR: 1.250000e-04 | Dur: 102.56s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   0.   0.   0.  26.]
 [  0. 576.   0.   0.   7.]
 [  0.   0. 732.   0.  21.]
 [  0.   0.   0. 535.  12.]
 [  3.   2.   2.   3. 934.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.058 | Acc: 66.075% | Wgt Acc: 59.200% | Dur: 14.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   3.   1.  10.   7.]
 [  0.  38.   4.   0.   4.]
 [  0.   7.  19.   0.   0.]
 [  8.   1.   4.  47.   2.]
 [ 16.  29.  47.  29. 167.]]

I - Loading file: dataset_cls4_background06_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.464 | Acc: 98.000% | Wgt Acc: 98.722%
	I - Batch: 100 | Loss: 0.465 | Acc: 97.875% | Wgt Acc: 98.668%
	I - Batch: 150 | Loss: 0.467 | Acc: 97.667% | Wgt Acc: 98.415%
	I - Batch: 200 | Loss: 0.466 | Acc: 97.844% | Wgt Acc: 98.586%
I - num batch: 222
I - Train -- Loss: 0.466 | Acc: 97.886% | Wgt Acc: 98.640% | LR: 1.250000e-04 | Dur: 105.04s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   0.   0.   0.  16.]
 [  0. 578.   0.   0.  10.]
 [  0.   0. 732.   0.  13.]
 [  1.   0.   0. 533.  21.]
 [  7.   0.   2.   5. 940.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.027 | Acc: 66.864% | Wgt Acc: 60.997% | Dur: 14.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   3.  13.   7.]
 [  0.  36.   2.   1.   2.]
 [  0.  10.  27.   0.   3.]
 [  9.   4.  11.  49.   7.]
 [ 13.  25.  32.  23. 161.]]

I - Loading file: dataset_cls4_background07_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.466 | Acc: 97.625% | Wgt Acc: 98.519%
	I - Batch: 100 | Loss: 0.464 | Acc: 98.062% | Wgt Acc: 98.793%
	I - Batch: 150 | Loss: 0.465 | Acc: 97.792% | Wgt Acc: 98.617%
	I - Batch: 200 | Loss: 0.465 | Acc: 97.812% | Wgt Acc: 98.615%
I - num batch: 222
I - Train -- Loss: 0.465 | Acc: 97.942% | Wgt Acc: 98.711% | LR: 1.250000e-04 | Dur: 100.45s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   0.   0.   1.  17.]
 [  0. 576.   0.   0.  14.]
 [  0.   0. 731.   0.  17.]
 [  0.   0.   0. 536.  12.]
 [  6.   2.   3.   1. 940.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.012 | Acc: 67.653% | Wgt Acc: 61.676% | Dur: 14.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   5.   2.  12.   6.]
 [  0.  37.   2.   1.   4.]
 [  0.  11.  34.   1.   2.]
 [ 12.   2.   6.  48.   5.]
 [ 15.  23.  31.  24. 163.]]

I - Loading file: dataset_cls4_background08_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.458 | Acc: 98.625% | Wgt Acc: 99.145%
	I - Batch: 100 | Loss: 0.459 | Acc: 98.438% | Wgt Acc: 99.088%
	I - Batch: 150 | Loss: 0.460 | Acc: 98.375% | Wgt Acc: 99.045%
	I - Batch: 200 | Loss: 0.459 | Acc: 98.438% | Wgt Acc: 99.068%
I - num batch: 222
I - Train -- Loss: 0.459 | Acc: 98.393% | Wgt Acc: 99.057% | LR: 1.250000e-04 | Dur: 102.27s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   0.   0.   0.  22.]
 [  0. 577.   0.   0.   6.]
 [  0.   0. 732.   0.  10.]
 [  0.   0.   0. 538.  12.]
 [  4.   1.   2.   0. 950.]]

I - Validation: 
I - num batch: 32
I - Val -- Loss: 1.023 | Acc: 67.258% | Wgt Acc: 59.921% | Dur: 14.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 59.   3.   2.  10.   2.]
 [  0.  34.   2.   2.   2.]
 [  0.   8.  29.   0.   1.]
 [  9.   2.   7.  47.   3.]
 [ 20.  31.  35.  27. 172.]]

I - Loading file: dataset_cls4_background09_no_samples1000.pkl in /data_ssd/processed/kinetics400/processed_4class_fixed_50frames_256x256/train/new_background
I - New label distribution: [ 697.  578.  734.  538. 1000.]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.467 | Acc: 97.500% | Wgt Acc: 98.562%
