Tue Oct 18 20:12:35 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.2, 0.25, 0.2, 0.25, 0.08], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 4, 'doubleClasses': [1, 2], 'fixedDataset': True, 'loadData2memory': True, 'multiplyData': False, 'tossFirstLastFrames': True}, 'dataPath': '/data/processed/Kinetics/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat'], 'lastLayerInitUniform': True, 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 70.33639143730886, 'maxValidationTrainNo': 39, 'modelVersion': 10, 'multiStageModelList': [6, 7], 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 42, 'validationAccThr': 70, 'weightDecay': 0.001}
I - CONFIGURATION: {'background': [6717, 104557, 117656, 118800, 12379, 126138, 133287, 135007, 141242, 144859, 46195, 46587, 77996, 98407], 'pull ups': [1466, 4735, 9363, 100435, 102041, 10225, 102947, 103716, 104734, 105033, 10560, 106340, 109059, 109641, 109703, 111345, 117580, 119571, 119672, 122762, 123022, 123478, 124666, 12635, 129261, 12966, 129753, 130508, 131478, 132213, 133243, 135288, 135611, 135763, 136798, 138779, 13934, 141056, 141652, 142917, 146622, 147919, 148588, 149022, 149145, 15832, 158879, 159023, 159709, 164471, 174922, 175015, 175601, 175837, 177131, 179636, 181907, 185449, 186289, 187166, 188352, 191254, 201928, 202460, 202742, 203196, 210375, 213343, 213832, 216082, 218783, 218869, 219024, 27502, 30141, 32450, 34307, 35192, 35469, 37937, 42237, 43359, 43561, 53750, 54715, 60242, 61148, 65757, 67801, 68225, 70288, 71340, 71574, 72992, 73680, 74104, 74587, 74618, 75408, 77194, 81119, 83857, 86305, 86583, 86944, 87697, 90088, 91254, 91916], 'push up': [790, 1376, 1603, 2377, 2750, 4599, 5166, 6351, 7888, 8059, 102124, 103237, 105800, 106743, 107365, 111006, 114150, 116746, 117373, 119751, 123552, 124724, 127391, 12777, 128686, 131204, 134202, 138067, 142848, 145566, 150321, 155706, 156714, 15810, 15892, 162251, 162602, 162736, 16319, 16663, 16730, 167610, 167928, 168786, 170519, 170933, 17129, 172521, 173206, 174806, 183725, 186930, 187541, 190408, 191107, 197324, 199276, 203358, 204694, 207133, 208126, 209276, 209796, 210367, 210667, 213350, 218691, 219325, 23397, 29694, 37645, 38840, 46952, 47445, 48601, 48658, 50008, 52236, 52467, 52900, 53520, 55638, 55682, 59738, 61515, 62146, 62281, 72963, 74435, 74462, 75827, 78477, 78856, 79602, 79984, 83353, 85540, 91035, 92263, 97051, 99142], 'situp': [1055, 2266, 4304, 6078, 7337, 100065, 102891, 104650, 107273, 107851, 108111, 10812, 108505, 109397, 110563, 111111, 111478, 112311, 113868, 114249, 114806, 116566, 116875, 117511, 11801, 118772, 119784, 120384, 123275, 123658, 124222, 126160, 126270, 127277, 128880, 128907, 129493, 129720, 131406, 132060, 133096, 134974, 136812, 137005, 137612, 137882, 139213, 141774, 14206, 143300, 143548, 143934, 14494, 145544, 145953, 147146, 148867, 149066, 149252, 149654, 150259, 150302, 153122, 153227, 153691, 156335, 159646, 160557, 16466, 166424, 169419, 170487, 170628, 171290, 172016, 174857, 177150, 177829, 179891, 180278, 180585, 181684, 181706, 182300, 183368, 183863, 184207, 184593, 184957, 186845, 187706, 187731, 188119, 188206, 189995, 190008, 190573, 190974, 191164, 191208, 191236, 19150, 192699, 193865, 193967, 19414, 195064, 195797, 196874, 19720, 197631, 199326, 199590, 200068, 202952, 204138, 207569, 207605, 209000, 20909, 209637, 209970, 212019, 212142, 213373, 214038, 215579, 216500, 216585, 217089, 23537, 24779, 25129, 25863, 26253, 27849, 28232, 29356, 31966, 32607, 33814, 33943, 33980, 34065, 35811, 36921, 37090, 38130, 39060, 40342, 41741, 42035, 43028, 43224, 44043, 45388, 45595, 46880, 47767, 49078, 51658, 52742, 53045, 53413, 53513, 54037, 56415, 57137, 58072, 58816, 59113, 62391, 64925, 66736, 68754, 71858, 72809, 74758, 74854, 75001, 77120, 77245, 78401, 78882, 78966, 80218, 82439, 84326, 86384, 91813, 92396, 94219, 95689, 98098, 99540], 'squat': [215, 909, 3104, 3412, 3874, 4090, 4780, 5263, 5335, 5871, 6372, 6376, 9404, 101769, 103303, 103599, 103888, 10452, 105075, 105187, 105705, 106330, 107185, 109752, 109807, 110159, 110534, 112017, 112018, 112173, 112319, 112506, 112842, 113334, 114681, 115030, 115093, 115386, 118011, 118149, 118191, 118592, 119202, 119505, 12063, 120751, 120752, 12135, 121653, 122418, 123235, 123237, 124365, 124379, 124381, 126146, 126727, 127111, 128631, 129484, 130633, 131213, 131499, 131502, 132036, 132243, 133907, 133947, 13397, 134955, 137236, 140543, 140610, 141399, 142777, 143184, 143512, 143925, 144349, 144352, 14614, 146153, 14615, 146977, 147684, 147886, 147904, 148783, 149752, 151859, 152117, 153603, 15417, 154652, 155334, 156285, 156287, 156588, 15807, 158190, 158219, 158642, 158969, 159204, 159443, 159832, 162160, 162750, 16390, 165228, 166328, 166567, 168765, 169224, 169473, 169907, 170431, 170738, 171418, 172115, 172146, 173139, 173316, 173967, 174116, 174855, 175040, 175699, 175768, 175771, 179253, 181702, 182061, 182062, 182916, 183802, 184090, 185433, 186723, 186794, 186886, 188017, 188391, 188392, 189690, 190146, 190188, 191780, 192239, 196272, 196437, 199877, 199881, 20076, 20078, 201326, 203580, 203768, 203799, 204217, 20495, 204978, 207543, 207582, 207586, 207854, 208375, 208385, 208803, 209226, 210596, 211423, 212103, 212420, 212471, 212472, 212870, 213655, 213946, 215180, 215592, 21631, 217382, 217548, 218504, 218729, 219686, 23241, 23477, 23479, 23978, 24358, 24519, 26198, 28238, 28403, 28628, 30376, 31045, 31410, 32637, 32652, 33136, 33339, 34215, 34314, 35111, 36104, 36106, 37331, 38749, 38864, 39181, 39506, 39903, 40063, 40087, 40877, 41372, 41448, 43573, 43792, 43795, 45193, 45888, 47014, 47275, 47663, 47708, 48670, 49026, 49355, 50029, 50865, 51112, 51116, 51544, 51686, 52267, 52930, 53042, 53203, 54936, 54938, 55552, 56691, 57924, 60772, 61689, 61813, 62036, 62510, 62637, 63445, 63656, 63976, 66228, 67972, 69578, 71206, 71931, 72878, 72964, 72966, 75573, 77471, 78072, 78438, 78623, 78865, 79453, 79697, 80281, 80282, 81787, 82866, 83151, 83559, 84713, 85369, 85420, 85988, 87453, 88421, 88446, 89332, 90414, 91106, 91785, 91990, 93075, 93153, 93503, 93652, 93839, 94764, 94929, 95719, 95877, 97294, 97596, 99981]}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_cls0_pull_ups00_no_samples806.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls1_push_up00_no_samples390.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls2_situp00_no_samples562.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Loading file: dataset_cls3_squat00_no_samples840.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/train
I - Train set length:  2547
I - Label distribution: [697. 578. 734. 538.]
I - ========== TEST  SET ==========
I - Loading file: dataset_test00_no_samples327.pkl in /data/processed/Kinetics/processed_4class_fixed_50frames_256x256/test
I - Test set length:  327
I - Label distribution: [88. 78. 75. 86.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(3) data number in dataset:  tensor([ 40501,   5924,  92210,  78867,  19219, 119508,  54339,  66872, 146912,
        197692, 154336, 175872,  93315,  86439, 128717, 101350])
I - Initializing model TCNv10
I - Number of Model Parameters: 169868
I - Model output shape:  torch.Size([16, 4])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv10                                   [16, 4]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          --
│    └─ReLU: 2-1673                      [16, 64, 64, 64]          --
│    └─Conv2d: 2-2                       --                        3,136
│    └─BatchNorm2d: 2-1671               [16, 64, 64, 64]          --
│    └─OutputShiftSqueeze: 2-4           --                        --
│    └─One: 2-5                          [1]                       --
│    └─Scaler: 2-1672                    [16, 64, 64, 64]          --
│    └─OutputScale: 2-7                  --                        --
│    └─Empty: 2-8                        [64, 48, 1, 1]            --
│    └─Empty: 2-9                        [64, 48, 1, 1]            --
│    └─Empty: 2-10                       [64]                      --
│    └─Empty: 2-11                       [64]                      --
│    └─BatchNorm2d: 2-12                 [16, 64, 64, 64]          --
│    └─Scaler: 2-13                      [16, 64, 64, 64]          --
│    └─Empty: 2-14                       --                        --
│    └─Empty: 2-15                       --                        --
│    └─ReLU: 2-16                        [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1685                      [16, 64, 64, 64]          --
│    └─Conv2d: 2-18                      --                        36,928
│    └─BatchNorm2d: 2-1683               [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-20                       [16, 64, 64, 64]          --
│    └─Clamp: 2-21                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1684                    [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-23          --                        --
│    └─One: 2-24                         [1]                       --
│    └─OutputScale: 2-25                 --                        --
│    └─Empty: 2-26                       [64, 64, 3, 3]            --
│    └─Empty: 2-27                       [64, 64, 3, 3]            --
│    └─Empty: 2-28                       [64]                      --
│    └─Empty: 2-29                       [64]                      --
│    └─BatchNorm2d: 2-30                 [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-127        [16, 64, 32, 32]          (recursive)
│    └─ReLU: 2-1700                      [16, 64, 32, 32]          --
│    └─MaxPool2d: 2-1688                 [16, 64, 32, 32]          --
│    └─Conv2d: 2-33                      --                        36,928
│    └─BatchNorm2d: 2-1698               [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-35                      [16, 64, 64, 64]          --
│    └─ReLU: 2-36                        [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1699                    [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-38                       [16, 64, 64, 64]          --
│    └─Clamp: 2-39                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-4          [16, 64, 32, 32]          32,774
│    └─MaxPool2d: 2-40                   [16, 64, 32, 32]          --
│    └─Empty: 2-41                       [16, 64, 32, 32]          --
│    └─Empty: 2-42                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-43          --                        --
│    └─Empty: 2-1689                     [16, 64, 32, 32]          --
│    └─Empty: 2-1690                     [16, 64, 32, 32]          --
│    └─One: 2-46                         [1]                       --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1712                      [16, 64, 32, 32]          --
│    └─Conv2d: 2-48                      --                        4,160
│    └─BatchNorm2d: 2-1710               [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-50                 --                        --
│    └─Empty: 2-51                       [64, 64, 3, 3]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1711                    [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-53                       [64, 64, 3, 3]            --
│    └─Empty: 2-54                       [64]                      --
│    └─Empty: 2-55                       [64]                      --
│    └─BatchNorm2d: 2-56                 [16, 64, 32, 32]          --
│    └─Scaler: 2-57                      [16, 64, 32, 32]          --
│    └─ReLU: 2-58                        [16, 64, 32, 32]          --
│    └─Empty: 2-59                       [16, 64, 32, 32]          --
│    └─Clamp: 2-60                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-5                 [16, 64, 32, 32]          4,166
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 64, 32, 32]          (recursive)
│    └─ReLU: 2-1727                      [16, 64, 32, 32]          --
│    └─MaxPool2d: 2-1715                 [16, 64, 32, 32]          --
│    └─Conv2d: 2-63                      --                        36,928
│    └─BatchNorm2d: 2-1725               [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1726                    [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-68                 --                        --
│    └─Empty: 2-69                       [64, 64, 1, 1]            --
│    └─Empty: 2-70                       [64, 64, 1, 1]            --
│    └─Empty: 2-71                       [64]                      --
│    └─Empty: 2-72                       [64]                      --
│    └─BatchNorm2d: 2-73                 [16, 64, 32, 32]          --
│    └─Scaler: 2-74                      [16, 64, 32, 32]          --
│    └─ReLU: 2-75                        [16, 64, 32, 32]          --
│    └─Empty: 2-76                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 16, 16]          (recursive)
│    └─ReLU: 2-1742                      [16, 64, 16, 16]          --
│    └─MaxPool2d: 2-1730                 [16, 64, 16, 16]          --
│    └─Conv2d: 2-79                      --                        36,928
│    └─BatchNorm2d: 2-1740               [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-81                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-8          [16, 64, 32, 32]          36,674
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1741                    [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─MaxPool2d: 2-83                   [16, 64, 32, 32]          --
│    └─Empty: 2-84                       [16, 64, 32, 32]          --
│    └─Empty: 2-85                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-86          --                        --
│    └─One: 2-87                         [1]                       --
│    └─OutputScale: 2-88                 --                        --
│    └─Empty: 2-89                       [64, 64, 3, 3]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-1731                     [16, 64, 16, 16]          --
│    └─Empty: 2-1732                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-92                       [64, 64, 3, 3]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─ReLU: 2-1754                      [16, 4, 16, 16]           --
│    └─Conv2d: 2-94                      --                        260
│    └─BatchNorm2d: 2-1752               [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-96                       [64]                      --
│    └─Empty: 2-97                       [64]                      --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-1753                    [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─BatchNorm2d: 2-99                 [16, 64, 32, 32]          --
│    └─Scaler: 2-100                     [16, 64, 32, 32]          --
│    └─ReLU: 2-101                       [16, 64, 32, 32]          --
│    └─Empty: 2-102                      [16, 64, 32, 32]          --
│    └─Clamp: 2-103                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-104                  [16, 64, 16, 16]          --
│    └─Empty: 2-105                      [16, 64, 16, 16]          --
│    └─Empty: 2-106                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 4, 16, 16]           (recursive)
│    └─ReLU: 2-1769                      [16, 4, 16, 16]           --
│    └─MaxPool2d: 2-1757                 [16, 64, 16, 16]          --
│    └─Conv2d: 2-109                     --                        2,308
│    └─BatchNorm2d: 2-1767               [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputShiftSqueeze: 2-111         --                        --
│    └─One: 2-112                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Scaler: 2-1768                    [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-114                --                        --
│    └─Empty: 2-115                      [64, 64, 3, 3]            --
│    └─Empty: 2-116                      [64, 64, 3, 3]            --
│    └─Empty: 2-117                      [64]                      --
│    └─Empty: 2-118                      [64]                      --
│    └─BatchNorm2d: 2-119                [16, 64, 16, 16]          --
│    └─Scaler: 2-120                     [16, 64, 16, 16]          --
│    └─ReLU: 2-121                       [16, 64, 16, 16]          --
│    └─Empty: 2-122                      [16, 64, 16, 16]          --
│    └─Clamp: 2-123                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-11                [16, 4, 16, 16]           266
│    └─OutputShiftSqueeze: 2-124         --                        --
│    └─One: 2-125                        [1]                       --
│    └─OutputScale: 2-126                --                        --
├─Conv1d: 1                              --                        --
│    └─Scaler: 2-1779                    [16, 4, 14]               --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-128                      [4, 64, 1, 1]             --
│    └─Empty: 2-129                      [4, 64, 1, 1]             --
│    └─Empty: 2-130                      [4]                       --
│    └─Empty: 2-131                      [4]                       --
│    └─BatchNorm2d: 2-132                [16, 4, 16, 16]           --
│    └─Scaler: 2-133                     [16, 4, 16, 16]           --
│    └─ReLU: 2-134                       [16, 4, 16, 16]           --
│    └─Empty: 2-135                      [16, 4, 16, 16]           --
│    └─Clamp: 2-136                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 4, 16, 16]           2,314
│    └─MaxPool2d: 2-137                  [16, 64, 16, 16]          --
│    └─Empty: 2-138                      [16, 64, 16, 16]          --
│    └─Empty: 2-139                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-140         --                        --
│    └─One: 2-141                        [1]                       --
│    └─OutputScale: 2-142                --                        --
│    └─Empty: 2-143                      [4, 64, 3, 3]             --
│    └─Empty: 2-144                      [4, 64, 3, 3]             --
│    └─Empty: 2-145                      [4]                       --
│    └─Empty: 2-146                      [4]                       --
│    └─BatchNorm2d: 2-147                [16, 4, 16, 16]           --
│    └─Scaler: 2-148                     [16, 4, 16, 16]           --
│    └─ReLU: 2-149                       [16, 4, 16, 16]           --
│    └─Empty: 2-150                      [16, 4, 16, 16]           --
│    └─Clamp: 2-151                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-13                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-152         --                        --
│    └─One: 2-153                        [1]                       --
│    └─OutputScale: 2-154                --                        --
│    └─Empty: 2-155                      [64, 48, 1, 1]            --
│    └─Empty: 2-156                      [64, 48, 1, 1]            --
│    └─Empty: 2-157                      [64]                      --
│    └─Empty: 2-158                      [64]                      --
│    └─BatchNorm2d: 2-159                [16, 64, 64, 64]          --
│    └─Scaler: 2-160                     [16, 64, 64, 64]          --
│    └─ReLU: 2-161                       [16, 64, 64, 64]          --
│    └─Empty: 2-162                      [16, 64, 64, 64]          --
│    └─Clamp: 2-163                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-14                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-164         --                        --
│    └─One: 2-165                        [1]                       --
│    └─OutputScale: 2-166                --                        --
│    └─Empty: 2-167                      [64, 64, 3, 3]            --
│    └─Empty: 2-168                      [64, 64, 3, 3]            --
│    └─Empty: 2-169                      [64]                      --
│    └─Empty: 2-170                      [64]                      --
│    └─BatchNorm2d: 2-171                [16, 64, 64, 64]          --
│    └─Scaler: 2-172                     [16, 64, 64, 64]          --
│    └─ReLU: 2-173                       [16, 64, 64, 64]          --
│    └─Empty: 2-174                      [16, 64, 64, 64]          --
│    └─Clamp: 2-175                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-176                  [16, 64, 32, 32]          --
│    └─Empty: 2-177                      [16, 64, 32, 32]          --
│    └─Empty: 2-178                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-179         --                        --
│    └─One: 2-180                        [1]                       --
│    └─OutputScale: 2-181                --                        --
│    └─Empty: 2-182                      [64, 64, 3, 3]            --
│    └─Empty: 2-183                      [64, 64, 3, 3]            --
│    └─Empty: 2-184                      [64]                      --
│    └─Empty: 2-185                      [64]                      --
│    └─BatchNorm2d: 2-186                [16, 64, 32, 32]          --
│    └─Scaler: 2-187                     [16, 64, 32, 32]          --
│    └─ReLU: 2-188                       [16, 64, 32, 32]          --
│    └─Empty: 2-189                      [16, 64, 32, 32]          --
│    └─Clamp: 2-190                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-16                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-191         --                        --
│    └─One: 2-192                        [1]                       --
│    └─OutputScale: 2-193                --                        --
│    └─Empty: 2-194                      [64, 64, 1, 1]            --
│    └─Empty: 2-195                      [64, 64, 1, 1]            --
│    └─Empty: 2-196                      [64]                      --
│    └─Empty: 2-197                      [64]                      --
│    └─BatchNorm2d: 2-198                [16, 64, 32, 32]          --
│    └─Scaler: 2-199                     [16, 64, 32, 32]          --
│    └─ReLU: 2-200                       [16, 64, 32, 32]          --
│    └─Empty: 2-201                      [16, 64, 32, 32]          --
│    └─Clamp: 2-202                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-203                  [16, 64, 32, 32]          --
│    └─Empty: 2-204                      [16, 64, 32, 32]          --
│    └─Empty: 2-205                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-206         --                        --
│    └─One: 2-207                        [1]                       --
│    └─OutputScale: 2-208                --                        --
│    └─Empty: 2-209                      [64, 64, 3, 3]            --
│    └─Empty: 2-210                      [64, 64, 3, 3]            --
│    └─Empty: 2-211                      [64]                      --
│    └─Empty: 2-212                      [64]                      --
│    └─BatchNorm2d: 2-213                [16, 64, 32, 32]          --
│    └─Scaler: 2-214                     [16, 64, 32, 32]          --
│    └─ReLU: 2-215                       [16, 64, 32, 32]          --
│    └─Empty: 2-216                      [16, 64, 32, 32]          --
│    └─Clamp: 2-217                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-18         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-218                  [16, 64, 16, 16]          --
│    └─Empty: 2-219                      [16, 64, 16, 16]          --
│    └─Empty: 2-220                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-221         --                        --
│    └─One: 2-222                        [1]                       --
│    └─OutputScale: 2-223                --                        --
│    └─Empty: 2-224                      [64, 64, 3, 3]            --
│    └─Empty: 2-225                      [64, 64, 3, 3]            --
│    └─Empty: 2-226                      [64]                      --
│    └─Empty: 2-227                      [64]                      --
│    └─BatchNorm2d: 2-228                [16, 64, 16, 16]          --
│    └─Scaler: 2-229                     [16, 64, 16, 16]          --
│    └─ReLU: 2-230                       [16, 64, 16, 16]          --
│    └─Empty: 2-231                      [16, 64, 16, 16]          --
│    └─Clamp: 2-232                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-19                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-233         --                        --
│    └─One: 2-234                        [1]                       --
│    └─OutputScale: 2-235                --                        --
│    └─Empty: 2-236                      [4, 64, 1, 1]             --
│    └─Empty: 2-237                      [4, 64, 1, 1]             --
│    └─Empty: 2-238                      [4]                       --
│    └─Empty: 2-239                      [4]                       --
│    └─BatchNorm2d: 2-240                [16, 4, 16, 16]           --
│    └─Scaler: 2-241                     [16, 4, 16, 16]           --
│    └─ReLU: 2-242                       [16, 4, 16, 16]           --
│    └─Empty: 2-243                      [16, 4, 16, 16]           --
│    └─Clamp: 2-244                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-20         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-245                  [16, 64, 16, 16]          --
│    └─Empty: 2-246                      [16, 64, 16, 16]          --
│    └─Empty: 2-247                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-248         --                        --
│    └─One: 2-249                        [1]                       --
│    └─OutputScale: 2-250                --                        --
│    └─Empty: 2-251                      [4, 64, 3, 3]             --
│    └─Empty: 2-252                      [4, 64, 3, 3]             --
│    └─Empty: 2-253                      [4]                       --
│    └─Empty: 2-254                      [4]                       --
│    └─BatchNorm2d: 2-255                [16, 4, 16, 16]           --
│    └─Scaler: 2-256                     [16, 4, 16, 16]           --
│    └─ReLU: 2-257                       [16, 4, 16, 16]           --
│    └─Empty: 2-258                      [16, 4, 16, 16]           --
│    └─Clamp: 2-259                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-260         --                        --
│    └─One: 2-261                        [1]                       --
│    └─OutputScale: 2-262                --                        --
│    └─Empty: 2-263                      [64, 48, 1, 1]            --
│    └─Empty: 2-264                      [64, 48, 1, 1]            --
│    └─Empty: 2-265                      [64]                      --
│    └─Empty: 2-266                      [64]                      --
│    └─BatchNorm2d: 2-267                [16, 64, 64, 64]          --
│    └─Scaler: 2-268                     [16, 64, 64, 64]          --
│    └─ReLU: 2-269                       [16, 64, 64, 64]          --
│    └─Empty: 2-270                      [16, 64, 64, 64]          --
│    └─Clamp: 2-271                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-22                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-272         --                        --
│    └─One: 2-273                        [1]                       --
│    └─OutputScale: 2-274                --                        --
│    └─Empty: 2-275                      [64, 64, 3, 3]            --
│    └─Empty: 2-276                      [64, 64, 3, 3]            --
│    └─Empty: 2-277                      [64]                      --
│    └─Empty: 2-278                      [64]                      --
│    └─BatchNorm2d: 2-279                [16, 64, 64, 64]          --
│    └─Scaler: 2-280                     [16, 64, 64, 64]          --
│    └─ReLU: 2-281                       [16, 64, 64, 64]          --
│    └─Empty: 2-282                      [16, 64, 64, 64]          --
│    └─Clamp: 2-283                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-23         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-284                  [16, 64, 32, 32]          --
│    └─Empty: 2-285                      [16, 64, 32, 32]          --
│    └─Empty: 2-286                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-287         --                        --
│    └─One: 2-288                        [1]                       --
│    └─OutputScale: 2-289                --                        --
│    └─Empty: 2-290                      [64, 64, 3, 3]            --
│    └─Empty: 2-291                      [64, 64, 3, 3]            --
│    └─Empty: 2-292                      [64]                      --
│    └─Empty: 2-293                      [64]                      --
│    └─BatchNorm2d: 2-294                [16, 64, 32, 32]          --
│    └─Scaler: 2-295                     [16, 64, 32, 32]          --
│    └─ReLU: 2-296                       [16, 64, 32, 32]          --
│    └─Empty: 2-297                      [16, 64, 32, 32]          --
│    └─Clamp: 2-298                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-24                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-299         --                        --
│    └─One: 2-300                        [1]                       --
│    └─OutputScale: 2-301                --                        --
│    └─Empty: 2-302                      [64, 64, 1, 1]            --
│    └─Empty: 2-303                      [64, 64, 1, 1]            --
│    └─Empty: 2-304                      [64]                      --
│    └─Empty: 2-305                      [64]                      --
│    └─BatchNorm2d: 2-306                [16, 64, 32, 32]          --
│    └─Scaler: 2-307                     [16, 64, 32, 32]          --
│    └─ReLU: 2-308                       [16, 64, 32, 32]          --
│    └─Empty: 2-309                      [16, 64, 32, 32]          --
│    └─Clamp: 2-310                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-25         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-311                  [16, 64, 32, 32]          --
│    └─Empty: 2-312                      [16, 64, 32, 32]          --
│    └─Empty: 2-313                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-314         --                        --
│    └─One: 2-315                        [1]                       --
│    └─OutputScale: 2-316                --                        --
│    └─Empty: 2-317                      [64, 64, 3, 3]            --
│    └─Empty: 2-318                      [64, 64, 3, 3]            --
│    └─Empty: 2-319                      [64]                      --
│    └─Empty: 2-320                      [64]                      --
│    └─BatchNorm2d: 2-321                [16, 64, 32, 32]          --
│    └─Scaler: 2-322                     [16, 64, 32, 32]          --
│    └─ReLU: 2-323                       [16, 64, 32, 32]          --
│    └─Empty: 2-324                      [16, 64, 32, 32]          --
│    └─Clamp: 2-325                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-326                  [16, 64, 16, 16]          --
│    └─Empty: 2-327                      [16, 64, 16, 16]          --
│    └─Empty: 2-328                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-329         --                        --
│    └─One: 2-330                        [1]                       --
│    └─OutputScale: 2-331                --                        --
│    └─Empty: 2-332                      [64, 64, 3, 3]            --
│    └─Empty: 2-333                      [64, 64, 3, 3]            --
│    └─Empty: 2-334                      [64]                      --
│    └─Empty: 2-335                      [64]                      --
│    └─BatchNorm2d: 2-336                [16, 64, 16, 16]          --
│    └─Scaler: 2-337                     [16, 64, 16, 16]          --
│    └─ReLU: 2-338                       [16, 64, 16, 16]          --
│    └─Empty: 2-339                      [16, 64, 16, 16]          --
│    └─Clamp: 2-340                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-27                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-341         --                        --
│    └─One: 2-342                        [1]                       --
│    └─OutputScale: 2-343                --                        --
│    └─Empty: 2-344                      [4, 64, 1, 1]             --
│    └─Empty: 2-345                      [4, 64, 1, 1]             --
│    └─Empty: 2-346                      [4]                       --
│    └─Empty: 2-347                      [4]                       --
│    └─BatchNorm2d: 2-348                [16, 4, 16, 16]           --
│    └─Scaler: 2-349                     [16, 4, 16, 16]           --
│    └─ReLU: 2-350                       [16, 4, 16, 16]           --
│    └─Empty: 2-351                      [16, 4, 16, 16]           --
│    └─Clamp: 2-352                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-353                  [16, 64, 16, 16]          --
│    └─Empty: 2-354                      [16, 64, 16, 16]          --
│    └─Empty: 2-355                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-356         --                        --
│    └─One: 2-357                        [1]                       --
│    └─OutputScale: 2-358                --                        --
│    └─Empty: 2-359                      [4, 64, 3, 3]             --
│    └─Empty: 2-360                      [4, 64, 3, 3]             --
│    └─Empty: 2-361                      [4]                       --
│    └─Empty: 2-362                      [4]                       --
│    └─BatchNorm2d: 2-363                [16, 4, 16, 16]           --
│    └─Scaler: 2-364                     [16, 4, 16, 16]           --
│    └─ReLU: 2-365                       [16, 4, 16, 16]           --
│    └─Empty: 2-366                      [16, 4, 16, 16]           --
│    └─Clamp: 2-367                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-29                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-368         --                        --
│    └─One: 2-369                        [1]                       --
│    └─OutputScale: 2-370                --                        --
│    └─Empty: 2-371                      [64, 48, 1, 1]            --
│    └─Empty: 2-372                      [64, 48, 1, 1]            --
│    └─Empty: 2-373                      [64]                      --
│    └─Empty: 2-374                      [64]                      --
│    └─BatchNorm2d: 2-375                [16, 64, 64, 64]          --
│    └─Scaler: 2-376                     [16, 64, 64, 64]          --
│    └─ReLU: 2-377                       [16, 64, 64, 64]          --
│    └─Empty: 2-378                      [16, 64, 64, 64]          --
│    └─Clamp: 2-379                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-30                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-380         --                        --
│    └─One: 2-381                        [1]                       --
│    └─OutputScale: 2-382                --                        --
│    └─Empty: 2-383                      [64, 64, 3, 3]            --
│    └─Empty: 2-384                      [64, 64, 3, 3]            --
│    └─Empty: 2-385                      [64]                      --
│    └─Empty: 2-386                      [64]                      --
│    └─BatchNorm2d: 2-387                [16, 64, 64, 64]          --
│    └─Scaler: 2-388                     [16, 64, 64, 64]          --
│    └─ReLU: 2-389                       [16, 64, 64, 64]          --
│    └─Empty: 2-390                      [16, 64, 64, 64]          --
│    └─Clamp: 2-391                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-392                  [16, 64, 32, 32]          --
│    └─Empty: 2-393                      [16, 64, 32, 32]          --
│    └─Empty: 2-394                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-395         --                        --
│    └─One: 2-396                        [1]                       --
│    └─OutputScale: 2-397                --                        --
│    └─Empty: 2-398                      [64, 64, 3, 3]            --
│    └─Empty: 2-399                      [64, 64, 3, 3]            --
│    └─Empty: 2-400                      [64]                      --
│    └─Empty: 2-401                      [64]                      --
│    └─BatchNorm2d: 2-402                [16, 64, 32, 32]          --
│    └─Scaler: 2-403                     [16, 64, 32, 32]          --
│    └─ReLU: 2-404                       [16, 64, 32, 32]          --
│    └─Empty: 2-405                      [16, 64, 32, 32]          --
│    └─Clamp: 2-406                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-32                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-407         --                        --
│    └─One: 2-408                        [1]                       --
│    └─OutputScale: 2-409                --                        --
│    └─Empty: 2-410                      [64, 64, 1, 1]            --
│    └─Empty: 2-411                      [64, 64, 1, 1]            --
│    └─Empty: 2-412                      [64]                      --
│    └─Empty: 2-413                      [64]                      --
│    └─BatchNorm2d: 2-414                [16, 64, 32, 32]          --
│    └─Scaler: 2-415                     [16, 64, 32, 32]          --
│    └─ReLU: 2-416                       [16, 64, 32, 32]          --
│    └─Empty: 2-417                      [16, 64, 32, 32]          --
│    └─Clamp: 2-418                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-33         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-419                  [16, 64, 32, 32]          --
│    └─Empty: 2-420                      [16, 64, 32, 32]          --
│    └─Empty: 2-421                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-422         --                        --
│    └─One: 2-423                        [1]                       --
│    └─OutputScale: 2-424                --                        --
│    └─Empty: 2-425                      [64, 64, 3, 3]            --
│    └─Empty: 2-426                      [64, 64, 3, 3]            --
│    └─Empty: 2-427                      [64]                      --
│    └─Empty: 2-428                      [64]                      --
│    └─BatchNorm2d: 2-429                [16, 64, 32, 32]          --
│    └─Scaler: 2-430                     [16, 64, 32, 32]          --
│    └─ReLU: 2-431                       [16, 64, 32, 32]          --
│    └─Empty: 2-432                      [16, 64, 32, 32]          --
│    └─Clamp: 2-433                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-434                  [16, 64, 16, 16]          --
│    └─Empty: 2-435                      [16, 64, 16, 16]          --
│    └─Empty: 2-436                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-437         --                        --
│    └─One: 2-438                        [1]                       --
│    └─OutputScale: 2-439                --                        --
│    └─Empty: 2-440                      [64, 64, 3, 3]            --
│    └─Empty: 2-441                      [64, 64, 3, 3]            --
│    └─Empty: 2-442                      [64]                      --
│    └─Empty: 2-443                      [64]                      --
│    └─BatchNorm2d: 2-444                [16, 64, 16, 16]          --
│    └─Scaler: 2-445                     [16, 64, 16, 16]          --
│    └─ReLU: 2-446                       [16, 64, 16, 16]          --
│    └─Empty: 2-447                      [16, 64, 16, 16]          --
│    └─Clamp: 2-448                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-35                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-449         --                        --
│    └─One: 2-450                        [1]                       --
│    └─OutputScale: 2-451                --                        --
│    └─Empty: 2-452                      [4, 64, 1, 1]             --
│    └─Empty: 2-453                      [4, 64, 1, 1]             --
│    └─Empty: 2-454                      [4]                       --
│    └─Empty: 2-455                      [4]                       --
│    └─BatchNorm2d: 2-456                [16, 4, 16, 16]           --
│    └─Scaler: 2-457                     [16, 4, 16, 16]           --
│    └─ReLU: 2-458                       [16, 4, 16, 16]           --
│    └─Empty: 2-459                      [16, 4, 16, 16]           --
│    └─Clamp: 2-460                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-36         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-461                  [16, 64, 16, 16]          --
│    └─Empty: 2-462                      [16, 64, 16, 16]          --
│    └─Empty: 2-463                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-464         --                        --
│    └─One: 2-465                        [1]                       --
│    └─OutputScale: 2-466                --                        --
│    └─Empty: 2-467                      [4, 64, 3, 3]             --
│    └─Empty: 2-468                      [4, 64, 3, 3]             --
│    └─Empty: 2-469                      [4]                       --
│    └─Empty: 2-470                      [4]                       --
│    └─BatchNorm2d: 2-471                [16, 4, 16, 16]           --
│    └─Scaler: 2-472                     [16, 4, 16, 16]           --
│    └─ReLU: 2-473                       [16, 4, 16, 16]           --
│    └─Empty: 2-474                      [16, 4, 16, 16]           --
│    └─Clamp: 2-475                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-476         --                        --
│    └─One: 2-477                        [1]                       --
│    └─OutputScale: 2-478                --                        --
│    └─Empty: 2-479                      [64, 48, 1, 1]            --
│    └─Empty: 2-480                      [64, 48, 1, 1]            --
│    └─Empty: 2-481                      [64]                      --
│    └─Empty: 2-482                      [64]                      --
│    └─BatchNorm2d: 2-483                [16, 64, 64, 64]          --
│    └─Scaler: 2-484                     [16, 64, 64, 64]          --
│    └─ReLU: 2-485                       [16, 64, 64, 64]          --
│    └─Empty: 2-486                      [16, 64, 64, 64]          --
│    └─Clamp: 2-487                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-488         --                        --
│    └─One: 2-489                        [1]                       --
│    └─OutputScale: 2-490                --                        --
│    └─Empty: 2-491                      [64, 64, 3, 3]            --
│    └─Empty: 2-492                      [64, 64, 3, 3]            --
│    └─Empty: 2-493                      [64]                      --
│    └─Empty: 2-494                      [64]                      --
│    └─BatchNorm2d: 2-495                [16, 64, 64, 64]          --
│    └─Scaler: 2-496                     [16, 64, 64, 64]          --
│    └─ReLU: 2-497                       [16, 64, 64, 64]          --
│    └─Empty: 2-498                      [16, 64, 64, 64]          --
│    └─Clamp: 2-499                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-500                  [16, 64, 32, 32]          --
│    └─Empty: 2-501                      [16, 64, 32, 32]          --
│    └─Empty: 2-502                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-503         --                        --
│    └─One: 2-504                        [1]                       --
│    └─OutputScale: 2-505                --                        --
│    └─Empty: 2-506                      [64, 64, 3, 3]            --
│    └─Empty: 2-507                      [64, 64, 3, 3]            --
│    └─Empty: 2-508                      [64]                      --
│    └─Empty: 2-509                      [64]                      --
│    └─BatchNorm2d: 2-510                [16, 64, 32, 32]          --
│    └─Scaler: 2-511                     [16, 64, 32, 32]          --
│    └─ReLU: 2-512                       [16, 64, 32, 32]          --
│    └─Empty: 2-513                      [16, 64, 32, 32]          --
│    └─Clamp: 2-514                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-515         --                        --
│    └─One: 2-516                        [1]                       --
│    └─OutputScale: 2-517                --                        --
│    └─Empty: 2-518                      [64, 64, 1, 1]            --
│    └─Empty: 2-519                      [64, 64, 1, 1]            --
│    └─Empty: 2-520                      [64]                      --
│    └─Empty: 2-521                      [64]                      --
│    └─BatchNorm2d: 2-522                [16, 64, 32, 32]          --
│    └─Scaler: 2-523                     [16, 64, 32, 32]          --
│    └─ReLU: 2-524                       [16, 64, 32, 32]          --
│    └─Empty: 2-525                      [16, 64, 32, 32]          --
│    └─Clamp: 2-526                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-527                  [16, 64, 32, 32]          --
│    └─Empty: 2-528                      [16, 64, 32, 32]          --
│    └─Empty: 2-529                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-530         --                        --
│    └─One: 2-531                        [1]                       --
│    └─OutputScale: 2-532                --                        --
│    └─Empty: 2-533                      [64, 64, 3, 3]            --
│    └─Empty: 2-534                      [64, 64, 3, 3]            --
│    └─Empty: 2-535                      [64]                      --
│    └─Empty: 2-536                      [64]                      --
│    └─BatchNorm2d: 2-537                [16, 64, 32, 32]          --
│    └─Scaler: 2-538                     [16, 64, 32, 32]          --
│    └─ReLU: 2-539                       [16, 64, 32, 32]          --
│    └─Empty: 2-540                      [16, 64, 32, 32]          --
│    └─Clamp: 2-541                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-42         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-542                  [16, 64, 16, 16]          --
│    └─Empty: 2-543                      [16, 64, 16, 16]          --
│    └─Empty: 2-544                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-545         --                        --
│    └─One: 2-546                        [1]                       --
│    └─OutputScale: 2-547                --                        --
│    └─Empty: 2-548                      [64, 64, 3, 3]            --
│    └─Empty: 2-549                      [64, 64, 3, 3]            --
│    └─Empty: 2-550                      [64]                      --
│    └─Empty: 2-551                      [64]                      --
│    └─BatchNorm2d: 2-552                [16, 64, 16, 16]          --
│    └─Scaler: 2-553                     [16, 64, 16, 16]          --
│    └─ReLU: 2-554                       [16, 64, 16, 16]          --
│    └─Empty: 2-555                      [16, 64, 16, 16]          --
│    └─Clamp: 2-556                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-43                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-557         --                        --
│    └─One: 2-558                        [1]                       --
│    └─OutputScale: 2-559                --                        --
│    └─Empty: 2-560                      [4, 64, 1, 1]             --
│    └─Empty: 2-561                      [4, 64, 1, 1]             --
│    └─Empty: 2-562                      [4]                       --
│    └─Empty: 2-563                      [4]                       --
│    └─BatchNorm2d: 2-564                [16, 4, 16, 16]           --
│    └─Scaler: 2-565                     [16, 4, 16, 16]           --
│    └─ReLU: 2-566                       [16, 4, 16, 16]           --
│    └─Empty: 2-567                      [16, 4, 16, 16]           --
│    └─Clamp: 2-568                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-44         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-569                  [16, 64, 16, 16]          --
│    └─Empty: 2-570                      [16, 64, 16, 16]          --
│    └─Empty: 2-571                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-572         --                        --
│    └─One: 2-573                        [1]                       --
│    └─OutputScale: 2-574                --                        --
│    └─Empty: 2-575                      [4, 64, 3, 3]             --
│    └─Empty: 2-576                      [4, 64, 3, 3]             --
│    └─Empty: 2-577                      [4]                       --
│    └─Empty: 2-578                      [4]                       --
│    └─BatchNorm2d: 2-579                [16, 4, 16, 16]           --
│    └─Scaler: 2-580                     [16, 4, 16, 16]           --
│    └─ReLU: 2-581                       [16, 4, 16, 16]           --
│    └─Empty: 2-582                      [16, 4, 16, 16]           --
│    └─Clamp: 2-583                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-45                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-584         --                        --
│    └─One: 2-585                        [1]                       --
│    └─OutputScale: 2-586                --                        --
│    └─Empty: 2-587                      [64, 48, 1, 1]            --
│    └─Empty: 2-588                      [64, 48, 1, 1]            --
│    └─Empty: 2-589                      [64]                      --
│    └─Empty: 2-590                      [64]                      --
│    └─BatchNorm2d: 2-591                [16, 64, 64, 64]          --
│    └─Scaler: 2-592                     [16, 64, 64, 64]          --
│    └─ReLU: 2-593                       [16, 64, 64, 64]          --
│    └─Empty: 2-594                      [16, 64, 64, 64]          --
│    └─Clamp: 2-595                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-46                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-596         --                        --
│    └─One: 2-597                        [1]                       --
│    └─OutputScale: 2-598                --                        --
│    └─Empty: 2-599                      [64, 64, 3, 3]            --
│    └─Empty: 2-600                      [64, 64, 3, 3]            --
│    └─Empty: 2-601                      [64]                      --
│    └─Empty: 2-602                      [64]                      --
│    └─BatchNorm2d: 2-603                [16, 64, 64, 64]          --
│    └─Scaler: 2-604                     [16, 64, 64, 64]          --
│    └─ReLU: 2-605                       [16, 64, 64, 64]          --
│    └─Empty: 2-606                      [16, 64, 64, 64]          --
│    └─Clamp: 2-607                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-47         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-608                  [16, 64, 32, 32]          --
│    └─Empty: 2-609                      [16, 64, 32, 32]          --
│    └─Empty: 2-610                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-611         --                        --
│    └─One: 2-612                        [1]                       --
│    └─OutputScale: 2-613                --                        --
│    └─Empty: 2-614                      [64, 64, 3, 3]            --
│    └─Empty: 2-615                      [64, 64, 3, 3]            --
│    └─Empty: 2-616                      [64]                      --
│    └─Empty: 2-617                      [64]                      --
│    └─BatchNorm2d: 2-618                [16, 64, 32, 32]          --
│    └─Scaler: 2-619                     [16, 64, 32, 32]          --
│    └─ReLU: 2-620                       [16, 64, 32, 32]          --
│    └─Empty: 2-621                      [16, 64, 32, 32]          --
│    └─Clamp: 2-622                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-48                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-623         --                        --
│    └─One: 2-624                        [1]                       --
│    └─OutputScale: 2-625                --                        --
│    └─Empty: 2-626                      [64, 64, 1, 1]            --
│    └─Empty: 2-627                      [64, 64, 1, 1]            --
│    └─Empty: 2-628                      [64]                      --
│    └─Empty: 2-629                      [64]                      --
│    └─BatchNorm2d: 2-630                [16, 64, 32, 32]          --
│    └─Scaler: 2-631                     [16, 64, 32, 32]          --
│    └─ReLU: 2-632                       [16, 64, 32, 32]          --
│    └─Empty: 2-633                      [16, 64, 32, 32]          --
│    └─Clamp: 2-634                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-635                  [16, 64, 32, 32]          --
│    └─Empty: 2-636                      [16, 64, 32, 32]          --
│    └─Empty: 2-637                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-638         --                        --
│    └─One: 2-639                        [1]                       --
│    └─OutputScale: 2-640                --                        --
│    └─Empty: 2-641                      [64, 64, 3, 3]            --
│    └─Empty: 2-642                      [64, 64, 3, 3]            --
│    └─Empty: 2-643                      [64]                      --
│    └─Empty: 2-644                      [64]                      --
│    └─BatchNorm2d: 2-645                [16, 64, 32, 32]          --
│    └─Scaler: 2-646                     [16, 64, 32, 32]          --
│    └─ReLU: 2-647                       [16, 64, 32, 32]          --
│    └─Empty: 2-648                      [16, 64, 32, 32]          --
│    └─Clamp: 2-649                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-50         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-650                  [16, 64, 16, 16]          --
│    └─Empty: 2-651                      [16, 64, 16, 16]          --
│    └─Empty: 2-652                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-653         --                        --
│    └─One: 2-654                        [1]                       --
│    └─OutputScale: 2-655                --                        --
│    └─Empty: 2-656                      [64, 64, 3, 3]            --
│    └─Empty: 2-657                      [64, 64, 3, 3]            --
│    └─Empty: 2-658                      [64]                      --
│    └─Empty: 2-659                      [64]                      --
│    └─BatchNorm2d: 2-660                [16, 64, 16, 16]          --
│    └─Scaler: 2-661                     [16, 64, 16, 16]          --
│    └─ReLU: 2-662                       [16, 64, 16, 16]          --
│    └─Empty: 2-663                      [16, 64, 16, 16]          --
│    └─Clamp: 2-664                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-51                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-665         --                        --
│    └─One: 2-666                        [1]                       --
│    └─OutputScale: 2-667                --                        --
│    └─Empty: 2-668                      [4, 64, 1, 1]             --
│    └─Empty: 2-669                      [4, 64, 1, 1]             --
│    └─Empty: 2-670                      [4]                       --
│    └─Empty: 2-671                      [4]                       --
│    └─BatchNorm2d: 2-672                [16, 4, 16, 16]           --
│    └─Scaler: 2-673                     [16, 4, 16, 16]           --
│    └─ReLU: 2-674                       [16, 4, 16, 16]           --
│    └─Empty: 2-675                      [16, 4, 16, 16]           --
│    └─Clamp: 2-676                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-52         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-677                  [16, 64, 16, 16]          --
│    └─Empty: 2-678                      [16, 64, 16, 16]          --
│    └─Empty: 2-679                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-680         --                        --
│    └─One: 2-681                        [1]                       --
│    └─OutputScale: 2-682                --                        --
│    └─Empty: 2-683                      [4, 64, 3, 3]             --
│    └─Empty: 2-684                      [4, 64, 3, 3]             --
│    └─Empty: 2-685                      [4]                       --
│    └─Empty: 2-686                      [4]                       --
│    └─BatchNorm2d: 2-687                [16, 4, 16, 16]           --
│    └─Scaler: 2-688                     [16, 4, 16, 16]           --
│    └─ReLU: 2-689                       [16, 4, 16, 16]           --
│    └─Empty: 2-690                      [16, 4, 16, 16]           --
│    └─Clamp: 2-691                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-692         --                        --
│    └─One: 2-693                        [1]                       --
│    └─OutputScale: 2-694                --                        --
│    └─Empty: 2-695                      [64, 48, 1, 1]            --
│    └─Empty: 2-696                      [64, 48, 1, 1]            --
│    └─Empty: 2-697                      [64]                      --
│    └─Empty: 2-698                      [64]                      --
│    └─BatchNorm2d: 2-699                [16, 64, 64, 64]          --
│    └─Scaler: 2-700                     [16, 64, 64, 64]          --
│    └─ReLU: 2-701                       [16, 64, 64, 64]          --
│    └─Empty: 2-702                      [16, 64, 64, 64]          --
│    └─Clamp: 2-703                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-704         --                        --
│    └─One: 2-705                        [1]                       --
│    └─OutputScale: 2-706                --                        --
│    └─Empty: 2-707                      [64, 64, 3, 3]            --
│    └─Empty: 2-708                      [64, 64, 3, 3]            --
│    └─Empty: 2-709                      [64]                      --
│    └─Empty: 2-710                      [64]                      --
│    └─BatchNorm2d: 2-711                [16, 64, 64, 64]          --
│    └─Scaler: 2-712                     [16, 64, 64, 64]          --
│    └─ReLU: 2-713                       [16, 64, 64, 64]          --
│    └─Empty: 2-714                      [16, 64, 64, 64]          --
│    └─Clamp: 2-715                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-55         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-716                  [16, 64, 32, 32]          --
│    └─Empty: 2-717                      [16, 64, 32, 32]          --
│    └─Empty: 2-718                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-719         --                        --
│    └─One: 2-720                        [1]                       --
│    └─OutputScale: 2-721                --                        --
│    └─Empty: 2-722                      [64, 64, 3, 3]            --
│    └─Empty: 2-723                      [64, 64, 3, 3]            --
│    └─Empty: 2-724                      [64]                      --
│    └─Empty: 2-725                      [64]                      --
│    └─BatchNorm2d: 2-726                [16, 64, 32, 32]          --
│    └─Scaler: 2-727                     [16, 64, 32, 32]          --
│    └─ReLU: 2-728                       [16, 64, 32, 32]          --
│    └─Empty: 2-729                      [16, 64, 32, 32]          --
│    └─Clamp: 2-730                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-56                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-731         --                        --
│    └─One: 2-732                        [1]                       --
│    └─OutputScale: 2-733                --                        --
│    └─Empty: 2-734                      [64, 64, 1, 1]            --
│    └─Empty: 2-735                      [64, 64, 1, 1]            --
│    └─Empty: 2-736                      [64]                      --
│    └─Empty: 2-737                      [64]                      --
│    └─BatchNorm2d: 2-738                [16, 64, 32, 32]          --
│    └─Scaler: 2-739                     [16, 64, 32, 32]          --
│    └─ReLU: 2-740                       [16, 64, 32, 32]          --
│    └─Empty: 2-741                      [16, 64, 32, 32]          --
│    └─Clamp: 2-742                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-57         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-743                  [16, 64, 32, 32]          --
│    └─Empty: 2-744                      [16, 64, 32, 32]          --
│    └─Empty: 2-745                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-746         --                        --
│    └─One: 2-747                        [1]                       --
│    └─OutputScale: 2-748                --                        --
│    └─Empty: 2-749                      [64, 64, 3, 3]            --
│    └─Empty: 2-750                      [64, 64, 3, 3]            --
│    └─Empty: 2-751                      [64]                      --
│    └─Empty: 2-752                      [64]                      --
│    └─BatchNorm2d: 2-753                [16, 64, 32, 32]          --
│    └─Scaler: 2-754                     [16, 64, 32, 32]          --
│    └─ReLU: 2-755                       [16, 64, 32, 32]          --
│    └─Empty: 2-756                      [16, 64, 32, 32]          --
│    └─Clamp: 2-757                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-758                  [16, 64, 16, 16]          --
│    └─Empty: 2-759                      [16, 64, 16, 16]          --
│    └─Empty: 2-760                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-761         --                        --
│    └─One: 2-762                        [1]                       --
│    └─OutputScale: 2-763                --                        --
│    └─Empty: 2-764                      [64, 64, 3, 3]            --
│    └─Empty: 2-765                      [64, 64, 3, 3]            --
│    └─Empty: 2-766                      [64]                      --
│    └─Empty: 2-767                      [64]                      --
│    └─BatchNorm2d: 2-768                [16, 64, 16, 16]          --
│    └─Scaler: 2-769                     [16, 64, 16, 16]          --
│    └─ReLU: 2-770                       [16, 64, 16, 16]          --
│    └─Empty: 2-771                      [16, 64, 16, 16]          --
│    └─Clamp: 2-772                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-773         --                        --
│    └─One: 2-774                        [1]                       --
│    └─OutputScale: 2-775                --                        --
│    └─Empty: 2-776                      [4, 64, 1, 1]             --
│    └─Empty: 2-777                      [4, 64, 1, 1]             --
│    └─Empty: 2-778                      [4]                       --
│    └─Empty: 2-779                      [4]                       --
│    └─BatchNorm2d: 2-780                [16, 4, 16, 16]           --
│    └─Scaler: 2-781                     [16, 4, 16, 16]           --
│    └─ReLU: 2-782                       [16, 4, 16, 16]           --
│    └─Empty: 2-783                      [16, 4, 16, 16]           --
│    └─Clamp: 2-784                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-785                  [16, 64, 16, 16]          --
│    └─Empty: 2-786                      [16, 64, 16, 16]          --
│    └─Empty: 2-787                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-788         --                        --
│    └─One: 2-789                        [1]                       --
│    └─OutputScale: 2-790                --                        --
│    └─Empty: 2-791                      [4, 64, 3, 3]             --
│    └─Empty: 2-792                      [4, 64, 3, 3]             --
│    └─Empty: 2-793                      [4]                       --
│    └─Empty: 2-794                      [4]                       --
│    └─BatchNorm2d: 2-795                [16, 4, 16, 16]           --
│    └─Scaler: 2-796                     [16, 4, 16, 16]           --
│    └─ReLU: 2-797                       [16, 4, 16, 16]           --
│    └─Empty: 2-798                      [16, 4, 16, 16]           --
│    └─Clamp: 2-799                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-61                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-800         --                        --
│    └─One: 2-801                        [1]                       --
│    └─OutputScale: 2-802                --                        --
│    └─Empty: 2-803                      [64, 48, 1, 1]            --
│    └─Empty: 2-804                      [64, 48, 1, 1]            --
│    └─Empty: 2-805                      [64]                      --
│    └─Empty: 2-806                      [64]                      --
│    └─BatchNorm2d: 2-807                [16, 64, 64, 64]          --
│    └─Scaler: 2-808                     [16, 64, 64, 64]          --
│    └─ReLU: 2-809                       [16, 64, 64, 64]          --
│    └─Empty: 2-810                      [16, 64, 64, 64]          --
│    └─Clamp: 2-811                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-62                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-812         --                        --
│    └─One: 2-813                        [1]                       --
│    └─OutputScale: 2-814                --                        --
│    └─Empty: 2-815                      [64, 64, 3, 3]            --
│    └─Empty: 2-816                      [64, 64, 3, 3]            --
│    └─Empty: 2-817                      [64]                      --
│    └─Empty: 2-818                      [64]                      --
│    └─BatchNorm2d: 2-819                [16, 64, 64, 64]          --
│    └─Scaler: 2-820                     [16, 64, 64, 64]          --
│    └─ReLU: 2-821                       [16, 64, 64, 64]          --
│    └─Empty: 2-822                      [16, 64, 64, 64]          --
│    └─Clamp: 2-823                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-824                  [16, 64, 32, 32]          --
│    └─Empty: 2-825                      [16, 64, 32, 32]          --
│    └─Empty: 2-826                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-827         --                        --
│    └─One: 2-828                        [1]                       --
│    └─OutputScale: 2-829                --                        --
│    └─Empty: 2-830                      [64, 64, 3, 3]            --
│    └─Empty: 2-831                      [64, 64, 3, 3]            --
│    └─Empty: 2-832                      [64]                      --
│    └─Empty: 2-833                      [64]                      --
│    └─BatchNorm2d: 2-834                [16, 64, 32, 32]          --
│    └─Scaler: 2-835                     [16, 64, 32, 32]          --
│    └─ReLU: 2-836                       [16, 64, 32, 32]          --
│    └─Empty: 2-837                      [16, 64, 32, 32]          --
│    └─Clamp: 2-838                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-64                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-839         --                        --
│    └─One: 2-840                        [1]                       --
│    └─OutputScale: 2-841                --                        --
│    └─Empty: 2-842                      [64, 64, 1, 1]            --
│    └─Empty: 2-843                      [64, 64, 1, 1]            --
│    └─Empty: 2-844                      [64]                      --
│    └─Empty: 2-845                      [64]                      --
│    └─BatchNorm2d: 2-846                [16, 64, 32, 32]          --
│    └─Scaler: 2-847                     [16, 64, 32, 32]          --
│    └─ReLU: 2-848                       [16, 64, 32, 32]          --
│    └─Empty: 2-849                      [16, 64, 32, 32]          --
│    └─Clamp: 2-850                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-851                  [16, 64, 32, 32]          --
│    └─Empty: 2-852                      [16, 64, 32, 32]          --
│    └─Empty: 2-853                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-854         --                        --
│    └─One: 2-855                        [1]                       --
│    └─OutputScale: 2-856                --                        --
│    └─Empty: 2-857                      [64, 64, 3, 3]            --
│    └─Empty: 2-858                      [64, 64, 3, 3]            --
│    └─Empty: 2-859                      [64]                      --
│    └─Empty: 2-860                      [64]                      --
│    └─BatchNorm2d: 2-861                [16, 64, 32, 32]          --
│    └─Scaler: 2-862                     [16, 64, 32, 32]          --
│    └─ReLU: 2-863                       [16, 64, 32, 32]          --
│    └─Empty: 2-864                      [16, 64, 32, 32]          --
│    └─Clamp: 2-865                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-866                  [16, 64, 16, 16]          --
│    └─Empty: 2-867                      [16, 64, 16, 16]          --
│    └─Empty: 2-868                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-869         --                        --
│    └─One: 2-870                        [1]                       --
│    └─OutputScale: 2-871                --                        --
│    └─Empty: 2-872                      [64, 64, 3, 3]            --
│    └─Empty: 2-873                      [64, 64, 3, 3]            --
│    └─Empty: 2-874                      [64]                      --
│    └─Empty: 2-875                      [64]                      --
│    └─BatchNorm2d: 2-876                [16, 64, 16, 16]          --
│    └─Scaler: 2-877                     [16, 64, 16, 16]          --
│    └─ReLU: 2-878                       [16, 64, 16, 16]          --
│    └─Empty: 2-879                      [16, 64, 16, 16]          --
│    └─Clamp: 2-880                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-67                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-881         --                        --
│    └─One: 2-882                        [1]                       --
│    └─OutputScale: 2-883                --                        --
│    └─Empty: 2-884                      [4, 64, 1, 1]             --
│    └─Empty: 2-885                      [4, 64, 1, 1]             --
│    └─Empty: 2-886                      [4]                       --
│    └─Empty: 2-887                      [4]                       --
│    └─BatchNorm2d: 2-888                [16, 4, 16, 16]           --
│    └─Scaler: 2-889                     [16, 4, 16, 16]           --
│    └─ReLU: 2-890                       [16, 4, 16, 16]           --
│    └─Empty: 2-891                      [16, 4, 16, 16]           --
│    └─Clamp: 2-892                      [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-893                  [16, 64, 16, 16]          --
│    └─Empty: 2-894                      [16, 64, 16, 16]          --
│    └─Empty: 2-895                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-896         --                        --
│    └─One: 2-897                        [1]                       --
│    └─OutputScale: 2-898                --                        --
│    └─Empty: 2-899                      [4, 64, 3, 3]             --
│    └─Empty: 2-900                      [4, 64, 3, 3]             --
│    └─Empty: 2-901                      [4]                       --
│    └─Empty: 2-902                      [4]                       --
│    └─BatchNorm2d: 2-903                [16, 4, 16, 16]           --
│    └─Scaler: 2-904                     [16, 4, 16, 16]           --
│    └─ReLU: 2-905                       [16, 4, 16, 16]           --
│    └─Empty: 2-906                      [16, 4, 16, 16]           --
│    └─Clamp: 2-907                      [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-908         --                        --
│    └─One: 2-909                        [1]                       --
│    └─OutputScale: 2-910                --                        --
│    └─Empty: 2-911                      [64, 48, 1, 1]            --
│    └─Empty: 2-912                      [64, 48, 1, 1]            --
│    └─Empty: 2-913                      [64]                      --
│    └─Empty: 2-914                      [64]                      --
│    └─BatchNorm2d: 2-915                [16, 64, 64, 64]          --
│    └─Scaler: 2-916                     [16, 64, 64, 64]          --
│    └─ReLU: 2-917                       [16, 64, 64, 64]          --
│    └─Empty: 2-918                      [16, 64, 64, 64]          --
│    └─Clamp: 2-919                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-920         --                        --
│    └─One: 2-921                        [1]                       --
│    └─OutputScale: 2-922                --                        --
│    └─Empty: 2-923                      [64, 64, 3, 3]            --
│    └─Empty: 2-924                      [64, 64, 3, 3]            --
│    └─Empty: 2-925                      [64]                      --
│    └─Empty: 2-926                      [64]                      --
│    └─BatchNorm2d: 2-927                [16, 64, 64, 64]          --
│    └─Scaler: 2-928                     [16, 64, 64, 64]          --
│    └─ReLU: 2-929                       [16, 64, 64, 64]          --
│    └─Empty: 2-930                      [16, 64, 64, 64]          --
│    └─Clamp: 2-931                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-71         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-932                  [16, 64, 32, 32]          --
│    └─Empty: 2-933                      [16, 64, 32, 32]          --
│    └─Empty: 2-934                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-935         --                        --
│    └─One: 2-936                        [1]                       --
│    └─OutputScale: 2-937                --                        --
│    └─Empty: 2-938                      [64, 64, 3, 3]            --
│    └─Empty: 2-939                      [64, 64, 3, 3]            --
│    └─Empty: 2-940                      [64]                      --
│    └─Empty: 2-941                      [64]                      --
│    └─BatchNorm2d: 2-942                [16, 64, 32, 32]          --
│    └─Scaler: 2-943                     [16, 64, 32, 32]          --
│    └─ReLU: 2-944                       [16, 64, 32, 32]          --
│    └─Empty: 2-945                      [16, 64, 32, 32]          --
│    └─Clamp: 2-946                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-947         --                        --
│    └─One: 2-948                        [1]                       --
│    └─OutputScale: 2-949                --                        --
│    └─Empty: 2-950                      [64, 64, 1, 1]            --
│    └─Empty: 2-951                      [64, 64, 1, 1]            --
│    └─Empty: 2-952                      [64]                      --
│    └─Empty: 2-953                      [64]                      --
│    └─BatchNorm2d: 2-954                [16, 64, 32, 32]          --
│    └─Scaler: 2-955                     [16, 64, 32, 32]          --
│    └─ReLU: 2-956                       [16, 64, 32, 32]          --
│    └─Empty: 2-957                      [16, 64, 32, 32]          --
│    └─Clamp: 2-958                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-959                  [16, 64, 32, 32]          --
│    └─Empty: 2-960                      [16, 64, 32, 32]          --
│    └─Empty: 2-961                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-962         --                        --
│    └─One: 2-963                        [1]                       --
│    └─OutputScale: 2-964                --                        --
│    └─Empty: 2-965                      [64, 64, 3, 3]            --
│    └─Empty: 2-966                      [64, 64, 3, 3]            --
│    └─Empty: 2-967                      [64]                      --
│    └─Empty: 2-968                      [64]                      --
│    └─BatchNorm2d: 2-969                [16, 64, 32, 32]          --
│    └─Scaler: 2-970                     [16, 64, 32, 32]          --
│    └─ReLU: 2-971                       [16, 64, 32, 32]          --
│    └─Empty: 2-972                      [16, 64, 32, 32]          --
│    └─Clamp: 2-973                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-74         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-974                  [16, 64, 16, 16]          --
│    └─Empty: 2-975                      [16, 64, 16, 16]          --
│    └─Empty: 2-976                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-977         --                        --
│    └─One: 2-978                        [1]                       --
│    └─OutputScale: 2-979                --                        --
│    └─Empty: 2-980                      [64, 64, 3, 3]            --
│    └─Empty: 2-981                      [64, 64, 3, 3]            --
│    └─Empty: 2-982                      [64]                      --
│    └─Empty: 2-983                      [64]                      --
│    └─BatchNorm2d: 2-984                [16, 64, 16, 16]          --
│    └─Scaler: 2-985                     [16, 64, 16, 16]          --
│    └─ReLU: 2-986                       [16, 64, 16, 16]          --
│    └─Empty: 2-987                      [16, 64, 16, 16]          --
│    └─Clamp: 2-988                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-75                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-989         --                        --
│    └─One: 2-990                        [1]                       --
│    └─OutputScale: 2-991                --                        --
│    └─Empty: 2-992                      [4, 64, 1, 1]             --
│    └─Empty: 2-993                      [4, 64, 1, 1]             --
│    └─Empty: 2-994                      [4]                       --
│    └─Empty: 2-995                      [4]                       --
│    └─BatchNorm2d: 2-996                [16, 4, 16, 16]           --
│    └─Scaler: 2-997                     [16, 4, 16, 16]           --
│    └─ReLU: 2-998                       [16, 4, 16, 16]           --
│    └─Empty: 2-999                      [16, 4, 16, 16]           --
│    └─Clamp: 2-1000                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-76         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1001                 [16, 64, 16, 16]          --
│    └─Empty: 2-1002                     [16, 64, 16, 16]          --
│    └─Empty: 2-1003                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1004        --                        --
│    └─One: 2-1005                       [1]                       --
│    └─OutputScale: 2-1006               --                        --
│    └─Empty: 2-1007                     [4, 64, 3, 3]             --
│    └─Empty: 2-1008                     [4, 64, 3, 3]             --
│    └─Empty: 2-1009                     [4]                       --
│    └─Empty: 2-1010                     [4]                       --
│    └─BatchNorm2d: 2-1011               [16, 4, 16, 16]           --
│    └─Scaler: 2-1012                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1013                      [16, 4, 16, 16]           --
│    └─Empty: 2-1014                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1015                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-77                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1016        --                        --
│    └─One: 2-1017                       [1]                       --
│    └─OutputScale: 2-1018               --                        --
│    └─Empty: 2-1019                     [64, 48, 1, 1]            --
│    └─Empty: 2-1020                     [64, 48, 1, 1]            --
│    └─Empty: 2-1021                     [64]                      --
│    └─Empty: 2-1022                     [64]                      --
│    └─BatchNorm2d: 2-1023               [16, 64, 64, 64]          --
│    └─Scaler: 2-1024                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1025                      [16, 64, 64, 64]          --
│    └─Empty: 2-1026                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1027                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-78                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1028        --                        --
│    └─One: 2-1029                       [1]                       --
│    └─OutputScale: 2-1030               --                        --
│    └─Empty: 2-1031                     [64, 64, 3, 3]            --
│    └─Empty: 2-1032                     [64, 64, 3, 3]            --
│    └─Empty: 2-1033                     [64]                      --
│    └─Empty: 2-1034                     [64]                      --
│    └─BatchNorm2d: 2-1035               [16, 64, 64, 64]          --
│    └─Scaler: 2-1036                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1037                      [16, 64, 64, 64]          --
│    └─Empty: 2-1038                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1039                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1040                 [16, 64, 32, 32]          --
│    └─Empty: 2-1041                     [16, 64, 32, 32]          --
│    └─Empty: 2-1042                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1043        --                        --
│    └─One: 2-1044                       [1]                       --
│    └─OutputScale: 2-1045               --                        --
│    └─Empty: 2-1046                     [64, 64, 3, 3]            --
│    └─Empty: 2-1047                     [64, 64, 3, 3]            --
│    └─Empty: 2-1048                     [64]                      --
│    └─Empty: 2-1049                     [64]                      --
│    └─BatchNorm2d: 2-1050               [16, 64, 32, 32]          --
│    └─Scaler: 2-1051                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1052                      [16, 64, 32, 32]          --
│    └─Empty: 2-1053                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1054                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-80                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1055        --                        --
│    └─One: 2-1056                       [1]                       --
│    └─OutputScale: 2-1057               --                        --
│    └─Empty: 2-1058                     [64, 64, 1, 1]            --
│    └─Empty: 2-1059                     [64, 64, 1, 1]            --
│    └─Empty: 2-1060                     [64]                      --
│    └─Empty: 2-1061                     [64]                      --
│    └─BatchNorm2d: 2-1062               [16, 64, 32, 32]          --
│    └─Scaler: 2-1063                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1064                      [16, 64, 32, 32]          --
│    └─Empty: 2-1065                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1066                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-81         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1067                 [16, 64, 32, 32]          --
│    └─Empty: 2-1068                     [16, 64, 32, 32]          --
│    └─Empty: 2-1069                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1070        --                        --
│    └─One: 2-1071                       [1]                       --
│    └─OutputScale: 2-1072               --                        --
│    └─Empty: 2-1073                     [64, 64, 3, 3]            --
│    └─Empty: 2-1074                     [64, 64, 3, 3]            --
│    └─Empty: 2-1075                     [64]                      --
│    └─Empty: 2-1076                     [64]                      --
│    └─BatchNorm2d: 2-1077               [16, 64, 32, 32]          --
│    └─Scaler: 2-1078                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1079                      [16, 64, 32, 32]          --
│    └─Empty: 2-1080                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1081                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1082                 [16, 64, 16, 16]          --
│    └─Empty: 2-1083                     [16, 64, 16, 16]          --
│    └─Empty: 2-1084                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1085        --                        --
│    └─One: 2-1086                       [1]                       --
│    └─OutputScale: 2-1087               --                        --
│    └─Empty: 2-1088                     [64, 64, 3, 3]            --
│    └─Empty: 2-1089                     [64, 64, 3, 3]            --
│    └─Empty: 2-1090                     [64]                      --
│    └─Empty: 2-1091                     [64]                      --
│    └─BatchNorm2d: 2-1092               [16, 64, 16, 16]          --
│    └─Scaler: 2-1093                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1094                      [16, 64, 16, 16]          --
│    └─Empty: 2-1095                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1096                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-83                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1097        --                        --
│    └─One: 2-1098                       [1]                       --
│    └─OutputScale: 2-1099               --                        --
│    └─Empty: 2-1100                     [4, 64, 1, 1]             --
│    └─Empty: 2-1101                     [4, 64, 1, 1]             --
│    └─Empty: 2-1102                     [4]                       --
│    └─Empty: 2-1103                     [4]                       --
│    └─BatchNorm2d: 2-1104               [16, 4, 16, 16]           --
│    └─Scaler: 2-1105                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1106                      [16, 4, 16, 16]           --
│    └─Empty: 2-1107                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1108                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-84         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1109                 [16, 64, 16, 16]          --
│    └─Empty: 2-1110                     [16, 64, 16, 16]          --
│    └─Empty: 2-1111                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1112        --                        --
│    └─One: 2-1113                       [1]                       --
│    └─OutputScale: 2-1114               --                        --
│    └─Empty: 2-1115                     [4, 64, 3, 3]             --
│    └─Empty: 2-1116                     [4, 64, 3, 3]             --
│    └─Empty: 2-1117                     [4]                       --
│    └─Empty: 2-1118                     [4]                       --
│    └─BatchNorm2d: 2-1119               [16, 4, 16, 16]           --
│    └─Scaler: 2-1120                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1121                      [16, 4, 16, 16]           --
│    └─Empty: 2-1122                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1123                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-85                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1124        --                        --
│    └─One: 2-1125                       [1]                       --
│    └─OutputScale: 2-1126               --                        --
│    └─Empty: 2-1127                     [64, 48, 1, 1]            --
│    └─Empty: 2-1128                     [64, 48, 1, 1]            --
│    └─Empty: 2-1129                     [64]                      --
│    └─Empty: 2-1130                     [64]                      --
│    └─BatchNorm2d: 2-1131               [16, 64, 64, 64]          --
│    └─Scaler: 2-1132                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1133                      [16, 64, 64, 64]          --
│    └─Empty: 2-1134                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1135                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1136        --                        --
│    └─One: 2-1137                       [1]                       --
│    └─OutputScale: 2-1138               --                        --
│    └─Empty: 2-1139                     [64, 64, 3, 3]            --
│    └─Empty: 2-1140                     [64, 64, 3, 3]            --
│    └─Empty: 2-1141                     [64]                      --
│    └─Empty: 2-1142                     [64]                      --
│    └─BatchNorm2d: 2-1143               [16, 64, 64, 64]          --
│    └─Scaler: 2-1144                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1145                      [16, 64, 64, 64]          --
│    └─Empty: 2-1146                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1147                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-87         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1148                 [16, 64, 32, 32]          --
│    └─Empty: 2-1149                     [16, 64, 32, 32]          --
│    └─Empty: 2-1150                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1151        --                        --
│    └─One: 2-1152                       [1]                       --
│    └─OutputScale: 2-1153               --                        --
│    └─Empty: 2-1154                     [64, 64, 3, 3]            --
│    └─Empty: 2-1155                     [64, 64, 3, 3]            --
│    └─Empty: 2-1156                     [64]                      --
│    └─Empty: 2-1157                     [64]                      --
│    └─BatchNorm2d: 2-1158               [16, 64, 32, 32]          --
│    └─Scaler: 2-1159                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1160                      [16, 64, 32, 32]          --
│    └─Empty: 2-1161                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1162                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1163        --                        --
│    └─One: 2-1164                       [1]                       --
│    └─OutputScale: 2-1165               --                        --
│    └─Empty: 2-1166                     [64, 64, 1, 1]            --
│    └─Empty: 2-1167                     [64, 64, 1, 1]            --
│    └─Empty: 2-1168                     [64]                      --
│    └─Empty: 2-1169                     [64]                      --
│    └─BatchNorm2d: 2-1170               [16, 64, 32, 32]          --
│    └─Scaler: 2-1171                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1172                      [16, 64, 32, 32]          --
│    └─Empty: 2-1173                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1174                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-89         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1175                 [16, 64, 32, 32]          --
│    └─Empty: 2-1176                     [16, 64, 32, 32]          --
│    └─Empty: 2-1177                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1178        --                        --
│    └─One: 2-1179                       [1]                       --
│    └─OutputScale: 2-1180               --                        --
│    └─Empty: 2-1181                     [64, 64, 3, 3]            --
│    └─Empty: 2-1182                     [64, 64, 3, 3]            --
│    └─Empty: 2-1183                     [64]                      --
│    └─Empty: 2-1184                     [64]                      --
│    └─BatchNorm2d: 2-1185               [16, 64, 32, 32]          --
│    └─Scaler: 2-1186                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1187                      [16, 64, 32, 32]          --
│    └─Empty: 2-1188                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1189                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1190                 [16, 64, 16, 16]          --
│    └─Empty: 2-1191                     [16, 64, 16, 16]          --
│    └─Empty: 2-1192                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1193        --                        --
│    └─One: 2-1194                       [1]                       --
│    └─OutputScale: 2-1195               --                        --
│    └─Empty: 2-1196                     [64, 64, 3, 3]            --
│    └─Empty: 2-1197                     [64, 64, 3, 3]            --
│    └─Empty: 2-1198                     [64]                      --
│    └─Empty: 2-1199                     [64]                      --
│    └─BatchNorm2d: 2-1200               [16, 64, 16, 16]          --
│    └─Scaler: 2-1201                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1202                      [16, 64, 16, 16]          --
│    └─Empty: 2-1203                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1204                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-91                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1205        --                        --
│    └─One: 2-1206                       [1]                       --
│    └─OutputScale: 2-1207               --                        --
│    └─Empty: 2-1208                     [4, 64, 1, 1]             --
│    └─Empty: 2-1209                     [4, 64, 1, 1]             --
│    └─Empty: 2-1210                     [4]                       --
│    └─Empty: 2-1211                     [4]                       --
│    └─BatchNorm2d: 2-1212               [16, 4, 16, 16]           --
│    └─Scaler: 2-1213                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1214                      [16, 4, 16, 16]           --
│    └─Empty: 2-1215                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1216                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1217                 [16, 64, 16, 16]          --
│    └─Empty: 2-1218                     [16, 64, 16, 16]          --
│    └─Empty: 2-1219                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1220        --                        --
│    └─One: 2-1221                       [1]                       --
│    └─OutputScale: 2-1222               --                        --
│    └─Empty: 2-1223                     [4, 64, 3, 3]             --
│    └─Empty: 2-1224                     [4, 64, 3, 3]             --
│    └─Empty: 2-1225                     [4]                       --
│    └─Empty: 2-1226                     [4]                       --
│    └─BatchNorm2d: 2-1227               [16, 4, 16, 16]           --
│    └─Scaler: 2-1228                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1229                      [16, 4, 16, 16]           --
│    └─Empty: 2-1230                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1231                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-93                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1232        --                        --
│    └─One: 2-1233                       [1]                       --
│    └─OutputScale: 2-1234               --                        --
│    └─Empty: 2-1235                     [64, 48, 1, 1]            --
│    └─Empty: 2-1236                     [64, 48, 1, 1]            --
│    └─Empty: 2-1237                     [64]                      --
│    └─Empty: 2-1238                     [64]                      --
│    └─BatchNorm2d: 2-1239               [16, 64, 64, 64]          --
│    └─Scaler: 2-1240                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1241                      [16, 64, 64, 64]          --
│    └─Empty: 2-1242                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1243                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-94                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1244        --                        --
│    └─One: 2-1245                       [1]                       --
│    └─OutputScale: 2-1246               --                        --
│    └─Empty: 2-1247                     [64, 64, 3, 3]            --
│    └─Empty: 2-1248                     [64, 64, 3, 3]            --
│    └─Empty: 2-1249                     [64]                      --
│    └─Empty: 2-1250                     [64]                      --
│    └─BatchNorm2d: 2-1251               [16, 64, 64, 64]          --
│    └─Scaler: 2-1252                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1253                      [16, 64, 64, 64]          --
│    └─Empty: 2-1254                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1255                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-95         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1256                 [16, 64, 32, 32]          --
│    └─Empty: 2-1257                     [16, 64, 32, 32]          --
│    └─Empty: 2-1258                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1259        --                        --
│    └─One: 2-1260                       [1]                       --
│    └─OutputScale: 2-1261               --                        --
│    └─Empty: 2-1262                     [64, 64, 3, 3]            --
│    └─Empty: 2-1263                     [64, 64, 3, 3]            --
│    └─Empty: 2-1264                     [64]                      --
│    └─Empty: 2-1265                     [64]                      --
│    └─BatchNorm2d: 2-1266               [16, 64, 32, 32]          --
│    └─Scaler: 2-1267                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1268                      [16, 64, 32, 32]          --
│    └─Empty: 2-1269                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1270                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-96                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1271        --                        --
│    └─One: 2-1272                       [1]                       --
│    └─OutputScale: 2-1273               --                        --
│    └─Empty: 2-1274                     [64, 64, 1, 1]            --
│    └─Empty: 2-1275                     [64, 64, 1, 1]            --
│    └─Empty: 2-1276                     [64]                      --
│    └─Empty: 2-1277                     [64]                      --
│    └─BatchNorm2d: 2-1278               [16, 64, 32, 32]          --
│    └─Scaler: 2-1279                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1280                      [16, 64, 32, 32]          --
│    └─Empty: 2-1281                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1282                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1283                 [16, 64, 32, 32]          --
│    └─Empty: 2-1284                     [16, 64, 32, 32]          --
│    └─Empty: 2-1285                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1286        --                        --
│    └─One: 2-1287                       [1]                       --
│    └─OutputScale: 2-1288               --                        --
│    └─Empty: 2-1289                     [64, 64, 3, 3]            --
│    └─Empty: 2-1290                     [64, 64, 3, 3]            --
│    └─Empty: 2-1291                     [64]                      --
│    └─Empty: 2-1292                     [64]                      --
│    └─BatchNorm2d: 2-1293               [16, 64, 32, 32]          --
│    └─Scaler: 2-1294                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1295                      [16, 64, 32, 32]          --
│    └─Empty: 2-1296                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1297                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-98         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1298                 [16, 64, 16, 16]          --
│    └─Empty: 2-1299                     [16, 64, 16, 16]          --
│    └─Empty: 2-1300                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1301        --                        --
│    └─One: 2-1302                       [1]                       --
│    └─OutputScale: 2-1303               --                        --
│    └─Empty: 2-1304                     [64, 64, 3, 3]            --
│    └─Empty: 2-1305                     [64, 64, 3, 3]            --
│    └─Empty: 2-1306                     [64]                      --
│    └─Empty: 2-1307                     [64]                      --
│    └─BatchNorm2d: 2-1308               [16, 64, 16, 16]          --
│    └─Scaler: 2-1309                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1310                      [16, 64, 16, 16]          --
│    └─Empty: 2-1311                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1312                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-99                [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1313        --                        --
│    └─One: 2-1314                       [1]                       --
│    └─OutputScale: 2-1315               --                        --
│    └─Empty: 2-1316                     [4, 64, 1, 1]             --
│    └─Empty: 2-1317                     [4, 64, 1, 1]             --
│    └─Empty: 2-1318                     [4]                       --
│    └─Empty: 2-1319                     [4]                       --
│    └─BatchNorm2d: 2-1320               [16, 4, 16, 16]           --
│    └─Scaler: 2-1321                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1322                      [16, 4, 16, 16]           --
│    └─Empty: 2-1323                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1324                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1325                 [16, 64, 16, 16]          --
│    └─Empty: 2-1326                     [16, 64, 16, 16]          --
│    └─Empty: 2-1327                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1328        --                        --
│    └─One: 2-1329                       [1]                       --
│    └─OutputScale: 2-1330               --                        --
│    └─Empty: 2-1331                     [4, 64, 3, 3]             --
│    └─Empty: 2-1332                     [4, 64, 3, 3]             --
│    └─Empty: 2-1333                     [4]                       --
│    └─Empty: 2-1334                     [4]                       --
│    └─BatchNorm2d: 2-1335               [16, 4, 16, 16]           --
│    └─Scaler: 2-1336                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1337                      [16, 4, 16, 16]           --
│    └─Empty: 2-1338                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1339                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-101               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1340        --                        --
│    └─One: 2-1341                       [1]                       --
│    └─OutputScale: 2-1342               --                        --
│    └─Empty: 2-1343                     [64, 48, 1, 1]            --
│    └─Empty: 2-1344                     [64, 48, 1, 1]            --
│    └─Empty: 2-1345                     [64]                      --
│    └─Empty: 2-1346                     [64]                      --
│    └─BatchNorm2d: 2-1347               [16, 64, 64, 64]          --
│    └─Scaler: 2-1348                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1349                      [16, 64, 64, 64]          --
│    └─Empty: 2-1350                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1351                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-102               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1352        --                        --
│    └─One: 2-1353                       [1]                       --
│    └─OutputScale: 2-1354               --                        --
│    └─Empty: 2-1355                     [64, 64, 3, 3]            --
│    └─Empty: 2-1356                     [64, 64, 3, 3]            --
│    └─Empty: 2-1357                     [64]                      --
│    └─Empty: 2-1358                     [64]                      --
│    └─BatchNorm2d: 2-1359               [16, 64, 64, 64]          --
│    └─Scaler: 2-1360                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1361                      [16, 64, 64, 64]          --
│    └─Empty: 2-1362                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1363                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-103        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1364                 [16, 64, 32, 32]          --
│    └─Empty: 2-1365                     [16, 64, 32, 32]          --
│    └─Empty: 2-1366                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1367        --                        --
│    └─One: 2-1368                       [1]                       --
│    └─OutputScale: 2-1369               --                        --
│    └─Empty: 2-1370                     [64, 64, 3, 3]            --
│    └─Empty: 2-1371                     [64, 64, 3, 3]            --
│    └─Empty: 2-1372                     [64]                      --
│    └─Empty: 2-1373                     [64]                      --
│    └─BatchNorm2d: 2-1374               [16, 64, 32, 32]          --
│    └─Scaler: 2-1375                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1376                      [16, 64, 32, 32]          --
│    └─Empty: 2-1377                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1378                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1379        --                        --
│    └─One: 2-1380                       [1]                       --
│    └─OutputScale: 2-1381               --                        --
│    └─Empty: 2-1382                     [64, 64, 1, 1]            --
│    └─Empty: 2-1383                     [64, 64, 1, 1]            --
│    └─Empty: 2-1384                     [64]                      --
│    └─Empty: 2-1385                     [64]                      --
│    └─BatchNorm2d: 2-1386               [16, 64, 32, 32]          --
│    └─Scaler: 2-1387                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1388                      [16, 64, 32, 32]          --
│    └─Empty: 2-1389                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1390                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-105        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1391                 [16, 64, 32, 32]          --
│    └─Empty: 2-1392                     [16, 64, 32, 32]          --
│    └─Empty: 2-1393                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1394        --                        --
│    └─One: 2-1395                       [1]                       --
│    └─OutputScale: 2-1396               --                        --
│    └─Empty: 2-1397                     [64, 64, 3, 3]            --
│    └─Empty: 2-1398                     [64, 64, 3, 3]            --
│    └─Empty: 2-1399                     [64]                      --
│    └─Empty: 2-1400                     [64]                      --
│    └─BatchNorm2d: 2-1401               [16, 64, 32, 32]          --
│    └─Scaler: 2-1402                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1403                      [16, 64, 32, 32]          --
│    └─Empty: 2-1404                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1405                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-106        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1406                 [16, 64, 16, 16]          --
│    └─Empty: 2-1407                     [16, 64, 16, 16]          --
│    └─Empty: 2-1408                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1409        --                        --
│    └─One: 2-1410                       [1]                       --
│    └─OutputScale: 2-1411               --                        --
│    └─Empty: 2-1412                     [64, 64, 3, 3]            --
│    └─Empty: 2-1413                     [64, 64, 3, 3]            --
│    └─Empty: 2-1414                     [64]                      --
│    └─Empty: 2-1415                     [64]                      --
│    └─BatchNorm2d: 2-1416               [16, 64, 16, 16]          --
│    └─Scaler: 2-1417                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1418                      [16, 64, 16, 16]          --
│    └─Empty: 2-1419                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1420                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-107               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1421        --                        --
│    └─One: 2-1422                       [1]                       --
│    └─OutputScale: 2-1423               --                        --
│    └─Empty: 2-1424                     [4, 64, 1, 1]             --
│    └─Empty: 2-1425                     [4, 64, 1, 1]             --
│    └─Empty: 2-1426                     [4]                       --
│    └─Empty: 2-1427                     [4]                       --
│    └─BatchNorm2d: 2-1428               [16, 4, 16, 16]           --
│    └─Scaler: 2-1429                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1430                      [16, 4, 16, 16]           --
│    └─Empty: 2-1431                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1432                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-108        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1433                 [16, 64, 16, 16]          --
│    └─Empty: 2-1434                     [16, 64, 16, 16]          --
│    └─Empty: 2-1435                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1436        --                        --
│    └─One: 2-1437                       [1]                       --
│    └─OutputScale: 2-1438               --                        --
│    └─Empty: 2-1439                     [4, 64, 3, 3]             --
│    └─Empty: 2-1440                     [4, 64, 3, 3]             --
│    └─Empty: 2-1441                     [4]                       --
│    └─Empty: 2-1442                     [4]                       --
│    └─BatchNorm2d: 2-1443               [16, 4, 16, 16]           --
│    └─Scaler: 2-1444                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1445                      [16, 4, 16, 16]           --
│    └─Empty: 2-1446                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1447                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-109               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1448        --                        --
│    └─One: 2-1449                       [1]                       --
│    └─OutputScale: 2-1450               --                        --
│    └─Empty: 2-1451                     [64, 48, 1, 1]            --
│    └─Empty: 2-1452                     [64, 48, 1, 1]            --
│    └─Empty: 2-1453                     [64]                      --
│    └─Empty: 2-1454                     [64]                      --
│    └─BatchNorm2d: 2-1455               [16, 64, 64, 64]          --
│    └─Scaler: 2-1456                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1457                      [16, 64, 64, 64]          --
│    └─Empty: 2-1458                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1459                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1460        --                        --
│    └─One: 2-1461                       [1]                       --
│    └─OutputScale: 2-1462               --                        --
│    └─Empty: 2-1463                     [64, 64, 3, 3]            --
│    └─Empty: 2-1464                     [64, 64, 3, 3]            --
│    └─Empty: 2-1465                     [64]                      --
│    └─Empty: 2-1466                     [64]                      --
│    └─BatchNorm2d: 2-1467               [16, 64, 64, 64]          --
│    └─Scaler: 2-1468                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1469                      [16, 64, 64, 64]          --
│    └─Empty: 2-1470                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1471                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1472                 [16, 64, 32, 32]          --
│    └─Empty: 2-1473                     [16, 64, 32, 32]          --
│    └─Empty: 2-1474                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1475        --                        --
│    └─One: 2-1476                       [1]                       --
│    └─OutputScale: 2-1477               --                        --
│    └─Empty: 2-1478                     [64, 64, 3, 3]            --
│    └─Empty: 2-1479                     [64, 64, 3, 3]            --
│    └─Empty: 2-1480                     [64]                      --
│    └─Empty: 2-1481                     [64]                      --
│    └─BatchNorm2d: 2-1482               [16, 64, 32, 32]          --
│    └─Scaler: 2-1483                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1484                      [16, 64, 32, 32]          --
│    └─Empty: 2-1485                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1486                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-112               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1487        --                        --
│    └─One: 2-1488                       [1]                       --
│    └─OutputScale: 2-1489               --                        --
│    └─Empty: 2-1490                     [64, 64, 1, 1]            --
│    └─Empty: 2-1491                     [64, 64, 1, 1]            --
│    └─Empty: 2-1492                     [64]                      --
│    └─Empty: 2-1493                     [64]                      --
│    └─BatchNorm2d: 2-1494               [16, 64, 32, 32]          --
│    └─Scaler: 2-1495                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1496                      [16, 64, 32, 32]          --
│    └─Empty: 2-1497                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1498                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1499                 [16, 64, 32, 32]          --
│    └─Empty: 2-1500                     [16, 64, 32, 32]          --
│    └─Empty: 2-1501                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1502        --                        --
│    └─One: 2-1503                       [1]                       --
│    └─OutputScale: 2-1504               --                        --
│    └─Empty: 2-1505                     [64, 64, 3, 3]            --
│    └─Empty: 2-1506                     [64, 64, 3, 3]            --
│    └─Empty: 2-1507                     [64]                      --
│    └─Empty: 2-1508                     [64]                      --
│    └─BatchNorm2d: 2-1509               [16, 64, 32, 32]          --
│    └─Scaler: 2-1510                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1511                      [16, 64, 32, 32]          --
│    └─Empty: 2-1512                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1513                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1514                 [16, 64, 16, 16]          --
│    └─Empty: 2-1515                     [16, 64, 16, 16]          --
│    └─Empty: 2-1516                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1517        --                        --
│    └─One: 2-1518                       [1]                       --
│    └─OutputScale: 2-1519               --                        --
│    └─Empty: 2-1520                     [64, 64, 3, 3]            --
│    └─Empty: 2-1521                     [64, 64, 3, 3]            --
│    └─Empty: 2-1522                     [64]                      --
│    └─Empty: 2-1523                     [64]                      --
│    └─BatchNorm2d: 2-1524               [16, 64, 16, 16]          --
│    └─Scaler: 2-1525                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1526                      [16, 64, 16, 16]          --
│    └─Empty: 2-1527                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1528                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-115               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1529        --                        --
│    └─One: 2-1530                       [1]                       --
│    └─OutputScale: 2-1531               --                        --
│    └─Empty: 2-1532                     [4, 64, 1, 1]             --
│    └─Empty: 2-1533                     [4, 64, 1, 1]             --
│    └─Empty: 2-1534                     [4]                       --
│    └─Empty: 2-1535                     [4]                       --
│    └─BatchNorm2d: 2-1536               [16, 4, 16, 16]           --
│    └─Scaler: 2-1537                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1538                      [16, 4, 16, 16]           --
│    └─Empty: 2-1539                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1540                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1541                 [16, 64, 16, 16]          --
│    └─Empty: 2-1542                     [16, 64, 16, 16]          --
│    └─Empty: 2-1543                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1544        --                        --
│    └─One: 2-1545                       [1]                       --
│    └─OutputScale: 2-1546               --                        --
│    └─Empty: 2-1547                     [4, 64, 3, 3]             --
│    └─Empty: 2-1548                     [4, 64, 3, 3]             --
│    └─Empty: 2-1549                     [4]                       --
│    └─Empty: 2-1550                     [4]                       --
│    └─BatchNorm2d: 2-1551               [16, 4, 16, 16]           --
│    └─Scaler: 2-1552                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1553                      [16, 4, 16, 16]           --
│    └─Empty: 2-1554                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1555                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-117               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1556        --                        --
│    └─One: 2-1557                       [1]                       --
│    └─OutputScale: 2-1558               --                        --
│    └─Empty: 2-1559                     [64, 48, 1, 1]            --
│    └─Empty: 2-1560                     [64, 48, 1, 1]            --
│    └─Empty: 2-1561                     [64]                      --
│    └─Empty: 2-1562                     [64]                      --
│    └─BatchNorm2d: 2-1563               [16, 64, 64, 64]          --
│    └─Scaler: 2-1564                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1565                      [16, 64, 64, 64]          --
│    └─Empty: 2-1566                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1567                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-118               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1568        --                        --
│    └─One: 2-1569                       [1]                       --
│    └─OutputScale: 2-1570               --                        --
│    └─Empty: 2-1571                     [64, 64, 3, 3]            --
│    └─Empty: 2-1572                     [64, 64, 3, 3]            --
│    └─Empty: 2-1573                     [64]                      --
│    └─Empty: 2-1574                     [64]                      --
│    └─BatchNorm2d: 2-1575               [16, 64, 64, 64]          --
│    └─Scaler: 2-1576                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1577                      [16, 64, 64, 64]          --
│    └─Empty: 2-1578                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1579                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1580                 [16, 64, 32, 32]          --
│    └─Empty: 2-1581                     [16, 64, 32, 32]          --
│    └─Empty: 2-1582                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1583        --                        --
│    └─One: 2-1584                       [1]                       --
│    └─OutputScale: 2-1585               --                        --
│    └─Empty: 2-1586                     [64, 64, 3, 3]            --
│    └─Empty: 2-1587                     [64, 64, 3, 3]            --
│    └─Empty: 2-1588                     [64]                      --
│    └─Empty: 2-1589                     [64]                      --
│    └─BatchNorm2d: 2-1590               [16, 64, 32, 32]          --
│    └─Scaler: 2-1591                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1592                      [16, 64, 32, 32]          --
│    └─Empty: 2-1593                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1594                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-120               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1595        --                        --
│    └─One: 2-1596                       [1]                       --
│    └─OutputScale: 2-1597               --                        --
│    └─Empty: 2-1598                     [64, 64, 1, 1]            --
│    └─Empty: 2-1599                     [64, 64, 1, 1]            --
│    └─Empty: 2-1600                     [64]                      --
│    └─Empty: 2-1601                     [64]                      --
│    └─BatchNorm2d: 2-1602               [16, 64, 32, 32]          --
│    └─Scaler: 2-1603                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1604                      [16, 64, 32, 32]          --
│    └─Empty: 2-1605                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1606                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-121        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1607                 [16, 64, 32, 32]          --
│    └─Empty: 2-1608                     [16, 64, 32, 32]          --
│    └─Empty: 2-1609                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1610        --                        --
│    └─One: 2-1611                       [1]                       --
│    └─OutputScale: 2-1612               --                        --
│    └─Empty: 2-1613                     [64, 64, 3, 3]            --
│    └─Empty: 2-1614                     [64, 64, 3, 3]            --
│    └─Empty: 2-1615                     [64]                      --
│    └─Empty: 2-1616                     [64]                      --
│    └─BatchNorm2d: 2-1617               [16, 64, 32, 32]          --
│    └─Scaler: 2-1618                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1619                      [16, 64, 32, 32]          --
│    └─Empty: 2-1620                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1621                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-122        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1622                 [16, 64, 16, 16]          --
│    └─Empty: 2-1623                     [16, 64, 16, 16]          --
│    └─Empty: 2-1624                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1625        --                        --
│    └─One: 2-1626                       [1]                       --
│    └─OutputScale: 2-1627               --                        --
│    └─Empty: 2-1628                     [64, 64, 3, 3]            --
│    └─Empty: 2-1629                     [64, 64, 3, 3]            --
│    └─Empty: 2-1630                     [64]                      --
│    └─Empty: 2-1631                     [64]                      --
│    └─BatchNorm2d: 2-1632               [16, 64, 16, 16]          --
│    └─Scaler: 2-1633                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1634                      [16, 64, 16, 16]          --
│    └─Empty: 2-1635                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1636                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-123               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1637        --                        --
│    └─One: 2-1638                       [1]                       --
│    └─OutputScale: 2-1639               --                        --
│    └─Empty: 2-1640                     [4, 64, 1, 1]             --
│    └─Empty: 2-1641                     [4, 64, 1, 1]             --
│    └─Empty: 2-1642                     [4]                       --
│    └─Empty: 2-1643                     [4]                       --
│    └─BatchNorm2d: 2-1644               [16, 4, 16, 16]           --
│    └─Scaler: 2-1645                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1646                      [16, 4, 16, 16]           --
│    └─Empty: 2-1647                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1648                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1649                 [16, 64, 16, 16]          --
│    └─Empty: 2-1650                     [16, 64, 16, 16]          --
│    └─Empty: 2-1651                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1652        --                        --
│    └─One: 2-1653                       [1]                       --
│    └─OutputScale: 2-1654               --                        --
│    └─Empty: 2-1655                     [4, 64, 3, 3]             --
│    └─Empty: 2-1656                     [4, 64, 3, 3]             --
│    └─Empty: 2-1657                     [4]                       --
│    └─Empty: 2-1658                     [4]                       --
│    └─BatchNorm2d: 2-1659               [16, 4, 16, 16]           --
│    └─Scaler: 2-1660                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1661                      [16, 4, 16, 16]           --
│    └─Empty: 2-1662                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1663                     [16, 4, 16, 16]           --
├─FusedConv2dBNReLU: 1-125               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1664        --                        --
│    └─One: 2-1665                       [1]                       --
│    └─OutputScale: 2-1666               --                        --
│    └─Empty: 2-1667                     [64, 48, 1, 1]            --
│    └─Empty: 2-1668                     [64, 48, 1, 1]            --
│    └─Empty: 2-1669                     [64]                      --
│    └─Empty: 2-1670                     [64]                      --
│    └─BatchNorm2d: 2-1671               [16, 64, 64, 64]          --
│    └─Scaler: 2-1672                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1673                      [16, 64, 64, 64]          --
│    └─Empty: 2-1674                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1675                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-126               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1676        --                        --
│    └─One: 2-1677                       [1]                       --
│    └─OutputScale: 2-1678               --                        --
│    └─Empty: 2-1679                     [64, 64, 3, 3]            --
│    └─Empty: 2-1680                     [64, 64, 3, 3]            --
│    └─Empty: 2-1681                     [64]                      --
│    └─Empty: 2-1682                     [64]                      --
│    └─BatchNorm2d: 2-1683               [16, 64, 64, 64]          --
│    └─Scaler: 2-1684                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1685                      [16, 64, 64, 64]          --
│    └─Empty: 2-1686                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1687                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-127        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1688                 [16, 64, 32, 32]          --
│    └─Empty: 2-1689                     [16, 64, 32, 32]          --
│    └─Empty: 2-1690                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1691        --                        --
│    └─One: 2-1692                       [1]                       --
│    └─OutputScale: 2-1693               --                        --
│    └─Empty: 2-1694                     [64, 64, 3, 3]            --
│    └─Empty: 2-1695                     [64, 64, 3, 3]            --
│    └─Empty: 2-1696                     [64]                      --
│    └─Empty: 2-1697                     [64]                      --
│    └─BatchNorm2d: 2-1698               [16, 64, 32, 32]          --
│    └─Scaler: 2-1699                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1700                      [16, 64, 32, 32]          --
│    └─Empty: 2-1701                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1702                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-128               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1703        --                        --
│    └─One: 2-1704                       [1]                       --
│    └─OutputScale: 2-1705               --                        --
│    └─Empty: 2-1706                     [64, 64, 1, 1]            --
│    └─Empty: 2-1707                     [64, 64, 1, 1]            --
│    └─Empty: 2-1708                     [64]                      --
│    └─Empty: 2-1709                     [64]                      --
│    └─BatchNorm2d: 2-1710               [16, 64, 32, 32]          --
│    └─Scaler: 2-1711                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1712                      [16, 64, 32, 32]          --
│    └─Empty: 2-1713                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1714                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-129        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1715                 [16, 64, 32, 32]          --
│    └─Empty: 2-1716                     [16, 64, 32, 32]          --
│    └─Empty: 2-1717                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1718        --                        --
│    └─One: 2-1719                       [1]                       --
│    └─OutputScale: 2-1720               --                        --
│    └─Empty: 2-1721                     [64, 64, 3, 3]            --
│    └─Empty: 2-1722                     [64, 64, 3, 3]            --
│    └─Empty: 2-1723                     [64]                      --
│    └─Empty: 2-1724                     [64]                      --
│    └─BatchNorm2d: 2-1725               [16, 64, 32, 32]          --
│    └─Scaler: 2-1726                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1727                      [16, 64, 32, 32]          --
│    └─Empty: 2-1728                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1729                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1730                 [16, 64, 16, 16]          --
│    └─Empty: 2-1731                     [16, 64, 16, 16]          --
│    └─Empty: 2-1732                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1733        --                        --
│    └─One: 2-1734                       [1]                       --
│    └─OutputScale: 2-1735               --                        --
│    └─Empty: 2-1736                     [64, 64, 3, 3]            --
│    └─Empty: 2-1737                     [64, 64, 3, 3]            --
│    └─Empty: 2-1738                     [64]                      --
│    └─Empty: 2-1739                     [64]                      --
│    └─BatchNorm2d: 2-1740               [16, 64, 16, 16]          --
│    └─Scaler: 2-1741                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1742                      [16, 64, 16, 16]          --
│    └─Empty: 2-1743                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1744                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-131               [16, 4, 16, 16]           (recursive)
│    └─OutputShiftSqueeze: 2-1745        --                        --
│    └─One: 2-1746                       [1]                       --
│    └─OutputScale: 2-1747               --                        --
│    └─Empty: 2-1748                     [4, 64, 1, 1]             --
│    └─Empty: 2-1749                     [4, 64, 1, 1]             --
│    └─Empty: 2-1750                     [4]                       --
│    └─Empty: 2-1751                     [4]                       --
│    └─BatchNorm2d: 2-1752               [16, 4, 16, 16]           --
│    └─Scaler: 2-1753                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1754                      [16, 4, 16, 16]           --
│    └─Empty: 2-1755                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1756                     [16, 4, 16, 16]           --
├─FusedMaxPoolConv2dBNReLU: 1-132        [16, 4, 16, 16]           (recursive)
│    └─MaxPool2d: 2-1757                 [16, 64, 16, 16]          --
│    └─Empty: 2-1758                     [16, 64, 16, 16]          --
│    └─Empty: 2-1759                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1760        --                        --
│    └─One: 2-1761                       [1]                       --
│    └─OutputScale: 2-1762               --                        --
│    └─Empty: 2-1763                     [4, 64, 3, 3]             --
│    └─Empty: 2-1764                     [4, 64, 3, 3]             --
│    └─Empty: 2-1765                     [4]                       --
│    └─Empty: 2-1766                     [4]                       --
│    └─BatchNorm2d: 2-1767               [16, 4, 16, 16]           --
│    └─Scaler: 2-1768                    [16, 4, 16, 16]           --
│    └─ReLU: 2-1769                      [16, 4, 16, 16]           --
│    └─Empty: 2-1770                     [16, 4, 16, 16]           --
│    └─Clamp: 2-1771                     [16, 4, 16, 16]           --
├─Conv1d: 1-133                          [16, 4, 14]               12,298
│    └─OutputShiftSqueeze: 2-1772        --                        --
│    └─One: 2-1773                       [1]                       --
│    └─OutputScale: 2-1774               --                        --
│    └─Empty: 2-1775                     [4, 1024, 3]              --
│    └─Empty: 2-1776                     [4, 1024, 3]              --
│    └─Empty: 2-1777                     [4]                       --
│    └─Empty: 2-1778                     [4]                       --
│    └─Scaler: 2-1779                    [16, 4, 14]               --
│    └─Empty: 2-1780                     [16, 4, 14]               --
│    └─Empty: 2-1781                     [16, 4, 14]               --
│    └─Clamp: 2-1782                     [16, 4, 14]               --
==========================================================================================
Total params: 169,922
Trainable params: 169,868
Non-trainable params: 54
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.63
Estimated Total Size (MB): 201.96
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.377 | Acc: 32.875% | Wgt Acc: 32.806%
	I - Batch: 100 | Loss: 1.275 | Acc: 39.062% | Wgt Acc: 39.592%
	I - Batch: 150 | Loss: 1.208 | Acc: 42.458% | Wgt Acc: 43.117%
I - num batch: 160
I - Train -- Loss: 1.200 | Acc: 43.070% | Wgt Acc: 43.666% | LR: 1.000000e-03 | Dur: 110.42s
I - Confusion Matrix: [row->prediction - col->label]
[[315.  61.  83. 168.]
 [103. 317. 324.  70.]
 [ 94. 132. 234.  69.]
 [185.  68.  93. 231.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.177 | Acc: 48.012% | Wgt Acc: 48.030% | Dur: 12.15s
I - Confusion Matrix: [row->prediction - col->label]
[[49. 14. 15. 27.]
 [ 2. 32. 12.  5.]
 [ 3. 24. 29.  7.]
 [34.  8. 19. 47.]]

I - Local maximum validation set accuracy:  48.01

I - Validation set results: 
[14-1-2-0.10][50-3-3-0.99][124-2-3-0.39][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-3-0.44][615-0-3-0.90][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.99][1212-3-3-0.90][1368-0-2-0.83][2181-2-0-0.15][2476-2-3-0.99][2721-2-2-0.99][2818-1-2-0.91][2886-2-1-0.99]
[3231-2-1-0.99][3333-2-3-0.56][3482-2-2-0.35][3536-3-3-0.82][3625-1-1-0.99][3909-0-3-0.99][4035-0-3-0.99][4140-0-0-0.99][4214-1-3-0.01][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-3-0.97][4838-3-2--0.26][4845-1-2-0.45][4868-0-0-0.99][4939-0-0-0.84][4984-2-3-0.92][5078-1-2-0.75][5396-0-0-0.99][5479-1-2--0.03]
[5717-0-0-0.99][5843-1-1-0.70][5949-3-0-0.99][5987-2-2-0.99][6014-3-0-0.15][6033-3-0-0.99][6313-0-3-0.99][6421-3-0-0.99][6500-1-0-0.99][6583-3-3-0.99]
[6683-3-3-0.06][6825-2-3-0.99][6998-3-3-0.86][7049-3-3-0.43][7517-1-1-0.99][7521-1-0-0.63][7528-1-3-0.99][7949-1-2-0.52][8135-1-0-0.99][8185-3-3-0.99]
[8269-3-1-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-0-0.99][8672-0-3-0.99][8903-1-2-0.39][9001-2-1-0.68][9036-2-0-0.36][9281-3-0--0.56][9300-2-0-0.65]
[9571-0-3-0.99][9617-1-0-0.58][9644-2-2-0.81][9705-2-2-0.64][9801-0-3-0.98][9803-3-0-0.99][9865-3-0-0.99][9896-2-2-0.99][10314-1-2-0.91][10337-3-0-0.99]
[10403-0-0-0.24][10653-2-1-0.53][10704-2-3-0.99][10719-1-2-0.97][10727-1-1-0.99][10836-0-3-0.99][10969-2-3-0.99][11042-0-3-0.99][11088-1-2-0.96][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-3-0.99][11502-3-3-0.99][11512-3-3-0.94][11608-1-1-0.98][11610-0-3-0.94][11692-0-3-0.99][11905-0-0-0.99][11993-1-2-0.99][12002-2-3-0.99]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-2-0.99][12320-1-2-0.97][12377-2-1-0.99][12398-2-0-0.19][12503-1-1-0.99][12617-0-3-0.39][12685-3-1-0.04][12738-2-3-0.97]
[12742-2-2-0.95][12823-0-3-0.99][13110-1-1-0.60][13240-3-3-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.99][13763-2-3-0.99][13905-3-2-0.62][14060-2-0-0.17]
[14065-3-3-0.64][14147-3-3-0.50][14595-2-2-0.99][14687-2-2--0.15][14788-2-3-0.99][14869-1-1-0.99][14872-3-2-0.73][14877-1-0-0.59][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-2-0.99][15178-2-0-0.37][15375-3-3-0.92][15389-3-3-0.99][15568-2-2--0.02][15675-3-3-0.99][15869-1-3-0.33][16207-3-0-0.76][16236-0-3-0.42][16302-3-3-0.06]
[16331-2-2-0.98][16381-0-0-0.99][16488-1-1-0.93][16495-0-0-0.99][16650-0-0-0.99][16719-1-1--0.17][16801-0-0-0.99][16828-0-0-0.98][17137-3-3-0.98][17245-1-2-0.14]
[17278-3-1-0.77][17282-0-0-0.97][17311-2-2-0.82][17336-2-2-0.46][17608-3-3-0.99][17627-0-2-0.61][17877-3-1-0.99][17924-1-2-0.33][17984-3-0-0.99][18211-0-3-0.99]
[18276-3-0-0.99][18287-1-3-0.85][18394-0-3-0.99][18428-0-0-0.99][18442-0-0-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-3-0.96][18663-0-0-0.98][18718-0-3-0.99]
[18766-2-2-0.93][18824-2-0--0.06][18890-3-2-0.36][18930-3-0-0.99][18938-3-3-0.99][19817-1-2-0.99][19839-0-2-0.56][19930-3-0-0.99][19944-0-1-0.31][20036-2-0-0.58]
[20101-3-3-0.99][20474-1-2-0.98][20547-3-0-0.22][20929-2-2-0.74][21245-1-1-0.99][21257-3-0-0.69][21293-1-1-0.15][21316-1-1-0.99][21384-1-2-0.99][21448-1-1-0.44]
[21483-0-0-0.99][21487-2-2-0.93][21714-0-3-0.28][21943-3-2-0.35][21947-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21998-1-3-0.72][22025-0-3-0.65][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-3-0.99][22811-3-3-0.99][22976-3-0-0.66][22985-3-0-0.99][23014-0-3-0.99][23112-1-1-0.77][23144-3-0-0.99][23168-2-0-0.99]
[23219-0-0-0.99][23363-3-3-0.99][23470-0-0-0.99][23486-2-3-0.43][23497-0-0-0.99][23516-0-0-0.99][23690-1-1-0.99][23921-2-2-0.13][23936-1-3-0.99][24040-3-2-0.45]
[24111-1-1-0.99][24182-0-3-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.99][24364-1-2-0.27][24427-3-3-0.99][24477-2-2-0.31][24495-2-0-0.51][24893-2-2-0.98]
[25012-1-0-0.31][25121-2-0-0.99][25165-3-0-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-3-0.99][25574-2-3-0.31][25644-1-1-0.99][25718-1-1-0.13][25774-2-3-0.95]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-0-0.57][26321-1-1--0.27][26732-1-1-0.14][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-2-0.57][26860-1-2-0.35]
[26948-0-0-0.95][27049-3-0-0.99][27098-1-2-0.37][27526-0-0-0.99][27639-3-3-0.99][27698-3-3-0.99][27772-0-3-0.99][27890-1-0-0.81][28040-0-0-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-3-0.99][29777-0-0-0.99][29877-2-3-0.97][30035-1-1-0.99][30098-0-0-0.99][30326-1-0-0.40][30572-2-3-0.26][30716-0-0-0.99]
[30806-2-3-0.17][30906-1-1-0.99][31007-0-0-0.70][31181-3-3-0.42][31238-0-3-0.99][31347-0-3-0.99][31422-2-1-0.66][31429-3-0-0.99][31431-0-3-0.99][31432-1-0-0.82]
[31477-0-0-0.99][31524-1-0-0.61][31597-1-2-0.99][31619-1-2-0.64][31701-0-3-0.98][31755-0-3-0.96][31854-3-3-0.99][32074-1-0-0.14][32078-3-3-0.69][32111-1-1-0.99]
[32127-1-1-0.99][32140-3-3-0.75][32263-2-0-0.95][32365-0-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-0-0.99][32584-0-0-0.99][32622-0-1-0.14]
[32858-3-3-0.62][32969-3-3-0.99][33016-2-1-0.99][33031-1-0-0.99][33035-2-2-0.88][33133-2-1-0.75][33173-2-3-0.03][33175-3-1-0.99][33306-3-2-0.66][33309-2-2-0.77]
[33474-0-3-0.94][33478-2-0-0.97][33618-1-1-0.59][33712-0-0-0.99][33782-2-1-0.99][33914-3-3-0.87][34076-3-3-0.83][34112-2-1--0.40][34138-2-2-0.96][34239-1-1-0.45]
[34364-2-1-0.99][34617-1-3-0.52][34751-3-3-0.99][34783-2-2-0.76][35015-3-3-0.31][35018-1-1-0.79][35288-2-3-0.80]
---------------------------
I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.019 | Acc: 55.250% | Wgt Acc: 55.288%
	I - Batch: 100 | Loss: 1.025 | Acc: 53.375% | Wgt Acc: 53.648%
	I - Batch: 150 | Loss: 1.032 | Acc: 52.750% | Wgt Acc: 53.206%
I - num batch: 160
I - Train -- Loss: 1.036 | Acc: 52.964% | Wgt Acc: 53.388% | LR: 1.000000e-03 | Dur: 109.15s
I - Confusion Matrix: [row->prediction - col->label]
[[438.  34.  61. 199.]
 [ 67. 408. 349.  70.]
 [ 44.  98. 272.  38.]
 [148.  38.  52. 231.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.147 | Acc: 48.318% | Wgt Acc: 48.098% | Dur: 11.79s
I - Confusion Matrix: [row->prediction - col->label]
[[50.  3.  3. 28.]
 [11. 46. 38. 11.]
 [15. 29. 32. 17.]
 [12.  0.  2. 30.]]

I - Local maximum validation set accuracy:  48.32

I - Validation set results: 
[14-1-1-0.99][50-3-1-0.60][124-2-2-0.99][127-0-0-0.99][443-2-1-0.99][567-0-0-0.99][573-1-1-0.40][615-0-3-0.98][695-1-2-0.94][722-3-0-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-2-0.67][1212-3-3-0.72][1368-0-0-0.99][2181-2-2-0.86][2476-2-1-0.97][2721-2-1-0.99][2818-1-2-0.99][2886-2-1-0.99]
[3231-2-1-0.99][3333-2-1-0.68][3482-2-2-0.99][3536-3-3--0.53][3625-1-1-0.99][3909-0-1-0.82][4035-0-3-0.67][4140-0-0-0.24][4214-1-2--0.03][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-1-0.99][4838-3-2-0.70][4845-1-2-0.87][4868-0-0-0.47][4939-0-1-0.99][4984-2-0-0.62][5078-1-2-0.98][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.59][5843-1-1-0.99][5949-3-0-0.57][5987-2-1-0.99][6014-3-2-0.01][6033-3-0-0.98][6313-0-3-0.99][6421-3-3-0.84][6500-1-1-0.67][6583-3-3-0.84]
[6683-3-1-0.99][6825-2-1-0.13][6998-3-2-0.91][7049-3-2-0.26][7517-1-1-0.99][7521-1-1-0.69][7528-1-2--0.43][7949-1-2-0.99][8135-1-0-0.43][8185-3-3-0.99]
[8269-3-2-0.83][8273-3-3-0.55][8543-3-0-0.99][8666-1-1-0.85][8672-0-3-0.85][8903-1-2-0.70][9001-2-2-0.94][9036-2-2-0.99][9281-3-1--0.22][9300-2-1-0.99]
[9571-0-0-0.84][9617-1-1-0.99][9644-2-2-0.99][9705-2-2-0.99][9801-0-1-0.17][9803-3-3--0.54][9865-3-0-0.99][9896-2-1-0.99][10314-1-1-0.99][10337-3-0-0.99]
[10403-0-2-0.95][10653-2-1-0.99][10704-2-1-0.79][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-2--0.17][11042-0-0-0.99][11088-1-2-0.99][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0--0.29][11502-3-3-0.96][11512-3-1-0.89][11608-1-1-0.99][11610-0-2--0.07][11692-0-3-0.99][11905-0-0-0.99][11993-1-1-0.99][12002-2-2--0.04]
[12052-0-0-0.64][12201-0-0-0.99][12235-2-1-0.99][12320-1-2-0.94][12377-2-2-0.99][12398-2-2--0.69][12503-1-2-0.99][12617-0-1-0.96][12685-3-2-0.32][12738-2-2-0.98]
[12742-2-2-0.99][12823-0-0-0.99][13110-1-2-0.95][13240-3-0-0.38][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.99][13763-2-1-0.44][13905-3-2--0.18][14060-2-1-0.99]
[14065-3-3-0.29][14147-3-2-0.83][14595-2-1-0.99][14687-2-2-0.80][14788-2-2-0.88][14869-1-1-0.86][14872-3-0-0.04][14877-1-2-0.99][14927-0-3-0.98][15066-0-0-0.99]
[15175-1-2-0.99][15178-2-0-0.02][15375-3-0-0.91][15389-3-3-0.99][15568-2-1-0.99][15675-3-1-0.10][15869-1-2-0.99][16207-3-0-0.80][16236-0-2-0.15][16302-3-0-0.90]
[16331-2-2-0.99][16381-0-0-0.99][16488-1-1-0.99][16495-0-0-0.99][16650-0-0-0.99][16719-1-2-0.66][16801-0-0-0.99][16828-0-0-0.91][17137-3-0-0.64][17245-1-2-0.74]
[17278-3-1-0.13][17282-0-2-0.28][17311-2-2-0.99][17336-2-1-0.99][17608-3-3-0.99][17627-0-2-0.40][17877-3-1-0.99][17924-1-2-0.82][17984-3-0-0.99][18211-0-0--0.01]
[18276-3-0-0.99][18287-1-1-0.62][18394-0-0-0.99][18428-0-0--0.06][18442-0-0-0.99][18478-3-0-0.99][18607-0-1-0.99][18616-0-1--0.60][18663-0-2--0.22][18718-0-0-0.99]
[18766-2-1-0.99][18824-2-1-0.99][18890-3-2-0.99][18930-3-2-0.90][18938-3-3-0.24][19817-1-2-0.99][19839-0-1-0.99][19930-3-3-0.30][19944-0-1-0.99][20036-2-1-0.99]
[20101-3-3--0.12][20474-1-2-0.99][20547-3-0-0.32][20929-2-1-0.99][21245-1-1-0.99][21257-3-0--0.21][21293-1-1-0.99][21316-1-2-0.77][21384-1-2-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-1-0.99][21714-0-2-0.38][21943-3-2-0.99][21947-0-0-0.94][21948-0-0-0.99][21965-2-1-0.99][21998-1-1-0.95][22025-0-2-0.12][22228-3-0-0.77]
[22446-1-1-0.99][22494-3-0-0.98][22757-0-0-0.99][22811-3-3-0.99][22976-3-2-0.74][22985-3-0-0.86][23014-0-0-0.99][23112-1-1-0.99][23144-3-0-0.99][23168-2-1-0.13]
[23219-0-0-0.85][23363-3-3-0.68][23470-0-2-0.53][23486-2-2-0.13][23497-0-3-0.99][23516-0-0-0.99][23690-1-1-0.42][23921-2-1-0.99][23936-1-2-0.99][24040-3-2-0.99]
[24111-1-1-0.99][24182-0-3-0.99][24238-3-3-0.99][24290-2-0-0.67][24345-0-0-0.82][24364-1-2-0.84][24427-3-0-0.28][24477-2-2-0.99][24495-2-1-0.84][24893-2-2-0.99]
[25012-1-2-0.64][25121-2-2-0.99][25165-3-0--0.06][25183-0-1-0.19][25297-3-3-0.68][25398-0-0-0.38][25574-2-2-0.91][25644-1-1-0.99][25718-1-1-0.10][25774-2-1-0.99]
[26032-3-3-0.82][26051-3-3-0.99][26120-0-2-0.25][26321-1-1-0.79][26732-1-1-0.97][26784-3-3-0.99][26827-3-3--0.21][26833-0-3-0.99][26838-2-2-0.88][26860-1-2-0.99]
[26948-0-0-0.61][27049-3-0--0.17][27098-1-1-0.93][27526-0-0-0.99][27639-3-3--0.08][27698-3-3-0.77][27772-0-0-0.99][27890-1-1-0.99][28040-0-0-0.55][28503-2-1-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-1-0.99][29777-0-0-0.99][29877-2-2-0.49][30035-1-1-0.99][30098-0-0-0.18][30326-1-1-0.99][30572-2-2-0.89][30716-0-1-0.99]
[30806-2-1-0.82][30906-1-1-0.99][31007-0-2-0.78][31181-3-2-0.43][31238-0-0-0.88][31347-0-3-0.99][31422-2-1-0.99][31429-3-0--0.22][31431-0-2--0.34][31432-1-1-0.99]
[31477-0-3-0.99][31524-1-0--0.15][31597-1-2-0.99][31619-1-2-0.99][31701-0-0-0.99][31755-0-3-0.99][31854-3-3--0.17][32074-1-2-0.59][32078-3-2-0.93][32111-1-1-0.99]
[32127-1-1-0.99][32140-3-3-0.99][32263-2-2-0.60][32365-0-0-0.67][32411-2-3-0.99][32429-3-3-0.99][32473-3-0-0.92][32574-3-3-0.95][32584-0-1-0.08][32622-0-2-0.95]
[32858-3-0-0.52][32969-3-0-0.99][33016-2-2-0.99][33031-1-1--0.90][33035-2-2-0.99][33133-2-1-0.99][33173-2-1-0.98][33175-3-1-0.99][33306-3-1-0.99][33309-2-2-0.76]
[33474-0-2-0.23][33478-2-2-0.42][33618-1-1-0.67][33712-0-0-0.21][33782-2-1-0.99][33914-3-3-0.93][34076-3-2-0.30][34112-2-1-0.96][34138-2-1-0.99][34239-1-1-0.99]
[34364-2-1-0.99][34617-1-1-0.99][34751-3-3-0.94][34783-2-1-0.99][35015-3-2-0.07][35018-1-1-0.99][35288-2-3-0.22]
---------------------------
I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 0.975 | Acc: 57.875% | Wgt Acc: 57.739%
	I - Batch: 100 | Loss: 0.959 | Acc: 58.438% | Wgt Acc: 58.683%
	I - Batch: 150 | Loss: 0.961 | Acc: 59.292% | Wgt Acc: 59.465%
I - num batch: 160
I - Train -- Loss: 0.964 | Acc: 59.207% | Wgt Acc: 59.342% | LR: 1.000000e-03 | Dur: 111.14s
I - Confusion Matrix: [row->prediction - col->label]
[[476.  28.  40. 170.]
 [ 44. 404. 282.  53.]
 [ 43. 109. 356.  43.]
 [134.  37.  56. 272.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.062 | Acc: 53.823% | Wgt Acc: 54.552% | Dur: 11.33s
I - Confusion Matrix: [row->prediction - col->label]
[[48.  2.  4. 17.]
 [ 8. 47. 33. 12.]
 [ 8. 25. 29.  5.]
 [24.  4.  9. 52.]]

I - Local maximum validation set accuracy:  53.82

I - Validation set results: 
[14-1-1-0.99][50-3-1-0.86][124-2-2-0.92][127-0-3-0.99][443-2-1-0.99][567-0-0-0.97][573-1-1-0.84][615-0-3-0.99][695-1-2-0.79][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.22][1212-3-3--0.46][1368-0-0-0.99][2181-2-2--0.49][2476-2-1-0.64][2721-2-2-0.99][2818-1-2-0.32][2886-2-1-0.99]
[3231-2-1-0.95][3333-2-1-0.97][3482-2-2-0.60][3536-3-3-0.99][3625-1-1-0.99][3909-0-1--0.47][4035-0-3-0.99][4140-0-0-0.78][4214-1-1--0.04][4346-1-3-0.05]
[4581-2-2-0.99][4708-3-1-0.49][4838-3-3--0.34][4845-1-1-0.67][4868-0-0-0.81][4939-0-1-0.99][4984-2-0-0.91][5078-1-2-0.63][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0--0.26][5843-1-1-0.87][5949-3-3-0.96][5987-2-1-0.99][6014-3-1--0.64][6033-3-0-0.99][6313-0-3-0.99][6421-3-3-0.99][6500-1-1-0.79][6583-3-3-0.98]
[6683-3-1-0.42][6825-2-3-0.99][6998-3-3--0.25][7049-3-3--0.16][7517-1-1-0.99][7521-1-3--0.04][7528-1-2--0.17][7949-1-2-0.99][8135-1-0-0.58][8185-3-3-0.99]
[8269-3-1-0.47][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.95][8672-0-0-0.99][8903-1-2-0.61][9001-2-1-0.99][9036-2-1-0.99][9281-3-1-0.23][9300-2-2-0.99]
[9571-0-3-0.56][9617-1-1-0.26][9644-2-2-0.99][9705-2-2--0.00][9801-0-3-0.43][9803-3-3-0.71][9865-3-0-0.99][9896-2-1-0.99][10314-1-1-0.99][10337-3-3-0.99]
[10403-0-2-0.28][10653-2-1-0.99][10704-2-1-0.99][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.73][11042-0-0--0.16][11088-1-2-0.87][11322-0-0-0.89]
[11398-2-2-0.95][11499-0-0--0.25][11502-3-3-0.99][11512-3-1-0.59][11608-1-1-0.99][11610-0-3--0.56][11692-0-3-0.99][11905-0-0-0.97][11993-1-2-0.78][12002-2-3-0.99]
[12052-0-0-0.73][12201-0-3-0.99][12235-2-1-0.99][12320-1-2-0.74][12377-2-1-0.99][12398-2-3--0.43][12503-1-2-0.49][12617-0-1-0.98][12685-3-3-0.64][12738-2-3-0.05]
[12742-2-1-0.91][12823-0-0-0.99][13110-1-3--0.71][13240-3-3-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.99][13763-2-3-0.77][13905-3-3-0.24][14060-2-1-0.99]
[14065-3-3-0.99][14147-3-3-0.09][14595-2-1-0.99][14687-2-2-0.99][14788-2-2-0.37][14869-1-1-0.99][14872-3-0-0.94][14877-1-2--0.35][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-2-0.55][15178-2-3--0.65][15375-3-3-0.99][15389-3-3-0.99][15568-2-1-0.99][15675-3-3-0.77][15869-1-2-0.99][16207-3-0-0.99][16236-0-2--0.53][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-3-0.86][16488-1-1-0.99][16495-0-0-0.70][16650-0-0-0.99][16719-1-2-0.83][16801-0-0-0.99][16828-0-0-0.87][17137-3-0-0.60][17245-1-2--0.05]
[17278-3-1-0.91][17282-0-0-0.32][17311-2-2-0.99][17336-2-1-0.99][17608-3-3-0.99][17627-0-3--0.29][17877-3-1-0.88][17924-1-0--0.29][17984-3-0-0.99][18211-0-3-0.83]
[18276-3-3-0.92][18287-1-1-0.99][18394-0-0-0.99][18428-0-1-0.42][18442-0-3-0.99][18478-3-0-0.29][18607-0-1-0.81][18616-0-0-0.48][18663-0-0-0.43][18718-0-0-0.99]
[18766-2-1-0.89][18824-2-1-0.99][18890-3-2-0.94][18930-3-2-0.72][18938-3-3-0.99][19817-1-2-0.86][19839-0-2-0.42][19930-3-3-0.62][19944-0-2-0.39][20036-2-1-0.99]
[20101-3-3-0.96][20474-1-1--0.22][20547-3-0--0.61][20929-2-2-0.72][21245-1-1-0.99][21257-3-3-0.46][21293-1-1-0.99][21316-1-1-0.99][21384-1-2-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-2--0.41][21943-3-1-0.09][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.36][22025-0-2-0.91][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.80][22757-0-0-0.99][22811-3-3-0.74][22976-3-1-0.99][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-0-0.99][23168-2-0-0.94]
[23219-0-3-0.29][23363-3-3-0.99][23470-0-1-0.03][23486-2-2-0.04][23497-0-3-0.99][23516-0-3-0.99][23690-1-2-0.60][23921-2-1-0.99][23936-1-2-0.99][24040-3-2-0.98]
[24111-1-1-0.99][24182-0-3-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.31][24364-1-2-0.58][24427-3-3-0.93][24477-2-2-0.99][24495-2-1-0.99][24893-2-2-0.99]
[25012-1-1-0.01][25121-2-2-0.99][25165-3-3-0.99][25183-0-1--0.26][25297-3-3-0.99][25398-0-0-0.99][25574-2-3-0.54][25644-1-1-0.99][25718-1-1-0.99][25774-2-1-0.51]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-0-0.05][26321-1-1-0.74][26732-1-1-0.90][26784-3-3-0.99][26827-3-3-0.95][26833-0-3-0.99][26838-2-1-0.24][26860-1-2-0.94]
[26948-0-0-0.80][27049-3-0-0.99][27098-1-1--0.51][27526-0-0-0.99][27639-3-3-0.99][27698-3-3-0.99][27772-0-3-0.70][27890-1-1-0.99][28040-0-0--0.00][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-2--0.28][29777-0-0-0.99][29877-2-1-0.52][30035-1-1-0.99][30098-0-3-0.99][30326-1-1-0.99][30572-2-2-0.97][30716-0-1-0.99]
[30806-2-2--0.26][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.99][31238-0-0-0.82][31347-0-3-0.99][31422-2-1-0.74][31429-3-3-0.08][31431-0-3-0.99][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-2--0.29][31597-1-2-0.99][31619-1-2-0.03][31701-0-0-0.99][31755-0-0-0.30][31854-3-3-0.35][32074-1-1--0.05][32078-3-3-0.79][32111-1-1-0.94]
[32127-1-1-0.98][32140-3-3-0.99][32263-2-1-0.79][32365-0-0--0.52][32411-2-3-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-3-0.99][32584-0-2--0.62][32622-0-2-0.20]
[32858-3-0-0.91][32969-3-3-0.98][33016-2-2-0.99][33031-1-3-0.96][33035-2-2-0.99][33133-2-2-0.99][33173-2-2-0.69][33175-3-1-0.99][33306-3-2-0.94][33309-2-0--0.29]
[33474-0-0-0.52][33478-2-2-0.45][33618-1-1-0.98][33712-0-3--0.79][33782-2-1-0.99][33914-3-3-0.73][34076-3-3-0.97][34112-2-1-0.99][34138-2-2-0.89][34239-1-2-0.61]
[34364-2-1-0.92][34617-1-1-0.99][34751-3-3-0.99][34783-2-1-0.99][35015-3-3-0.54][35018-1-1-0.99][35288-2-1-0.16]
---------------------------
I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 0.930 | Acc: 59.500% | Wgt Acc: 60.258%
	I - Batch: 100 | Loss: 0.944 | Acc: 59.438% | Wgt Acc: 59.556%
	I - Batch: 150 | Loss: 0.943 | Acc: 60.042% | Wgt Acc: 60.103%
I - num batch: 160
I - Train -- Loss: 0.941 | Acc: 60.346% | Wgt Acc: 60.412% | LR: 1.000000e-03 | Dur: 108.91s
I - Confusion Matrix: [row->prediction - col->label]
[[515.  27.  41. 187.]
 [ 39. 427. 313.  56.]
 [ 35.  88. 341.  41.]
 [108.  36.  39. 254.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.077 | Acc: 53.823% | Wgt Acc: 53.804% | Dur: 11.59s
I - Confusion Matrix: [row->prediction - col->label]
[[38.  2.  2.  8.]
 [ 4. 39. 19.  4.]
 [15. 34. 50. 25.]
 [31.  3.  4. 49.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 0.881 | Acc: 64.250% | Wgt Acc: 64.595%
	I - Batch: 100 | Loss: 0.883 | Acc: 64.875% | Wgt Acc: 64.820%
	I - Batch: 150 | Loss: 0.891 | Acc: 64.167% | Wgt Acc: 64.111%
I - num batch: 160
I - Train -- Loss: 0.893 | Acc: 63.958% | Wgt Acc: 63.907% | LR: 1.000000e-03 | Dur: 110.65s
I - Confusion Matrix: [row->prediction - col->label]
[[525.  23.  40. 162.]
 [ 40. 420. 251.  41.]
 [ 34.  88. 396.  47.]
 [ 98.  47.  47. 288.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.023 | Acc: 54.434% | Wgt Acc: 55.027% | Dur: 11.67s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  8. 35.]
 [ 4. 62. 44. 12.]
 [ 3.  8. 15.  3.]
 [16.  3.  8. 36.]]

I - Local maximum validation set accuracy:  54.43

I - Validation set results: 
[14-1-1-0.99][50-3-1-0.30][124-2-1--0.89][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.99][615-0-3-0.99][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.45][1212-3-3-0.97][1368-0-0-0.99][2181-2-3-0.69][2476-2-1-0.97][2721-2-2-0.99][2818-1-1-0.21][2886-2-1-0.99]
[3231-2-1-0.99][3333-2-1-0.99][3482-2-1-0.99][3536-3-0-0.92][3625-1-1-0.99][3909-0-0-0.65][4035-0-0-0.99][4140-0-0-0.51][4214-1-1-0.33][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-1-0.31][4838-3-0-0.48][4845-1-1-0.82][4868-0-0-0.99][4939-0-2--0.45][4984-2-2-0.07][5078-1-1-0.40][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.74][5843-1-1-0.99][5949-3-0-0.99][5987-2-1-0.99][6014-3-3--0.16][6033-3-0-0.98][6313-0-0-0.72][6421-3-3-0.99][6500-1-1-0.34][6583-3-3-0.99]
[6683-3-1-0.96][6825-2-3-0.76][6998-3-0--0.29][7049-3-3-0.27][7517-1-1-0.99][7521-1-1-0.99][7528-1-3-0.71][7949-1-1-0.12][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-1-0.65][8273-3-3-0.92][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-3-0.88][9001-2-1-0.99][9036-2-2-0.99][9281-3-1-0.75][9300-2-1-0.99]
[9571-0-3-0.48][9617-1-1-0.14][9644-2-2-0.58][9705-2-1--0.58][9801-0-3-0.24][9803-3-3-0.62][9865-3-0-0.99][9896-2-2-0.97][10314-1-1-0.84][10337-3-0-0.99]
[10403-0-0-0.40][10653-2-1-0.99][10704-2-1-0.99][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.83][11088-1-1-0.97][11322-0-0-0.99]
[11398-2-2-0.94][11499-0-0-0.50][11502-3-3-0.99][11512-3-1-0.51][11608-1-1-0.99][11610-0-0-0.84][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.96][12002-2-0-0.99]
[12052-0-0-0.74][12201-0-0-0.99][12235-2-1-0.99][12320-1-2--0.03][12377-2-1-0.74][12398-2-0--0.03][12503-1-1-0.99][12617-0-1-0.99][12685-3-0-0.37][12738-2-3-0.59]
[12742-2-1-0.99][12823-0-0-0.99][13110-1-1-0.99][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.99][13763-2-1-0.77][13905-3-2--0.86][14060-2-1-0.99]
[14065-3-0-0.94][14147-3-3-0.73][14595-2-1-0.99][14687-2-2-0.22][14788-2-3-0.42][14869-1-1-0.99][14872-3-0-0.38][14877-1-1-0.99][14927-0-3-0.40][15066-0-0-0.99]
[15175-1-1-0.62][15178-2-3-0.89][15375-3-3-0.40][15389-3-3-0.99][15568-2-1-0.99][15675-3-3-0.82][15869-1-1--0.87][16207-3-0-0.99][16236-0-3-0.16][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-0-0.99][16488-1-1-0.99][16495-0-0-0.36][16650-0-0-0.99][16719-1-1-0.18][16801-0-0-0.99][16828-0-0-0.99][17137-3-0-0.99][17245-1-0--0.64]
[17278-3-0--0.12][17282-0-0-0.82][17311-2-2-0.99][17336-2-1-0.99][17608-3-3-0.99][17627-0-3-0.23][17877-3-0-0.76][17924-1-0--0.66][17984-3-0-0.99][18211-0-3--0.25]
[18276-3-0-0.99][18287-1-1-0.99][18394-0-0-0.99][18428-0-0-0.39][18442-0-3-0.99][18478-3-0-0.79][18607-0-1-0.07][18616-0-0-0.66][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-1-0.96][18824-2-1-0.92][18890-3-2--0.16][18930-3-2--0.09][18938-3-3-0.99][19817-1-2-0.94][19839-0-2--0.19][19930-3-0-0.87][19944-0-1-0.99][20036-2-2-0.92]
[20101-3-3-0.93][20474-1-1-0.88][20547-3-0-0.12][20929-2-1-0.99][21245-1-1-0.99][21257-3-1-0.71][21293-1-1-0.99][21316-1-1-0.99][21384-1-2-0.99][21448-1-1-0.99]
[21483-0-0-0.99][21487-2-1-0.99][21714-0-3-0.31][21943-3-1--0.41][21947-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21998-1-1-0.99][22025-0-3--0.21][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-0-0.99][22811-3-0-0.99][22976-3-1-0.99][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-0-0.90][23168-2-0-0.99]
[23219-0-0-0.99][23363-3-3-0.99][23470-0-0--0.12][23486-2-3-0.40][23497-0-0-0.99][23516-0-0-0.99][23690-1-1-0.99][23921-2-1-0.94][23936-1-2-0.84][24040-3-0--0.21]
[24111-1-1-0.99][24182-0-3-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.61][24364-1-2--0.09][24427-3-3-0.94][24477-2-2-0.99][24495-2-1-0.81][24893-2-1-0.99]
[25012-1-1-0.73][25121-2-0-0.43][25165-3-3-0.99][25183-0-0-0.67][25297-3-3-0.99][25398-0-0-0.97][25574-2-1-0.99][25644-1-1-0.99][25718-1-1-0.94][25774-2-1--0.53]
[26032-3-3-0.92][26051-3-3-0.99][26120-0-0-0.02][26321-1-1-0.98][26732-1-1-0.96][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-1-0.06][26860-1-2-0.97]
[26948-0-0-0.76][27049-3-0-0.96][27098-1-1-0.15][27526-0-0-0.99][27639-3-3-0.76][27698-3-0-0.56][27772-0-0-0.99][27890-1-1-0.88][28040-0-0-0.86][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-1-0.01][29777-0-0-0.99][29877-2-1-0.44][30035-1-1-0.99][30098-0-3-0.90][30326-1-1-0.99][30572-2-1-0.87][30716-0-1-0.99]
[30806-2-0--0.91][30906-1-1-0.99][31007-0-0-0.04][31181-3-3-0.99][31238-0-3-0.99][31347-0-0-0.96][31422-2-0-0.95][31429-3-3--0.08][31431-0-3-0.00][31432-1-1-0.99]
[31477-0-3-0.99][31524-1-3-0.75][31597-1-1-0.43][31619-1-2-0.38][31701-0-0-0.99][31755-0-0-0.84][31854-3-3-0.99][32074-1-1-0.65][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-1-0.99][32140-3-3-0.99][32263-2-1-0.62][32365-0-0-0.80][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-0-0.99][32584-0-0-0.99][32622-0-2-0.10]
[32858-3-0-0.99][32969-3-0-0.99][33016-2-1-0.99][33031-1-0-0.22][33035-2-2-0.99][33133-2-1-0.99][33173-2-1-0.24][33175-3-1-0.99][33306-3-1-0.92][33309-2-1--0.28]
[33474-0-0-0.90][33478-2-3--0.15][33618-1-1-0.99][33712-0-0--0.13][33782-2-1-0.99][33914-3-3-0.99][34076-3-3-0.85][34112-2-1-0.99][34138-2-1-0.99][34239-1-1-0.99]
[34364-2-1-0.76][34617-1-1-0.42][34751-3-3-0.99][34783-2-1-0.99][35015-3-3-0.50][35018-1-1-0.99][35288-2-1--0.29]
---------------------------
I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 0.863 | Acc: 63.625% | Wgt Acc: 64.023%
	I - Batch: 100 | Loss: 0.878 | Acc: 65.438% | Wgt Acc: 65.335%
	I - Batch: 150 | Loss: 0.883 | Acc: 65.250% | Wgt Acc: 65.243%
I - num batch: 160
I - Train -- Loss: 0.879 | Acc: 65.607% | Wgt Acc: 65.649% | LR: 1.000000e-03 | Dur: 108.98s
I - Confusion Matrix: [row->prediction - col->label]
[[512.  29.  26. 140.]
 [ 43. 428. 241.  41.]
 [ 36.  93. 422.  48.]
 [106.  28.  45. 309.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.091 | Acc: 55.046% | Wgt Acc: 54.552% | Dur: 12.41s
I - Confusion Matrix: [row->prediction - col->label]
[[68. 11.  8. 28.]
 [ 1. 33. 16.  3.]
 [ 3. 19. 29.  5.]
 [16. 15. 22. 50.]]

I - Local maximum validation set accuracy:  55.05

I - Validation set results: 
[14-1-1-0.18][50-3-3-0.99][124-2-2-0.39][127-0-0-0.77][443-2-2-0.99][567-0-0-0.99][573-1-1-0.02][615-0-3-0.99][695-1-0-0.99][722-3-0-0.99]
[826-0-0-0.99][878-0-3-0.99][1103-0-0-0.26][1212-3-3-0.75][1368-0-0-0.97][2181-2-0-0.99][2476-2-0-0.43][2721-2-2-0.97][2818-1-2-0.42][2886-2-1-0.99]
[3231-2-1-0.99][3333-2-3-0.99][3482-2-2-0.18][3536-3-3-0.99][3625-1-1-0.99][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.67][4214-1-3-0.64][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-3-0.97][4838-3-2--0.51][4845-1-3-0.78][4868-0-0-0.99][4939-0-2--0.31][4984-2-2-0.99][5078-1-2-0.69][5396-0-0-0.99][5479-1-1-0.35]
[5717-0-0-0.99][5843-1-1-0.84][5949-3-0-0.99][5987-2-1-0.86][6014-3-3-0.10][6033-3-0-0.76][6313-0-0-0.99][6421-3-3-0.99][6500-1-0-0.49][6583-3-3-0.99]
[6683-3-3-0.91][6825-2-3-0.99][6998-3-0-0.29][7049-3-3-0.86][7517-1-1-0.99][7521-1-0-0.99][7528-1-3-0.99][7949-1-2-0.87][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-1-0.99][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.83][8672-0-0-0.99][8903-1-2-0.39][9001-2-1-0.78][9036-2-2-0.99][9281-3-3-0.91][9300-2-2-0.93]
[9571-0-3-0.99][9617-1-1-0.06][9644-2-2-0.65][9705-2-3-0.03][9801-0-0-0.99][9803-3-3-0.99][9865-3-3-0.99][9896-2-2-0.82][10314-1-0-0.35][10337-3-3-0.99]
[10403-0-0-0.08][10653-2-1-0.76][10704-2-1-0.99][10719-1-1-0.99][10727-1-1-0.56][10836-0-0-0.99][10969-2-3-0.99][11042-0-0-0.75][11088-1-2-0.99][11322-0-0-0.99]
[11398-2-2-0.94][11499-0-0-0.98][11502-3-3-0.83][11512-3-3-0.99][11608-1-1-0.86][11610-0-0-0.99][11692-0-0-0.99][11905-0-3-0.99][11993-1-0--0.96][12002-2-3-0.90]
[12052-0-0-0.99][12201-0-0-0.99][12235-2-2-0.98][12320-1-0-0.20][12377-2-2-0.04][12398-2-1-0.49][12503-1-2-0.99][12617-0-1-0.72][12685-3-3-0.99][12738-2-3-0.99]
[12742-2-1-0.71][12823-0-0-0.99][13110-1-3--0.11][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-3-0.87][13763-2-3-0.99][13905-3-2-0.95][14060-2-1-0.99]
[14065-3-3-0.92][14147-3-3-0.98][14595-2-3--0.37][14687-2-3-0.34][14788-2-3-0.99][14869-1-1-0.66][14872-3-0-0.69][14877-1-1-0.11][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-2-0.84][15178-2-3-0.99][15375-3-3-0.83][15389-3-3-0.99][15568-2-1-0.97][15675-3-3-0.97][15869-1-3-0.99][16207-3-0-0.99][16236-0-3-0.80][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-3-0.93][16488-1-1-0.25][16495-0-0-0.93][16650-0-0-0.99][16719-1-2-0.93][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.99][17245-1-3-0.91]
[17278-3-0--0.22][17282-0-0-0.99][17311-2-2-0.63][17336-2-3-0.90][17608-3-3-0.99][17627-0-0-0.41][17877-3-0-0.44][17924-1-3-0.39][17984-3-0-0.99][18211-0-3-0.99]
[18276-3-0-0.99][18287-1-3-0.78][18394-0-0-0.99][18428-0-0-0.96][18442-0-0-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-1-0.99][18824-2-2-0.28][18890-3-2-0.99][18930-3-2-0.15][18938-3-3-0.99][19817-1-2-0.99][19839-0-0-0.99][19930-3-3-0.99][19944-0-2-0.92][20036-2-2-0.92]
[20101-3-3-0.98][20474-1-1--0.40][20547-3-1-0.28][20929-2-2-0.49][21245-1-1-0.66][21257-3-3-0.74][21293-1-1-0.99][21316-1-1-0.90][21384-1-2-0.99][21448-1-1-0.53]
[21483-0-0-0.99][21487-2-2-0.73][21714-0-3-0.99][21943-3-3-0.04][21947-0-0-0.41][21948-0-0-0.99][21965-2-1-0.72][21998-1-3-0.19][22025-0-3-0.99][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-0-0.99][22811-3-0-0.99][22976-3-1-0.48][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.89][23144-3-0-0.99][23168-2-0-0.72]
[23219-0-3-0.92][23363-3-3-0.99][23470-0-0-0.90][23486-2-3-0.82][23497-0-0-0.99][23516-0-0-0.99][23690-1-2-0.83][23921-2-2-0.45][23936-1-2-0.99][24040-3-0-0.99]
[24111-1-1-0.63][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.17][24364-1-2-0.91][24427-3-0-0.98][24477-2-2-0.98][24495-2-0--0.24][24893-2-1-0.70]
[25012-1-2-0.04][25121-2-2-0.95][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-2--0.03][25644-1-1-0.99][25718-1-1-0.48][25774-2-3--0.15]
[26032-3-3-0.54][26051-3-3-0.99][26120-0-0-0.87][26321-1-3-0.90][26732-1-1--0.47][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-2--0.44][26860-1-2-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-0--0.21][27526-0-0-0.99][27639-3-3-0.97][27698-3-3-0.99][27772-0-0-0.95][27890-1-1-0.54][28040-0-0-0.43][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-0--0.61][29777-0-0-0.99][29877-2-3-0.43][30035-1-2-0.42][30098-0-3-0.99][30326-1-1-0.99][30572-2-3-0.83][30716-0-3-0.48]
[30806-2-3--0.28][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.99][31238-0-3-0.99][31347-0-0-0.99][31422-2-0-0.99][31429-3-0--0.11][31431-0-3-0.24][31432-1-1-0.69]
[31477-0-0-0.99][31524-1-3-0.00][31597-1-2-0.72][31619-1-0-0.99][31701-0-0-0.99][31755-0-0-0.72][31854-3-3-0.99][32074-1-3--0.48][32078-3-3-0.99][32111-1-0-0.13]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-0--0.16][32365-0-0-0.74][32411-2-3-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-0-0.99][32584-0-0--0.49][32622-0-2-0.61]
[32858-3-0-0.99][32969-3-0-0.99][33016-2-2-0.99][33031-1-3--0.35][33035-2-2-0.99][33133-2-1-0.54][33173-2-0--0.47][33175-3-2-0.99][33306-3-3--0.24][33309-2-3-0.41]
[33474-0-0-0.99][33478-2-3-0.99][33618-1-1--0.27][33712-0-0-0.53][33782-2-2-0.99][33914-3-3-0.99][34076-3-3-0.99][34112-2-1-0.99][34138-2-3-0.87][34239-1-3-0.23]
[34364-2-2-0.61][34617-1-2-0.80][34751-3-3-0.99][34783-2-1-0.41][35015-3-3-0.99][35018-1-1-0.73][35288-2-3-0.61]
---------------------------
I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 0.843 | Acc: 67.625% | Wgt Acc: 67.529%
	I - Batch: 100 | Loss: 0.844 | Acc: 67.562% | Wgt Acc: 67.579%
	I - Batch: 150 | Loss: 0.851 | Acc: 67.167% | Wgt Acc: 67.258%
I - num batch: 160
I - Train -- Loss: 0.852 | Acc: 66.902% | Wgt Acc: 66.932% | LR: 1.000000e-03 | Dur: 109.84s
I - Confusion Matrix: [row->prediction - col->label]
[[545.  24.  36. 142.]
 [ 37. 438. 249.  44.]
 [ 24.  87. 409.  40.]
 [ 91.  29.  40. 312.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.047 | Acc: 56.881% | Wgt Acc: 56.590% | Dur: 12.38s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  3.  7. 29.]
 [ 3. 47. 19.  5.]
 [ 8. 22. 30. 10.]
 [10.  6. 19. 42.]]

I - Local maximum validation set accuracy:  56.88

I - Validation set results: 
[14-1-1-0.44][50-3-1--0.50][124-2-2-0.10][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.99][615-0-3-0.99][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.26][1212-3-3-0.99][1368-0-0-0.31][2181-2-3-0.99][2476-2-2-0.33][2721-2-2-0.99][2818-1-2-0.98][2886-2-1-0.99]
[3231-2-1-0.99][3333-2-1-0.99][3482-2-2-0.88][3536-3-3-0.99][3625-1-1-0.99][3909-0-0-0.97][4035-0-0-0.99][4140-0-0-0.04][4214-1-3-0.88][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-2-0.99][4838-3-2-0.98][4845-1-1-0.43][4868-0-0-0.99][4939-0-2--0.08][4984-2-0-0.92][5078-1-2-0.99][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.78][5843-1-1-0.99][5949-3-0-0.99][5987-2-1-0.99][6014-3-3-0.86][6033-3-0-0.99][6313-0-3-0.99][6421-3-3-0.99][6500-1-0--0.51][6583-3-3-0.99]
[6683-3-1-0.53][6825-2-3-0.96][6998-3-2-0.85][7049-3-3-0.99][7517-1-1-0.99][7521-1-1-0.85][7528-1-3-0.99][7949-1-2-0.99][8135-1-0-0.98][8185-3-0-0.99]
[8269-3-1-0.97][8273-3-3-0.99][8543-3-0-0.99][8666-1-1-0.99][8672-0-0-0.99][8903-1-2-0.97][9001-2-0-0.41][9036-2-2-0.99][9281-3-1-0.24][9300-2-2-0.96]
[9571-0-3-0.92][9617-1-1-0.94][9644-2-2-0.99][9705-2-0--0.07][9801-0-0-0.99][9803-3-3-0.86][9865-3-0-0.99][9896-2-1-0.94][10314-1-1-0.99][10337-3-3-0.99]
[10403-0-2-0.04][10653-2-1-0.90][10704-2-1-0.99][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.99][11042-0-3-0.96][11088-1-1-0.69][11322-0-0-0.99]
[11398-2-2-0.85][11499-0-0-0.99][11502-3-0-0.97][11512-3-3-0.99][11608-1-1-0.99][11610-0-0-0.29][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.92][12002-2-3--0.34]
[12052-0-0-0.34][12201-0-0-0.99][12235-2-2-0.99][12320-1-2-0.88][12377-2-2-0.76][12398-2-3-0.87][12503-1-1-0.99][12617-0-1-0.78][12685-3-3-0.99][12738-2-3-0.99]
[12742-2-1-0.99][12823-0-0-0.99][13110-1-1-0.69][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-1-0.80][13763-2-3-0.99][13905-3-0-0.71][14060-2-1-0.99]
[14065-3-3-0.30][14147-3-3-0.99][14595-2-2-0.92][14687-2-2-0.93][14788-2-3-0.97][14869-1-1-0.99][14872-3-2-0.77][14877-1-1-0.99][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-2-0.99][15178-2-3-0.99][15375-3-3-0.94][15389-3-0-0.99][15568-2-1-0.99][15675-3-3-0.98][15869-1-3-0.23][16207-3-0-0.99][16236-0-2-0.84][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-0-0.83][16488-1-1-0.86][16495-0-0-0.99][16650-0-0-0.99][16719-1-1-0.99][16801-0-0-0.99][16828-0-0-0.90][17137-3-0-0.99][17245-1-2-0.13]
[17278-3-0--0.44][17282-0-0-0.37][17311-2-2-0.99][17336-2-3-0.71][17608-3-3-0.99][17627-0-0-0.50][17877-3-0-0.26][17924-1-2--0.12][17984-3-0-0.99][18211-0-3-0.63]
[18276-3-0-0.99][18287-1-1-0.99][18394-0-0-0.99][18428-0-0-0.57][18442-0-0-0.99][18478-3-0-0.87][18607-0-0-0.29][18616-0-1--0.15][18663-0-0-0.83][18718-0-0-0.99]
[18766-2-3-0.89][18824-2-1-0.99][18890-3-2-0.99][18930-3-2-0.23][18938-3-3-0.99][19817-1-2-0.99][19839-0-2-0.26][19930-3-3-0.89][19944-0-2-0.92][20036-2-2-0.99]
[20101-3-3-0.99][20474-1-2-0.78][20547-3-0--0.30][20929-2-1-0.99][21245-1-2-0.97][21257-3-3-0.77][21293-1-1-0.99][21316-1-3-0.62][21384-1-2-0.99][21448-1-1-0.99]
[21483-0-0-0.95][21487-2-2-0.94][21714-0-3-0.77][21943-3-2--0.02][21947-0-0-0.74][21948-0-0-0.99][21965-2-1-0.78][21998-1-1-0.57][22025-0-2-0.99][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-0-0.99][22811-3-0-0.99][22976-3-2-0.87][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0-0.46]
[23219-0-3-0.99][23363-3-3-0.98][23470-0-0-0.54][23486-2-3-0.86][23497-0-0-0.99][23516-0-0-0.99][23690-1-1-0.99][23921-2-1-0.97][23936-1-2-0.99][24040-3-0-0.81]
[24111-1-1-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.37][24364-1-3-0.83][24427-3-0-0.99][24477-2-2-0.93][24495-2-1-0.97][24893-2-1-0.78]
[25012-1-2-0.21][25121-2-2-0.64][25165-3-3-0.99][25183-0-0-0.29][25297-3-3-0.99][25398-0-0-0.99][25574-2-2-0.35][25644-1-1-0.99][25718-1-1-0.95][25774-2-3-0.98]
[26032-3-3-0.80][26051-3-3-0.99][26120-0-0-0.84][26321-1-1-0.94][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-2--0.03][26860-1-2-0.56]
[26948-0-2--0.41][27049-3-0-0.99][27098-1-1--0.07][27526-0-0-0.99][27639-3-3-0.99][27698-3-3-0.99][27772-0-0-0.63][27890-1-1-0.94][28040-0-0-0.99][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-2-0.57][29777-0-0-0.99][29877-2-3-0.95][30035-1-1-0.99][30098-0-0-0.99][30326-1-1-0.99][30572-2-2-0.99][30716-0-1-0.99]
[30806-2-3--0.33][30906-1-1-0.99][31007-0-0-0.61][31181-3-3-0.99][31238-0-3-0.99][31347-0-0-0.99][31422-2-0-0.97][31429-3-0-0.41][31431-0-0-0.12][31432-1-1-0.99]
[31477-0-0-0.99][31524-1-3-0.99][31597-1-2-0.83][31619-1-2-0.95][31701-0-0-0.99][31755-0-0-0.94][31854-3-3-0.99][32074-1-2--0.02][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-1-0.99][32140-3-3-0.99][32263-2-1--0.52][32365-0-0-0.76][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-3-0.99][32584-0-0-0.91][32622-0-2-0.97]
[32858-3-0-0.99][32969-3-0-0.99][33016-2-2-0.99][33031-1-1--0.02][33035-2-2-0.97][33133-2-2-0.58][33173-2-2--0.32][33175-3-1-0.99][33306-3-2-0.07][33309-2-3--0.09]
[33474-0-0-0.69][33478-2-3-0.89][33618-1-1-0.99][33712-0-0-0.52][33782-2-2-0.99][33914-3-3-0.99][34076-3-3-0.99][34112-2-2-0.98][34138-2-3-0.99][34239-1-2-0.95]
[34364-2-1-0.99][34617-1-2-0.98][34751-3-3-0.99][34783-2-1-0.90][35015-3-3-0.99][35018-1-2-0.99][35288-2-3-0.02]
---------------------------
I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 0.864 | Acc: 67.000% | Wgt Acc: 67.051%
	I - Batch: 100 | Loss: 0.829 | Acc: 70.688% | Wgt Acc: 70.492%
	I - Batch: 150 | Loss: 0.819 | Acc: 70.833% | Wgt Acc: 70.693%
I - num batch: 160
I - Train -- Loss: 0.821 | Acc: 70.711% | Wgt Acc: 70.577% | LR: 1.000000e-03 | Dur: 108.82s
I - Confusion Matrix: [row->prediction - col->label]
[[539.  24.  17. 111.]
 [ 39. 437. 177.  41.]
 [ 29.  93. 488.  49.]
 [ 90.  24.  52. 337.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.106 | Acc: 51.682% | Wgt Acc: 50.476% | Dur: 11.29s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 16. 14. 44.]
 [ 0. 32. 11.  3.]
 [ 4. 13. 29.  4.]
 [11. 17. 21. 35.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 0.805 | Acc: 71.875% | Wgt Acc: 72.012%
	I - Batch: 100 | Loss: 0.777 | Acc: 73.312% | Wgt Acc: 73.244%
	I - Batch: 150 | Loss: 0.785 | Acc: 73.042% | Wgt Acc: 72.733%
I - num batch: 160
I - Train -- Loss: 0.787 | Acc: 72.713% | Wgt Acc: 72.435% | LR: 1.000000e-03 | Dur: 109.59s
I - Confusion Matrix: [row->prediction - col->label]
[[553.  13.  32. 121.]
 [ 26. 441. 144.  30.]
 [ 33.  98. 519.  48.]
 [ 85.  26.  39. 339.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.037 | Acc: 58.104% | Wgt Acc: 58.016% | Dur: 11.39s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  7.  7. 29.]
 [ 4. 45. 26.  4.]
 [ 4. 18. 28.  4.]
 [12.  8. 14. 49.]]

I - Local maximum validation set accuracy:  58.10

I - Validation set results: 
[14-1-1-0.43][50-3-3-0.90][124-2-2-0.93][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.97][615-0-3-0.99][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.13][1212-3-3-0.52][1368-0-0-0.99][2181-2-3-0.79][2476-2-1-0.45][2721-2-2-0.99][2818-1-2--0.18][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-1-0.99][3482-2-2-0.91][3536-3-3-0.99][3625-1-1-0.99][3909-0-0-0.93][4035-0-0-0.99][4140-0-0-0.97][4214-1-3-0.81][4346-1-0-0.99]
[4581-2-2-0.99][4708-3-3-0.99][4838-3-0-0.11][4845-1-1-0.13][4868-0-0-0.99][4939-0-2--0.38][4984-2-1-0.03][5078-1-2-0.74][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.99][5949-3-0-0.99][5987-2-1-0.99][6014-3-1-0.15][6033-3-0-0.80][6313-0-0-0.99][6421-3-3-0.99][6500-1-0-0.50][6583-3-3-0.99]
[6683-3-3-0.63][6825-2-3-0.95][6998-3-3-0.47][7049-3-3-0.62][7517-1-1-0.99][7521-1-0-0.58][7528-1-3-0.88][7949-1-2-0.40][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-2-0.99][8273-3-3-0.97][8543-3-0-0.99][8666-1-1-0.65][8672-0-0-0.99][8903-1-2-0.47][9001-2-1-0.99][9036-2-2-0.99][9281-3-3-0.62][9300-2-2-0.99]
[9571-0-3-0.76][9617-1-0--0.35][9644-2-1-0.68][9705-2-2-0.60][9801-0-3-0.91][9803-3-3-0.99][9865-3-0-0.99][9896-2-2-0.95][10314-1-1-0.27][10337-3-0-0.99]
[10403-0-0-0.59][10653-2-1-0.99][10704-2-3-0.99][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3-0.95][11042-0-0-0.94][11088-1-1-0.38][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0-0.99][11502-3-3-0.99][11512-3-3-0.99][11608-1-1-0.99][11610-0-0-0.64][11692-0-0-0.99][11905-0-0-0.99][11993-1-1-0.82][12002-2-0-0.99]
[12052-0-0-0.86][12201-0-0-0.99][12235-2-1-0.96][12320-1-0-0.58][12377-2-1-0.51][12398-2-0-0.85][12503-1-2-0.99][12617-0-1-0.97][12685-3-3-0.90][12738-2-3-0.55]
[12742-2-1-0.98][12823-0-0-0.99][13110-1-2-0.99][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-2-0.58][13763-2-3-0.40][13905-3-3-0.64][14060-2-1-0.96]
[14065-3-3-0.66][14147-3-0-0.99][14595-2-1-0.99][14687-2-2-0.99][14788-2-3-0.80][14869-1-1-0.99][14872-3-0-0.52][14877-1-1-0.95][14927-0-3-0.99][15066-0-0-0.99]
[15175-1-2-0.63][15178-2-3-0.80][15375-3-3-0.89][15389-3-3-0.99][15568-2-1-0.99][15675-3-3-0.99][15869-1-3-0.50][16207-3-0-0.99][16236-0-2-0.33][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-0-0.99][16488-1-1-0.99][16495-0-0-0.15][16650-0-0-0.99][16719-1-1-0.75][16801-0-0-0.99][16828-0-0-0.99][17137-3-0-0.99][17245-1-3--0.21]
[17278-3-3--0.24][17282-0-0-0.99][17311-2-2-0.70][17336-2-1-0.99][17608-3-3-0.99][17627-0-1--0.27][17877-3-0-0.50][17924-1-2--0.42][17984-3-0-0.99][18211-0-3-0.99]
[18276-3-0-0.99][18287-1-1-0.58][18394-0-0-0.99][18428-0-0-0.99][18442-0-0-0.99][18478-3-3-0.08][18607-0-0-0.91][18616-0-0-0.62][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-1-0.97][18824-2-2-0.75][18890-3-2-0.99][18930-3-2-0.95][18938-3-3-0.99][19817-1-2-0.96][19839-0-2-0.05][19930-3-0-0.99][19944-0-1-0.99][20036-2-2-0.99]
[20101-3-3-0.52][20474-1-1--0.76][20547-3-3-0.99][20929-2-1-0.99][21245-1-1-0.94][21257-3-3-0.90][21293-1-1-0.99][21316-1-1-0.96][21384-1-2-0.99][21448-1-1-0.87]
[21483-0-0-0.99][21487-2-2-0.97][21714-0-3-0.99][21943-3-3--0.28][21947-0-0-0.53][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.70][22025-0-3-0.98][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-0-0.99][22811-3-0-0.99][22976-3-1-0.99][22985-3-0-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0-0.99]
[23219-0-3-0.99][23363-3-3-0.99][23470-0-0-0.97][23486-2-3-0.99][23497-0-0-0.99][23516-0-0-0.99][23690-1-3-0.81][23921-2-2-0.49][23936-1-2-0.85][24040-3-2-0.26]
[24111-1-1-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-1-0.84][24364-1-2-0.97][24427-3-3-0.99][24477-2-2-0.99][24495-2-1-0.30][24893-2-2-0.99]
[25012-1-1--0.09][25121-2-2-0.41][25165-3-3-0.99][25183-0-0-0.70][25297-3-3-0.99][25398-0-0-0.99][25574-2-1--0.53][25644-1-1-0.84][25718-1-1-0.99][25774-2-3-0.07]
[26032-3-3-0.99][26051-3-3-0.99][26120-0-0-0.92][26321-1-1-0.84][26732-1-1-0.47][26784-3-3-0.99][26827-3-3-0.99][26833-0-3-0.99][26838-2-1-0.03][26860-1-2-0.99]
[26948-0-0-0.99][27049-3-0-0.99][27098-1-1-0.79][27526-0-0-0.72][27639-3-3-0.99][27698-3-3-0.99][27772-0-0-0.99][27890-1-1-0.83][28040-0-0-0.99][28503-2-2-0.99]
[28577-1-2-0.99][28959-0-0-0.99][29198-3-0--0.45][29777-0-0-0.99][29877-2-2-0.56][30035-1-1-0.68][30098-0-3-0.99][30326-1-1-0.99][30572-2-1-0.72][30716-0-3-0.53]
[30806-2-3--0.80][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.99][31238-0-0-0.81][31347-0-0-0.99][31422-2-0-0.95][31429-3-0-0.31][31431-0-0-0.50][31432-1-1-0.69]
[31477-0-0-0.99][31524-1-3--0.13][31597-1-1--0.08][31619-1-0-0.97][31701-0-0-0.99][31755-0-0-0.41][31854-3-3-0.99][32074-1-1--0.17][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-0--0.18][32365-0-0-0.79][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-0-0.99][32584-0-0-0.71][32622-0-2-0.34]
[32858-3-0-0.99][32969-3-0-0.99][33016-2-2-0.99][33031-1-3--0.05][33035-2-2-0.80][33133-2-2-0.80][33173-2-1-0.16][33175-3-1-0.99][33306-3-1-0.59][33309-2-3-0.33]
[33474-0-0-0.92][33478-2-3-0.99][33618-1-1-0.99][33712-0-3-0.82][33782-2-2-0.94][33914-3-3-0.99][34076-3-3-0.15][34112-2-1-0.99][34138-2-1-0.99][34239-1-2-0.62]
[34364-2-1-0.99][34617-1-3--0.53][34751-3-3-0.99][34783-2-1-0.96][35015-3-3-0.99][35018-1-1-0.99][35288-2-3--0.01]
---------------------------
I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 0.767 | Acc: 76.375% | Wgt Acc: 75.864%
	I - Batch: 100 | Loss: 0.757 | Acc: 75.750% | Wgt Acc: 75.384%
	I - Batch: 150 | Loss: 0.770 | Acc: 74.458% | Wgt Acc: 74.273%
I - num batch: 160
I - Train -- Loss: 0.767 | Acc: 74.755% | Wgt Acc: 74.558% | LR: 1.000000e-03 | Dur: 109.38s
I - Confusion Matrix: [row->prediction - col->label]
[[558.  18.  15. 107.]
 [ 32. 453. 140.  31.]
 [ 28.  82. 534.  41.]
 [ 79.  25.  45. 359.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.071 | Acc: 57.187% | Wgt Acc: 56.522% | Dur: 12.02s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  2.  8. 29.]
 [ 9. 50. 27. 12.]
 [ 5. 25. 38. 11.]
 [ 9.  1.  2. 34.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 0.739 | Acc: 77.125% | Wgt Acc: 77.085%
	I - Batch: 100 | Loss: 0.724 | Acc: 77.938% | Wgt Acc: 77.756%
	I - Batch: 150 | Loss: 0.725 | Acc: 78.250% | Wgt Acc: 78.092%
I - num batch: 160
I - Train -- Loss: 0.722 | Acc: 78.288% | Wgt Acc: 78.114% | LR: 5.000000e-04 | Dur: 109.59s
I - Confusion Matrix: [row->prediction - col->label]
[[568.  15.  20. 102.]
 [ 33. 472. 119.  25.]
 [ 31.  74. 572.  29.]
 [ 65.  17.  23. 382.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.064 | Acc: 58.104% | Wgt Acc: 56.454% | Dur: 11.22s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  4.  8. 32.]
 [ 3. 39. 16.  8.]
 [ 6. 33. 47. 14.]
 [ 7.  2.  4. 32.]]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 0.705 | Acc: 81.000% | Wgt Acc: 80.383%
	I - Batch: 100 | Loss: 0.715 | Acc: 79.562% | Wgt Acc: 79.243%
	I - Batch: 150 | Loss: 0.717 | Acc: 79.042% | Wgt Acc: 78.684%
I - num batch: 160
I - Train -- Loss: 0.716 | Acc: 78.838% | Wgt Acc: 78.459% | LR: 5.000000e-04 | Dur: 107.68s
I - Confusion Matrix: [row->prediction - col->label]
[[598.  22.  21. 109.]
 [ 25. 466.  99.  31.]
 [ 29.  71. 573.  27.]
 [ 45.  19.  41. 371.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.032 | Acc: 56.575% | Wgt Acc: 55.707% | Dur: 11.35s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  3.  6. 28.]
 [ 3. 43. 21. 10.]
 [ 7. 27. 38. 11.]
 [11.  5. 10. 37.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 0.687 | Acc: 81.125% | Wgt Acc: 81.077%
	I - Batch: 100 | Loss: 0.693 | Acc: 80.375% | Wgt Acc: 80.141%
	I - Batch: 150 | Loss: 0.689 | Acc: 81.250% | Wgt Acc: 81.053%
I - num batch: 160
I - Train -- Loss: 0.687 | Acc: 81.351% | Wgt Acc: 81.139% | LR: 5.000000e-04 | Dur: 109.96s
I - Confusion Matrix: [row->prediction - col->label]
[[593.  18.  20.  76.]
 [ 16. 487.  84.  23.]
 [ 28.  55. 595.  42.]
 [ 60.  18.  35. 397.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.001 | Acc: 61.774% | Wgt Acc: 61.345% | Dur: 11.11s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  5.  9. 29.]
 [ 4. 51. 23. 10.]
 [ 1. 20. 36.  3.]
 [12.  2.  7. 44.]]

I - Local maximum validation set accuracy:  61.77

I - Validation set results: 
[14-1-1-0.95][50-3-1-0.36][124-2-2-0.52][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.96][615-0-3-0.98][695-1-2-0.99][722-3-3-0.99]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.89][1212-3-3-0.08][1368-0-0-0.99][2181-2-3--0.49][2476-2-2--0.14][2721-2-2-0.99][2818-1-0-0.54][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-1-0.99][3482-2-2-0.95][3536-3-3-0.91][3625-1-1-0.99][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.98][4214-1-3-0.99][4346-1-0-0.84]
[4581-2-2-0.97][4708-3-2-0.04][4838-3-0-0.46][4845-1-1-0.06][4868-0-0-0.99][4939-0-1--0.20][4984-2-3--0.26][5078-1-2-0.44][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.99][5843-1-1-0.99][5949-3-0-0.95][5987-2-1-0.98][6014-3-1-0.96][6033-3-0-0.89][6313-0-0--0.02][6421-3-3-0.99][6500-1-1--0.62][6583-3-3-0.99]
[6683-3-3--0.21][6825-2-1-0.81][6998-3-3--0.14][7049-3-3-0.99][7517-1-1-0.99][7521-1-0-0.97][7528-1-3-0.61][7949-1-2-0.76][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-1--0.05][8273-3-3--0.08][8543-3-0-0.99][8666-1-1-0.46][8672-0-0-0.99][8903-1-2-0.44][9001-2-1-0.99][9036-2-2-0.94][9281-3-1--0.21][9300-2-2-0.99]
[9571-0-3-0.44][9617-1-1--0.22][9644-2-1-0.63][9705-2-0--0.10][9801-0-3-0.89][9803-3-3-0.45][9865-3-3-0.93][9896-2-2-0.94][10314-1-1-0.93][10337-3-3-0.84]
[10403-0-0-0.98][10653-2-1-0.99][10704-2-1-0.99][10719-1-1-0.86][10727-1-1-0.99][10836-0-0-0.99][10969-2-3--0.15][11042-0-0-0.99][11088-1-1-0.98][11322-0-0-0.99]
[11398-2-2-0.99][11499-0-0-0.98][11502-3-3-0.90][11512-3-3-0.77][11608-1-1-0.99][11610-0-0-0.98][11692-0-0-0.94][11905-0-3-0.90][11993-1-1-0.99][12002-2-0-0.56]
[12052-0-0-0.70][12201-0-3-0.99][12235-2-2-0.88][12320-1-0-0.81][12377-2-1-0.82][12398-2-0-0.16][12503-1-2-0.99][12617-0-1-0.31][12685-3-3-0.44][12738-2-0--0.23]
[12742-2-2-0.95][12823-0-0-0.99][13110-1-1-0.99][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-2-0.62][13763-2-3--0.19][13905-3-0--0.88][14060-2-1-0.99]
[14065-3-0-0.92][14147-3-3-0.53][14595-2-1-0.88][14687-2-2-0.85][14788-2-2-0.60][14869-1-1-0.65][14872-3-0-0.88][14877-1-1-0.99][14927-0-3--0.37][15066-0-0-0.99]
[15175-1-2-0.44][15178-2-3-0.85][15375-3-0-0.55][15389-3-3-0.99][15568-2-1-0.99][15675-3-3-0.99][15869-1-2--0.10][16207-3-0-0.99][16236-0-0--0.54][16302-3-0-0.90]
[16331-2-2-0.99][16381-0-3-0.47][16488-1-1-0.99][16495-0-0-0.93][16650-0-0-0.99][16719-1-2-0.95][16801-0-0-0.99][16828-0-0-0.99][17137-3-0-0.99][17245-1-2--0.27]
[17278-3-1--0.80][17282-0-0-0.26][17311-2-2-0.94][17336-2-1-0.31][17608-3-3-0.99][17627-0-0--0.14][17877-3-1-0.99][17924-1-2--0.02][17984-3-0-0.99][18211-0-1-0.79]
[18276-3-0-0.99][18287-1-1-0.52][18394-0-0-0.99][18428-0-0-0.76][18442-0-3-0.99][18478-3-3-0.60][18607-0-0-0.99][18616-0-0-0.54][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-2-0.54][18824-2-1-0.99][18890-3-2-0.58][18930-3-2-0.37][18938-3-3-0.09][19817-1-2-0.90][19839-0-0-0.78][19930-3-0-0.31][19944-0-2-0.58][20036-2-2-0.99]
[20101-3-3-0.74][20474-1-1--0.01][20547-3-0--0.23][20929-2-1-0.99][21245-1-1-0.90][21257-3-3--0.40][21293-1-1-0.99][21316-1-1-0.86][21384-1-2-0.99][21448-1-1-0.81]
[21483-0-0-0.99][21487-2-2-0.88][21714-0-0-0.58][21943-3-1--0.05][21947-0-0-0.51][21948-0-0-0.99][21965-2-1-0.99][21998-1-1-0.99][22025-0-3-0.14][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-0-0.99][22757-0-0-0.99][22811-3-0-0.80][22976-3-1-0.97][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-0-0.68][23168-2-0-0.99]
[23219-0-0-0.89][23363-3-3-0.96][23470-0-0-0.77][23486-2-3-0.79][23497-0-0-0.99][23516-0-0-0.99][23690-1-1--0.27][23921-2-2-0.60][23936-1-2-0.99][24040-3-0-0.13]
[24111-1-1-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.95][24364-1-2-0.98][24427-3-0-0.98][24477-2-2-0.99][24495-2-1-0.99][24893-2-1-0.99]
[25012-1-1-0.11][25121-2-2-0.53][25165-3-3-0.99][25183-0-0-0.94][25297-3-3-0.99][25398-0-0-0.99][25574-2-2-0.14][25644-1-1-0.99][25718-1-1-0.38][25774-2-2-0.49]
[26032-3-3--0.15][26051-3-3-0.99][26120-0-0-0.28][26321-1-1-0.93][26732-1-1-0.98][26784-3-3-0.99][26827-3-3-0.03][26833-0-3-0.99][26838-2-2-0.37][26860-1-2-0.31]
[26948-0-0-0.02][27049-3-0-0.99][27098-1-1-0.30][27526-0-0-0.60][27639-3-3--0.03][27698-3-3-0.13][27772-0-0-0.99][27890-1-1-0.76][28040-0-3--0.20][28503-2-2-0.99]
[28577-1-1-0.99][28959-0-0-0.99][29198-3-0-0.30][29777-0-0-0.99][29877-2-2-0.75][30035-1-2-0.76][30098-0-3-0.95][30326-1-1-0.99][30572-2-2-0.38][30716-0-1-0.88]
[30806-2-3--0.36][30906-1-1-0.99][31007-0-0-0.99][31181-3-3-0.63][31238-0-0-0.26][31347-0-0-0.99][31422-2-0-0.37][31429-3-3--0.28][31431-0-0--0.16][31432-1-1-0.96]
[31477-0-0-0.99][31524-1-2--0.26][31597-1-1-0.45][31619-1-2-0.99][31701-0-0-0.99][31755-0-0-0.55][31854-3-3-0.96][32074-1-1--0.28][32078-3-3-0.99][32111-1-1-0.99]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-0--0.84][32365-0-0-0.93][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-3-0.97][32584-0-0--0.76][32622-0-0-0.15]
[32858-3-0-0.99][32969-3-0--0.28][33016-2-2-0.99][33031-1-1--0.22][33035-2-2-0.99][33133-2-2-0.99][33173-2-1-0.25][33175-3-1-0.99][33306-3-1-0.78][33309-2-1--0.69]
[33474-0-0-0.99][33478-2-2-0.43][33618-1-1-0.99][33712-0-0-0.27][33782-2-2-0.99][33914-3-3-0.99][34076-3-3--0.60][34112-2-1-0.99][34138-2-1-0.64][34239-1-1-0.08]
[34364-2-1-0.88][34617-1-1--0.26][34751-3-3-0.99][34783-2-2-0.82][35015-3-3-0.60][35018-1-1-0.99][35288-2-2-0.81]
---------------------------
I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 0.667 | Acc: 83.250% | Wgt Acc: 83.033%
	I - Batch: 100 | Loss: 0.662 | Acc: 83.188% | Wgt Acc: 83.042%
	I - Batch: 150 | Loss: 0.666 | Acc: 82.583% | Wgt Acc: 82.398%
I - num batch: 160
I - Train -- Loss: 0.667 | Acc: 82.489% | Wgt Acc: 82.316% | LR: 5.000000e-04 | Dur: 108.46s
I - Confusion Matrix: [row->prediction - col->label]
[[592.  17.  16.  82.]
 [ 23. 500.  76.  28.]
 [ 19.  50. 608.  27.]
 [ 63.  11.  34. 401.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.080 | Acc: 56.881% | Wgt Acc: 55.707% | Dur: 11.29s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  9. 11. 34.]
 [ 1. 34. 16.  4.]
 [ 0. 26. 34.  6.]
 [11.  9. 14. 42.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 0.657 | Acc: 83.375% | Wgt Acc: 83.263%
	I - Batch: 100 | Loss: 0.671 | Acc: 82.188% | Wgt Acc: 81.983%
	I - Batch: 150 | Loss: 0.661 | Acc: 82.792% | Wgt Acc: 82.603%
I - num batch: 160
I - Train -- Loss: 0.664 | Acc: 82.764% | Wgt Acc: 82.573% | LR: 5.000000e-04 | Dur: 109.16s
I - Confusion Matrix: [row->prediction - col->label]
[[599.  10.  14.  81.]
 [ 19. 498.  82.  23.]
 [ 16.  54. 607.  30.]
 [ 63.  16.  31. 404.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.004 | Acc: 60.245% | Wgt Acc: 60.394% | Dur: 11.38s
I - Confusion Matrix: [row->prediction - col->label]
[[61.  3.  4. 16.]
 [ 5. 52. 29. 13.]
 [ 3. 20. 35.  8.]
 [19.  3.  7. 49.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 0.671 | Acc: 82.500% | Wgt Acc: 82.247%
	I - Batch: 100 | Loss: 0.660 | Acc: 82.812% | Wgt Acc: 82.649%
	I - Batch: 150 | Loss: 0.659 | Acc: 83.083% | Wgt Acc: 82.884%
I - num batch: 160
I - Train -- Loss: 0.660 | Acc: 83.196% | Wgt Acc: 83.015% | LR: 5.000000e-04 | Dur: 110.03s
I - Confusion Matrix: [row->prediction - col->label]
[[604.  14.  20.  77.]
 [ 21. 504.  79.  21.]
 [ 29.  53. 607.  36.]
 [ 43.   7.  28. 404.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.113 | Acc: 53.823% | Wgt Acc: 53.057% | Dur: 11.44s
I - Confusion Matrix: [row->prediction - col->label]
[[50.  2.  3. 18.]
 [12. 45. 22. 16.]
 [13. 29. 49. 20.]
 [13.  2.  1. 32.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 0.652 | Acc: 83.750% | Wgt Acc: 83.544%
	I - Batch: 100 | Loss: 0.649 | Acc: 84.438% | Wgt Acc: 84.275%
	I - Batch: 150 | Loss: 0.650 | Acc: 84.292% | Wgt Acc: 84.110%
I - num batch: 160
I - Train -- Loss: 0.650 | Acc: 84.217% | Wgt Acc: 84.076% | LR: 5.000000e-04 | Dur: 107.92s
I - Confusion Matrix: [row->prediction - col->label]
[[598.  14.  13.  66.]
 [ 17. 499.  74.  25.]
 [ 14.  52. 623.  22.]
 [ 68.  13.  24. 425.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.022 | Acc: 60.856% | Wgt Acc: 59.918% | Dur: 11.13s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  7. 11. 27.]
 [ 3. 44. 15.  8.]
 [ 3. 25. 38.  9.]
 [ 7.  2. 11. 42.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 0.635 | Acc: 84.500% | Wgt Acc: 84.284%
	I - Batch: 100 | Loss: 0.634 | Acc: 84.312% | Wgt Acc: 84.165%
	I - Batch: 150 | Loss: 0.630 | Acc: 84.708% | Wgt Acc: 84.532%
I - num batch: 160
I - Train -- Loss: 0.635 | Acc: 84.609% | Wgt Acc: 84.421% | LR: 5.000000e-04 | Dur: 109.19s
I - Confusion Matrix: [row->prediction - col->label]
[[606.  17.  13.  67.]
 [ 19. 498.  72.  23.]
 [ 15.  51. 626.  23.]
 [ 57.  12.  23. 425.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.028 | Acc: 59.633% | Wgt Acc: 59.375% | Dur: 11.56s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  7.  8. 24.]
 [ 2. 43. 14.  5.]
 [ 2. 21. 39.  6.]
 [22.  7. 14. 51.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 0.629 | Acc: 86.625% | Wgt Acc: 86.282%
	I - Batch: 100 | Loss: 0.627 | Acc: 85.750% | Wgt Acc: 85.486%
	I - Batch: 150 | Loss: 0.620 | Acc: 86.083% | Wgt Acc: 85.870%
I - num batch: 160
I - Train -- Loss: 0.623 | Acc: 85.866% | Wgt Acc: 85.642% | LR: 5.000000e-04 | Dur: 109.32s
I - Confusion Matrix: [row->prediction - col->label]
[[619.  13.  16.  71.]
 [ 19. 512.  61.  19.]
 [ 23.  45. 635.  27.]
 [ 36.   8.  22. 421.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.040 | Acc: 57.798% | Wgt Acc: 56.590% | Dur: 11.30s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  4.  5. 21.]
 [ 4. 42. 15.  9.]
 [ 6. 29. 52. 21.]
 [18.  3.  3. 35.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 0.601 | Acc: 88.000% | Wgt Acc: 87.817%
	I - Batch: 100 | Loss: 0.610 | Acc: 87.188% | Wgt Acc: 86.942%
	I - Batch: 150 | Loss: 0.614 | Acc: 86.792% | Wgt Acc: 86.521%
I - num batch: 160
I - Train -- Loss: 0.616 | Acc: 86.651% | Wgt Acc: 86.394% | LR: 5.000000e-04 | Dur: 109.75s
I - Confusion Matrix: [row->prediction - col->label]
[[611.  10.  10.  64.]
 [ 15. 511.  51.  15.]
 [ 20.  48. 658.  32.]
 [ 51.   9.  15. 427.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.004 | Acc: 61.774% | Wgt Acc: 60.530% | Dur: 11.57s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  6.  3. 22.]
 [ 2. 45. 15. 13.]
 [ 3. 26. 52. 13.]
 [16.  1.  5. 38.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 0.587 | Acc: 86.125% | Wgt Acc: 85.948%
	I - Batch: 100 | Loss: 0.577 | Acc: 87.938% | Wgt Acc: 87.763%
	I - Batch: 150 | Loss: 0.580 | Acc: 88.167% | Wgt Acc: 88.004%
I - num batch: 160
I - Train -- Loss: 0.579 | Acc: 88.143% | Wgt Acc: 87.969% | LR: 2.500000e-04 | Dur: 109.28s
I - Confusion Matrix: [row->prediction - col->label]
[[621.  11.  10.  54.]
 [ 18. 524.  45.  20.]
 [ 19.  30. 660.  24.]
 [ 39.  13.  19. 440.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.061 | Acc: 56.575% | Wgt Acc: 55.571% | Dur: 12.18s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 17.  9. 41.]
 [ 2. 38. 15.  4.]
 [ 0. 16. 32.  1.]
 [11.  7. 19. 40.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 0.547 | Acc: 91.250% | Wgt Acc: 91.084%
	I - Batch: 100 | Loss: 0.549 | Acc: 90.125% | Wgt Acc: 89.958%
	I - Batch: 150 | Loss: 0.558 | Acc: 89.875% | Wgt Acc: 89.649%
I - num batch: 160
I - Train -- Loss: 0.559 | Acc: 89.870% | Wgt Acc: 89.623% | LR: 2.500000e-04 | Dur: 97.00s
I - Confusion Matrix: [row->prediction - col->label]
[[643.  11.   6.  56.]
 [ 10. 531.  44.  18.]
 [ 13.  25. 671.  20.]
 [ 31.  11.  13. 444.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.010 | Acc: 61.162% | Wgt Acc: 60.258% | Dur: 9.70s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  6.  5. 15.]
 [ 3. 36. 12.  7.]
 [ 5. 35. 51. 13.]
 [18.  1.  7. 51.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 0.529 | Acc: 92.000% | Wgt Acc: 91.763%
	I - Batch: 100 | Loss: 0.540 | Acc: 91.312% | Wgt Acc: 91.081%
	I - Batch: 150 | Loss: 0.548 | Acc: 91.125% | Wgt Acc: 90.895%
I - num batch: 160
I - Train -- Loss: 0.548 | Acc: 91.166% | Wgt Acc: 90.915% | LR: 2.500000e-04 | Dur: 93.19s
I - Confusion Matrix: [row->prediction - col->label]
[[648.   7.   5.  53.]
 [  9. 534.  27.  11.]
 [  8.  27. 685.  19.]
 [ 32.  10.  17. 455.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.996 | Acc: 62.691% | Wgt Acc: 62.636% | Dur: 9.45s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  8. 23.]
 [ 3. 53. 21.  6.]
 [ 3. 15. 37.  8.]
 [16.  5.  9. 49.]]

I - Local maximum validation set accuracy:  62.69

I - Validation set results: 
[14-1-1-0.89][50-3-1-0.55][124-2-2-0.99][127-0-0-0.99][443-2-2-0.99][567-0-0-0.92][573-1-1-0.63][615-0-3-0.99][695-1-2-0.99][722-3-3-0.98]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.18][1212-3-3-0.58][1368-0-0-0.99][2181-2-2--0.57][2476-2-2-0.30][2721-2-2-0.98][2818-1-0-0.22][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-1-0.99][3482-2-2-0.91][3536-3-3-0.97][3625-1-1-0.99][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.91][4214-1-1-0.45][4346-1-0--0.65]
[4581-2-2-0.99][4708-3-2-0.99][4838-3-0-0.63][4845-1-1-0.99][4868-0-0-0.99][4939-0-2--0.01][4984-2-0--0.20][5078-1-2-0.83][5396-0-0-0.99][5479-1-1-0.99]
[5717-0-0-0.90][5843-1-1-0.71][5949-3-0-0.99][5987-2-2-0.84][6014-3-1-0.99][6033-3-0-0.81][6313-0-0-0.89][6421-3-3-0.99][6500-1-1--0.93][6583-3-3-0.99]
[6683-3-3--0.20][6825-2-3-0.99][6998-3-3--0.16][7049-3-3-0.39][7517-1-1-0.99][7521-1-0-0.97][7528-1-3-0.74][7949-1-2--0.48][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-2-0.18][8273-3-3-0.90][8543-3-0-0.99][8666-1-1-0.10][8672-0-3-0.99][8903-1-2-0.36][9001-2-1-0.99][9036-2-2-0.99][9281-3-0--0.00][9300-2-2-0.90]
[9571-0-3-0.49][9617-1-1-0.03][9644-2-2-0.78][9705-2-2-0.38][9801-0-3-0.99][9803-3-0-0.83][9865-3-3-0.92][9896-2-2-0.82][10314-1-1-0.64][10337-3-3-0.80]
[10403-0-0-0.87][10653-2-1-0.36][10704-2-1-0.78][10719-1-1-0.99][10727-1-1-0.98][10836-0-0-0.99][10969-2-1--0.84][11042-0-3-0.27][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.77][11499-0-0-0.91][11502-3-0-0.92][11512-3-1--0.42][11608-1-1-0.99][11610-0-0-0.99][11692-0-0-0.40][11905-0-3-0.98][11993-1-1-0.99][12002-2-2--0.42]
[12052-0-0-0.90][12201-0-3-0.92][12235-2-2-0.57][12320-1-0-0.95][12377-2-2-0.64][12398-2-0--0.57][12503-1-1-0.99][12617-0-1-0.35][12685-3-3--0.12][12738-2-0--0.25]
[12742-2-2-0.99][12823-0-3-0.99][13110-1-1-0.75][13240-3-3-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-2-0.65][13763-2-0--0.72][13905-3-3--0.33][14060-2-1-0.99]
[14065-3-0-0.99][14147-3-3-0.85][14595-2-1-0.93][14687-2-2-0.99][14788-2-3-0.80][14869-1-1-0.51][14872-3-0-0.91][14877-1-1-0.99][14927-0-3-0.88][15066-0-0-0.99]
[15175-1-1--0.17][15178-2-3-0.87][15375-3-0-0.28][15389-3-3-0.99][15568-2-2-0.64][15675-3-3-0.99][15869-1-1--0.17][16207-3-0-0.99][16236-0-2-0.20][16302-3-0-0.99]
[16331-2-1-0.99][16381-0-0-0.58][16488-1-1-0.99][16495-0-0-0.74][16650-0-0-0.99][16719-1-2-0.72][16801-0-0-0.99][16828-0-0-0.99][17137-3-0-0.99][17245-1-3--0.23]
[17278-3-2--0.38][17282-0-0-0.94][17311-2-2-0.98][17336-2-1-0.99][17608-3-3-0.99][17627-0-0--0.22][17877-3-0-0.93][17924-1-3--0.11][17984-3-0-0.99][18211-0-3-0.25]
[18276-3-0-0.99][18287-1-1-0.96][18394-0-0-0.99][18428-0-0-0.42][18442-0-3-0.99][18478-3-3-0.99][18607-0-0-0.99][18616-0-0-0.87][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-3-0.33][18824-2-1-0.97][18890-3-2-0.99][18930-3-1-0.06][18938-3-3-0.77][19817-1-2-0.93][19839-0-0-0.67][19930-3-3-0.39][19944-0-2-0.12][20036-2-2-0.99]
[20101-3-3-0.62][20474-1-1--0.33][20547-3-3-0.89][20929-2-1-0.32][21245-1-1-0.71][21257-3-3-0.29][21293-1-1-0.99][21316-1-1-0.42][21384-1-2-0.92][21448-1-1-0.56]
[21483-0-0-0.99][21487-2-2-0.96][21714-0-3-0.99][21943-3-3-0.14][21947-0-0-0.72][21948-0-0-0.99][21965-2-1-0.99][21998-1-1-0.99][22025-0-3-0.61][22228-3-0-0.99]
[22446-1-1-0.99][22494-3-3-0.99][22757-0-0-0.99][22811-3-3-0.99][22976-3-2-0.25][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0-0.75]
[23219-0-3-0.83][23363-3-3-0.99][23470-0-0-0.70][23486-2-3-0.43][23497-0-0-0.99][23516-0-0-0.99][23690-1-1-0.06][23921-2-2-0.76][23936-1-2-0.99][24040-3-2-0.24]
[24111-1-1-0.99][24182-0-0-0.99][24238-3-3-0.99][24290-2-0-0.99][24345-0-0-0.99][24364-1-2-0.99][24427-3-0-0.99][24477-2-2-0.13][24495-2-1-0.99][24893-2-1-0.95]
[25012-1-2-0.92][25121-2-2-0.74][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-1--0.24][25644-1-1-0.37][25718-1-1-0.27][25774-2-2--0.33]
[26032-3-3--0.68][26051-3-3-0.99][26120-0-0-0.73][26321-1-1--0.16][26732-1-1-0.99][26784-3-3-0.99][26827-3-3-0.84][26833-0-3-0.99][26838-2-1-0.35][26860-1-2--0.16]
[26948-0-0-0.92][27049-3-0-0.99][27098-1-1-0.96][27526-0-0-0.99][27639-3-3-0.91][27698-3-3-0.99][27772-0-0-0.99][27890-1-1-0.90][28040-0-0-0.75][28503-2-2-0.95]
[28577-1-1-0.90][28959-0-0-0.99][29198-3-2-0.45][29777-0-0-0.99][29877-2-2-0.96][30035-1-1-0.99][30098-0-3-0.39][30326-1-1-0.99][30572-2-1-0.25][30716-0-1-0.99]
[30806-2-3-0.45][30906-1-1-0.99][31007-0-0-0.72][31181-3-3-0.24][31238-0-0-0.38][31347-0-0-0.83][31422-2-0-0.19][31429-3-3-0.11][31431-0-0--0.05][31432-1-1-0.95]
[31477-0-0-0.99][31524-1-3-0.50][31597-1-1-0.88][31619-1-2-0.83][31701-0-0-0.99][31755-0-0-0.97][31854-3-3-0.91][32074-1-3-0.82][32078-3-3-0.87][32111-1-1-0.99]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-3--0.39][32365-0-0-0.99][32411-2-0-0.99][32429-3-0-0.99][32473-3-0-0.99][32574-3-3-0.62][32584-0-1--0.66][32622-0-0-0.54]
[32858-3-0-0.99][32969-3-3-0.99][33016-2-2-0.99][33031-1-1--0.90][33035-2-2-0.99][33133-2-2-0.62][33173-2-2-0.07][33175-3-1-0.99][33306-3-1-0.20][33309-2-3-0.41]
[33474-0-0-0.99][33478-2-3-0.97][33618-1-1-0.99][33712-0-0--0.04][33782-2-2-0.99][33914-3-3-0.99][34076-3-2--0.37][34112-2-1-0.99][34138-2-1-0.96][34239-1-1-0.52]
[34364-2-1-0.99][34617-1-2-0.31][34751-3-3-0.99][34783-2-2-0.81][35015-3-3-0.36][35018-1-1-0.75][35288-2-2-0.96]
---------------------------
I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 0.551 | Acc: 91.375% | Wgt Acc: 91.162%
	I - Batch: 100 | Loss: 0.543 | Acc: 91.062% | Wgt Acc: 90.901%
	I - Batch: 150 | Loss: 0.546 | Acc: 90.708% | Wgt Acc: 90.533%
I - num batch: 160
I - Train -- Loss: 0.546 | Acc: 90.734% | Wgt Acc: 90.570% | LR: 2.500000e-04 | Dur: 95.37s
I - Confusion Matrix: [row->prediction - col->label]
[[642.   5.   7.  46.]
 [  8. 537.  40.  14.]
 [ 14.  25. 675.  21.]
 [ 33.  11.  12. 457.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.043 | Acc: 59.633% | Wgt Acc: 58.560% | Dur: 9.63s
I - Confusion Matrix: [row->prediction - col->label]
[[62.  3.  4. 22.]
 [ 4. 40. 15.  8.]
 [ 6. 32. 51. 14.]
 [16.  3.  5. 42.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 0.545 | Acc: 90.500% | Wgt Acc: 90.222%
	I - Batch: 100 | Loss: 0.541 | Acc: 91.125% | Wgt Acc: 90.912%
	I - Batch: 150 | Loss: 0.542 | Acc: 91.375% | Wgt Acc: 91.179%
I - num batch: 160
I - Train -- Loss: 0.543 | Acc: 91.245% | Wgt Acc: 91.030% | LR: 2.500000e-04 | Dur: 92.59s
I - Confusion Matrix: [row->prediction - col->label]
[[644.  10.  10.  46.]
 [ 11. 531.  28.  11.]
 [ 10.  27. 686.  18.]
 [ 32.  10.  10. 463.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.018 | Acc: 59.327% | Wgt Acc: 57.948% | Dur: 9.52s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  5. 26.]
 [ 2. 35. 16.  8.]
 [ 2. 35. 48. 10.]
 [15.  3.  6. 42.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 0.514 | Acc: 93.000% | Wgt Acc: 92.829%
	I - Batch: 100 | Loss: 0.519 | Acc: 92.562% | Wgt Acc: 92.320%
	I - Batch: 150 | Loss: 0.516 | Acc: 92.875% | Wgt Acc: 92.655%
I - num batch: 160
I - Train -- Loss: 0.517 | Acc: 92.815% | Wgt Acc: 92.604% | LR: 1.250000e-04 | Dur: 95.20s
I - Confusion Matrix: [row->prediction - col->label]
[[657.   8.   4.  35.]
 [  8. 544.  24.  15.]
 [ 10.  19. 695.  20.]
 [ 22.   7.  11. 468.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.047 | Acc: 58.716% | Wgt Acc: 57.065% | Dur: 10.50s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  4.  3. 23.]
 [ 4. 40. 15.  9.]
 [ 9. 31. 55. 22.]
 [10.  3.  2. 32.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 0.497 | Acc: 94.250% | Wgt Acc: 94.035%
	I - Batch: 100 | Loss: 0.507 | Acc: 92.625% | Wgt Acc: 92.455%
	I - Batch: 150 | Loss: 0.498 | Acc: 93.375% | Wgt Acc: 93.180%
I - num batch: 160
I - Train -- Loss: 0.505 | Acc: 92.933% | Wgt Acc: 92.737% | LR: 1.250000e-04 | Dur: 92.51s
I - Confusion Matrix: [row->prediction - col->label]
[[651.   5.   5.  35.]
 [  9. 544.  17.  11.]
 [ 10.  21. 701.  21.]
 [ 27.   8.  11. 471.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.121 | Acc: 54.434% | Wgt Acc: 53.125% | Dur: 9.44s
I - Confusion Matrix: [row->prediction - col->label]
[[84. 20. 19. 50.]
 [ 1. 38. 16.  3.]
 [ 0. 14. 24.  1.]
 [ 3.  6. 16. 32.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 0.488 | Acc: 94.125% | Wgt Acc: 94.192%
	I - Batch: 100 | Loss: 0.498 | Acc: 93.562% | Wgt Acc: 93.547%
	I - Batch: 150 | Loss: 0.499 | Acc: 93.583% | Wgt Acc: 93.521%
I - num batch: 160
I - Train -- Loss: 0.502 | Acc: 93.443% | Wgt Acc: 93.356% | LR: 1.250000e-04 | Dur: 95.25s
I - Confusion Matrix: [row->prediction - col->label]
[[656.   5.   7.  30.]
 [  6. 553.  26.  13.]
 [  8.  12. 691.  15.]
 [ 27.   8.  10. 480.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.000 | Acc: 63.303% | Wgt Acc: 62.568% | Dur: 10.51s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  2.  3. 22.]
 [ 3. 48. 19. 11.]
 [ 4. 26. 46.  8.]
 [13.  2.  7. 45.]]

I - Local maximum validation set accuracy:  63.30

I - Validation set results: 
[14-1-2-0.56][50-3-1-0.00][124-2-2-0.80][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.35][615-0-3-0.25][695-1-2-0.99][722-3-3-0.36]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.26][1212-3-3-0.15][1368-0-0-0.98][2181-2-2--0.40][2476-2-2-0.33][2721-2-2-0.98][2818-1-1--0.18][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-1-0.24][3482-2-2-0.99][3536-3-3-0.95][3625-1-1-0.99][3909-0-0-0.89][4035-0-0-0.99][4140-0-0-0.05][4214-1-3--0.21][4346-1-1--0.25]
[4581-2-2-0.99][4708-3-2-0.99][4838-3-0-0.58][4845-1-1-0.92][4868-0-0-0.95][4939-0-2--0.33][4984-2-2-0.52][5078-1-2-0.40][5396-0-0-0.99][5479-1-1-0.23]
[5717-0-0-0.50][5843-1-1-0.93][5949-3-0-0.97][5987-2-2-0.77][6014-3-1-0.75][6033-3-0-0.70][6313-0-0-0.75][6421-3-3-0.95][6500-1-2-0.02][6583-3-3-0.99]
[6683-3-3-0.09][6825-2-1-0.41][6998-3-3-0.57][7049-3-2-0.53][7517-1-1-0.99][7521-1-1-0.40][7528-1-3-0.04][7949-1-2-0.17][8135-1-0-0.99][8185-3-0-0.99]
[8269-3-1-0.22][8273-3-3-0.62][8543-3-0-0.99][8666-1-1-0.21][8672-0-0-0.99][8903-1-2-0.99][9001-2-0-0.64][9036-2-1-0.78][9281-3-1--0.67][9300-2-2-0.99]
[9571-0-0--0.07][9617-1-1-0.05][9644-2-1-0.80][9705-2-2-0.65][9801-0-3-0.85][9803-3-3-0.97][9865-3-3-0.52][9896-2-2-0.97][10314-1-1-0.62][10337-3-3-0.94]
[10403-0-2-0.22][10653-2-1-0.77][10704-2-1-0.24][10719-1-1-0.99][10727-1-1-0.99][10836-0-0-0.99][10969-2-3--0.15][11042-0-3--0.01][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.89][11499-0-0-0.79][11502-3-3-0.03][11512-3-1-0.47][11608-1-1-0.99][11610-0-0--0.22][11692-0-0-0.82][11905-0-0-0.86][11993-1-1-0.99][12002-2-2--0.13]
[12052-0-0-0.94][12201-0-0-0.13][12235-2-2-0.93][12320-1-0-0.68][12377-2-2-0.68][12398-2-2--0.28][12503-1-2--0.08][12617-0-1-0.92][12685-3-3--0.33][12738-2-2--0.20]
[12742-2-2-0.99][12823-0-3-0.97][13110-1-2-0.97][13240-3-3-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-2-0.71][13763-2-2--0.37][13905-3-0--0.46][14060-2-1-0.99]
[14065-3-0-0.99][14147-3-3-0.80][14595-2-1-0.99][14687-2-2-0.87][14788-2-3-0.56][14869-1-2-0.52][14872-3-0-0.42][14877-1-1-0.99][14927-0-3--0.17][15066-0-0-0.76]
[15175-1-1-0.40][15178-2-3-0.42][15375-3-1--0.36][15389-3-3-0.98][15568-2-1-0.99][15675-3-3-0.99][15869-1-2-0.03][16207-3-0-0.91][16236-0-2-0.67][16302-3-0-0.66]
[16331-2-2-0.95][16381-0-3-0.67][16488-1-1-0.99][16495-0-0-0.30][16650-0-0-0.99][16719-1-2-0.77][16801-0-0-0.99][16828-0-0-0.92][17137-3-3--0.02][17245-1-2--0.24]
[17278-3-1--0.37][17282-0-0-0.96][17311-2-2-0.99][17336-2-1-0.95][17608-3-3-0.99][17627-0-0-0.00][17877-3-0-0.51][17924-1-2-0.69][17984-3-0-0.99][18211-0-1-0.79]
[18276-3-0-0.47][18287-1-1-0.95][18394-0-0-0.98][18428-0-0-0.99][18442-0-3-0.99][18478-3-3-0.87][18607-0-0-0.99][18616-0-0-0.89][18663-0-0-0.97][18718-0-0-0.99]
[18766-2-1-0.14][18824-2-1-0.49][18890-3-2-0.97][18930-3-0-0.36][18938-3-2-0.19][19817-1-2-0.86][19839-0-0-0.44][19930-3-3-0.41][19944-0-2-0.40][20036-2-2-0.99]
[20101-3-3-0.80][20474-1-2-0.57][20547-3-3-0.91][20929-2-1-0.04][21245-1-1-0.11][21257-3-1-0.61][21293-1-1-0.99][21316-1-1-0.98][21384-1-2-0.99][21448-1-1-0.85]
[21483-0-0-0.99][21487-2-2-0.96][21714-0-3--0.32][21943-3-3-0.53][21947-0-0-0.99][21948-0-0-0.99][21965-2-1-0.99][21998-1-1-0.83][22025-0-3-0.30][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-0-0.34][22757-0-0-0.65][22811-3-3-0.47][22976-3-1-0.44][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.99][23168-2-0--0.28]
[23219-0-0-0.35][23363-3-3-0.44][23470-0-0-0.58][23486-2-3-0.73][23497-0-0-0.94][23516-0-0-0.99][23690-1-1--0.01][23921-2-2-0.54][23936-1-2-0.99][24040-3-0-0.16]
[24111-1-1-0.99][24182-0-0-0.89][24238-3-3-0.86][24290-2-0-0.99][24345-0-0-0.99][24364-1-2-0.99][24427-3-0-0.80][24477-2-2-0.96][24495-2-1-0.77][24893-2-2-0.93]
[25012-1-2-0.91][25121-2-2-0.27][25165-3-3-0.99][25183-0-0-0.79][25297-3-3-0.99][25398-0-0-0.90][25574-2-2-0.54][25644-1-1-0.99][25718-1-2--0.31][25774-2-2-0.60]
[26032-3-0--0.60][26051-3-3-0.99][26120-0-0-0.91][26321-1-1-0.03][26732-1-1-0.92][26784-3-3-0.97][26827-3-3-0.47][26833-0-3-0.99][26838-2-2-0.40][26860-1-2-0.04]
[26948-0-0-0.21][27049-3-0-0.99][27098-1-1-0.92][27526-0-0-0.99][27639-3-3--0.07][27698-3-3-0.79][27772-0-0-0.20][27890-1-1-0.53][28040-0-0--0.03][28503-2-2-0.99]
[28577-1-1-0.92][28959-0-0-0.93][29198-3-2-0.12][29777-0-0-0.99][29877-2-2-0.58][30035-1-1-0.53][30098-0-3-0.28][30326-1-1-0.99][30572-2-2-0.76][30716-0-1-0.99]
[30806-2-3-0.47][30906-1-1-0.99][31007-0-0-0.81][31181-3-2-0.19][31238-0-3--0.21][31347-0-0-0.95][31422-2-2--0.33][31429-3-3-0.04][31431-0-0-0.60][31432-1-1-0.64]
[31477-0-0-0.45][31524-1-1-0.14][31597-1-1-0.35][31619-1-2-0.99][31701-0-0-0.99][31755-0-0-0.72][31854-3-3-0.63][32074-1-2-0.50][32078-3-3-0.94][32111-1-1-0.99]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-2-0.58][32365-0-0-0.59][32411-2-3-0.99][32429-3-0-0.93][32473-3-0-0.71][32574-3-3-0.93][32584-0-3--0.53][32622-0-0-0.56]
[32858-3-0-0.46][32969-3-3-0.16][33016-2-2-0.92][33031-1-1--1.00][33035-2-2-0.99][33133-2-2-0.88][33173-2-1-0.51][33175-3-1-0.92][33306-3-1-0.74][33309-2-3-0.31]
[33474-0-0-0.99][33478-2-2-0.20][33618-1-1-0.99][33712-0-0--0.28][33782-2-2-0.96][33914-3-3-0.66][34076-3-2-0.37][34112-2-1-0.98][34138-2-1-0.71][34239-1-2--0.30]
[34364-2-2-0.89][34617-1-1--0.04][34751-3-3-0.79][34783-2-2-0.78][35015-3-2-0.53][35018-1-1-0.84][35288-2-2-0.82]
---------------------------
I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 0.510 | Acc: 92.750% | Wgt Acc: 92.666%
	I - Batch: 100 | Loss: 0.500 | Acc: 93.812% | Wgt Acc: 93.726%
	I - Batch: 150 | Loss: 0.505 | Acc: 93.583% | Wgt Acc: 93.462%
I - num batch: 160
I - Train -- Loss: 0.502 | Acc: 93.875% | Wgt Acc: 93.754% | LR: 1.250000e-04 | Dur: 91.21s
I - Confusion Matrix: [row->prediction - col->label]
[[658.   4.   3.  34.]
 [  5. 553.  26.  11.]
 [ 11.  15. 699.  12.]
 [ 23.   6.   6. 481.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.040 | Acc: 61.162% | Wgt Acc: 59.647% | Dur: 9.72s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  6.  5. 26.]
 [ 5. 42. 19. 10.]
 [ 2. 27. 47. 14.]
 [ 6.  3.  4. 36.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 0.493 | Acc: 94.375% | Wgt Acc: 94.298%
	I - Batch: 100 | Loss: 0.489 | Acc: 94.438% | Wgt Acc: 94.358%
	I - Batch: 150 | Loss: 0.492 | Acc: 94.250% | Wgt Acc: 94.160%
I - num batch: 160
I - Train -- Loss: 0.492 | Acc: 94.150% | Wgt Acc: 94.055% | LR: 1.250000e-04 | Dur: 91.90s
I - Confusion Matrix: [row->prediction - col->label]
[[653.   7.   1.  29.]
 [  6. 552.  19.   9.]
 [ 11.  12. 705.  12.]
 [ 27.   7.   9. 488.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.021 | Acc: 61.774% | Wgt Acc: 61.005% | Dur: 10.84s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  9. 30.]
 [ 4. 43. 18.  4.]
 [ 3. 27. 40.  5.]
 [ 9.  2.  8. 47.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 0.494 | Acc: 94.500% | Wgt Acc: 94.357%
	I - Batch: 100 | Loss: 0.490 | Acc: 94.812% | Wgt Acc: 94.662%
	I - Batch: 150 | Loss: 0.491 | Acc: 94.417% | Wgt Acc: 94.302%
I - num batch: 160
I - Train -- Loss: 0.493 | Acc: 94.425% | Wgt Acc: 94.321% | LR: 1.250000e-04 | Dur: 91.45s
I - Confusion Matrix: [row->prediction - col->label]
[[659.   8.   3.  28.]
 [ 10. 555.  17.  11.]
 [  8.  11. 704.  12.]
 [ 20.   4.  10. 487.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.018 | Acc: 61.774% | Wgt Acc: 60.870% | Dur: 9.41s
I - Confusion Matrix: [row->prediction - col->label]
[[74.  6.  9. 25.]
 [ 4. 46. 23. 15.]
 [ 2. 24. 40.  4.]
 [ 8.  2.  3. 42.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 0.477 | Acc: 95.250% | Wgt Acc: 95.109%
	I - Batch: 100 | Loss: 0.481 | Acc: 95.000% | Wgt Acc: 94.898%
	I - Batch: 150 | Loss: 0.482 | Acc: 95.000% | Wgt Acc: 94.855%
I - num batch: 160
I - Train -- Loss: 0.483 | Acc: 95.132% | Wgt Acc: 94.993% | LR: 1.250000e-04 | Dur: 93.37s
I - Confusion Matrix: [row->prediction - col->label]
[[664.   8.   3.  25.]
 [  7. 552.  11.  11.]
 [  9.  13. 713.   8.]
 [ 17.   5.   7. 494.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.057 | Acc: 60.245% | Wgt Acc: 58.492% | Dur: 10.98s
I - Confusion Matrix: [row->prediction - col->label]
[[75.  6.  5. 33.]
 [ 3. 41. 19. 11.]
 [ 4. 29. 49. 10.]
 [ 6.  2.  2. 32.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 0.474 | Acc: 95.375% | Wgt Acc: 95.251%
	I - Batch: 100 | Loss: 0.472 | Acc: 95.750% | Wgt Acc: 95.620%
	I - Batch: 150 | Loss: 0.479 | Acc: 95.375% | Wgt Acc: 95.267%
I - num batch: 160
I - Train -- Loss: 0.477 | Acc: 95.446% | Wgt Acc: 95.338% | LR: 1.250000e-04 | Dur: 95.32s
I - Confusion Matrix: [row->prediction - col->label]
[[668.   1.   5.  29.]
 [ 10. 559.  12.   5.]
 [  7.  14. 710.  10.]
 [ 12.   4.   7. 494.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.026 | Acc: 59.633% | Wgt Acc: 59.035% | Dur: 9.60s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  9.  8. 23.]
 [ 2. 35. 15.  5.]
 [ 1. 23. 34.  4.]
 [13. 11. 18. 54.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 0.473 | Acc: 95.625% | Wgt Acc: 95.548%
	I - Batch: 100 | Loss: 0.475 | Acc: 95.062% | Wgt Acc: 94.944%
	I - Batch: 150 | Loss: 0.474 | Acc: 95.458% | Wgt Acc: 95.351%
I - num batch: 160
I - Train -- Loss: 0.473 | Acc: 95.406% | Wgt Acc: 95.294% | LR: 1.250000e-04 | Dur: 91.63s
I - Confusion Matrix: [row->prediction - col->label]
[[662.   5.   3.  21.]
 [  7. 557.   9.  10.]
 [  8.   9. 716.  12.]
 [ 20.   7.   6. 495.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.024 | Acc: 60.856% | Wgt Acc: 60.326% | Dur: 10.16s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  6. 21.]
 [ 2. 37. 11.  2.]
 [ 1. 27. 43.  8.]
 [21.  7. 15. 55.]]

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 0.463 | Acc: 95.125% | Wgt Acc: 95.007%
	I - Batch: 100 | Loss: 0.471 | Acc: 94.938% | Wgt Acc: 94.828%
	I - Batch: 150 | Loss: 0.470 | Acc: 95.208% | Wgt Acc: 95.089%
I - num batch: 160
I - Train -- Loss: 0.468 | Acc: 95.367% | Wgt Acc: 95.258% | LR: 1.250000e-04 | Dur: 105.76s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   5.   5.  29.]
 [  7. 557.  14.  10.]
 [  3.   9. 707.   4.]
 [ 17.   7.   8. 495.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.048 | Acc: 60.245% | Wgt Acc: 58.899% | Dur: 10.83s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  6.  9. 36.]
 [ 2. 38. 19.  3.]
 [ 2. 32. 42.  6.]
 [ 8.  2.  5. 41.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 0.468 | Acc: 95.750% | Wgt Acc: 95.636%
	I - Batch: 100 | Loss: 0.468 | Acc: 95.625% | Wgt Acc: 95.498%
	I - Batch: 150 | Loss: 0.464 | Acc: 95.917% | Wgt Acc: 95.803%
I - num batch: 160
I - Train -- Loss: 0.465 | Acc: 95.799% | Wgt Acc: 95.683% | LR: 1.250000e-04 | Dur: 105.45s
I - Confusion Matrix: [row->prediction - col->label]
[[669.   7.   5.  20.]
 [  5. 560.  11.  10.]
 [  7.  10. 715.  12.]
 [ 16.   1.   3. 496.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.045 | Acc: 59.939% | Wgt Acc: 58.899% | Dur: 10.49s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  7.  8. 25.]
 [ 2. 36. 12.  6.]
 [ 3. 32. 44.  8.]
 [14.  3. 11. 47.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 0.451 | Acc: 96.750% | Wgt Acc: 96.685%
	I - Batch: 100 | Loss: 0.458 | Acc: 96.062% | Wgt Acc: 95.933%
	I - Batch: 150 | Loss: 0.459 | Acc: 96.042% | Wgt Acc: 95.908%
I - num batch: 160
I - Train -- Loss: 0.459 | Acc: 95.917% | Wgt Acc: 95.789% | LR: 1.250000e-04 | Dur: 106.95s
I - Confusion Matrix: [row->prediction - col->label]
[[669.   2.   2.  24.]
 [  8. 561.  12.   9.]
 [  5.  11. 718.  10.]
 [ 15.   4.   2. 495.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.056 | Acc: 60.245% | Wgt Acc: 59.239% | Dur: 10.88s
I - Confusion Matrix: [row->prediction - col->label]
[[77.  9.  9. 33.]
 [ 2. 45. 20.  7.]
 [ 3. 20. 36.  7.]
 [ 6.  4. 10. 39.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 0.453 | Acc: 96.125% | Wgt Acc: 96.036%
	I - Batch: 100 | Loss: 0.451 | Acc: 96.312% | Wgt Acc: 96.222%
	I - Batch: 150 | Loss: 0.458 | Acc: 96.042% | Wgt Acc: 95.905%
I - num batch: 160
I - Train -- Loss: 0.459 | Acc: 96.035% | Wgt Acc: 95.904% | LR: 1.250000e-04 | Dur: 103.73s
I - Confusion Matrix: [row->prediction - col->label]
[[670.   3.   2.  21.]
 [  5. 560.   9.  11.]
 [  7.  12. 719.   9.]
 [ 15.   3.   4. 497.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.032 | Acc: 59.633% | Wgt Acc: 58.764% | Dur: 11.00s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  5. 21.]
 [ 4. 43. 22. 11.]
 [ 2. 26. 41. 12.]
 [13.  3.  7. 42.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 0.448 | Acc: 96.500% | Wgt Acc: 96.394%
	I - Batch: 100 | Loss: 0.453 | Acc: 96.562% | Wgt Acc: 96.413%
	I - Batch: 150 | Loss: 0.457 | Acc: 96.417% | Wgt Acc: 96.264%
I - num batch: 160
I - Train -- Loss: 0.456 | Acc: 96.506% | Wgt Acc: 96.364% | LR: 1.250000e-04 | Dur: 107.02s
I - Confusion Matrix: [row->prediction - col->label]
[[671.   4.   0.  22.]
 [  6. 561.   8.   6.]
 [  8.   8. 726.  10.]
 [ 12.   5.   0. 500.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.006 | Acc: 59.939% | Wgt Acc: 58.628% | Dur: 10.68s
I - Confusion Matrix: [row->prediction - col->label]
[[63.  6.  3. 17.]
 [ 3. 31. 12.  5.]
 [ 6. 37. 54. 16.]
 [16.  4.  6. 48.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 0.452 | Acc: 96.375% | Wgt Acc: 96.281%
	I - Batch: 100 | Loss: 0.455 | Acc: 96.438% | Wgt Acc: 96.342%
	I - Batch: 150 | Loss: 0.448 | Acc: 97.167% | Wgt Acc: 97.072%
I - num batch: 160
I - Train -- Loss: 0.449 | Acc: 97.095% | Wgt Acc: 96.992% | LR: 1.250000e-04 | Dur: 106.35s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   2.   1.  16.]
 [  4. 566.   6.   9.]
 [  4.   5. 724.   7.]
 [ 12.   5.   3. 506.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.039 | Acc: 57.187% | Wgt Acc: 55.978% | Dur: 10.78s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 14. 13. 34.]
 [ 3. 32. 15.  4.]
 [ 1. 24. 36.  4.]
 [ 9.  8. 11. 44.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 0.446 | Acc: 97.250% | Wgt Acc: 97.220%
	I - Batch: 100 | Loss: 0.440 | Acc: 97.562% | Wgt Acc: 97.498%
	I - Batch: 150 | Loss: 0.442 | Acc: 97.250% | Wgt Acc: 97.184%
I - num batch: 160
I - Train -- Loss: 0.445 | Acc: 97.095% | Wgt Acc: 97.036% | LR: 1.250000e-04 | Dur: 103.87s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   4.   3.  17.]
 [  4. 568.   8.   6.]
 [  6.   3. 717.   6.]
 [  8.   3.   6. 509.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.029 | Acc: 60.550% | Wgt Acc: 59.103% | Dur: 10.85s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  8.  5. 27.]
 [ 2. 33. 11.  4.]
 [ 2. 32. 50. 10.]
 [14.  5.  9. 45.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 0.430 | Acc: 98.000% | Wgt Acc: 97.937%
	I - Batch: 100 | Loss: 0.444 | Acc: 97.062% | Wgt Acc: 96.965%
	I - Batch: 150 | Loss: 0.442 | Acc: 97.125% | Wgt Acc: 97.035%
I - num batch: 160
I - Train -- Loss: 0.441 | Acc: 97.252% | Wgt Acc: 97.160% | LR: 1.250000e-04 | Dur: 107.83s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   3.   3.  17.]
 [  6. 564.   7.   4.]
 [  1.   7. 723.   6.]
 [ 11.   4.   1. 511.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.032 | Acc: 59.327% | Wgt Acc: 58.288% | Dur: 10.97s
I - Confusion Matrix: [row->prediction - col->label]
[[69. 10.  6. 24.]
 [ 3. 31. 12.  6.]
 [ 3. 32. 43.  5.]
 [13.  5. 14. 51.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 0.444 | Acc: 97.375% | Wgt Acc: 97.262%
	I - Batch: 100 | Loss: 0.440 | Acc: 96.938% | Wgt Acc: 96.804%
	I - Batch: 150 | Loss: 0.436 | Acc: 97.333% | Wgt Acc: 97.220%
I - num batch: 160
I - Train -- Loss: 0.438 | Acc: 97.173% | Wgt Acc: 97.054% | LR: 1.250000e-04 | Dur: 103.90s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   2.   1.  18.]
 [  5. 567.   7.   7.]
 [  6.   7. 726.   9.]
 [  8.   2.   0. 504.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.033 | Acc: 62.080% | Wgt Acc: 60.802% | Dur: 10.62s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5.  3. 19.]
 [ 5. 41. 16. 11.]
 [ 6. 30. 51. 14.]
 [ 8.  2.  5. 42.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 0.439 | Acc: 97.375% | Wgt Acc: 97.296%
	I - Batch: 100 | Loss: 0.438 | Acc: 97.188% | Wgt Acc: 97.126%
	I - Batch: 150 | Loss: 0.434 | Acc: 97.458% | Wgt Acc: 97.390%
I - num batch: 160
I - Train -- Loss: 0.435 | Acc: 97.409% | Wgt Acc: 97.337% | LR: 1.250000e-04 | Dur: 107.83s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   5.   1.  17.]
 [  1. 566.   7.   4.]
 [  3.   5. 723.   4.]
 [ 14.   2.   3. 513.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.021 | Acc: 62.691% | Wgt Acc: 61.345% | Dur: 11.80s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  3.  4. 28.]
 [ 3. 40. 10.  7.]
 [ 6. 31. 56.  8.]
 [13.  4.  5. 43.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 0.442 | Acc: 96.750% | Wgt Acc: 96.710%
	I - Batch: 100 | Loss: 0.438 | Acc: 97.000% | Wgt Acc: 96.968%
	I - Batch: 150 | Loss: 0.439 | Acc: 97.000% | Wgt Acc: 96.901%
I - num batch: 160
I - Train -- Loss: 0.437 | Acc: 97.134% | Wgt Acc: 97.036% | LR: 1.250000e-04 | Dur: 105.62s
I - Confusion Matrix: [row->prediction - col->label]
[[677.   2.   0.  23.]
 [  5. 570.   8.   6.]
 [  4.   5. 724.   6.]
 [ 11.   1.   2. 503.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.093 | Acc: 56.575% | Wgt Acc: 55.231% | Dur: 10.67s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 10. 15. 41.]
 [ 3. 37. 17.  5.]
 [ 1. 26. 34.  4.]
 [ 6.  5.  9. 36.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 0.426 | Acc: 98.000% | Wgt Acc: 97.862%
	I - Batch: 100 | Loss: 0.428 | Acc: 97.812% | Wgt Acc: 97.708%
	I - Batch: 150 | Loss: 0.432 | Acc: 97.750% | Wgt Acc: 97.634%
I - num batch: 160
I - Train -- Loss: 0.430 | Acc: 97.841% | Wgt Acc: 97.735% | LR: 1.250000e-04 | Dur: 106.13s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   3.   1.  17.]
 [  1. 569.   3.   4.]
 [  2.   2. 728.   6.]
 [ 10.   4.   2. 511.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.021 | Acc: 61.774% | Wgt Acc: 61.209% | Dur: 10.99s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 10. 10. 33.]
 [ 3. 47. 20.  2.]
 [ 0. 19. 34.  5.]
 [10.  2. 11. 46.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 0.423 | Acc: 98.250% | Wgt Acc: 98.175%
	I - Batch: 100 | Loss: 0.425 | Acc: 97.938% | Wgt Acc: 97.872%
	I - Batch: 150 | Loss: 0.426 | Acc: 97.875% | Wgt Acc: 97.813%
I - num batch: 160
I - Train -- Loss: 0.426 | Acc: 97.841% | Wgt Acc: 97.771% | LR: 1.250000e-04 | Dur: 108.09s
I - Confusion Matrix: [row->prediction - col->label]
[[679.   4.   0.  13.]
 [  2. 572.   4.   9.]
 [  4.   1. 729.   4.]
 [ 12.   1.   1. 512.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.022 | Acc: 64.526% | Wgt Acc: 63.995% | Dur: 11.93s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  8.  3. 22.]
 [ 5. 46. 18.  6.]
 [ 1. 19. 44.  6.]
 [13.  5. 10. 52.]]

I - Local maximum validation set accuracy:  64.53

I - Validation set results: 
[14-1-1-0.28][50-3-1-0.67][124-2-2-0.99][127-0-0-0.99][443-2-2-0.99][567-0-0-0.99][573-1-1-0.24][615-0-3--0.10][695-1-2-0.99][722-3-3-0.94]
[826-0-0-0.99][878-0-0-0.99][1103-0-0-0.07][1212-3-3-0.48][1368-0-0-0.99][2181-2-2-0.99][2476-2-2--0.60][2721-2-2-0.82][2818-1-1--0.62][2886-2-1-0.99]
[3231-2-2-0.99][3333-2-1-0.28][3482-2-2-0.89][3536-3-3-0.76][3625-1-1-0.87][3909-0-0-0.99][4035-0-0-0.99][4140-0-0-0.80][4214-1-3-0.19][4346-1-1--0.59]
[4581-2-2-0.44][4708-3-3-0.54][4838-3-0-0.56][4845-1-1-0.84][4868-0-0-0.95][4939-0-1-0.16][4984-2-2-0.42][5078-1-0-0.49][5396-0-0-0.99][5479-1-1--0.42]
[5717-0-0-0.70][5843-1-1-0.66][5949-3-3-0.09][5987-2-2-0.15][6014-3-3-0.32][6033-3-0--0.36][6313-0-0-0.45][6421-3-3-0.67][6500-1-2--0.07][6583-3-3-0.98]
[6683-3-3-0.83][6825-2-1-0.80][6998-3-3-0.02][7049-3-3-0.64][7517-1-1-0.51][7521-1-0-0.93][7528-1-3-0.95][7949-1-1--0.15][8135-1-0-0.87][8185-3-0-0.99]
[8269-3-1-0.01][8273-3-3-0.90][8543-3-0-0.99][8666-1-1--0.20][8672-0-3-0.55][8903-1-2-0.95][9001-2-1-0.94][9036-2-2-0.79][9281-3-1--0.11][9300-2-2-0.48]
[9571-0-0--0.28][9617-1-1-0.31][9644-2-2-0.28][9705-2-2-0.07][9801-0-3-0.89][9803-3-3-0.40][9865-3-3--0.40][9896-2-2-0.12][10314-1-0-0.64][10337-3-3-0.68]
[10403-0-0--0.13][10653-2-1--0.09][10704-2-1-0.11][10719-1-1-0.97][10727-1-2-0.37][10836-0-0-0.99][10969-2-2--0.41][11042-0-3-0.26][11088-1-1-0.99][11322-0-0-0.99]
[11398-2-2-0.33][11499-0-0-0.99][11502-3-0--0.07][11512-3-3-0.80][11608-1-1-0.99][11610-0-0-0.60][11692-0-0-0.99][11905-0-0-0.17][11993-1-1-0.99][12002-2-0--0.01]
[12052-0-0-0.99][12201-0-0-0.44][12235-2-2-0.88][12320-1-0-0.83][12377-2-1-0.25][12398-2-2-0.27][12503-1-1-0.34][12617-0-1-0.83][12685-3-3--0.24][12738-2-2-0.82]
[12742-2-2-0.99][12823-0-3-0.99][13110-1-1-0.99][13240-3-0-0.99][13253-1-1-0.99][13273-0-0-0.99][13634-1-2--0.32][13763-2-3--0.56][13905-3-0-0.09][14060-2-1-0.91]
[14065-3-0-0.99][14147-3-3-0.83][14595-2-1-0.67][14687-2-2-0.99][14788-2-1-0.84][14869-1-1-0.57][14872-3-2-0.72][14877-1-1-0.99][14927-0-3-0.21][15066-0-0-0.99]
[15175-1-1-0.33][15178-2-3--0.11][15375-3-0--0.11][15389-3-3-0.99][15568-2-1-0.72][15675-3-3-0.97][15869-1-2--0.53][16207-3-0-0.99][16236-0-2-0.76][16302-3-0-0.99]
[16331-2-2-0.99][16381-0-3-0.37][16488-1-1-0.99][16495-0-0-0.65][16650-0-0-0.99][16719-1-2-0.41][16801-0-0-0.99][16828-0-0-0.99][17137-3-3-0.38][17245-1-3--0.43]
[17278-3-0-0.38][17282-0-0-0.90][17311-2-2-0.99][17336-2-1-0.75][17608-3-3-0.99][17627-0-0-0.69][17877-3-0-0.94][17924-1-3-0.45][17984-3-0-0.99][18211-0-1-0.32]
[18276-3-3-0.76][18287-1-1-0.99][18394-0-0-0.99][18428-0-3--0.38][18442-0-3-0.99][18478-3-3-0.43][18607-0-0-0.94][18616-0-0-0.99][18663-0-0-0.99][18718-0-0-0.99]
[18766-2-3-0.93][18824-2-2-0.24][18890-3-2--0.17][18930-3-1-0.58][18938-3-3-0.60][19817-1-2--0.27][19839-0-0--0.13][19930-3-3-0.68][19944-0-0-0.30][20036-2-2-0.38]
[20101-3-3-0.54][20474-1-2-0.63][20547-3-3-0.79][20929-2-1-0.20][21245-1-1-0.64][21257-3-3--0.45][21293-1-2-0.61][21316-1-1-0.02][21384-1-2-0.97][21448-1-1-0.17]
[21483-0-0-0.99][21487-2-2-0.99][21714-0-0--0.02][21943-3-3-0.25][21947-0-0-0.99][21948-0-0-0.99][21965-2-2-0.99][21998-1-1-0.99][22025-0-3-0.17][22228-3-3-0.99]
[22446-1-1-0.99][22494-3-0-0.30][22757-0-0-0.93][22811-3-3-0.92][22976-3-1-0.33][22985-3-3-0.99][23014-0-0-0.99][23112-1-1-0.99][23144-3-3-0.10][23168-2-0--0.42]
[23219-0-0-0.99][23363-3-3-0.60][23470-0-0-0.18][23486-2-2--0.24][23497-0-3-0.99][23516-0-0-0.99][23690-1-2-0.10][23921-2-2-0.63][23936-1-2-0.99][24040-3-0-0.68]
[24111-1-2-0.91][24182-0-0-0.86][24238-3-3-0.70][24290-2-0-0.76][24345-0-0--0.33][24364-1-2-0.99][24427-3-0-0.99][24477-2-2-0.77][24495-2-1-0.83][24893-2-2-0.90]
[25012-1-1-0.27][25121-2-1--0.25][25165-3-3-0.99][25183-0-0-0.99][25297-3-3-0.99][25398-0-0-0.99][25574-2-2-0.32][25644-1-1-0.99][25718-1-1-0.09][25774-2-3-0.82]
[26032-3-0-0.17][26051-3-3-0.93][26120-0-0-0.53][26321-1-1--0.10][26732-1-1-0.78][26784-3-3-0.91][26827-3-3-0.65][26833-0-3-0.99][26838-2-3--0.16][26860-1-1-0.21]
[26948-0-0-0.68][27049-3-0-0.99][27098-1-0-0.65][27526-0-0-0.99][27639-3-3--0.30][27698-3-3-0.99][27772-0-0-0.92][27890-1-1-0.87][28040-0-0-0.98][28503-2-2-0.93]
[28577-1-1--0.11][28959-0-0-0.90][29198-3-2-0.63][29777-0-0-0.99][29877-2-3-0.30][30035-1-1--0.70][30098-0-0-0.31][30326-1-1-0.99][30572-2-2-0.34][30716-0-1-0.98]
[30806-2-3-0.99][30906-1-1-0.98][31007-0-0-0.88][31181-3-3--0.47][31238-0-0-0.31][31347-0-0-0.99][31422-2-2-0.31][31429-3-3--0.31][31431-0-0-0.30][31432-1-1-0.64]
[31477-0-0-0.80][31524-1-0--0.42][31597-1-1-0.53][31619-1-2-0.99][31701-0-0-0.99][31755-0-0-0.80][31854-3-3-0.24][32074-1-1--0.22][32078-3-3-0.99][32111-1-1-0.86]
[32127-1-2-0.99][32140-3-3-0.99][32263-2-2-0.02][32365-0-0-0.94][32411-2-3-0.99][32429-3-0-0.99][32473-3-0-0.74][32574-3-3-0.96][32584-0-3-0.14][32622-0-0--0.05]
[32858-3-0-0.99][32969-3-3-0.94][33016-2-2-0.99][33031-1-0-0.10][33035-2-2-0.70][33133-2-2-0.29][33173-2-1-0.39][33175-3-2-0.99][33306-3-1-0.65][33309-2-3-0.77]
[33474-0-1-0.60][33478-2-2--0.58][33618-1-1-0.99][33712-0-0-0.48][33782-2-2-0.81][33914-3-3-0.95][34076-3-2--0.33][34112-2-1-0.99][34138-2-3-0.88][34239-1-3--0.38]
[34364-2-1-0.15][34617-1-2-0.32][34751-3-3-0.39][34783-2-2-0.66][35015-3-2-0.83][35018-1-2-0.41][35288-2-2-0.81]
---------------------------
I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.429 | Acc: 97.625% | Wgt Acc: 97.591%
	I - Batch: 100 | Loss: 0.428 | Acc: 97.188% | Wgt Acc: 97.164%
	I - Batch: 150 | Loss: 0.426 | Acc: 97.625% | Wgt Acc: 97.579%
I - num batch: 160
I - Train -- Loss: 0.426 | Acc: 97.605% | Wgt Acc: 97.558% | LR: 1.250000e-04 | Dur: 105.13s
I - Confusion Matrix: [row->prediction - col->label]
[[678.   5.   2.  12.]
 [  4. 568.   5.   3.]
 [  4.   4. 724.   7.]
 [ 11.   1.   3. 516.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.043 | Acc: 59.633% | Wgt Acc: 58.560% | Dur: 10.82s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  6.  3. 20.]
 [ 5. 36. 15.  7.]
 [ 5. 30. 49. 13.]
 [14.  6.  8. 46.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 0.419 | Acc: 98.000% | Wgt Acc: 97.888%
	I - Batch: 100 | Loss: 0.415 | Acc: 98.438% | Wgt Acc: 98.353%
	I - Batch: 150 | Loss: 0.418 | Acc: 98.333% | Wgt Acc: 98.243%
I - num batch: 160
I - Train -- Loss: 0.418 | Acc: 98.312% | Wgt Acc: 98.222% | LR: 1.250000e-04 | Dur: 107.14s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   3.   0.  10.]
 [  1. 571.   1.   4.]
 [  4.   2. 732.   8.]
 [  7.   2.   1. 516.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.016 | Acc: 61.162% | Wgt Acc: 60.462% | Dur: 10.53s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  6.  4. 24.]
 [ 4. 40. 17.  6.]
 [ 4. 28. 41.  6.]
 [11.  4. 13. 50.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.417 | Acc: 98.000% | Wgt Acc: 97.889%
	I - Batch: 100 | Loss: 0.415 | Acc: 98.125% | Wgt Acc: 98.067%
	I - Batch: 150 | Loss: 0.416 | Acc: 98.000% | Wgt Acc: 97.935%
I - num batch: 160
I - Train -- Loss: 0.417 | Acc: 97.998% | Wgt Acc: 97.930% | LR: 1.250000e-04 | Dur: 105.41s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   2.   0.  14.]
 [  5. 573.   4.   5.]
 [  5.   3. 730.   6.]
 [  7.   0.   0. 513.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.030 | Acc: 62.997% | Wgt Acc: 61.821% | Dur: 10.97s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  7.  5. 19.]
 [ 4. 42. 18.  8.]
 [ 4. 26. 49. 15.]
 [ 9.  3.  3. 44.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.414 | Acc: 98.000% | Wgt Acc: 98.001%
	I - Batch: 100 | Loss: 0.415 | Acc: 98.062% | Wgt Acc: 98.014%
	I - Batch: 150 | Loss: 0.413 | Acc: 98.292% | Wgt Acc: 98.236%
I - num batch: 160
I - Train -- Loss: 0.414 | Acc: 98.312% | Wgt Acc: 98.257% | LR: 1.250000e-04 | Dur: 106.50s
I - Confusion Matrix: [row->prediction - col->label]
[[682.   4.   0.  13.]
 [  2. 574.   2.   3.]
 [  3.   0. 731.   5.]
 [ 10.   0.   1. 517.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.045 | Acc: 60.550% | Wgt Acc: 60.190% | Dur: 10.82s
I - Confusion Matrix: [row->prediction - col->label]
[[74. 11. 11. 27.]
 [ 1. 40. 18.  2.]
 [ 0. 19. 30.  3.]
 [13.  8. 16. 54.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.421 | Acc: 97.375% | Wgt Acc: 97.269%
	I - Batch: 100 | Loss: 0.417 | Acc: 97.562% | Wgt Acc: 97.479%
	I - Batch: 150 | Loss: 0.414 | Acc: 97.958% | Wgt Acc: 97.887%
I - num batch: 160
I - Train -- Loss: 0.414 | Acc: 97.998% | Wgt Acc: 97.921% | LR: 1.250000e-04 | Dur: 106.06s
I - Confusion Matrix: [row->prediction - col->label]
[[680.   4.   0.  16.]
 [  3. 572.   1.   2.]
 [  3.   0. 731.   7.]
 [ 11.   2.   2. 513.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.057 | Acc: 59.939% | Wgt Acc: 58.152% | Dur: 10.78s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  6.  5. 36.]
 [ 3. 38. 14.  5.]
 [ 4. 32. 52. 11.]
 [ 9.  2.  4. 34.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.402 | Acc: 98.500% | Wgt Acc: 98.441%
	I - Batch: 100 | Loss: 0.403 | Acc: 98.562% | Wgt Acc: 98.489%
	I - Batch: 150 | Loss: 0.407 | Acc: 98.500% | Wgt Acc: 98.440%
I - num batch: 160
I - Train -- Loss: 0.409 | Acc: 98.390% | Wgt Acc: 98.319% | LR: 1.250000e-04 | Dur: 107.43s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   2.   1.  11.]
 [  1. 571.   0.   1.]
 [  3.   2. 732.   7.]
 [  9.   3.   1. 519.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.023 | Acc: 62.080% | Wgt Acc: 61.481% | Dur: 11.69s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  7.  5. 23.]
 [ 5. 43. 16.  5.]
 [ 2. 23. 44.  8.]
 [15.  5. 10. 50.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.416 | Acc: 98.250% | Wgt Acc: 98.238%
	I - Batch: 100 | Loss: 0.417 | Acc: 98.125% | Wgt Acc: 98.058%
	I - Batch: 150 | Loss: 0.413 | Acc: 98.417% | Wgt Acc: 98.358%
I - num batch: 160
I - Train -- Loss: 0.412 | Acc: 98.390% | Wgt Acc: 98.337% | LR: 1.250000e-04 | Dur: 104.52s
I - Confusion Matrix: [row->prediction - col->label]
[[684.   3.   0.  10.]
 [  5. 572.   2.   2.]
 [  2.   1. 730.   6.]
 [  6.   2.   2. 520.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.042 | Acc: 59.939% | Wgt Acc: 58.288% | Dur: 10.83s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  4.  4. 26.]
 [ 4. 36. 15.  4.]
 [ 4. 36. 52. 18.]
 [10.  2.  4. 38.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.403 | Acc: 98.875% | Wgt Acc: 98.815%
	I - Batch: 100 | Loss: 0.404 | Acc: 98.875% | Wgt Acc: 98.832%
	I - Batch: 150 | Loss: 0.411 | Acc: 98.542% | Wgt Acc: 98.451%
I - num batch: 160
I - Train -- Loss: 0.411 | Acc: 98.547% | Wgt Acc: 98.470% | LR: 1.250000e-04 | Dur: 103.75s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   5.   0.  12.]
 [  2. 570.   2.   3.]
 [  3.   2. 731.   2.]
 [  4.   1.   1. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.035 | Acc: 62.691% | Wgt Acc: 61.549% | Dur: 11.05s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  6.  3. 16.]
 [ 4. 37. 13.  7.]
 [ 6. 32. 55. 14.]
 [14.  3.  4. 49.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.407 | Acc: 98.875% | Wgt Acc: 98.815%
	I - Batch: 100 | Loss: 0.403 | Acc: 98.750% | Wgt Acc: 98.663%
	I - Batch: 150 | Loss: 0.406 | Acc: 98.708% | Wgt Acc: 98.639%
I - num batch: 160
I - Train -- Loss: 0.406 | Acc: 98.744% | Wgt Acc: 98.673% | LR: 1.250000e-04 | Dur: 106.62s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   2.   1.  10.]
 [  3. 574.   1.   1.]
 [  4.   0. 731.   7.]
 [  0.   2.   1. 520.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.060 | Acc: 59.021% | Wgt Acc: 58.424% | Dur: 11.87s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  8.  6. 30.]
 [ 2. 38. 15.  3.]
 [ 0. 21. 32.  3.]
 [13. 11. 22. 50.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.406 | Acc: 98.875% | Wgt Acc: 98.871%
	I - Batch: 100 | Loss: 0.404 | Acc: 98.750% | Wgt Acc: 98.719%
	I - Batch: 150 | Loss: 0.401 | Acc: 98.875% | Wgt Acc: 98.836%
I - num batch: 160
I - Train -- Loss: 0.404 | Acc: 98.704% | Wgt Acc: 98.646% | LR: 1.250000e-04 | Dur: 106.82s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   3.   0.  11.]
 [  4. 574.   0.   3.]
 [  3.   1. 733.   3.]
 [  4.   0.   1. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.047 | Acc: 61.774% | Wgt Acc: 60.734% | Dur: 10.78s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 11.  8. 30.]
 [ 1. 38. 15.  4.]
 [ 1. 26. 43.  4.]
 [13.  3.  9. 48.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.405 | Acc: 98.875% | Wgt Acc: 98.813%
	I - Batch: 100 | Loss: 0.405 | Acc: 98.625% | Wgt Acc: 98.517%
	I - Batch: 150 | Loss: 0.403 | Acc: 98.708% | Wgt Acc: 98.638%
I - num batch: 160
I - Train -- Loss: 0.404 | Acc: 98.587% | Wgt Acc: 98.523% | LR: 1.250000e-04 | Dur: 110.23s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   3.   0.   9.]
 [  3. 572.   1.   2.]
 [  2.   2. 732.   6.]
 [  6.   1.   1. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.016 | Acc: 61.774% | Wgt Acc: 60.938% | Dur: 11.36s
I - Confusion Matrix: [row->prediction - col->label]
[[60.  3.  1. 19.]
 [ 9. 47. 14. 14.]
 [ 7. 27. 53. 11.]
 [12.  1.  7. 42.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.397 | Acc: 99.125% | Wgt Acc: 99.075%
	I - Batch: 100 | Loss: 0.398 | Acc: 99.062% | Wgt Acc: 99.000%
	I - Batch: 150 | Loss: 0.401 | Acc: 98.625% | Wgt Acc: 98.526%
I - num batch: 160
I - Train -- Loss: 0.400 | Acc: 98.626% | Wgt Acc: 98.531% | LR: 1.250000e-04 | Dur: 105.02s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   3.   0.  10.]
 [  0. 572.   3.   3.]
 [  2.   2. 730.   7.]
 [  3.   1.   1. 518.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.051 | Acc: 57.798% | Wgt Acc: 57.065% | Dur: 10.70s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  7.  4. 32.]
 [ 6. 47. 24.  7.]
 [ 3. 22. 38. 10.]
 [12.  2.  9. 37.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.395 | Acc: 99.000% | Wgt Acc: 98.950%
	I - Batch: 100 | Loss: 0.400 | Acc: 99.188% | Wgt Acc: 99.137%
	I - Batch: 150 | Loss: 0.402 | Acc: 98.958% | Wgt Acc: 98.900%
I - num batch: 160
I - Train -- Loss: 0.402 | Acc: 98.940% | Wgt Acc: 98.877% | LR: 1.250000e-04 | Dur: 108.04s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   1.   0.  11.]
 [  0. 574.   0.   2.]
 [  2.   1. 733.   2.]
 [  5.   2.   1. 523.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.061 | Acc: 60.550% | Wgt Acc: 59.715% | Dur: 10.90s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  1.  2. 21.]
 [10. 50. 23. 15.]
 [ 5. 25. 47. 13.]
 [ 9.  2.  3. 37.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.412 | Acc: 98.500% | Wgt Acc: 98.393%
	I - Batch: 100 | Loss: 0.405 | Acc: 98.625% | Wgt Acc: 98.550%
	I - Batch: 150 | Loss: 0.403 | Acc: 98.875% | Wgt Acc: 98.817%
I - num batch: 160
I - Train -- Loss: 0.403 | Acc: 98.901% | Wgt Acc: 98.841% | LR: 1.250000e-04 | Dur: 107.12s
I - Confusion Matrix: [row->prediction - col->label]
[[688.   2.   0.   6.]
 [  1. 574.   0.   4.]
 [  3.   0. 734.   5.]
 [  5.   2.   0. 523.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.016 | Acc: 62.080% | Wgt Acc: 61.141% | Dur: 10.70s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  5.  5. 22.]
 [ 5. 36.  9.  3.]
 [ 2. 31. 49.  9.]
 [15.  6. 12. 52.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.388 | Acc: 99.125% | Wgt Acc: 99.125%
	I - Batch: 100 | Loss: 0.393 | Acc: 98.938% | Wgt Acc: 98.887%
	I - Batch: 150 | Loss: 0.398 | Acc: 98.667% | Wgt Acc: 98.630%
I - num batch: 160
I - Train -- Loss: 0.399 | Acc: 98.626% | Wgt Acc: 98.576% | LR: 1.250000e-04 | Dur: 104.23s
I - Confusion Matrix: [row->prediction - col->label]
[[685.   1.   1.  10.]
 [  2. 574.   1.   3.]
 [  4.   1. 732.   4.]
 [  6.   2.   0. 521.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.060 | Acc: 59.633% | Wgt Acc: 58.560% | Dur: 12.08s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  6.  4. 26.]
 [ 5. 33. 13.  2.]
 [ 2. 33. 45.  9.]
 [13.  6. 13. 49.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.402 | Acc: 98.625% | Wgt Acc: 98.537%
	I - Batch: 100 | Loss: 0.395 | Acc: 98.938% | Wgt Acc: 98.870%
	I - Batch: 150 | Loss: 0.395 | Acc: 99.000% | Wgt Acc: 98.938%
I - num batch: 160
I - Train -- Loss: 0.397 | Acc: 99.018% | Wgt Acc: 98.965% | LR: 1.250000e-04 | Dur: 107.30s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   2.   1.   9.]
 [  1. 573.   0.   2.]
 [  3.   2. 732.   1.]
 [  2.   1.   1. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.079 | Acc: 56.269% | Wgt Acc: 56.658% | Dur: 10.82s
I - Confusion Matrix: [row->prediction - col->label]
[[51.  9.  2. 16.]
 [ 3. 35. 14.  3.]
 [ 2. 18. 35.  4.]
 [32. 16. 24. 63.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.414 | Acc: 98.250% | Wgt Acc: 98.195%
	I - Batch: 100 | Loss: 0.405 | Acc: 98.562% | Wgt Acc: 98.518%
	I - Batch: 150 | Loss: 0.401 | Acc: 98.667% | Wgt Acc: 98.648%
I - num batch: 160
I - Train -- Loss: 0.401 | Acc: 98.665% | Wgt Acc: 98.638% | LR: 1.250000e-04 | Dur: 103.88s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   2.   1.   9.]
 [  3. 574.   4.   1.]
 [  2.   1. 729.   4.]
 [  6.   1.   0. 524.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.073 | Acc: 57.492% | Wgt Acc: 55.978% | Dur: 10.68s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 14. 11. 44.]
 [ 3. 39. 20.  3.]
 [ 0. 19. 35.  6.]
 [ 4.  6.  9. 33.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.393 | Acc: 99.125% | Wgt Acc: 99.068%
	I - Batch: 100 | Loss: 0.392 | Acc: 99.062% | Wgt Acc: 98.999%
	I - Batch: 150 | Loss: 0.392 | Acc: 99.000% | Wgt Acc: 98.940%
I - num batch: 160
I - Train -- Loss: 0.395 | Acc: 99.018% | Wgt Acc: 98.965% | LR: 1.250000e-04 | Dur: 108.83s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   3.   0.   8.]
 [  2. 573.   0.   1.]
 [  2.   1. 733.   3.]
 [  3.   1.   1. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.049 | Acc: 59.327% | Wgt Acc: 58.696% | Dur: 11.00s
I - Confusion Matrix: [row->prediction - col->label]
[[73.  7.  4. 28.]
 [ 2. 38. 18.  3.]
 [ 0. 27. 33.  5.]
 [13.  6. 20. 50.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.412 | Acc: 98.625% | Wgt Acc: 98.589%
	I - Batch: 100 | Loss: 0.407 | Acc: 98.688% | Wgt Acc: 98.634%
	I - Batch: 150 | Loss: 0.402 | Acc: 98.875% | Wgt Acc: 98.807%
I - num batch: 160
I - Train -- Loss: 0.403 | Acc: 98.822% | Wgt Acc: 98.744% | LR: 1.250000e-04 | Dur: 108.96s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   3.   1.  10.]
 [  2. 572.   0.   1.]
 [  1.   1. 733.   5.]
 [  4.   2.   0. 522.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.000 | Acc: 62.997% | Wgt Acc: 61.685% | Dur: 11.08s
I - Confusion Matrix: [row->prediction - col->label]
[[71.  5.  4. 31.]
 [ 3. 40.  8.  4.]
 [ 2. 31. 51.  7.]
 [12.  2. 12. 44.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.377 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.383 | Acc: 99.375% | Wgt Acc: 99.366%
	I - Batch: 150 | Loss: 0.390 | Acc: 99.083% | Wgt Acc: 99.042%
I - num batch: 160
I - Train -- Loss: 0.390 | Acc: 99.097% | Wgt Acc: 99.062% | LR: 1.250000e-04 | Dur: 107.85s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   4.   0.   6.]
 [  1. 574.   1.   1.]
 [  3.   0. 732.   3.]
 [  3.   0.   1. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.036 | Acc: 61.774% | Wgt Acc: 61.005% | Dur: 11.03s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  6.  3. 18.]
 [ 4. 40. 14.  7.]
 [ 4. 29. 48. 11.]
 [16.  3. 10. 50.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.394 | Acc: 98.875% | Wgt Acc: 98.874%
	I - Batch: 100 | Loss: 0.393 | Acc: 99.188% | Wgt Acc: 99.155%
	I - Batch: 150 | Loss: 0.392 | Acc: 99.208% | Wgt Acc: 99.164%
I - num batch: 160
I - Train -- Loss: 0.394 | Acc: 99.176% | Wgt Acc: 99.124% | LR: 1.250000e-04 | Dur: 108.49s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   1.   0.   5.]
 [  1. 573.   0.   1.]
 [  0.   3. 734.   4.]
 [  5.   1.   0. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.019 | Acc: 60.245% | Wgt Acc: 59.783% | Dur: 10.74s
I - Confusion Matrix: [row->prediction - col->label]
[[69.  5. 10. 24.]
 [ 4. 40. 20.  4.]
 [ 2. 21. 36.  6.]
 [13. 12.  9. 52.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.391 | Acc: 98.625% | Wgt Acc: 98.596%
	I - Batch: 100 | Loss: 0.388 | Acc: 99.062% | Wgt Acc: 99.028%
	I - Batch: 150 | Loss: 0.391 | Acc: 98.958% | Wgt Acc: 98.902%
I - num batch: 160
I - Train -- Loss: 0.390 | Acc: 99.018% | Wgt Acc: 98.965% | LR: 1.250000e-04 | Dur: 107.48s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   2.   0.   6.]
 [  6. 571.   0.   3.]
 [  1.   3. 734.   1.]
 [  1.   2.   0. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.085 | Acc: 59.021% | Wgt Acc: 57.541% | Dur: 11.00s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 13. 12. 39.]
 [ 2. 38. 14.  4.]
 [ 2. 22. 40.  6.]
 [ 6.  5.  9. 37.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.385 | Acc: 99.250% | Wgt Acc: 99.270%
	I - Batch: 100 | Loss: 0.385 | Acc: 99.125% | Wgt Acc: 99.086%
	I - Batch: 150 | Loss: 0.387 | Acc: 99.125% | Wgt Acc: 99.071%
I - num batch: 160
I - Train -- Loss: 0.387 | Acc: 99.136% | Wgt Acc: 99.080% | LR: 1.250000e-04 | Dur: 103.08s
I - Confusion Matrix: [row->prediction - col->label]
[[691.   2.   0.   8.]
 [  3. 574.   0.   1.]
 [  3.   1. 734.   3.]
 [  0.   1.   0. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.045 | Acc: 59.327% | Wgt Acc: 58.560% | Dur: 10.71s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  5.  5. 25.]
 [ 3. 42. 19.  7.]
 [ 4. 28. 43. 10.]
 [16.  3.  8. 44.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.375 | Acc: 99.500% | Wgt Acc: 99.463%
	I - Batch: 100 | Loss: 0.382 | Acc: 99.250% | Wgt Acc: 99.183%
	I - Batch: 150 | Loss: 0.383 | Acc: 99.250% | Wgt Acc: 99.183%
I - num batch: 160
I - Train -- Loss: 0.384 | Acc: 99.254% | Wgt Acc: 99.186% | LR: 1.250000e-04 | Dur: 106.41s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   2.   0.   8.]
 [  0. 574.   0.   0.]
 [  2.   1. 734.   4.]
 [  1.   1.   0. 526.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.041 | Acc: 60.550% | Wgt Acc: 59.851% | Dur: 11.03s
I - Confusion Matrix: [row->prediction - col->label]
[[70.  9.  7. 27.]
 [ 5. 39. 18.  2.]
 [ 3. 24. 39.  7.]
 [10.  6. 11. 50.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.376 | Acc: 99.375% | Wgt Acc: 99.377%
	I - Batch: 100 | Loss: 0.380 | Acc: 99.312% | Wgt Acc: 99.281%
	I - Batch: 150 | Loss: 0.383 | Acc: 99.208% | Wgt Acc: 99.155%
I - num batch: 160
I - Train -- Loss: 0.385 | Acc: 99.176% | Wgt Acc: 99.115% | LR: 1.250000e-04 | Dur: 106.99s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   1.   0.   5.]
 [  0. 572.   0.   2.]
 [  2.   3. 733.   3.]
 [  2.   2.   1. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.062 | Acc: 59.939% | Wgt Acc: 59.443% | Dur: 12.09s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 10. 11. 25.]
 [ 0. 33. 14.  1.]
 [ 0. 22. 30.  2.]
 [13. 13. 20. 58.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.405 | Acc: 98.875% | Wgt Acc: 98.790%
	I - Batch: 100 | Loss: 0.395 | Acc: 99.188% | Wgt Acc: 99.113%
	I - Batch: 150 | Loss: 0.393 | Acc: 99.208% | Wgt Acc: 99.174%
I - num batch: 160
I - Train -- Loss: 0.392 | Acc: 99.254% | Wgt Acc: 99.222% | LR: 1.250000e-04 | Dur: 107.29s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   2.   0.   6.]
 [  2. 575.   0.   0.]
 [  3.   1. 734.   3.]
 [  2.   0.   0. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.013 | Acc: 60.856% | Wgt Acc: 59.783% | Dur: 11.38s
I - Confusion Matrix: [row->prediction - col->label]
[[70. 10.  8. 29.]
 [ 4. 35. 12.  1.]
 [ 1. 28. 45.  7.]
 [13.  5. 10. 49.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.392 | Acc: 99.125% | Wgt Acc: 99.128%
	I - Batch: 100 | Loss: 0.385 | Acc: 99.250% | Wgt Acc: 99.240%
	I - Batch: 150 | Loss: 0.383 | Acc: 99.292% | Wgt Acc: 99.267%
I - num batch: 160
I - Train -- Loss: 0.383 | Acc: 99.293% | Wgt Acc: 99.266% | LR: 1.250000e-04 | Dur: 105.28s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   1.   0.   5.]
 [  2. 574.   1.   1.]
 [  2.   1. 732.   1.]
 [  1.   2.   1. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.030 | Acc: 61.162% | Wgt Acc: 60.938% | Dur: 10.92s
I - Confusion Matrix: [row->prediction - col->label]
[[59.  6.  4. 19.]
 [ 5. 38. 14.  3.]
 [ 2. 26. 44.  5.]
 [22.  8. 13. 59.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.378 | Acc: 99.375% | Wgt Acc: 99.318%
	I - Batch: 100 | Loss: 0.378 | Acc: 99.250% | Wgt Acc: 99.199%
	I - Batch: 150 | Loss: 0.380 | Acc: 99.167% | Wgt Acc: 99.117%
I - num batch: 160
I - Train -- Loss: 0.380 | Acc: 99.176% | Wgt Acc: 99.133% | LR: 1.250000e-04 | Dur: 105.39s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   3.   0.   7.]
 [  2. 574.   0.   2.]
 [  3.   0. 734.   1.]
 [  2.   1.   0. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.012 | Acc: 62.080% | Wgt Acc: 61.821% | Dur: 10.73s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  7.  6. 15.]
 [ 3. 39. 13.  2.]
 [ 2. 25. 41. 10.]
 [19.  7. 15. 59.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.382 | Acc: 99.250% | Wgt Acc: 99.211%
	I - Batch: 100 | Loss: 0.381 | Acc: 99.312% | Wgt Acc: 99.282%
	I - Batch: 150 | Loss: 0.378 | Acc: 99.458% | Wgt Acc: 99.437%
I - num batch: 160
I - Train -- Loss: 0.379 | Acc: 99.372% | Wgt Acc: 99.337% | LR: 1.250000e-04 | Dur: 105.30s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   4.   0.   5.]
 [  2. 574.   1.   1.]
 [  0.   0. 733.   1.]
 [  2.   0.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.996 | Acc: 63.914% | Wgt Acc: 62.840% | Dur: 10.72s
I - Confusion Matrix: [row->prediction - col->label]
[[76. 11.  8. 24.]
 [ 4. 37. 11.  3.]
 [ 1. 24. 44.  7.]
 [ 7.  6. 12. 52.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.371 | Acc: 99.375% | Wgt Acc: 99.380%
	I - Batch: 100 | Loss: 0.371 | Acc: 99.500% | Wgt Acc: 99.478%
	I - Batch: 150 | Loss: 0.377 | Acc: 99.250% | Wgt Acc: 99.193%
I - num batch: 160
I - Train -- Loss: 0.380 | Acc: 99.215% | Wgt Acc: 99.160% | LR: 1.250000e-04 | Dur: 105.40s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   2.   0.  10.]
 [  1. 574.   0.   0.]
 [  3.   1. 733.   1.]
 [  0.   1.   1. 527.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.183 | Acc: 55.352% | Wgt Acc: 52.649% | Dur: 11.71s
I - Confusion Matrix: [row->prediction - col->label]
[[87. 18. 14. 54.]
 [ 1. 25. 10.  0.]
 [ 0. 30. 43.  6.]
 [ 0.  5.  8. 26.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.433 | Acc: 97.125% | Wgt Acc: 97.012%
	I - Batch: 100 | Loss: 0.418 | Acc: 97.938% | Wgt Acc: 97.860%
	I - Batch: 150 | Loss: 0.405 | Acc: 98.500% | Wgt Acc: 98.451%
I - num batch: 160
I - Train -- Loss: 0.403 | Acc: 98.547% | Wgt Acc: 98.496% | LR: 1.250000e-04 | Dur: 106.55s
I - Confusion Matrix: [row->prediction - col->label]
[[686.   5.   0.   8.]
 [  4. 569.   3.   3.]
 [  3.   4. 730.   2.]
 [  4.   0.   1. 525.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.016 | Acc: 63.609% | Wgt Acc: 62.908% | Dur: 12.25s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  6.  1. 20.]
 [ 5. 40. 18.  1.]
 [ 2. 27. 50. 11.]
 [17.  5.  6. 54.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.389 | Acc: 99.000% | Wgt Acc: 98.958%
	I - Batch: 100 | Loss: 0.386 | Acc: 99.000% | Wgt Acc: 98.944%
	I - Batch: 150 | Loss: 0.383 | Acc: 99.167% | Wgt Acc: 99.136%
I - num batch: 160
I - Train -- Loss: 0.382 | Acc: 99.215% | Wgt Acc: 99.186% | LR: 1.250000e-04 | Dur: 105.93s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   2.   0.   4.]
 [  1. 573.   0.   1.]
 [  1.   2. 734.   2.]
 [  6.   1.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.992 | Acc: 63.914% | Wgt Acc: 63.247% | Dur: 10.65s
I - Confusion Matrix: [row->prediction - col->label]
[[66.  7.  3. 18.]
 [ 4. 36. 14.  1.]
 [ 1. 28. 48.  8.]
 [17.  7. 10. 59.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.379 | Acc: 99.500% | Wgt Acc: 99.439%
	I - Batch: 100 | Loss: 0.380 | Acc: 99.250% | Wgt Acc: 99.198%
	I - Batch: 150 | Loss: 0.378 | Acc: 99.333% | Wgt Acc: 99.296%
I - num batch: 160
I - Train -- Loss: 0.381 | Acc: 99.372% | Wgt Acc: 99.337% | LR: 1.250000e-04 | Dur: 106.00s
I - Confusion Matrix: [row->prediction - col->label]
[[692.   0.   0.   4.]
 [  2. 572.   0.   1.]
 [  2.   3. 734.   0.]
 [  1.   3.   0. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.108 | Acc: 55.963% | Wgt Acc: 54.484% | Dur: 12.30s
I - Confusion Matrix: [row->prediction - col->label]
[[81. 16. 15. 42.]
 [ 2. 29.  8.  1.]
 [ 0. 29. 32.  2.]
 [ 5.  4. 20. 41.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.381 | Acc: 99.625% | Wgt Acc: 99.604%
	I - Batch: 100 | Loss: 0.380 | Acc: 99.500% | Wgt Acc: 99.463%
	I - Batch: 150 | Loss: 0.382 | Acc: 99.292% | Wgt Acc: 99.239%
I - num batch: 160
I - Train -- Loss: 0.383 | Acc: 99.293% | Wgt Acc: 99.239% | LR: 1.250000e-04 | Dur: 110.12s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   4.   0.   7.]
 [  1. 574.   0.   0.]
 [  2.   0. 734.   3.]
 [  1.   0.   0. 528.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.011 | Acc: 61.774% | Wgt Acc: 60.802% | Dur: 11.99s
I - Confusion Matrix: [row->prediction - col->label]
[[65.  6.  6. 24.]
 [ 4. 37. 11.  1.]
 [ 3. 30. 50. 11.]
 [16.  5.  8. 50.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.377 | Acc: 99.750% | Wgt Acc: 99.776%
	I - Batch: 100 | Loss: 0.377 | Acc: 99.625% | Wgt Acc: 99.621%
	I - Batch: 150 | Loss: 0.378 | Acc: 99.458% | Wgt Acc: 99.437%
I - num batch: 160
I - Train -- Loss: 0.379 | Acc: 99.450% | Wgt Acc: 99.425% | LR: 1.250000e-04 | Dur: 107.88s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   1.   0.   4.]
 [  0. 574.   0.   1.]
 [  3.   1. 733.   0.]
 [  1.   2.   1. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.068 | Acc: 61.162% | Wgt Acc: 59.851% | Dur: 11.92s
I - Confusion Matrix: [row->prediction - col->label]
[[76.  8.  9. 32.]
 [ 4. 39. 15.  2.]
 [ 1. 27. 43. 10.]
 [ 7.  4.  8. 42.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.385 | Acc: 99.375% | Wgt Acc: 99.296%
	I - Batch: 100 | Loss: 0.381 | Acc: 99.500% | Wgt Acc: 99.451%
	I - Batch: 150 | Loss: 0.381 | Acc: 99.417% | Wgt Acc: 99.362%
I - num batch: 160
I - Train -- Loss: 0.381 | Acc: 99.411% | Wgt Acc: 99.363% | LR: 1.250000e-04 | Dur: 108.98s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   3.   0.   5.]
 [  0. 573.   0.   0.]
 [  2.   1. 734.   2.]
 [  1.   1.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.051 | Acc: 59.939% | Wgt Acc: 58.832% | Dur: 10.66s
I - Confusion Matrix: [row->prediction - col->label]
[[71. 10. 10. 30.]
 [ 3. 43. 17.  7.]
 [ 2. 21. 43. 10.]
 [12.  4.  5. 39.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.376 | Acc: 99.750% | Wgt Acc: 99.719%
	I - Batch: 100 | Loss: 0.379 | Acc: 99.375% | Wgt Acc: 99.367%
	I - Batch: 150 | Loss: 0.378 | Acc: 99.417% | Wgt Acc: 99.390%
I - num batch: 160
I - Train -- Loss: 0.378 | Acc: 99.411% | Wgt Acc: 99.381% | LR: 1.250000e-04 | Dur: 108.14s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   2.   0.   5.]
 [  3. 575.   1.   0.]
 [  0.   0. 733.   2.]
 [  1.   1.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 0.999 | Acc: 62.691% | Wgt Acc: 62.500% | Dur: 11.53s
I - Confusion Matrix: [row->prediction - col->label]
[[68.  6.  8. 16.]
 [ 2. 38. 18.  2.]
 [ 4. 24. 37.  6.]
 [14. 10. 12. 62.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.367 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.372 | Acc: 99.625% | Wgt Acc: 99.591%
	I - Batch: 150 | Loss: 0.373 | Acc: 99.500% | Wgt Acc: 99.465%
I - num batch: 160
I - Train -- Loss: 0.372 | Acc: 99.529% | Wgt Acc: 99.496% | LR: 1.250000e-04 | Dur: 106.98s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   2.   0.   5.]
 [  0. 576.   0.   1.]
 [  3.   0. 734.   1.]
 [  0.   0.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.034 | Acc: 60.245% | Wgt Acc: 59.918% | Dur: 11.66s
I - Confusion Matrix: [row->prediction - col->label]
[[64. 10.  6. 23.]
 [ 3. 39. 11.  4.]
 [ 3. 24. 39.  4.]
 [18.  5. 19. 55.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.378 | Acc: 99.000% | Wgt Acc: 98.960%
	I - Batch: 100 | Loss: 0.375 | Acc: 99.312% | Wgt Acc: 99.282%
	I - Batch: 150 | Loss: 0.375 | Acc: 99.458% | Wgt Acc: 99.427%
I - num batch: 160
I - Train -- Loss: 0.375 | Acc: 99.450% | Wgt Acc: 99.425% | LR: 1.250000e-04 | Dur: 105.39s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   1.   0.   5.]
 [  1. 575.   1.   0.]
 [  1.   2. 733.   1.]
 [  2.   0.   0. 532.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.041 | Acc: 63.303% | Wgt Acc: 62.228% | Dur: 10.87s
I - Confusion Matrix: [row->prediction - col->label]
[[75. 10.  7. 30.]
 [ 3. 41. 12.  1.]
 [ 2. 22. 44.  8.]
 [ 8.  5. 12. 47.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.368 | Acc: 99.875% | Wgt Acc: 99.888%
	I - Batch: 100 | Loss: 0.372 | Acc: 99.562% | Wgt Acc: 99.564%
	I - Batch: 150 | Loss: 0.374 | Acc: 99.458% | Wgt Acc: 99.437%
I - num batch: 160
I - Train -- Loss: 0.375 | Acc: 99.372% | Wgt Acc: 99.354% | LR: 1.250000e-04 | Dur: 108.05s
I - Confusion Matrix: [row->prediction - col->label]
[[690.   2.   0.   4.]
 [  2. 576.   0.   1.]
 [  3.   0. 734.   2.]
 [  2.   0.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.001 | Acc: 61.468% | Wgt Acc: 61.073% | Dur: 10.68s
I - Confusion Matrix: [row->prediction - col->label]
[[73. 11.  8. 27.]
 [ 3. 40. 17.  2.]
 [ 0. 20. 33.  2.]
 [12.  7. 17. 55.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.384 | Acc: 99.250% | Wgt Acc: 99.155%
	I - Batch: 100 | Loss: 0.375 | Acc: 99.562% | Wgt Acc: 99.508%
	I - Batch: 150 | Loss: 0.373 | Acc: 99.583% | Wgt Acc: 99.549%
I - num batch: 160
I - Train -- Loss: 0.373 | Acc: 99.529% | Wgt Acc: 99.496% | LR: 1.250000e-04 | Dur: 104.22s
I - Confusion Matrix: [row->prediction - col->label]
[[695.   1.   1.   4.]
 [  1. 576.   0.   1.]
 [  0.   0. 733.   2.]
 [  1.   1.   0. 531.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.001 | Acc: 62.997% | Wgt Acc: 61.957% | Dur: 11.92s
I - Confusion Matrix: [row->prediction - col->label]
[[64.  6.  4. 21.]
 [ 5. 35.  9.  4.]
 [ 5. 33. 54.  8.]
 [14.  4.  8. 53.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.367 | Acc: 99.875% | Wgt Acc: 99.859%
	I - Batch: 100 | Loss: 0.369 | Acc: 99.750% | Wgt Acc: 99.732%
	I - Batch: 150 | Loss: 0.368 | Acc: 99.625% | Wgt Acc: 99.606%
I - num batch: 160
I - Train -- Loss: 0.370 | Acc: 99.607% | Wgt Acc: 99.584% | LR: 1.250000e-04 | Dur: 107.85s
I - Confusion Matrix: [row->prediction - col->label]
[[694.   2.   0.   4.]
 [  0. 576.   0.   0.]
 [  2.   0. 734.   1.]
 [  1.   0.   0. 533.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.039 | Acc: 62.080% | Wgt Acc: 59.986% | Dur: 10.96s
I - Confusion Matrix: [row->prediction - col->label]
[[78. 12.  6. 34.]
 [ 1. 33.  9.  1.]
 [ 4. 31. 54. 13.]
 [ 5.  2.  6. 38.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.397 | Acc: 98.375% | Wgt Acc: 98.400%
	I - Batch: 100 | Loss: 0.384 | Acc: 99.062% | Wgt Acc: 99.074%
	I - Batch: 150 | Loss: 0.382 | Acc: 99.167% | Wgt Acc: 99.155%
I - num batch: 160
I - Train -- Loss: 0.381 | Acc: 99.176% | Wgt Acc: 99.160% | LR: 1.250000e-04 | Dur: 104.32s
I - Confusion Matrix: [row->prediction - col->label]
[[689.   2.   1.   6.]
 [  1. 576.   1.   1.]
 [  5.   0. 732.   2.]
 [  2.   0.   0. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.044 | Acc: 62.691% | Wgt Acc: 61.753% | Dur: 12.15s
I - Confusion Matrix: [row->prediction - col->label]
[[72.  8.  6. 30.]
 [ 3. 41. 15.  0.]
 [ 1. 25. 44.  8.]
 [12.  4. 10. 48.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.368 | Acc: 99.750% | Wgt Acc: 99.747%
	I - Batch: 100 | Loss: 0.368 | Acc: 99.500% | Wgt Acc: 99.466%
	I - Batch: 150 | Loss: 0.369 | Acc: 99.417% | Wgt Acc: 99.380%
I - num batch: 160
I - Train -- Loss: 0.370 | Acc: 99.411% | Wgt Acc: 99.372% | LR: 1.250000e-04 | Dur: 107.19s
I - Confusion Matrix: [row->prediction - col->label]
[[693.   2.   0.   6.]
 [  1. 576.   0.   1.]
 [  1.   0. 734.   2.]
 [  2.   0.   0. 529.]]

I - Validation: 
I - num batch: 21
I - Val -- Loss: 1.017 | Acc: 62.691% | Wgt Acc: 61.753% | Dur: 11.56s
I - Confusion Matrix: [row->prediction - col->label]
[[67.  9.  4. 22.]
 [ 5. 38. 16.  4.]
 [ 2. 25. 49.  9.]
 [14.  6.  6. 51.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.378 | Acc: 99.750% | Wgt Acc: 99.746%
	I - Batch: 100 | Loss: 0.379 | Acc: 99.438% | Wgt Acc: 99.409%
	I - Batch: 150 | Loss: 0.377 | Acc: 99.458% | Wgt Acc: 99.427%
