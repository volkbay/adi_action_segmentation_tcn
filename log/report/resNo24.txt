Sat Oct  1 12:18:12 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.25, 0.26, 0.18, 0.24, 0.07], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 5, 'doubleClasses': [1, 2], 'loadData2memory': True, 'multiplyData': False, 'tossFirstLastFrames': True}, 'dataPath': '/data/processed/Kinetics/', 'dropoutRate': 0.5, 'epochNo': 250, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 6, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 24, 'validationAccThr': 60, 'weightDecay': 0.01}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Number of frames greater than dataset description, tossed data with #frames =  964
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  5815
I - Label distribution: [ 692.  668.  974.  718. 2763.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Tossed a data with insufficient frame number.
I - Test set length:  1392
I - Label distribution: [199. 268. 290. 204. 431.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([4083, 1060, 1725, 1844,   63, 2077, 4655, 1964, 4615, 5029, 4758, 5751,
         696, 2774,  425, 1223])
I - Initializing model TCNv6
I - Number of Model Parameters: 646479
I - Model output shape:  torch.Size([3, 16, 5, 16])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv6                                    [3, 16, 5, 16]            --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─ReLU: 2-62                        [16, 64, 32, 32]          --
│    └─Empty: 2-63                       [16, 64, 32, 32]          --
│    └─Clamp: 2-64                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-65          --                        --
│    └─One: 2-66                         [1]                       --
│    └─OutputScale: 2-67                 --                        --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64, 64, 3, 3]            --
│    └─Empty: 2-70                       [64]                      --
│    └─Empty: 2-71                       [64]                      --
│    └─BatchNorm2d: 2-72                 [16, 64, 32, 32]          --
│    └─Scaler: 2-73                      [16, 64, 32, 32]          --
│    └─ReLU: 2-74                        [16, 64, 32, 32]          --
│    └─Empty: 2-75                       [16, 64, 32, 32]          --
│    └─Clamp: 2-76                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-77                   [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─Empty: 2-79                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-80          --                        --
│    └─One: 2-81                         [1]                       --
│    └─OutputScale: 2-82                 --                        --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64, 64, 3, 3]            --
│    └─Empty: 2-85                       [64]                      --
│    └─Empty: 2-86                       [64]                      --
│    └─BatchNorm2d: 2-87                 [16, 64, 16, 16]          --
│    └─Scaler: 2-88                      [16, 64, 16, 16]          --
│    └─ReLU: 2-89                        [16, 64, 16, 16]          --
│    └─Empty: 2-90                       [16, 64, 16, 16]          --
│    └─Clamp: 2-91                       [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-93          --                        --
│    └─One: 2-94                         [1]                       --
│    └─OutputScale: 2-95                 --                        --
│    └─Empty: 2-96                       [64, 64, 3, 3]            --
│    └─Empty: 2-97                       [64, 64, 3, 3]            --
│    └─Empty: 2-98                       [64]                      --
│    └─Empty: 2-99                       [64]                      --
│    └─BatchNorm2d: 2-100                [16, 64, 16, 16]          --
│    └─Scaler: 2-101                     [16, 64, 16, 16]          --
│    └─ReLU: 2-102                       [16, 64, 16, 16]          --
│    └─Empty: 2-103                      [16, 64, 16, 16]          --
│    └─Clamp: 2-104                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-105                  [16, 64, 8, 8]            --
│    └─Empty: 2-106                      [16, 64, 8, 8]            --
│    └─Empty: 2-107                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-108         --                        --
│    └─One: 2-109                        [1]                       --
│    └─OutputScale: 2-110                --                        --
│    └─Empty: 2-111                      [64, 64, 3, 3]            --
│    └─Empty: 2-112                      [64, 64, 3, 3]            --
│    └─Empty: 2-113                      [64]                      --
│    └─Empty: 2-114                      [64]                      --
│    └─BatchNorm2d: 2-115                [16, 64, 8, 8]            --
│    └─Scaler: 2-116                     [16, 64, 8, 8]            --
│    └─ReLU: 2-117                       [16, 64, 8, 8]            --
│    └─Empty: 2-118                      [16, 64, 8, 8]            --
│    └─Clamp: 2-119                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-120         --                        --
│    └─One: 2-121                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─OutputScale: 2-123                --                        --
│    └─Empty: 2-124                      [64, 64, 1, 1]            --
│    └─Empty: 2-125                      [64, 64, 1, 1]            --
│    └─Empty: 2-126                      [64]                      --
│    └─Empty: 2-127                      [64]                      --
│    └─BatchNorm2d: 2-128                [16, 64, 8, 8]            --
│    └─Scaler: 2-129                     [16, 64, 8, 8]            --
│    └─ReLU: 2-130                       [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Clamp: 2-132                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-133                  [16, 64, 8, 8]            --
│    └─Empty: 2-134                      [16, 64, 8, 8]            --
│    └─Empty: 2-135                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-136         --                        --
│    └─One: 2-137                        [1]                       --
│    └─OutputScale: 2-138                --                        --
│    └─Empty: 2-139                      [64, 64, 3, 3]            --
│    └─Empty: 2-140                      [64, 64, 3, 3]            --
│    └─Empty: 2-141                      [64]                      --
│    └─Empty: 2-142                      [64]                      --
│    └─BatchNorm2d: 2-143                [16, 64, 8, 8]            --
│    └─Scaler: 2-144                     [16, 64, 8, 8]            --
│    └─ReLU: 2-145                       [16, 64, 8, 8]            --
│    └─Empty: 2-146                      [16, 64, 8, 8]            --
│    └─Clamp: 2-147                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-148                  [16, 64, 4, 4]            --
│    └─Empty: 2-149                      [16, 64, 4, 4]            --
│    └─Empty: 2-150                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-151         --                        --
│    └─One: 2-152                        [1]                       --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─OutputScale: 2-154                --                        --
│    └─Empty: 2-155                      [64, 64, 3, 3]            --
│    └─Empty: 2-156                      [64, 64, 3, 3]            --
│    └─Empty: 2-157                      [64]                      --
│    └─Empty: 2-158                      [64]                      --
│    └─BatchNorm2d: 2-159                [16, 64, 4, 4]            --
│    └─Scaler: 2-160                     [16, 64, 4, 4]            --
│    └─ReLU: 2-161                       [16, 64, 4, 4]            --
│    └─Empty: 2-162                      [16, 64, 4, 4]            --
│    └─Clamp: 2-163                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-164         --                        --
│    └─One: 2-165                        [1]                       --
│    └─OutputScale: 2-166                --                        --
│    └─Empty: 2-167                      [64, 64, 1, 1]            --
│    └─Empty: 2-168                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Empty: 2-170                      [64]                      --
│    └─Empty: 2-171                      [64]                      --
│    └─BatchNorm2d: 2-172                [16, 64, 4, 4]            --
│    └─Scaler: 2-173                     [16, 64, 4, 4]            --
│    └─ReLU: 2-174                       [16, 64, 4, 4]            --
│    └─Empty: 2-175                      [16, 64, 4, 4]            --
│    └─Clamp: 2-176                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-177                  [16, 64, 4, 4]            --
│    └─Empty: 2-178                      [16, 64, 4, 4]            --
│    └─Empty: 2-179                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-180         --                        --
│    └─One: 2-181                        [1]                       --
│    └─OutputScale: 2-182                --                        --
│    └─Empty: 2-183                      [64, 64, 3, 3]            --
│    └─Empty: 2-184                      [64, 64, 3, 3]            --
│    └─Empty: 2-185                      [64]                      --
│    └─Empty: 2-186                      [64]                      --
│    └─BatchNorm2d: 2-187                [16, 64, 4, 4]            --
│    └─Scaler: 2-188                     [16, 64, 4, 4]            --
│    └─ReLU: 2-189                       [16, 64, 4, 4]            --
│    └─Empty: 2-190                      [16, 64, 4, 4]            --
│    └─Clamp: 2-191                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-192                  [16, 64, 2, 2]            --
│    └─Empty: 2-193                      [16, 64, 2, 2]            --
│    └─Empty: 2-194                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-195         --                        --
│    └─One: 2-196                        [1]                       --
│    └─OutputScale: 2-197                --                        --
│    └─Empty: 2-198                      [64, 64, 1, 1]            --
│    └─Empty: 2-199                      [64, 64, 1, 1]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─Empty: 2-201                      [64]                      --
│    └─Empty: 2-202                      [64]                      --
│    └─BatchNorm2d: 2-203                [16, 64, 2, 2]            --
│    └─Scaler: 2-204                     [16, 64, 2, 2]            --
│    └─ReLU: 2-205                       [16, 64, 2, 2]            --
│    └─Empty: 2-206                      [16, 64, 2, 2]            --
│    └─Clamp: 2-207                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-208         --                        --
│    └─One: 2-209                        [1]                       --
│    └─OutputScale: 2-210                --                        --
│    └─Empty: 2-211                      [64, 64, 1, 1]            --
│    └─Empty: 2-212                      [64, 64, 1, 1]            --
│    └─Empty: 2-213                      [64]                      --
│    └─Empty: 2-214                      [64]                      --
│    └─BatchNorm2d: 2-215                [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Scaler: 2-217                     [16, 64, 2, 2]            --
│    └─ReLU: 2-218                       [16, 64, 2, 2]            --
│    └─Empty: 2-219                      [16, 64, 2, 2]            --
│    └─Clamp: 2-220                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-221                  [16, 64, 2, 2]            --
│    └─Empty: 2-222                      [16, 64, 2, 2]            --
│    └─Empty: 2-223                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-224         --                        --
│    └─One: 2-225                        [1]                       --
│    └─OutputScale: 2-226                --                        --
│    └─Empty: 2-227                      [64, 64, 3, 3]            --
│    └─Empty: 2-228                      [64, 64, 3, 3]            --
│    └─Empty: 2-229                      [64]                      --
│    └─Empty: 2-230                      [64]                      --
│    └─BatchNorm2d: 2-231                [16, 64, 2, 2]            --
│    └─Scaler: 2-232                     [16, 64, 2, 2]            --
│    └─ReLU: 2-233                       [16, 64, 2, 2]            --
│    └─Empty: 2-234                      [16, 64, 2, 2]            --
│    └─Clamp: 2-235                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-236         --                        --
│    └─One: 2-237                        [1]                       --
│    └─OutputScale: 2-238                --                        --
│    └─Empty: 2-239                      [64, 48, 1, 1]            --
│    └─Empty: 2-240                      [64, 48, 1, 1]            --
│    └─Empty: 2-241                      [64]                      --
│    └─Empty: 2-242                      [64]                      --
│    └─BatchNorm2d: 2-243                [16, 64, 64, 64]          --
│    └─Scaler: 2-244                     [16, 64, 64, 64]          --
│    └─ReLU: 2-245                       [16, 64, 64, 64]          --
│    └─Empty: 2-246                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1            --                        --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1                   --                        --
│    └─Clamp: 2-248                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-249         --                        --
│    └─One: 2-250                        [1]                       --
│    └─OutputScale: 2-251                --                        --
│    └─Empty: 2-252                      [64, 64, 3, 3]            --
│    └─Empty: 2-253                      [64, 64, 3, 3]            --
│    └─Empty: 2-254                      [64]                      --
│    └─Empty: 2-255                      [64]                      --
│    └─BatchNorm2d: 2-256                [16, 64, 64, 64]          --
│    └─Scaler: 2-257                     [16, 64, 64, 64]          --
│    └─ReLU: 2-258                       [16, 64, 64, 64]          --
│    └─Empty: 2-259                      [16, 64, 64, 64]          --
│    └─Clamp: 2-260                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-261         --                        --
│    └─One: 2-262                        [1]                       --
│    └─OutputScale: 2-263                --                        --
│    └─Empty: 2-264                      [64, 64, 1, 1]            --
│    └─Empty: 2-265                      [64, 64, 1, 1]            --
│    └─Empty: 2-266                      [64]                      --
│    └─Empty: 2-267                      [64]                      --
│    └─BatchNorm2d: 2-268                [16, 64, 64, 64]          --
│    └─Scaler: 2-269                     [16, 64, 64, 64]          --
│    └─ReLU: 2-270                       [16, 64, 64, 64]          --
│    └─Empty: 2-271                      [16, 64, 64, 64]          --
│    └─Clamp: 2-272                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-273         --                        --
│    └─One: 2-274                        [1]                       --
│    └─OutputScale: 2-275                --                        --
│    └─Empty: 2-276                      [64, 64, 3, 3]            --
│    └─Empty: 2-277                      [64, 64, 3, 3]            --
│    └─Empty: 2-278                      [64]                      --
│    └─Empty: 2-279                      [64]                      --
│    └─BatchNorm2d: 2-280                [16, 64, 64, 64]          --
│    └─Scaler: 2-281                     [16, 64, 64, 64]          --
│    └─ReLU: 2-282                       [16, 64, 64, 64]          --
│    └─Empty: 2-283                      [16, 64, 64, 64]          --
│    └─Clamp: 2-284                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-285                  [16, 64, 32, 32]          --
│    └─Empty: 2-286                      [16, 64, 32, 32]          --
│    └─Empty: 2-287                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-288         --                        --
│    └─One: 2-289                        [1]                       --
│    └─OutputScale: 2-290                --                        --
│    └─Empty: 2-291                      [64, 64, 3, 3]            --
│    └─Empty: 2-292                      [64, 64, 3, 3]            --
│    └─Empty: 2-293                      [64]                      --
│    └─Empty: 2-294                      [64]                      --
│    └─BatchNorm2d: 2-295                [16, 64, 32, 32]          --
│    └─Scaler: 2-296                     [16, 64, 32, 32]          --
│    └─ReLU: 2-297                       [16, 64, 32, 32]          --
│    └─Empty: 2-298                      [16, 64, 32, 32]          --
│    └─Clamp: 2-299                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-300         --                        --
│    └─One: 2-301                        [1]                       --
│    └─OutputScale: 2-302                --                        --
│    └─Empty: 2-303                      [64, 64, 3, 3]            --
│    └─Empty: 2-304                      [64, 64, 3, 3]            --
│    └─Empty: 2-305                      [64]                      --
│    └─Empty: 2-306                      [64]                      --
│    └─BatchNorm2d: 2-307                [16, 64, 32, 32]          --
│    └─Scaler: 2-308                     [16, 64, 32, 32]          --
│    └─ReLU: 2-309                       [16, 64, 32, 32]          --
│    └─Empty: 2-310                      [16, 64, 32, 32]          --
│    └─Clamp: 2-311                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-312                  [16, 64, 16, 16]          --
│    └─Empty: 2-313                      [16, 64, 16, 16]          --
│    └─Empty: 2-314                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-315         --                        --
│    └─One: 2-316                        [1]                       --
│    └─OutputScale: 2-317                --                        --
│    └─Empty: 2-318                      [64, 64, 3, 3]            --
│    └─Empty: 2-319                      [64, 64, 3, 3]            --
│    └─Empty: 2-320                      [64]                      --
│    └─Empty: 2-321                      [64]                      --
│    └─BatchNorm2d: 2-322                [16, 64, 16, 16]          --
│    └─Scaler: 2-323                     [16, 64, 16, 16]          --
│    └─ReLU: 2-324                       [16, 64, 16, 16]          --
│    └─Empty: 2-325                      [16, 64, 16, 16]          --
│    └─Clamp: 2-326                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-327         --                        --
│    └─One: 2-328                        [1]                       --
│    └─OutputScale: 2-329                --                        --
│    └─Empty: 2-330                      [64, 64, 3, 3]            --
│    └─Empty: 2-331                      [64, 64, 3, 3]            --
│    └─Empty: 2-332                      [64]                      --
│    └─Empty: 2-333                      [64]                      --
│    └─BatchNorm2d: 2-334                [16, 64, 16, 16]          --
│    └─Scaler: 2-335                     [16, 64, 16, 16]          --
│    └─ReLU: 2-336                       [16, 64, 16, 16]          --
│    └─Empty: 2-337                      [16, 64, 16, 16]          --
│    └─Clamp: 2-338                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-339                  [16, 64, 8, 8]            --
│    └─Empty: 2-340                      [16, 64, 8, 8]            --
│    └─Empty: 2-341                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-342         --                        --
│    └─One: 2-343                        [1]                       --
│    └─OutputScale: 2-344                --                        --
│    └─Empty: 2-345                      [64, 64, 3, 3]            --
│    └─Empty: 2-346                      [64, 64, 3, 3]            --
│    └─Empty: 2-347                      [64]                      --
│    └─Empty: 2-348                      [64]                      --
│    └─BatchNorm2d: 2-349                [16, 64, 8, 8]            --
│    └─Scaler: 2-350                     [16, 64, 8, 8]            --
│    └─ReLU: 2-351                       [16, 64, 8, 8]            --
│    └─Empty: 2-352                      [16, 64, 8, 8]            --
│    └─Clamp: 2-353                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-354         --                        --
│    └─One: 2-355                        [1]                       --
│    └─OutputScale: 2-356                --                        --
│    └─Empty: 2-357                      [64, 64, 1, 1]            --
│    └─Empty: 2-358                      [64, 64, 1, 1]            --
│    └─Empty: 2-359                      [64]                      --
│    └─Empty: 2-360                      [64]                      --
│    └─BatchNorm2d: 2-361                [16, 64, 8, 8]            --
│    └─Scaler: 2-362                     [16, 64, 8, 8]            --
│    └─ReLU: 2-363                       [16, 64, 8, 8]            --
│    └─Empty: 2-364                      [16, 64, 8, 8]            --
│    └─Clamp: 2-365                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-366                  [16, 64, 8, 8]            --
│    └─Empty: 2-367                      [16, 64, 8, 8]            --
│    └─Empty: 2-368                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-369         --                        --
│    └─One: 2-370                        [1]                       --
│    └─OutputScale: 2-371                --                        --
│    └─Empty: 2-372                      [64, 64, 3, 3]            --
│    └─Empty: 2-373                      [64, 64, 3, 3]            --
│    └─Empty: 2-374                      [64]                      --
│    └─Empty: 2-375                      [64]                      --
│    └─BatchNorm2d: 2-376                [16, 64, 8, 8]            --
│    └─Scaler: 2-377                     [16, 64, 8, 8]            --
│    └─ReLU: 2-378                       [16, 64, 8, 8]            --
│    └─Empty: 2-379                      [16, 64, 8, 8]            --
│    └─Clamp: 2-380                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-381                  [16, 64, 4, 4]            --
│    └─Empty: 2-382                      [16, 64, 4, 4]            --
│    └─Empty: 2-383                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-384         --                        --
│    └─One: 2-385                        [1]                       --
│    └─OutputScale: 2-386                --                        --
│    └─Empty: 2-387                      [64, 64, 3, 3]            --
│    └─Empty: 2-388                      [64, 64, 3, 3]            --
│    └─Empty: 2-389                      [64]                      --
│    └─Empty: 2-390                      [64]                      --
│    └─BatchNorm2d: 2-391                [16, 64, 4, 4]            --
│    └─Scaler: 2-392                     [16, 64, 4, 4]            --
│    └─ReLU: 2-393                       [16, 64, 4, 4]            --
│    └─Empty: 2-394                      [16, 64, 4, 4]            --
│    └─Clamp: 2-395                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-396         --                        --
│    └─One: 2-397                        [1]                       --
│    └─OutputScale: 2-398                --                        --
│    └─Empty: 2-399                      [64, 64, 1, 1]            --
│    └─Empty: 2-400                      [64, 64, 1, 1]            --
│    └─Empty: 2-401                      [64]                      --
│    └─Empty: 2-402                      [64]                      --
│    └─BatchNorm2d: 2-403                [16, 64, 4, 4]            --
│    └─Scaler: 2-404                     [16, 64, 4, 4]            --
│    └─ReLU: 2-405                       [16, 64, 4, 4]            --
│    └─Empty: 2-406                      [16, 64, 4, 4]            --
│    └─Clamp: 2-407                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-408                  [16, 64, 4, 4]            --
│    └─Empty: 2-409                      [16, 64, 4, 4]            --
│    └─Empty: 2-410                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-411         --                        --
│    └─One: 2-412                        [1]                       --
│    └─OutputScale: 2-413                --                        --
│    └─Empty: 2-414                      [64, 64, 3, 3]            --
│    └─Empty: 2-415                      [64, 64, 3, 3]            --
│    └─Empty: 2-416                      [64]                      --
│    └─Empty: 2-417                      [64]                      --
│    └─BatchNorm2d: 2-418                [16, 64, 4, 4]            --
│    └─Scaler: 2-419                     [16, 64, 4, 4]            --
│    └─ReLU: 2-420                       [16, 64, 4, 4]            --
│    └─Empty: 2-421                      [16, 64, 4, 4]            --
│    └─Clamp: 2-422                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-423                  [16, 64, 2, 2]            --
│    └─Empty: 2-424                      [16, 64, 2, 2]            --
│    └─Empty: 2-425                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-426         --                        --
│    └─One: 2-427                        [1]                       --
│    └─OutputScale: 2-428                --                        --
│    └─Empty: 2-429                      [64, 64, 1, 1]            --
│    └─Empty: 2-430                      [64, 64, 1, 1]            --
│    └─Empty: 2-431                      [64]                      --
│    └─Empty: 2-432                      [64]                      --
│    └─BatchNorm2d: 2-433                [16, 64, 2, 2]            --
│    └─Scaler: 2-434                     [16, 64, 2, 2]            --
│    └─ReLU: 2-435                       [16, 64, 2, 2]            --
│    └─Empty: 2-436                      [16, 64, 2, 2]            --
│    └─Clamp: 2-437                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-438         --                        --
│    └─One: 2-439                        [1]                       --
│    └─OutputScale: 2-440                --                        --
│    └─Empty: 2-441                      [64, 64, 1, 1]            --
│    └─Empty: 2-442                      [64, 64, 1, 1]            --
│    └─Empty: 2-443                      [64]                      --
│    └─Empty: 2-444                      [64]                      --
│    └─BatchNorm2d: 2-445                [16, 64, 2, 2]            --
│    └─Scaler: 2-446                     [16, 64, 2, 2]            --
│    └─ReLU: 2-447                       [16, 64, 2, 2]            --
│    └─Empty: 2-448                      [16, 64, 2, 2]            --
│    └─Clamp: 2-449                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-450                  [16, 64, 2, 2]            --
│    └─Empty: 2-451                      [16, 64, 2, 2]            --
│    └─Empty: 2-452                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-453         --                        --
│    └─One: 2-454                        [1]                       --
│    └─OutputScale: 2-455                --                        --
│    └─Empty: 2-456                      [64, 64, 3, 3]            --
│    └─Empty: 2-457                      [64, 64, 3, 3]            --
│    └─Empty: 2-458                      [64]                      --
│    └─Empty: 2-459                      [64]                      --
│    └─BatchNorm2d: 2-460                [16, 64, 2, 2]            --
│    └─Scaler: 2-461                     [16, 64, 2, 2]            --
│    └─ReLU: 2-462                       [16, 64, 2, 2]            --
│    └─Empty: 2-463                      [16, 64, 2, 2]            --
│    └─Clamp: 2-464                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-465         --                        --
│    └─One: 2-466                        [1]                       --
│    └─OutputScale: 2-467                --                        --
│    └─Empty: 2-468                      [64, 48, 1, 1]            --
│    └─Empty: 2-469                      [64, 48, 1, 1]            --
│    └─Empty: 2-470                      [64]                      --
│    └─Empty: 2-471                      [64]                      --
│    └─BatchNorm2d: 2-472                [16, 64, 64, 64]          --
│    └─Scaler: 2-473                     [16, 64, 64, 64]          --
│    └─ReLU: 2-474                       [16, 64, 64, 64]          --
│    └─Empty: 2-475                      [16, 64, 64, 64]          --
│    └─Clamp: 2-476                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-477         --                        --
│    └─One: 2-478                        [1]                       --
│    └─OutputScale: 2-479                --                        --
│    └─Empty: 2-480                      [64, 64, 3, 3]            --
│    └─Empty: 2-481                      [64, 64, 3, 3]            --
│    └─Empty: 2-482                      [64]                      --
│    └─Empty: 2-483                      [64]                      --
│    └─BatchNorm2d: 2-484                [16, 64, 64, 64]          --
│    └─Scaler: 2-485                     [16, 64, 64, 64]          --
│    └─ReLU: 2-486                       [16, 64, 64, 64]          --
│    └─Empty: 2-487                      [16, 64, 64, 64]          --
│    └─Clamp: 2-488                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-489         --                        --
│    └─One: 2-490                        [1]                       --
│    └─OutputScale: 2-491                --                        --
│    └─Empty: 2-492                      [64, 64, 1, 1]            --
│    └─Empty: 2-493                      [64, 64, 1, 1]            --
│    └─Empty: 2-494                      [64]                      --
│    └─Empty: 2-495                      [64]                      --
│    └─BatchNorm2d: 2-496                [16, 64, 64, 64]          --
│    └─Scaler: 2-497                     [16, 64, 64, 64]          --
│    └─ReLU: 2-498                       [16, 64, 64, 64]          --
│    └─Empty: 2-499                      [16, 64, 64, 64]          --
│    └─Clamp: 2-500                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-501         --                        --
│    └─One: 2-502                        [1]                       --
│    └─OutputScale: 2-503                --                        --
│    └─Empty: 2-504                      [64, 64, 3, 3]            --
│    └─Empty: 2-505                      [64, 64, 3, 3]            --
│    └─Empty: 2-506                      [64]                      --
│    └─Empty: 2-507                      [64]                      --
│    └─BatchNorm2d: 2-508                [16, 64, 64, 64]          --
│    └─Scaler: 2-509                     [16, 64, 64, 64]          --
│    └─ReLU: 2-510                       [16, 64, 64, 64]          --
│    └─Empty: 2-511                      [16, 64, 64, 64]          --
│    └─Clamp: 2-512                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-513                  [16, 64, 32, 32]          --
│    └─Empty: 2-514                      [16, 64, 32, 32]          --
│    └─Empty: 2-515                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-516         --                        --
│    └─One: 2-517                        [1]                       --
│    └─OutputScale: 2-518                --                        --
│    └─Empty: 2-519                      [64, 64, 3, 3]            --
│    └─Empty: 2-520                      [64, 64, 3, 3]            --
│    └─Empty: 2-521                      [64]                      --
│    └─Empty: 2-522                      [64]                      --
│    └─BatchNorm2d: 2-523                [16, 64, 32, 32]          --
│    └─Scaler: 2-524                     [16, 64, 32, 32]          --
│    └─ReLU: 2-525                       [16, 64, 32, 32]          --
│    └─Empty: 2-526                      [16, 64, 32, 32]          --
│    └─Clamp: 2-527                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-528         --                        --
│    └─One: 2-529                        [1]                       --
│    └─OutputScale: 2-530                --                        --
│    └─Empty: 2-531                      [64, 64, 3, 3]            --
│    └─Empty: 2-532                      [64, 64, 3, 3]            --
│    └─Empty: 2-533                      [64]                      --
│    └─Empty: 2-534                      [64]                      --
│    └─BatchNorm2d: 2-535                [16, 64, 32, 32]          --
│    └─Scaler: 2-536                     [16, 64, 32, 32]          --
│    └─ReLU: 2-537                       [16, 64, 32, 32]          --
│    └─Empty: 2-538                      [16, 64, 32, 32]          --
│    └─Clamp: 2-539                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-540                  [16, 64, 16, 16]          --
│    └─Empty: 2-541                      [16, 64, 16, 16]          --
│    └─Empty: 2-542                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-543         --                        --
│    └─One: 2-544                        [1]                       --
│    └─OutputScale: 2-545                --                        --
│    └─Empty: 2-546                      [64, 64, 3, 3]            --
│    └─Empty: 2-547                      [64, 64, 3, 3]            --
│    └─Empty: 2-548                      [64]                      --
│    └─Empty: 2-549                      [64]                      --
│    └─BatchNorm2d: 2-550                [16, 64, 16, 16]          --
│    └─Scaler: 2-551                     [16, 64, 16, 16]          --
│    └─ReLU: 2-552                       [16, 64, 16, 16]          --
│    └─Empty: 2-553                      [16, 64, 16, 16]          --
│    └─Clamp: 2-554                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-555         --                        --
│    └─One: 2-556                        [1]                       --
│    └─OutputScale: 2-557                --                        --
│    └─Empty: 2-558                      [64, 64, 3, 3]            --
│    └─Empty: 2-559                      [64, 64, 3, 3]            --
│    └─Empty: 2-560                      [64]                      --
│    └─Empty: 2-561                      [64]                      --
│    └─BatchNorm2d: 2-562                [16, 64, 16, 16]          --
│    └─Scaler: 2-563                     [16, 64, 16, 16]          --
│    └─ReLU: 2-564                       [16, 64, 16, 16]          --
│    └─Empty: 2-565                      [16, 64, 16, 16]          --
│    └─Clamp: 2-566                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-567                  [16, 64, 8, 8]            --
│    └─Empty: 2-568                      [16, 64, 8, 8]            --
│    └─Empty: 2-569                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-570         --                        --
│    └─One: 2-571                        [1]                       --
│    └─OutputScale: 2-572                --                        --
│    └─Empty: 2-573                      [64, 64, 3, 3]            --
│    └─Empty: 2-574                      [64, 64, 3, 3]            --
│    └─Empty: 2-575                      [64]                      --
│    └─Empty: 2-576                      [64]                      --
│    └─BatchNorm2d: 2-577                [16, 64, 8, 8]            --
│    └─Scaler: 2-578                     [16, 64, 8, 8]            --
│    └─ReLU: 2-579                       [16, 64, 8, 8]            --
│    └─Empty: 2-580                      [16, 64, 8, 8]            --
│    └─Clamp: 2-581                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-582         --                        --
│    └─One: 2-583                        [1]                       --
│    └─OutputScale: 2-584                --                        --
│    └─Empty: 2-585                      [64, 64, 1, 1]            --
│    └─Empty: 2-586                      [64, 64, 1, 1]            --
│    └─Empty: 2-587                      [64]                      --
│    └─Empty: 2-588                      [64]                      --
│    └─BatchNorm2d: 2-589                [16, 64, 8, 8]            --
│    └─Scaler: 2-590                     [16, 64, 8, 8]            --
│    └─ReLU: 2-591                       [16, 64, 8, 8]            --
│    └─Empty: 2-592                      [16, 64, 8, 8]            --
│    └─Clamp: 2-593                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-594                  [16, 64, 8, 8]            --
│    └─Empty: 2-595                      [16, 64, 8, 8]            --
│    └─Empty: 2-596                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-597         --                        --
│    └─One: 2-598                        [1]                       --
│    └─OutputScale: 2-599                --                        --
│    └─Empty: 2-600                      [64, 64, 3, 3]            --
│    └─Empty: 2-601                      [64, 64, 3, 3]            --
│    └─Empty: 2-602                      [64]                      --
│    └─Empty: 2-603                      [64]                      --
│    └─BatchNorm2d: 2-604                [16, 64, 8, 8]            --
│    └─Scaler: 2-605                     [16, 64, 8, 8]            --
│    └─ReLU: 2-606                       [16, 64, 8, 8]            --
│    └─Empty: 2-607                      [16, 64, 8, 8]            --
│    └─Clamp: 2-608                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-609                  [16, 64, 4, 4]            --
│    └─Empty: 2-610                      [16, 64, 4, 4]            --
│    └─Empty: 2-611                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-612         --                        --
│    └─One: 2-613                        [1]                       --
│    └─OutputScale: 2-614                --                        --
│    └─Empty: 2-615                      [64, 64, 3, 3]            --
│    └─Empty: 2-616                      [64, 64, 3, 3]            --
│    └─Empty: 2-617                      [64]                      --
│    └─Empty: 2-618                      [64]                      --
│    └─BatchNorm2d: 2-619                [16, 64, 4, 4]            --
│    └─Scaler: 2-620                     [16, 64, 4, 4]            --
│    └─ReLU: 2-621                       [16, 64, 4, 4]            --
│    └─Empty: 2-622                      [16, 64, 4, 4]            --
│    └─Clamp: 2-623                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-624         --                        --
│    └─One: 2-625                        [1]                       --
│    └─OutputScale: 2-626                --                        --
│    └─Empty: 2-627                      [64, 64, 1, 1]            --
│    └─Empty: 2-628                      [64, 64, 1, 1]            --
│    └─Empty: 2-629                      [64]                      --
│    └─Empty: 2-630                      [64]                      --
│    └─BatchNorm2d: 2-631                [16, 64, 4, 4]            --
│    └─Scaler: 2-632                     [16, 64, 4, 4]            --
│    └─ReLU: 2-633                       [16, 64, 4, 4]            --
│    └─Empty: 2-634                      [16, 64, 4, 4]            --
│    └─Clamp: 2-635                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-636                  [16, 64, 4, 4]            --
│    └─Empty: 2-637                      [16, 64, 4, 4]            --
│    └─Empty: 2-638                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-639         --                        --
│    └─One: 2-640                        [1]                       --
│    └─OutputScale: 2-641                --                        --
│    └─Empty: 2-642                      [64, 64, 3, 3]            --
│    └─Empty: 2-643                      [64, 64, 3, 3]            --
│    └─Empty: 2-644                      [64]                      --
│    └─Empty: 2-645                      [64]                      --
│    └─BatchNorm2d: 2-646                [16, 64, 4, 4]            --
│    └─Scaler: 2-647                     [16, 64, 4, 4]            --
│    └─ReLU: 2-648                       [16, 64, 4, 4]            --
│    └─Empty: 2-649                      [16, 64, 4, 4]            --
│    └─Clamp: 2-650                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-651                  [16, 64, 2, 2]            --
│    └─Empty: 2-652                      [16, 64, 2, 2]            --
│    └─Empty: 2-653                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-654         --                        --
│    └─One: 2-655                        [1]                       --
│    └─OutputScale: 2-656                --                        --
│    └─Empty: 2-657                      [64, 64, 1, 1]            --
│    └─Empty: 2-658                      [64, 64, 1, 1]            --
│    └─Empty: 2-659                      [64]                      --
│    └─Empty: 2-660                      [64]                      --
│    └─BatchNorm2d: 2-661                [16, 64, 2, 2]            --
│    └─Scaler: 2-662                     [16, 64, 2, 2]            --
│    └─ReLU: 2-663                       [16, 64, 2, 2]            --
│    └─Empty: 2-664                      [16, 64, 2, 2]            --
│    └─Clamp: 2-665                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-666         --                        --
│    └─One: 2-667                        [1]                       --
│    └─OutputScale: 2-668                --                        --
│    └─Empty: 2-669                      [64, 64, 1, 1]            --
│    └─Empty: 2-670                      [64, 64, 1, 1]            --
│    └─Empty: 2-671                      [64]                      --
│    └─Empty: 2-672                      [64]                      --
│    └─BatchNorm2d: 2-673                [16, 64, 2, 2]            --
│    └─Scaler: 2-674                     [16, 64, 2, 2]            --
│    └─ReLU: 2-675                       [16, 64, 2, 2]            --
│    └─Empty: 2-676                      [16, 64, 2, 2]            --
│    └─Clamp: 2-677                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-678                  [16, 64, 2, 2]            --
│    └─Empty: 2-679                      [16, 64, 2, 2]            --
│    └─Empty: 2-680                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-681         --                        --
│    └─One: 2-682                        [1]                       --
│    └─OutputScale: 2-683                --                        --
│    └─Empty: 2-684                      [64, 64, 3, 3]            --
│    └─Empty: 2-685                      [64, 64, 3, 3]            --
│    └─Empty: 2-686                      [64]                      --
│    └─Empty: 2-687                      [64]                      --
│    └─BatchNorm2d: 2-688                [16, 64, 2, 2]            --
│    └─Scaler: 2-689                     [16, 64, 2, 2]            --
│    └─ReLU: 2-690                       [16, 64, 2, 2]            --
│    └─Empty: 2-691                      [16, 64, 2, 2]            --
│    └─Clamp: 2-692                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-693         --                        --
│    └─One: 2-694                        [1]                       --
│    └─OutputScale: 2-695                --                        --
│    └─Empty: 2-696                      [64, 48, 1, 1]            --
│    └─Empty: 2-697                      [64, 48, 1, 1]            --
│    └─Empty: 2-698                      [64]                      --
│    └─Empty: 2-699                      [64]                      --
│    └─BatchNorm2d: 2-700                [16, 64, 64, 64]          --
│    └─Scaler: 2-701                     [16, 64, 64, 64]          --
│    └─ReLU: 2-702                       [16, 64, 64, 64]          --
│    └─Empty: 2-703                      [16, 64, 64, 64]          --
│    └─Clamp: 2-704                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-705         --                        --
│    └─One: 2-706                        [1]                       --
│    └─OutputScale: 2-707                --                        --
│    └─Empty: 2-708                      [64, 64, 3, 3]            --
│    └─Empty: 2-709                      [64, 64, 3, 3]            --
│    └─Empty: 2-710                      [64]                      --
│    └─Empty: 2-711                      [64]                      --
│    └─BatchNorm2d: 2-712                [16, 64, 64, 64]          --
│    └─Scaler: 2-713                     [16, 64, 64, 64]          --
│    └─ReLU: 2-714                       [16, 64, 64, 64]          --
│    └─Empty: 2-715                      [16, 64, 64, 64]          --
│    └─Clamp: 2-716                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-717         --                        --
│    └─One: 2-718                        [1]                       --
│    └─OutputScale: 2-719                --                        --
│    └─Empty: 2-720                      [64, 64, 1, 1]            --
│    └─Empty: 2-721                      [64, 64, 1, 1]            --
│    └─Empty: 2-722                      [64]                      --
│    └─Empty: 2-723                      [64]                      --
│    └─BatchNorm2d: 2-724                [16, 64, 64, 64]          --
│    └─Scaler: 2-725                     [16, 64, 64, 64]          --
│    └─ReLU: 2-726                       [16, 64, 64, 64]          --
│    └─Empty: 2-727                      [16, 64, 64, 64]          --
│    └─Clamp: 2-728                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-729         --                        --
│    └─One: 2-730                        [1]                       --
│    └─OutputScale: 2-731                --                        --
│    └─Empty: 2-732                      [64, 64, 3, 3]            --
│    └─Empty: 2-733                      [64, 64, 3, 3]            --
│    └─Empty: 2-734                      [64]                      --
│    └─Empty: 2-735                      [64]                      --
│    └─BatchNorm2d: 2-736                [16, 64, 64, 64]          --
│    └─Scaler: 2-737                     [16, 64, 64, 64]          --
│    └─ReLU: 2-738                       [16, 64, 64, 64]          --
│    └─Empty: 2-739                      [16, 64, 64, 64]          --
│    └─Clamp: 2-740                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-741                  [16, 64, 32, 32]          --
│    └─Empty: 2-742                      [16, 64, 32, 32]          --
│    └─Empty: 2-743                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-744         --                        --
│    └─One: 2-745                        [1]                       --
│    └─OutputScale: 2-746                --                        --
│    └─Empty: 2-747                      [64, 64, 3, 3]            --
│    └─Empty: 2-748                      [64, 64, 3, 3]            --
│    └─Empty: 2-749                      [64]                      --
│    └─Empty: 2-750                      [64]                      --
│    └─BatchNorm2d: 2-751                [16, 64, 32, 32]          --
│    └─Scaler: 2-752                     [16, 64, 32, 32]          --
│    └─ReLU: 2-753                       [16, 64, 32, 32]          --
│    └─Empty: 2-754                      [16, 64, 32, 32]          --
│    └─Clamp: 2-755                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-756         --                        --
│    └─One: 2-757                        [1]                       --
│    └─OutputScale: 2-758                --                        --
│    └─Empty: 2-759                      [64, 64, 3, 3]            --
│    └─Empty: 2-760                      [64, 64, 3, 3]            --
│    └─Empty: 2-761                      [64]                      --
│    └─Empty: 2-762                      [64]                      --
│    └─BatchNorm2d: 2-763                [16, 64, 32, 32]          --
│    └─Scaler: 2-764                     [16, 64, 32, 32]          --
│    └─ReLU: 2-765                       [16, 64, 32, 32]          --
│    └─Empty: 2-766                      [16, 64, 32, 32]          --
│    └─Clamp: 2-767                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-768                  [16, 64, 16, 16]          --
│    └─Empty: 2-769                      [16, 64, 16, 16]          --
│    └─Empty: 2-770                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-771         --                        --
│    └─One: 2-772                        [1]                       --
│    └─OutputScale: 2-773                --                        --
│    └─Empty: 2-774                      [64, 64, 3, 3]            --
│    └─Empty: 2-775                      [64, 64, 3, 3]            --
│    └─Empty: 2-776                      [64]                      --
│    └─Empty: 2-777                      [64]                      --
│    └─BatchNorm2d: 2-778                [16, 64, 16, 16]          --
│    └─Scaler: 2-779                     [16, 64, 16, 16]          --
│    └─ReLU: 2-780                       [16, 64, 16, 16]          --
│    └─Empty: 2-781                      [16, 64, 16, 16]          --
│    └─Clamp: 2-782                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-783         --                        --
│    └─One: 2-784                        [1]                       --
│    └─OutputScale: 2-785                --                        --
│    └─Empty: 2-786                      [64, 64, 3, 3]            --
│    └─Empty: 2-787                      [64, 64, 3, 3]            --
│    └─Empty: 2-788                      [64]                      --
│    └─Empty: 2-789                      [64]                      --
│    └─BatchNorm2d: 2-790                [16, 64, 16, 16]          --
│    └─Scaler: 2-791                     [16, 64, 16, 16]          --
│    └─ReLU: 2-792                       [16, 64, 16, 16]          --
│    └─Empty: 2-793                      [16, 64, 16, 16]          --
│    └─Clamp: 2-794                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-795                  [16, 64, 8, 8]            --
│    └─Empty: 2-796                      [16, 64, 8, 8]            --
│    └─Empty: 2-797                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-798         --                        --
│    └─One: 2-799                        [1]                       --
│    └─OutputScale: 2-800                --                        --
│    └─Empty: 2-801                      [64, 64, 3, 3]            --
│    └─Empty: 2-802                      [64, 64, 3, 3]            --
│    └─Empty: 2-803                      [64]                      --
│    └─Empty: 2-804                      [64]                      --
│    └─BatchNorm2d: 2-805                [16, 64, 8, 8]            --
│    └─Scaler: 2-806                     [16, 64, 8, 8]            --
│    └─ReLU: 2-807                       [16, 64, 8, 8]            --
│    └─Empty: 2-808                      [16, 64, 8, 8]            --
│    └─Clamp: 2-809                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-810         --                        --
│    └─One: 2-811                        [1]                       --
│    └─OutputScale: 2-812                --                        --
│    └─Empty: 2-813                      [64, 64, 1, 1]            --
│    └─Empty: 2-814                      [64, 64, 1, 1]            --
│    └─Empty: 2-815                      [64]                      --
│    └─Empty: 2-816                      [64]                      --
│    └─BatchNorm2d: 2-817                [16, 64, 8, 8]            --
│    └─Scaler: 2-818                     [16, 64, 8, 8]            --
│    └─ReLU: 2-819                       [16, 64, 8, 8]            --
│    └─Empty: 2-820                      [16, 64, 8, 8]            --
│    └─Clamp: 2-821                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-822                  [16, 64, 8, 8]            --
│    └─Empty: 2-823                      [16, 64, 8, 8]            --
│    └─Empty: 2-824                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-825         --                        --
│    └─One: 2-826                        [1]                       --
│    └─OutputScale: 2-827                --                        --
│    └─Empty: 2-828                      [64, 64, 3, 3]            --
│    └─Empty: 2-829                      [64, 64, 3, 3]            --
│    └─Empty: 2-830                      [64]                      --
│    └─Empty: 2-831                      [64]                      --
│    └─BatchNorm2d: 2-832                [16, 64, 8, 8]            --
│    └─Scaler: 2-833                     [16, 64, 8, 8]            --
│    └─ReLU: 2-834                       [16, 64, 8, 8]            --
│    └─Empty: 2-835                      [16, 64, 8, 8]            --
│    └─Clamp: 2-836                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-837                  [16, 64, 4, 4]            --
│    └─Empty: 2-838                      [16, 64, 4, 4]            --
│    └─Empty: 2-839                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-840         --                        --
│    └─One: 2-841                        [1]                       --
│    └─OutputScale: 2-842                --                        --
│    └─Empty: 2-843                      [64, 64, 3, 3]            --
│    └─Empty: 2-844                      [64, 64, 3, 3]            --
│    └─Empty: 2-845                      [64]                      --
│    └─Empty: 2-846                      [64]                      --
│    └─BatchNorm2d: 2-847                [16, 64, 4, 4]            --
│    └─Scaler: 2-848                     [16, 64, 4, 4]            --
│    └─ReLU: 2-849                       [16, 64, 4, 4]            --
│    └─Empty: 2-850                      [16, 64, 4, 4]            --
│    └─Clamp: 2-851                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-852         --                        --
│    └─One: 2-853                        [1]                       --
│    └─OutputScale: 2-854                --                        --
│    └─Empty: 2-855                      [64, 64, 1, 1]            --
│    └─Empty: 2-856                      [64, 64, 1, 1]            --
│    └─Empty: 2-857                      [64]                      --
│    └─Empty: 2-858                      [64]                      --
│    └─BatchNorm2d: 2-859                [16, 64, 4, 4]            --
│    └─Scaler: 2-860                     [16, 64, 4, 4]            --
│    └─ReLU: 2-861                       [16, 64, 4, 4]            --
│    └─Empty: 2-862                      [16, 64, 4, 4]            --
│    └─Clamp: 2-863                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-864                  [16, 64, 4, 4]            --
│    └─Empty: 2-865                      [16, 64, 4, 4]            --
│    └─Empty: 2-866                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-867         --                        --
│    └─One: 2-868                        [1]                       --
│    └─OutputScale: 2-869                --                        --
│    └─Empty: 2-870                      [64, 64, 3, 3]            --
│    └─Empty: 2-871                      [64, 64, 3, 3]            --
│    └─Empty: 2-872                      [64]                      --
│    └─Empty: 2-873                      [64]                      --
│    └─BatchNorm2d: 2-874                [16, 64, 4, 4]            --
│    └─Scaler: 2-875                     [16, 64, 4, 4]            --
│    └─ReLU: 2-876                       [16, 64, 4, 4]            --
│    └─Empty: 2-877                      [16, 64, 4, 4]            --
│    └─Clamp: 2-878                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-879                  [16, 64, 2, 2]            --
│    └─Empty: 2-880                      [16, 64, 2, 2]            --
│    └─Empty: 2-881                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-882         --                        --
│    └─One: 2-883                        [1]                       --
│    └─OutputScale: 2-884                --                        --
│    └─Empty: 2-885                      [64, 64, 1, 1]            --
│    └─Empty: 2-886                      [64, 64, 1, 1]            --
│    └─Empty: 2-887                      [64]                      --
│    └─Empty: 2-888                      [64]                      --
│    └─BatchNorm2d: 2-889                [16, 64, 2, 2]            --
│    └─Scaler: 2-890                     [16, 64, 2, 2]            --
│    └─ReLU: 2-891                       [16, 64, 2, 2]            --
│    └─Empty: 2-892                      [16, 64, 2, 2]            --
│    └─Clamp: 2-893                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-894         --                        --
│    └─One: 2-895                        [1]                       --
│    └─OutputScale: 2-896                --                        --
│    └─Empty: 2-897                      [64, 64, 1, 1]            --
│    └─Empty: 2-898                      [64, 64, 1, 1]            --
│    └─Empty: 2-899                      [64]                      --
│    └─Empty: 2-900                      [64]                      --
│    └─BatchNorm2d: 2-901                [16, 64, 2, 2]            --
│    └─Scaler: 2-902                     [16, 64, 2, 2]            --
│    └─ReLU: 2-903                       [16, 64, 2, 2]            --
│    └─Empty: 2-904                      [16, 64, 2, 2]            --
│    └─Clamp: 2-905                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-906                  [16, 64, 2, 2]            --
│    └─Empty: 2-907                      [16, 64, 2, 2]            --
│    └─Empty: 2-908                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-909         --                        --
│    └─One: 2-910                        [1]                       --
│    └─OutputScale: 2-911                --                        --
│    └─Empty: 2-912                      [64, 64, 3, 3]            --
│    └─Empty: 2-913                      [64, 64, 3, 3]            --
│    └─Empty: 2-914                      [64]                      --
│    └─Empty: 2-915                      [64]                      --
│    └─BatchNorm2d: 2-916                [16, 64, 2, 2]            --
│    └─Scaler: 2-917                     [16, 64, 2, 2]            --
│    └─ReLU: 2-918                       [16, 64, 2, 2]            --
│    └─Empty: 2-919                      [16, 64, 2, 2]            --
│    └─Clamp: 2-920                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-921         --                        --
│    └─One: 2-922                        [1]                       --
│    └─OutputScale: 2-923                --                        --
│    └─Empty: 2-924                      [64, 48, 1, 1]            --
│    └─Empty: 2-925                      [64, 48, 1, 1]            --
│    └─Empty: 2-926                      [64]                      --
│    └─Empty: 2-927                      [64]                      --
│    └─BatchNorm2d: 2-928                [16, 64, 64, 64]          --
│    └─Scaler: 2-929                     [16, 64, 64, 64]          --
│    └─ReLU: 2-930                       [16, 64, 64, 64]          --
│    └─Empty: 2-931                      [16, 64, 64, 64]          --
│    └─Clamp: 2-932                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-933         --                        --
│    └─One: 2-934                        [1]                       --
│    └─OutputScale: 2-935                --                        --
│    └─Empty: 2-936                      [64, 64, 3, 3]            --
│    └─Empty: 2-937                      [64, 64, 3, 3]            --
│    └─Empty: 2-938                      [64]                      --
│    └─Empty: 2-939                      [64]                      --
│    └─BatchNorm2d: 2-940                [16, 64, 64, 64]          --
│    └─Scaler: 2-941                     [16, 64, 64, 64]          --
│    └─ReLU: 2-942                       [16, 64, 64, 64]          --
│    └─Empty: 2-943                      [16, 64, 64, 64]          --
│    └─Clamp: 2-944                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-945         --                        --
│    └─One: 2-946                        [1]                       --
│    └─OutputScale: 2-947                --                        --
│    └─Empty: 2-948                      [64, 64, 1, 1]            --
│    └─Empty: 2-949                      [64, 64, 1, 1]            --
│    └─Empty: 2-950                      [64]                      --
│    └─Empty: 2-951                      [64]                      --
│    └─BatchNorm2d: 2-952                [16, 64, 64, 64]          --
│    └─Scaler: 2-953                     [16, 64, 64, 64]          --
│    └─ReLU: 2-954                       [16, 64, 64, 64]          --
│    └─Empty: 2-955                      [16, 64, 64, 64]          --
│    └─Clamp: 2-956                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-957         --                        --
│    └─One: 2-958                        [1]                       --
│    └─OutputScale: 2-959                --                        --
│    └─Empty: 2-960                      [64, 64, 3, 3]            --
│    └─Empty: 2-961                      [64, 64, 3, 3]            --
│    └─Empty: 2-962                      [64]                      --
│    └─Empty: 2-963                      [64]                      --
│    └─BatchNorm2d: 2-964                [16, 64, 64, 64]          --
│    └─Scaler: 2-965                     [16, 64, 64, 64]          --
│    └─ReLU: 2-966                       [16, 64, 64, 64]          --
│    └─Empty: 2-967                      [16, 64, 64, 64]          --
│    └─Clamp: 2-968                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-969                  [16, 64, 32, 32]          --
│    └─Empty: 2-970                      [16, 64, 32, 32]          --
│    └─Empty: 2-971                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-972         --                        --
│    └─One: 2-973                        [1]                       --
│    └─OutputScale: 2-974                --                        --
│    └─Empty: 2-975                      [64, 64, 3, 3]            --
│    └─Empty: 2-976                      [64, 64, 3, 3]            --
│    └─Empty: 2-977                      [64]                      --
│    └─Empty: 2-978                      [64]                      --
│    └─BatchNorm2d: 2-979                [16, 64, 32, 32]          --
│    └─Scaler: 2-980                     [16, 64, 32, 32]          --
│    └─ReLU: 2-981                       [16, 64, 32, 32]          --
│    └─Empty: 2-982                      [16, 64, 32, 32]          --
│    └─Clamp: 2-983                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-984         --                        --
│    └─One: 2-985                        [1]                       --
│    └─OutputScale: 2-986                --                        --
│    └─Empty: 2-987                      [64, 64, 3, 3]            --
│    └─Empty: 2-988                      [64, 64, 3, 3]            --
│    └─Empty: 2-989                      [64]                      --
│    └─Empty: 2-990                      [64]                      --
│    └─BatchNorm2d: 2-991                [16, 64, 32, 32]          --
│    └─Scaler: 2-992                     [16, 64, 32, 32]          --
│    └─ReLU: 2-993                       [16, 64, 32, 32]          --
│    └─Empty: 2-994                      [16, 64, 32, 32]          --
│    └─Clamp: 2-995                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-996                  [16, 64, 16, 16]          --
│    └─Empty: 2-997                      [16, 64, 16, 16]          --
│    └─Empty: 2-998                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-999         --                        --
│    └─One: 2-1000                       [1]                       --
│    └─OutputScale: 2-1001               --                        --
│    └─Empty: 2-1002                     [64, 64, 3, 3]            --
│    └─Empty: 2-1003                     [64, 64, 3, 3]            --
│    └─Empty: 2-1004                     [64]                      --
│    └─Empty: 2-1005                     [64]                      --
│    └─BatchNorm2d: 2-1006               [16, 64, 16, 16]          --
│    └─Scaler: 2-1007                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1008                      [16, 64, 16, 16]          --
│    └─Empty: 2-1009                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1010                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1011        --                        --
│    └─One: 2-1012                       [1]                       --
│    └─OutputScale: 2-1013               --                        --
│    └─Empty: 2-1014                     [64, 64, 3, 3]            --
│    └─Empty: 2-1015                     [64, 64, 3, 3]            --
│    └─Empty: 2-1016                     [64]                      --
│    └─Empty: 2-1017                     [64]                      --
│    └─BatchNorm2d: 2-1018               [16, 64, 16, 16]          --
│    └─Scaler: 2-1019                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1020                      [16, 64, 16, 16]          --
│    └─Empty: 2-1021                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1022                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1023                 [16, 64, 8, 8]            --
│    └─Empty: 2-1024                     [16, 64, 8, 8]            --
│    └─Empty: 2-1025                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1026        --                        --
│    └─One: 2-1027                       [1]                       --
│    └─OutputScale: 2-1028               --                        --
│    └─Empty: 2-1029                     [64, 64, 3, 3]            --
│    └─Empty: 2-1030                     [64, 64, 3, 3]            --
│    └─Empty: 2-1031                     [64]                      --
│    └─Empty: 2-1032                     [64]                      --
│    └─BatchNorm2d: 2-1033               [16, 64, 8, 8]            --
│    └─Scaler: 2-1034                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1035                      [16, 64, 8, 8]            --
│    └─Empty: 2-1036                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1037                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1038        --                        --
│    └─One: 2-1039                       [1]                       --
│    └─OutputScale: 2-1040               --                        --
│    └─Empty: 2-1041                     [64, 64, 1, 1]            --
│    └─Empty: 2-1042                     [64, 64, 1, 1]            --
│    └─Empty: 2-1043                     [64]                      --
│    └─Empty: 2-1044                     [64]                      --
│    └─BatchNorm2d: 2-1045               [16, 64, 8, 8]            --
│    └─Scaler: 2-1046                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1047                      [16, 64, 8, 8]            --
│    └─Empty: 2-1048                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1049                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1050                 [16, 64, 8, 8]            --
│    └─Empty: 2-1051                     [16, 64, 8, 8]            --
│    └─Empty: 2-1052                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1053        --                        --
│    └─One: 2-1054                       [1]                       --
│    └─OutputScale: 2-1055               --                        --
│    └─Empty: 2-1056                     [64, 64, 3, 3]            --
│    └─Empty: 2-1057                     [64, 64, 3, 3]            --
│    └─Empty: 2-1058                     [64]                      --
│    └─Empty: 2-1059                     [64]                      --
│    └─BatchNorm2d: 2-1060               [16, 64, 8, 8]            --
│    └─Scaler: 2-1061                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1062                      [16, 64, 8, 8]            --
│    └─Empty: 2-1063                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1064                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1065                 [16, 64, 4, 4]            --
│    └─Empty: 2-1066                     [16, 64, 4, 4]            --
│    └─Empty: 2-1067                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1068        --                        --
│    └─One: 2-1069                       [1]                       --
│    └─OutputScale: 2-1070               --                        --
│    └─Empty: 2-1071                     [64, 64, 3, 3]            --
│    └─Empty: 2-1072                     [64, 64, 3, 3]            --
│    └─Empty: 2-1073                     [64]                      --
│    └─Empty: 2-1074                     [64]                      --
│    └─BatchNorm2d: 2-1075               [16, 64, 4, 4]            --
│    └─Scaler: 2-1076                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1077                      [16, 64, 4, 4]            --
│    └─Empty: 2-1078                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1079                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1080        --                        --
│    └─One: 2-1081                       [1]                       --
│    └─OutputScale: 2-1082               --                        --
│    └─Empty: 2-1083                     [64, 64, 1, 1]            --
│    └─Empty: 2-1084                     [64, 64, 1, 1]            --
│    └─Empty: 2-1085                     [64]                      --
│    └─Empty: 2-1086                     [64]                      --
│    └─BatchNorm2d: 2-1087               [16, 64, 4, 4]            --
│    └─Scaler: 2-1088                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1089                      [16, 64, 4, 4]            --
│    └─Empty: 2-1090                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1091                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1092                 [16, 64, 4, 4]            --
│    └─Empty: 2-1093                     [16, 64, 4, 4]            --
│    └─Empty: 2-1094                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1095        --                        --
│    └─One: 2-1096                       [1]                       --
│    └─OutputScale: 2-1097               --                        --
│    └─Empty: 2-1098                     [64, 64, 3, 3]            --
│    └─Empty: 2-1099                     [64, 64, 3, 3]            --
│    └─Empty: 2-1100                     [64]                      --
│    └─Empty: 2-1101                     [64]                      --
│    └─BatchNorm2d: 2-1102               [16, 64, 4, 4]            --
│    └─Scaler: 2-1103                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1104                      [16, 64, 4, 4]            --
│    └─Empty: 2-1105                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1106                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1107                 [16, 64, 2, 2]            --
│    └─Empty: 2-1108                     [16, 64, 2, 2]            --
│    └─Empty: 2-1109                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1110        --                        --
│    └─One: 2-1111                       [1]                       --
│    └─OutputScale: 2-1112               --                        --
│    └─Empty: 2-1113                     [64, 64, 1, 1]            --
│    └─Empty: 2-1114                     [64, 64, 1, 1]            --
│    └─Empty: 2-1115                     [64]                      --
│    └─Empty: 2-1116                     [64]                      --
│    └─BatchNorm2d: 2-1117               [16, 64, 2, 2]            --
│    └─Scaler: 2-1118                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1119                      [16, 64, 2, 2]            --
│    └─Empty: 2-1120                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1121                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1122        --                        --
│    └─One: 2-1123                       [1]                       --
│    └─OutputScale: 2-1124               --                        --
│    └─Empty: 2-1125                     [64, 64, 1, 1]            --
│    └─Empty: 2-1126                     [64, 64, 1, 1]            --
│    └─Empty: 2-1127                     [64]                      --
│    └─Empty: 2-1128                     [64]                      --
│    └─BatchNorm2d: 2-1129               [16, 64, 2, 2]            --
│    └─Scaler: 2-1130                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1131                      [16, 64, 2, 2]            --
│    └─Empty: 2-1132                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1133                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1134                 [16, 64, 2, 2]            --
│    └─Empty: 2-1135                     [16, 64, 2, 2]            --
│    └─Empty: 2-1136                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1137        --                        --
│    └─One: 2-1138                       [1]                       --
│    └─OutputScale: 2-1139               --                        --
│    └─Empty: 2-1140                     [64, 64, 3, 3]            --
│    └─Empty: 2-1141                     [64, 64, 3, 3]            --
│    └─Empty: 2-1142                     [64]                      --
│    └─Empty: 2-1143                     [64]                      --
│    └─BatchNorm2d: 2-1144               [16, 64, 2, 2]            --
│    └─Scaler: 2-1145                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1146                      [16, 64, 2, 2]            --
│    └─Empty: 2-1147                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1148                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1149        --                        --
│    └─One: 2-1150                       [1]                       --
│    └─OutputScale: 2-1151               --                        --
│    └─Empty: 2-1152                     [64, 48, 1, 1]            --
│    └─Empty: 2-1153                     [64, 48, 1, 1]            --
│    └─Empty: 2-1154                     [64]                      --
│    └─Empty: 2-1155                     [64]                      --
│    └─BatchNorm2d: 2-1156               [16, 64, 64, 64]          --
│    └─Scaler: 2-1157                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1158                      [16, 64, 64, 64]          --
│    └─Empty: 2-1159                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1160                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1161        --                        --
│    └─One: 2-1162                       [1]                       --
│    └─OutputScale: 2-1163               --                        --
│    └─Empty: 2-1164                     [64, 64, 3, 3]            --
│    └─Empty: 2-1165                     [64, 64, 3, 3]            --
│    └─Empty: 2-1166                     [64]                      --
│    └─Empty: 2-1167                     [64]                      --
│    └─BatchNorm2d: 2-1168               [16, 64, 64, 64]          --
│    └─Scaler: 2-1169                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1170                      [16, 64, 64, 64]          --
│    └─Empty: 2-1171                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1172                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1173        --                        --
│    └─One: 2-1174                       [1]                       --
│    └─OutputScale: 2-1175               --                        --
│    └─Empty: 2-1176                     [64, 64, 1, 1]            --
│    └─Empty: 2-1177                     [64, 64, 1, 1]            --
│    └─Empty: 2-1178                     [64]                      --
│    └─Empty: 2-1179                     [64]                      --
│    └─BatchNorm2d: 2-1180               [16, 64, 64, 64]          --
│    └─Scaler: 2-1181                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1182                      [16, 64, 64, 64]          --
│    └─Empty: 2-1183                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1184                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1185        --                        --
│    └─One: 2-1186                       [1]                       --
│    └─OutputScale: 2-1187               --                        --
│    └─Empty: 2-1188                     [64, 64, 3, 3]            --
│    └─Empty: 2-1189                     [64, 64, 3, 3]            --
│    └─Empty: 2-1190                     [64]                      --
│    └─Empty: 2-1191                     [64]                      --
│    └─BatchNorm2d: 2-1192               [16, 64, 64, 64]          --
│    └─Scaler: 2-1193                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1194                      [16, 64, 64, 64]          --
│    └─Empty: 2-1195                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1196                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1197                 [16, 64, 32, 32]          --
│    └─Empty: 2-1198                     [16, 64, 32, 32]          --
│    └─Empty: 2-1199                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1200        --                        --
│    └─One: 2-1201                       [1]                       --
│    └─OutputScale: 2-1202               --                        --
│    └─Empty: 2-1203                     [64, 64, 3, 3]            --
│    └─Empty: 2-1204                     [64, 64, 3, 3]            --
│    └─Empty: 2-1205                     [64]                      --
│    └─Empty: 2-1206                     [64]                      --
│    └─BatchNorm2d: 2-1207               [16, 64, 32, 32]          --
│    └─Scaler: 2-1208                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1209                      [16, 64, 32, 32]          --
│    └─Empty: 2-1210                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1211                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1212        --                        --
│    └─One: 2-1213                       [1]                       --
│    └─OutputScale: 2-1214               --                        --
│    └─Empty: 2-1215                     [64, 64, 3, 3]            --
│    └─Empty: 2-1216                     [64, 64, 3, 3]            --
│    └─Empty: 2-1217                     [64]                      --
│    └─Empty: 2-1218                     [64]                      --
│    └─BatchNorm2d: 2-1219               [16, 64, 32, 32]          --
│    └─Scaler: 2-1220                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1221                      [16, 64, 32, 32]          --
│    └─Empty: 2-1222                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1223                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1224                 [16, 64, 16, 16]          --
│    └─Empty: 2-1225                     [16, 64, 16, 16]          --
│    └─Empty: 2-1226                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1227        --                        --
│    └─One: 2-1228                       [1]                       --
│    └─OutputScale: 2-1229               --                        --
│    └─Empty: 2-1230                     [64, 64, 3, 3]            --
│    └─Empty: 2-1231                     [64, 64, 3, 3]            --
│    └─Empty: 2-1232                     [64]                      --
│    └─Empty: 2-1233                     [64]                      --
│    └─BatchNorm2d: 2-1234               [16, 64, 16, 16]          --
│    └─Scaler: 2-1235                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1236                      [16, 64, 16, 16]          --
│    └─Empty: 2-1237                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1238                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1239        --                        --
│    └─One: 2-1240                       [1]                       --
│    └─OutputScale: 2-1241               --                        --
│    └─Empty: 2-1242                     [64, 64, 3, 3]            --
│    └─Empty: 2-1243                     [64, 64, 3, 3]            --
│    └─Empty: 2-1244                     [64]                      --
│    └─Empty: 2-1245                     [64]                      --
│    └─BatchNorm2d: 2-1246               [16, 64, 16, 16]          --
│    └─Scaler: 2-1247                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1248                      [16, 64, 16, 16]          --
│    └─Empty: 2-1249                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1250                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1251                 [16, 64, 8, 8]            --
│    └─Empty: 2-1252                     [16, 64, 8, 8]            --
│    └─Empty: 2-1253                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1254        --                        --
│    └─One: 2-1255                       [1]                       --
│    └─OutputScale: 2-1256               --                        --
│    └─Empty: 2-1257                     [64, 64, 3, 3]            --
│    └─Empty: 2-1258                     [64, 64, 3, 3]            --
│    └─Empty: 2-1259                     [64]                      --
│    └─Empty: 2-1260                     [64]                      --
│    └─BatchNorm2d: 2-1261               [16, 64, 8, 8]            --
│    └─Scaler: 2-1262                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1263                      [16, 64, 8, 8]            --
│    └─Empty: 2-1264                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1265                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1266        --                        --
│    └─One: 2-1267                       [1]                       --
│    └─OutputScale: 2-1268               --                        --
│    └─Empty: 2-1269                     [64, 64, 1, 1]            --
│    └─Empty: 2-1270                     [64, 64, 1, 1]            --
│    └─Empty: 2-1271                     [64]                      --
│    └─Empty: 2-1272                     [64]                      --
│    └─BatchNorm2d: 2-1273               [16, 64, 8, 8]            --
│    └─Scaler: 2-1274                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1275                      [16, 64, 8, 8]            --
│    └─Empty: 2-1276                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1277                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1278                 [16, 64, 8, 8]            --
│    └─Empty: 2-1279                     [16, 64, 8, 8]            --
│    └─Empty: 2-1280                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1281        --                        --
│    └─One: 2-1282                       [1]                       --
│    └─OutputScale: 2-1283               --                        --
│    └─Empty: 2-1284                     [64, 64, 3, 3]            --
│    └─Empty: 2-1285                     [64, 64, 3, 3]            --
│    └─Empty: 2-1286                     [64]                      --
│    └─Empty: 2-1287                     [64]                      --
│    └─BatchNorm2d: 2-1288               [16, 64, 8, 8]            --
│    └─Scaler: 2-1289                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1290                      [16, 64, 8, 8]            --
│    └─Empty: 2-1291                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1292                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1293                 [16, 64, 4, 4]            --
│    └─Empty: 2-1294                     [16, 64, 4, 4]            --
│    └─Empty: 2-1295                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1296        --                        --
│    └─One: 2-1297                       [1]                       --
│    └─OutputScale: 2-1298               --                        --
│    └─Empty: 2-1299                     [64, 64, 3, 3]            --
│    └─Empty: 2-1300                     [64, 64, 3, 3]            --
│    └─Empty: 2-1301                     [64]                      --
│    └─Empty: 2-1302                     [64]                      --
│    └─BatchNorm2d: 2-1303               [16, 64, 4, 4]            --
│    └─Scaler: 2-1304                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1305                      [16, 64, 4, 4]            --
│    └─Empty: 2-1306                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1307                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1308        --                        --
│    └─One: 2-1309                       [1]                       --
│    └─OutputScale: 2-1310               --                        --
│    └─Empty: 2-1311                     [64, 64, 1, 1]            --
│    └─Empty: 2-1312                     [64, 64, 1, 1]            --
│    └─Empty: 2-1313                     [64]                      --
│    └─Empty: 2-1314                     [64]                      --
│    └─BatchNorm2d: 2-1315               [16, 64, 4, 4]            --
│    └─Scaler: 2-1316                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1317                      [16, 64, 4, 4]            --
│    └─Empty: 2-1318                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1319                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1320                 [16, 64, 4, 4]            --
│    └─Empty: 2-1321                     [16, 64, 4, 4]            --
│    └─Empty: 2-1322                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1323        --                        --
│    └─One: 2-1324                       [1]                       --
│    └─OutputScale: 2-1325               --                        --
│    └─Empty: 2-1326                     [64, 64, 3, 3]            --
│    └─Empty: 2-1327                     [64, 64, 3, 3]            --
│    └─Empty: 2-1328                     [64]                      --
│    └─Empty: 2-1329                     [64]                      --
│    └─BatchNorm2d: 2-1330               [16, 64, 4, 4]            --
│    └─Scaler: 2-1331                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1332                      [16, 64, 4, 4]            --
│    └─Empty: 2-1333                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1334                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1335                 [16, 64, 2, 2]            --
│    └─Empty: 2-1336                     [16, 64, 2, 2]            --
│    └─Empty: 2-1337                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1338        --                        --
│    └─One: 2-1339                       [1]                       --
│    └─OutputScale: 2-1340               --                        --
│    └─Empty: 2-1341                     [64, 64, 1, 1]            --
│    └─Empty: 2-1342                     [64, 64, 1, 1]            --
│    └─Empty: 2-1343                     [64]                      --
│    └─Empty: 2-1344                     [64]                      --
│    └─BatchNorm2d: 2-1345               [16, 64, 2, 2]            --
│    └─Scaler: 2-1346                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1347                      [16, 64, 2, 2]            --
│    └─Empty: 2-1348                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1349                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1350        --                        --
│    └─One: 2-1351                       [1]                       --
│    └─OutputScale: 2-1352               --                        --
│    └─Empty: 2-1353                     [64, 64, 1, 1]            --
│    └─Empty: 2-1354                     [64, 64, 1, 1]            --
│    └─Empty: 2-1355                     [64]                      --
│    └─Empty: 2-1356                     [64]                      --
│    └─BatchNorm2d: 2-1357               [16, 64, 2, 2]            --
│    └─Scaler: 2-1358                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1359                      [16, 64, 2, 2]            --
│    └─Empty: 2-1360                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1361                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1362                 [16, 64, 2, 2]            --
│    └─Empty: 2-1363                     [16, 64, 2, 2]            --
│    └─Empty: 2-1364                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1365        --                        --
│    └─One: 2-1366                       [1]                       --
│    └─OutputScale: 2-1367               --                        --
│    └─Empty: 2-1368                     [64, 64, 3, 3]            --
│    └─Empty: 2-1369                     [64, 64, 3, 3]            --
│    └─Empty: 2-1370                     [64]                      --
│    └─Empty: 2-1371                     [64]                      --
│    └─BatchNorm2d: 2-1372               [16, 64, 2, 2]            --
│    └─Scaler: 2-1373                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1374                      [16, 64, 2, 2]            --
│    └─Empty: 2-1375                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1376                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1377        --                        --
│    └─One: 2-1378                       [1]                       --
│    └─OutputScale: 2-1379               --                        --
│    └─Empty: 2-1380                     [64, 48, 1, 1]            --
│    └─Empty: 2-1381                     [64, 48, 1, 1]            --
│    └─Empty: 2-1382                     [64]                      --
│    └─Empty: 2-1383                     [64]                      --
│    └─BatchNorm2d: 2-1384               [16, 64, 64, 64]          --
│    └─Scaler: 2-1385                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1386                      [16, 64, 64, 64]          --
│    └─Empty: 2-1387                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1388                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1389        --                        --
│    └─One: 2-1390                       [1]                       --
│    └─OutputScale: 2-1391               --                        --
│    └─Empty: 2-1392                     [64, 64, 3, 3]            --
│    └─Empty: 2-1393                     [64, 64, 3, 3]            --
│    └─Empty: 2-1394                     [64]                      --
│    └─Empty: 2-1395                     [64]                      --
│    └─BatchNorm2d: 2-1396               [16, 64, 64, 64]          --
│    └─Scaler: 2-1397                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1398                      [16, 64, 64, 64]          --
│    └─Empty: 2-1399                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1400                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1401        --                        --
│    └─One: 2-1402                       [1]                       --
│    └─OutputScale: 2-1403               --                        --
│    └─Empty: 2-1404                     [64, 64, 1, 1]            --
│    └─Empty: 2-1405                     [64, 64, 1, 1]            --
│    └─Empty: 2-1406                     [64]                      --
│    └─Empty: 2-1407                     [64]                      --
│    └─BatchNorm2d: 2-1408               [16, 64, 64, 64]          --
│    └─Scaler: 2-1409                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1410                      [16, 64, 64, 64]          --
│    └─Empty: 2-1411                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1412                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1413        --                        --
│    └─One: 2-1414                       [1]                       --
│    └─OutputScale: 2-1415               --                        --
│    └─Empty: 2-1416                     [64, 64, 3, 3]            --
│    └─Empty: 2-1417                     [64, 64, 3, 3]            --
│    └─Empty: 2-1418                     [64]                      --
│    └─Empty: 2-1419                     [64]                      --
│    └─BatchNorm2d: 2-1420               [16, 64, 64, 64]          --
│    └─Scaler: 2-1421                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1422                      [16, 64, 64, 64]          --
│    └─Empty: 2-1423                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1424                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1425                 [16, 64, 32, 32]          --
│    └─Empty: 2-1426                     [16, 64, 32, 32]          --
│    └─Empty: 2-1427                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1428        --                        --
│    └─One: 2-1429                       [1]                       --
│    └─OutputScale: 2-1430               --                        --
│    └─Empty: 2-1431                     [64, 64, 3, 3]            --
│    └─Empty: 2-1432                     [64, 64, 3, 3]            --
│    └─Empty: 2-1433                     [64]                      --
│    └─Empty: 2-1434                     [64]                      --
│    └─BatchNorm2d: 2-1435               [16, 64, 32, 32]          --
│    └─Scaler: 2-1436                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1437                      [16, 64, 32, 32]          --
│    └─Empty: 2-1438                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1439                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1440        --                        --
│    └─One: 2-1441                       [1]                       --
│    └─OutputScale: 2-1442               --                        --
│    └─Empty: 2-1443                     [64, 64, 3, 3]            --
│    └─Empty: 2-1444                     [64, 64, 3, 3]            --
│    └─Empty: 2-1445                     [64]                      --
│    └─Empty: 2-1446                     [64]                      --
│    └─BatchNorm2d: 2-1447               [16, 64, 32, 32]          --
│    └─Scaler: 2-1448                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1449                      [16, 64, 32, 32]          --
│    └─Empty: 2-1450                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1451                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1452                 [16, 64, 16, 16]          --
│    └─Empty: 2-1453                     [16, 64, 16, 16]          --
│    └─Empty: 2-1454                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1455        --                        --
│    └─One: 2-1456                       [1]                       --
│    └─OutputScale: 2-1457               --                        --
│    └─Empty: 2-1458                     [64, 64, 3, 3]            --
│    └─Empty: 2-1459                     [64, 64, 3, 3]            --
│    └─Empty: 2-1460                     [64]                      --
│    └─Empty: 2-1461                     [64]                      --
│    └─BatchNorm2d: 2-1462               [16, 64, 16, 16]          --
│    └─Scaler: 2-1463                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1464                      [16, 64, 16, 16]          --
│    └─Empty: 2-1465                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1466                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1467        --                        --
│    └─One: 2-1468                       [1]                       --
│    └─OutputScale: 2-1469               --                        --
│    └─Empty: 2-1470                     [64, 64, 3, 3]            --
│    └─Empty: 2-1471                     [64, 64, 3, 3]            --
│    └─Empty: 2-1472                     [64]                      --
│    └─Empty: 2-1473                     [64]                      --
│    └─BatchNorm2d: 2-1474               [16, 64, 16, 16]          --
│    └─Scaler: 2-1475                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1476                      [16, 64, 16, 16]          --
│    └─Empty: 2-1477                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1478                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1479                 [16, 64, 8, 8]            --
│    └─Empty: 2-1480                     [16, 64, 8, 8]            --
│    └─Empty: 2-1481                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1482        --                        --
│    └─One: 2-1483                       [1]                       --
│    └─OutputScale: 2-1484               --                        --
│    └─Empty: 2-1485                     [64, 64, 3, 3]            --
│    └─Empty: 2-1486                     [64, 64, 3, 3]            --
│    └─Empty: 2-1487                     [64]                      --
│    └─Empty: 2-1488                     [64]                      --
│    └─BatchNorm2d: 2-1489               [16, 64, 8, 8]            --
│    └─Scaler: 2-1490                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1491                      [16, 64, 8, 8]            --
│    └─Empty: 2-1492                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1493                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1494        --                        --
│    └─One: 2-1495                       [1]                       --
│    └─OutputScale: 2-1496               --                        --
│    └─Empty: 2-1497                     [64, 64, 1, 1]            --
│    └─Empty: 2-1498                     [64, 64, 1, 1]            --
│    └─Empty: 2-1499                     [64]                      --
│    └─Empty: 2-1500                     [64]                      --
│    └─BatchNorm2d: 2-1501               [16, 64, 8, 8]            --
│    └─Scaler: 2-1502                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1503                      [16, 64, 8, 8]            --
│    └─Empty: 2-1504                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1505                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1506                 [16, 64, 8, 8]            --
│    └─Empty: 2-1507                     [16, 64, 8, 8]            --
│    └─Empty: 2-1508                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1509        --                        --
│    └─One: 2-1510                       [1]                       --
│    └─OutputScale: 2-1511               --                        --
│    └─Empty: 2-1512                     [64, 64, 3, 3]            --
│    └─Empty: 2-1513                     [64, 64, 3, 3]            --
│    └─Empty: 2-1514                     [64]                      --
│    └─Empty: 2-1515                     [64]                      --
│    └─BatchNorm2d: 2-1516               [16, 64, 8, 8]            --
│    └─Scaler: 2-1517                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1518                      [16, 64, 8, 8]            --
│    └─Empty: 2-1519                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1520                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1521                 [16, 64, 4, 4]            --
│    └─Empty: 2-1522                     [16, 64, 4, 4]            --
│    └─Empty: 2-1523                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1524        --                        --
│    └─One: 2-1525                       [1]                       --
│    └─OutputScale: 2-1526               --                        --
│    └─Empty: 2-1527                     [64, 64, 3, 3]            --
│    └─Empty: 2-1528                     [64, 64, 3, 3]            --
│    └─Empty: 2-1529                     [64]                      --
│    └─Empty: 2-1530                     [64]                      --
│    └─BatchNorm2d: 2-1531               [16, 64, 4, 4]            --
│    └─Scaler: 2-1532                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1533                      [16, 64, 4, 4]            --
│    └─Empty: 2-1534                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1535                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1536        --                        --
│    └─One: 2-1537                       [1]                       --
│    └─OutputScale: 2-1538               --                        --
│    └─Empty: 2-1539                     [64, 64, 1, 1]            --
│    └─Empty: 2-1540                     [64, 64, 1, 1]            --
│    └─Empty: 2-1541                     [64]                      --
│    └─Empty: 2-1542                     [64]                      --
│    └─BatchNorm2d: 2-1543               [16, 64, 4, 4]            --
│    └─Scaler: 2-1544                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1545                      [16, 64, 4, 4]            --
│    └─Empty: 2-1546                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1547                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1548                 [16, 64, 4, 4]            --
│    └─Empty: 2-1549                     [16, 64, 4, 4]            --
│    └─Empty: 2-1550                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1551        --                        --
│    └─One: 2-1552                       [1]                       --
│    └─OutputScale: 2-1553               --                        --
│    └─Empty: 2-1554                     [64, 64, 3, 3]            --
│    └─Empty: 2-1555                     [64, 64, 3, 3]            --
│    └─Empty: 2-1556                     [64]                      --
│    └─Empty: 2-1557                     [64]                      --
│    └─BatchNorm2d: 2-1558               [16, 64, 4, 4]            --
│    └─Scaler: 2-1559                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1560                      [16, 64, 4, 4]            --
│    └─Empty: 2-1561                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1562                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1563                 [16, 64, 2, 2]            --
│    └─Empty: 2-1564                     [16, 64, 2, 2]            --
│    └─Empty: 2-1565                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1566        --                        --
│    └─One: 2-1567                       [1]                       --
│    └─OutputScale: 2-1568               --                        --
│    └─Empty: 2-1569                     [64, 64, 1, 1]            --
│    └─Empty: 2-1570                     [64, 64, 1, 1]            --
│    └─Empty: 2-1571                     [64]                      --
│    └─Empty: 2-1572                     [64]                      --
│    └─BatchNorm2d: 2-1573               [16, 64, 2, 2]            --
│    └─Scaler: 2-1574                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1575                      [16, 64, 2, 2]            --
│    └─Empty: 2-1576                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1577                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1578        --                        --
│    └─One: 2-1579                       [1]                       --
│    └─OutputScale: 2-1580               --                        --
│    └─Empty: 2-1581                     [64, 64, 1, 1]            --
│    └─Empty: 2-1582                     [64, 64, 1, 1]            --
│    └─Empty: 2-1583                     [64]                      --
│    └─Empty: 2-1584                     [64]                      --
│    └─BatchNorm2d: 2-1585               [16, 64, 2, 2]            --
│    └─Scaler: 2-1586                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1587                      [16, 64, 2, 2]            --
│    └─Empty: 2-1588                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1589                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1590                 [16, 64, 2, 2]            --
│    └─Empty: 2-1591                     [16, 64, 2, 2]            --
│    └─Empty: 2-1592                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1593        --                        --
│    └─One: 2-1594                       [1]                       --
│    └─OutputScale: 2-1595               --                        --
│    └─Empty: 2-1596                     [64, 64, 3, 3]            --
│    └─Empty: 2-1597                     [64, 64, 3, 3]            --
│    └─Empty: 2-1598                     [64]                      --
│    └─Empty: 2-1599                     [64]                      --
│    └─BatchNorm2d: 2-1600               [16, 64, 2, 2]            --
│    └─Scaler: 2-1601                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1602                      [16, 64, 2, 2]            --
│    └─Empty: 2-1603                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1604                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1605        --                        --
│    └─One: 2-1606                       [1]                       --
│    └─OutputScale: 2-1607               --                        --
│    └─Empty: 2-1608                     [64, 48, 1, 1]            --
│    └─Empty: 2-1609                     [64, 48, 1, 1]            --
│    └─Empty: 2-1610                     [64]                      --
│    └─Empty: 2-1611                     [64]                      --
│    └─BatchNorm2d: 2-1612               [16, 64, 64, 64]          --
│    └─Scaler: 2-1613                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1614                      [16, 64, 64, 64]          --
│    └─Empty: 2-1615                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1616                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1617        --                        --
│    └─One: 2-1618                       [1]                       --
│    └─OutputScale: 2-1619               --                        --
│    └─Empty: 2-1620                     [64, 64, 3, 3]            --
│    └─Empty: 2-1621                     [64, 64, 3, 3]            --
│    └─Empty: 2-1622                     [64]                      --
│    └─Empty: 2-1623                     [64]                      --
│    └─BatchNorm2d: 2-1624               [16, 64, 64, 64]          --
│    └─Scaler: 2-1625                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1626                      [16, 64, 64, 64]          --
│    └─Empty: 2-1627                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1628                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1629        --                        --
│    └─One: 2-1630                       [1]                       --
│    └─OutputScale: 2-1631               --                        --
│    └─Empty: 2-1632                     [64, 64, 1, 1]            --
│    └─Empty: 2-1633                     [64, 64, 1, 1]            --
│    └─Empty: 2-1634                     [64]                      --
│    └─Empty: 2-1635                     [64]                      --
│    └─BatchNorm2d: 2-1636               [16, 64, 64, 64]          --
│    └─Scaler: 2-1637                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1638                      [16, 64, 64, 64]          --
│    └─Empty: 2-1639                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1640                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1641        --                        --
│    └─One: 2-1642                       [1]                       --
│    └─OutputScale: 2-1643               --                        --
│    └─Empty: 2-1644                     [64, 64, 3, 3]            --
│    └─Empty: 2-1645                     [64, 64, 3, 3]            --
│    └─Empty: 2-1646                     [64]                      --
│    └─Empty: 2-1647                     [64]                      --
│    └─BatchNorm2d: 2-1648               [16, 64, 64, 64]          --
│    └─Scaler: 2-1649                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1650                      [16, 64, 64, 64]          --
│    └─Empty: 2-1651                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1652                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1653                 [16, 64, 32, 32]          --
│    └─Empty: 2-1654                     [16, 64, 32, 32]          --
│    └─Empty: 2-1655                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1656        --                        --
│    └─One: 2-1657                       [1]                       --
│    └─OutputScale: 2-1658               --                        --
│    └─Empty: 2-1659                     [64, 64, 3, 3]            --
│    └─Empty: 2-1660                     [64, 64, 3, 3]            --
│    └─Empty: 2-1661                     [64]                      --
│    └─Empty: 2-1662                     [64]                      --
│    └─BatchNorm2d: 2-1663               [16, 64, 32, 32]          --
│    └─Scaler: 2-1664                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1665                      [16, 64, 32, 32]          --
│    └─Empty: 2-1666                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1667                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1668        --                        --
│    └─One: 2-1669                       [1]                       --
│    └─OutputScale: 2-1670               --                        --
│    └─Empty: 2-1671                     [64, 64, 3, 3]            --
│    └─Empty: 2-1672                     [64, 64, 3, 3]            --
│    └─Empty: 2-1673                     [64]                      --
│    └─Empty: 2-1674                     [64]                      --
│    └─BatchNorm2d: 2-1675               [16, 64, 32, 32]          --
│    └─Scaler: 2-1676                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1677                      [16, 64, 32, 32]          --
│    └─Empty: 2-1678                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1679                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1680                 [16, 64, 16, 16]          --
│    └─Empty: 2-1681                     [16, 64, 16, 16]          --
│    └─Empty: 2-1682                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1683        --                        --
│    └─One: 2-1684                       [1]                       --
│    └─OutputScale: 2-1685               --                        --
│    └─Empty: 2-1686                     [64, 64, 3, 3]            --
│    └─Empty: 2-1687                     [64, 64, 3, 3]            --
│    └─Empty: 2-1688                     [64]                      --
│    └─Empty: 2-1689                     [64]                      --
│    └─BatchNorm2d: 2-1690               [16, 64, 16, 16]          --
│    └─Scaler: 2-1691                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1692                      [16, 64, 16, 16]          --
│    └─Empty: 2-1693                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1694                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1695        --                        --
│    └─One: 2-1696                       [1]                       --
│    └─OutputScale: 2-1697               --                        --
│    └─Empty: 2-1698                     [64, 64, 3, 3]            --
│    └─Empty: 2-1699                     [64, 64, 3, 3]            --
│    └─Empty: 2-1700                     [64]                      --
│    └─Empty: 2-1701                     [64]                      --
│    └─BatchNorm2d: 2-1702               [16, 64, 16, 16]          --
│    └─Scaler: 2-1703                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1704                      [16, 64, 16, 16]          --
│    └─Empty: 2-1705                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1706                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1707                 [16, 64, 8, 8]            --
│    └─Empty: 2-1708                     [16, 64, 8, 8]            --
│    └─Empty: 2-1709                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1710        --                        --
│    └─One: 2-1711                       [1]                       --
│    └─OutputScale: 2-1712               --                        --
│    └─Empty: 2-1713                     [64, 64, 3, 3]            --
│    └─Empty: 2-1714                     [64, 64, 3, 3]            --
│    └─Empty: 2-1715                     [64]                      --
│    └─Empty: 2-1716                     [64]                      --
│    └─BatchNorm2d: 2-1717               [16, 64, 8, 8]            --
│    └─Scaler: 2-1718                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1719                      [16, 64, 8, 8]            --
│    └─Empty: 2-1720                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1721                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1722        --                        --
│    └─One: 2-1723                       [1]                       --
│    └─OutputScale: 2-1724               --                        --
│    └─Empty: 2-1725                     [64, 64, 1, 1]            --
│    └─Empty: 2-1726                     [64, 64, 1, 1]            --
│    └─Empty: 2-1727                     [64]                      --
│    └─Empty: 2-1728                     [64]                      --
│    └─BatchNorm2d: 2-1729               [16, 64, 8, 8]            --
│    └─Scaler: 2-1730                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1731                      [16, 64, 8, 8]            --
│    └─Empty: 2-1732                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1733                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1734                 [16, 64, 8, 8]            --
│    └─Empty: 2-1735                     [16, 64, 8, 8]            --
│    └─Empty: 2-1736                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1737        --                        --
│    └─One: 2-1738                       [1]                       --
│    └─OutputScale: 2-1739               --                        --
│    └─Empty: 2-1740                     [64, 64, 3, 3]            --
│    └─Empty: 2-1741                     [64, 64, 3, 3]            --
│    └─Empty: 2-1742                     [64]                      --
│    └─Empty: 2-1743                     [64]                      --
│    └─BatchNorm2d: 2-1744               [16, 64, 8, 8]            --
│    └─Scaler: 2-1745                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1746                      [16, 64, 8, 8]            --
│    └─Empty: 2-1747                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1748                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1749                 [16, 64, 4, 4]            --
│    └─Empty: 2-1750                     [16, 64, 4, 4]            --
│    └─Empty: 2-1751                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1752        --                        --
│    └─One: 2-1753                       [1]                       --
│    └─OutputScale: 2-1754               --                        --
│    └─Empty: 2-1755                     [64, 64, 3, 3]            --
│    └─Empty: 2-1756                     [64, 64, 3, 3]            --
│    └─Empty: 2-1757                     [64]                      --
│    └─Empty: 2-1758                     [64]                      --
│    └─BatchNorm2d: 2-1759               [16, 64, 4, 4]            --
│    └─Scaler: 2-1760                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1761                      [16, 64, 4, 4]            --
│    └─Empty: 2-1762                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1763                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1764        --                        --
│    └─One: 2-1765                       [1]                       --
│    └─OutputScale: 2-1766               --                        --
│    └─Empty: 2-1767                     [64, 64, 1, 1]            --
│    └─Empty: 2-1768                     [64, 64, 1, 1]            --
│    └─Empty: 2-1769                     [64]                      --
│    └─Empty: 2-1770                     [64]                      --
│    └─BatchNorm2d: 2-1771               [16, 64, 4, 4]            --
│    └─Scaler: 2-1772                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1773                      [16, 64, 4, 4]            --
│    └─Empty: 2-1774                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1775                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1776                 [16, 64, 4, 4]            --
│    └─Empty: 2-1777                     [16, 64, 4, 4]            --
│    └─Empty: 2-1778                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1779        --                        --
│    └─One: 2-1780                       [1]                       --
│    └─OutputScale: 2-1781               --                        --
│    └─Empty: 2-1782                     [64, 64, 3, 3]            --
│    └─Empty: 2-1783                     [64, 64, 3, 3]            --
│    └─Empty: 2-1784                     [64]                      --
│    └─Empty: 2-1785                     [64]                      --
│    └─BatchNorm2d: 2-1786               [16, 64, 4, 4]            --
│    └─Scaler: 2-1787                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1788                      [16, 64, 4, 4]            --
│    └─Empty: 2-1789                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1790                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1791                 [16, 64, 2, 2]            --
│    └─Empty: 2-1792                     [16, 64, 2, 2]            --
│    └─Empty: 2-1793                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1794        --                        --
│    └─One: 2-1795                       [1]                       --
│    └─OutputScale: 2-1796               --                        --
│    └─Empty: 2-1797                     [64, 64, 1, 1]            --
│    └─Empty: 2-1798                     [64, 64, 1, 1]            --
│    └─Empty: 2-1799                     [64]                      --
│    └─Empty: 2-1800                     [64]                      --
│    └─BatchNorm2d: 2-1801               [16, 64, 2, 2]            --
│    └─Scaler: 2-1802                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1803                      [16, 64, 2, 2]            --
│    └─Empty: 2-1804                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1805                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1806        --                        --
│    └─One: 2-1807                       [1]                       --
│    └─OutputScale: 2-1808               --                        --
│    └─Empty: 2-1809                     [64, 64, 1, 1]            --
│    └─Empty: 2-1810                     [64, 64, 1, 1]            --
│    └─Empty: 2-1811                     [64]                      --
│    └─Empty: 2-1812                     [64]                      --
│    └─BatchNorm2d: 2-1813               [16, 64, 2, 2]            --
│    └─Scaler: 2-1814                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1815                      [16, 64, 2, 2]            --
│    └─Empty: 2-1816                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1817                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1818                 [16, 64, 2, 2]            --
│    └─Empty: 2-1819                     [16, 64, 2, 2]            --
│    └─Empty: 2-1820                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1821        --                        --
│    └─One: 2-1822                       [1]                       --
│    └─OutputScale: 2-1823               --                        --
│    └─Empty: 2-1824                     [64, 64, 3, 3]            --
│    └─Empty: 2-1825                     [64, 64, 3, 3]            --
│    └─Empty: 2-1826                     [64]                      --
│    └─Empty: 2-1827                     [64]                      --
│    └─BatchNorm2d: 2-1828               [16, 64, 2, 2]            --
│    └─Scaler: 2-1829                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1830                      [16, 64, 2, 2]            --
│    └─Empty: 2-1831                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1832                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1833        --                        --
│    └─One: 2-1834                       [1]                       --
│    └─OutputScale: 2-1835               --                        --
│    └─Empty: 2-1836                     [64, 48, 1, 1]            --
│    └─Empty: 2-1837                     [64, 48, 1, 1]            --
│    └─Empty: 2-1838                     [64]                      --
│    └─Empty: 2-1839                     [64]                      --
│    └─BatchNorm2d: 2-1840               [16, 64, 64, 64]          --
│    └─Scaler: 2-1841                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1842                      [16, 64, 64, 64]          --
│    └─Empty: 2-1843                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1844                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1845        --                        --
│    └─One: 2-1846                       [1]                       --
│    └─OutputScale: 2-1847               --                        --
│    └─Empty: 2-1848                     [64, 64, 3, 3]            --
│    └─Empty: 2-1849                     [64, 64, 3, 3]            --
│    └─Empty: 2-1850                     [64]                      --
│    └─Empty: 2-1851                     [64]                      --
│    └─BatchNorm2d: 2-1852               [16, 64, 64, 64]          --
│    └─Scaler: 2-1853                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1854                      [16, 64, 64, 64]          --
│    └─Empty: 2-1855                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1856                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1857        --                        --
│    └─One: 2-1858                       [1]                       --
│    └─OutputScale: 2-1859               --                        --
│    └─Empty: 2-1860                     [64, 64, 1, 1]            --
│    └─Empty: 2-1861                     [64, 64, 1, 1]            --
│    └─Empty: 2-1862                     [64]                      --
│    └─Empty: 2-1863                     [64]                      --
│    └─BatchNorm2d: 2-1864               [16, 64, 64, 64]          --
│    └─Scaler: 2-1865                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1866                      [16, 64, 64, 64]          --
│    └─Empty: 2-1867                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1868                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1869        --                        --
│    └─One: 2-1870                       [1]                       --
│    └─OutputScale: 2-1871               --                        --
│    └─Empty: 2-1872                     [64, 64, 3, 3]            --
│    └─Empty: 2-1873                     [64, 64, 3, 3]            --
│    └─Empty: 2-1874                     [64]                      --
│    └─Empty: 2-1875                     [64]                      --
│    └─BatchNorm2d: 2-1876               [16, 64, 64, 64]          --
│    └─Scaler: 2-1877                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1878                      [16, 64, 64, 64]          --
│    └─Empty: 2-1879                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1880                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1881                 [16, 64, 32, 32]          --
│    └─Empty: 2-1882                     [16, 64, 32, 32]          --
│    └─Empty: 2-1883                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1884        --                        --
│    └─One: 2-1885                       [1]                       --
│    └─OutputScale: 2-1886               --                        --
│    └─Empty: 2-1887                     [64, 64, 3, 3]            --
│    └─Empty: 2-1888                     [64, 64, 3, 3]            --
│    └─Empty: 2-1889                     [64]                      --
│    └─Empty: 2-1890                     [64]                      --
│    └─BatchNorm2d: 2-1891               [16, 64, 32, 32]          --
│    └─Scaler: 2-1892                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1893                      [16, 64, 32, 32]          --
│    └─Empty: 2-1894                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1895                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1896        --                        --
│    └─One: 2-1897                       [1]                       --
│    └─OutputScale: 2-1898               --                        --
│    └─Empty: 2-1899                     [64, 64, 3, 3]            --
│    └─Empty: 2-1900                     [64, 64, 3, 3]            --
│    └─Empty: 2-1901                     [64]                      --
│    └─Empty: 2-1902                     [64]                      --
│    └─BatchNorm2d: 2-1903               [16, 64, 32, 32]          --
│    └─Scaler: 2-1904                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1905                      [16, 64, 32, 32]          --
│    └─Empty: 2-1906                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1907                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1908                 [16, 64, 16, 16]          --
│    └─Empty: 2-1909                     [16, 64, 16, 16]          --
│    └─Empty: 2-1910                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1911        --                        --
│    └─One: 2-1912                       [1]                       --
│    └─OutputScale: 2-1913               --                        --
│    └─Empty: 2-1914                     [64, 64, 3, 3]            --
│    └─Empty: 2-1915                     [64, 64, 3, 3]            --
│    └─Empty: 2-1916                     [64]                      --
│    └─Empty: 2-1917                     [64]                      --
│    └─BatchNorm2d: 2-1918               [16, 64, 16, 16]          --
│    └─Scaler: 2-1919                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1920                      [16, 64, 16, 16]          --
│    └─Empty: 2-1921                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1922                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1923        --                        --
│    └─One: 2-1924                       [1]                       --
│    └─OutputScale: 2-1925               --                        --
│    └─Empty: 2-1926                     [64, 64, 3, 3]            --
│    └─Empty: 2-1927                     [64, 64, 3, 3]            --
│    └─Empty: 2-1928                     [64]                      --
│    └─Empty: 2-1929                     [64]                      --
│    └─BatchNorm2d: 2-1930               [16, 64, 16, 16]          --
│    └─Scaler: 2-1931                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1932                      [16, 64, 16, 16]          --
│    └─Empty: 2-1933                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1934                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1935                 [16, 64, 8, 8]            --
│    └─Empty: 2-1936                     [16, 64, 8, 8]            --
│    └─Empty: 2-1937                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1938        --                        --
│    └─One: 2-1939                       [1]                       --
│    └─OutputScale: 2-1940               --                        --
│    └─Empty: 2-1941                     [64, 64, 3, 3]            --
│    └─Empty: 2-1942                     [64, 64, 3, 3]            --
│    └─Empty: 2-1943                     [64]                      --
│    └─Empty: 2-1944                     [64]                      --
│    └─BatchNorm2d: 2-1945               [16, 64, 8, 8]            --
│    └─Scaler: 2-1946                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1947                      [16, 64, 8, 8]            --
│    └─Empty: 2-1948                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1949                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1950        --                        --
│    └─One: 2-1951                       [1]                       --
│    └─OutputScale: 2-1952               --                        --
│    └─Empty: 2-1953                     [64, 64, 1, 1]            --
│    └─Empty: 2-1954                     [64, 64, 1, 1]            --
│    └─Empty: 2-1955                     [64]                      --
│    └─Empty: 2-1956                     [64]                      --
│    └─BatchNorm2d: 2-1957               [16, 64, 8, 8]            --
│    └─Scaler: 2-1958                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1959                      [16, 64, 8, 8]            --
│    └─Empty: 2-1960                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1961                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1962                 [16, 64, 8, 8]            --
│    └─Empty: 2-1963                     [16, 64, 8, 8]            --
│    └─Empty: 2-1964                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1965        --                        --
│    └─One: 2-1966                       [1]                       --
│    └─OutputScale: 2-1967               --                        --
│    └─Empty: 2-1968                     [64, 64, 3, 3]            --
│    └─Empty: 2-1969                     [64, 64, 3, 3]            --
│    └─Empty: 2-1970                     [64]                      --
│    └─Empty: 2-1971                     [64]                      --
│    └─BatchNorm2d: 2-1972               [16, 64, 8, 8]            --
│    └─Scaler: 2-1973                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1974                      [16, 64, 8, 8]            --
│    └─Empty: 2-1975                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1976                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1977                 [16, 64, 4, 4]            --
│    └─Empty: 2-1978                     [16, 64, 4, 4]            --
│    └─Empty: 2-1979                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1980        --                        --
│    └─One: 2-1981                       [1]                       --
│    └─OutputScale: 2-1982               --                        --
│    └─Empty: 2-1983                     [64, 64, 3, 3]            --
│    └─Empty: 2-1984                     [64, 64, 3, 3]            --
│    └─Empty: 2-1985                     [64]                      --
│    └─Empty: 2-1986                     [64]                      --
│    └─BatchNorm2d: 2-1987               [16, 64, 4, 4]            --
│    └─Scaler: 2-1988                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1989                      [16, 64, 4, 4]            --
│    └─Empty: 2-1990                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1991                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1992        --                        --
│    └─One: 2-1993                       [1]                       --
│    └─OutputScale: 2-1994               --                        --
│    └─Empty: 2-1995                     [64, 64, 1, 1]            --
│    └─Empty: 2-1996                     [64, 64, 1, 1]            --
│    └─Empty: 2-1997                     [64]                      --
│    └─Empty: 2-1998                     [64]                      --
│    └─BatchNorm2d: 2-1999               [16, 64, 4, 4]            --
│    └─Scaler: 2-2000                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2001                      [16, 64, 4, 4]            --
│    └─Empty: 2-2002                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2003                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2004                 [16, 64, 4, 4]            --
│    └─Empty: 2-2005                     [16, 64, 4, 4]            --
│    └─Empty: 2-2006                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2007        --                        --
│    └─One: 2-2008                       [1]                       --
│    └─OutputScale: 2-2009               --                        --
│    └─Empty: 2-2010                     [64, 64, 3, 3]            --
│    └─Empty: 2-2011                     [64, 64, 3, 3]            --
│    └─Empty: 2-2012                     [64]                      --
│    └─Empty: 2-2013                     [64]                      --
│    └─BatchNorm2d: 2-2014               [16, 64, 4, 4]            --
│    └─Scaler: 2-2015                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2016                      [16, 64, 4, 4]            --
│    └─Empty: 2-2017                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2018                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2019                 [16, 64, 2, 2]            --
│    └─Empty: 2-2020                     [16, 64, 2, 2]            --
│    └─Empty: 2-2021                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2022        --                        --
│    └─One: 2-2023                       [1]                       --
│    └─OutputScale: 2-2024               --                        --
│    └─Empty: 2-2025                     [64, 64, 1, 1]            --
│    └─Empty: 2-2026                     [64, 64, 1, 1]            --
│    └─Empty: 2-2027                     [64]                      --
│    └─Empty: 2-2028                     [64]                      --
│    └─BatchNorm2d: 2-2029               [16, 64, 2, 2]            --
│    └─Scaler: 2-2030                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2031                      [16, 64, 2, 2]            --
│    └─Empty: 2-2032                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2033                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2034        --                        --
│    └─One: 2-2035                       [1]                       --
│    └─OutputScale: 2-2036               --                        --
│    └─Empty: 2-2037                     [64, 64, 1, 1]            --
│    └─Empty: 2-2038                     [64, 64, 1, 1]            --
│    └─Empty: 2-2039                     [64]                      --
│    └─Empty: 2-2040                     [64]                      --
│    └─BatchNorm2d: 2-2041               [16, 64, 2, 2]            --
│    └─Scaler: 2-2042                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2043                      [16, 64, 2, 2]            --
│    └─Empty: 2-2044                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2045                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2046                 [16, 64, 2, 2]            --
│    └─Empty: 2-2047                     [16, 64, 2, 2]            --
│    └─Empty: 2-2048                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2049        --                        --
│    └─One: 2-2050                       [1]                       --
│    └─OutputScale: 2-2051               --                        --
│    └─Empty: 2-2052                     [64, 64, 3, 3]            --
│    └─Empty: 2-2053                     [64, 64, 3, 3]            --
│    └─Empty: 2-2054                     [64]                      --
│    └─Empty: 2-2055                     [64]                      --
│    └─BatchNorm2d: 2-2056               [16, 64, 2, 2]            --
│    └─Scaler: 2-2057                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2058                      [16, 64, 2, 2]            --
│    └─Empty: 2-2059                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2060                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2061        --                        --
│    └─One: 2-2062                       [1]                       --
│    └─OutputScale: 2-2063               --                        --
│    └─Empty: 2-2064                     [64, 48, 1, 1]            --
│    └─Empty: 2-2065                     [64, 48, 1, 1]            --
│    └─Empty: 2-2066                     [64]                      --
│    └─Empty: 2-2067                     [64]                      --
│    └─BatchNorm2d: 2-2068               [16, 64, 64, 64]          --
│    └─Scaler: 2-2069                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2070                      [16, 64, 64, 64]          --
│    └─Empty: 2-2071                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2072                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2073        --                        --
│    └─One: 2-2074                       [1]                       --
│    └─OutputScale: 2-2075               --                        --
│    └─Empty: 2-2076                     [64, 64, 3, 3]            --
│    └─Empty: 2-2077                     [64, 64, 3, 3]            --
│    └─Empty: 2-2078                     [64]                      --
│    └─Empty: 2-2079                     [64]                      --
│    └─BatchNorm2d: 2-2080               [16, 64, 64, 64]          --
│    └─Scaler: 2-2081                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2082                      [16, 64, 64, 64]          --
│    └─Empty: 2-2083                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2084                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2085        --                        --
│    └─One: 2-2086                       [1]                       --
│    └─OutputScale: 2-2087               --                        --
│    └─Empty: 2-2088                     [64, 64, 1, 1]            --
│    └─Empty: 2-2089                     [64, 64, 1, 1]            --
│    └─Empty: 2-2090                     [64]                      --
│    └─Empty: 2-2091                     [64]                      --
│    └─BatchNorm2d: 2-2092               [16, 64, 64, 64]          --
│    └─Scaler: 2-2093                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2094                      [16, 64, 64, 64]          --
│    └─Empty: 2-2095                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2096                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2097        --                        --
│    └─One: 2-2098                       [1]                       --
│    └─OutputScale: 2-2099               --                        --
│    └─Empty: 2-2100                     [64, 64, 3, 3]            --
│    └─Empty: 2-2101                     [64, 64, 3, 3]            --
│    └─Empty: 2-2102                     [64]                      --
│    └─Empty: 2-2103                     [64]                      --
│    └─BatchNorm2d: 2-2104               [16, 64, 64, 64]          --
│    └─Scaler: 2-2105                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2106                      [16, 64, 64, 64]          --
│    └─Empty: 2-2107                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2108                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2109                 [16, 64, 32, 32]          --
│    └─Empty: 2-2110                     [16, 64, 32, 32]          --
│    └─Empty: 2-2111                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2112        --                        --
│    └─One: 2-2113                       [1]                       --
│    └─OutputScale: 2-2114               --                        --
│    └─Empty: 2-2115                     [64, 64, 3, 3]            --
│    └─Empty: 2-2116                     [64, 64, 3, 3]            --
│    └─Empty: 2-2117                     [64]                      --
│    └─Empty: 2-2118                     [64]                      --
│    └─BatchNorm2d: 2-2119               [16, 64, 32, 32]          --
│    └─Scaler: 2-2120                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2121                      [16, 64, 32, 32]          --
│    └─Empty: 2-2122                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2123                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2124        --                        --
│    └─One: 2-2125                       [1]                       --
│    └─OutputScale: 2-2126               --                        --
│    └─Empty: 2-2127                     [64, 64, 3, 3]            --
│    └─Empty: 2-2128                     [64, 64, 3, 3]            --
│    └─Empty: 2-2129                     [64]                      --
│    └─Empty: 2-2130                     [64]                      --
│    └─BatchNorm2d: 2-2131               [16, 64, 32, 32]          --
│    └─Scaler: 2-2132                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2133                      [16, 64, 32, 32]          --
│    └─Empty: 2-2134                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2135                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2136                 [16, 64, 16, 16]          --
│    └─Empty: 2-2137                     [16, 64, 16, 16]          --
│    └─Empty: 2-2138                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2139        --                        --
│    └─One: 2-2140                       [1]                       --
│    └─OutputScale: 2-2141               --                        --
│    └─Empty: 2-2142                     [64, 64, 3, 3]            --
│    └─Empty: 2-2143                     [64, 64, 3, 3]            --
│    └─Empty: 2-2144                     [64]                      --
│    └─Empty: 2-2145                     [64]                      --
│    └─BatchNorm2d: 2-2146               [16, 64, 16, 16]          --
│    └─Scaler: 2-2147                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2148                      [16, 64, 16, 16]          --
│    └─Empty: 2-2149                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2150                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2151        --                        --
│    └─One: 2-2152                       [1]                       --
│    └─OutputScale: 2-2153               --                        --
│    └─Empty: 2-2154                     [64, 64, 3, 3]            --
│    └─Empty: 2-2155                     [64, 64, 3, 3]            --
│    └─Empty: 2-2156                     [64]                      --
│    └─Empty: 2-2157                     [64]                      --
│    └─BatchNorm2d: 2-2158               [16, 64, 16, 16]          --
│    └─Scaler: 2-2159                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2160                      [16, 64, 16, 16]          --
│    └─Empty: 2-2161                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2162                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2163                 [16, 64, 8, 8]            --
│    └─Empty: 2-2164                     [16, 64, 8, 8]            --
│    └─Empty: 2-2165                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2166        --                        --
│    └─One: 2-2167                       [1]                       --
│    └─OutputScale: 2-2168               --                        --
│    └─Empty: 2-2169                     [64, 64, 3, 3]            --
│    └─Empty: 2-2170                     [64, 64, 3, 3]            --
│    └─Empty: 2-2171                     [64]                      --
│    └─Empty: 2-2172                     [64]                      --
│    └─BatchNorm2d: 2-2173               [16, 64, 8, 8]            --
│    └─Scaler: 2-2174                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2175                      [16, 64, 8, 8]            --
│    └─Empty: 2-2176                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2177                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2178        --                        --
│    └─One: 2-2179                       [1]                       --
│    └─OutputScale: 2-2180               --                        --
│    └─Empty: 2-2181                     [64, 64, 1, 1]            --
│    └─Empty: 2-2182                     [64, 64, 1, 1]            --
│    └─Empty: 2-2183                     [64]                      --
│    └─Empty: 2-2184                     [64]                      --
│    └─BatchNorm2d: 2-2185               [16, 64, 8, 8]            --
│    └─Scaler: 2-2186                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2187                      [16, 64, 8, 8]            --
│    └─Empty: 2-2188                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2189                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2190                 [16, 64, 8, 8]            --
│    └─Empty: 2-2191                     [16, 64, 8, 8]            --
│    └─Empty: 2-2192                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2193        --                        --
│    └─One: 2-2194                       [1]                       --
│    └─OutputScale: 2-2195               --                        --
│    └─Empty: 2-2196                     [64, 64, 3, 3]            --
│    └─Empty: 2-2197                     [64, 64, 3, 3]            --
│    └─Empty: 2-2198                     [64]                      --
│    └─Empty: 2-2199                     [64]                      --
│    └─BatchNorm2d: 2-2200               [16, 64, 8, 8]            --
│    └─Scaler: 2-2201                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2202                      [16, 64, 8, 8]            --
│    └─Empty: 2-2203                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2204                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2205                 [16, 64, 4, 4]            --
│    └─Empty: 2-2206                     [16, 64, 4, 4]            --
│    └─Empty: 2-2207                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2208        --                        --
│    └─One: 2-2209                       [1]                       --
│    └─OutputScale: 2-2210               --                        --
│    └─Empty: 2-2211                     [64, 64, 3, 3]            --
│    └─Empty: 2-2212                     [64, 64, 3, 3]            --
│    └─Empty: 2-2213                     [64]                      --
│    └─Empty: 2-2214                     [64]                      --
│    └─BatchNorm2d: 2-2215               [16, 64, 4, 4]            --
│    └─Scaler: 2-2216                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2217                      [16, 64, 4, 4]            --
│    └─Empty: 2-2218                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2219                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2220        --                        --
│    └─One: 2-2221                       [1]                       --
│    └─OutputScale: 2-2222               --                        --
│    └─Empty: 2-2223                     [64, 64, 1, 1]            --
│    └─Empty: 2-2224                     [64, 64, 1, 1]            --
│    └─Empty: 2-2225                     [64]                      --
│    └─Empty: 2-2226                     [64]                      --
│    └─BatchNorm2d: 2-2227               [16, 64, 4, 4]            --
│    └─Scaler: 2-2228                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2229                      [16, 64, 4, 4]            --
│    └─Empty: 2-2230                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2231                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2232                 [16, 64, 4, 4]            --
│    └─Empty: 2-2233                     [16, 64, 4, 4]            --
│    └─Empty: 2-2234                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2235        --                        --
│    └─One: 2-2236                       [1]                       --
│    └─OutputScale: 2-2237               --                        --
│    └─Empty: 2-2238                     [64, 64, 3, 3]            --
│    └─Empty: 2-2239                     [64, 64, 3, 3]            --
│    └─Empty: 2-2240                     [64]                      --
│    └─Empty: 2-2241                     [64]                      --
│    └─BatchNorm2d: 2-2242               [16, 64, 4, 4]            --
│    └─Scaler: 2-2243                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2244                      [16, 64, 4, 4]            --
│    └─Empty: 2-2245                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2246                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2247                 [16, 64, 2, 2]            --
│    └─Empty: 2-2248                     [16, 64, 2, 2]            --
│    └─Empty: 2-2249                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2250        --                        --
│    └─One: 2-2251                       [1]                       --
│    └─OutputScale: 2-2252               --                        --
│    └─Empty: 2-2253                     [64, 64, 1, 1]            --
│    └─Empty: 2-2254                     [64, 64, 1, 1]            --
│    └─Empty: 2-2255                     [64]                      --
│    └─Empty: 2-2256                     [64]                      --
│    └─BatchNorm2d: 2-2257               [16, 64, 2, 2]            --
│    └─Scaler: 2-2258                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2259                      [16, 64, 2, 2]            --
│    └─Empty: 2-2260                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2261                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2262        --                        --
│    └─One: 2-2263                       [1]                       --
│    └─OutputScale: 2-2264               --                        --
│    └─Empty: 2-2265                     [64, 64, 1, 1]            --
│    └─Empty: 2-2266                     [64, 64, 1, 1]            --
│    └─Empty: 2-2267                     [64]                      --
│    └─Empty: 2-2268                     [64]                      --
│    └─BatchNorm2d: 2-2269               [16, 64, 2, 2]            --
│    └─Scaler: 2-2270                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2271                      [16, 64, 2, 2]            --
│    └─Empty: 2-2272                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2273                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2274                 [16, 64, 2, 2]            --
│    └─Empty: 2-2275                     [16, 64, 2, 2]            --
│    └─Empty: 2-2276                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2277        --                        --
│    └─One: 2-2278                       [1]                       --
│    └─OutputScale: 2-2279               --                        --
│    └─Empty: 2-2280                     [64, 64, 3, 3]            --
│    └─Empty: 2-2281                     [64, 64, 3, 3]            --
│    └─Empty: 2-2282                     [64]                      --
│    └─Empty: 2-2283                     [64]                      --
│    └─BatchNorm2d: 2-2284               [16, 64, 2, 2]            --
│    └─Scaler: 2-2285                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2286                      [16, 64, 2, 2]            --
│    └─Empty: 2-2287                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2288                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2289        --                        --
│    └─One: 2-2290                       [1]                       --
│    └─OutputScale: 2-2291               --                        --
│    └─Empty: 2-2292                     [64, 48, 1, 1]            --
│    └─Empty: 2-2293                     [64, 48, 1, 1]            --
│    └─Empty: 2-2294                     [64]                      --
│    └─Empty: 2-2295                     [64]                      --
│    └─BatchNorm2d: 2-2296               [16, 64, 64, 64]          --
│    └─Scaler: 2-2297                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2298                      [16, 64, 64, 64]          --
│    └─Empty: 2-2299                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2300                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2301        --                        --
│    └─One: 2-2302                       [1]                       --
│    └─OutputScale: 2-2303               --                        --
│    └─Empty: 2-2304                     [64, 64, 3, 3]            --
│    └─Empty: 2-2305                     [64, 64, 3, 3]            --
│    └─Empty: 2-2306                     [64]                      --
│    └─Empty: 2-2307                     [64]                      --
│    └─BatchNorm2d: 2-2308               [16, 64, 64, 64]          --
│    └─Scaler: 2-2309                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2310                      [16, 64, 64, 64]          --
│    └─Empty: 2-2311                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2312                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2313        --                        --
│    └─One: 2-2314                       [1]                       --
│    └─OutputScale: 2-2315               --                        --
│    └─Empty: 2-2316                     [64, 64, 1, 1]            --
│    └─Empty: 2-2317                     [64, 64, 1, 1]            --
│    └─Empty: 2-2318                     [64]                      --
│    └─Empty: 2-2319                     [64]                      --
│    └─BatchNorm2d: 2-2320               [16, 64, 64, 64]          --
│    └─Scaler: 2-2321                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2322                      [16, 64, 64, 64]          --
│    └─Empty: 2-2323                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2324                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2325        --                        --
│    └─One: 2-2326                       [1]                       --
│    └─OutputScale: 2-2327               --                        --
│    └─Empty: 2-2328                     [64, 64, 3, 3]            --
│    └─Empty: 2-2329                     [64, 64, 3, 3]            --
│    └─Empty: 2-2330                     [64]                      --
│    └─Empty: 2-2331                     [64]                      --
│    └─BatchNorm2d: 2-2332               [16, 64, 64, 64]          --
│    └─Scaler: 2-2333                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2334                      [16, 64, 64, 64]          --
│    └─Empty: 2-2335                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2336                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2337                 [16, 64, 32, 32]          --
│    └─Empty: 2-2338                     [16, 64, 32, 32]          --
│    └─Empty: 2-2339                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2340        --                        --
│    └─One: 2-2341                       [1]                       --
│    └─OutputScale: 2-2342               --                        --
│    └─Empty: 2-2343                     [64, 64, 3, 3]            --
│    └─Empty: 2-2344                     [64, 64, 3, 3]            --
│    └─Empty: 2-2345                     [64]                      --
│    └─Empty: 2-2346                     [64]                      --
│    └─BatchNorm2d: 2-2347               [16, 64, 32, 32]          --
│    └─Scaler: 2-2348                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2349                      [16, 64, 32, 32]          --
│    └─Empty: 2-2350                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2351                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2352        --                        --
│    └─One: 2-2353                       [1]                       --
│    └─OutputScale: 2-2354               --                        --
│    └─Empty: 2-2355                     [64, 64, 3, 3]            --
│    └─Empty: 2-2356                     [64, 64, 3, 3]            --
│    └─Empty: 2-2357                     [64]                      --
│    └─Empty: 2-2358                     [64]                      --
│    └─BatchNorm2d: 2-2359               [16, 64, 32, 32]          --
│    └─Scaler: 2-2360                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2361                      [16, 64, 32, 32]          --
│    └─Empty: 2-2362                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2363                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2364                 [16, 64, 16, 16]          --
│    └─Empty: 2-2365                     [16, 64, 16, 16]          --
│    └─Empty: 2-2366                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2367        --                        --
│    └─One: 2-2368                       [1]                       --
│    └─OutputScale: 2-2369               --                        --
│    └─Empty: 2-2370                     [64, 64, 3, 3]            --
│    └─Empty: 2-2371                     [64, 64, 3, 3]            --
│    └─Empty: 2-2372                     [64]                      --
│    └─Empty: 2-2373                     [64]                      --
│    └─BatchNorm2d: 2-2374               [16, 64, 16, 16]          --
│    └─Scaler: 2-2375                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2376                      [16, 64, 16, 16]          --
│    └─Empty: 2-2377                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2378                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2379        --                        --
│    └─One: 2-2380                       [1]                       --
│    └─OutputScale: 2-2381               --                        --
│    └─Empty: 2-2382                     [64, 64, 3, 3]            --
│    └─Empty: 2-2383                     [64, 64, 3, 3]            --
│    └─Empty: 2-2384                     [64]                      --
│    └─Empty: 2-2385                     [64]                      --
│    └─BatchNorm2d: 2-2386               [16, 64, 16, 16]          --
│    └─Scaler: 2-2387                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2388                      [16, 64, 16, 16]          --
│    └─Empty: 2-2389                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2390                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2391                 [16, 64, 8, 8]            --
│    └─Empty: 2-2392                     [16, 64, 8, 8]            --
│    └─Empty: 2-2393                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2394        --                        --
│    └─One: 2-2395                       [1]                       --
│    └─OutputScale: 2-2396               --                        --
│    └─Empty: 2-2397                     [64, 64, 3, 3]            --
│    └─Empty: 2-2398                     [64, 64, 3, 3]            --
│    └─Empty: 2-2399                     [64]                      --
│    └─Empty: 2-2400                     [64]                      --
│    └─BatchNorm2d: 2-2401               [16, 64, 8, 8]            --
│    └─Scaler: 2-2402                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2403                      [16, 64, 8, 8]            --
│    └─Empty: 2-2404                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2405                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2406        --                        --
│    └─One: 2-2407                       [1]                       --
│    └─OutputScale: 2-2408               --                        --
│    └─Empty: 2-2409                     [64, 64, 1, 1]            --
│    └─Empty: 2-2410                     [64, 64, 1, 1]            --
│    └─Empty: 2-2411                     [64]                      --
│    └─Empty: 2-2412                     [64]                      --
│    └─BatchNorm2d: 2-2413               [16, 64, 8, 8]            --
│    └─Scaler: 2-2414                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2415                      [16, 64, 8, 8]            --
│    └─Empty: 2-2416                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2417                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2418                 [16, 64, 8, 8]            --
│    └─Empty: 2-2419                     [16, 64, 8, 8]            --
│    └─Empty: 2-2420                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2421        --                        --
│    └─One: 2-2422                       [1]                       --
│    └─OutputScale: 2-2423               --                        --
│    └─Empty: 2-2424                     [64, 64, 3, 3]            --
│    └─Empty: 2-2425                     [64, 64, 3, 3]            --
│    └─Empty: 2-2426                     [64]                      --
│    └─Empty: 2-2427                     [64]                      --
│    └─BatchNorm2d: 2-2428               [16, 64, 8, 8]            --
│    └─Scaler: 2-2429                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2430                      [16, 64, 8, 8]            --
│    └─Empty: 2-2431                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2432                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2433                 [16, 64, 4, 4]            --
│    └─Empty: 2-2434                     [16, 64, 4, 4]            --
│    └─Empty: 2-2435                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2436        --                        --
│    └─One: 2-2437                       [1]                       --
│    └─OutputScale: 2-2438               --                        --
│    └─Empty: 2-2439                     [64, 64, 3, 3]            --
│    └─Empty: 2-2440                     [64, 64, 3, 3]            --
│    └─Empty: 2-2441                     [64]                      --
│    └─Empty: 2-2442                     [64]                      --
│    └─BatchNorm2d: 2-2443               [16, 64, 4, 4]            --
│    └─Scaler: 2-2444                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2445                      [16, 64, 4, 4]            --
│    └─Empty: 2-2446                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2447                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2448        --                        --
│    └─One: 2-2449                       [1]                       --
│    └─OutputScale: 2-2450               --                        --
│    └─Empty: 2-2451                     [64, 64, 1, 1]            --
│    └─Empty: 2-2452                     [64, 64, 1, 1]            --
│    └─Empty: 2-2453                     [64]                      --
│    └─Empty: 2-2454                     [64]                      --
│    └─BatchNorm2d: 2-2455               [16, 64, 4, 4]            --
│    └─Scaler: 2-2456                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2457                      [16, 64, 4, 4]            --
│    └─Empty: 2-2458                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2459                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2460                 [16, 64, 4, 4]            --
│    └─Empty: 2-2461                     [16, 64, 4, 4]            --
│    └─Empty: 2-2462                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2463        --                        --
│    └─One: 2-2464                       [1]                       --
│    └─OutputScale: 2-2465               --                        --
│    └─Empty: 2-2466                     [64, 64, 3, 3]            --
│    └─Empty: 2-2467                     [64, 64, 3, 3]            --
│    └─Empty: 2-2468                     [64]                      --
│    └─Empty: 2-2469                     [64]                      --
│    └─BatchNorm2d: 2-2470               [16, 64, 4, 4]            --
│    └─Scaler: 2-2471                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2472                      [16, 64, 4, 4]            --
│    └─Empty: 2-2473                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2474                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2475                 [16, 64, 2, 2]            --
│    └─Empty: 2-2476                     [16, 64, 2, 2]            --
│    └─Empty: 2-2477                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2478        --                        --
│    └─One: 2-2479                       [1]                       --
│    └─OutputScale: 2-2480               --                        --
│    └─Empty: 2-2481                     [64, 64, 1, 1]            --
│    └─Empty: 2-2482                     [64, 64, 1, 1]            --
│    └─Empty: 2-2483                     [64]                      --
│    └─Empty: 2-2484                     [64]                      --
│    └─BatchNorm2d: 2-2485               [16, 64, 2, 2]            --
│    └─Scaler: 2-2486                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2487                      [16, 64, 2, 2]            --
│    └─Empty: 2-2488                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2489                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2490        --                        --
│    └─One: 2-2491                       [1]                       --
│    └─OutputScale: 2-2492               --                        --
│    └─Empty: 2-2493                     [64, 64, 1, 1]            --
│    └─Empty: 2-2494                     [64, 64, 1, 1]            --
│    └─Empty: 2-2495                     [64]                      --
│    └─Empty: 2-2496                     [64]                      --
│    └─BatchNorm2d: 2-2497               [16, 64, 2, 2]            --
│    └─Scaler: 2-2498                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2499                      [16, 64, 2, 2]            --
│    └─Empty: 2-2500                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2501                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2502                 [16, 64, 2, 2]            --
│    └─Empty: 2-2503                     [16, 64, 2, 2]            --
│    └─Empty: 2-2504                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2505        --                        --
│    └─One: 2-2506                       [1]                       --
│    └─OutputScale: 2-2507               --                        --
│    └─Empty: 2-2508                     [64, 64, 3, 3]            --
│    └─Empty: 2-2509                     [64, 64, 3, 3]            --
│    └─Empty: 2-2510                     [64]                      --
│    └─Empty: 2-2511                     [64]                      --
│    └─BatchNorm2d: 2-2512               [16, 64, 2, 2]            --
│    └─Scaler: 2-2513                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2514                      [16, 64, 2, 2]            --
│    └─Empty: 2-2515                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2516                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2517        --                        --
│    └─One: 2-2518                       [1]                       --
│    └─OutputScale: 2-2519               --                        --
│    └─Empty: 2-2520                     [64, 48, 1, 1]            --
│    └─Empty: 2-2521                     [64, 48, 1, 1]            --
│    └─Empty: 2-2522                     [64]                      --
│    └─Empty: 2-2523                     [64]                      --
│    └─BatchNorm2d: 2-2524               [16, 64, 64, 64]          --
│    └─Scaler: 2-2525                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2526                      [16, 64, 64, 64]          --
│    └─Empty: 2-2527                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2528                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2529        --                        --
│    └─One: 2-2530                       [1]                       --
│    └─OutputScale: 2-2531               --                        --
│    └─Empty: 2-2532                     [64, 64, 3, 3]            --
│    └─Empty: 2-2533                     [64, 64, 3, 3]            --
│    └─Empty: 2-2534                     [64]                      --
│    └─Empty: 2-2535                     [64]                      --
│    └─BatchNorm2d: 2-2536               [16, 64, 64, 64]          --
│    └─Scaler: 2-2537                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2538                      [16, 64, 64, 64]          --
│    └─Empty: 2-2539                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2540                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2541        --                        --
│    └─One: 2-2542                       [1]                       --
│    └─OutputScale: 2-2543               --                        --
│    └─Empty: 2-2544                     [64, 64, 1, 1]            --
│    └─Empty: 2-2545                     [64, 64, 1, 1]            --
│    └─Empty: 2-2546                     [64]                      --
│    └─Empty: 2-2547                     [64]                      --
│    └─BatchNorm2d: 2-2548               [16, 64, 64, 64]          --
│    └─Scaler: 2-2549                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2550                      [16, 64, 64, 64]          --
│    └─Empty: 2-2551                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2552                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2553        --                        --
│    └─One: 2-2554                       [1]                       --
│    └─OutputScale: 2-2555               --                        --
│    └─Empty: 2-2556                     [64, 64, 3, 3]            --
│    └─Empty: 2-2557                     [64, 64, 3, 3]            --
│    └─Empty: 2-2558                     [64]                      --
│    └─Empty: 2-2559                     [64]                      --
│    └─BatchNorm2d: 2-2560               [16, 64, 64, 64]          --
│    └─Scaler: 2-2561                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2562                      [16, 64, 64, 64]          --
│    └─Empty: 2-2563                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2564                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2565                 [16, 64, 32, 32]          --
│    └─Empty: 2-2566                     [16, 64, 32, 32]          --
│    └─Empty: 2-2567                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2568        --                        --
│    └─One: 2-2569                       [1]                       --
│    └─OutputScale: 2-2570               --                        --
│    └─Empty: 2-2571                     [64, 64, 3, 3]            --
│    └─Empty: 2-2572                     [64, 64, 3, 3]            --
│    └─Empty: 2-2573                     [64]                      --
│    └─Empty: 2-2574                     [64]                      --
│    └─BatchNorm2d: 2-2575               [16, 64, 32, 32]          --
│    └─Scaler: 2-2576                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2577                      [16, 64, 32, 32]          --
│    └─Empty: 2-2578                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2579                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2580        --                        --
│    └─One: 2-2581                       [1]                       --
│    └─OutputScale: 2-2582               --                        --
│    └─Empty: 2-2583                     [64, 64, 3, 3]            --
│    └─Empty: 2-2584                     [64, 64, 3, 3]            --
│    └─Empty: 2-2585                     [64]                      --
│    └─Empty: 2-2586                     [64]                      --
│    └─BatchNorm2d: 2-2587               [16, 64, 32, 32]          --
│    └─Scaler: 2-2588                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2589                      [16, 64, 32, 32]          --
│    └─Empty: 2-2590                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2591                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2592                 [16, 64, 16, 16]          --
│    └─Empty: 2-2593                     [16, 64, 16, 16]          --
│    └─Empty: 2-2594                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2595        --                        --
│    └─One: 2-2596                       [1]                       --
│    └─OutputScale: 2-2597               --                        --
│    └─Empty: 2-2598                     [64, 64, 3, 3]            --
│    └─Empty: 2-2599                     [64, 64, 3, 3]            --
│    └─Empty: 2-2600                     [64]                      --
│    └─Empty: 2-2601                     [64]                      --
│    └─BatchNorm2d: 2-2602               [16, 64, 16, 16]          --
│    └─Scaler: 2-2603                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2604                      [16, 64, 16, 16]          --
│    └─Empty: 2-2605                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2606                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2607        --                        --
│    └─One: 2-2608                       [1]                       --
│    └─OutputScale: 2-2609               --                        --
│    └─Empty: 2-2610                     [64, 64, 3, 3]            --
│    └─Empty: 2-2611                     [64, 64, 3, 3]            --
│    └─Empty: 2-2612                     [64]                      --
│    └─Empty: 2-2613                     [64]                      --
│    └─BatchNorm2d: 2-2614               [16, 64, 16, 16]          --
│    └─Scaler: 2-2615                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2616                      [16, 64, 16, 16]          --
│    └─Empty: 2-2617                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2618                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2619                 [16, 64, 8, 8]            --
│    └─Empty: 2-2620                     [16, 64, 8, 8]            --
│    └─Empty: 2-2621                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2622        --                        --
│    └─One: 2-2623                       [1]                       --
│    └─OutputScale: 2-2624               --                        --
│    └─Empty: 2-2625                     [64, 64, 3, 3]            --
│    └─Empty: 2-2626                     [64, 64, 3, 3]            --
│    └─Empty: 2-2627                     [64]                      --
│    └─Empty: 2-2628                     [64]                      --
│    └─BatchNorm2d: 2-2629               [16, 64, 8, 8]            --
│    └─Scaler: 2-2630                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2631                      [16, 64, 8, 8]            --
│    └─Empty: 2-2632                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2633                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2634        --                        --
│    └─One: 2-2635                       [1]                       --
│    └─OutputScale: 2-2636               --                        --
│    └─Empty: 2-2637                     [64, 64, 1, 1]            --
│    └─Empty: 2-2638                     [64, 64, 1, 1]            --
│    └─Empty: 2-2639                     [64]                      --
│    └─Empty: 2-2640                     [64]                      --
│    └─BatchNorm2d: 2-2641               [16, 64, 8, 8]            --
│    └─Scaler: 2-2642                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2643                      [16, 64, 8, 8]            --
│    └─Empty: 2-2644                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2645                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2646                 [16, 64, 8, 8]            --
│    └─Empty: 2-2647                     [16, 64, 8, 8]            --
│    └─Empty: 2-2648                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2649        --                        --
│    └─One: 2-2650                       [1]                       --
│    └─OutputScale: 2-2651               --                        --
│    └─Empty: 2-2652                     [64, 64, 3, 3]            --
│    └─Empty: 2-2653                     [64, 64, 3, 3]            --
│    └─Empty: 2-2654                     [64]                      --
│    └─Empty: 2-2655                     [64]                      --
│    └─BatchNorm2d: 2-2656               [16, 64, 8, 8]            --
│    └─Scaler: 2-2657                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2658                      [16, 64, 8, 8]            --
│    └─Empty: 2-2659                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2660                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2661                 [16, 64, 4, 4]            --
│    └─Empty: 2-2662                     [16, 64, 4, 4]            --
│    └─Empty: 2-2663                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2664        --                        --
│    └─One: 2-2665                       [1]                       --
│    └─OutputScale: 2-2666               --                        --
│    └─Empty: 2-2667                     [64, 64, 3, 3]            --
│    └─Empty: 2-2668                     [64, 64, 3, 3]            --
│    └─Empty: 2-2669                     [64]                      --
│    └─Empty: 2-2670                     [64]                      --
│    └─BatchNorm2d: 2-2671               [16, 64, 4, 4]            --
│    └─Scaler: 2-2672                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2673                      [16, 64, 4, 4]            --
│    └─Empty: 2-2674                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2675                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2676        --                        --
│    └─One: 2-2677                       [1]                       --
│    └─OutputScale: 2-2678               --                        --
│    └─Empty: 2-2679                     [64, 64, 1, 1]            --
│    └─Empty: 2-2680                     [64, 64, 1, 1]            --
│    └─Empty: 2-2681                     [64]                      --
│    └─Empty: 2-2682                     [64]                      --
│    └─BatchNorm2d: 2-2683               [16, 64, 4, 4]            --
│    └─Scaler: 2-2684                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2685                      [16, 64, 4, 4]            --
│    └─Empty: 2-2686                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2687                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2688                 [16, 64, 4, 4]            --
│    └─Empty: 2-2689                     [16, 64, 4, 4]            --
│    └─Empty: 2-2690                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2691        --                        --
│    └─One: 2-2692                       [1]                       --
│    └─OutputScale: 2-2693               --                        --
│    └─Empty: 2-2694                     [64, 64, 3, 3]            --
│    └─Empty: 2-2695                     [64, 64, 3, 3]            --
│    └─Empty: 2-2696                     [64]                      --
│    └─Empty: 2-2697                     [64]                      --
│    └─BatchNorm2d: 2-2698               [16, 64, 4, 4]            --
│    └─Scaler: 2-2699                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2700                      [16, 64, 4, 4]            --
│    └─Empty: 2-2701                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2702                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2703                 [16, 64, 2, 2]            --
│    └─Empty: 2-2704                     [16, 64, 2, 2]            --
│    └─Empty: 2-2705                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2706        --                        --
│    └─One: 2-2707                       [1]                       --
│    └─OutputScale: 2-2708               --                        --
│    └─Empty: 2-2709                     [64, 64, 1, 1]            --
│    └─Empty: 2-2710                     [64, 64, 1, 1]            --
│    └─Empty: 2-2711                     [64]                      --
│    └─Empty: 2-2712                     [64]                      --
│    └─BatchNorm2d: 2-2713               [16, 64, 2, 2]            --
│    └─Scaler: 2-2714                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2715                      [16, 64, 2, 2]            --
│    └─Empty: 2-2716                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2717                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2718        --                        --
│    └─One: 2-2719                       [1]                       --
│    └─OutputScale: 2-2720               --                        --
│    └─Empty: 2-2721                     [64, 64, 1, 1]            --
│    └─Empty: 2-2722                     [64, 64, 1, 1]            --
│    └─Empty: 2-2723                     [64]                      --
│    └─Empty: 2-2724                     [64]                      --
│    └─BatchNorm2d: 2-2725               [16, 64, 2, 2]            --
│    └─Scaler: 2-2726                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2727                      [16, 64, 2, 2]            --
│    └─Empty: 2-2728                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2729                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2730                 [16, 64, 2, 2]            --
│    └─Empty: 2-2731                     [16, 64, 2, 2]            --
│    └─Empty: 2-2732                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2733        --                        --
│    └─One: 2-2734                       [1]                       --
│    └─OutputScale: 2-2735               --                        --
│    └─Empty: 2-2736                     [64, 64, 3, 3]            --
│    └─Empty: 2-2737                     [64, 64, 3, 3]            --
│    └─Empty: 2-2738                     [64]                      --
│    └─Empty: 2-2739                     [64]                      --
│    └─BatchNorm2d: 2-2740               [16, 64, 2, 2]            --
│    └─Scaler: 2-2741                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2742                      [16, 64, 2, 2]            --
│    └─Empty: 2-2743                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2744                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2745        --                        --
│    └─One: 2-2746                       [1]                       --
│    └─OutputScale: 2-2747               --                        --
│    └─Empty: 2-2748                     [64, 48, 1, 1]            --
│    └─Empty: 2-2749                     [64, 48, 1, 1]            --
│    └─Empty: 2-2750                     [64]                      --
│    └─Empty: 2-2751                     [64]                      --
│    └─BatchNorm2d: 2-2752               [16, 64, 64, 64]          --
│    └─Scaler: 2-2753                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2754                      [16, 64, 64, 64]          --
│    └─Empty: 2-2755                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2756                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2757        --                        --
│    └─One: 2-2758                       [1]                       --
│    └─OutputScale: 2-2759               --                        --
│    └─Empty: 2-2760                     [64, 64, 3, 3]            --
│    └─Empty: 2-2761                     [64, 64, 3, 3]            --
│    └─Empty: 2-2762                     [64]                      --
│    └─Empty: 2-2763                     [64]                      --
│    └─BatchNorm2d: 2-2764               [16, 64, 64, 64]          --
│    └─Scaler: 2-2765                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2766                      [16, 64, 64, 64]          --
│    └─Empty: 2-2767                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2768                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2769        --                        --
│    └─One: 2-2770                       [1]                       --
│    └─OutputScale: 2-2771               --                        --
│    └─Empty: 2-2772                     [64, 64, 1, 1]            --
│    └─Empty: 2-2773                     [64, 64, 1, 1]            --
│    └─Empty: 2-2774                     [64]                      --
│    └─Empty: 2-2775                     [64]                      --
│    └─BatchNorm2d: 2-2776               [16, 64, 64, 64]          --
│    └─Scaler: 2-2777                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2778                      [16, 64, 64, 64]          --
│    └─Empty: 2-2779                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2780                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2781        --                        --
│    └─One: 2-2782                       [1]                       --
│    └─OutputScale: 2-2783               --                        --
│    └─Empty: 2-2784                     [64, 64, 3, 3]            --
│    └─Empty: 2-2785                     [64, 64, 3, 3]            --
│    └─Empty: 2-2786                     [64]                      --
│    └─Empty: 2-2787                     [64]                      --
│    └─BatchNorm2d: 2-2788               [16, 64, 64, 64]          --
│    └─Scaler: 2-2789                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2790                      [16, 64, 64, 64]          --
│    └─Empty: 2-2791                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2792                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2793                 [16, 64, 32, 32]          --
│    └─Empty: 2-2794                     [16, 64, 32, 32]          --
│    └─Empty: 2-2795                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2796        --                        --
│    └─One: 2-2797                       [1]                       --
│    └─OutputScale: 2-2798               --                        --
│    └─Empty: 2-2799                     [64, 64, 3, 3]            --
│    └─Empty: 2-2800                     [64, 64, 3, 3]            --
│    └─Empty: 2-2801                     [64]                      --
│    └─Empty: 2-2802                     [64]                      --
│    └─BatchNorm2d: 2-2803               [16, 64, 32, 32]          --
│    └─Scaler: 2-2804                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2805                      [16, 64, 32, 32]          --
│    └─Empty: 2-2806                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2807                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2808        --                        --
│    └─One: 2-2809                       [1]                       --
│    └─OutputScale: 2-2810               --                        --
│    └─Empty: 2-2811                     [64, 64, 3, 3]            --
│    └─Empty: 2-2812                     [64, 64, 3, 3]            --
│    └─Empty: 2-2813                     [64]                      --
│    └─Empty: 2-2814                     [64]                      --
│    └─BatchNorm2d: 2-2815               [16, 64, 32, 32]          --
│    └─Scaler: 2-2816                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2817                      [16, 64, 32, 32]          --
│    └─Empty: 2-2818                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2819                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2820                 [16, 64, 16, 16]          --
│    └─Empty: 2-2821                     [16, 64, 16, 16]          --
│    └─Empty: 2-2822                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2823        --                        --
│    └─One: 2-2824                       [1]                       --
│    └─OutputScale: 2-2825               --                        --
│    └─Empty: 2-2826                     [64, 64, 3, 3]            --
│    └─Empty: 2-2827                     [64, 64, 3, 3]            --
│    └─Empty: 2-2828                     [64]                      --
│    └─Empty: 2-2829                     [64]                      --
│    └─BatchNorm2d: 2-2830               [16, 64, 16, 16]          --
│    └─Scaler: 2-2831                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2832                      [16, 64, 16, 16]          --
│    └─Empty: 2-2833                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2834                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2835        --                        --
│    └─One: 2-2836                       [1]                       --
│    └─OutputScale: 2-2837               --                        --
│    └─Empty: 2-2838                     [64, 64, 3, 3]            --
│    └─Empty: 2-2839                     [64, 64, 3, 3]            --
│    └─Empty: 2-2840                     [64]                      --
│    └─Empty: 2-2841                     [64]                      --
│    └─BatchNorm2d: 2-2842               [16, 64, 16, 16]          --
│    └─Scaler: 2-2843                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2844                      [16, 64, 16, 16]          --
│    └─Empty: 2-2845                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2846                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2847                 [16, 64, 8, 8]            --
│    └─Empty: 2-2848                     [16, 64, 8, 8]            --
│    └─Empty: 2-2849                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2850        --                        --
│    └─One: 2-2851                       [1]                       --
│    └─OutputScale: 2-2852               --                        --
│    └─Empty: 2-2853                     [64, 64, 3, 3]            --
│    └─Empty: 2-2854                     [64, 64, 3, 3]            --
│    └─Empty: 2-2855                     [64]                      --
│    └─Empty: 2-2856                     [64]                      --
│    └─BatchNorm2d: 2-2857               [16, 64, 8, 8]            --
│    └─Scaler: 2-2858                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2859                      [16, 64, 8, 8]            --
│    └─Empty: 2-2860                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2861                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2862        --                        --
│    └─One: 2-2863                       [1]                       --
│    └─OutputScale: 2-2864               --                        --
│    └─Empty: 2-2865                     [64, 64, 1, 1]            --
│    └─Empty: 2-2866                     [64, 64, 1, 1]            --
│    └─Empty: 2-2867                     [64]                      --
│    └─Empty: 2-2868                     [64]                      --
│    └─BatchNorm2d: 2-2869               [16, 64, 8, 8]            --
│    └─Scaler: 2-2870                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2871                      [16, 64, 8, 8]            --
│    └─Empty: 2-2872                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2873                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2874                 [16, 64, 8, 8]            --
│    └─Empty: 2-2875                     [16, 64, 8, 8]            --
│    └─Empty: 2-2876                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2877        --                        --
│    └─One: 2-2878                       [1]                       --
│    └─OutputScale: 2-2879               --                        --
│    └─Empty: 2-2880                     [64, 64, 3, 3]            --
│    └─Empty: 2-2881                     [64, 64, 3, 3]            --
│    └─Empty: 2-2882                     [64]                      --
│    └─Empty: 2-2883                     [64]                      --
│    └─BatchNorm2d: 2-2884               [16, 64, 8, 8]            --
│    └─Scaler: 2-2885                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2886                      [16, 64, 8, 8]            --
│    └─Empty: 2-2887                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2888                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2889                 [16, 64, 4, 4]            --
│    └─Empty: 2-2890                     [16, 64, 4, 4]            --
│    └─Empty: 2-2891                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2892        --                        --
│    └─One: 2-2893                       [1]                       --
│    └─OutputScale: 2-2894               --                        --
│    └─Empty: 2-2895                     [64, 64, 3, 3]            --
│    └─Empty: 2-2896                     [64, 64, 3, 3]            --
│    └─Empty: 2-2897                     [64]                      --
│    └─Empty: 2-2898                     [64]                      --
│    └─BatchNorm2d: 2-2899               [16, 64, 4, 4]            --
│    └─Scaler: 2-2900                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2901                      [16, 64, 4, 4]            --
│    └─Empty: 2-2902                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2903                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2904        --                        --
│    └─One: 2-2905                       [1]                       --
│    └─OutputScale: 2-2906               --                        --
│    └─Empty: 2-2907                     [64, 64, 1, 1]            --
│    └─Empty: 2-2908                     [64, 64, 1, 1]            --
│    └─Empty: 2-2909                     [64]                      --
│    └─Empty: 2-2910                     [64]                      --
│    └─BatchNorm2d: 2-2911               [16, 64, 4, 4]            --
│    └─Scaler: 2-2912                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2913                      [16, 64, 4, 4]            --
│    └─Empty: 2-2914                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2915                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2916                 [16, 64, 4, 4]            --
│    └─Empty: 2-2917                     [16, 64, 4, 4]            --
│    └─Empty: 2-2918                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2919        --                        --
│    └─One: 2-2920                       [1]                       --
│    └─OutputScale: 2-2921               --                        --
│    └─Empty: 2-2922                     [64, 64, 3, 3]            --
│    └─Empty: 2-2923                     [64, 64, 3, 3]            --
│    └─Empty: 2-2924                     [64]                      --
│    └─Empty: 2-2925                     [64]                      --
│    └─BatchNorm2d: 2-2926               [16, 64, 4, 4]            --
│    └─Scaler: 2-2927                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2928                      [16, 64, 4, 4]            --
│    └─Empty: 2-2929                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2930                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2931                 [16, 64, 2, 2]            --
│    └─Empty: 2-2932                     [16, 64, 2, 2]            --
│    └─Empty: 2-2933                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2934        --                        --
│    └─One: 2-2935                       [1]                       --
│    └─OutputScale: 2-2936               --                        --
│    └─Empty: 2-2937                     [64, 64, 1, 1]            --
│    └─Empty: 2-2938                     [64, 64, 1, 1]            --
│    └─Empty: 2-2939                     [64]                      --
│    └─Empty: 2-2940                     [64]                      --
│    └─BatchNorm2d: 2-2941               [16, 64, 2, 2]            --
│    └─Scaler: 2-2942                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2943                      [16, 64, 2, 2]            --
│    └─Empty: 2-2944                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2945                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2946        --                        --
│    └─One: 2-2947                       [1]                       --
│    └─OutputScale: 2-2948               --                        --
│    └─Empty: 2-2949                     [64, 64, 1, 1]            --
│    └─Empty: 2-2950                     [64, 64, 1, 1]            --
│    └─Empty: 2-2951                     [64]                      --
│    └─Empty: 2-2952                     [64]                      --
│    └─BatchNorm2d: 2-2953               [16, 64, 2, 2]            --
│    └─Scaler: 2-2954                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2955                      [16, 64, 2, 2]            --
│    └─Empty: 2-2956                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2957                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2958                 [16, 64, 2, 2]            --
│    └─Empty: 2-2959                     [16, 64, 2, 2]            --
│    └─Empty: 2-2960                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2961        --                        --
│    └─One: 2-2962                       [1]                       --
│    └─OutputScale: 2-2963               --                        --
│    └─Empty: 2-2964                     [64, 64, 3, 3]            --
│    └─Empty: 2-2965                     [64, 64, 3, 3]            --
│    └─Empty: 2-2966                     [64]                      --
│    └─Empty: 2-2967                     [64]                      --
│    └─BatchNorm2d: 2-2968               [16, 64, 2, 2]            --
│    └─Scaler: 2-2969                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2970                      [16, 64, 2, 2]            --
│    └─Empty: 2-2971                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2972                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2973        --                        --
│    └─One: 2-2974                       [1]                       --
│    └─OutputScale: 2-2975               --                        --
│    └─Empty: 2-2976                     [64, 48, 1, 1]            --
│    └─Empty: 2-2977                     [64, 48, 1, 1]            --
│    └─Empty: 2-2978                     [64]                      --
│    └─Empty: 2-2979                     [64]                      --
│    └─BatchNorm2d: 2-2980               [16, 64, 64, 64]          --
│    └─Scaler: 2-2981                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2982                      [16, 64, 64, 64]          --
│    └─Empty: 2-2983                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2984                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2985        --                        --
│    └─One: 2-2986                       [1]                       --
│    └─OutputScale: 2-2987               --                        --
│    └─Empty: 2-2988                     [64, 64, 3, 3]            --
│    └─Empty: 2-2989                     [64, 64, 3, 3]            --
│    └─Empty: 2-2990                     [64]                      --
│    └─Empty: 2-2991                     [64]                      --
│    └─BatchNorm2d: 2-2992               [16, 64, 64, 64]          --
│    └─Scaler: 2-2993                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2994                      [16, 64, 64, 64]          --
│    └─Empty: 2-2995                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2996                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2997        --                        --
│    └─One: 2-2998                       [1]                       --
│    └─OutputScale: 2-2999               --                        --
│    └─Empty: 2-3000                     [64, 64, 1, 1]            --
│    └─Empty: 2-3001                     [64, 64, 1, 1]            --
│    └─Empty: 2-3002                     [64]                      --
│    └─Empty: 2-3003                     [64]                      --
│    └─BatchNorm2d: 2-3004               [16, 64, 64, 64]          --
│    └─Scaler: 2-3005                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3006                      [16, 64, 64, 64]          --
│    └─Empty: 2-3007                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3008                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3009        --                        --
│    └─One: 2-3010                       [1]                       --
│    └─OutputScale: 2-3011               --                        --
│    └─Empty: 2-3012                     [64, 64, 3, 3]            --
│    └─Empty: 2-3013                     [64, 64, 3, 3]            --
│    └─Empty: 2-3014                     [64]                      --
│    └─Empty: 2-3015                     [64]                      --
│    └─BatchNorm2d: 2-3016               [16, 64, 64, 64]          --
│    └─Scaler: 2-3017                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3018                      [16, 64, 64, 64]          --
│    └─Empty: 2-3019                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3020                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3021                 [16, 64, 32, 32]          --
│    └─Empty: 2-3022                     [16, 64, 32, 32]          --
│    └─Empty: 2-3023                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3024        --                        --
│    └─One: 2-3025                       [1]                       --
│    └─OutputScale: 2-3026               --                        --
│    └─Empty: 2-3027                     [64, 64, 3, 3]            --
│    └─Empty: 2-3028                     [64, 64, 3, 3]            --
│    └─Empty: 2-3029                     [64]                      --
│    └─Empty: 2-3030                     [64]                      --
│    └─BatchNorm2d: 2-3031               [16, 64, 32, 32]          --
│    └─Scaler: 2-3032                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3033                      [16, 64, 32, 32]          --
│    └─Empty: 2-3034                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3035                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3036        --                        --
│    └─One: 2-3037                       [1]                       --
│    └─OutputScale: 2-3038               --                        --
│    └─Empty: 2-3039                     [64, 64, 3, 3]            --
│    └─Empty: 2-3040                     [64, 64, 3, 3]            --
│    └─Empty: 2-3041                     [64]                      --
│    └─Empty: 2-3042                     [64]                      --
│    └─BatchNorm2d: 2-3043               [16, 64, 32, 32]          --
│    └─Scaler: 2-3044                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3045                      [16, 64, 32, 32]          --
│    └─Empty: 2-3046                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3047                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3048                 [16, 64, 16, 16]          --
│    └─Empty: 2-3049                     [16, 64, 16, 16]          --
│    └─Empty: 2-3050                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3051        --                        --
│    └─One: 2-3052                       [1]                       --
│    └─OutputScale: 2-3053               --                        --
│    └─Empty: 2-3054                     [64, 64, 3, 3]            --
│    └─Empty: 2-3055                     [64, 64, 3, 3]            --
│    └─Empty: 2-3056                     [64]                      --
│    └─Empty: 2-3057                     [64]                      --
│    └─BatchNorm2d: 2-3058               [16, 64, 16, 16]          --
│    └─Scaler: 2-3059                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3060                      [16, 64, 16, 16]          --
│    └─Empty: 2-3061                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3062                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3063        --                        --
│    └─One: 2-3064                       [1]                       --
│    └─OutputScale: 2-3065               --                        --
│    └─Empty: 2-3066                     [64, 64, 3, 3]            --
│    └─Empty: 2-3067                     [64, 64, 3, 3]            --
│    └─Empty: 2-3068                     [64]                      --
│    └─Empty: 2-3069                     [64]                      --
│    └─BatchNorm2d: 2-3070               [16, 64, 16, 16]          --
│    └─Scaler: 2-3071                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3072                      [16, 64, 16, 16]          --
│    └─Empty: 2-3073                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3074                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3075                 [16, 64, 8, 8]            --
│    └─Empty: 2-3076                     [16, 64, 8, 8]            --
│    └─Empty: 2-3077                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3078        --                        --
│    └─One: 2-3079                       [1]                       --
│    └─OutputScale: 2-3080               --                        --
│    └─Empty: 2-3081                     [64, 64, 3, 3]            --
│    └─Empty: 2-3082                     [64, 64, 3, 3]            --
│    └─Empty: 2-3083                     [64]                      --
│    └─Empty: 2-3084                     [64]                      --
│    └─BatchNorm2d: 2-3085               [16, 64, 8, 8]            --
│    └─Scaler: 2-3086                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3087                      [16, 64, 8, 8]            --
│    └─Empty: 2-3088                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3089                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3090        --                        --
│    └─One: 2-3091                       [1]                       --
│    └─OutputScale: 2-3092               --                        --
│    └─Empty: 2-3093                     [64, 64, 1, 1]            --
│    └─Empty: 2-3094                     [64, 64, 1, 1]            --
│    └─Empty: 2-3095                     [64]                      --
│    └─Empty: 2-3096                     [64]                      --
│    └─BatchNorm2d: 2-3097               [16, 64, 8, 8]            --
│    └─Scaler: 2-3098                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3099                      [16, 64, 8, 8]            --
│    └─Empty: 2-3100                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3101                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3102                 [16, 64, 8, 8]            --
│    └─Empty: 2-3103                     [16, 64, 8, 8]            --
│    └─Empty: 2-3104                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3105        --                        --
│    └─One: 2-3106                       [1]                       --
│    └─OutputScale: 2-3107               --                        --
│    └─Empty: 2-3108                     [64, 64, 3, 3]            --
│    └─Empty: 2-3109                     [64, 64, 3, 3]            --
│    └─Empty: 2-3110                     [64]                      --
│    └─Empty: 2-3111                     [64]                      --
│    └─BatchNorm2d: 2-3112               [16, 64, 8, 8]            --
│    └─Scaler: 2-3113                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3114                      [16, 64, 8, 8]            --
│    └─Empty: 2-3115                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3116                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3117                 [16, 64, 4, 4]            --
│    └─Empty: 2-3118                     [16, 64, 4, 4]            --
│    └─Empty: 2-3119                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3120        --                        --
│    └─One: 2-3121                       [1]                       --
│    └─OutputScale: 2-3122               --                        --
│    └─Empty: 2-3123                     [64, 64, 3, 3]            --
│    └─Empty: 2-3124                     [64, 64, 3, 3]            --
│    └─Empty: 2-3125                     [64]                      --
│    └─Empty: 2-3126                     [64]                      --
│    └─BatchNorm2d: 2-3127               [16, 64, 4, 4]            --
│    └─Scaler: 2-3128                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3129                      [16, 64, 4, 4]            --
│    └─Empty: 2-3130                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3131                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3132        --                        --
│    └─One: 2-3133                       [1]                       --
│    └─OutputScale: 2-3134               --                        --
│    └─Empty: 2-3135                     [64, 64, 1, 1]            --
│    └─Empty: 2-3136                     [64, 64, 1, 1]            --
│    └─Empty: 2-3137                     [64]                      --
│    └─Empty: 2-3138                     [64]                      --
│    └─BatchNorm2d: 2-3139               [16, 64, 4, 4]            --
│    └─Scaler: 2-3140                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3141                      [16, 64, 4, 4]            --
│    └─Empty: 2-3142                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3143                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3144                 [16, 64, 4, 4]            --
│    └─Empty: 2-3145                     [16, 64, 4, 4]            --
│    └─Empty: 2-3146                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3147        --                        --
│    └─One: 2-3148                       [1]                       --
│    └─OutputScale: 2-3149               --                        --
│    └─Empty: 2-3150                     [64, 64, 3, 3]            --
│    └─Empty: 2-3151                     [64, 64, 3, 3]            --
│    └─Empty: 2-3152                     [64]                      --
│    └─Empty: 2-3153                     [64]                      --
│    └─BatchNorm2d: 2-3154               [16, 64, 4, 4]            --
│    └─Scaler: 2-3155                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3156                      [16, 64, 4, 4]            --
│    └─Empty: 2-3157                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3158                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3159                 [16, 64, 2, 2]            --
│    └─Empty: 2-3160                     [16, 64, 2, 2]            --
│    └─Empty: 2-3161                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3162        --                        --
│    └─One: 2-3163                       [1]                       --
│    └─OutputScale: 2-3164               --                        --
│    └─Empty: 2-3165                     [64, 64, 1, 1]            --
│    └─Empty: 2-3166                     [64, 64, 1, 1]            --
│    └─Empty: 2-3167                     [64]                      --
│    └─Empty: 2-3168                     [64]                      --
│    └─BatchNorm2d: 2-3169               [16, 64, 2, 2]            --
│    └─Scaler: 2-3170                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3171                      [16, 64, 2, 2]            --
│    └─Empty: 2-3172                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3173                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3174        --                        --
│    └─One: 2-3175                       [1]                       --
│    └─OutputScale: 2-3176               --                        --
│    └─Empty: 2-3177                     [64, 64, 1, 1]            --
│    └─Empty: 2-3178                     [64, 64, 1, 1]            --
│    └─Empty: 2-3179                     [64]                      --
│    └─Empty: 2-3180                     [64]                      --
│    └─BatchNorm2d: 2-3181               [16, 64, 2, 2]            --
│    └─Scaler: 2-3182                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3183                      [16, 64, 2, 2]            --
│    └─Empty: 2-3184                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3185                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3186                 [16, 64, 2, 2]            --
│    └─Empty: 2-3187                     [16, 64, 2, 2]            --
│    └─Empty: 2-3188                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3189        --                        --
│    └─One: 2-3190                       [1]                       --
│    └─OutputScale: 2-3191               --                        --
│    └─Empty: 2-3192                     [64, 64, 3, 3]            --
│    └─Empty: 2-3193                     [64, 64, 3, 3]            --
│    └─Empty: 2-3194                     [64]                      --
│    └─Empty: 2-3195                     [64]                      --
│    └─BatchNorm2d: 2-3196               [16, 64, 2, 2]            --
│    └─Scaler: 2-3197                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3198                      [16, 64, 2, 2]            --
│    └─Empty: 2-3199                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3200                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3201        --                        --
│    └─One: 2-3202                       [1]                       --
│    └─OutputScale: 2-3203               --                        --
│    └─Empty: 2-3204                     [64, 48, 1, 1]            --
│    └─Empty: 2-3205                     [64, 48, 1, 1]            --
│    └─Empty: 2-3206                     [64]                      --
│    └─Empty: 2-3207                     [64]                      --
│    └─BatchNorm2d: 2-3208               [16, 64, 64, 64]          --
│    └─Scaler: 2-3209                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3210                      [16, 64, 64, 64]          --
│    └─Empty: 2-3211                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3212                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3213        --                        --
│    └─One: 2-3214                       [1]                       --
│    └─OutputScale: 2-3215               --                        --
│    └─Empty: 2-3216                     [64, 64, 3, 3]            --
│    └─Empty: 2-3217                     [64, 64, 3, 3]            --
│    └─Empty: 2-3218                     [64]                      --
│    └─Empty: 2-3219                     [64]                      --
│    └─BatchNorm2d: 2-3220               [16, 64, 64, 64]          --
│    └─Scaler: 2-3221                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3222                      [16, 64, 64, 64]          --
│    └─Empty: 2-3223                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3224                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3225        --                        --
│    └─One: 2-3226                       [1]                       --
│    └─OutputScale: 2-3227               --                        --
│    └─Empty: 2-3228                     [64, 64, 1, 1]            --
│    └─Empty: 2-3229                     [64, 64, 1, 1]            --
│    └─Empty: 2-3230                     [64]                      --
│    └─Empty: 2-3231                     [64]                      --
│    └─BatchNorm2d: 2-3232               [16, 64, 64, 64]          --
│    └─Scaler: 2-3233                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3234                      [16, 64, 64, 64]          --
│    └─Empty: 2-3235                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3236                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3237        --                        --
│    └─One: 2-3238                       [1]                       --
│    └─OutputScale: 2-3239               --                        --
│    └─Empty: 2-3240                     [64, 64, 3, 3]            --
│    └─Empty: 2-3241                     [64, 64, 3, 3]            --
│    └─Empty: 2-3242                     [64]                      --
│    └─Empty: 2-3243                     [64]                      --
│    └─BatchNorm2d: 2-3244               [16, 64, 64, 64]          --
│    └─Scaler: 2-3245                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3246                      [16, 64, 64, 64]          --
│    └─Empty: 2-3247                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3248                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3249                 [16, 64, 32, 32]          --
│    └─Empty: 2-3250                     [16, 64, 32, 32]          --
│    └─Empty: 2-3251                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3252        --                        --
│    └─One: 2-3253                       [1]                       --
│    └─OutputScale: 2-3254               --                        --
│    └─Empty: 2-3255                     [64, 64, 3, 3]            --
│    └─Empty: 2-3256                     [64, 64, 3, 3]            --
│    └─Empty: 2-3257                     [64]                      --
│    └─Empty: 2-3258                     [64]                      --
│    └─BatchNorm2d: 2-3259               [16, 64, 32, 32]          --
│    └─Scaler: 2-3260                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3261                      [16, 64, 32, 32]          --
│    └─Empty: 2-3262                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3263                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3264        --                        --
│    └─One: 2-3265                       [1]                       --
│    └─OutputScale: 2-3266               --                        --
│    └─Empty: 2-3267                     [64, 64, 3, 3]            --
│    └─Empty: 2-3268                     [64, 64, 3, 3]            --
│    └─Empty: 2-3269                     [64]                      --
│    └─Empty: 2-3270                     [64]                      --
│    └─BatchNorm2d: 2-3271               [16, 64, 32, 32]          --
│    └─Scaler: 2-3272                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3273                      [16, 64, 32, 32]          --
│    └─Empty: 2-3274                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3275                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3276                 [16, 64, 16, 16]          --
│    └─Empty: 2-3277                     [16, 64, 16, 16]          --
│    └─Empty: 2-3278                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3279        --                        --
│    └─One: 2-3280                       [1]                       --
│    └─OutputScale: 2-3281               --                        --
│    └─Empty: 2-3282                     [64, 64, 3, 3]            --
│    └─Empty: 2-3283                     [64, 64, 3, 3]            --
│    └─Empty: 2-3284                     [64]                      --
│    └─Empty: 2-3285                     [64]                      --
│    └─BatchNorm2d: 2-3286               [16, 64, 16, 16]          --
│    └─Scaler: 2-3287                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3288                      [16, 64, 16, 16]          --
│    └─Empty: 2-3289                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3290                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3291        --                        --
│    └─One: 2-3292                       [1]                       --
│    └─OutputScale: 2-3293               --                        --
│    └─Empty: 2-3294                     [64, 64, 3, 3]            --
│    └─Empty: 2-3295                     [64, 64, 3, 3]            --
│    └─Empty: 2-3296                     [64]                      --
│    └─Empty: 2-3297                     [64]                      --
│    └─BatchNorm2d: 2-3298               [16, 64, 16, 16]          --
│    └─Scaler: 2-3299                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3300                      [16, 64, 16, 16]          --
│    └─Empty: 2-3301                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3302                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3303                 [16, 64, 8, 8]            --
│    └─Empty: 2-3304                     [16, 64, 8, 8]            --
│    └─Empty: 2-3305                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3306        --                        --
│    └─One: 2-3307                       [1]                       --
│    └─OutputScale: 2-3308               --                        --
│    └─Empty: 2-3309                     [64, 64, 3, 3]            --
│    └─Empty: 2-3310                     [64, 64, 3, 3]            --
│    └─Empty: 2-3311                     [64]                      --
│    └─Empty: 2-3312                     [64]                      --
│    └─BatchNorm2d: 2-3313               [16, 64, 8, 8]            --
│    └─Scaler: 2-3314                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3315                      [16, 64, 8, 8]            --
│    └─Empty: 2-3316                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3317                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3318        --                        --
│    └─One: 2-3319                       [1]                       --
│    └─OutputScale: 2-3320               --                        --
│    └─Empty: 2-3321                     [64, 64, 1, 1]            --
│    └─Empty: 2-3322                     [64, 64, 1, 1]            --
│    └─Empty: 2-3323                     [64]                      --
│    └─Empty: 2-3324                     [64]                      --
│    └─BatchNorm2d: 2-3325               [16, 64, 8, 8]            --
│    └─Scaler: 2-3326                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3327                      [16, 64, 8, 8]            --
│    └─Empty: 2-3328                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3329                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3330                 [16, 64, 8, 8]            --
│    └─Empty: 2-3331                     [16, 64, 8, 8]            --
│    └─Empty: 2-3332                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3333        --                        --
│    └─One: 2-3334                       [1]                       --
│    └─OutputScale: 2-3335               --                        --
│    └─Empty: 2-3336                     [64, 64, 3, 3]            --
│    └─Empty: 2-3337                     [64, 64, 3, 3]            --
│    └─Empty: 2-3338                     [64]                      --
│    └─Empty: 2-3339                     [64]                      --
│    └─BatchNorm2d: 2-3340               [16, 64, 8, 8]            --
│    └─Scaler: 2-3341                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3342                      [16, 64, 8, 8]            --
│    └─Empty: 2-3343                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3344                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3345                 [16, 64, 4, 4]            --
│    └─Empty: 2-3346                     [16, 64, 4, 4]            --
│    └─Empty: 2-3347                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3348        --                        --
│    └─One: 2-3349                       [1]                       --
│    └─OutputScale: 2-3350               --                        --
│    └─Empty: 2-3351                     [64, 64, 3, 3]            --
│    └─Empty: 2-3352                     [64, 64, 3, 3]            --
│    └─Empty: 2-3353                     [64]                      --
│    └─Empty: 2-3354                     [64]                      --
│    └─BatchNorm2d: 2-3355               [16, 64, 4, 4]            --
│    └─Scaler: 2-3356                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3357                      [16, 64, 4, 4]            --
│    └─Empty: 2-3358                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3359                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3360        --                        --
│    └─One: 2-3361                       [1]                       --
│    └─OutputScale: 2-3362               --                        --
│    └─Empty: 2-3363                     [64, 64, 1, 1]            --
│    └─Empty: 2-3364                     [64, 64, 1, 1]            --
│    └─Empty: 2-3365                     [64]                      --
│    └─Empty: 2-3366                     [64]                      --
│    └─BatchNorm2d: 2-3367               [16, 64, 4, 4]            --
│    └─Scaler: 2-3368                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3369                      [16, 64, 4, 4]            --
│    └─Empty: 2-3370                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3371                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3372                 [16, 64, 4, 4]            --
│    └─Empty: 2-3373                     [16, 64, 4, 4]            --
│    └─Empty: 2-3374                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3375        --                        --
│    └─One: 2-3376                       [1]                       --
│    └─OutputScale: 2-3377               --                        --
│    └─Empty: 2-3378                     [64, 64, 3, 3]            --
│    └─Empty: 2-3379                     [64, 64, 3, 3]            --
│    └─Empty: 2-3380                     [64]                      --
│    └─Empty: 2-3381                     [64]                      --
│    └─BatchNorm2d: 2-3382               [16, 64, 4, 4]            --
│    └─Scaler: 2-3383                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3384                      [16, 64, 4, 4]            --
│    └─Empty: 2-3385                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3386                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3387                 [16, 64, 2, 2]            --
│    └─Empty: 2-3388                     [16, 64, 2, 2]            --
│    └─Empty: 2-3389                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3390        --                        --
│    └─One: 2-3391                       [1]                       --
│    └─OutputScale: 2-3392               --                        --
│    └─Empty: 2-3393                     [64, 64, 1, 1]            --
│    └─Empty: 2-3394                     [64, 64, 1, 1]            --
│    └─Empty: 2-3395                     [64]                      --
│    └─Empty: 2-3396                     [64]                      --
│    └─BatchNorm2d: 2-3397               [16, 64, 2, 2]            --
│    └─Scaler: 2-3398                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3399                      [16, 64, 2, 2]            --
│    └─Empty: 2-3400                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3401                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3402        --                        --
│    └─One: 2-3403                       [1]                       --
│    └─OutputScale: 2-3404               --                        --
│    └─Empty: 2-3405                     [64, 64, 1, 1]            --
│    └─Empty: 2-3406                     [64, 64, 1, 1]            --
│    └─Empty: 2-3407                     [64]                      --
│    └─Empty: 2-3408                     [64]                      --
│    └─BatchNorm2d: 2-3409               [16, 64, 2, 2]            --
│    └─Scaler: 2-3410                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3411                      [16, 64, 2, 2]            --
│    └─Empty: 2-3412                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3413                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3414                 [16, 64, 2, 2]            --
│    └─Empty: 2-3415                     [16, 64, 2, 2]            --
│    └─Empty: 2-3416                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3417        --                        --
│    └─One: 2-3418                       [1]                       --
│    └─OutputScale: 2-3419               --                        --
│    └─Empty: 2-3420                     [64, 64, 3, 3]            --
│    └─Empty: 2-3421                     [64, 64, 3, 3]            --
│    └─Empty: 2-3422                     [64]                      --
│    └─Empty: 2-3423                     [64]                      --
│    └─BatchNorm2d: 2-3424               [16, 64, 2, 2]            --
│    └─Scaler: 2-3425                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3426                      [16, 64, 2, 2]            --
│    └─Empty: 2-3427                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3428                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3429        --                        --
│    └─One: 2-3430                       [1]                       --
│    └─OutputScale: 2-3431               --                        --
│    └─Empty: 2-3432                     [64, 48, 1, 1]            --
│    └─Empty: 2-3433                     [64, 48, 1, 1]            --
│    └─Empty: 2-3434                     [64]                      --
│    └─Empty: 2-3435                     [64]                      --
│    └─BatchNorm2d: 2-3436               [16, 64, 64, 64]          --
│    └─Scaler: 2-3437                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3438                      [16, 64, 64, 64]          --
│    └─Empty: 2-3439                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3440                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3441        --                        --
│    └─One: 2-3442                       [1]                       --
│    └─OutputScale: 2-3443               --                        --
│    └─Empty: 2-3444                     [64, 64, 3, 3]            --
│    └─Empty: 2-3445                     [64, 64, 3, 3]            --
│    └─Empty: 2-3446                     [64]                      --
│    └─Empty: 2-3447                     [64]                      --
│    └─BatchNorm2d: 2-3448               [16, 64, 64, 64]          --
│    └─Scaler: 2-3449                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3450                      [16, 64, 64, 64]          --
│    └─Empty: 2-3451                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3452                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3453        --                        --
│    └─One: 2-3454                       [1]                       --
│    └─OutputScale: 2-3455               --                        --
│    └─Empty: 2-3456                     [64, 64, 1, 1]            --
│    └─Empty: 2-3457                     [64, 64, 1, 1]            --
│    └─Empty: 2-3458                     [64]                      --
│    └─Empty: 2-3459                     [64]                      --
│    └─BatchNorm2d: 2-3460               [16, 64, 64, 64]          --
│    └─Scaler: 2-3461                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3462                      [16, 64, 64, 64]          --
│    └─Empty: 2-3463                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3464                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3465        --                        --
│    └─One: 2-3466                       [1]                       --
│    └─OutputScale: 2-3467               --                        --
│    └─Empty: 2-3468                     [64, 64, 3, 3]            --
│    └─Empty: 2-3469                     [64, 64, 3, 3]            --
│    └─Empty: 2-3470                     [64]                      --
│    └─Empty: 2-3471                     [64]                      --
│    └─BatchNorm2d: 2-3472               [16, 64, 64, 64]          --
│    └─Scaler: 2-3473                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3474                      [16, 64, 64, 64]          --
│    └─Empty: 2-3475                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3476                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3477                 [16, 64, 32, 32]          --
│    └─Empty: 2-3478                     [16, 64, 32, 32]          --
│    └─Empty: 2-3479                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3480        --                        --
│    └─One: 2-3481                       [1]                       --
│    └─OutputScale: 2-3482               --                        --
│    └─Empty: 2-3483                     [64, 64, 3, 3]            --
│    └─Empty: 2-3484                     [64, 64, 3, 3]            --
│    └─Empty: 2-3485                     [64]                      --
│    └─Empty: 2-3486                     [64]                      --
│    └─BatchNorm2d: 2-3487               [16, 64, 32, 32]          --
│    └─Scaler: 2-3488                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3489                      [16, 64, 32, 32]          --
│    └─Empty: 2-3490                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3491                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3492        --                        --
│    └─One: 2-3493                       [1]                       --
│    └─OutputScale: 2-3494               --                        --
│    └─Empty: 2-3495                     [64, 64, 3, 3]            --
│    └─Empty: 2-3496                     [64, 64, 3, 3]            --
│    └─Empty: 2-3497                     [64]                      --
│    └─Empty: 2-3498                     [64]                      --
│    └─BatchNorm2d: 2-3499               [16, 64, 32, 32]          --
│    └─Scaler: 2-3500                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3501                      [16, 64, 32, 32]          --
│    └─Empty: 2-3502                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3503                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3504                 [16, 64, 16, 16]          --
│    └─Empty: 2-3505                     [16, 64, 16, 16]          --
│    └─Empty: 2-3506                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3507        --                        --
│    └─One: 2-3508                       [1]                       --
│    └─OutputScale: 2-3509               --                        --
│    └─Empty: 2-3510                     [64, 64, 3, 3]            --
│    └─Empty: 2-3511                     [64, 64, 3, 3]            --
│    └─Empty: 2-3512                     [64]                      --
│    └─Empty: 2-3513                     [64]                      --
│    └─BatchNorm2d: 2-3514               [16, 64, 16, 16]          --
│    └─Scaler: 2-3515                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3516                      [16, 64, 16, 16]          --
│    └─Empty: 2-3517                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3518                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3519        --                        --
│    └─One: 2-3520                       [1]                       --
│    └─OutputScale: 2-3521               --                        --
│    └─Empty: 2-3522                     [64, 64, 3, 3]            --
│    └─Empty: 2-3523                     [64, 64, 3, 3]            --
│    └─Empty: 2-3524                     [64]                      --
│    └─Empty: 2-3525                     [64]                      --
│    └─BatchNorm2d: 2-3526               [16, 64, 16, 16]          --
│    └─Scaler: 2-3527                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3528                      [16, 64, 16, 16]          --
│    └─Empty: 2-3529                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3530                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3531                 [16, 64, 8, 8]            --
│    └─Empty: 2-3532                     [16, 64, 8, 8]            --
│    └─Empty: 2-3533                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3534        --                        --
│    └─One: 2-3535                       [1]                       --
│    └─OutputScale: 2-3536               --                        --
│    └─Empty: 2-3537                     [64, 64, 3, 3]            --
│    └─Empty: 2-3538                     [64, 64, 3, 3]            --
│    └─Empty: 2-3539                     [64]                      --
│    └─Empty: 2-3540                     [64]                      --
│    └─BatchNorm2d: 2-3541               [16, 64, 8, 8]            --
│    └─Scaler: 2-3542                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3543                      [16, 64, 8, 8]            --
│    └─Empty: 2-3544                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3545                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3546        --                        --
│    └─One: 2-3547                       [1]                       --
│    └─OutputScale: 2-3548               --                        --
│    └─Empty: 2-3549                     [64, 64, 1, 1]            --
│    └─Empty: 2-3550                     [64, 64, 1, 1]            --
│    └─Empty: 2-3551                     [64]                      --
│    └─Empty: 2-3552                     [64]                      --
│    └─BatchNorm2d: 2-3553               [16, 64, 8, 8]            --
│    └─Scaler: 2-3554                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3555                      [16, 64, 8, 8]            --
│    └─Empty: 2-3556                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3557                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3558                 [16, 64, 8, 8]            --
│    └─Empty: 2-3559                     [16, 64, 8, 8]            --
│    └─Empty: 2-3560                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3561        --                        --
│    └─One: 2-3562                       [1]                       --
│    └─OutputScale: 2-3563               --                        --
│    └─Empty: 2-3564                     [64, 64, 3, 3]            --
│    └─Empty: 2-3565                     [64, 64, 3, 3]            --
│    └─Empty: 2-3566                     [64]                      --
│    └─Empty: 2-3567                     [64]                      --
│    └─BatchNorm2d: 2-3568               [16, 64, 8, 8]            --
│    └─Scaler: 2-3569                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3570                      [16, 64, 8, 8]            --
│    └─Empty: 2-3571                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3572                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3573                 [16, 64, 4, 4]            --
│    └─Empty: 2-3574                     [16, 64, 4, 4]            --
│    └─Empty: 2-3575                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3576        --                        --
│    └─One: 2-3577                       [1]                       --
│    └─OutputScale: 2-3578               --                        --
│    └─Empty: 2-3579                     [64, 64, 3, 3]            --
│    └─Empty: 2-3580                     [64, 64, 3, 3]            --
│    └─Empty: 2-3581                     [64]                      --
│    └─Empty: 2-3582                     [64]                      --
│    └─BatchNorm2d: 2-3583               [16, 64, 4, 4]            --
│    └─Scaler: 2-3584                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3585                      [16, 64, 4, 4]            --
│    └─Empty: 2-3586                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3587                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3588        --                        --
│    └─One: 2-3589                       [1]                       --
│    └─OutputScale: 2-3590               --                        --
│    └─Empty: 2-3591                     [64, 64, 1, 1]            --
│    └─Empty: 2-3592                     [64, 64, 1, 1]            --
│    └─Empty: 2-3593                     [64]                      --
│    └─Empty: 2-3594                     [64]                      --
│    └─BatchNorm2d: 2-3595               [16, 64, 4, 4]            --
│    └─Scaler: 2-3596                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3597                      [16, 64, 4, 4]            --
│    └─Empty: 2-3598                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3599                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3600                 [16, 64, 4, 4]            --
│    └─Empty: 2-3601                     [16, 64, 4, 4]            --
│    └─Empty: 2-3602                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3603        --                        --
│    └─One: 2-3604                       [1]                       --
│    └─OutputScale: 2-3605               --                        --
│    └─Empty: 2-3606                     [64, 64, 3, 3]            --
│    └─Empty: 2-3607                     [64, 64, 3, 3]            --
│    └─Empty: 2-3608                     [64]                      --
│    └─Empty: 2-3609                     [64]                      --
│    └─BatchNorm2d: 2-3610               [16, 64, 4, 4]            --
│    └─Scaler: 2-3611                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3612                      [16, 64, 4, 4]            --
│    └─Empty: 2-3613                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3614                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3615                 [16, 64, 2, 2]            --
│    └─Empty: 2-3616                     [16, 64, 2, 2]            --
│    └─Empty: 2-3617                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3618        --                        --
│    └─One: 2-3619                       [1]                       --
│    └─OutputScale: 2-3620               --                        --
│    └─Empty: 2-3621                     [64, 64, 1, 1]            --
│    └─Empty: 2-3622                     [64, 64, 1, 1]            --
│    └─Empty: 2-3623                     [64]                      --
│    └─Empty: 2-3624                     [64]                      --
│    └─BatchNorm2d: 2-3625               [16, 64, 2, 2]            --
│    └─Scaler: 2-3626                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3627                      [16, 64, 2, 2]            --
│    └─Empty: 2-3628                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3629                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3630        --                        --
│    └─One: 2-3631                       [1]                       --
│    └─OutputScale: 2-3632               --                        --
│    └─Empty: 2-3633                     [64, 64, 1, 1]            --
│    └─Empty: 2-3634                     [64, 64, 1, 1]            --
│    └─Empty: 2-3635                     [64]                      --
│    └─Empty: 2-3636                     [64]                      --
│    └─BatchNorm2d: 2-3637               [16, 64, 2, 2]            --
│    └─Scaler: 2-3638                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3639                      [16, 64, 2, 2]            --
│    └─Empty: 2-3640                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3641                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3642                 [16, 64, 2, 2]            --
│    └─Empty: 2-3643                     [16, 64, 2, 2]            --
│    └─Empty: 2-3644                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3645        --                        --
│    └─One: 2-3646                       [1]                       --
│    └─OutputScale: 2-3647               --                        --
│    └─Empty: 2-3648                     [64, 64, 3, 3]            --
│    └─Empty: 2-3649                     [64, 64, 3, 3]            --
│    └─Empty: 2-3650                     [64]                      --
│    └─Empty: 2-3651                     [64]                      --
│    └─BatchNorm2d: 2-3652               [16, 64, 2, 2]            --
│    └─Scaler: 2-3653                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3654                      [16, 64, 2, 2]            --
│    └─Empty: 2-3655                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3656                     [16, 64, 2, 2]            --
├─Conv1d: 1-273                          [16, 64, 16]              16,454
│    └─OutputShiftSqueeze: 2-3657        --                        --
│    └─One: 2-3658                       [1]                       --
│    └─OutputScale: 2-3659               --                        --
│    └─Empty: 2-3660                     [64, 256, 1]              --
│    └─Empty: 2-3661                     [64, 256, 1]              --
│    └─Empty: 2-3662                     [64]                      --
│    └─Empty: 2-3663                     [64]                      --
│    └─Scaler: 2-3664                    [16, 64, 16]              --
│    └─Empty: 2-3665                     [16, 64, 16]              --
│    └─Empty: 2-3666                     [16, 64, 16]              --
│    └─Clamp: 2-3667                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3668        --                        --
│    └─One: 2-3669                       [1]                       --
│    └─OutputScale: 2-3670               --                        --
│    └─Empty: 2-3671                     [64, 64, 3]               --
│    └─Empty: 2-3672                     [64, 64, 3]               --
│    └─Empty: 2-3673                     [64]                      --
│    └─Empty: 2-3674                     [64]                      --
│    └─BatchNorm1d: 2-3675               [16, 64, 16]              --
│    └─Scaler: 2-3676                    [16, 64, 16]              --
│    └─ReLU: 2-3677                      [16, 64, 16]              --
│    └─Empty: 2-3678                     [16, 64, 16]              --
│    └─Clamp: 2-3679                     [16, 64, 16]              --
├─Conv1d: 1-275                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3680        --                        --
│    └─One: 2-3681                       [1]                       --
│    └─OutputScale: 2-3682               --                        --
│    └─Empty: 2-3683                     [64, 64, 1]               --
│    └─Empty: 2-3684                     [64, 64, 1]               --
│    └─Empty: 2-3685                     [64]                      --
│    └─Empty: 2-3686                     [64]                      --
│    └─Scaler: 2-3687                    [16, 64, 16]              --
│    └─Empty: 2-3688                     [16, 64, 16]              --
│    └─Empty: 2-3689                     [16, 64, 16]              --
│    └─Clamp: 2-3690                     [16, 64, 16]              --
├─Dropout: 1-276                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-277               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3691        --                        --
│    └─One: 2-3692                       [1]                       --
│    └─OutputScale: 2-3693               --                        --
│    └─Empty: 2-3694                     [64, 64, 3]               --
│    └─Empty: 2-3695                     [64, 64, 3]               --
│    └─Empty: 2-3696                     [64]                      --
│    └─Empty: 2-3697                     [64]                      --
│    └─BatchNorm1d: 2-3698               [16, 64, 16]              --
│    └─Scaler: 2-3699                    [16, 64, 16]              --
│    └─ReLU: 2-3700                      [16, 64, 16]              --
│    └─Empty: 2-3701                     [16, 64, 16]              --
│    └─Clamp: 2-3702                     [16, 64, 16]              --
├─Conv1d: 1-278                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3703        --                        --
│    └─One: 2-3704                       [1]                       --
│    └─OutputScale: 2-3705               --                        --
│    └─Empty: 2-3706                     [64, 64, 1]               --
│    └─Empty: 2-3707                     [64, 64, 1]               --
│    └─Empty: 2-3708                     [64]                      --
│    └─Empty: 2-3709                     [64]                      --
│    └─Scaler: 2-3710                    [16, 64, 16]              --
│    └─Empty: 2-3711                     [16, 64, 16]              --
│    └─Empty: 2-3712                     [16, 64, 16]              --
│    └─Clamp: 2-3713                     [16, 64, 16]              --
├─Dropout: 1-279                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-280               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3714        --                        --
│    └─One: 2-3715                       [1]                       --
│    └─OutputScale: 2-3716               --                        --
│    └─Empty: 2-3717                     [64, 64, 3]               --
│    └─Empty: 2-3718                     [64, 64, 3]               --
│    └─Empty: 2-3719                     [64]                      --
│    └─Empty: 2-3720                     [64]                      --
│    └─BatchNorm1d: 2-3721               [16, 64, 16]              --
│    └─Scaler: 2-3722                    [16, 64, 16]              --
│    └─ReLU: 2-3723                      [16, 64, 16]              --
│    └─Empty: 2-3724                     [16, 64, 16]              --
│    └─Clamp: 2-3725                     [16, 64, 16]              --
├─Conv1d: 1-281                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3726        --                        --
│    └─One: 2-3727                       [1]                       --
│    └─OutputScale: 2-3728               --                        --
│    └─Empty: 2-3729                     [64, 64, 1]               --
│    └─Empty: 2-3730                     [64, 64, 1]               --
│    └─Empty: 2-3731                     [64]                      --
│    └─Empty: 2-3732                     [64]                      --
│    └─Scaler: 2-3733                    [16, 64, 16]              --
│    └─Empty: 2-3734                     [16, 64, 16]              --
│    └─Empty: 2-3735                     [16, 64, 16]              --
│    └─Clamp: 2-3736                     [16, 64, 16]              --
├─Dropout: 1-282                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-283               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3737        --                        --
│    └─One: 2-3738                       [1]                       --
│    └─OutputScale: 2-3739               --                        --
│    └─Empty: 2-3740                     [64, 64, 3]               --
│    └─Empty: 2-3741                     [64, 64, 3]               --
│    └─Empty: 2-3742                     [64]                      --
│    └─Empty: 2-3743                     [64]                      --
│    └─BatchNorm1d: 2-3744               [16, 64, 16]              --
│    └─Scaler: 2-3745                    [16, 64, 16]              --
│    └─ReLU: 2-3746                      [16, 64, 16]              --
│    └─Empty: 2-3747                     [16, 64, 16]              --
│    └─Clamp: 2-3748                     [16, 64, 16]              --
├─Conv1d: 1-284                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3749        --                        --
│    └─One: 2-3750                       [1]                       --
│    └─OutputScale: 2-3751               --                        --
│    └─Empty: 2-3752                     [64, 64, 1]               --
│    └─Empty: 2-3753                     [64, 64, 1]               --
│    └─Empty: 2-3754                     [64]                      --
│    └─Empty: 2-3755                     [64]                      --
│    └─Scaler: 2-3756                    [16, 64, 16]              --
│    └─Empty: 2-3757                     [16, 64, 16]              --
│    └─Empty: 2-3758                     [16, 64, 16]              --
│    └─Clamp: 2-3759                     [16, 64, 16]              --
├─Dropout: 1-285                         [16, 64, 16]              --
├─Conv1d: 1-286                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3760        --                        --
│    └─One: 2-3761                       [1]                       --
│    └─OutputScale: 2-3762               --                        --
│    └─Empty: 2-3763                     [5, 64, 1]                --
│    └─Empty: 2-3764                     [5, 64, 1]                --
│    └─Empty: 2-3765                     [5]                       --
│    └─Empty: 2-3766                     [5]                       --
│    └─Scaler: 2-3767                    [16, 5, 16]               --
│    └─Empty: 2-3768                     [16, 5, 16]               --
│    └─Empty: 2-3769                     [16, 5, 16]               --
│    └─Clamp: 2-3770                     [16, 5, 16]               --
├─Conv1d: 1-287                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3771        --                        --
│    └─One: 2-3772                       [1]                       --
│    └─OutputScale: 2-3773               --                        --
│    └─Empty: 2-3774                     [64, 5, 1]                --
│    └─Empty: 2-3775                     [64, 5, 1]                --
│    └─Empty: 2-3776                     [64]                      --
│    └─Empty: 2-3777                     [64]                      --
│    └─Scaler: 2-3778                    [16, 64, 16]              --
│    └─Empty: 2-3779                     [16, 64, 16]              --
│    └─Empty: 2-3780                     [16, 64, 16]              --
│    └─Clamp: 2-3781                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-288               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3782        --                        --
│    └─One: 2-3783                       [1]                       --
│    └─OutputScale: 2-3784               --                        --
│    └─Empty: 2-3785                     [64, 64, 3]               --
│    └─Empty: 2-3786                     [64, 64, 3]               --
│    └─Empty: 2-3787                     [64]                      --
│    └─Empty: 2-3788                     [64]                      --
│    └─BatchNorm1d: 2-3789               [16, 64, 16]              --
│    └─Scaler: 2-3790                    [16, 64, 16]              --
│    └─ReLU: 2-3791                      [16, 64, 16]              --
│    └─Empty: 2-3792                     [16, 64, 16]              --
│    └─Clamp: 2-3793                     [16, 64, 16]              --
├─Conv1d: 1-289                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3794        --                        --
│    └─One: 2-3795                       [1]                       --
│    └─OutputScale: 2-3796               --                        --
│    └─Empty: 2-3797                     [64, 64, 1]               --
│    └─Empty: 2-3798                     [64, 64, 1]               --
│    └─Empty: 2-3799                     [64]                      --
│    └─Empty: 2-3800                     [64]                      --
│    └─Scaler: 2-3801                    [16, 64, 16]              --
│    └─Empty: 2-3802                     [16, 64, 16]              --
│    └─Empty: 2-3803                     [16, 64, 16]              --
│    └─Clamp: 2-3804                     [16, 64, 16]              --
├─Dropout: 1-290                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-291               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3805        --                        --
│    └─One: 2-3806                       [1]                       --
│    └─OutputScale: 2-3807               --                        --
│    └─Empty: 2-3808                     [64, 64, 3]               --
│    └─Empty: 2-3809                     [64, 64, 3]               --
│    └─Empty: 2-3810                     [64]                      --
│    └─Empty: 2-3811                     [64]                      --
│    └─BatchNorm1d: 2-3812               [16, 64, 16]              --
│    └─Scaler: 2-3813                    [16, 64, 16]              --
│    └─ReLU: 2-3814                      [16, 64, 16]              --
│    └─Empty: 2-3815                     [16, 64, 16]              --
│    └─Clamp: 2-3816                     [16, 64, 16]              --
├─Conv1d: 1-292                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3817        --                        --
│    └─One: 2-3818                       [1]                       --
│    └─OutputScale: 2-3819               --                        --
│    └─Empty: 2-3820                     [64, 64, 1]               --
│    └─Empty: 2-3821                     [64, 64, 1]               --
│    └─Empty: 2-3822                     [64]                      --
│    └─Empty: 2-3823                     [64]                      --
│    └─Scaler: 2-3824                    [16, 64, 16]              --
│    └─Empty: 2-3825                     [16, 64, 16]              --
│    └─Empty: 2-3826                     [16, 64, 16]              --
│    └─Clamp: 2-3827                     [16, 64, 16]              --
├─Dropout: 1-293                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-294               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3828        --                        --
│    └─One: 2-3829                       [1]                       --
│    └─OutputScale: 2-3830               --                        --
│    └─Empty: 2-3831                     [64, 64, 3]               --
│    └─Empty: 2-3832                     [64, 64, 3]               --
│    └─Empty: 2-3833                     [64]                      --
│    └─Empty: 2-3834                     [64]                      --
│    └─BatchNorm1d: 2-3835               [16, 64, 16]              --
│    └─Scaler: 2-3836                    [16, 64, 16]              --
│    └─ReLU: 2-3837                      [16, 64, 16]              --
│    └─Empty: 2-3838                     [16, 64, 16]              --
│    └─Clamp: 2-3839                     [16, 64, 16]              --
├─Conv1d: 1-295                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3840        --                        --
│    └─One: 2-3841                       [1]                       --
│    └─OutputScale: 2-3842               --                        --
│    └─Empty: 2-3843                     [64, 64, 1]               --
│    └─Empty: 2-3844                     [64, 64, 1]               --
│    └─Empty: 2-3845                     [64]                      --
│    └─Empty: 2-3846                     [64]                      --
│    └─Scaler: 2-3847                    [16, 64, 16]              --
│    └─Empty: 2-3848                     [16, 64, 16]              --
│    └─Empty: 2-3849                     [16, 64, 16]              --
│    └─Clamp: 2-3850                     [16, 64, 16]              --
├─Dropout: 1-296                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-297               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3851        --                        --
│    └─One: 2-3852                       [1]                       --
│    └─OutputScale: 2-3853               --                        --
│    └─Empty: 2-3854                     [64, 64, 3]               --
│    └─Empty: 2-3855                     [64, 64, 3]               --
│    └─Empty: 2-3856                     [64]                      --
│    └─Empty: 2-3857                     [64]                      --
│    └─BatchNorm1d: 2-3858               [16, 64, 16]              --
│    └─Scaler: 2-3859                    [16, 64, 16]              --
│    └─ReLU: 2-3860                      [16, 64, 16]              --
│    └─Empty: 2-3861                     [16, 64, 16]              --
│    └─Clamp: 2-3862                     [16, 64, 16]              --
├─Conv1d: 1-298                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3863        --                        --
│    └─One: 2-3864                       [1]                       --
│    └─OutputScale: 2-3865               --                        --
│    └─Empty: 2-3866                     [64, 64, 1]               --
│    └─Empty: 2-3867                     [64, 64, 1]               --
│    └─Empty: 2-3868                     [64]                      --
│    └─Empty: 2-3869                     [64]                      --
│    └─Scaler: 2-3870                    [16, 64, 16]              --
│    └─Empty: 2-3871                     [16, 64, 16]              --
│    └─Empty: 2-3872                     [16, 64, 16]              --
│    └─Clamp: 2-3873                     [16, 64, 16]              --
├─Dropout: 1-299                         [16, 64, 16]              --
├─Conv1d: 1-300                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3874        --                        --
│    └─One: 2-3875                       [1]                       --
│    └─OutputScale: 2-3876               --                        --
│    └─Empty: 2-3877                     [5, 64, 1]                --
│    └─Empty: 2-3878                     [5, 64, 1]                --
│    └─Empty: 2-3879                     [5]                       --
│    └─Empty: 2-3880                     [5]                       --
│    └─Scaler: 2-3881                    [16, 5, 16]               --
│    └─Empty: 2-3882                     [16, 5, 16]               --
│    └─Empty: 2-3883                     [16, 5, 16]               --
│    └─Clamp: 2-3884                     [16, 5, 16]               --
├─Conv1d: 1-301                          [16, 64, 16]              390
│    └─OutputShiftSqueeze: 2-3885        --                        --
│    └─One: 2-3886                       [1]                       --
│    └─OutputScale: 2-3887               --                        --
│    └─Empty: 2-3888                     [64, 5, 1]                --
│    └─Empty: 2-3889                     [64, 5, 1]                --
│    └─Empty: 2-3890                     [64]                      --
│    └─Empty: 2-3891                     [64]                      --
│    └─Scaler: 2-3892                    [16, 64, 16]              --
│    └─Empty: 2-3893                     [16, 64, 16]              --
│    └─Empty: 2-3894                     [16, 64, 16]              --
│    └─Clamp: 2-3895                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-302               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3896        --                        --
│    └─One: 2-3897                       [1]                       --
│    └─OutputScale: 2-3898               --                        --
│    └─Empty: 2-3899                     [64, 64, 3]               --
│    └─Empty: 2-3900                     [64, 64, 3]               --
│    └─Empty: 2-3901                     [64]                      --
│    └─Empty: 2-3902                     [64]                      --
│    └─BatchNorm1d: 2-3903               [16, 64, 16]              --
│    └─Scaler: 2-3904                    [16, 64, 16]              --
│    └─ReLU: 2-3905                      [16, 64, 16]              --
│    └─Empty: 2-3906                     [16, 64, 16]              --
│    └─Clamp: 2-3907                     [16, 64, 16]              --
├─Conv1d: 1-303                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3908        --                        --
│    └─One: 2-3909                       [1]                       --
│    └─OutputScale: 2-3910               --                        --
│    └─Empty: 2-3911                     [64, 64, 1]               --
│    └─Empty: 2-3912                     [64, 64, 1]               --
│    └─Empty: 2-3913                     [64]                      --
│    └─Empty: 2-3914                     [64]                      --
│    └─Scaler: 2-3915                    [16, 64, 16]              --
│    └─Empty: 2-3916                     [16, 64, 16]              --
│    └─Empty: 2-3917                     [16, 64, 16]              --
│    └─Clamp: 2-3918                     [16, 64, 16]              --
├─Dropout: 1-304                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-305               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3919        --                        --
│    └─One: 2-3920                       [1]                       --
│    └─OutputScale: 2-3921               --                        --
│    └─Empty: 2-3922                     [64, 64, 3]               --
│    └─Empty: 2-3923                     [64, 64, 3]               --
│    └─Empty: 2-3924                     [64]                      --
│    └─Empty: 2-3925                     [64]                      --
│    └─BatchNorm1d: 2-3926               [16, 64, 16]              --
│    └─Scaler: 2-3927                    [16, 64, 16]              --
│    └─ReLU: 2-3928                      [16, 64, 16]              --
│    └─Empty: 2-3929                     [16, 64, 16]              --
│    └─Clamp: 2-3930                     [16, 64, 16]              --
├─Conv1d: 1-306                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3931        --                        --
│    └─One: 2-3932                       [1]                       --
│    └─OutputScale: 2-3933               --                        --
│    └─Empty: 2-3934                     [64, 64, 1]               --
│    └─Empty: 2-3935                     [64, 64, 1]               --
│    └─Empty: 2-3936                     [64]                      --
│    └─Empty: 2-3937                     [64]                      --
│    └─Scaler: 2-3938                    [16, 64, 16]              --
│    └─Empty: 2-3939                     [16, 64, 16]              --
│    └─Empty: 2-3940                     [16, 64, 16]              --
│    └─Clamp: 2-3941                     [16, 64, 16]              --
├─Dropout: 1-307                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-308               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3942        --                        --
│    └─One: 2-3943                       [1]                       --
│    └─OutputScale: 2-3944               --                        --
│    └─Empty: 2-3945                     [64, 64, 3]               --
│    └─Empty: 2-3946                     [64, 64, 3]               --
│    └─Empty: 2-3947                     [64]                      --
│    └─Empty: 2-3948                     [64]                      --
│    └─BatchNorm1d: 2-3949               [16, 64, 16]              --
│    └─Scaler: 2-3950                    [16, 64, 16]              --
│    └─ReLU: 2-3951                      [16, 64, 16]              --
│    └─Empty: 2-3952                     [16, 64, 16]              --
│    └─Clamp: 2-3953                     [16, 64, 16]              --
├─Conv1d: 1-309                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3954        --                        --
│    └─One: 2-3955                       [1]                       --
│    └─OutputScale: 2-3956               --                        --
│    └─Empty: 2-3957                     [64, 64, 1]               --
│    └─Empty: 2-3958                     [64, 64, 1]               --
│    └─Empty: 2-3959                     [64]                      --
│    └─Empty: 2-3960                     [64]                      --
│    └─Scaler: 2-3961                    [16, 64, 16]              --
│    └─Empty: 2-3962                     [16, 64, 16]              --
│    └─Empty: 2-3963                     [16, 64, 16]              --
│    └─Clamp: 2-3964                     [16, 64, 16]              --
├─Dropout: 1-310                         [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-311               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3965        --                        --
│    └─One: 2-3966                       [1]                       --
│    └─OutputScale: 2-3967               --                        --
│    └─Empty: 2-3968                     [64, 64, 3]               --
│    └─Empty: 2-3969                     [64, 64, 3]               --
│    └─Empty: 2-3970                     [64]                      --
│    └─Empty: 2-3971                     [64]                      --
│    └─BatchNorm1d: 2-3972               [16, 64, 16]              --
│    └─Scaler: 2-3973                    [16, 64, 16]              --
│    └─ReLU: 2-3974                      [16, 64, 16]              --
│    └─Empty: 2-3975                     [16, 64, 16]              --
│    └─Clamp: 2-3976                     [16, 64, 16]              --
├─Conv1d: 1-312                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3977        --                        --
│    └─One: 2-3978                       [1]                       --
│    └─OutputScale: 2-3979               --                        --
│    └─Empty: 2-3980                     [64, 64, 1]               --
│    └─Empty: 2-3981                     [64, 64, 1]               --
│    └─Empty: 2-3982                     [64]                      --
│    └─Empty: 2-3983                     [64]                      --
│    └─Scaler: 2-3984                    [16, 64, 16]              --
│    └─Empty: 2-3985                     [16, 64, 16]              --
│    └─Empty: 2-3986                     [16, 64, 16]              --
│    └─Clamp: 2-3987                     [16, 64, 16]              --
├─Dropout: 1-313                         [16, 64, 16]              --
├─Conv1d: 1-314                          [16, 5, 16]               331
│    └─OutputShiftSqueeze: 2-3988        --                        --
│    └─One: 2-3989                       [1]                       --
│    └─OutputScale: 2-3990               --                        --
│    └─Empty: 2-3991                     [5, 64, 1]                --
│    └─Empty: 2-3992                     [5, 64, 1]                --
│    └─Empty: 2-3993                     [5]                       --
│    └─Empty: 2-3994                     [5]                       --
│    └─Scaler: 2-3995                    [16, 5, 16]               --
│    └─Empty: 2-3996                     [16, 5, 16]               --
│    └─Empty: 2-3997                     [16, 5, 16]               --
│    └─Clamp: 2-3998                     [16, 5, 16]               --
==========================================================================================
Total params: 646,761
Trainable params: 646,479
Non-trainable params: 282
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 4.684 | Acc: 30.750% | Wgt Acc: 27.462%
	I - Batch: 100 | Loss: 4.612 | Acc: 35.188% | Wgt Acc: 26.980%
	I - Batch: 150 | Loss: 4.546 | Acc: 33.083% | Wgt Acc: 28.215%
	I - Batch: 200 | Loss: 4.468 | Acc: 34.125% | Wgt Acc: 29.065%
	I - Batch: 250 | Loss: 4.413 | Acc: 33.700% | Wgt Acc: 29.945%
	I - Batch: 300 | Loss: 4.402 | Acc: 33.500% | Wgt Acc: 30.252%
	I - Batch: 350 | Loss: 4.388 | Acc: 33.125% | Wgt Acc: 30.336%
I - num batch: 364
I - Train -- Loss: 4.380 | Acc: 33.087% | Wgt Acc: 30.259% | LR: 1.000000e-03 | Dur: 233.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 280.   51.   72.  237.  256.]
 [  27.  138.  219.   41.  484.]
 [  19.  117.  144.   39.  404.]
 [ 240.   80.  158.  244.  501.]
 [ 126.  282.  381.  157. 1118.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.402 | Acc: 29.125% | Wgt Acc: 29.330%
I - num batch: 87
I - Val -- Loss: 5.360 | Acc: 32.184% | Wgt Acc: 31.113% | Dur: 42.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 89.   3.  12.  79.  18.]
 [  5.  87. 118.   4. 132.]
 [  0.   0.   0.   0.   0.]
 [ 82.  39.  45.  83.  92.]
 [ 23. 139. 115.  38. 189.]]

I - Local maximum validation set accuracy:  32.18

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 4.239 | Acc: 37.500% | Wgt Acc: 30.029%
	I - Batch: 100 | Loss: 4.212 | Acc: 35.812% | Wgt Acc: 31.511%
	I - Batch: 150 | Loss: 4.271 | Acc: 33.917% | Wgt Acc: 31.514%
	I - Batch: 200 | Loss: 4.255 | Acc: 33.406% | Wgt Acc: 31.148%
	I - Batch: 250 | Loss: 4.261 | Acc: 33.375% | Wgt Acc: 30.832%
	I - Batch: 300 | Loss: 4.273 | Acc: 32.021% | Wgt Acc: 30.768%
	I - Batch: 350 | Loss: 4.271 | Acc: 33.054% | Wgt Acc: 30.871%
I - num batch: 364
I - Train -- Loss: 4.267 | Acc: 32.812% | Wgt Acc: 30.959% | LR: 1.000000e-03 | Dur: 233.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 304.   34.   69.  280.  260.]
 [  29.  201.  292.   47.  779.]
 [  18.   89.  146.   20.  341.]
 [ 225.   43.   85.  190.  316.]
 [ 116.  301.  382.  181. 1067.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.504 | Acc: 32.500% | Wgt Acc: 38.075%
I - num batch: 87
I - Val -- Loss: 5.498 | Acc: 30.029% | Wgt Acc: 36.669% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [ 18. 202. 223.  36. 272.]
 [  0.   0.   0.   0.   0.]
 [162.  35.  31. 143.  86.]
 [ 19.  31.  36.  25.  73.]]

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 4.244 | Acc: 27.750% | Wgt Acc: 33.986%
	I - Batch: 100 | Loss: 4.181 | Acc: 28.938% | Wgt Acc: 33.496%
	I - Batch: 150 | Loss: 4.201 | Acc: 30.583% | Wgt Acc: 33.012%
	I - Batch: 200 | Loss: 4.208 | Acc: 33.594% | Wgt Acc: 32.260%
	I - Batch: 250 | Loss: 4.214 | Acc: 33.575% | Wgt Acc: 31.895%
	I - Batch: 300 | Loss: 4.239 | Acc: 35.042% | Wgt Acc: 31.650%
	I - Batch: 350 | Loss: 4.255 | Acc: 35.375% | Wgt Acc: 31.112%
I - num batch: 364
I - Train -- Loss: 4.258 | Acc: 35.856% | Wgt Acc: 31.171% | LR: 1.000000e-03 | Dur: 233.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 309.   25.   58.  270.  216.]
 [  13.  150.  221.   37.  567.]
 [  12.   73.  118.   23.  335.]
 [ 211.   66.   78.  198.  335.]
 [ 147.  354.  499.  190. 1310.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.119 | Acc: 26.500% | Wgt Acc: 16.260%
I - num batch: 87
I - Val -- Loss: 5.058 | Acc: 36.207% | Wgt Acc: 20.653% | Dur: 43.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 36.   0.   3.  26.   2.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 73.   4.   7.  59.  20.]
 [ 90. 264. 280. 119. 409.]]

I - Local maximum validation set accuracy:  36.21

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 4.239 | Acc: 38.000% | Wgt Acc: 29.370%
	I - Batch: 100 | Loss: 4.194 | Acc: 34.500% | Wgt Acc: 31.912%
	I - Batch: 150 | Loss: 4.240 | Acc: 34.208% | Wgt Acc: 32.400%
	I - Batch: 200 | Loss: 4.270 | Acc: 35.812% | Wgt Acc: 31.570%
	I - Batch: 250 | Loss: 4.268 | Acc: 36.750% | Wgt Acc: 31.605%
	I - Batch: 300 | Loss: 4.271 | Acc: 37.000% | Wgt Acc: 31.579%
	I - Batch: 350 | Loss: 4.279 | Acc: 36.125% | Wgt Acc: 31.753%
I - num batch: 364
I - Train -- Loss: 4.275 | Acc: 35.976% | Wgt Acc: 31.970% | LR: 1.000000e-03 | Dur: 233.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 360.   52.   83.  296.  314.]
 [  16.  119.  160.   25.  482.]
 [  19.  120.  193.   24.  418.]
 [ 176.   46.   75.  169.  298.]
 [ 121.  331.  463.  204. 1251.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.621 | Acc: 32.875% | Wgt Acc: 40.042%
I - num batch: 87
I - Val -- Loss: 5.595 | Acc: 29.885% | Wgt Acc: 37.765% | Dur: 43.07s
I - Confusion Matrix: [row->prediction - col->label]
[[139.  26.  35. 143.  70.]
 [ 22. 191. 201.  26. 263.]
 [ 15.  13.  28.  13.  35.]
 [  8.   9.   4.   7.  12.]
 [ 15.  29.  22.  15.  51.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 4.265 | Acc: 43.750% | Wgt Acc: 33.317%
	I - Batch: 100 | Loss: 4.294 | Acc: 40.625% | Wgt Acc: 32.033%
	I - Batch: 150 | Loss: 4.266 | Acc: 43.792% | Wgt Acc: 32.788%
	I - Batch: 200 | Loss: 4.243 | Acc: 42.469% | Wgt Acc: 33.103%
	I - Batch: 250 | Loss: 4.242 | Acc: 40.650% | Wgt Acc: 32.899%
	I - Batch: 300 | Loss: 4.235 | Acc: 38.542% | Wgt Acc: 32.764%
	I - Batch: 350 | Loss: 4.250 | Acc: 37.768% | Wgt Acc: 32.624%
I - num batch: 364
I - Train -- Loss: 4.253 | Acc: 37.506% | Wgt Acc: 32.522% | LR: 1.000000e-03 | Dur: 233.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 432.   51.   98.  370.  360.]
 [   4.   46.   68.    7.  178.]
 [  25.  188.  302.   54.  703.]
 [  97.   53.   44.   96.  217.]
 [ 134.  330.  462.  191. 1305.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.659 | Acc: 34.875% | Wgt Acc: 33.787%
I - num batch: 87
I - Val -- Loss: 5.661 | Acc: 33.190% | Wgt Acc: 33.889% | Dur: 42.38s
I - Confusion Matrix: [row->prediction - col->label]
[[159.  28.  42. 145.  95.]
 [  0.   0.   0.   0.   0.]
 [ 16. 192. 206.  28. 235.]
 [  3.   6.   5.   8.  12.]
 [ 21.  42.  37.  23.  89.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 4.225 | Acc: 44.000% | Wgt Acc: 35.390%
	I - Batch: 100 | Loss: 4.237 | Acc: 38.625% | Wgt Acc: 33.886%
	I - Batch: 150 | Loss: 4.254 | Acc: 38.917% | Wgt Acc: 32.956%
	I - Batch: 200 | Loss: 4.234 | Acc: 41.938% | Wgt Acc: 33.207%
	I - Batch: 250 | Loss: 4.247 | Acc: 43.125% | Wgt Acc: 32.941%
	I - Batch: 300 | Loss: 4.241 | Acc: 42.375% | Wgt Acc: 32.842%
	I - Batch: 350 | Loss: 4.248 | Acc: 40.589% | Wgt Acc: 32.626%
I - num batch: 364
I - Train -- Loss: 4.254 | Acc: 40.361% | Wgt Acc: 32.698% | LR: 1.000000e-03 | Dur: 229.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 409.   45.   68.  342.  300.]
 [  10.   81.  112.   17.  303.]
 [  12.   90.  146.   16.  343.]
 [ 109.   43.   71.  123.  229.]
 [ 152.  409.  577.  220. 1588.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.296 | Acc: 27.375% | Wgt Acc: 21.115%
I - num batch: 87
I - Val -- Loss: 5.271 | Acc: 34.626% | Wgt Acc: 24.928% | Dur: 42.38s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  48.  59. 162.  84.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 11.  10.  12.   3.  25.]
 [ 31. 210. 219.  39. 322.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 4.134 | Acc: 41.250% | Wgt Acc: 33.615%
	I - Batch: 100 | Loss: 4.151 | Acc: 42.312% | Wgt Acc: 32.877%
	I - Batch: 150 | Loss: 4.172 | Acc: 39.667% | Wgt Acc: 33.987%
	I - Batch: 200 | Loss: 4.197 | Acc: 37.375% | Wgt Acc: 33.363%
	I - Batch: 250 | Loss: 4.209 | Acc: 36.375% | Wgt Acc: 33.075%
	I - Batch: 300 | Loss: 4.211 | Acc: 36.083% | Wgt Acc: 33.511%
	I - Batch: 350 | Loss: 4.216 | Acc: 35.161% | Wgt Acc: 33.239%
I - num batch: 364
I - Train -- Loss: 4.216 | Acc: 35.116% | Wgt Acc: 33.142% | LR: 1.000000e-03 | Dur: 230.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 399.   39.   79.  350.  283.]
 [  20.  185.  246.   36.  632.]
 [  19.  139.  208.   25.  472.]
 [ 134.   45.   68.  126.  252.]
 [ 120.  260.  373.  181. 1124.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.280 | Acc: 26.625% | Wgt Acc: 19.047%
I - num batch: 87
I - Val -- Loss: 5.235 | Acc: 34.626% | Wgt Acc: 23.556% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [159.  25.  35. 149.  98.]
 [ 40. 243. 255.  55. 333.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 4.211 | Acc: 29.750% | Wgt Acc: 31.131%
	I - Batch: 100 | Loss: 4.225 | Acc: 32.875% | Wgt Acc: 31.142%
	I - Batch: 150 | Loss: 4.214 | Acc: 32.667% | Wgt Acc: 32.059%
	I - Batch: 200 | Loss: 4.235 | Acc: 31.750% | Wgt Acc: 32.142%
	I - Batch: 250 | Loss: 4.247 | Acc: 33.700% | Wgt Acc: 32.381%
	I - Batch: 300 | Loss: 4.232 | Acc: 35.917% | Wgt Acc: 32.538%
	I - Batch: 350 | Loss: 4.243 | Acc: 37.732% | Wgt Acc: 32.675%
I - num batch: 364
I - Train -- Loss: 4.246 | Acc: 37.902% | Wgt Acc: 32.635% | LR: 1.000000e-03 | Dur: 229.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 410.   53.   81.  346.  281.]
 [  23.  154.  223.   34.  563.]
 [  17.   85.   98.   11.  244.]
 [ 117.   35.   56.  127.  260.]
 [ 125.  341.  516.  200. 1415.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.498 | Acc: 25.500% | Wgt Acc: 22.716%
I - num batch: 87
I - Val -- Loss: 5.448 | Acc: 28.879% | Wgt Acc: 25.052% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[156.  59.  63. 166. 111.]
 [  0.   0.   0.   0.   0.]
 [  0.  46.  43.   2.  77.]
 [ 22.  22.  31.  11.  51.]
 [ 21. 141. 153.  25. 192.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 4.188 | Acc: 34.000% | Wgt Acc: 33.774%
	I - Batch: 100 | Loss: 4.239 | Acc: 31.500% | Wgt Acc: 32.727%
	I - Batch: 150 | Loss: 4.247 | Acc: 31.333% | Wgt Acc: 31.904%
	I - Batch: 200 | Loss: 4.231 | Acc: 36.250% | Wgt Acc: 32.609%
	I - Batch: 250 | Loss: 4.224 | Acc: 38.350% | Wgt Acc: 33.058%
	I - Batch: 300 | Loss: 4.228 | Acc: 36.667% | Wgt Acc: 33.008%
	I - Batch: 350 | Loss: 4.233 | Acc: 36.214% | Wgt Acc: 33.257%
I - num batch: 364
I - Train -- Loss: 4.245 | Acc: 36.045% | Wgt Acc: 33.101% | LR: 1.000000e-03 | Dur: 230.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 452.   39.   99.  365.  347.]
 [  18.  154.  234.   26.  518.]
 [  18.   97.  165.   24.  419.]
 [  80.   36.   60.  108.  262.]
 [ 124.  342.  416.  195. 1217.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.162 | Acc: 24.250% | Wgt Acc: 12.635%
I - num batch: 87
I - Val -- Loss: 5.134 | Acc: 34.698% | Wgt Acc: 17.483% | Dur: 42.27s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 80.   2.   5.  59.   7.]
 [119. 266. 285. 145. 424.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 4.136 | Acc: 37.125% | Wgt Acc: 34.256%
	I - Batch: 100 | Loss: 4.166 | Acc: 35.000% | Wgt Acc: 33.897%
	I - Batch: 150 | Loss: 4.143 | Acc: 33.667% | Wgt Acc: 33.388%
	I - Batch: 200 | Loss: 4.170 | Acc: 32.438% | Wgt Acc: 33.871%
	I - Batch: 250 | Loss: 4.188 | Acc: 32.875% | Wgt Acc: 33.890%
	I - Batch: 300 | Loss: 4.201 | Acc: 32.729% | Wgt Acc: 33.518%
	I - Batch: 350 | Loss: 4.210 | Acc: 34.946% | Wgt Acc: 33.899%
I - num batch: 364
I - Train -- Loss: 4.216 | Acc: 35.271% | Wgt Acc: 33.699% | LR: 1.000000e-03 | Dur: 229.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.   49.   87.  385.  377.]
 [  14.  191.  264.   35.  623.]
 [  17.  121.  177.   27.  405.]
 [  81.   34.   57.   97.  235.]
 [ 117.  273.  389.  174. 1123.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.387 | Acc: 26.250% | Wgt Acc: 19.709%
I - num batch: 87
I - Val -- Loss: 5.337 | Acc: 34.052% | Wgt Acc: 23.939% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   6.  13. 120.  47.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 35.  22.  36.  33.  61.]
 [ 46. 240. 241.  51. 323.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 4.142 | Acc: 51.750% | Wgt Acc: 34.745%
	I - Batch: 100 | Loss: 4.158 | Acc: 49.375% | Wgt Acc: 34.685%
	I - Batch: 150 | Loss: 4.154 | Acc: 49.000% | Wgt Acc: 34.236%
	I - Batch: 200 | Loss: 4.171 | Acc: 48.156% | Wgt Acc: 33.642%
	I - Batch: 250 | Loss: 4.169 | Acc: 45.450% | Wgt Acc: 33.655%
	I - Batch: 300 | Loss: 4.161 | Acc: 43.500% | Wgt Acc: 33.990%
	I - Batch: 350 | Loss: 4.177 | Acc: 42.214% | Wgt Acc: 33.451%
I - num batch: 364
I - Train -- Loss: 4.176 | Acc: 41.978% | Wgt Acc: 33.327% | LR: 5.000000e-04 | Dur: 229.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 424.   29.   62.  349.  288.]
 [   9.  153.  225.   26.  489.]
 [   0.    7.    5.    2.   17.]
 [  94.   38.   69.  112.  222.]
 [ 165.  441.  613.  229. 1747.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.589 | Acc: 35.375% | Wgt Acc: 42.084%
I - num batch: 87
I - Val -- Loss: 5.580 | Acc: 32.615% | Wgt Acc: 40.070% | Dur: 41.73s
I - Confusion Matrix: [row->prediction - col->label]
[[141.  12.  29. 123.  46.]
 [ 16. 211. 225.  29. 288.]
 [  0.   0.   0.   0.   0.]
 [ 11.   9.   5.  19.  14.]
 [ 31.  36.  31.  33.  83.]]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 4.169 | Acc: 33.250% | Wgt Acc: 33.717%
	I - Batch: 100 | Loss: 4.214 | Acc: 32.062% | Wgt Acc: 33.371%
	I - Batch: 150 | Loss: 4.177 | Acc: 32.042% | Wgt Acc: 33.450%
	I - Batch: 200 | Loss: 4.168 | Acc: 33.406% | Wgt Acc: 33.932%
	I - Batch: 250 | Loss: 4.164 | Acc: 35.800% | Wgt Acc: 33.845%
	I - Batch: 300 | Loss: 4.152 | Acc: 37.021% | Wgt Acc: 34.484%
	I - Batch: 350 | Loss: 4.158 | Acc: 37.411% | Wgt Acc: 34.146%
I - num batch: 364
I - Train -- Loss: 4.147 | Acc: 37.644% | Wgt Acc: 34.333% | LR: 5.000000e-04 | Dur: 228.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 501.   47.   77.  389.  347.]
 [  14.  119.  192.   20.  376.]
 [  11.  169.  238.   24.  593.]
 [  59.   32.   45.   74.  190.]
 [ 107.  301.  422.  211. 1257.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.477 | Acc: 36.750% | Wgt Acc: 39.474%
I - num batch: 87
I - Val -- Loss: 5.455 | Acc: 36.063% | Wgt Acc: 38.922% | Dur: 41.79s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   8.  14. 125.  30.]
 [  8. 168. 157.  18. 176.]
 [  3.  27.  43.   9.  66.]
 [ 13.   6.  15.  11.  12.]
 [ 42.  59.  61.  41. 147.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 4.141 | Acc: 36.500% | Wgt Acc: 34.655%
	I - Batch: 100 | Loss: 4.146 | Acc: 39.125% | Wgt Acc: 36.491%
	I - Batch: 150 | Loss: 4.139 | Acc: 38.875% | Wgt Acc: 35.998%
	I - Batch: 200 | Loss: 4.156 | Acc: 38.219% | Wgt Acc: 35.955%
	I - Batch: 250 | Loss: 4.147 | Acc: 37.500% | Wgt Acc: 36.007%
	I - Batch: 300 | Loss: 4.157 | Acc: 36.667% | Wgt Acc: 35.202%
	I - Batch: 350 | Loss: 4.155 | Acc: 37.161% | Wgt Acc: 35.299%
I - num batch: 364
I - Train -- Loss: 4.154 | Acc: 37.008% | Wgt Acc: 35.169% | LR: 5.000000e-04 | Dur: 228.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 441.   26.   57.  336.  251.]
 [   6.  112.  157.   14.  363.]
 [  22.  233.  325.   43.  731.]
 [  97.   42.   53.  148.  292.]
 [ 126.  255.  382.  177. 1126.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.488 | Acc: 35.375% | Wgt Acc: 33.882%
I - num batch: 87
I - Val -- Loss: 5.443 | Acc: 35.273% | Wgt Acc: 34.021% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[155.  28.  39. 141.  60.]
 [  0.   0.   0.   0.   0.]
 [  4. 173. 177.  13. 197.]
 [ 10.  14.   9.  21.  36.]
 [ 30.  53.  65.  29. 138.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 4.079 | Acc: 38.250% | Wgt Acc: 36.457%
	I - Batch: 100 | Loss: 4.092 | Acc: 38.938% | Wgt Acc: 37.120%
	I - Batch: 150 | Loss: 4.091 | Acc: 40.208% | Wgt Acc: 35.488%
	I - Batch: 200 | Loss: 4.130 | Acc: 38.875% | Wgt Acc: 34.325%
	I - Batch: 250 | Loss: 4.137 | Acc: 37.500% | Wgt Acc: 34.692%
	I - Batch: 300 | Loss: 4.141 | Acc: 37.354% | Wgt Acc: 34.906%
	I - Batch: 350 | Loss: 4.147 | Acc: 37.625% | Wgt Acc: 34.912%
I - num batch: 364
I - Train -- Loss: 4.147 | Acc: 37.902% | Wgt Acc: 34.809% | LR: 5.000000e-04 | Dur: 228.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 460.   22.   67.  373.  319.]
 [  10.  151.  210.   19.  435.]
 [   9.  135.  237.   25.  519.]
 [  79.   39.   62.  101.  235.]
 [ 134.  321.  398.  200. 1255.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.604 | Acc: 33.375% | Wgt Acc: 40.559%
I - num batch: 87
I - Val -- Loss: 5.636 | Acc: 30.388% | Wgt Acc: 38.327% | Dur: 41.79s
I - Confusion Matrix: [row->prediction - col->label]
[[126.  16.  15. 105.  33.]
 [ 29. 219. 240.  44. 319.]
 [  0.   0.   0.   0.   0.]
 [ 14.   6.   7.  13.  14.]
 [ 30.  27.  28.  42.  65.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 4.174 | Acc: 38.500% | Wgt Acc: 34.309%
	I - Batch: 100 | Loss: 4.159 | Acc: 38.500% | Wgt Acc: 35.463%
	I - Batch: 150 | Loss: 4.192 | Acc: 41.042% | Wgt Acc: 34.783%
	I - Batch: 200 | Loss: 4.196 | Acc: 41.344% | Wgt Acc: 34.011%
	I - Batch: 250 | Loss: 4.183 | Acc: 39.900% | Wgt Acc: 34.290%
	I - Batch: 300 | Loss: 4.169 | Acc: 39.500% | Wgt Acc: 34.245%
	I - Batch: 350 | Loss: 4.169 | Acc: 40.571% | Wgt Acc: 34.348%
I - num batch: 364
I - Train -- Loss: 4.162 | Acc: 40.688% | Wgt Acc: 34.251% | LR: 5.000000e-04 | Dur: 229.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 494.   51.   79.  394.  342.]
 [   5.   91.  142.   21.  321.]
 [  11.  114.  174.   16.  383.]
 [  51.   26.   37.   77.  187.]
 [ 131.  386.  542.  210. 1530.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.484 | Acc: 36.500% | Wgt Acc: 39.279%
I - num batch: 87
I - Val -- Loss: 5.465 | Acc: 36.997% | Wgt Acc: 39.408% | Dur: 42.27s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   7.  17. 122.  38.]
 [  8. 181. 180.  17. 189.]
 [  0.   0.   0.   0.   0.]
 [ 16.  12.  14.  24.  29.]
 [ 40.  68.  79.  41. 175.]]

I - Local maximum validation set accuracy:  37.00

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 4.183 | Acc: 39.500% | Wgt Acc: 32.470%
	I - Batch: 100 | Loss: 4.151 | Acc: 39.312% | Wgt Acc: 33.752%
	I - Batch: 150 | Loss: 4.137 | Acc: 38.750% | Wgt Acc: 33.230%
	I - Batch: 200 | Loss: 4.154 | Acc: 37.531% | Wgt Acc: 32.970%
	I - Batch: 250 | Loss: 4.176 | Acc: 38.525% | Wgt Acc: 33.482%
	I - Batch: 300 | Loss: 4.161 | Acc: 38.917% | Wgt Acc: 33.656%
	I - Batch: 350 | Loss: 4.151 | Acc: 38.518% | Wgt Acc: 33.921%
I - num batch: 364
I - Train -- Loss: 4.149 | Acc: 38.280% | Wgt Acc: 33.996% | LR: 5.000000e-04 | Dur: 230.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 475.   30.   76.  372.  347.]
 [  16.  230.  384.   32.  817.]
 [   0.    1.    1.    0.    1.]
 [  76.   38.   61.   98.  176.]
 [ 125.  369.  452.  216. 1422.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.525 | Acc: 34.250% | Wgt Acc: 40.723%
I - num batch: 87
I - Val -- Loss: 5.518 | Acc: 32.687% | Wgt Acc: 39.863% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[140.  10.  19. 138.  47.]
 [ 20. 216. 219.  30. 275.]
 [  0.   0.   0.   0.   0.]
 [ 17.   8.  11.  11.  21.]
 [ 22.  34.  41.  25.  88.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 4.181 | Acc: 37.000% | Wgt Acc: 32.973%
	I - Batch: 100 | Loss: 4.175 | Acc: 36.375% | Wgt Acc: 32.335%
	I - Batch: 150 | Loss: 4.168 | Acc: 34.833% | Wgt Acc: 32.910%
	I - Batch: 200 | Loss: 4.125 | Acc: 34.375% | Wgt Acc: 33.543%
	I - Batch: 250 | Loss: 4.136 | Acc: 34.325% | Wgt Acc: 33.694%
	I - Batch: 300 | Loss: 4.133 | Acc: 34.792% | Wgt Acc: 34.056%
	I - Batch: 350 | Loss: 4.136 | Acc: 35.089% | Wgt Acc: 34.173%
I - num batch: 364
I - Train -- Loss: 4.136 | Acc: 35.133% | Wgt Acc: 34.328% | LR: 5.000000e-04 | Dur: 232.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 459.   36.   66.  386.  315.]
 [  15.  224.  320.   34.  757.]
 [   9.  118.  170.   13.  372.]
 [ 100.   46.   52.  105.  234.]
 [ 109.  244.  366.  180. 1085.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.618 | Acc: 33.375% | Wgt Acc: 32.898%
I - num batch: 87
I - Val -- Loss: 5.565 | Acc: 31.968% | Wgt Acc: 32.896% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[166.  42.  44. 160.  94.]
 [  0.   0.   0.   0.   0.]
 [  8. 163. 175.   9. 190.]
 [ 17.  21.  22.  13.  56.]
 [  8.  42.  49.  22.  91.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 4.172 | Acc: 39.625% | Wgt Acc: 32.083%
	I - Batch: 100 | Loss: 4.149 | Acc: 39.562% | Wgt Acc: 32.139%
	I - Batch: 150 | Loss: 4.138 | Acc: 38.958% | Wgt Acc: 32.911%
	I - Batch: 200 | Loss: 4.157 | Acc: 37.688% | Wgt Acc: 33.020%
	I - Batch: 250 | Loss: 4.149 | Acc: 37.050% | Wgt Acc: 32.949%
	I - Batch: 300 | Loss: 4.148 | Acc: 36.917% | Wgt Acc: 33.500%
	I - Batch: 350 | Loss: 4.166 | Acc: 37.304% | Wgt Acc: 33.522%
I - num batch: 364
I - Train -- Loss: 4.165 | Acc: 37.799% | Wgt Acc: 33.604% | LR: 5.000000e-04 | Dur: 232.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 378.   28.   69.  303.  258.]
 [  11.  161.  246.   24.  583.]
 [   7.  113.  143.   12.  285.]
 [ 182.   44.   86.  177.  298.]
 [ 114.  322.  430.  202. 1339.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.503 | Acc: 30.000% | Wgt Acc: 29.462%
I - num batch: 87
I - Val -- Loss: 5.446 | Acc: 32.112% | Wgt Acc: 30.595% | Dur: 42.39s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  37.  48. 160.  89.]
 [  2.  85. 104.   2. 120.]
 [  0.   0.   0.   0.   0.]
 [ 10.  14.  12.   6.  23.]
 [ 30. 132. 126.  36. 199.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 4.072 | Acc: 49.250% | Wgt Acc: 34.656%
	I - Batch: 100 | Loss: 4.059 | Acc: 48.500% | Wgt Acc: 33.963%
	I - Batch: 150 | Loss: 4.083 | Acc: 46.458% | Wgt Acc: 33.493%
	I - Batch: 200 | Loss: 4.097 | Acc: 43.094% | Wgt Acc: 33.525%
	I - Batch: 250 | Loss: 4.105 | Acc: 40.875% | Wgt Acc: 33.418%
	I - Batch: 300 | Loss: 4.123 | Acc: 40.917% | Wgt Acc: 33.146%
	I - Batch: 350 | Loss: 4.127 | Acc: 41.536% | Wgt Acc: 33.102%
I - num batch: 364
I - Train -- Loss: 4.121 | Acc: 41.496% | Wgt Acc: 33.153% | LR: 5.000000e-04 | Dur: 231.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 464.   31.   71.  399.  326.]
 [   9.  139.  218.   25.  518.]
 [   0.    0.    0.    0.    0.]
 [  85.   33.   55.   91.  200.]
 [ 134.  465.  630.  203. 1719.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.566 | Acc: 34.750% | Wgt Acc: 41.902%
I - num batch: 87
I - Val -- Loss: 5.562 | Acc: 31.537% | Wgt Acc: 39.835% | Dur: 42.65s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   6.  11.  90.  25.]
 [ 26. 235. 248.  45. 326.]
 [  0.   0.   0.   0.   0.]
 [ 13.   6.   7.  15.  13.]
 [ 38.  21.  24.  54.  67.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 4.135 | Acc: 35.125% | Wgt Acc: 34.839%
	I - Batch: 100 | Loss: 4.167 | Acc: 36.438% | Wgt Acc: 33.616%
	I - Batch: 150 | Loss: 4.162 | Acc: 39.625% | Wgt Acc: 32.969%
	I - Batch: 200 | Loss: 4.161 | Acc: 41.688% | Wgt Acc: 33.469%
	I - Batch: 250 | Loss: 4.167 | Acc: 41.300% | Wgt Acc: 33.367%
	I - Batch: 300 | Loss: 4.156 | Acc: 40.354% | Wgt Acc: 34.140%
	I - Batch: 350 | Loss: 4.158 | Acc: 39.500% | Wgt Acc: 34.286%
I - num batch: 364
I - Train -- Loss: 4.156 | Acc: 39.604% | Wgt Acc: 34.452% | LR: 5.000000e-04 | Dur: 231.96s
I - Confusion Matrix: [row->prediction - col->label]
[[ 452.   30.   70.  368.  288.]
 [  12.  202.  273.   30.  581.]
 [   8.   44.   64.   12.  170.]
 [  93.   27.   53.  105.  244.]
 [ 127.  365.  514.  203. 1480.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.496 | Acc: 33.125% | Wgt Acc: 36.555%
I - num batch: 87
I - Val -- Loss: 5.458 | Acc: 33.764% | Wgt Acc: 36.760% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[144.  18.  25. 133.  62.]
 [  3. 133. 140.  10. 156.]
 [  9.  41.  55.  10.  72.]
 [  9.   7.   8.  12.  15.]
 [ 34.  69.  62.  39. 126.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 4.179 | Acc: 35.250% | Wgt Acc: 35.715%
	I - Batch: 100 | Loss: 4.135 | Acc: 36.250% | Wgt Acc: 36.767%
	I - Batch: 150 | Loss: 4.085 | Acc: 37.542% | Wgt Acc: 37.322%
	I - Batch: 200 | Loss: 4.093 | Acc: 37.219% | Wgt Acc: 36.630%
	I - Batch: 250 | Loss: 4.109 | Acc: 36.675% | Wgt Acc: 35.740%
	I - Batch: 300 | Loss: 4.095 | Acc: 36.312% | Wgt Acc: 35.551%
	I - Batch: 350 | Loss: 4.097 | Acc: 36.429% | Wgt Acc: 35.377%
I - num batch: 364
I - Train -- Loss: 4.095 | Acc: 36.268% | Wgt Acc: 35.316% | LR: 2.500000e-04 | Dur: 232.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 527.   34.   79.  411.  362.]
 [   4.   59.   89.   10.  239.]
 [  23.  341.  451.   53. 1001.]
 [  35.   15.   32.   60.  149.]
 [ 103.  219.  323.  184. 1012.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.612 | Acc: 35.125% | Wgt Acc: 40.426%
I - num batch: 87
I - Val -- Loss: 5.584 | Acc: 32.759% | Wgt Acc: 38.782% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[144.  19.  33. 147.  64.]
 [ 15. 195. 202.  23. 238.]
 [  2.   4.   6.   1.  11.]
 [ 10.  13.   8.  10.  17.]
 [ 28.  37.  41.  23. 101.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 4.100 | Acc: 36.500% | Wgt Acc: 36.354%
	I - Batch: 100 | Loss: 4.118 | Acc: 36.188% | Wgt Acc: 36.214%
	I - Batch: 150 | Loss: 4.126 | Acc: 36.875% | Wgt Acc: 36.164%
	I - Batch: 200 | Loss: 4.139 | Acc: 38.938% | Wgt Acc: 35.944%
	I - Batch: 250 | Loss: 4.121 | Acc: 39.825% | Wgt Acc: 35.063%
	I - Batch: 300 | Loss: 4.108 | Acc: 40.292% | Wgt Acc: 35.227%
	I - Batch: 350 | Loss: 4.111 | Acc: 40.232% | Wgt Acc: 34.867%
I - num batch: 364
I - Train -- Loss: 4.108 | Acc: 40.206% | Wgt Acc: 34.859% | LR: 2.500000e-04 | Dur: 232.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 492.   29.   70.  408.  331.]
 [   5.   99.  150.   10.  283.]
 [  13.  158.  255.   26.  529.]
 [  54.   21.   47.   61.  189.]
 [ 128.  361.  452.  213. 1431.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.532 | Acc: 35.000% | Wgt Acc: 38.112%
I - num batch: 87
I - Val -- Loss: 5.490 | Acc: 35.920% | Wgt Acc: 38.268% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[153.  14.  32. 137.  52.]
 [  4. 161. 167.   9. 170.]
 [  1.   1.   1.   0.   2.]
 [ 15.  21.  11.  16.  38.]
 [ 26.  71.  79.  42. 169.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 4.030 | Acc: 36.875% | Wgt Acc: 35.196%
	I - Batch: 100 | Loss: 4.083 | Acc: 36.562% | Wgt Acc: 35.202%
	I - Batch: 150 | Loss: 4.085 | Acc: 37.833% | Wgt Acc: 35.652%
	I - Batch: 200 | Loss: 4.086 | Acc: 38.062% | Wgt Acc: 35.196%
	I - Batch: 250 | Loss: 4.074 | Acc: 38.550% | Wgt Acc: 35.220%
	I - Batch: 300 | Loss: 4.092 | Acc: 38.938% | Wgt Acc: 35.016%
	I - Batch: 350 | Loss: 4.099 | Acc: 38.964% | Wgt Acc: 34.699%
I - num batch: 364
I - Train -- Loss: 4.096 | Acc: 38.951% | Wgt Acc: 34.768% | LR: 2.500000e-04 | Dur: 232.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 468.   28.   66.  376.  338.]
 [   6.   64.  119.    9.  203.]
 [  10.  256.  312.   30.  670.]
 [  88.   27.   57.  114.  245.]
 [ 120.  293.  420.  189. 1307.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.813 | Acc: 25.750% | Wgt Acc: 29.248%
I - num batch: 87
I - Val -- Loss: 5.758 | Acc: 24.425% | Wgt Acc: 28.856% | Dur: 42.77s
I - Confusion Matrix: [row->prediction - col->label]
[[190.  99. 125. 188. 218.]
 [  2.  53.  78.   1.  80.]
 [  0.  22.  22.   1.  21.]
 [  5.  32.  21.  11.  48.]
 [  2.  62.  44.   3.  64.]]

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 4.195 | Acc: 34.500% | Wgt Acc: 32.392%
	I - Batch: 100 | Loss: 4.141 | Acc: 38.438% | Wgt Acc: 34.846%
	I - Batch: 150 | Loss: 4.121 | Acc: 38.250% | Wgt Acc: 34.886%
	I - Batch: 200 | Loss: 4.111 | Acc: 36.688% | Wgt Acc: 34.896%
	I - Batch: 250 | Loss: 4.095 | Acc: 35.675% | Wgt Acc: 35.064%
	I - Batch: 300 | Loss: 4.104 | Acc: 35.104% | Wgt Acc: 34.744%
	I - Batch: 350 | Loss: 4.109 | Acc: 36.500% | Wgt Acc: 34.907%
I - num batch: 364
I - Train -- Loss: 4.100 | Acc: 36.870% | Wgt Acc: 35.280% | LR: 2.500000e-04 | Dur: 232.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 473.   24.   63.  377.  272.]
 [  19.  242.  328.   27.  693.]
 [   6.   99.  127.   21.  292.]
 [  87.   32.   68.  106.  310.]
 [ 107.  271.  388.  187. 1196.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.528 | Acc: 35.375% | Wgt Acc: 40.811%
I - num batch: 87
I - Val -- Loss: 5.517 | Acc: 32.974% | Wgt Acc: 38.997% | Dur: 42.81s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   7.  11.  98.  18.]
 [ 15. 205. 224.  28. 298.]
 [  0.   0.   0.   0.   0.]
 [ 25.  10.   7.  29.  11.]
 [ 38.  46.  48.  49. 104.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 4.052 | Acc: 36.250% | Wgt Acc: 35.625%
	I - Batch: 100 | Loss: 4.082 | Acc: 37.375% | Wgt Acc: 34.690%
	I - Batch: 150 | Loss: 4.063 | Acc: 39.792% | Wgt Acc: 34.688%
	I - Batch: 200 | Loss: 4.043 | Acc: 40.344% | Wgt Acc: 35.460%
	I - Batch: 250 | Loss: 4.052 | Acc: 40.375% | Wgt Acc: 34.875%
	I - Batch: 300 | Loss: 4.059 | Acc: 39.958% | Wgt Acc: 35.037%
	I - Batch: 350 | Loss: 4.067 | Acc: 39.446% | Wgt Acc: 34.670%
I - num batch: 364
I - Train -- Loss: 4.070 | Acc: 39.243% | Wgt Acc: 34.613% | LR: 2.500000e-04 | Dur: 232.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 492.   26.   61.  390.  289.]
 [  16.  198.  316.   20.  654.]
 [   1.   51.   55.    6.  113.]
 [  71.   37.   55.   90.  260.]
 [ 112.  356.  487.  212. 1447.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.427 | Acc: 28.750% | Wgt Acc: 21.852%
I - num batch: 87
I - Val -- Loss: 5.360 | Acc: 35.417% | Wgt Acc: 25.367% | Dur: 42.83s
I - Confusion Matrix: [row->prediction - col->label]
[[139.  13.  23. 136.  55.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 28.  23.  27.  24.  46.]
 [ 32. 232. 240.  44. 330.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 4.040 | Acc: 36.875% | Wgt Acc: 34.001%
	I - Batch: 100 | Loss: 4.005 | Acc: 39.312% | Wgt Acc: 34.664%
	I - Batch: 150 | Loss: 4.048 | Acc: 39.583% | Wgt Acc: 34.159%
	I - Batch: 200 | Loss: 4.031 | Acc: 40.656% | Wgt Acc: 34.231%
	I - Batch: 250 | Loss: 4.044 | Acc: 41.100% | Wgt Acc: 34.379%
	I - Batch: 300 | Loss: 4.043 | Acc: 41.125% | Wgt Acc: 34.617%
	I - Batch: 350 | Loss: 4.036 | Acc: 41.214% | Wgt Acc: 34.817%
I - num batch: 364
I - Train -- Loss: 4.038 | Acc: 41.341% | Wgt Acc: 34.815% | LR: 1.250000e-04 | Dur: 233.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 503.   31.   64.  415.  347.]
 [   1.   25.   46.    6.   83.]
 [   7.  224.  276.   16.  584.]
 [  79.   29.   51.   89.  238.]
 [ 102.  359.  537.  192. 1511.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.406 | Acc: 29.375% | Wgt Acc: 23.422%
I - num batch: 87
I - Val -- Loss: 5.323 | Acc: 35.560% | Wgt Acc: 26.767% | Dur: 42.75s
I - Confusion Matrix: [row->prediction - col->label]
[[153.  10.  26. 138.  57.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 28.  21.  28.  29.  61.]
 [ 18. 237. 236.  37. 313.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 3.983 | Acc: 46.500% | Wgt Acc: 36.084%
	I - Batch: 100 | Loss: 3.993 | Acc: 46.562% | Wgt Acc: 36.128%
	I - Batch: 150 | Loss: 3.964 | Acc: 47.083% | Wgt Acc: 35.979%
	I - Batch: 200 | Loss: 3.985 | Acc: 47.062% | Wgt Acc: 35.760%
	I - Batch: 250 | Loss: 3.977 | Acc: 46.925% | Wgt Acc: 35.718%
	I - Batch: 300 | Loss: 3.985 | Acc: 46.812% | Wgt Acc: 36.028%
	I - Batch: 350 | Loss: 3.990 | Acc: 46.911% | Wgt Acc: 35.814%
I - num batch: 364
I - Train -- Loss: 3.992 | Acc: 46.948% | Wgt Acc: 35.741% | LR: 1.250000e-04 | Dur: 233.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 473.   18.   48.  369.  252.]
 [   2.   38.   54.    1.   63.]
 [   2.   85.   88.   11.  126.]
 [ 109.   37.   60.  142.  333.]
 [ 106.  490.  724.  195. 1989.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.255 | Acc: 26.000% | Wgt Acc: 16.147%
I - num batch: 87
I - Val -- Loss: 5.184 | Acc: 36.135% | Wgt Acc: 21.363% | Dur: 42.77s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [140.   4.  15. 108.  36.]
 [ 59. 264. 275.  96. 395.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 4.018 | Acc: 47.125% | Wgt Acc: 33.590%
	I - Batch: 100 | Loss: 3.970 | Acc: 46.875% | Wgt Acc: 35.735%
	I - Batch: 150 | Loss: 3.992 | Acc: 46.583% | Wgt Acc: 36.456%
	I - Batch: 200 | Loss: 3.998 | Acc: 45.156% | Wgt Acc: 36.688%
	I - Batch: 250 | Loss: 4.006 | Acc: 45.225% | Wgt Acc: 36.806%
	I - Batch: 300 | Loss: 4.004 | Acc: 45.396% | Wgt Acc: 36.988%
	I - Batch: 350 | Loss: 3.995 | Acc: 45.929% | Wgt Acc: 37.596%
I - num batch: 364
I - Train -- Loss: 3.995 | Acc: 46.088% | Wgt Acc: 37.696% | LR: 1.250000e-04 | Dur: 232.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 472.   16.   37.  347.  242.]
 [   2.   56.   72.    7.  102.]
 [   6.  204.  259.   17.  387.]
 [  99.   26.   59.  135.  274.]
 [ 113.  366.  547.  212. 1758.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.474 | Acc: 33.750% | Wgt Acc: 29.922%
I - num batch: 87
I - Val -- Loss: 5.410 | Acc: 40.158% | Wgt Acc: 33.267% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[153.  10.  21. 129.  53.]
 [  0.  64.  60.   0.  27.]
 [  0.   0.   0.   0.   0.]
 [ 17.  10.  16.  27.  36.]
 [ 29. 184. 193.  48. 315.]]

I - Local maximum validation set accuracy:  40.16

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 4.044 | Acc: 47.875% | Wgt Acc: 37.917%
	I - Batch: 100 | Loss: 4.018 | Acc: 46.625% | Wgt Acc: 37.804%
	I - Batch: 150 | Loss: 3.960 | Acc: 46.542% | Wgt Acc: 38.194%
	I - Batch: 200 | Loss: 3.977 | Acc: 47.406% | Wgt Acc: 38.672%
	I - Batch: 250 | Loss: 3.996 | Acc: 47.225% | Wgt Acc: 37.410%
	I - Batch: 300 | Loss: 3.982 | Acc: 47.646% | Wgt Acc: 37.048%
	I - Batch: 350 | Loss: 3.982 | Acc: 47.679% | Wgt Acc: 36.889%
I - num batch: 364
I - Train -- Loss: 3.989 | Acc: 47.532% | Wgt Acc: 36.733% | LR: 1.250000e-04 | Dur: 232.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.   13.   37.  363.  251.]
 [   3.  131.  160.    8.  142.]
 [   0.   21.   13.    1.   27.]
 [ 109.   37.   57.  135.  321.]
 [ 117.  466.  707.  211. 2022.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.398 | Acc: 27.000% | Wgt Acc: 19.608%
I - num batch: 87
I - Val -- Loss: 5.313 | Acc: 35.345% | Wgt Acc: 24.242% | Dur: 42.82s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [163.  11.  44. 155.  94.]
 [ 36. 257. 246.  49. 337.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 3.939 | Acc: 49.000% | Wgt Acc: 36.018%
	I - Batch: 100 | Loss: 3.928 | Acc: 49.812% | Wgt Acc: 37.115%
	I - Batch: 150 | Loss: 3.925 | Acc: 49.542% | Wgt Acc: 36.500%
	I - Batch: 200 | Loss: 3.938 | Acc: 48.812% | Wgt Acc: 35.854%
	I - Batch: 250 | Loss: 3.930 | Acc: 48.750% | Wgt Acc: 35.543%
	I - Batch: 300 | Loss: 3.940 | Acc: 49.312% | Wgt Acc: 35.844%
	I - Batch: 350 | Loss: 3.949 | Acc: 49.411% | Wgt Acc: 35.693%
I - num batch: 364
I - Train -- Loss: 3.962 | Acc: 49.304% | Wgt Acc: 35.496% | LR: 1.250000e-04 | Dur: 233.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 421.   10.   29.  315.  183.]
 [   0.   19.   26.    1.   15.]
 [   0.   53.   65.    2.   50.]
 [ 149.   28.   54.  164.  317.]
 [ 122.  558.  800.  236. 2198.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.393 | Acc: 26.750% | Wgt Acc: 17.483%
I - num batch: 87
I - Val -- Loss: 5.305 | Acc: 36.566% | Wgt Acc: 22.819% | Dur: 42.77s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [150.  14.  22. 127.  49.]
 [ 49. 254. 268.  77. 382.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 3.954 | Acc: 46.375% | Wgt Acc: 32.066%
	I - Batch: 100 | Loss: 3.960 | Acc: 47.625% | Wgt Acc: 34.157%
	I - Batch: 150 | Loss: 3.970 | Acc: 48.167% | Wgt Acc: 34.851%
	I - Batch: 200 | Loss: 3.943 | Acc: 48.688% | Wgt Acc: 35.223%
	I - Batch: 250 | Loss: 3.941 | Acc: 49.775% | Wgt Acc: 35.997%
	I - Batch: 300 | Loss: 3.942 | Acc: 49.542% | Wgt Acc: 35.697%
	I - Batch: 350 | Loss: 3.948 | Acc: 48.929% | Wgt Acc: 35.197%
I - num batch: 364
I - Train -- Loss: 3.948 | Acc: 48.994% | Wgt Acc: 35.204% | LR: 1.250000e-04 | Dur: 232.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 426.   12.   33.  304.  188.]
 [   0.   14.   23.    0.   17.]
 [   1.    9.    7.    3.    9.]
 [ 168.   27.   69.  194.  341.]
 [  97.  606.  842.  217. 2208.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.425 | Acc: 29.500% | Wgt Acc: 21.606%
I - num batch: 87
I - Val -- Loss: 5.342 | Acc: 38.218% | Wgt Acc: 25.730% | Dur: 42.90s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   0.   7.  88.  19.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 48.   6.  20.  44.  34.]
 [ 41. 262. 263.  72. 378.]]

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 3.921 | Acc: 51.625% | Wgt Acc: 37.587%
	I - Batch: 100 | Loss: 3.909 | Acc: 49.938% | Wgt Acc: 36.063%
	I - Batch: 150 | Loss: 3.896 | Acc: 50.625% | Wgt Acc: 36.814%
	I - Batch: 200 | Loss: 3.897 | Acc: 50.188% | Wgt Acc: 36.574%
	I - Batch: 250 | Loss: 3.905 | Acc: 49.400% | Wgt Acc: 36.110%
	I - Batch: 300 | Loss: 3.903 | Acc: 49.917% | Wgt Acc: 36.245%
	I - Batch: 350 | Loss: 3.896 | Acc: 50.018% | Wgt Acc: 36.325%
I - num batch: 364
I - Train -- Loss: 3.898 | Acc: 49.957% | Wgt Acc: 36.290% | LR: 1.250000e-04 | Dur: 233.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 413.    8.   33.  317.  157.]
 [   1.   48.   54.    1.   23.]
 [   0.   30.   37.    2.   22.]
 [ 157.   17.   59.  184.  338.]
 [ 121.  565.  791.  214. 2223.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.653 | Acc: 35.250% | Wgt Acc: 35.370%
I - num batch: 87
I - Val -- Loss: 5.569 | Acc: 38.003% | Wgt Acc: 35.907% | Dur: 43.03s
I - Confusion Matrix: [row->prediction - col->label]
[[162.  12.  35. 150.  80.]
 [  1. 103. 104.   1.  33.]
 [  0.  10.   8.   3.  13.]
 [ 24.  32.  28.  20.  69.]
 [ 12. 111. 115.  30. 236.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 3.985 | Acc: 49.875% | Wgt Acc: 35.881%
	I - Batch: 100 | Loss: 3.961 | Acc: 48.875% | Wgt Acc: 35.299%
	I - Batch: 150 | Loss: 3.957 | Acc: 47.875% | Wgt Acc: 34.577%
	I - Batch: 200 | Loss: 3.946 | Acc: 48.469% | Wgt Acc: 34.974%
	I - Batch: 250 | Loss: 3.931 | Acc: 48.300% | Wgt Acc: 34.404%
	I - Batch: 300 | Loss: 3.921 | Acc: 48.521% | Wgt Acc: 34.416%
	I - Batch: 350 | Loss: 3.916 | Acc: 48.179% | Wgt Acc: 33.916%
I - num batch: 364
I - Train -- Loss: 3.917 | Acc: 48.134% | Wgt Acc: 33.850% | LR: 1.250000e-04 | Dur: 233.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 154.    5.   15.  117.   62.]
 [   0.   29.   28.    0.   17.]
 [   0.   60.   52.    4.   45.]
 [ 421.   33.   76.  386.  461.]
 [ 117.  541.  803.  211. 2178.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.405 | Acc: 28.125% | Wgt Acc: 18.423%
I - num batch: 87
I - Val -- Loss: 5.297 | Acc: 38.147% | Wgt Acc: 23.724% | Dur: 42.92s
I - Confusion Matrix: [row->prediction - col->label]
[[  5.   0.   0.   2.   1.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [132.  11.  12. 126.  30.]
 [ 62. 257. 278.  76. 400.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 3.874 | Acc: 49.375% | Wgt Acc: 36.189%
	I - Batch: 100 | Loss: 3.833 | Acc: 49.562% | Wgt Acc: 36.470%
	I - Batch: 150 | Loss: 3.849 | Acc: 49.875% | Wgt Acc: 36.552%
	I - Batch: 200 | Loss: 3.854 | Acc: 49.188% | Wgt Acc: 35.958%
	I - Batch: 250 | Loss: 3.859 | Acc: 49.700% | Wgt Acc: 36.634%
	I - Batch: 300 | Loss: 3.862 | Acc: 49.479% | Wgt Acc: 36.527%
	I - Batch: 350 | Loss: 3.860 | Acc: 50.143% | Wgt Acc: 37.043%
I - num batch: 364
I - Train -- Loss: 3.853 | Acc: 50.249% | Wgt Acc: 37.074% | LR: 1.250000e-04 | Dur: 233.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 293.   15.   15.  199.  104.]
 [   0.   42.   49.    3.   24.]
 [   1.  106.  103.    8.   61.]
 [ 289.   15.   64.  309.  399.]
 [ 109.  490.  743.  199. 2175.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.569 | Acc: 41.000% | Wgt Acc: 39.449%
I - num batch: 87
I - Val -- Loss: 5.504 | Acc: 45.618% | Wgt Acc: 40.979% | Dur: 43.03s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   3.  82.  14.]
 [  3. 150. 144.   9.  66.]
 [  0.   9.  10.   0.  12.]
 [ 28.   6.  14.  45.  26.]
 [ 51. 101. 119.  68. 313.]]

I - Local maximum validation set accuracy:  45.62

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 3.848 | Acc: 50.125% | Wgt Acc: 36.590%
	I - Batch: 100 | Loss: 3.864 | Acc: 49.188% | Wgt Acc: 35.478%
	I - Batch: 150 | Loss: 3.870 | Acc: 48.917% | Wgt Acc: 35.842%
	I - Batch: 200 | Loss: 3.872 | Acc: 48.406% | Wgt Acc: 35.408%
	I - Batch: 250 | Loss: 3.878 | Acc: 48.925% | Wgt Acc: 36.196%
	I - Batch: 300 | Loss: 3.875 | Acc: 49.312% | Wgt Acc: 36.253%
	I - Batch: 350 | Loss: 3.867 | Acc: 49.732% | Wgt Acc: 36.694%
I - num batch: 364
I - Train -- Loss: 3.862 | Acc: 50.060% | Wgt Acc: 36.909% | LR: 1.250000e-04 | Dur: 233.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 272.    3.   17.  224.   99.]
 [   3.   77.   86.    1.   50.]
 [   2.  107.  103.    3.   59.]
 [ 288.   32.   53.  288.  384.]
 [ 127.  449.  715.  202. 2171.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.504 | Acc: 37.875% | Wgt Acc: 29.569%
I - num batch: 87
I - Val -- Loss: 5.432 | Acc: 45.618% | Wgt Acc: 32.964% | Dur: 43.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   0.   2.  58.   6.]
 [  0.  41.  29.   0.   3.]
 [  0.  54.  50.   1.  10.]
 [ 34.   1.   3.  46.   9.]
 [ 70. 172. 206.  99. 403.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 3.807 | Acc: 49.500% | Wgt Acc: 35.376%
	I - Batch: 100 | Loss: 3.765 | Acc: 50.750% | Wgt Acc: 38.656%
	I - Batch: 150 | Loss: 3.794 | Acc: 50.125% | Wgt Acc: 37.822%
	I - Batch: 200 | Loss: 3.816 | Acc: 50.469% | Wgt Acc: 37.879%
	I - Batch: 250 | Loss: 3.811 | Acc: 50.550% | Wgt Acc: 37.944%
	I - Batch: 300 | Loss: 3.806 | Acc: 50.750% | Wgt Acc: 37.916%
	I - Batch: 350 | Loss: 3.794 | Acc: 50.732% | Wgt Acc: 37.903%
I - num batch: 364
I - Train -- Loss: 3.792 | Acc: 51.006% | Wgt Acc: 38.238% | LR: 1.250000e-04 | Dur: 234.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 238.    3.    9.  182.   91.]
 [   1.   48.   48.    4.   28.]
 [   1.  159.  196.    3.   99.]
 [ 336.   28.   63.  343.  404.]
 [ 116.  430.  658.  186. 2141.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.544 | Acc: 28.000% | Wgt Acc: 17.710%
I - num batch: 87
I - Val -- Loss: 5.421 | Acc: 38.147% | Wgt Acc: 23.501% | Dur: 43.24s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [140.   7.  14. 128.  28.]
 [ 59. 261. 276.  76. 403.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 3.737 | Acc: 50.875% | Wgt Acc: 38.216%
	I - Batch: 100 | Loss: 3.723 | Acc: 49.562% | Wgt Acc: 37.264%
	I - Batch: 150 | Loss: 3.761 | Acc: 48.625% | Wgt Acc: 36.353%
	I - Batch: 200 | Loss: 3.788 | Acc: 49.656% | Wgt Acc: 37.241%
	I - Batch: 250 | Loss: 3.798 | Acc: 49.300% | Wgt Acc: 36.827%
	I - Batch: 300 | Loss: 3.795 | Acc: 49.792% | Wgt Acc: 37.300%
	I - Batch: 350 | Loss: 3.784 | Acc: 50.286% | Wgt Acc: 37.458%
I - num batch: 364
I - Train -- Loss: 3.787 | Acc: 50.249% | Wgt Acc: 37.382% | LR: 1.250000e-04 | Dur: 234.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 314.    2.   13.  274.  129.]
 [   0.   46.   49.    1.   32.]
 [   3.  178.  187.    7.  121.]
 [ 266.   25.   63.  244.  350.]
 [ 109.  417.  662.  192. 2131.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.625 | Acc: 39.500% | Wgt Acc: 38.711%
I - num batch: 87
I - Val -- Loss: 5.546 | Acc: 42.385% | Wgt Acc: 39.217% | Dur: 43.17s
I - Confusion Matrix: [row->prediction - col->label]
[[123.  12.  16. 109.  17.]
 [  1. 131. 149.   4.  71.]
 [  0.   5.   6.   0.   7.]
 [ 47.  16.  18.  55.  61.]
 [ 28. 104. 101.  36. 275.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 3.709 | Acc: 52.250% | Wgt Acc: 39.900%
	I - Batch: 100 | Loss: 3.739 | Acc: 53.312% | Wgt Acc: 40.537%
	I - Batch: 150 | Loss: 3.757 | Acc: 51.292% | Wgt Acc: 38.200%
	I - Batch: 200 | Loss: 3.764 | Acc: 50.531% | Wgt Acc: 37.720%
	I - Batch: 250 | Loss: 3.751 | Acc: 50.725% | Wgt Acc: 38.286%
	I - Batch: 300 | Loss: 3.757 | Acc: 50.542% | Wgt Acc: 38.244%
	I - Batch: 350 | Loss: 3.759 | Acc: 50.696% | Wgt Acc: 38.177%
I - num batch: 364
I - Train -- Loss: 3.758 | Acc: 50.628% | Wgt Acc: 38.031% | LR: 1.250000e-04 | Dur: 233.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 274.    2.   15.  235.   93.]
 [   4.   89.   92.    5.   59.]
 [   1.  134.  147.    4.   94.]
 [ 280.   22.   58.  289.  372.]
 [ 133.  421.  662.  185. 2145.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.605 | Acc: 41.625% | Wgt Acc: 35.092%
I - num batch: 87
I - Val -- Loss: 5.534 | Acc: 45.977% | Wgt Acc: 37.877% | Dur: 43.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   3.   2.  48.   9.]
 [  0.   0.   0.   0.   0.]
 [  0. 143. 132.   8.  41.]
 [ 75.  12.  34. 106.  77.]
 [ 26. 110. 122.  42. 304.]]

I - Local maximum validation set accuracy:  45.98

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 3.751 | Acc: 51.375% | Wgt Acc: 39.969%
	I - Batch: 100 | Loss: 3.744 | Acc: 50.750% | Wgt Acc: 39.050%
	I - Batch: 150 | Loss: 3.730 | Acc: 50.917% | Wgt Acc: 38.592%
	I - Batch: 200 | Loss: 3.718 | Acc: 51.312% | Wgt Acc: 39.297%
	I - Batch: 250 | Loss: 3.731 | Acc: 51.200% | Wgt Acc: 39.035%
	I - Batch: 300 | Loss: 3.737 | Acc: 51.854% | Wgt Acc: 39.599%
	I - Batch: 350 | Loss: 3.748 | Acc: 51.982% | Wgt Acc: 39.440%
I - num batch: 364
I - Train -- Loss: 3.749 | Acc: 51.866% | Wgt Acc: 39.248% | LR: 1.250000e-04 | Dur: 234.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 151.    4.   10.   94.   25.]
 [   0.   75.   52.    3.   37.]
 [   2.  180.  207.    4.  105.]
 [ 420.   28.   72.  430.  443.]
 [ 119.  381.  633.  187. 2153.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.606 | Acc: 42.125% | Wgt Acc: 40.098%
I - num batch: 87
I - Val -- Loss: 5.558 | Acc: 46.839% | Wgt Acc: 42.766% | Dur: 43.14s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   4.   6.  95.  13.]
 [  3. 145. 143.   9.  48.]
 [  0.  12.  15.   0.  18.]
 [ 32.  11.  23.  54.  43.]
 [ 35.  96. 103.  46. 309.]]

I - Local maximum validation set accuracy:  46.84

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 3.667 | Acc: 53.875% | Wgt Acc: 40.459%
	I - Batch: 100 | Loss: 3.718 | Acc: 52.188% | Wgt Acc: 38.631%
	I - Batch: 150 | Loss: 3.701 | Acc: 51.750% | Wgt Acc: 38.164%
	I - Batch: 200 | Loss: 3.684 | Acc: 52.094% | Wgt Acc: 38.932%
	I - Batch: 250 | Loss: 3.689 | Acc: 51.675% | Wgt Acc: 38.707%
	I - Batch: 300 | Loss: 3.688 | Acc: 52.146% | Wgt Acc: 39.238%
	I - Batch: 350 | Loss: 3.697 | Acc: 52.268% | Wgt Acc: 39.143%
I - num batch: 364
I - Train -- Loss: 3.703 | Acc: 52.193% | Wgt Acc: 39.029% | LR: 1.250000e-04 | Dur: 231.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 164.    0.    9.  102.   51.]
 [   0.   72.  104.    3.   35.]
 [   1.  174.  158.    7.   80.]
 [ 418.   22.   60.  432.  388.]
 [ 109.  400.  643.  174. 2209.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.630 | Acc: 39.125% | Wgt Acc: 40.130%
I - num batch: 87
I - Val -- Loss: 5.578 | Acc: 41.307% | Wgt Acc: 40.880% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   2.   7.  97.  13.]
 [  1. 165. 177.   7. 103.]
 [  0.   8.   5.   2.  15.]
 [ 64.  23.  28.  60.  67.]
 [ 22.  70.  73.  38. 233.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 3.671 | Acc: 51.250% | Wgt Acc: 37.004%
	I - Batch: 100 | Loss: 3.705 | Acc: 50.000% | Wgt Acc: 36.324%
	I - Batch: 150 | Loss: 3.700 | Acc: 50.333% | Wgt Acc: 36.591%
	I - Batch: 200 | Loss: 3.693 | Acc: 50.969% | Wgt Acc: 37.661%
	I - Batch: 250 | Loss: 3.713 | Acc: 51.150% | Wgt Acc: 38.016%
	I - Batch: 300 | Loss: 3.729 | Acc: 51.250% | Wgt Acc: 37.967%
	I - Batch: 350 | Loss: 3.725 | Acc: 51.232% | Wgt Acc: 37.754%
I - num batch: 364
I - Train -- Loss: 3.722 | Acc: 51.298% | Wgt Acc: 37.782% | LR: 1.250000e-04 | Dur: 232.90s
I - Confusion Matrix: [row->prediction - col->label]
[[  82.    2.    2.   64.   20.]
 [   0.   87.  105.    1.   38.]
 [   2.  153.  157.    7.   73.]
 [ 485.   20.   59.  459.  434.]
 [ 123.  406.  651.  187. 2198.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.646 | Acc: 43.000% | Wgt Acc: 42.393%
I - num batch: 87
I - Val -- Loss: 5.615 | Acc: 46.193% | Wgt Acc: 43.576% | Dur: 42.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   2.   2.  63.   6.]
 [  7. 188. 186.  15.  99.]
 [  1.   8.  14.   3.  20.]
 [ 41.  10.  12.  54.  18.]
 [ 51.  60.  76.  69. 288.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 3.668 | Acc: 52.250% | Wgt Acc: 39.001%
	I - Batch: 100 | Loss: 3.647 | Acc: 51.500% | Wgt Acc: 38.670%
	I - Batch: 150 | Loss: 3.676 | Acc: 51.583% | Wgt Acc: 39.011%
	I - Batch: 200 | Loss: 3.643 | Acc: 52.125% | Wgt Acc: 39.133%
	I - Batch: 250 | Loss: 3.646 | Acc: 51.750% | Wgt Acc: 38.814%
	I - Batch: 300 | Loss: 3.666 | Acc: 51.583% | Wgt Acc: 38.599%
	I - Batch: 350 | Loss: 3.671 | Acc: 51.911% | Wgt Acc: 39.062%
I - num batch: 364
I - Train -- Loss: 3.679 | Acc: 52.021% | Wgt Acc: 39.228% | LR: 1.250000e-04 | Dur: 232.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 152.    5.    8.  119.   43.]
 [   0.  134.  141.    2.   64.]
 [   2.  135.  127.    5.   57.]
 [ 426.   20.   47.  410.  397.]
 [ 112.  374.  651.  182. 2202.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.641 | Acc: 38.250% | Wgt Acc: 35.950%
I - num batch: 87
I - Val -- Loss: 5.558 | Acc: 43.247% | Wgt Acc: 38.224% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  3. 159. 170.   6.  91.]
 [  1.   2.   5.   0.   9.]
 [134.   9.  24. 135.  28.]
 [ 61.  98.  91.  63. 303.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 3.549 | Acc: 53.500% | Wgt Acc: 40.788%
	I - Batch: 100 | Loss: 3.560 | Acc: 53.938% | Wgt Acc: 41.838%
	I - Batch: 150 | Loss: 3.617 | Acc: 52.708% | Wgt Acc: 39.673%
	I - Batch: 200 | Loss: 3.623 | Acc: 52.531% | Wgt Acc: 39.476%
	I - Batch: 250 | Loss: 3.655 | Acc: 53.025% | Wgt Acc: 39.741%
	I - Batch: 300 | Loss: 3.658 | Acc: 52.833% | Wgt Acc: 39.397%
	I - Batch: 350 | Loss: 3.666 | Acc: 52.679% | Wgt Acc: 39.306%
I - num batch: 364
I - Train -- Loss: 3.662 | Acc: 52.605% | Wgt Acc: 39.226% | LR: 1.250000e-04 | Dur: 231.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 155.    2.    5.  134.   44.]
 [   1.  121.  119.    1.   50.]
 [   0.  104.  132.    4.   47.]
 [ 428.   18.   60.  404.  375.]
 [ 108.  423.  658.  175. 2247.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.693 | Acc: 42.250% | Wgt Acc: 41.359%
I - num batch: 87
I - Val -- Loss: 5.648 | Acc: 44.899% | Wgt Acc: 41.861% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   5.  14. 109.  19.]
 [  4. 155. 156.   9.  70.]
 [  0.  10.  13.   2.  22.]
 [ 36.  11.  22.  44.  34.]
 [ 32.  87.  85.  40. 286.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 3.646 | Acc: 51.750% | Wgt Acc: 37.281%
	I - Batch: 100 | Loss: 3.645 | Acc: 52.250% | Wgt Acc: 38.651%
	I - Batch: 150 | Loss: 3.660 | Acc: 51.000% | Wgt Acc: 38.187%
	I - Batch: 200 | Loss: 3.645 | Acc: 51.688% | Wgt Acc: 38.573%
	I - Batch: 250 | Loss: 3.635 | Acc: 52.375% | Wgt Acc: 39.227%
	I - Batch: 300 | Loss: 3.612 | Acc: 52.167% | Wgt Acc: 38.975%
	I - Batch: 350 | Loss: 3.633 | Acc: 51.768% | Wgt Acc: 38.569%
I - num batch: 364
I - Train -- Loss: 3.636 | Acc: 51.866% | Wgt Acc: 38.602% | LR: 1.250000e-04 | Dur: 231.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 224.    3.    7.  211.   77.]
 [   1.  139.  127.    4.   73.]
 [   2.   91.  101.    0.   60.]
 [ 358.   14.   51.  316.  317.]
 [ 107.  421.  688.  187. 2236.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.645 | Acc: 35.375% | Wgt Acc: 29.645%
I - num batch: 87
I - Val -- Loss: 5.546 | Acc: 42.816% | Wgt Acc: 33.319% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  1.  98.  88.   5.  21.]
 [  0.   7.   7.   1.   7.]
 [157.  10.  20. 132.  44.]
 [ 41. 153. 175.  66. 359.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 3.638 | Acc: 52.125% | Wgt Acc: 39.239%
	I - Batch: 100 | Loss: 3.644 | Acc: 53.938% | Wgt Acc: 41.386%
	I - Batch: 150 | Loss: 3.644 | Acc: 54.208% | Wgt Acc: 41.686%
	I - Batch: 200 | Loss: 3.637 | Acc: 53.969% | Wgt Acc: 41.126%
	I - Batch: 250 | Loss: 3.628 | Acc: 53.450% | Wgt Acc: 40.488%
	I - Batch: 300 | Loss: 3.612 | Acc: 54.062% | Wgt Acc: 41.540%
	I - Batch: 350 | Loss: 3.617 | Acc: 53.893% | Wgt Acc: 41.489%
I - num batch: 364
I - Train -- Loss: 3.618 | Acc: 53.775% | Wgt Acc: 41.293% | LR: 1.250000e-04 | Dur: 231.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 182.    3.    7.  128.   45.]
 [   0.  178.  155.    6.   74.]
 [   4.   98.   99.    3.   42.]
 [ 401.   19.   54.  413.  347.]
 [ 105.  370.  659.  168. 2255.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.610 | Acc: 42.875% | Wgt Acc: 39.165%
I - num batch: 87
I - Val -- Loss: 5.555 | Acc: 49.713% | Wgt Acc: 42.563% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   0.   2.  64.   9.]
 [  1. 121.  86.   4.  13.]
 [  1.  25.  45.   3.  19.]
 [ 65.  12.  18.  79.  37.]
 [ 38. 110. 139.  54. 353.]]

I - Local maximum validation set accuracy:  49.71

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 3.565 | Acc: 54.000% | Wgt Acc: 40.339%
	I - Batch: 100 | Loss: 3.611 | Acc: 52.250% | Wgt Acc: 38.207%
	I - Batch: 150 | Loss: 3.564 | Acc: 52.625% | Wgt Acc: 39.575%
	I - Batch: 200 | Loss: 3.566 | Acc: 52.094% | Wgt Acc: 39.127%
	I - Batch: 250 | Loss: 3.560 | Acc: 52.350% | Wgt Acc: 39.670%
	I - Batch: 300 | Loss: 3.562 | Acc: 52.583% | Wgt Acc: 39.621%
	I - Batch: 350 | Loss: 3.558 | Acc: 53.000% | Wgt Acc: 40.491%
I - num batch: 364
I - Train -- Loss: 3.556 | Acc: 53.001% | Wgt Acc: 40.564% | LR: 1.250000e-04 | Dur: 231.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 176.    1.    5.  157.   55.]
 [   1.  145.  152.    2.   71.]
 [   2.  151.  165.    5.   89.]
 [ 426.   13.   42.  394.  346.]
 [  87.  358.  610.  160. 2202.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.694 | Acc: 37.875% | Wgt Acc: 41.454%
I - num batch: 87
I - Val -- Loss: 5.656 | Acc: 37.716% | Wgt Acc: 41.259% | Dur: 42.68s
I - Confusion Matrix: [row->prediction - col->label]
[[153.   9.  30. 145.  38.]
 [  3. 175. 184.   9. 143.]
 [  0.  10.   9.   1.  21.]
 [ 29.  16.  15.  29.  70.]
 [ 14.  58.  52.  20. 159.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 3.608 | Acc: 53.750% | Wgt Acc: 40.658%
	I - Batch: 100 | Loss: 3.541 | Acc: 53.938% | Wgt Acc: 41.493%
	I - Batch: 150 | Loss: 3.564 | Acc: 54.500% | Wgt Acc: 42.456%
	I - Batch: 200 | Loss: 3.550 | Acc: 53.875% | Wgt Acc: 41.848%
	I - Batch: 250 | Loss: 3.549 | Acc: 53.975% | Wgt Acc: 41.929%
	I - Batch: 300 | Loss: 3.562 | Acc: 53.708% | Wgt Acc: 41.693%
	I - Batch: 350 | Loss: 3.588 | Acc: 53.607% | Wgt Acc: 41.332%
I - num batch: 364
I - Train -- Loss: 3.586 | Acc: 53.379% | Wgt Acc: 41.060% | LR: 1.250000e-04 | Dur: 231.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 172.    2.    5.  119.   39.]
 [   2.  125.  141.    4.   67.]
 [   0.  196.  195.    5.   94.]
 [ 416.   18.   39.  418.  369.]
 [ 102.  327.  594.  172. 2194.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.660 | Acc: 41.875% | Wgt Acc: 39.625%
I - num batch: 87
I - Val -- Loss: 5.611 | Acc: 46.839% | Wgt Acc: 42.315% | Dur: 42.66s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   7.  13. 107.  19.]
 [  1. 153. 143.  11.  33.]
 [  0.  15.  18.   1.  22.]
 [ 44.  14.  18.  46.  42.]
 [ 34.  79.  98.  39. 315.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 3.547 | Acc: 53.000% | Wgt Acc: 41.138%
	I - Batch: 100 | Loss: 3.572 | Acc: 53.562% | Wgt Acc: 40.873%
	I - Batch: 150 | Loss: 3.550 | Acc: 54.833% | Wgt Acc: 42.367%
	I - Batch: 200 | Loss: 3.568 | Acc: 53.781% | Wgt Acc: 41.545%
	I - Batch: 250 | Loss: 3.570 | Acc: 54.275% | Wgt Acc: 42.162%
	I - Batch: 300 | Loss: 3.568 | Acc: 53.938% | Wgt Acc: 41.791%
	I - Batch: 350 | Loss: 3.554 | Acc: 53.857% | Wgt Acc: 41.639%
I - num batch: 364
I - Train -- Loss: 3.555 | Acc: 53.964% | Wgt Acc: 41.773% | LR: 1.250000e-04 | Dur: 231.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 173.    0.    6.  124.   47.]
 [   4.  162.  186.    4.   73.]
 [   1.  157.  170.    2.   89.]
 [ 420.   16.   41.  415.  336.]
 [  94.  333.  571.  173. 2218.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.669 | Acc: 36.875% | Wgt Acc: 27.918%
I - num batch: 87
I - Val -- Loss: 5.579 | Acc: 44.109% | Wgt Acc: 31.959% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 26.   0.   2.  16.   4.]
 [  0.   0.   0.   0.   0.]
 [  1. 105.  82.   2.  13.]
 [137.  16.  27. 138.  46.]
 [ 35. 147. 179.  48. 368.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 3.528 | Acc: 51.250% | Wgt Acc: 39.986%
	I - Batch: 100 | Loss: 3.512 | Acc: 53.875% | Wgt Acc: 43.561%
	I - Batch: 150 | Loss: 3.505 | Acc: 55.292% | Wgt Acc: 44.723%
	I - Batch: 200 | Loss: 3.521 | Acc: 54.938% | Wgt Acc: 43.742%
	I - Batch: 250 | Loss: 3.511 | Acc: 55.000% | Wgt Acc: 44.077%
	I - Batch: 300 | Loss: 3.515 | Acc: 54.917% | Wgt Acc: 44.086%
	I - Batch: 350 | Loss: 3.514 | Acc: 55.089% | Wgt Acc: 44.229%
I - num batch: 364
I - Train -- Loss: 3.511 | Acc: 55.013% | Wgt Acc: 44.046% | LR: 1.250000e-04 | Dur: 232.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 160.    3.    1.  101.   34.]
 [   0.  197.  184.    2.   79.]
 [   3.  194.  209.    3.  120.]
 [ 431.   14.   40.  458.  355.]
 [  98.  260.  540.  154. 2175.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.698 | Acc: 40.875% | Wgt Acc: 42.620%
I - num batch: 87
I - Val -- Loss: 5.654 | Acc: 42.744% | Wgt Acc: 43.197% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[149.  14.  18. 112.  26.]
 [  3. 146. 156.   4.  75.]
 [  0.   4.   5.   0.  16.]
 [ 31.  27.  41.  68.  87.]
 [ 16.  77.  70.  20. 227.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 3.592 | Acc: 54.000% | Wgt Acc: 40.479%
	I - Batch: 100 | Loss: 3.573 | Acc: 54.688% | Wgt Acc: 41.575%
	I - Batch: 150 | Loss: 3.548 | Acc: 54.208% | Wgt Acc: 41.624%
	I - Batch: 200 | Loss: 3.533 | Acc: 54.500% | Wgt Acc: 42.054%
	I - Batch: 250 | Loss: 3.529 | Acc: 54.075% | Wgt Acc: 41.903%
	I - Batch: 300 | Loss: 3.521 | Acc: 54.625% | Wgt Acc: 42.681%
	I - Batch: 350 | Loss: 3.511 | Acc: 54.821% | Wgt Acc: 43.033%
I - num batch: 364
I - Train -- Loss: 3.509 | Acc: 54.772% | Wgt Acc: 43.002% | LR: 1.250000e-04 | Dur: 232.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 144.    4.    3.  111.   37.]
 [   2.  180.  156.    4.   73.]
 [   1.  170.  200.    4.  102.]
 [ 432.    7.   37.  451.  341.]
 [ 113.  307.  578.  148. 2210.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.783 | Acc: 38.000% | Wgt Acc: 37.627%
I - num batch: 87
I - Val -- Loss: 5.703 | Acc: 42.457% | Wgt Acc: 40.393% | Dur: 42.72s
I - Confusion Matrix: [row->prediction - col->label]
[[158.  11.  32. 132.  43.]
 [  0. 116. 105.   2.  21.]
 [  1.   4.   7.   1.   8.]
 [ 33.  39.  49.  51. 100.]
 [  7.  98.  97.  18. 259.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 3.473 | Acc: 55.625% | Wgt Acc: 43.846%
	I - Batch: 100 | Loss: 3.497 | Acc: 55.250% | Wgt Acc: 43.345%
	I - Batch: 150 | Loss: 3.461 | Acc: 56.208% | Wgt Acc: 44.024%
	I - Batch: 200 | Loss: 3.446 | Acc: 55.500% | Wgt Acc: 43.436%
	I - Batch: 250 | Loss: 3.473 | Acc: 55.425% | Wgt Acc: 43.635%
	I - Batch: 300 | Loss: 3.471 | Acc: 55.312% | Wgt Acc: 43.618%
	I - Batch: 350 | Loss: 3.467 | Acc: 55.357% | Wgt Acc: 43.520%
I - num batch: 364
I - Train -- Loss: 3.469 | Acc: 55.529% | Wgt Acc: 43.702% | LR: 1.250000e-04 | Dur: 232.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 151.    1.    5.  123.   42.]
 [   4.  217.  213.    6.   91.]
 [   1.  150.  181.    3.   79.]
 [ 427.   17.   28.  433.  304.]
 [ 109.  283.  547.  153. 2247.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.759 | Acc: 35.000% | Wgt Acc: 26.625%
I - num batch: 87
I - Val -- Loss: 5.624 | Acc: 43.247% | Wgt Acc: 31.125% | Dur: 42.75s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   3.   4.  73.   9.]
 [  0.   0.   0.   0.   0.]
 [  0.  59.  34.   1.   2.]
 [ 51.  12.  23.  77.  35.]
 [ 42. 194. 229.  53. 385.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 3.387 | Acc: 57.625% | Wgt Acc: 48.279%
	I - Batch: 100 | Loss: 3.443 | Acc: 55.188% | Wgt Acc: 44.231%
	I - Batch: 150 | Loss: 3.446 | Acc: 55.083% | Wgt Acc: 44.322%
	I - Batch: 200 | Loss: 3.446 | Acc: 55.406% | Wgt Acc: 44.457%
	I - Batch: 250 | Loss: 3.454 | Acc: 55.700% | Wgt Acc: 44.710%
	I - Batch: 300 | Loss: 3.466 | Acc: 55.229% | Wgt Acc: 44.594%
	I - Batch: 350 | Loss: 3.460 | Acc: 55.286% | Wgt Acc: 44.497%
I - num batch: 364
I - Train -- Loss: 3.468 | Acc: 55.305% | Wgt Acc: 44.358% | LR: 1.250000e-04 | Dur: 232.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 210.    2.    6.  157.   53.]
 [   0.  223.  221.    5.  105.]
 [   1.  149.  177.    4.   78.]
 [ 375.    9.   37.  406.  327.]
 [ 106.  285.  533.  146. 2200.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.702 | Acc: 39.500% | Wgt Acc: 35.168%
I - num batch: 87
I - Val -- Loss: 5.600 | Acc: 44.899% | Wgt Acc: 38.040% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  1. 141. 127.   5.  52.]
 [  1.  12.   8.   0.   6.]
 [155.  16.  35. 141.  38.]
 [ 42.  99. 120.  58. 335.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 3.474 | Acc: 53.375% | Wgt Acc: 41.868%
	I - Batch: 100 | Loss: 3.478 | Acc: 54.562% | Wgt Acc: 43.920%
	I - Batch: 150 | Loss: 3.497 | Acc: 53.333% | Wgt Acc: 42.866%
	I - Batch: 200 | Loss: 3.479 | Acc: 54.375% | Wgt Acc: 43.717%
	I - Batch: 250 | Loss: 3.466 | Acc: 54.900% | Wgt Acc: 44.076%
	I - Batch: 300 | Loss: 3.444 | Acc: 55.604% | Wgt Acc: 44.642%
	I - Batch: 350 | Loss: 3.444 | Acc: 55.696% | Wgt Acc: 44.894%
I - num batch: 364
I - Train -- Loss: 3.443 | Acc: 55.684% | Wgt Acc: 44.876% | LR: 1.250000e-04 | Dur: 232.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 170.    2.    2.  131.   42.]
 [   1.  216.  216.    3.  105.]
 [   2.  187.  219.    2.   88.]
 [ 421.   14.   29.  447.  342.]
 [  98.  249.  508.  135. 2186.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.648 | Acc: 44.250% | Wgt Acc: 44.474%
I - num batch: 87
I - Val -- Loss: 5.626 | Acc: 46.839% | Wgt Acc: 44.999% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 93.   3.   2.  60.  11.]
 [  6. 184. 172.   6.  88.]
 [  0.   9.   8.   0.  15.]
 [ 56.   8.  26.  86.  36.]
 [ 44.  64.  82.  52. 281.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 3.373 | Acc: 60.375% | Wgt Acc: 48.158%
	I - Batch: 100 | Loss: 3.416 | Acc: 58.688% | Wgt Acc: 46.566%
	I - Batch: 150 | Loss: 3.408 | Acc: 57.375% | Wgt Acc: 45.651%
	I - Batch: 200 | Loss: 3.398 | Acc: 56.969% | Wgt Acc: 45.139%
	I - Batch: 250 | Loss: 3.408 | Acc: 56.775% | Wgt Acc: 44.869%
	I - Batch: 300 | Loss: 3.421 | Acc: 56.104% | Wgt Acc: 44.430%
	I - Batch: 350 | Loss: 3.433 | Acc: 56.161% | Wgt Acc: 44.474%
I - num batch: 364
I - Train -- Loss: 3.430 | Acc: 56.457% | Wgt Acc: 44.965% | LR: 1.250000e-04 | Dur: 232.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 205.    2.    9.  163.   52.]
 [   1.  222.  244.    2.   92.]
 [   1.  227.  201.    3.   83.]
 [ 372.   15.   28.  401.  282.]
 [ 113.  202.  492.  149. 2254.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.682 | Acc: 38.250% | Wgt Acc: 30.603%
I - num batch: 87
I - Val -- Loss: 5.606 | Acc: 45.259% | Wgt Acc: 34.443% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.  89.  56.   2.  11.]
 [  0.  51.  42.   3.  16.]
 [139.   7.  13. 122.  27.]
 [ 60. 121. 179.  77. 377.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 3.427 | Acc: 55.875% | Wgt Acc: 44.176%
	I - Batch: 100 | Loss: 3.419 | Acc: 56.438% | Wgt Acc: 44.560%
	I - Batch: 150 | Loss: 3.415 | Acc: 57.000% | Wgt Acc: 44.920%
	I - Batch: 200 | Loss: 3.412 | Acc: 56.531% | Wgt Acc: 44.194%
	I - Batch: 250 | Loss: 3.405 | Acc: 56.750% | Wgt Acc: 45.027%
	I - Batch: 300 | Loss: 3.414 | Acc: 56.312% | Wgt Acc: 44.767%
	I - Batch: 350 | Loss: 3.407 | Acc: 56.339% | Wgt Acc: 45.040%
I - num batch: 364
I - Train -- Loss: 3.400 | Acc: 56.457% | Wgt Acc: 45.216% | LR: 1.250000e-04 | Dur: 232.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 192.    1.    4.  155.   40.]
 [   3.  236.  254.    5.   92.]
 [   1.  187.  189.    4.  104.]
 [ 389.    6.   29.  420.  281.]
 [ 107.  238.  498.  134. 2246.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.721 | Acc: 42.000% | Wgt Acc: 42.185%
I - num batch: 87
I - Val -- Loss: 5.647 | Acc: 44.828% | Wgt Acc: 43.053% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[152.  13.  23. 133.  33.]
 [  0. 142. 115.   1.  31.]
 [  0.   4.  10.   0.   4.]
 [ 30.  30.  34.  52.  95.]
 [ 17.  79. 108.  18. 268.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 3.322 | Acc: 57.125% | Wgt Acc: 46.843%
	I - Batch: 100 | Loss: 3.335 | Acc: 55.812% | Wgt Acc: 44.646%
	I - Batch: 150 | Loss: 3.333 | Acc: 57.042% | Wgt Acc: 45.903%
	I - Batch: 200 | Loss: 3.347 | Acc: 56.312% | Wgt Acc: 45.030%
	I - Batch: 250 | Loss: 3.337 | Acc: 56.950% | Wgt Acc: 45.993%
	I - Batch: 300 | Loss: 3.341 | Acc: 57.479% | Wgt Acc: 46.441%
	I - Batch: 350 | Loss: 3.337 | Acc: 57.661% | Wgt Acc: 46.521%
I - num batch: 364
I - Train -- Loss: 3.344 | Acc: 57.524% | Wgt Acc: 46.320% | LR: 1.250000e-04 | Dur: 232.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 239.    2.    3.  192.   41.]
 [   0.  251.  272.    4.   83.]
 [   2.  175.  193.    1.   89.]
 [ 349.    6.   32.  383.  271.]
 [ 102.  234.  474.  138. 2279.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.685 | Acc: 36.125% | Wgt Acc: 26.190%
I - num batch: 87
I - Val -- Loss: 5.633 | Acc: 43.606% | Wgt Acc: 29.797% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  2. 153. 123.   5.  31.]
 [128.   8.  14. 110.  26.]
 [ 69. 107. 153.  89. 374.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 3.274 | Acc: 59.250% | Wgt Acc: 47.984%
	I - Batch: 100 | Loss: 3.345 | Acc: 58.125% | Wgt Acc: 48.358%
	I - Batch: 150 | Loss: 3.372 | Acc: 56.875% | Wgt Acc: 46.441%
	I - Batch: 200 | Loss: 3.380 | Acc: 56.344% | Wgt Acc: 46.148%
	I - Batch: 250 | Loss: 3.391 | Acc: 56.875% | Wgt Acc: 46.491%
	I - Batch: 300 | Loss: 3.399 | Acc: 56.833% | Wgt Acc: 46.588%
	I - Batch: 350 | Loss: 3.391 | Acc: 56.911% | Wgt Acc: 46.169%
I - num batch: 364
I - Train -- Loss: 3.392 | Acc: 56.767% | Wgt Acc: 45.981% | LR: 1.250000e-04 | Dur: 232.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 180.    3.    3.  137.   39.]
 [   3.  262.  269.    3.  110.]
 [   1.  176.  197.    2.   90.]
 [ 411.   15.   27.  431.  293.]
 [  97.  212.  478.  145. 2231.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.804 | Acc: 32.125% | Wgt Acc: 25.263%
I - num batch: 87
I - Val -- Loss: 5.690 | Acc: 39.440% | Wgt Acc: 28.418% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   9.  98.  12.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 45.  13.  32.  65.  56.]
 [ 33. 253. 249.  41. 363.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 3.424 | Acc: 54.875% | Wgt Acc: 43.870%
	I - Batch: 100 | Loss: 3.407 | Acc: 54.688% | Wgt Acc: 43.035%
	I - Batch: 150 | Loss: 3.391 | Acc: 54.917% | Wgt Acc: 43.971%
	I - Batch: 200 | Loss: 3.359 | Acc: 56.094% | Wgt Acc: 45.420%
	I - Batch: 250 | Loss: 3.344 | Acc: 56.975% | Wgt Acc: 46.219%
	I - Batch: 300 | Loss: 3.364 | Acc: 56.958% | Wgt Acc: 46.337%
	I - Batch: 350 | Loss: 3.384 | Acc: 56.000% | Wgt Acc: 45.236%
I - num batch: 364
I - Train -- Loss: 3.386 | Acc: 55.959% | Wgt Acc: 45.308% | LR: 1.250000e-04 | Dur: 232.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 140.    0.    3.  120.   42.]
 [   3.  270.  242.    1.   94.]
 [   1.  145.  184.    2.   90.]
 [ 458.    9.   34.  457.  334.]
 [  90.  244.  511.  138. 2203.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.752 | Acc: 42.125% | Wgt Acc: 40.124%
I - num batch: 87
I - Val -- Loss: 5.683 | Acc: 46.767% | Wgt Acc: 41.649% | Dur: 42.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 61.   1.   2.  21.   6.]
 [  5. 175. 173.   8.  67.]
 [  0.   6.  11.   1.  18.]
 [ 63.   8.  14.  79.  15.]
 [ 70.  78.  90.  95. 325.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 3.298 | Acc: 58.750% | Wgt Acc: 48.357%
	I - Batch: 100 | Loss: 3.303 | Acc: 57.688% | Wgt Acc: 47.100%
	I - Batch: 150 | Loss: 3.302 | Acc: 57.500% | Wgt Acc: 47.081%
	I - Batch: 200 | Loss: 3.340 | Acc: 56.344% | Wgt Acc: 45.605%
	I - Batch: 250 | Loss: 3.361 | Acc: 56.775% | Wgt Acc: 46.151%
	I - Batch: 300 | Loss: 3.357 | Acc: 57.042% | Wgt Acc: 46.736%
	I - Batch: 350 | Loss: 3.339 | Acc: 57.143% | Wgt Acc: 46.631%
I - num batch: 364
I - Train -- Loss: 3.341 | Acc: 57.231% | Wgt Acc: 46.830% | LR: 1.250000e-04 | Dur: 232.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 162.    1.    1.  110.   38.]
 [   3.  290.  319.    7.  101.]
 [   0.  153.  166.    3.   87.]
 [ 445.   11.   29.  472.  299.]
 [  82.  213.  459.  126. 2238.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.744 | Acc: 43.625% | Wgt Acc: 42.513%
I - num batch: 87
I - Val -- Loss: 5.684 | Acc: 47.557% | Wgt Acc: 42.866% | Dur: 42.95s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   9.  14. 112.  17.]
 [  6. 168. 148.   9.  49.]
 [  0.   7.   8.   2.  11.]
 [ 36.   7.  17.  45.  28.]
 [ 42.  77. 103.  36. 326.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 3.257 | Acc: 57.125% | Wgt Acc: 47.424%
	I - Batch: 100 | Loss: 3.257 | Acc: 59.438% | Wgt Acc: 49.035%
	I - Batch: 150 | Loss: 3.242 | Acc: 59.083% | Wgt Acc: 47.764%
	I - Batch: 200 | Loss: 3.234 | Acc: 59.375% | Wgt Acc: 48.645%
	I - Batch: 250 | Loss: 3.236 | Acc: 58.975% | Wgt Acc: 48.268%
	I - Batch: 300 | Loss: 3.229 | Acc: 59.438% | Wgt Acc: 48.958%
	I - Batch: 350 | Loss: 3.226 | Acc: 59.625% | Wgt Acc: 48.984%
I - num batch: 364
I - Train -- Loss: 3.228 | Acc: 59.639% | Wgt Acc: 49.027% | LR: 1.250000e-04 | Dur: 233.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 214.    3.    3.  124.   38.]
 [   1.  273.  273.    4.   72.]
 [   1.  182.  197.    3.   74.]
 [ 387.    7.   19.  473.  268.]
 [  89.  203.  482.  114. 2311.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.753 | Acc: 38.000% | Wgt Acc: 40.224%
I - num batch: 87
I - Val -- Loss: 5.705 | Acc: 39.152% | Wgt Acc: 40.349% | Dur: 42.64s
I - Confusion Matrix: [row->prediction - col->label]
[[179.  30.  38. 173. 104.]
 [  1. 133.  99.   3.  17.]
 [  0.   9.  21.   0.   6.]
 [ 13.  28.  39.  19. 111.]
 [  6.  68.  93.   9. 193.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 3.101 | Acc: 63.500% | Wgt Acc: 53.305%
	I - Batch: 100 | Loss: 3.187 | Acc: 60.188% | Wgt Acc: 49.263%
	I - Batch: 150 | Loss: 3.215 | Acc: 59.167% | Wgt Acc: 48.008%
	I - Batch: 200 | Loss: 3.219 | Acc: 58.938% | Wgt Acc: 47.786%
	I - Batch: 250 | Loss: 3.218 | Acc: 59.150% | Wgt Acc: 48.356%
	I - Batch: 300 | Loss: 3.226 | Acc: 58.896% | Wgt Acc: 47.953%
	I - Batch: 350 | Loss: 3.240 | Acc: 58.607% | Wgt Acc: 47.669%
I - num batch: 364
I - Train -- Loss: 3.240 | Acc: 58.676% | Wgt Acc: 47.909% | LR: 1.250000e-04 | Dur: 230.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 200.    4.    2.  153.   52.]
 [   2.  274.  241.    2.   67.]
 [   1.  207.  230.    5.   83.]
 [ 409.    7.   29.  430.  283.]
 [  80.  176.  472.  128. 2278.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.811 | Acc: 36.625% | Wgt Acc: 32.060%
I - num batch: 87
I - Val -- Loss: 5.722 | Acc: 42.960% | Wgt Acc: 35.887% | Dur: 41.87s
I - Confusion Matrix: [row->prediction - col->label]
[[146.  14.  24. 132.  33.]
 [  0.  75.  51.   2.   6.]
 [  0.  22.  15.   2.   3.]
 [ 26.  24.  16.  35.  62.]
 [ 27. 133. 184.  33. 327.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 3.083 | Acc: 62.000% | Wgt Acc: 53.832%
	I - Batch: 100 | Loss: 3.133 | Acc: 59.812% | Wgt Acc: 50.759%
	I - Batch: 150 | Loss: 3.139 | Acc: 60.292% | Wgt Acc: 50.992%
	I - Batch: 200 | Loss: 3.158 | Acc: 59.812% | Wgt Acc: 49.774%
	I - Batch: 250 | Loss: 3.165 | Acc: 59.425% | Wgt Acc: 49.240%
	I - Batch: 300 | Loss: 3.196 | Acc: 59.000% | Wgt Acc: 48.624%
	I - Batch: 350 | Loss: 3.198 | Acc: 58.982% | Wgt Acc: 48.640%
I - num batch: 364
I - Train -- Loss: 3.196 | Acc: 58.865% | Wgt Acc: 48.474% | LR: 1.250000e-04 | Dur: 228.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 225.    2.    2.  182.   41.]
 [   1.  301.  320.    1.   82.]
 [   2.  181.  195.    8.   82.]
 [ 383.    4.   18.  421.  277.]
 [  81.  180.  439.  106. 2281.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.708 | Acc: 42.875% | Wgt Acc: 40.300%
I - num batch: 87
I - Val -- Loss: 5.666 | Acc: 47.845% | Wgt Acc: 42.088% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   5.  12. 111.  13.]
 [  3. 143. 117.  11.  37.]
 [  0.  32.  30.   1.  32.]
 [ 31.  10.  15.  35.  16.]
 [ 40.  78. 116.  46. 333.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 3.255 | Acc: 55.125% | Wgt Acc: 40.931%
	I - Batch: 100 | Loss: 3.222 | Acc: 58.125% | Wgt Acc: 45.905%
	I - Batch: 150 | Loss: 3.222 | Acc: 58.208% | Wgt Acc: 46.573%
	I - Batch: 200 | Loss: 3.225 | Acc: 58.562% | Wgt Acc: 47.509%
	I - Batch: 250 | Loss: 3.216 | Acc: 58.200% | Wgt Acc: 47.401%
	I - Batch: 300 | Loss: 3.215 | Acc: 58.542% | Wgt Acc: 47.984%
	I - Batch: 350 | Loss: 3.206 | Acc: 58.875% | Wgt Acc: 48.341%
I - num batch: 364
I - Train -- Loss: 3.204 | Acc: 58.917% | Wgt Acc: 48.368% | LR: 1.250000e-04 | Dur: 231.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 197.    2.    2.  153.   48.]
 [   2.  286.  318.    4.   76.]
 [   1.  180.  196.    4.   79.]
 [ 401.    8.   24.  460.  273.]
 [  91.  192.  434.   97. 2287.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.633 | Acc: 42.750% | Wgt Acc: 44.146%
I - num batch: 87
I - Val -- Loss: 5.646 | Acc: 44.540% | Wgt Acc: 44.868% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   9.  15. 108.  20.]
 [  4. 176. 174.   9.  85.]
 [  1.   5.  13.   2.  25.]
 [ 34.   9.  23.  50.  63.]
 [ 17.  69.  65.  35. 238.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 3.186 | Acc: 62.125% | Wgt Acc: 51.599%
	I - Batch: 100 | Loss: 3.153 | Acc: 60.688% | Wgt Acc: 50.746%
	I - Batch: 150 | Loss: 3.128 | Acc: 61.583% | Wgt Acc: 51.421%
	I - Batch: 200 | Loss: 3.129 | Acc: 60.906% | Wgt Acc: 50.561%
	I - Batch: 250 | Loss: 3.140 | Acc: 60.375% | Wgt Acc: 50.189%
	I - Batch: 300 | Loss: 3.152 | Acc: 60.000% | Wgt Acc: 49.776%
	I - Batch: 350 | Loss: 3.153 | Acc: 59.643% | Wgt Acc: 49.562%
I - num batch: 364
I - Train -- Loss: 3.152 | Acc: 59.656% | Wgt Acc: 49.570% | LR: 1.250000e-04 | Dur: 231.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 190.    1.    1.  133.   33.]
 [   0.  300.  321.    4.   97.]
 [   1.  201.  222.    4.   72.]
 [ 412.    4.   20.  480.  284.]
 [  89.  162.  410.   97. 2277.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.699 | Acc: 36.625% | Wgt Acc: 26.385%
I - num batch: 87
I - Val -- Loss: 5.640 | Acc: 44.325% | Wgt Acc: 30.599% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  2. 112.  87.   4.  13.]
 [139.  15.  31. 141.  29.]
 [ 58. 141. 172.  59. 389.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 3.202 | Acc: 57.750% | Wgt Acc: 48.644%
	I - Batch: 100 | Loss: 3.137 | Acc: 60.750% | Wgt Acc: 50.837%
	I - Batch: 150 | Loss: 3.146 | Acc: 60.917% | Wgt Acc: 50.527%
	I - Batch: 200 | Loss: 3.129 | Acc: 61.250% | Wgt Acc: 50.703%
	I - Batch: 250 | Loss: 3.110 | Acc: 61.025% | Wgt Acc: 50.547%
	I - Batch: 300 | Loss: 3.099 | Acc: 61.125% | Wgt Acc: 50.745%
	I - Batch: 350 | Loss: 3.120 | Acc: 60.911% | Wgt Acc: 50.395%
I - num batch: 364
I - Train -- Loss: 3.128 | Acc: 60.757% | Wgt Acc: 50.288% | LR: 1.250000e-04 | Dur: 231.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 209.    1.    4.  154.   34.]
 [   1.  313.  303.    5.   64.]
 [   2.  187.  232.    6.   83.]
 [ 394.    6.   16.  450.  253.]
 [  86.  161.  419.  103. 2329.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.623 | Acc: 45.875% | Wgt Acc: 46.945%
I - num batch: 87
I - Val -- Loss: 5.615 | Acc: 47.486% | Wgt Acc: 47.133% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   5.   9.  59.  12.]
 [  1. 174. 150.   9.  53.]
 [  1.   8.   6.   4.  13.]
 [ 69.  20.  50. 104.  90.]
 [ 14.  61.  75.  28. 263.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 3.022 | Acc: 64.000% | Wgt Acc: 56.126%
	I - Batch: 100 | Loss: 3.013 | Acc: 65.000% | Wgt Acc: 57.771%
	I - Batch: 150 | Loss: 3.027 | Acc: 64.333% | Wgt Acc: 56.884%
	I - Batch: 200 | Loss: 3.039 | Acc: 63.469% | Wgt Acc: 56.356%
	I - Batch: 250 | Loss: 3.047 | Acc: 62.950% | Wgt Acc: 56.102%
	I - Batch: 300 | Loss: 3.051 | Acc: 62.812% | Wgt Acc: 56.095%
	I - Batch: 350 | Loss: 3.056 | Acc: 62.696% | Wgt Acc: 56.064%
I - num batch: 364
I - Train -- Loss: 3.055 | Acc: 62.666% | Wgt Acc: 56.010% | LR: 1.250000e-04 | Dur: 231.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 221.    3.    2.  130.   33.]
 [   3.  541.  555.   13.  123.]
 [   1.   78.  151.    8.  125.]
 [ 384.    8.   22.  488.  239.]
 [  83.   38.  244.   79. 2243.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.751 | Acc: 41.000% | Wgt Acc: 38.314%
I - num batch: 87
I - Val -- Loss: 5.696 | Acc: 46.264% | Wgt Acc: 41.398% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[158.  11.  24. 139.  34.]
 [  0. 101.  75.   1.   8.]
 [  1.  38.  36.   4.  11.]
 [ 26.  30.  29.  42.  71.]
 [ 14.  88. 126.  18. 307.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 2.988 | Acc: 61.875% | Wgt Acc: 55.885%
	I - Batch: 100 | Loss: 3.034 | Acc: 60.812% | Wgt Acc: 55.172%
	I - Batch: 150 | Loss: 3.031 | Acc: 62.708% | Wgt Acc: 57.659%
	I - Batch: 200 | Loss: 3.047 | Acc: 62.812% | Wgt Acc: 57.900%
	I - Batch: 250 | Loss: 3.022 | Acc: 62.825% | Wgt Acc: 57.379%
	I - Batch: 300 | Loss: 3.007 | Acc: 62.896% | Wgt Acc: 57.587%
	I - Batch: 350 | Loss: 3.012 | Acc: 62.214% | Wgt Acc: 56.736%
I - num batch: 364
I - Train -- Loss: 3.012 | Acc: 62.201% | Wgt Acc: 56.726% | LR: 1.250000e-04 | Dur: 231.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 248.    2.    1.  136.   43.]
 [   4.  564.  604.   13.  143.]
 [   2.   65.  159.    8.  168.]
 [ 365.   10.   14.  477.  240.]
 [  73.   27.  196.   84. 2169.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.697 | Acc: 49.125% | Wgt Acc: 45.615%
I - num batch: 87
I - Val -- Loss: 5.639 | Acc: 54.167% | Wgt Acc: 47.759% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   1.   3.  45.   9.]
 [  0. 131.  90.   3.  12.]
 [  0.  23.  26.   2.   9.]
 [ 50.  14.  30. 109.  28.]
 [ 34.  99. 141.  45. 373.]]

I - Local maximum validation set accuracy:  54.17

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 2.932 | Acc: 63.375% | Wgt Acc: 57.406%
	I - Batch: 100 | Loss: 2.928 | Acc: 63.000% | Wgt Acc: 55.984%
	I - Batch: 150 | Loss: 2.955 | Acc: 63.000% | Wgt Acc: 56.389%
	I - Batch: 200 | Loss: 2.960 | Acc: 62.625% | Wgt Acc: 56.179%
	I - Batch: 250 | Loss: 2.954 | Acc: 63.450% | Wgt Acc: 57.169%
	I - Batch: 300 | Loss: 2.961 | Acc: 63.083% | Wgt Acc: 56.867%
	I - Batch: 350 | Loss: 2.961 | Acc: 62.500% | Wgt Acc: 56.382%
I - num batch: 364
I - Train -- Loss: 2.968 | Acc: 62.253% | Wgt Acc: 56.177% | LR: 1.250000e-04 | Dur: 229.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 238.    2.    1.  157.   35.]
 [   3.  572.  619.    7.  132.]
 [   3.   72.  154.   11.  140.]
 [ 376.    5.   18.  452.  252.]
 [  72.   17.  182.   91. 2204.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.712 | Acc: 46.500% | Wgt Acc: 44.140%
I - num batch: 87
I - Val -- Loss: 5.683 | Acc: 51.006% | Wgt Acc: 46.008% | Dur: 42.37s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   5.  10.  76.  14.]
 [  1. 140. 119.   4.  27.]
 [  4.  33.  44.  10.  32.]
 [ 34.  13.  21.  69.  26.]
 [ 35.  77.  96.  45. 332.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 2.921 | Acc: 65.250% | Wgt Acc: 58.411%
	I - Batch: 100 | Loss: 2.909 | Acc: 64.188% | Wgt Acc: 58.489%
	I - Batch: 150 | Loss: 2.951 | Acc: 63.167% | Wgt Acc: 57.614%
	I - Batch: 200 | Loss: 2.946 | Acc: 63.781% | Wgt Acc: 58.009%
	I - Batch: 250 | Loss: 2.946 | Acc: 63.750% | Wgt Acc: 57.853%
	I - Batch: 300 | Loss: 2.941 | Acc: 63.708% | Wgt Acc: 57.685%
	I - Batch: 350 | Loss: 2.942 | Acc: 63.625% | Wgt Acc: 57.417%
I - num batch: 364
I - Train -- Loss: 2.942 | Acc: 63.594% | Wgt Acc: 57.515% | LR: 1.250000e-04 | Dur: 230.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 237.    1.    1.  130.   29.]
 [   1.  554.  604.    2.  114.]
 [   3.   76.  191.   10.  159.]
 [ 369.    6.   11.  487.  232.]
 [  82.   31.  167.   89. 2229.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.671 | Acc: 47.125% | Wgt Acc: 48.427%
I - num batch: 87
I - Val -- Loss: 5.665 | Acc: 49.066% | Wgt Acc: 49.860% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   9.  16.  78.  20.]
 [  0. 150. 109.   4.  26.]
 [  1.  22.  42.   2.  20.]
 [ 47.  36.  51. 108. 125.]
 [  8.  51.  72.  12. 240.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 2.898 | Acc: 64.500% | Wgt Acc: 60.159%
	I - Batch: 100 | Loss: 2.904 | Acc: 64.562% | Wgt Acc: 59.609%
	I - Batch: 150 | Loss: 2.891 | Acc: 63.708% | Wgt Acc: 58.168%
	I - Batch: 200 | Loss: 2.920 | Acc: 63.156% | Wgt Acc: 57.154%
	I - Batch: 250 | Loss: 2.928 | Acc: 63.325% | Wgt Acc: 57.245%
	I - Batch: 300 | Loss: 2.941 | Acc: 62.812% | Wgt Acc: 56.513%
	I - Batch: 350 | Loss: 2.950 | Acc: 62.643% | Wgt Acc: 56.503%
I - num batch: 364
I - Train -- Loss: 2.949 | Acc: 62.580% | Wgt Acc: 56.336% | LR: 1.250000e-04 | Dur: 230.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 184.    1.    3.   92.   26.]
 [   1.  517.  561.    7.  102.]
 [   5.  114.  233.    9.  184.]
 [ 433.    8.   15.  520.  266.]
 [  69.   28.  162.   90. 2185.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.591 | Acc: 45.125% | Wgt Acc: 42.002%
I - num batch: 87
I - Val -- Loss: 5.617 | Acc: 48.348% | Wgt Acc: 42.846% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  5. 194. 142.  20.  47.]
 [  6.  19.  31.  16.  34.]
 [139.   6.  27. 118.  20.]
 [ 49.  49.  90.  50. 330.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 3.002 | Acc: 64.000% | Wgt Acc: 55.810%
	I - Batch: 100 | Loss: 3.003 | Acc: 62.875% | Wgt Acc: 55.411%
	I - Batch: 150 | Loss: 2.996 | Acc: 62.667% | Wgt Acc: 55.274%
	I - Batch: 200 | Loss: 2.958 | Acc: 63.000% | Wgt Acc: 55.705%
	I - Batch: 250 | Loss: 2.942 | Acc: 63.450% | Wgt Acc: 56.260%
	I - Batch: 300 | Loss: 2.931 | Acc: 63.188% | Wgt Acc: 55.810%
	I - Batch: 350 | Loss: 2.928 | Acc: 62.929% | Wgt Acc: 55.674%
I - num batch: 364
I - Train -- Loss: 2.921 | Acc: 63.078% | Wgt Acc: 55.910% | LR: 1.250000e-04 | Dur: 230.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 144.    0.    1.   57.   20.]
 [   3.  462.  510.    6.   72.]
 [   1.  168.  285.    9.  193.]
 [ 480.   10.   14.  556.  257.]
 [  64.   28.  164.   90. 2221.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.645 | Acc: 48.500% | Wgt Acc: 46.952%
I - num batch: 87
I - Val -- Loss: 5.633 | Acc: 52.227% | Wgt Acc: 48.421% | Dur: 42.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   2.   3.  20.   9.]
 [  1. 131. 102.   4.  15.]
 [  1.  35.  43.   8.  15.]
 [ 83.  16.  41. 139.  74.]
 [ 18.  84. 101.  33. 318.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 3.053 | Acc: 60.875% | Wgt Acc: 53.732%
	I - Batch: 100 | Loss: 2.971 | Acc: 62.500% | Wgt Acc: 55.104%
	I - Batch: 150 | Loss: 2.944 | Acc: 62.792% | Wgt Acc: 54.857%
	I - Batch: 200 | Loss: 2.956 | Acc: 62.844% | Wgt Acc: 54.824%
	I - Batch: 250 | Loss: 2.971 | Acc: 62.450% | Wgt Acc: 54.748%
	I - Batch: 300 | Loss: 2.969 | Acc: 63.104% | Wgt Acc: 55.206%
	I - Batch: 350 | Loss: 2.969 | Acc: 63.250% | Wgt Acc: 55.425%
I - num batch: 364
I - Train -- Loss: 2.969 | Acc: 63.181% | Wgt Acc: 55.385% | LR: 1.250000e-04 | Dur: 230.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 102.    0.    0.   35.   10.]
 [   1.  369.  329.    3.   64.]
 [   2.  259.  445.   13.  222.]
 [ 512.   10.   23.  571.  280.]
 [  75.   30.  177.   96. 2187.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.564 | Acc: 45.250% | Wgt Acc: 44.720%
I - num batch: 87
I - Val -- Loss: 5.628 | Acc: 46.695% | Wgt Acc: 44.888% | Dur: 42.45s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  1. 173. 150.   8.  45.]
 [  5.  44.  62.  16.  68.]
 [169.  27.  50. 161.  64.]
 [ 24.  24.  28.  19. 254.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 3.000 | Acc: 63.000% | Wgt Acc: 55.223%
	I - Batch: 100 | Loss: 3.053 | Acc: 59.750% | Wgt Acc: 51.728%
	I - Batch: 150 | Loss: 3.020 | Acc: 61.167% | Wgt Acc: 53.046%
	I - Batch: 200 | Loss: 2.993 | Acc: 61.938% | Wgt Acc: 53.942%
	I - Batch: 250 | Loss: 2.990 | Acc: 62.275% | Wgt Acc: 54.422%
	I - Batch: 300 | Loss: 2.960 | Acc: 62.792% | Wgt Acc: 54.898%
	I - Batch: 350 | Loss: 2.961 | Acc: 62.893% | Wgt Acc: 54.672%
I - num batch: 364
I - Train -- Loss: 2.957 | Acc: 63.009% | Wgt Acc: 54.857% | LR: 1.250000e-04 | Dur: 231.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 128.    0.    1.   64.   11.]
 [   3.  301.  276.    4.   34.]
 [   5.  323.  513.   15.  259.]
 [ 476.    8.   23.  552.  289.]
 [  80.   36.  161.   83. 2170.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.563 | Acc: 48.750% | Wgt Acc: 50.545%
I - num batch: 87
I - Val -- Loss: 5.593 | Acc: 49.856% | Wgt Acc: 51.220% | Dur: 42.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   2.   8.  21.   7.]
 [  4. 160. 124.   5.  34.]
 [  0.  35.  58.   9.  67.]
 [ 93.  33.  47. 156.  95.]
 [ 10.  38.  53.  13. 228.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 2.890 | Acc: 64.750% | Wgt Acc: 56.133%
	I - Batch: 100 | Loss: 2.795 | Acc: 67.625% | Wgt Acc: 58.364%
	I - Batch: 150 | Loss: 2.822 | Acc: 66.500% | Wgt Acc: 57.486%
	I - Batch: 200 | Loss: 2.859 | Acc: 65.656% | Wgt Acc: 56.667%
	I - Batch: 250 | Loss: 2.874 | Acc: 64.750% | Wgt Acc: 55.579%
	I - Batch: 300 | Loss: 2.896 | Acc: 64.312% | Wgt Acc: 55.052%
	I - Batch: 350 | Loss: 2.905 | Acc: 63.750% | Wgt Acc: 54.820%
I - num batch: 364
I - Train -- Loss: 2.906 | Acc: 63.818% | Wgt Acc: 54.949% | LR: 1.250000e-04 | Dur: 231.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 114.    1.    0.   41.    9.]
 [   0.  236.  222.    2.   27.]
 [   8.  403.  584.   17.  254.]
 [ 493.    9.   12.  579.  275.]
 [  77.   19.  156.   79. 2198.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.704 | Acc: 44.625% | Wgt Acc: 40.584%
I - num batch: 87
I - Val -- Loss: 5.688 | Acc: 49.282% | Wgt Acc: 42.415% | Dur: 42.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 47.   0.   0.   6.   3.]
 [  2. 144. 106.   5.  21.]
 [  6.  42.  44.  12.  39.]
 [ 75.   7.  19. 104.  21.]
 [ 69.  75. 121.  77. 347.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 2.801 | Acc: 65.875% | Wgt Acc: 57.980%
	I - Batch: 100 | Loss: 2.824 | Acc: 66.000% | Wgt Acc: 57.898%
	I - Batch: 150 | Loss: 2.813 | Acc: 66.250% | Wgt Acc: 58.211%
	I - Batch: 200 | Loss: 2.823 | Acc: 65.562% | Wgt Acc: 57.521%
	I - Batch: 250 | Loss: 2.816 | Acc: 65.900% | Wgt Acc: 57.977%
	I - Batch: 300 | Loss: 2.810 | Acc: 66.104% | Wgt Acc: 58.004%
	I - Batch: 350 | Loss: 2.822 | Acc: 66.089% | Wgt Acc: 58.040%
I - num batch: 364
I - Train -- Loss: 2.822 | Acc: 65.899% | Wgt Acc: 57.668% | LR: 1.250000e-04 | Dur: 232.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 131.    0.    0.   29.   14.]
 [   0.  259.  229.    2.   29.]
 [   6.  384.  611.    8.  233.]
 [ 496.   11.   17.  610.  266.]
 [  59.   14.  117.   69. 2221.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.773 | Acc: 43.250% | Wgt Acc: 39.405%
I - num batch: 87
I - Val -- Loss: 5.715 | Acc: 49.641% | Wgt Acc: 42.890% | Dur: 42.42s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   3.   5.  50.  10.]
 [  1.  80.  59.   2.   8.]
 [  0.  63.  35.   4.   4.]
 [ 53.  32.  42. 109.  62.]
 [ 25.  90. 149.  39. 347.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 2.826 | Acc: 66.375% | Wgt Acc: 58.366%
	I - Batch: 100 | Loss: 2.793 | Acc: 66.938% | Wgt Acc: 58.899%
	I - Batch: 150 | Loss: 2.753 | Acc: 67.417% | Wgt Acc: 59.662%
	I - Batch: 200 | Loss: 2.755 | Acc: 67.031% | Wgt Acc: 58.880%
	I - Batch: 250 | Loss: 2.752 | Acc: 67.100% | Wgt Acc: 58.746%
	I - Batch: 300 | Loss: 2.767 | Acc: 66.604% | Wgt Acc: 58.364%
	I - Batch: 350 | Loss: 2.771 | Acc: 66.571% | Wgt Acc: 58.068%
I - num batch: 364
I - Train -- Loss: 2.775 | Acc: 66.346% | Wgt Acc: 57.737% | LR: 1.250000e-04 | Dur: 231.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 126.    0.    0.   24.   18.]
 [   1.  268.  257.    0.   26.]
 [   7.  374.  571.   10.  211.]
 [ 503.    7.   19.  624.  239.]
 [  55.   19.  127.   60. 2269.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.725 | Acc: 50.000% | Wgt Acc: 44.739%
I - num batch: 87
I - Val -- Loss: 5.689 | Acc: 53.520% | Wgt Acc: 46.562% | Dur: 42.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   0.   2.  20.   8.]
 [  0.  66.  51.   1.   4.]
 [  2.  99.  92.  11.  24.]
 [ 71.  31.  33. 143.  49.]
 [ 28.  72. 112.  29. 346.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 2.811 | Acc: 63.875% | Wgt Acc: 55.990%
	I - Batch: 100 | Loss: 2.766 | Acc: 65.438% | Wgt Acc: 56.936%
	I - Batch: 150 | Loss: 2.746 | Acc: 66.750% | Wgt Acc: 58.795%
	I - Batch: 200 | Loss: 2.725 | Acc: 66.812% | Wgt Acc: 59.431%
	I - Batch: 250 | Loss: 2.750 | Acc: 66.500% | Wgt Acc: 58.843%
	I - Batch: 300 | Loss: 2.745 | Acc: 66.604% | Wgt Acc: 58.746%
	I - Batch: 350 | Loss: 2.752 | Acc: 66.411% | Wgt Acc: 58.695%
I - num batch: 364
I - Train -- Loss: 2.756 | Acc: 66.483% | Wgt Acc: 58.817% | LR: 1.250000e-04 | Dur: 231.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 156.    0.    0.   18.    8.]
 [   0.  260.  247.    2.   22.]
 [   4.  384.  590.   10.  217.]
 [ 475.    8.   14.  642.  298.]
 [  57.   16.  123.   46. 2218.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.734 | Acc: 49.750% | Wgt Acc: 48.187%
I - num batch: 87
I - Val -- Loss: 5.693 | Acc: 52.802% | Wgt Acc: 49.494% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   4.   6.  55.  12.]
 [  1. 120.  87.   1.  13.]
 [  2.  50.  60.   6.  29.]
 [ 49.  37.  57. 120.  69.]
 [ 20.  57.  80.  22. 308.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 2.672 | Acc: 68.500% | Wgt Acc: 60.490%
	I - Batch: 100 | Loss: 2.649 | Acc: 68.000% | Wgt Acc: 60.386%
	I - Batch: 150 | Loss: 2.669 | Acc: 68.042% | Wgt Acc: 60.112%
	I - Batch: 200 | Loss: 2.653 | Acc: 68.531% | Wgt Acc: 60.278%
	I - Batch: 250 | Loss: 2.646 | Acc: 68.950% | Wgt Acc: 60.623%
	I - Batch: 300 | Loss: 2.681 | Acc: 68.021% | Wgt Acc: 59.474%
	I - Batch: 350 | Loss: 2.685 | Acc: 67.821% | Wgt Acc: 59.393%
I - num batch: 364
I - Train -- Loss: 2.684 | Acc: 67.721% | Wgt Acc: 59.287% | LR: 1.250000e-04 | Dur: 231.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 173.    0.    0.   27.   16.]
 [   1.  207.  199.    0.   11.]
 [   7.  437.  652.    7.  230.]
 [ 462.    8.    9.  638.  238.]
 [  49.   16.  114.   46. 2268.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.911 | Acc: 45.875% | Wgt Acc: 40.149%
I - num batch: 87
I - Val -- Loss: 5.824 | Acc: 51.724% | Wgt Acc: 43.304% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 84.   2.   2.  17.   6.]
 [  0.  86.  52.   3.   8.]
 [  3.  55.  56.   5.  25.]
 [ 64.  15.  20. 121.  19.]
 [ 48. 110. 160.  58. 373.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 2.738 | Acc: 66.375% | Wgt Acc: 59.799%
	I - Batch: 100 | Loss: 2.714 | Acc: 67.375% | Wgt Acc: 60.140%
	I - Batch: 150 | Loss: 2.722 | Acc: 66.208% | Wgt Acc: 58.622%
	I - Batch: 200 | Loss: 2.697 | Acc: 67.094% | Wgt Acc: 59.537%
	I - Batch: 250 | Loss: 2.736 | Acc: 66.575% | Wgt Acc: 58.557%
	I - Batch: 300 | Loss: 2.738 | Acc: 66.479% | Wgt Acc: 58.559%
	I - Batch: 350 | Loss: 2.739 | Acc: 66.625% | Wgt Acc: 58.768%
I - num batch: 364
I - Train -- Loss: 2.745 | Acc: 66.604% | Wgt Acc: 58.866% | LR: 1.250000e-04 | Dur: 231.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 204.    1.    0.   30.   18.]
 [   1.  243.  262.    1.   29.]
 [   4.  398.  565.   10.  214.]
 [ 426.    8.   19.  626.  267.]
 [  57.   18.  128.   51. 2235.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.533 | Acc: 48.875% | Wgt Acc: 50.621%
I - num batch: 87
I - Val -- Loss: 5.615 | Acc: 47.414% | Wgt Acc: 48.636% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 66.   3.   2.  14.   8.]
 [  2. 178. 162.  10.  56.]
 [  4.  30.  43.  16.  69.]
 [114.  29.  41. 149.  74.]
 [ 13.  28.  42.  15. 224.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 2.763 | Acc: 65.500% | Wgt Acc: 58.080%
	I - Batch: 100 | Loss: 2.791 | Acc: 65.000% | Wgt Acc: 57.617%
	I - Batch: 150 | Loss: 2.798 | Acc: 65.750% | Wgt Acc: 58.807%
	I - Batch: 200 | Loss: 2.781 | Acc: 66.156% | Wgt Acc: 58.857%
	I - Batch: 250 | Loss: 2.777 | Acc: 66.700% | Wgt Acc: 59.452%
	I - Batch: 300 | Loss: 2.766 | Acc: 67.479% | Wgt Acc: 59.853%
	I - Batch: 350 | Loss: 2.763 | Acc: 67.732% | Wgt Acc: 59.891%
I - num batch: 364
I - Train -- Loss: 2.766 | Acc: 67.687% | Wgt Acc: 59.856% | LR: 1.250000e-04 | Dur: 231.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 227.    0.    0.   41.   24.]
 [   1.  242.  235.    2.   32.]
 [   5.  396.  606.   14.  192.]
 [ 392.   11.   13.  602.  256.]
 [  67.   19.  120.   59. 2259.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.709 | Acc: 51.750% | Wgt Acc: 49.316%
I - num batch: 87
I - Val -- Loss: 5.699 | Acc: 54.598% | Wgt Acc: 50.546% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   2.  11.  47.  14.]
 [  1. 112.  85.   3.  10.]
 [  1.  57.  58.   5.  15.]
 [ 42.  23.  31. 127.  64.]
 [ 20.  74. 105.  22. 328.]]

I - Local maximum validation set accuracy:  54.60

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 2.708 | Acc: 65.500% | Wgt Acc: 57.189%
	I - Batch: 100 | Loss: 2.720 | Acc: 66.562% | Wgt Acc: 59.432%
	I - Batch: 150 | Loss: 2.713 | Acc: 67.583% | Wgt Acc: 60.347%
	I - Batch: 200 | Loss: 2.711 | Acc: 67.719% | Wgt Acc: 60.379%
	I - Batch: 250 | Loss: 2.692 | Acc: 68.725% | Wgt Acc: 61.401%
	I - Batch: 300 | Loss: 2.697 | Acc: 68.917% | Wgt Acc: 61.487%
	I - Batch: 350 | Loss: 2.704 | Acc: 68.321% | Wgt Acc: 60.641%
I - num batch: 364
I - Train -- Loss: 2.699 | Acc: 68.340% | Wgt Acc: 60.792% | LR: 1.250000e-04 | Dur: 231.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 227.    1.    0.   25.   23.]
 [   0.  235.  226.    1.   19.]
 [   1.  405.  620.   11.  216.]
 [ 405.    8.   15.  634.  247.]
 [  59.   19.  113.   47. 2258.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.859 | Acc: 45.375% | Wgt Acc: 39.512%
I - num batch: 87
I - Val -- Loss: 5.784 | Acc: 52.371% | Wgt Acc: 43.552% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   3.   5.  33.   9.]
 [  0.  80.  53.   0.   5.]
 [  3.  54.  41.   4.   4.]
 [ 49.  16.  22. 113.  25.]
 [ 40. 115. 169.  54. 388.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 2.697 | Acc: 67.500% | Wgt Acc: 58.672%
	I - Batch: 100 | Loss: 2.709 | Acc: 67.062% | Wgt Acc: 58.715%
	I - Batch: 150 | Loss: 2.688 | Acc: 68.208% | Wgt Acc: 60.431%
	I - Batch: 200 | Loss: 2.694 | Acc: 67.938% | Wgt Acc: 60.112%
	I - Batch: 250 | Loss: 2.700 | Acc: 68.400% | Wgt Acc: 60.791%
	I - Batch: 300 | Loss: 2.695 | Acc: 68.458% | Wgt Acc: 61.103%
	I - Batch: 350 | Loss: 2.683 | Acc: 68.696% | Wgt Acc: 61.381%
I - num batch: 364
I - Train -- Loss: 2.686 | Acc: 68.667% | Wgt Acc: 61.340% | LR: 1.250000e-04 | Dur: 228.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 280.    0.    1.   37.   39.]
 [   0.  251.  281.    1.   18.]
 [   1.  402.  564.    5.  173.]
 [ 345.    7.   16.  617.  252.]
 [  66.    8.  112.   58. 2281.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.615 | Acc: 49.625% | Wgt Acc: 49.139%
I - num batch: 87
I - Val -- Loss: 5.662 | Acc: 51.509% | Wgt Acc: 49.533% | Dur: 41.76s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   3.   6.  28.  15.]
 [  1. 149. 136.   0.  28.]
 [  7.  40.  56.  15.  57.]
 [ 46.  23.  27. 113.  45.]
 [ 32.  53.  65.  48. 286.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 2.701 | Acc: 71.375% | Wgt Acc: 64.019%
	I - Batch: 100 | Loss: 2.642 | Acc: 71.688% | Wgt Acc: 64.567%
	I - Batch: 150 | Loss: 2.649 | Acc: 70.500% | Wgt Acc: 63.494%
	I - Batch: 200 | Loss: 2.627 | Acc: 70.188% | Wgt Acc: 63.470%
	I - Batch: 250 | Loss: 2.638 | Acc: 70.025% | Wgt Acc: 63.083%
	I - Batch: 300 | Loss: 2.640 | Acc: 69.646% | Wgt Acc: 62.631%
	I - Batch: 350 | Loss: 2.650 | Acc: 69.446% | Wgt Acc: 62.305%
I - num batch: 364
I - Train -- Loss: 2.653 | Acc: 69.424% | Wgt Acc: 62.384% | LR: 1.250000e-04 | Dur: 228.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 279.    0.    1.   31.   42.]
 [   0.  270.  275.    2.   20.]
 [   1.  378.  569.    7.  179.]
 [ 354.    8.    7.  630.  233.]
 [  58.   12.  122.   48. 2289.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.713 | Acc: 48.625% | Wgt Acc: 45.735%
I - num batch: 87
I - Val -- Loss: 5.707 | Acc: 53.807% | Wgt Acc: 48.947% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   2.   5.  46.  18.]
 [  2. 113.  94.   4.  12.]
 [  3.  60.  62.   5.  30.]
 [ 39.  25.  29. 118.  37.]
 [ 33.  68. 100.  31. 334.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 2.607 | Acc: 72.625% | Wgt Acc: 66.236%
	I - Batch: 100 | Loss: 2.614 | Acc: 71.312% | Wgt Acc: 65.077%
	I - Batch: 150 | Loss: 2.624 | Acc: 69.917% | Wgt Acc: 63.187%
	I - Batch: 200 | Loss: 2.648 | Acc: 69.844% | Wgt Acc: 63.052%
	I - Batch: 250 | Loss: 2.666 | Acc: 69.350% | Wgt Acc: 62.591%
	I - Batch: 300 | Loss: 2.672 | Acc: 69.479% | Wgt Acc: 62.501%
	I - Batch: 350 | Loss: 2.665 | Acc: 69.875% | Wgt Acc: 63.108%
I - num batch: 364
I - Train -- Loss: 2.663 | Acc: 69.905% | Wgt Acc: 63.140% | LR: 1.250000e-04 | Dur: 228.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 307.    0.    0.   33.   39.]
 [   0.  278.  291.    0.   26.]
 [   7.  371.  551.    8.  188.]
 [ 318.    5.   13.  631.  212.]
 [  60.   14.  119.   46. 2298.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.635 | Acc: 51.125% | Wgt Acc: 50.054%
I - num batch: 87
I - Val -- Loss: 5.655 | Acc: 54.813% | Wgt Acc: 52.835% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   7.   7.  36.  24.]
 [  0. 146. 104.   7.  16.]
 [  3.  40.  67.   9.  49.]
 [ 34.  22.  31. 121.  43.]
 [ 32.  53.  81.  31. 299.]]

I - Local maximum validation set accuracy:  54.81

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 2.614 | Acc: 72.000% | Wgt Acc: 66.318%
	I - Batch: 100 | Loss: 2.627 | Acc: 71.688% | Wgt Acc: 66.114%
	I - Batch: 150 | Loss: 2.666 | Acc: 70.167% | Wgt Acc: 63.997%
	I - Batch: 200 | Loss: 2.656 | Acc: 70.281% | Wgt Acc: 64.066%
	I - Batch: 250 | Loss: 2.660 | Acc: 70.200% | Wgt Acc: 63.900%
	I - Batch: 300 | Loss: 2.651 | Acc: 70.771% | Wgt Acc: 64.498%
	I - Batch: 350 | Loss: 2.627 | Acc: 71.429% | Wgt Acc: 65.303%
I - num batch: 364
I - Train -- Loss: 2.625 | Acc: 71.402% | Wgt Acc: 65.274% | LR: 1.250000e-04 | Dur: 230.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 340.    0.    1.   22.   38.]
 [   1.  294.  299.    0.   24.]
 [   2.  345.  560.    8.  181.]
 [ 295.    6.   15.  648.  210.]
 [  54.   23.   99.   40. 2310.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.875 | Acc: 44.125% | Wgt Acc: 40.269%
I - num batch: 87
I - Val -- Loss: 5.804 | Acc: 50.718% | Wgt Acc: 44.732% | Dur: 42.32s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   9.  11.  54.  26.]
 [  0.  55.  46.   0.   2.]
 [  3.  67.  45.   3.   7.]
 [ 33.  32.  36. 125.  60.]
 [ 18. 105. 152.  22. 336.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 2.562 | Acc: 74.125% | Wgt Acc: 68.412%
	I - Batch: 100 | Loss: 2.587 | Acc: 72.375% | Wgt Acc: 65.536%
	I - Batch: 150 | Loss: 2.554 | Acc: 72.458% | Wgt Acc: 65.569%
	I - Batch: 200 | Loss: 2.576 | Acc: 71.844% | Wgt Acc: 64.726%
	I - Batch: 250 | Loss: 2.584 | Acc: 72.000% | Wgt Acc: 65.183%
	I - Batch: 300 | Loss: 2.583 | Acc: 71.854% | Wgt Acc: 65.207%
	I - Batch: 350 | Loss: 2.581 | Acc: 72.054% | Wgt Acc: 65.404%
I - num batch: 364
I - Train -- Loss: 2.577 | Acc: 72.227% | Wgt Acc: 65.660% | LR: 1.250000e-04 | Dur: 230.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 357.    0.    0.   35.   51.]
 [   0.  267.  277.    0.   18.]
 [   3.  384.  601.    3.  152.]
 [ 271.    4.   11.  634.  201.]
 [  61.   13.   85.   46. 2341.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.817 | Acc: 48.000% | Wgt Acc: 43.667%
I - num batch: 87
I - Val -- Loss: 5.782 | Acc: 52.730% | Wgt Acc: 46.315% | Dur: 42.29s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   4.   6.  31.  18.]
 [  1.  77.  56.   1.   5.]
 [  3.  63.  53.   5.  14.]
 [ 32.  26.  38. 124.  43.]
 [ 34.  98. 137.  43. 351.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 2.562 | Acc: 71.125% | Wgt Acc: 63.762%
	I - Batch: 100 | Loss: 2.579 | Acc: 71.125% | Wgt Acc: 64.035%
	I - Batch: 150 | Loss: 2.611 | Acc: 71.000% | Wgt Acc: 64.534%
	I - Batch: 200 | Loss: 2.627 | Acc: 71.094% | Wgt Acc: 64.666%
	I - Batch: 250 | Loss: 2.622 | Acc: 71.125% | Wgt Acc: 64.541%
	I - Batch: 300 | Loss: 2.607 | Acc: 71.479% | Wgt Acc: 64.994%
	I - Batch: 350 | Loss: 2.597 | Acc: 71.893% | Wgt Acc: 65.509%
I - num batch: 364
I - Train -- Loss: 2.606 | Acc: 71.488% | Wgt Acc: 65.041% | LR: 1.250000e-04 | Dur: 231.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 342.    0.    0.   23.   66.]
 [   1.  266.  260.    0.   17.]
 [   2.  381.  597.    7.  172.]
 [ 281.    9.   10.  639.  195.]
 [  66.   12.  107.   49. 2313.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.704 | Acc: 51.000% | Wgt Acc: 49.385%
I - num batch: 87
I - Val -- Loss: 5.694 | Acc: 53.017% | Wgt Acc: 51.009% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   4.  12.  43.  37.]
 [  2. 103.  86.   3.  18.]
 [  2.  63.  74.   8.  33.]
 [ 37.  30.  35. 132.  59.]
 [ 13.  68.  83.  18. 284.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 2.642 | Acc: 69.750% | Wgt Acc: 62.479%
	I - Batch: 100 | Loss: 2.573 | Acc: 72.188% | Wgt Acc: 66.741%
	I - Batch: 150 | Loss: 2.559 | Acc: 72.250% | Wgt Acc: 66.353%
	I - Batch: 200 | Loss: 2.551 | Acc: 73.156% | Wgt Acc: 67.654%
	I - Batch: 250 | Loss: 2.566 | Acc: 72.525% | Wgt Acc: 67.010%
	I - Batch: 300 | Loss: 2.584 | Acc: 72.125% | Wgt Acc: 66.577%
	I - Batch: 350 | Loss: 2.586 | Acc: 72.268% | Wgt Acc: 66.560%
I - num batch: 364
I - Train -- Loss: 2.578 | Acc: 72.313% | Wgt Acc: 66.559% | LR: 1.250000e-04 | Dur: 231.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 367.    0.    1.   24.   83.]
 [   0.  307.  304.    0.   13.]
 [   3.  334.  554.    4.  188.]
 [ 262.    9.   13.  654.  156.]
 [  60.   18.  102.   36. 2323.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.671 | Acc: 51.500% | Wgt Acc: 49.259%
I - num batch: 87
I - Val -- Loss: 5.702 | Acc: 54.239% | Wgt Acc: 50.231% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   2.   5.  25.  12.]
 [  0. 141. 118.   8.  29.]
 [  8.  59.  77.  11.  51.]
 [ 31.  14.  15. 103.  18.]
 [ 47.  52.  75.  57. 321.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 2.519 | Acc: 74.625% | Wgt Acc: 69.470%
	I - Batch: 100 | Loss: 2.628 | Acc: 73.188% | Wgt Acc: 67.054%
	I - Batch: 150 | Loss: 2.637 | Acc: 72.125% | Wgt Acc: 65.917%
	I - Batch: 200 | Loss: 2.611 | Acc: 72.344% | Wgt Acc: 66.033%
	I - Batch: 250 | Loss: 2.586 | Acc: 72.700% | Wgt Acc: 66.602%
	I - Batch: 300 | Loss: 2.590 | Acc: 72.396% | Wgt Acc: 66.482%
	I - Batch: 350 | Loss: 2.594 | Acc: 72.482% | Wgt Acc: 66.514%
I - num batch: 364
I - Train -- Loss: 2.600 | Acc: 72.433% | Wgt Acc: 66.304% | LR: 1.250000e-04 | Dur: 229.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 369.    1.    3.   31.   76.]
 [   3.  289.  283.    1.   13.]
 [   3.  360.  580.   12.  168.]
 [ 243.   10.   11.  639.  171.]
 [  74.    8.   97.   35. 2335.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.669 | Acc: 51.375% | Wgt Acc: 51.504%
I - num batch: 87
I - Val -- Loss: 5.696 | Acc: 55.029% | Wgt Acc: 53.298% | Dur: 42.02s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   7.  14.  53.  35.]
 [  3. 157. 109.   6.  28.]
 [  7.  31.  62.  14.  42.]
 [ 29.  21.  30. 108.  26.]
 [ 21.  52.  75.  23. 300.]]

I - Local maximum validation set accuracy:  55.03

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 2.480 | Acc: 74.000% | Wgt Acc: 68.050%
	I - Batch: 100 | Loss: 2.499 | Acc: 73.938% | Wgt Acc: 67.291%
	I - Batch: 150 | Loss: 2.504 | Acc: 74.125% | Wgt Acc: 67.953%
	I - Batch: 200 | Loss: 2.510 | Acc: 74.125% | Wgt Acc: 67.900%
	I - Batch: 250 | Loss: 2.516 | Acc: 74.000% | Wgt Acc: 67.826%
	I - Batch: 300 | Loss: 2.503 | Acc: 74.375% | Wgt Acc: 68.257%
	I - Batch: 350 | Loss: 2.516 | Acc: 74.179% | Wgt Acc: 68.092%
I - num batch: 364
I - Train -- Loss: 2.521 | Acc: 74.136% | Wgt Acc: 67.999% | LR: 1.250000e-04 | Dur: 229.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 401.    0.    1.   23.   65.]
 [   0.  290.  289.    0.   21.]
 [   3.  358.  592.    4.  155.]
 [ 238.    5.   10.  644.  138.]
 [  50.   15.   82.   47. 2384.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.637 | Acc: 49.125% | Wgt Acc: 48.118%
I - num batch: 87
I - Val -- Loss: 5.684 | Acc: 53.233% | Wgt Acc: 50.219% | Dur: 42.06s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   2.   9.  78.  30.]
 [  2. 141. 113.   6.  23.]
 [  3.  60.  95.  14.  60.]
 [ 16.  20.  21.  62.  21.]
 [ 32.  45.  52.  44. 297.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 2.497 | Acc: 75.000% | Wgt Acc: 69.455%
	I - Batch: 100 | Loss: 2.477 | Acc: 74.688% | Wgt Acc: 68.475%
	I - Batch: 150 | Loss: 2.502 | Acc: 73.750% | Wgt Acc: 67.225%
	I - Batch: 200 | Loss: 2.516 | Acc: 74.094% | Wgt Acc: 67.868%
	I - Batch: 250 | Loss: 2.520 | Acc: 74.250% | Wgt Acc: 68.120%
	I - Batch: 300 | Loss: 2.550 | Acc: 73.667% | Wgt Acc: 67.411%
	I - Batch: 350 | Loss: 2.560 | Acc: 73.554% | Wgt Acc: 67.141%
I - num batch: 364
I - Train -- Loss: 2.560 | Acc: 73.328% | Wgt Acc: 66.845% | LR: 1.250000e-04 | Dur: 229.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 385.    1.    2.   19.   70.]
 [   1.  268.  286.    0.   19.]
 [   2.  380.  579.    5.  150.]
 [ 245.    6.   19.  653.  145.]
 [  59.   13.   88.   41. 2379.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.745 | Acc: 50.750% | Wgt Acc: 47.614%
I - num batch: 87
I - Val -- Loss: 5.733 | Acc: 53.807% | Wgt Acc: 48.979% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   2.   9.  39.  16.]
 [  6. 131. 108.   8.  25.]
 [  1.  63.  68.  11.  40.]
 [ 22.   7.  16.  86.  16.]
 [ 40.  65.  89.  60. 334.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 2.618 | Acc: 73.750% | Wgt Acc: 68.247%
	I - Batch: 100 | Loss: 2.600 | Acc: 73.062% | Wgt Acc: 67.361%
	I - Batch: 150 | Loss: 2.562 | Acc: 74.042% | Wgt Acc: 68.534%
	I - Batch: 200 | Loss: 2.552 | Acc: 74.062% | Wgt Acc: 68.701%
	I - Batch: 250 | Loss: 2.562 | Acc: 73.600% | Wgt Acc: 67.891%
	I - Batch: 300 | Loss: 2.576 | Acc: 73.271% | Wgt Acc: 67.459%
	I - Batch: 350 | Loss: 2.569 | Acc: 73.232% | Wgt Acc: 67.382%
I - num batch: 364
I - Train -- Loss: 2.576 | Acc: 73.121% | Wgt Acc: 67.125% | LR: 1.250000e-04 | Dur: 231.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 382.    1.    1.   20.   74.]
 [   1.  286.  280.    0.   20.]
 [   2.  358.  597.    9.  174.]
 [ 245.    8.   11.  644.  152.]
 [  62.   15.   85.   45. 2343.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.672 | Acc: 48.750% | Wgt Acc: 46.264%
I - num batch: 87
I - Val -- Loss: 5.698 | Acc: 51.940% | Wgt Acc: 47.212% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   1.   3.  34.   8.]
 [  2. 140. 117.   8.  25.]
 [  4.  55.  69.  14.  58.]
 [ 27.  17.  19.  79.  17.]
 [ 54.  55.  82.  69. 323.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 2.463 | Acc: 76.125% | Wgt Acc: 71.091%
	I - Batch: 100 | Loss: 2.504 | Acc: 74.625% | Wgt Acc: 69.178%
	I - Batch: 150 | Loss: 2.496 | Acc: 74.667% | Wgt Acc: 69.220%
	I - Batch: 200 | Loss: 2.504 | Acc: 75.031% | Wgt Acc: 69.549%
	I - Batch: 250 | Loss: 2.496 | Acc: 75.100% | Wgt Acc: 69.435%
	I - Batch: 300 | Loss: 2.500 | Acc: 74.938% | Wgt Acc: 69.375%
	I - Batch: 350 | Loss: 2.520 | Acc: 74.786% | Wgt Acc: 69.092%
I - num batch: 364
I - Train -- Loss: 2.522 | Acc: 74.686% | Wgt Acc: 68.917% | LR: 1.250000e-04 | Dur: 229.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 437.    0.    1.   20.   52.]
 [   1.  301.  304.    1.   16.]
 [   1.  352.  557.    5.  164.]
 [ 205.    4.   13.  651.  134.]
 [  48.   11.   99.   41. 2397.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.730 | Acc: 50.625% | Wgt Acc: 46.851%
I - num batch: 87
I - Val -- Loss: 5.731 | Acc: 53.089% | Wgt Acc: 46.989% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   2.   7.  33.   9.]
 [  1. 132.  83.   4.  19.]
 [  8.  54.  60.  17.  38.]
 [ 17.  12.  13.  86.  14.]
 [ 63.  68. 127.  64. 351.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 2.556 | Acc: 72.750% | Wgt Acc: 68.217%
	I - Batch: 100 | Loss: 2.469 | Acc: 75.375% | Wgt Acc: 69.795%
	I - Batch: 150 | Loss: 2.454 | Acc: 75.417% | Wgt Acc: 70.021%
	I - Batch: 200 | Loss: 2.461 | Acc: 75.094% | Wgt Acc: 69.557%
	I - Batch: 250 | Loss: 2.464 | Acc: 75.200% | Wgt Acc: 69.295%
	I - Batch: 300 | Loss: 2.473 | Acc: 74.479% | Wgt Acc: 68.219%
	I - Batch: 350 | Loss: 2.475 | Acc: 74.464% | Wgt Acc: 68.150%
I - num batch: 364
I - Train -- Loss: 2.483 | Acc: 74.411% | Wgt Acc: 68.133% | LR: 1.250000e-04 | Dur: 230.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 399.    0.    0.   18.   53.]
 [   0.  328.  364.    2.   18.]
 [   1.  322.  521.    5.  125.]
 [ 229.    8.    8.  650.  138.]
 [  63.   10.   81.   43. 2429.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.684 | Acc: 51.875% | Wgt Acc: 48.616%
I - num batch: 87
I - Val -- Loss: 5.689 | Acc: 56.466% | Wgt Acc: 51.679% | Dur: 42.42s
I - Confusion Matrix: [row->prediction - col->label]
[[148.   5.  13.  60.  32.]
 [  0. 116.  66.   1.   5.]
 [  3.  64.  87.   4.  30.]
 [ 24.  13.  22.  96.  25.]
 [ 24.  70. 102.  43. 339.]]

I - Local maximum validation set accuracy:  56.47

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 2.460 | Acc: 75.875% | Wgt Acc: 70.511%
	I - Batch: 100 | Loss: 2.528 | Acc: 74.062% | Wgt Acc: 68.346%
	I - Batch: 150 | Loss: 2.551 | Acc: 73.417% | Wgt Acc: 67.124%
	I - Batch: 200 | Loss: 2.574 | Acc: 73.000% | Wgt Acc: 66.618%
	I - Batch: 250 | Loss: 2.556 | Acc: 73.300% | Wgt Acc: 66.909%
	I - Batch: 300 | Loss: 2.542 | Acc: 72.833% | Wgt Acc: 66.439%
	I - Batch: 350 | Loss: 2.540 | Acc: 73.107% | Wgt Acc: 66.954%
I - num batch: 364
I - Train -- Loss: 2.543 | Acc: 73.018% | Wgt Acc: 66.780% | LR: 1.250000e-04 | Dur: 231.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 383.    1.    2.   33.   71.]
 [   1.  304.  309.    0.   22.]
 [   3.  339.  531.    2.  154.]
 [ 229.    9.   12.  650.  138.]
 [  76.   15.  120.   33. 2378.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.756 | Acc: 47.625% | Wgt Acc: 44.184%
I - num batch: 87
I - Val -- Loss: 5.749 | Acc: 53.305% | Wgt Acc: 47.057% | Dur: 42.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   0.   2.  22.   7.]
 [  4. 146. 101.  11.  20.]
 [  3.  43.  55.  21.  35.]
 [ 26.   3.   7.  85.  12.]
 [ 67.  76. 125.  65. 357.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 2.505 | Acc: 74.125% | Wgt Acc: 68.847%
	I - Batch: 100 | Loss: 2.505 | Acc: 74.938% | Wgt Acc: 69.042%
	I - Batch: 150 | Loss: 2.497 | Acc: 75.667% | Wgt Acc: 70.035%
	I - Batch: 200 | Loss: 2.507 | Acc: 75.000% | Wgt Acc: 68.761%
	I - Batch: 250 | Loss: 2.504 | Acc: 74.850% | Wgt Acc: 68.644%
	I - Batch: 300 | Loss: 2.505 | Acc: 74.312% | Wgt Acc: 68.170%
	I - Batch: 350 | Loss: 2.509 | Acc: 74.304% | Wgt Acc: 68.128%
I - num batch: 364
I - Train -- Loss: 2.504 | Acc: 74.273% | Wgt Acc: 67.932% | LR: 1.250000e-04 | Dur: 231.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 394.    0.    1.   17.   63.]
 [   0.  282.  270.    1.   20.]
 [   5.  367.  599.    7.  146.]
 [ 214.    9.   17.  649.  139.]
 [  79.   10.   87.   44. 2395.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.713 | Acc: 50.250% | Wgt Acc: 46.050%
I - num batch: 87
I - Val -- Loss: 5.718 | Acc: 55.316% | Wgt Acc: 49.099% | Dur: 42.64s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   2.   7.  24.  13.]
 [  0. 100.  74.   1.   8.]
 [  6.  82.  79.  13.  40.]
 [ 27.  14.  18. 113.  16.]
 [ 42.  70. 112.  53. 354.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 2.431 | Acc: 76.500% | Wgt Acc: 71.801%
	I - Batch: 100 | Loss: 2.403 | Acc: 76.562% | Wgt Acc: 72.271%
	I - Batch: 150 | Loss: 2.445 | Acc: 74.833% | Wgt Acc: 70.107%
	I - Batch: 200 | Loss: 2.465 | Acc: 74.812% | Wgt Acc: 69.593%
	I - Batch: 250 | Loss: 2.489 | Acc: 74.600% | Wgt Acc: 69.194%
	I - Batch: 300 | Loss: 2.501 | Acc: 74.229% | Wgt Acc: 68.565%
	I - Batch: 350 | Loss: 2.494 | Acc: 74.196% | Wgt Acc: 68.639%
I - num batch: 364
I - Train -- Loss: 2.490 | Acc: 74.170% | Wgt Acc: 68.600% | LR: 1.250000e-04 | Dur: 232.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 429.    1.    2.   28.   80.]
 [   0.  310.  300.    1.   18.]
 [   5.  342.  565.    4.  175.]
 [ 201.    5.   14.  640.  121.]
 [  57.   10.   93.   45. 2369.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.658 | Acc: 50.500% | Wgt Acc: 50.400%
I - num batch: 87
I - Val -- Loss: 5.681 | Acc: 53.879% | Wgt Acc: 52.576% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   2.   3.  15.  21.]
 [  0. 149. 102.   6.  18.]
 [  9.  34.  57.   7.  36.]
 [ 67.  22.  42. 150.  69.]
 [ 16.  61.  86.  26. 287.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 2.436 | Acc: 75.500% | Wgt Acc: 67.990%
	I - Batch: 100 | Loss: 2.403 | Acc: 76.000% | Wgt Acc: 69.318%
	I - Batch: 150 | Loss: 2.398 | Acc: 76.833% | Wgt Acc: 70.342%
	I - Batch: 200 | Loss: 2.384 | Acc: 76.875% | Wgt Acc: 70.624%
	I - Batch: 250 | Loss: 2.371 | Acc: 76.725% | Wgt Acc: 70.801%
	I - Batch: 300 | Loss: 2.384 | Acc: 76.438% | Wgt Acc: 70.364%
	I - Batch: 350 | Loss: 2.402 | Acc: 75.946% | Wgt Acc: 69.607%
I - num batch: 364
I - Train -- Loss: 2.399 | Acc: 76.045% | Wgt Acc: 69.734% | LR: 1.250000e-04 | Dur: 230.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 415.    0.    1.   19.   73.]
 [   0.  284.  248.    1.   12.]
 [   3.  374.  621.    6.  125.]
 [ 216.    3.   10.  662.  113.]
 [  58.    7.   94.   30. 2440.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.670 | Acc: 52.750% | Wgt Acc: 52.046%
I - num batch: 87
I - Val -- Loss: 5.698 | Acc: 55.029% | Wgt Acc: 52.716% | Dur: 42.30s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   6.  18.  38.  32.]
 [  2. 127.  85.   1.  15.]
 [  3.  61.  65.   5.  45.]
 [ 34.  27.  29. 131.  35.]
 [ 21.  47.  93.  29. 304.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 2.385 | Acc: 76.125% | Wgt Acc: 70.053%
	I - Batch: 100 | Loss: 2.447 | Acc: 75.188% | Wgt Acc: 69.446%
	I - Batch: 150 | Loss: 2.470 | Acc: 74.792% | Wgt Acc: 68.739%
	I - Batch: 200 | Loss: 2.456 | Acc: 75.281% | Wgt Acc: 69.629%
	I - Batch: 250 | Loss: 2.453 | Acc: 75.500% | Wgt Acc: 69.754%
	I - Batch: 300 | Loss: 2.474 | Acc: 75.271% | Wgt Acc: 69.632%
	I - Batch: 350 | Loss: 2.478 | Acc: 75.554% | Wgt Acc: 69.965%
I - num batch: 364
I - Train -- Loss: 2.484 | Acc: 75.443% | Wgt Acc: 69.889% | LR: 1.250000e-04 | Dur: 230.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 465.    0.    1.   27.   87.]
 [   0.  262.  234.    0.   17.]
 [   6.  387.  629.    4.  144.]
 [ 161.    4.   17.  651.  135.]
 [  60.   15.   93.   36. 2380.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.664 | Acc: 51.500% | Wgt Acc: 48.635%
I - num batch: 87
I - Val -- Loss: 5.693 | Acc: 54.813% | Wgt Acc: 50.251% | Dur: 42.32s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   2.   4.  19.   8.]
 [  1. 133.  97.   5.  17.]
 [ 10.  76.  88.  13.  64.]
 [ 26.  10.  13. 105.  15.]
 [ 52.  47.  88.  62. 327.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 2.395 | Acc: 74.625% | Wgt Acc: 68.804%
	I - Batch: 100 | Loss: 2.381 | Acc: 76.500% | Wgt Acc: 71.768%
	I - Batch: 150 | Loss: 2.402 | Acc: 76.000% | Wgt Acc: 71.886%
	I - Batch: 200 | Loss: 2.419 | Acc: 76.000% | Wgt Acc: 71.757%
	I - Batch: 250 | Loss: 2.412 | Acc: 76.700% | Wgt Acc: 72.403%
	I - Batch: 300 | Loss: 2.417 | Acc: 76.854% | Wgt Acc: 72.527%
	I - Batch: 350 | Loss: 2.421 | Acc: 76.643% | Wgt Acc: 72.169%
I - num batch: 364
I - Train -- Loss: 2.420 | Acc: 76.664% | Wgt Acc: 72.147% | LR: 1.250000e-04 | Dur: 230.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 579.    0.    0.   36.  112.]
 [   1.  273.  288.    1.   15.]
 [   1.  383.  579.    5.  124.]
 [  56.    5.   14.  639.  124.]
 [  55.    7.   93.   37. 2388.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.687 | Acc: 49.500% | Wgt Acc: 46.214%
I - num batch: 87
I - Val -- Loss: 5.697 | Acc: 53.807% | Wgt Acc: 48.353% | Dur: 42.32s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   5.   8.  23.  21.]
 [  0.  91.  88.   3.  12.]
 [  3.  84.  66.   8.  33.]
 [ 36.  26.  35. 127.  26.]
 [ 34.  62.  93.  43. 339.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 2.269 | Acc: 80.375% | Wgt Acc: 77.489%
	I - Batch: 100 | Loss: 2.244 | Acc: 80.750% | Wgt Acc: 77.483%
	I - Batch: 150 | Loss: 2.283 | Acc: 80.083% | Wgt Acc: 76.046%
	I - Batch: 200 | Loss: 2.308 | Acc: 78.750% | Wgt Acc: 74.175%
	I - Batch: 250 | Loss: 2.338 | Acc: 78.125% | Wgt Acc: 73.656%
	I - Batch: 300 | Loss: 2.370 | Acc: 77.271% | Wgt Acc: 72.838%
	I - Batch: 350 | Loss: 2.388 | Acc: 76.964% | Wgt Acc: 72.583%
I - num batch: 364
I - Train -- Loss: 2.388 | Acc: 76.836% | Wgt Acc: 72.474% | LR: 1.250000e-04 | Dur: 230.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 606.    3.    2.   46.  106.]
 [   0.  235.  255.    1.   18.]
 [   2.  417.  622.    2.  167.]
 [  39.    4.   11.  638.  105.]
 [  45.    9.   84.   31. 2367.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.584 | Acc: 54.500% | Wgt Acc: 54.000%
I - num batch: 87
I - Val -- Loss: 5.648 | Acc: 55.603% | Wgt Acc: 53.641% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   2.   2.  28.  13.]
 [  3. 167. 126.  12.  27.]
 [  6.  47.  69.  11.  62.]
 [ 31.   9.  26. 111.  25.]
 [ 36.  43.  67.  42. 304.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 2.566 | Acc: 75.500% | Wgt Acc: 69.145%
	I - Batch: 100 | Loss: 2.553 | Acc: 74.875% | Wgt Acc: 70.222%
	I - Batch: 150 | Loss: 2.514 | Acc: 75.125% | Wgt Acc: 70.116%
	I - Batch: 200 | Loss: 2.490 | Acc: 75.500% | Wgt Acc: 70.578%
	I - Batch: 250 | Loss: 2.462 | Acc: 76.075% | Wgt Acc: 71.306%
	I - Batch: 300 | Loss: 2.440 | Acc: 76.500% | Wgt Acc: 72.052%
	I - Batch: 350 | Loss: 2.439 | Acc: 76.607% | Wgt Acc: 72.254%
I - num batch: 364
I - Train -- Loss: 2.440 | Acc: 76.681% | Wgt Acc: 72.301% | LR: 1.250000e-04 | Dur: 231.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 593.    1.    4.   60.  124.]
 [   0.  262.  230.    0.    9.]
 [   4.  391.  641.    6.  150.]
 [  45.    4.    9.  604.  121.]
 [  50.   10.   90.   48. 2359.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.779 | Acc: 49.125% | Wgt Acc: 44.858%
I - num batch: 87
I - Val -- Loss: 5.744 | Acc: 54.310% | Wgt Acc: 47.763% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   3.   7.  32.  14.]
 [  0.  83.  44.   0.   3.]
 [  1.  70.  73.   3.  28.]
 [ 43.  33.  43. 123.  32.]
 [ 32.  79. 123.  46. 354.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 2.255 | Acc: 79.250% | Wgt Acc: 75.204%
	I - Batch: 100 | Loss: 2.338 | Acc: 77.188% | Wgt Acc: 72.215%
	I - Batch: 150 | Loss: 2.346 | Acc: 76.792% | Wgt Acc: 72.310%
	I - Batch: 200 | Loss: 2.329 | Acc: 77.375% | Wgt Acc: 72.968%
	I - Batch: 250 | Loss: 2.347 | Acc: 77.025% | Wgt Acc: 72.649%
	I - Batch: 300 | Loss: 2.351 | Acc: 76.771% | Wgt Acc: 72.440%
	I - Batch: 350 | Loss: 2.361 | Acc: 76.571% | Wgt Acc: 72.295%
I - num batch: 364
I - Train -- Loss: 2.356 | Acc: 76.819% | Wgt Acc: 72.522% | LR: 1.250000e-04 | Dur: 230.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 609.    0.    4.   35.  129.]
 [   0.  257.  291.    0.   13.]
 [   2.  397.  579.    3.  131.]
 [  31.    4.   12.  641.  109.]
 [  50.   10.   88.   39. 2381.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.694 | Acc: 50.750% | Wgt Acc: 49.234%
I - num batch: 87
I - Val -- Loss: 5.721 | Acc: 53.305% | Wgt Acc: 50.251% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   4.  13.  35.  23.]
 [  1. 139. 102.   7.  23.]
 [  6.  47.  45.   2.  41.]
 [ 41.  19.  37. 121.  30.]
 [ 28.  59.  93.  39. 314.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 2.332 | Acc: 77.625% | Wgt Acc: 72.987%
	I - Batch: 100 | Loss: 2.360 | Acc: 77.500% | Wgt Acc: 73.106%
	I - Batch: 150 | Loss: 2.321 | Acc: 78.417% | Wgt Acc: 73.918%
	I - Batch: 200 | Loss: 2.312 | Acc: 78.031% | Wgt Acc: 73.358%
	I - Batch: 250 | Loss: 2.337 | Acc: 77.400% | Wgt Acc: 72.456%
	I - Batch: 300 | Loss: 2.323 | Acc: 77.875% | Wgt Acc: 73.149%
	I - Batch: 350 | Loss: 2.330 | Acc: 77.518% | Wgt Acc: 72.615%
I - num batch: 364
I - Train -- Loss: 2.333 | Acc: 77.438% | Wgt Acc: 72.567% | LR: 1.250000e-04 | Dur: 229.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 610.    0.    2.   35.   98.]
 [   2.  229.  265.    0.    9.]
 [   3.  425.  608.    4.  137.]
 [  37.    6.   11.  640.  103.]
 [  40.    8.   88.   39. 2416.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.775 | Acc: 48.375% | Wgt Acc: 44.278%
I - num batch: 87
I - Val -- Loss: 5.748 | Acc: 53.520% | Wgt Acc: 46.762% | Dur: 42.21s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   5.   7.  12.  17.]
 [  0.  86.  62.   2.  10.]
 [  8.  81.  57.   8.  26.]
 [ 54.  13.  26. 142.  20.]
 [ 35.  83. 138.  40. 358.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 2.367 | Acc: 77.375% | Wgt Acc: 74.475%
	I - Batch: 100 | Loss: 2.401 | Acc: 76.938% | Wgt Acc: 72.814%
	I - Batch: 150 | Loss: 2.402 | Acc: 76.708% | Wgt Acc: 72.560%
	I - Batch: 200 | Loss: 2.435 | Acc: 76.156% | Wgt Acc: 71.644%
	I - Batch: 250 | Loss: 2.434 | Acc: 76.000% | Wgt Acc: 71.755%
	I - Batch: 300 | Loss: 2.440 | Acc: 75.917% | Wgt Acc: 71.496%
	I - Batch: 350 | Loss: 2.436 | Acc: 76.107% | Wgt Acc: 72.007%
I - num batch: 364
I - Train -- Loss: 2.432 | Acc: 76.079% | Wgt Acc: 71.895% | LR: 1.250000e-04 | Dur: 229.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 586.    0.    2.   43.  141.]
 [   0.  252.  245.    1.   12.]
 [   3.  398.  619.    6.  163.]
 [  49.    9.   16.  630.  110.]
 [  54.    9.   92.   38. 2337.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.760 | Acc: 46.125% | Wgt Acc: 39.436%
I - num batch: 87
I - Val -- Loss: 5.721 | Acc: 51.940% | Wgt Acc: 43.069% | Dur: 42.23s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   0.   9.  26.  10.]
 [  0.   0.   0.   0.   0.]
 [  1. 137.  98.   2.  21.]
 [ 42.  34.  45. 145.  42.]
 [ 34.  97. 138.  31. 358.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 2.285 | Acc: 79.625% | Wgt Acc: 75.521%
	I - Batch: 100 | Loss: 2.313 | Acc: 78.188% | Wgt Acc: 74.397%
	I - Batch: 150 | Loss: 2.299 | Acc: 78.042% | Wgt Acc: 73.848%
	I - Batch: 200 | Loss: 2.310 | Acc: 77.719% | Wgt Acc: 73.906%
	I - Batch: 250 | Loss: 2.325 | Acc: 77.500% | Wgt Acc: 73.818%
	I - Batch: 300 | Loss: 2.337 | Acc: 77.042% | Wgt Acc: 73.172%
	I - Batch: 350 | Loss: 2.336 | Acc: 77.375% | Wgt Acc: 73.475%
I - num batch: 364
I - Train -- Loss: 2.340 | Acc: 77.334% | Wgt Acc: 73.360% | LR: 1.250000e-04 | Dur: 229.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 607.    2.    2.   31.  133.]
 [   0.  252.  258.    0.   12.]
 [   2.  403.  624.    3.  148.]
 [  35.    4.   11.  651.  107.]
 [  48.    7.   79.   33. 2363.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.718 | Acc: 51.000% | Wgt Acc: 48.194%
I - num batch: 87
I - Val -- Loss: 5.721 | Acc: 55.603% | Wgt Acc: 50.833% | Dur: 42.18s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   3.   9.  37.  11.]
 [  0. 139.  92.   8.  14.]
 [  6.  52.  63.  11.  43.]
 [ 20.  15.  22.  91.  18.]
 [ 37.  59. 104.  57. 345.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 2.245 | Acc: 82.875% | Wgt Acc: 79.243%
	I - Batch: 100 | Loss: 2.263 | Acc: 81.062% | Wgt Acc: 76.780%
	I - Batch: 150 | Loss: 2.286 | Acc: 80.083% | Wgt Acc: 75.876%
	I - Batch: 200 | Loss: 2.289 | Acc: 79.656% | Wgt Acc: 75.350%
	I - Batch: 250 | Loss: 2.328 | Acc: 78.350% | Wgt Acc: 73.775%
	I - Batch: 300 | Loss: 2.321 | Acc: 78.458% | Wgt Acc: 73.917%
	I - Batch: 350 | Loss: 2.320 | Acc: 78.714% | Wgt Acc: 74.141%
I - num batch: 364
I - Train -- Loss: 2.318 | Acc: 78.710% | Wgt Acc: 74.068% | LR: 1.250000e-04 | Dur: 229.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 617.    0.    3.   27.   97.]
 [   1.  239.  251.    0.    8.]
 [   2.  415.  627.    6.  138.]
 [  22.    9.    9.  657.   83.]
 [  50.    5.   84.   28. 2437.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.658 | Acc: 52.500% | Wgt Acc: 49.972%
I - num batch: 87
I - Val -- Loss: 5.679 | Acc: 54.454% | Wgt Acc: 50.550% | Dur: 42.20s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   2.   5.  38.  15.]
 [  0. 123.  83.   7.  11.]
 [  7.  70.  87.  12.  63.]
 [ 20.  11.  20. 100.  26.]
 [ 40.  62.  95.  47. 316.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 2.152 | Acc: 82.500% | Wgt Acc: 79.448%
	I - Batch: 100 | Loss: 2.259 | Acc: 80.312% | Wgt Acc: 76.211%
	I - Batch: 150 | Loss: 2.266 | Acc: 80.167% | Wgt Acc: 75.661%
	I - Batch: 200 | Loss: 2.241 | Acc: 80.531% | Wgt Acc: 76.078%
	I - Batch: 250 | Loss: 2.234 | Acc: 80.800% | Wgt Acc: 76.316%
	I - Batch: 300 | Loss: 2.254 | Acc: 80.354% | Wgt Acc: 75.719%
	I - Batch: 350 | Loss: 2.262 | Acc: 80.089% | Wgt Acc: 75.500%
I - num batch: 364
I - Train -- Loss: 2.267 | Acc: 80.069% | Wgt Acc: 75.479% | LR: 1.250000e-04 | Dur: 229.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 619.    1.    2.   23.  102.]
 [   1.  253.  226.    0.    7.]
 [   3.  398.  657.    5.  116.]
 [  22.    4.   10.  661.   72.]
 [  47.   12.   79.   29. 2466.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.700 | Acc: 46.875% | Wgt Acc: 44.795%
I - num batch: 87
I - Val -- Loss: 5.711 | Acc: 50.934% | Wgt Acc: 47.129% | Dur: 42.22s
I - Confusion Matrix: [row->prediction - col->label]
[[162.  19.  26. 106.  54.]
 [  1. 117.  73.   2.  13.]
 [  8.  72.  88.  16.  57.]
 [  5.   7.   7.  44.   9.]
 [ 23.  53.  96.  36. 298.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 2.241 | Acc: 79.750% | Wgt Acc: 74.378%
	I - Batch: 100 | Loss: 2.214 | Acc: 80.438% | Wgt Acc: 75.309%
	I - Batch: 150 | Loss: 2.214 | Acc: 80.458% | Wgt Acc: 75.569%
	I - Batch: 200 | Loss: 2.211 | Acc: 80.625% | Wgt Acc: 75.678%
	I - Batch: 250 | Loss: 2.211 | Acc: 81.075% | Wgt Acc: 76.278%
	I - Batch: 300 | Loss: 2.216 | Acc: 81.000% | Wgt Acc: 76.595%
	I - Batch: 350 | Loss: 2.218 | Acc: 80.946% | Wgt Acc: 76.387%
I - num batch: 364
I - Train -- Loss: 2.222 | Acc: 80.825% | Wgt Acc: 76.199% | LR: 1.250000e-04 | Dur: 229.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 634.    0.    1.   22.   97.]
 [   0.  222.  185.    1.    6.]
 [   2.  439.  713.    4.  118.]
 [  20.    3.    6.  663.   74.]
 [  36.    4.   69.   28. 2468.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.574 | Acc: 52.625% | Wgt Acc: 50.867%
I - num batch: 87
I - Val -- Loss: 5.634 | Acc: 53.664% | Wgt Acc: 50.977% | Dur: 42.02s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   4.  10.   9.  12.]
 [  0. 116.  80.   6.   9.]
 [  8.  96. 100.  12.  85.]
 [ 56.  24.  30. 142.  38.]
 [ 33.  28.  70.  35. 287.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 2.258 | Acc: 79.125% | Wgt Acc: 74.693%
	I - Batch: 100 | Loss: 2.299 | Acc: 78.500% | Wgt Acc: 73.522%
	I - Batch: 150 | Loss: 2.273 | Acc: 78.708% | Wgt Acc: 73.556%
	I - Batch: 200 | Loss: 2.268 | Acc: 78.906% | Wgt Acc: 74.214%
	I - Batch: 250 | Loss: 2.245 | Acc: 79.325% | Wgt Acc: 74.550%
	I - Batch: 300 | Loss: 2.250 | Acc: 79.438% | Wgt Acc: 74.840%
	I - Batch: 350 | Loss: 2.242 | Acc: 79.679% | Wgt Acc: 75.058%
I - num batch: 364
I - Train -- Loss: 2.239 | Acc: 79.948% | Wgt Acc: 75.370% | LR: 1.250000e-04 | Dur: 228.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 631.    2.    5.   19.   93.]
 [   0.  262.  270.    0.    6.]
 [   3.  397.  619.    5.  107.]
 [  24.    2.    8.  660.   80.]
 [  34.    5.   72.   34. 2477.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.818 | Acc: 48.000% | Wgt Acc: 43.862%
I - num batch: 87
I - Val -- Loss: 5.793 | Acc: 53.520% | Wgt Acc: 46.758% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[148.   8.  11.  60.  23.]
 [  0.  99.  53.   3.   6.]
 [  4.  59.  72.   8.  33.]
 [  7.  10.  13.  69.  12.]
 [ 40.  92. 141.  64. 357.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 2.196 | Acc: 83.375% | Wgt Acc: 78.826%
	I - Batch: 100 | Loss: 2.210 | Acc: 81.375% | Wgt Acc: 76.625%
	I - Batch: 150 | Loss: 2.237 | Acc: 80.625% | Wgt Acc: 76.394%
	I - Batch: 200 | Loss: 2.242 | Acc: 80.375% | Wgt Acc: 75.807%
	I - Batch: 250 | Loss: 2.229 | Acc: 80.600% | Wgt Acc: 76.064%
	I - Batch: 300 | Loss: 2.216 | Acc: 80.708% | Wgt Acc: 76.448%
	I - Batch: 350 | Loss: 2.220 | Acc: 80.375% | Wgt Acc: 75.855%
I - num batch: 364
I - Train -- Loss: 2.225 | Acc: 80.413% | Wgt Acc: 75.986% | LR: 1.250000e-04 | Dur: 228.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 639.    1.    1.   24.  107.]
 [   0.  238.  206.    1.   10.]
 [   3.  423.  683.    1.  110.]
 [  14.    3.    5.  658.   78.]
 [  36.    3.   79.   34. 2458.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.839 | Acc: 45.500% | Wgt Acc: 39.373%
I - num batch: 87
I - Val -- Loss: 5.789 | Acc: 51.078% | Wgt Acc: 42.654% | Dur: 41.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   0.   4.   7.   6.]
 [  0.  85.  36.   2.   7.]
 [  4.  89.  70.  10.  27.]
 [ 71.  19.  25. 122.  27.]
 [ 54.  75. 155.  63. 364.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 2.282 | Acc: 80.125% | Wgt Acc: 74.917%
	I - Batch: 100 | Loss: 2.278 | Acc: 79.938% | Wgt Acc: 75.317%
	I - Batch: 150 | Loss: 2.262 | Acc: 80.250% | Wgt Acc: 75.897%
	I - Batch: 200 | Loss: 2.231 | Acc: 80.844% | Wgt Acc: 76.266%
	I - Batch: 250 | Loss: 2.272 | Acc: 80.125% | Wgt Acc: 75.385%
	I - Batch: 300 | Loss: 2.286 | Acc: 80.042% | Wgt Acc: 75.170%
	I - Batch: 350 | Loss: 2.287 | Acc: 79.857% | Wgt Acc: 74.891%
I - num batch: 364
I - Train -- Loss: 2.281 | Acc: 80.034% | Wgt Acc: 75.084% | LR: 1.250000e-04 | Dur: 228.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 599.    1.    1.   23.   93.]
 [   0.  197.  139.    1.    5.]
 [   1.  461.  762.    6.  147.]
 [  41.    4.    7.  657.   79.]
 [  51.    5.   65.   31. 2439.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.529 | Acc: 53.875% | Wgt Acc: 54.284%
I - num batch: 87
I - Val -- Loss: 5.610 | Acc: 53.233% | Wgt Acc: 53.258% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   3.  10.  55.  30.]
 [  3. 145. 103.   4.  15.]
 [  6.  70. 110.  22. 105.]
 [ 25.  24.  21.  99.  34.]
 [ 25.  26.  46.  24. 247.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 2.316 | Acc: 77.875% | Wgt Acc: 72.094%
	I - Batch: 100 | Loss: 2.292 | Acc: 78.875% | Wgt Acc: 74.015%
	I - Batch: 150 | Loss: 2.249 | Acc: 79.500% | Wgt Acc: 74.327%
	I - Batch: 200 | Loss: 2.219 | Acc: 80.500% | Wgt Acc: 75.500%
	I - Batch: 250 | Loss: 2.234 | Acc: 80.100% | Wgt Acc: 75.002%
	I - Batch: 300 | Loss: 2.244 | Acc: 80.062% | Wgt Acc: 75.093%
	I - Batch: 350 | Loss: 2.249 | Acc: 79.911% | Wgt Acc: 74.919%
I - num batch: 364
I - Train -- Loss: 2.247 | Acc: 80.017% | Wgt Acc: 75.152% | LR: 1.250000e-04 | Dur: 228.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 628.    3.    1.   29.  100.]
 [   0.  208.  188.    0.    4.]
 [   4.  446.  711.    5.  134.]
 [  19.    4.    9.  651.   70.]
 [  41.    7.   65.   33. 2455.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.894 | Acc: 47.125% | Wgt Acc: 41.693%
I - num batch: 87
I - Val -- Loss: 5.826 | Acc: 51.580% | Wgt Acc: 43.978% | Dur: 41.84s
I - Confusion Matrix: [row->prediction - col->label]
[[160.   3.  18.  64.  34.]
 [  0.  49.  18.   0.   1.]
 [  3.  89.  74.   7.  25.]
 [  6.  12.  13.  81.  17.]
 [ 30. 115. 167.  52. 354.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 2.207 | Acc: 81.750% | Wgt Acc: 77.722%
	I - Batch: 100 | Loss: 2.238 | Acc: 79.875% | Wgt Acc: 75.842%
	I - Batch: 150 | Loss: 2.253 | Acc: 80.167% | Wgt Acc: 76.089%
	I - Batch: 200 | Loss: 2.258 | Acc: 79.781% | Wgt Acc: 75.930%
	I - Batch: 250 | Loss: 2.267 | Acc: 79.750% | Wgt Acc: 75.285%
	I - Batch: 300 | Loss: 2.249 | Acc: 80.000% | Wgt Acc: 75.686%
	I - Batch: 350 | Loss: 2.262 | Acc: 79.821% | Wgt Acc: 75.469%
I - num batch: 364
I - Train -- Loss: 2.265 | Acc: 79.656% | Wgt Acc: 75.277% | LR: 1.250000e-04 | Dur: 228.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 621.    1.    1.   23.   95.]
 [   0.  217.  180.    0.    7.]
 [   3.  440.  718.    5.  152.]
 [  24.    3.    8.  659.   92.]
 [  44.    7.   67.   31. 2417.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.779 | Acc: 50.000% | Wgt Acc: 46.844%
I - num batch: 87
I - Val -- Loss: 5.764 | Acc: 55.172% | Wgt Acc: 49.737% | Dur: 41.76s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   3.   7.  27.  11.]
 [  0. 111.  66.   3.  10.]
 [  2.  66.  62.   6.  29.]
 [ 30.  22.  31. 123.  32.]
 [ 44.  66. 124.  45. 349.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 2.173 | Acc: 80.125% | Wgt Acc: 75.620%
	I - Batch: 100 | Loss: 2.215 | Acc: 79.188% | Wgt Acc: 75.212%
	I - Batch: 150 | Loss: 2.228 | Acc: 79.667% | Wgt Acc: 75.765%
	I - Batch: 200 | Loss: 2.227 | Acc: 80.000% | Wgt Acc: 76.027%
	I - Batch: 250 | Loss: 2.219 | Acc: 80.300% | Wgt Acc: 76.321%
	I - Batch: 300 | Loss: 2.216 | Acc: 80.312% | Wgt Acc: 76.292%
	I - Batch: 350 | Loss: 2.229 | Acc: 79.857% | Wgt Acc: 75.666%
I - num batch: 364
I - Train -- Loss: 2.229 | Acc: 79.759% | Wgt Acc: 75.633% | LR: 1.250000e-04 | Dur: 228.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 628.    1.    1.   16.  101.]
 [   0.  229.  195.    0.    6.]
 [   3.  430.  703.    8.  155.]
 [  25.    3.    8.  664.   87.]
 [  36.    5.   67.   30. 2414.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.713 | Acc: 52.750% | Wgt Acc: 48.528%
I - num batch: 87
I - Val -- Loss: 5.728 | Acc: 55.460% | Wgt Acc: 49.059% | Dur: 41.80s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   5.   9.  54.  17.]
 [  0. 108.  56.   4.   5.]
 [  5.  94. 118.  14.  50.]
 [ 15.   2.   8.  70.  14.]
 [ 48.  59.  99.  62. 345.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 2.133 | Acc: 83.250% | Wgt Acc: 78.929%
	I - Batch: 100 | Loss: 2.107 | Acc: 84.188% | Wgt Acc: 80.367%
	I - Batch: 150 | Loss: 2.146 | Acc: 83.458% | Wgt Acc: 79.096%
	I - Batch: 200 | Loss: 2.139 | Acc: 83.469% | Wgt Acc: 79.026%
	I - Batch: 250 | Loss: 2.149 | Acc: 83.050% | Wgt Acc: 78.543%
	I - Batch: 300 | Loss: 2.130 | Acc: 83.208% | Wgt Acc: 78.808%
	I - Batch: 350 | Loss: 2.132 | Acc: 83.036% | Wgt Acc: 78.448%
I - num batch: 364
I - Train -- Loss: 2.135 | Acc: 82.803% | Wgt Acc: 78.038% | LR: 1.250000e-04 | Dur: 228.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    3.    3.   10.   79.]
 [   1.  224.  167.    0.    0.]
 [   5.  437.  749.    4.  107.]
 [  15.    1.    8.  683.   55.]
 [  34.    3.   47.   21. 2522.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.813 | Acc: 51.000% | Wgt Acc: 45.886%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 54.310% | Wgt Acc: 47.332% | Dur: 41.78s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   1.   2.  31.  24.]
 [  0.  60.  16.   1.   1.]
 [  3. 115. 111.   8.  44.]
 [ 19.  16.  19. 104.  17.]
 [ 41.  76. 142.  60. 345.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 2.179 | Acc: 82.375% | Wgt Acc: 78.278%
	I - Batch: 100 | Loss: 2.155 | Acc: 82.125% | Wgt Acc: 79.056%
	I - Batch: 150 | Loss: 2.147 | Acc: 82.250% | Wgt Acc: 78.340%
	I - Batch: 200 | Loss: 2.155 | Acc: 81.875% | Wgt Acc: 77.872%
	I - Batch: 250 | Loss: 2.160 | Acc: 82.075% | Wgt Acc: 77.824%
	I - Batch: 300 | Loss: 2.171 | Acc: 82.062% | Wgt Acc: 77.879%
	I - Batch: 350 | Loss: 2.198 | Acc: 81.732% | Wgt Acc: 77.562%
I - num batch: 364
I - Train -- Loss: 2.202 | Acc: 81.496% | Wgt Acc: 77.370% | LR: 1.250000e-04 | Dur: 228.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 634.    4.    3.   19.   81.]
 [   0.  230.  130.    0.    5.]
 [   1.  431.  755.    4.  147.]
 [  27.    2.   16.  672.   82.]
 [  30.    1.   70.   23. 2448.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.803 | Acc: 52.125% | Wgt Acc: 48.269%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 56.178% | Wgt Acc: 50.439% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   4.   9.  41.  27.]
 [  1. 101.  38.   1.   8.]
 [  5.  77.  88.  12.  35.]
 [ 18.  15.  18. 105.  12.]
 [ 36.  71. 137.  45. 349.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 2.249 | Acc: 80.000% | Wgt Acc: 77.138%
	I - Batch: 100 | Loss: 2.221 | Acc: 81.312% | Wgt Acc: 77.757%
	I - Batch: 150 | Loss: 2.225 | Acc: 80.500% | Wgt Acc: 76.857%
	I - Batch: 200 | Loss: 2.217 | Acc: 80.812% | Wgt Acc: 76.522%
	I - Batch: 250 | Loss: 2.219 | Acc: 81.025% | Wgt Acc: 76.754%
	I - Batch: 300 | Loss: 2.224 | Acc: 80.750% | Wgt Acc: 76.656%
	I - Batch: 350 | Loss: 2.218 | Acc: 81.000% | Wgt Acc: 76.730%
I - num batch: 364
I - Train -- Loss: 2.212 | Acc: 81.187% | Wgt Acc: 76.960% | LR: 1.250000e-04 | Dur: 228.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 625.    3.    4.   19.   99.]
 [   0.  225.  121.    0.    3.]
 [   5.  435.  766.    5.  145.]
 [  17.    3.   14.  666.   77.]
 [  45.    2.   69.   28. 2439.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.713 | Acc: 53.250% | Wgt Acc: 48.446%
I - num batch: 87
I - Val -- Loss: 5.712 | Acc: 55.747% | Wgt Acc: 48.692% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   1.   1.  17.  14.]
 [  0.  80.  28.   0.   4.]
 [  3. 117. 133.  16.  49.]
 [ 42.  12.  17. 111.  18.]
 [ 48.  58. 111.  60. 346.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 2.146 | Acc: 82.625% | Wgt Acc: 78.193%
	I - Batch: 100 | Loss: 2.118 | Acc: 83.938% | Wgt Acc: 79.924%
	I - Batch: 150 | Loss: 2.130 | Acc: 83.167% | Wgt Acc: 78.979%
	I - Batch: 200 | Loss: 2.110 | Acc: 83.219% | Wgt Acc: 79.316%
	I - Batch: 250 | Loss: 2.111 | Acc: 83.150% | Wgt Acc: 78.692%
	I - Batch: 300 | Loss: 2.114 | Acc: 83.104% | Wgt Acc: 78.592%
	I - Batch: 350 | Loss: 2.141 | Acc: 82.357% | Wgt Acc: 77.922%
I - num batch: 364
I - Train -- Loss: 2.144 | Acc: 82.442% | Wgt Acc: 77.994% | LR: 1.250000e-04 | Dur: 228.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    1.    2.    8.   76.]
 [   0.  209.  111.    0.    2.]
 [   1.  451.  794.    7.  139.]
 [  15.    6.    6.  677.   69.]
 [  39.    1.   61.   26. 2477.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.783 | Acc: 46.250% | Wgt Acc: 39.575%
I - num batch: 87
I - Val -- Loss: 5.754 | Acc: 51.221% | Wgt Acc: 42.794% | Dur: 41.76s
I - Confusion Matrix: [row->prediction - col->label]
[[154.   7.  18.  67.  37.]
 [  0.   0.   0.   0.   0.]
 [  2. 168. 140.   9.  34.]
 [ 14.  22.  12.  84.  25.]
 [ 29.  71. 120.  44. 335.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 2.094 | Acc: 83.625% | Wgt Acc: 80.656%
	I - Batch: 100 | Loss: 2.095 | Acc: 83.188% | Wgt Acc: 80.045%
	I - Batch: 150 | Loss: 2.116 | Acc: 82.583% | Wgt Acc: 79.342%
	I - Batch: 200 | Loss: 2.138 | Acc: 82.094% | Wgt Acc: 78.493%
	I - Batch: 250 | Loss: 2.142 | Acc: 82.300% | Wgt Acc: 78.600%
	I - Batch: 300 | Loss: 2.134 | Acc: 82.604% | Wgt Acc: 78.861%
	I - Batch: 350 | Loss: 2.138 | Acc: 82.500% | Wgt Acc: 78.769%
I - num batch: 364
I - Train -- Loss: 2.134 | Acc: 82.666% | Wgt Acc: 79.003% | LR: 1.250000e-04 | Dur: 228.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    1.    1.   11.   87.]
 [   0.  251.  114.    0.    2.]
 [   1.  411.  793.    4.  159.]
 [  15.    3.    7.  678.   67.]
 [  39.    2.   59.   25. 2448.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.990 | Acc: 44.625% | Wgt Acc: 39.966%
I - num batch: 87
I - Val -- Loss: 5.891 | Acc: 50.575% | Wgt Acc: 43.472% | Dur: 41.80s
I - Confusion Matrix: [row->prediction - col->label]
[[153.   9.  20.  62.  47.]
 [  0.  43.   4.   0.   1.]
 [  1.  64.  53.   2.   8.]
 [ 16.  32.  24. 107.  27.]
 [ 29. 120. 189.  33. 348.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 2.249 | Acc: 81.125% | Wgt Acc: 75.984%
	I - Batch: 100 | Loss: 2.226 | Acc: 81.375% | Wgt Acc: 77.248%
	I - Batch: 150 | Loss: 2.250 | Acc: 80.958% | Wgt Acc: 77.140%
	I - Batch: 200 | Loss: 2.257 | Acc: 81.062% | Wgt Acc: 77.348%
	I - Batch: 250 | Loss: 2.260 | Acc: 81.150% | Wgt Acc: 77.352%
	I - Batch: 300 | Loss: 2.248 | Acc: 81.146% | Wgt Acc: 77.167%
	I - Batch: 350 | Loss: 2.236 | Acc: 81.518% | Wgt Acc: 77.598%
I - num batch: 364
I - Train -- Loss: 2.233 | Acc: 81.668% | Wgt Acc: 77.779% | LR: 1.250000e-04 | Dur: 229.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 628.    1.    1.   26.   89.]
 [   0.  252.  115.    0.    3.]
 [   3.  405.  772.    4.  155.]
 [  21.    5.   12.  660.   79.]
 [  40.    5.   74.   28. 2437.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.853 | Acc: 48.375% | Wgt Acc: 44.209%
I - num batch: 87
I - Val -- Loss: 5.804 | Acc: 53.305% | Wgt Acc: 46.550% | Dur: 42.42s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   4.  15.  66.  34.]
 [  0.  64.  12.   0.   0.]
 [  2.  96.  96.   5.  28.]
 [ 28.  17.  28.  95.  26.]
 [ 25.  87. 139.  38. 343.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 2.170 | Acc: 80.375% | Wgt Acc: 76.098%
	I - Batch: 100 | Loss: 2.190 | Acc: 81.312% | Wgt Acc: 77.332%
	I - Batch: 150 | Loss: 2.226 | Acc: 81.125% | Wgt Acc: 76.957%
	I - Batch: 200 | Loss: 2.225 | Acc: 81.219% | Wgt Acc: 77.564%
	I - Batch: 250 | Loss: 2.245 | Acc: 80.850% | Wgt Acc: 77.121%
	I - Batch: 300 | Loss: 2.237 | Acc: 81.125% | Wgt Acc: 77.748%
	I - Batch: 350 | Loss: 2.228 | Acc: 81.143% | Wgt Acc: 77.528%
I - num batch: 364
I - Train -- Loss: 2.226 | Acc: 81.169% | Wgt Acc: 77.553% | LR: 1.250000e-04 | Dur: 231.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 630.    1.    3.   22.   78.]
 [   0.  253.  109.    1.    6.]
 [   4.  408.  778.    8.  176.]
 [  25.    2.   12.  653.   97.]
 [  33.    4.   72.   34. 2406.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.656 | Acc: 51.750% | Wgt Acc: 46.523%
I - num batch: 87
I - Val -- Loss: 5.677 | Acc: 54.239% | Wgt Acc: 48.122% | Dur: 42.46s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   2.   6.  20.  15.]
 [  0.  61.   9.   3.   6.]
 [ 11. 163. 186.  35.  87.]
 [ 26.   9.  17.  95.  19.]
 [ 53.  33.  72.  51. 304.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 2.191 | Acc: 83.250% | Wgt Acc: 80.260%
	I - Batch: 100 | Loss: 2.155 | Acc: 83.125% | Wgt Acc: 80.289%
	I - Batch: 150 | Loss: 2.158 | Acc: 82.792% | Wgt Acc: 79.632%
	I - Batch: 200 | Loss: 2.180 | Acc: 82.188% | Wgt Acc: 78.492%
	I - Batch: 250 | Loss: 2.169 | Acc: 82.375% | Wgt Acc: 78.728%
	I - Batch: 300 | Loss: 2.168 | Acc: 82.708% | Wgt Acc: 78.974%
	I - Batch: 350 | Loss: 2.168 | Acc: 82.661% | Wgt Acc: 78.984%
I - num batch: 364
I - Train -- Loss: 2.167 | Acc: 82.683% | Wgt Acc: 79.076% | LR: 1.250000e-04 | Dur: 231.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    0.    1.   17.   93.]
 [   1.  244.   86.    0.    0.]
 [   1.  414.  834.   10.  170.]
 [  12.    4.    6.  668.   70.]
 [  46.    6.   47.   23. 2430.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.750 | Acc: 52.625% | Wgt Acc: 48.364%
I - num batch: 87
I - Val -- Loss: 5.725 | Acc: 54.095% | Wgt Acc: 49.198% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   3.  14.  23.  22.]
 [  0.  64.  24.   0.   3.]
 [  4. 104. 115.   8.  42.]
 [ 58.  46.  39. 149.  53.]
 [ 23.  51.  98.  24. 311.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 2.108 | Acc: 82.875% | Wgt Acc: 79.394%
	I - Batch: 100 | Loss: 2.130 | Acc: 82.938% | Wgt Acc: 79.252%
	I - Batch: 150 | Loss: 2.150 | Acc: 83.083% | Wgt Acc: 79.883%
	I - Batch: 200 | Loss: 2.144 | Acc: 83.094% | Wgt Acc: 79.953%
	I - Batch: 250 | Loss: 2.135 | Acc: 83.125% | Wgt Acc: 79.801%
	I - Batch: 300 | Loss: 2.139 | Acc: 83.042% | Wgt Acc: 79.670%
	I - Batch: 350 | Loss: 2.146 | Acc: 83.054% | Wgt Acc: 79.777%
I - num batch: 364
I - Train -- Loss: 2.144 | Acc: 83.027% | Wgt Acc: 79.891% | LR: 1.250000e-04 | Dur: 231.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 641.    2.    0.   16.  116.]
 [   0.  266.   80.    0.    1.]
 [   4.  399.  822.    6.  145.]
 [  11.    1.    8.  676.   78.]
 [  36.    0.   64.   20. 2423.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.779 | Acc: 50.875% | Wgt Acc: 46.668%
I - num batch: 87
I - Val -- Loss: 5.763 | Acc: 55.532% | Wgt Acc: 48.832% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   2.   6.  30.   8.]
 [  0.  91.  36.   2.   6.]
 [  6.  87. 112.   9.  43.]
 [ 27.  12.  25. 105.  25.]
 [ 50.  76. 111.  58. 349.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 2.110 | Acc: 83.375% | Wgt Acc: 79.066%
	I - Batch: 100 | Loss: 2.119 | Acc: 84.375% | Wgt Acc: 80.290%
	I - Batch: 150 | Loss: 2.145 | Acc: 83.208% | Wgt Acc: 78.952%
	I - Batch: 200 | Loss: 2.186 | Acc: 82.062% | Wgt Acc: 78.598%
	I - Batch: 250 | Loss: 2.195 | Acc: 82.125% | Wgt Acc: 78.503%
	I - Batch: 300 | Loss: 2.181 | Acc: 82.354% | Wgt Acc: 78.811%
	I - Batch: 350 | Loss: 2.185 | Acc: 82.357% | Wgt Acc: 79.108%
I - num batch: 364
I - Train -- Loss: 2.184 | Acc: 82.528% | Wgt Acc: 79.264% | LR: 1.250000e-04 | Dur: 232.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 631.    1.    1.   14.   78.]
 [   0.  281.  118.    0.    4.]
 [   4.  377.  788.    8.  175.]
 [  22.    7.   12.  671.   78.]
 [  35.    2.   55.   25. 2428.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.850 | Acc: 48.875% | Wgt Acc: 43.118%
I - num batch: 87
I - Val -- Loss: 5.800 | Acc: 53.736% | Wgt Acc: 45.908% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   7.   5.  30.  18.]
 [  0.  55.  12.   2.   2.]
 [  5. 105. 122.  17.  44.]
 [ 13.  13.  13.  89.  17.]
 [ 49.  88. 138.  66. 350.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 2.076 | Acc: 84.750% | Wgt Acc: 82.100%
	I - Batch: 100 | Loss: 2.121 | Acc: 83.375% | Wgt Acc: 79.271%
	I - Batch: 150 | Loss: 2.107 | Acc: 84.292% | Wgt Acc: 80.532%
	I - Batch: 200 | Loss: 2.179 | Acc: 82.844% | Wgt Acc: 79.133%
	I - Batch: 250 | Loss: 2.227 | Acc: 82.000% | Wgt Acc: 78.184%
	I - Batch: 300 | Loss: 2.255 | Acc: 81.438% | Wgt Acc: 77.743%
	I - Batch: 350 | Loss: 2.258 | Acc: 80.821% | Wgt Acc: 77.015%
I - num batch: 364
I - Train -- Loss: 2.250 | Acc: 81.066% | Wgt Acc: 77.445% | LR: 1.250000e-04 | Dur: 232.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 619.    0.    1.   28.  106.]
 [   0.  257.  108.    0.    2.]
 [   3.  404.  778.    6.  169.]
 [  37.    3.   14.  657.   83.]
 [  33.    4.   73.   27. 2403.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.679 | Acc: 54.000% | Wgt Acc: 51.138%
I - num batch: 87
I - Val -- Loss: 5.707 | Acc: 55.029% | Wgt Acc: 50.961% | Dur: 42.78s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   4.  12.  45.  16.]
 [  1.  97.  36.   5.  13.]
 [ 13. 109. 156.  24.  92.]
 [ 11.  11.  11.  84.  16.]
 [ 39.  47.  75.  46. 294.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 2.167 | Acc: 82.125% | Wgt Acc: 79.410%
	I - Batch: 100 | Loss: 2.114 | Acc: 83.688% | Wgt Acc: 80.776%
	I - Batch: 150 | Loss: 2.137 | Acc: 83.458% | Wgt Acc: 80.837%
	I - Batch: 200 | Loss: 2.145 | Acc: 82.594% | Wgt Acc: 79.397%
	I - Batch: 250 | Loss: 2.134 | Acc: 82.600% | Wgt Acc: 79.690%
	I - Batch: 300 | Loss: 2.143 | Acc: 82.604% | Wgt Acc: 79.397%
	I - Batch: 350 | Loss: 2.131 | Acc: 83.179% | Wgt Acc: 79.965%
I - num batch: 364
I - Train -- Loss: 2.130 | Acc: 83.233% | Wgt Acc: 80.075% | LR: 1.250000e-04 | Dur: 232.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    2.    4.   16.   80.]
 [   0.  292.  118.    0.    4.]
 [   2.  368.  797.    2.  158.]
 [  18.    1.    4.  672.   79.]
 [  35.    5.   51.   28. 2442.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.764 | Acc: 51.500% | Wgt Acc: 48.206%
I - num batch: 87
I - Val -- Loss: 5.738 | Acc: 54.741% | Wgt Acc: 49.829% | Dur: 42.77s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   1.   8.  28.  24.]
 [  0.  72.  25.   0.   2.]
 [  1.  97. 110.  12.  41.]
 [ 41.  26.  46. 133.  46.]
 [ 28.  72. 101.  31. 318.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 2.103 | Acc: 84.375% | Wgt Acc: 81.279%
	I - Batch: 100 | Loss: 2.089 | Acc: 84.438% | Wgt Acc: 80.838%
	I - Batch: 150 | Loss: 2.078 | Acc: 84.458% | Wgt Acc: 80.791%
	I - Batch: 200 | Loss: 2.071 | Acc: 85.062% | Wgt Acc: 81.665%
	I - Batch: 250 | Loss: 2.072 | Acc: 85.200% | Wgt Acc: 81.854%
	I - Batch: 300 | Loss: 2.069 | Acc: 85.104% | Wgt Acc: 81.560%
	I - Batch: 350 | Loss: 2.083 | Acc: 84.875% | Wgt Acc: 81.536%
I - num batch: 364
I - Train -- Loss: 2.083 | Acc: 84.798% | Wgt Acc: 81.525% | LR: 1.250000e-04 | Dur: 232.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 635.    1.    0.    7.   81.]
 [   1.  307.   89.    0.    0.]
 [   4.  355.  818.    5.  144.]
 [  10.    2.   11.  682.   49.]
 [  42.    3.   56.   24. 2489.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.621 | Acc: 56.000% | Wgt Acc: 53.206%
I - num batch: 87
I - Val -- Loss: 5.678 | Acc: 56.681% | Wgt Acc: 53.653% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   4.  20.  45.  28.]
 [  0.  77.  14.   0.   1.]
 [ 12. 137. 179.  18.  96.]
 [ 20.  12.  26. 109.  29.]
 [ 20.  38.  51.  32. 277.]]

I - Local maximum validation set accuracy:  56.68

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 2.067 | Acc: 84.000% | Wgt Acc: 80.896%
	I - Batch: 100 | Loss: 2.033 | Acc: 85.125% | Wgt Acc: 81.816%
	I - Batch: 150 | Loss: 2.025 | Acc: 85.750% | Wgt Acc: 82.415%
	I - Batch: 200 | Loss: 2.042 | Acc: 85.906% | Wgt Acc: 82.803%
	I - Batch: 250 | Loss: 2.052 | Acc: 85.525% | Wgt Acc: 82.522%
	I - Batch: 300 | Loss: 2.047 | Acc: 85.417% | Wgt Acc: 82.305%
	I - Batch: 350 | Loss: 2.053 | Acc: 85.232% | Wgt Acc: 81.989%
I - num batch: 364
I - Train -- Loss: 2.055 | Acc: 85.279% | Wgt Acc: 82.025% | LR: 1.250000e-04 | Dur: 232.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 647.    0.    0.   11.   78.]
 [   0.  282.   68.    0.    1.]
 [   3.  381.  861.    2.  138.]
 [  13.    2.    5.  684.   61.]
 [  29.    3.   40.   21. 2485.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.882 | Acc: 49.375% | Wgt Acc: 43.137%
I - num batch: 87
I - Val -- Loss: 5.820 | Acc: 55.101% | Wgt Acc: 46.590% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   0.   7.  24.  16.]
 [  0.  54.   7.   0.   0.]
 [  9. 111. 144.  18.  38.]
 [ 18.   7.  12.  94.  19.]
 [ 55.  96. 120.  68. 358.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 2.073 | Acc: 85.625% | Wgt Acc: 82.403%
	I - Batch: 100 | Loss: 2.087 | Acc: 84.625% | Wgt Acc: 81.580%
	I - Batch: 150 | Loss: 2.060 | Acc: 85.625% | Wgt Acc: 82.687%
	I - Batch: 200 | Loss: 2.064 | Acc: 85.250% | Wgt Acc: 82.040%
	I - Batch: 250 | Loss: 2.064 | Acc: 84.975% | Wgt Acc: 81.659%
	I - Batch: 300 | Loss: 2.086 | Acc: 84.417% | Wgt Acc: 81.260%
	I - Batch: 350 | Loss: 2.091 | Acc: 84.589% | Wgt Acc: 81.619%
I - num batch: 364
I - Train -- Loss: 2.095 | Acc: 84.592% | Wgt Acc: 81.689% | LR: 1.250000e-04 | Dur: 232.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    0.    2.   12.   71.]
 [   0.  294.   85.    1.    2.]
 [   4.  365.  833.    6.  162.]
 [   7.    4.    6.  676.   70.]
 [  23.    5.   48.   23. 2458.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.785 | Acc: 51.750% | Wgt Acc: 47.796%
I - num batch: 87
I - Val -- Loss: 5.760 | Acc: 55.029% | Wgt Acc: 49.697% | Dur: 42.81s
I - Confusion Matrix: [row->prediction - col->label]
[[151.   6.  19.  54.  37.]
 [  0.  62.  13.   0.   1.]
 [  4.  99. 112.   6.  39.]
 [ 25.  31.  29. 116.  29.]
 [ 19.  70. 117.  28. 325.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 2.081 | Acc: 83.125% | Wgt Acc: 80.166%
	I - Batch: 100 | Loss: 2.097 | Acc: 83.312% | Wgt Acc: 80.043%
	I - Batch: 150 | Loss: 2.125 | Acc: 83.125% | Wgt Acc: 79.797%
	I - Batch: 200 | Loss: 2.122 | Acc: 83.312% | Wgt Acc: 79.971%
	I - Batch: 250 | Loss: 2.134 | Acc: 83.275% | Wgt Acc: 80.134%
	I - Batch: 300 | Loss: 2.135 | Acc: 83.646% | Wgt Acc: 80.662%
	I - Batch: 350 | Loss: 2.125 | Acc: 83.554% | Wgt Acc: 80.604%
I - num batch: 364
I - Train -- Loss: 2.129 | Acc: 83.422% | Wgt Acc: 80.419% | LR: 1.250000e-04 | Dur: 232.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 641.    0.    2.   21.   94.]
 [   0.  291.   85.    0.    0.]
 [   1.  373.  816.    4.  168.]
 [  13.    4.   13.  670.   68.]
 [  37.    0.   58.   23. 2433.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.792 | Acc: 51.125% | Wgt Acc: 45.577%
I - num batch: 87
I - Val -- Loss: 5.773 | Acc: 54.741% | Wgt Acc: 47.408% | Dur: 43.19s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.  12.  32.  18.]
 [  0.  54.   9.   0.   1.]
 [  3. 111. 137.   6.  40.]
 [ 39.  32.  27. 119.  31.]
 [ 46.  70. 105.  47. 341.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 2.045 | Acc: 84.250% | Wgt Acc: 80.032%
	I - Batch: 100 | Loss: 2.044 | Acc: 85.000% | Wgt Acc: 81.984%
	I - Batch: 150 | Loss: 2.049 | Acc: 84.625% | Wgt Acc: 81.040%
	I - Batch: 200 | Loss: 2.042 | Acc: 85.031% | Wgt Acc: 82.011%
	I - Batch: 250 | Loss: 2.030 | Acc: 85.925% | Wgt Acc: 83.154%
	I - Batch: 300 | Loss: 2.027 | Acc: 85.792% | Wgt Acc: 83.098%
	I - Batch: 350 | Loss: 2.018 | Acc: 86.000% | Wgt Acc: 83.059%
I - num batch: 364
I - Train -- Loss: 2.015 | Acc: 86.002% | Wgt Acc: 83.084% | LR: 1.250000e-04 | Dur: 234.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 649.    3.    2.    7.   58.]
 [   0.  326.   84.    0.    2.]
 [   3.  336.  842.    2.  148.]
 [   7.    2.    6.  683.   54.]
 [  33.    1.   40.   26. 2501.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.741 | Acc: 55.250% | Wgt Acc: 50.678%
I - num batch: 87
I - Val -- Loss: 5.739 | Acc: 57.471% | Wgt Acc: 51.368% | Dur: 43.30s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   3.   7.  23.  11.]
 [  1.  78.  13.   1.   6.]
 [  6. 104. 164.  12.  55.]
 [ 31.  22.  20. 109.  29.]
 [ 42.  61.  86.  59. 330.]]

I - Local maximum validation set accuracy:  57.47

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 2.084 | Acc: 84.125% | Wgt Acc: 81.855%
	I - Batch: 100 | Loss: 2.022 | Acc: 86.688% | Wgt Acc: 83.848%
	I - Batch: 150 | Loss: 1.980 | Acc: 88.125% | Wgt Acc: 85.689%
	I - Batch: 200 | Loss: 1.997 | Acc: 87.312% | Wgt Acc: 84.487%
	I - Batch: 250 | Loss: 2.051 | Acc: 86.575% | Wgt Acc: 83.614%
	I - Batch: 300 | Loss: 2.070 | Acc: 86.188% | Wgt Acc: 83.199%
	I - Batch: 350 | Loss: 2.078 | Acc: 86.071% | Wgt Acc: 83.061%
I - num batch: 364
I - Train -- Loss: 2.079 | Acc: 86.122% | Wgt Acc: 83.088% | LR: 1.250000e-04 | Dur: 234.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    1.    1.   20.   71.]
 [   0.  342.   77.    0.    1.]
 [   3.  320.  852.    5.  123.]
 [  23.    2.   12.  674.   60.]
 [  34.    3.   32.   19. 2508.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.641 | Acc: 56.750% | Wgt Acc: 54.788%
I - num batch: 87
I - Val -- Loss: 5.687 | Acc: 57.830% | Wgt Acc: 55.495% | Dur: 42.88s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   2.   8.  32.  11.]
 [  0. 139.  67.   9.  19.]
 [ 13.  81. 141.  25.  84.]
 [ 25.   8.  10. 105.  25.]
 [ 33.  38.  64.  33. 292.]]

I - Local maximum validation set accuracy:  57.83

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 2.007 | Acc: 86.500% | Wgt Acc: 83.538%
	I - Batch: 100 | Loss: 1.983 | Acc: 87.562% | Wgt Acc: 84.234%
	I - Batch: 150 | Loss: 2.011 | Acc: 86.042% | Wgt Acc: 82.579%
	I - Batch: 200 | Loss: 2.006 | Acc: 86.344% | Wgt Acc: 83.400%
	I - Batch: 250 | Loss: 2.031 | Acc: 85.725% | Wgt Acc: 82.662%
	I - Batch: 300 | Loss: 2.040 | Acc: 85.333% | Wgt Acc: 82.386%
	I - Batch: 350 | Loss: 2.045 | Acc: 85.393% | Wgt Acc: 82.608%
I - num batch: 364
I - Train -- Loss: 2.041 | Acc: 85.486% | Wgt Acc: 82.754% | LR: 1.250000e-04 | Dur: 233.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 650.    1.    1.    3.   76.]
 [   0.  319.   90.    0.    3.]
 [   1.  341.  831.    5.  137.]
 [   8.    2.   10.  692.   68.]
 [  33.    5.   42.   18. 2479.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.770 | Acc: 51.375% | Wgt Acc: 47.046%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 53.951% | Wgt Acc: 49.055% | Dur: 42.94s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   1.  11.  38.  19.]
 [  1.  46.   7.   0.   4.]
 [ 13. 153. 204.  22. 111.]
 [ 19.  15.   6.  88.  19.]
 [ 31.  53.  62.  56. 278.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 2.004 | Acc: 87.000% | Wgt Acc: 84.564%
	I - Batch: 100 | Loss: 1.998 | Acc: 87.250% | Wgt Acc: 84.758%
	I - Batch: 150 | Loss: 2.003 | Acc: 86.375% | Wgt Acc: 83.600%
	I - Batch: 200 | Loss: 1.994 | Acc: 86.969% | Wgt Acc: 84.610%
	I - Batch: 250 | Loss: 1.994 | Acc: 87.075% | Wgt Acc: 84.703%
	I - Batch: 300 | Loss: 2.000 | Acc: 86.750% | Wgt Acc: 84.286%
	I - Batch: 350 | Loss: 2.001 | Acc: 86.643% | Wgt Acc: 84.040%
I - num batch: 364
I - Train -- Loss: 2.001 | Acc: 86.655% | Wgt Acc: 84.142% | LR: 1.250000e-04 | Dur: 232.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 657.    1.    1.    5.   68.]
 [   0.  338.   71.    1.    0.]
 [   6.  324.  857.    2.  139.]
 [   2.    2.    6.  691.   60.]
 [  27.    3.   39.   19. 2496.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.907 | Acc: 47.875% | Wgt Acc: 43.503%
I - num batch: 87
I - Val -- Loss: 5.836 | Acc: 53.736% | Wgt Acc: 47.308% | Dur: 42.93s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   8.  10.  55.  41.]
 [  0.  51.   9.   0.   1.]
 [  2.  86. 104.   3.  21.]
 [ 28.  29.  26. 112.  32.]
 [ 24.  94. 141.  34. 336.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 1.989 | Acc: 86.875% | Wgt Acc: 84.117%
	I - Batch: 100 | Loss: 2.015 | Acc: 85.750% | Wgt Acc: 82.566%
	I - Batch: 150 | Loss: 2.037 | Acc: 85.208% | Wgt Acc: 82.403%
	I - Batch: 200 | Loss: 2.019 | Acc: 86.062% | Wgt Acc: 83.443%
	I - Batch: 250 | Loss: 2.021 | Acc: 86.325% | Wgt Acc: 83.571%
	I - Batch: 300 | Loss: 2.016 | Acc: 86.500% | Wgt Acc: 84.088%
	I - Batch: 350 | Loss: 2.010 | Acc: 86.446% | Wgt Acc: 83.978%
I - num batch: 364
I - Train -- Loss: 2.008 | Acc: 86.414% | Wgt Acc: 83.889% | LR: 1.250000e-04 | Dur: 233.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 653.    2.    1.    2.   69.]
 [   0.  341.   73.    0.    2.]
 [   3.  320.  850.    3.  134.]
 [   6.    2.    6.  689.   66.]
 [  30.    3.   44.   24. 2492.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.856 | Acc: 50.250% | Wgt Acc: 44.039%
I - num batch: 87
I - Val -- Loss: 5.822 | Acc: 55.316% | Wgt Acc: 46.870% | Dur: 42.94s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   0.   3.  26.  14.]
 [  0.  55.  12.   0.   2.]
 [  3. 107. 120.   6.  25.]
 [ 31.  16.  24. 106.  23.]
 [ 43.  90. 131.  66. 367.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 1.960 | Acc: 88.250% | Wgt Acc: 85.966%
	I - Batch: 100 | Loss: 1.971 | Acc: 88.188% | Wgt Acc: 85.620%
	I - Batch: 150 | Loss: 1.998 | Acc: 88.542% | Wgt Acc: 86.060%
	I - Batch: 200 | Loss: 1.996 | Acc: 87.875% | Wgt Acc: 85.397%
	I - Batch: 250 | Loss: 2.001 | Acc: 87.675% | Wgt Acc: 84.980%
	I - Batch: 300 | Loss: 2.003 | Acc: 88.021% | Wgt Acc: 85.508%
	I - Batch: 350 | Loss: 2.020 | Acc: 87.339% | Wgt Acc: 84.900%
I - num batch: 364
I - Train -- Loss: 2.030 | Acc: 87.068% | Wgt Acc: 84.583% | LR: 1.250000e-04 | Dur: 232.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    0.    0.    8.   76.]
 [   0.  358.   61.    0.    0.]
 [   4.  304.  865.    7.  123.]
 [  12.    5.    7.  683.   58.]
 [  25.    1.   41.   20. 2506.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.607 | Acc: 57.000% | Wgt Acc: 56.251%
I - num batch: 87
I - Val -- Loss: 5.670 | Acc: 57.543% | Wgt Acc: 56.393% | Dur: 42.89s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   4.   9.  33.  16.]
 [  1. 147.  77.   3.  14.]
 [  8.  71. 129.  19.  87.]
 [ 36.  12.  19. 124.  36.]
 [ 31.  34.  56.  25. 278.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 2.145 | Acc: 82.125% | Wgt Acc: 78.741%
	I - Batch: 100 | Loss: 2.102 | Acc: 83.250% | Wgt Acc: 80.744%
	I - Batch: 150 | Loss: 2.056 | Acc: 84.250% | Wgt Acc: 82.014%
	I - Batch: 200 | Loss: 2.045 | Acc: 85.312% | Wgt Acc: 83.137%
	I - Batch: 250 | Loss: 2.026 | Acc: 85.950% | Wgt Acc: 83.414%
	I - Batch: 300 | Loss: 2.038 | Acc: 85.750% | Wgt Acc: 83.074%
	I - Batch: 350 | Loss: 2.072 | Acc: 85.107% | Wgt Acc: 82.488%
I - num batch: 364
I - Train -- Loss: 2.077 | Acc: 85.039% | Wgt Acc: 82.417% | LR: 1.250000e-04 | Dur: 232.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    2.    3.   13.   79.]
 [   0.  331.   75.    0.    1.]
 [   5.  329.  841.    5.  161.]
 [  21.    2.    9.  679.   65.]
 [  29.    4.   46.   21. 2457.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.760 | Acc: 56.375% | Wgt Acc: 53.042%
I - num batch: 87
I - Val -- Loss: 5.745 | Acc: 59.052% | Wgt Acc: 54.797% | Dur: 42.87s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   3.   5.  28.  17.]
 [  1.  96.  24.   1.   4.]
 [  3.  71. 129.   6.  41.]
 [ 35.  34.  41. 134.  43.]
 [ 23.  64.  91.  35. 326.]]

I - Local maximum validation set accuracy:  59.05

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 2.134 | Acc: 84.875% | Wgt Acc: 82.186%
	I - Batch: 100 | Loss: 2.099 | Acc: 84.688% | Wgt Acc: 82.130%
	I - Batch: 150 | Loss: 2.102 | Acc: 84.500% | Wgt Acc: 82.031%
	I - Batch: 200 | Loss: 2.113 | Acc: 84.062% | Wgt Acc: 81.330%
	I - Batch: 250 | Loss: 2.089 | Acc: 84.725% | Wgt Acc: 82.158%
	I - Batch: 300 | Loss: 2.079 | Acc: 85.208% | Wgt Acc: 82.625%
	I - Batch: 350 | Loss: 2.064 | Acc: 85.464% | Wgt Acc: 82.895%
I - num batch: 364
I - Train -- Loss: 2.064 | Acc: 85.451% | Wgt Acc: 82.764% | LR: 1.250000e-04 | Dur: 230.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 639.    1.    0.    7.   83.]
 [   1.  335.   82.    0.    2.]
 [   3.  325.  842.    6.  135.]
 [  13.    4.    9.  680.   70.]
 [  36.    3.   41.   25. 2473.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.718 | Acc: 57.625% | Wgt Acc: 53.811%
I - num batch: 87
I - Val -- Loss: 5.738 | Acc: 58.836% | Wgt Acc: 53.593% | Dur: 42.07s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   5.   9.  61.  15.]
 [  1. 108.  25.   1.   7.]
 [  9.  86. 150.  11.  55.]
 [ 10.  12.  17.  82.  20.]
 [ 34.  57.  89.  49. 334.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 2.037 | Acc: 83.625% | Wgt Acc: 80.788%
	I - Batch: 100 | Loss: 2.049 | Acc: 84.688% | Wgt Acc: 81.575%
	I - Batch: 150 | Loss: 2.020 | Acc: 85.792% | Wgt Acc: 83.099%
	I - Batch: 200 | Loss: 2.009 | Acc: 85.750% | Wgt Acc: 82.827%
	I - Batch: 250 | Loss: 2.010 | Acc: 85.700% | Wgt Acc: 82.936%
	I - Batch: 300 | Loss: 2.014 | Acc: 85.771% | Wgt Acc: 82.798%
	I - Batch: 350 | Loss: 2.021 | Acc: 85.750% | Wgt Acc: 82.787%
I - num batch: 364
I - Train -- Loss: 2.022 | Acc: 85.727% | Wgt Acc: 82.654% | LR: 1.250000e-04 | Dur: 229.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    1.    1.    4.   63.]
 [   0.  309.   78.    0.    2.]
 [   4.  353.  851.    5.  157.]
 [  15.    4.    6.  693.   46.]
 [  36.    1.   38.   16. 2495.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.936 | Acc: 48.875% | Wgt Acc: 41.870%
I - num batch: 87
I - Val -- Loss: 5.869 | Acc: 54.239% | Wgt Acc: 45.151% | Dur: 42.10s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   2.   4.  33.  16.]
 [  0.  48.   9.   0.   1.]
 [  6. 109. 136.  12.  39.]
 [ 19.   2.   6.  79.  10.]
 [ 47. 107. 135.  80. 365.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 1.948 | Acc: 89.250% | Wgt Acc: 86.395%
	I - Batch: 100 | Loss: 1.915 | Acc: 89.750% | Wgt Acc: 87.210%
	I - Batch: 150 | Loss: 1.921 | Acc: 89.292% | Wgt Acc: 86.681%
	I - Batch: 200 | Loss: 1.927 | Acc: 89.062% | Wgt Acc: 86.025%
	I - Batch: 250 | Loss: 1.923 | Acc: 89.000% | Wgt Acc: 86.063%
	I - Batch: 300 | Loss: 1.939 | Acc: 89.146% | Wgt Acc: 86.452%
	I - Batch: 350 | Loss: 1.938 | Acc: 89.161% | Wgt Acc: 86.668%
I - num batch: 364
I - Train -- Loss: 1.937 | Acc: 89.132% | Wgt Acc: 86.603% | LR: 1.250000e-04 | Dur: 229.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    0.    3.   51.]
 [   0.  386.   60.    0.    1.]
 [   3.  277.  873.    2.   86.]
 [   5.    2.    4.  692.   54.]
 [  23.    3.   37.   21. 2571.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.775 | Acc: 55.250% | Wgt Acc: 51.441%
I - num batch: 87
I - Val -- Loss: 5.760 | Acc: 58.405% | Wgt Acc: 53.138% | Dur: 42.06s
I - Confusion Matrix: [row->prediction - col->label]
[[155.  12.  11.  53.  26.]
 [  0.  75.  14.   0.   1.]
 [  6.  90. 147.   6.  44.]
 [ 17.  22.  25. 106.  30.]
 [ 21.  69.  93.  39. 330.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 1.928 | Acc: 87.250% | Wgt Acc: 84.817%
	I - Batch: 100 | Loss: 1.882 | Acc: 89.625% | Wgt Acc: 87.562%
	I - Batch: 150 | Loss: 1.903 | Acc: 89.208% | Wgt Acc: 86.596%
	I - Batch: 200 | Loss: 1.927 | Acc: 88.906% | Wgt Acc: 86.038%
	I - Batch: 250 | Loss: 1.945 | Acc: 88.925% | Wgt Acc: 86.248%
	I - Batch: 300 | Loss: 1.952 | Acc: 88.771% | Wgt Acc: 86.262%
	I - Batch: 350 | Loss: 1.952 | Acc: 88.589% | Wgt Acc: 85.922%
I - num batch: 364
I - Train -- Loss: 1.955 | Acc: 88.684% | Wgt Acc: 86.034% | LR: 1.250000e-04 | Dur: 229.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 657.    1.    2.    9.   49.]
 [   0.  370.   50.    0.    4.]
 [   2.  293.  884.    2.  111.]
 [  10.    3.    4.  688.   41.]
 [  23.    1.   34.   19. 2558.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.803 | Acc: 53.125% | Wgt Acc: 50.224%
I - num batch: 87
I - Val -- Loss: 5.774 | Acc: 56.537% | Wgt Acc: 52.157% | Dur: 42.10s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   3.   9.  35.  25.]
 [  0.  80.   8.   0.   2.]
 [  1.  88. 118.   4.  39.]
 [ 32.  37.  42. 126.  47.]
 [ 21.  60. 113.  39. 318.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 1.869 | Acc: 90.750% | Wgt Acc: 88.474%
	I - Batch: 100 | Loss: 1.910 | Acc: 89.188% | Wgt Acc: 87.244%
	I - Batch: 150 | Loss: 1.928 | Acc: 89.000% | Wgt Acc: 86.896%
	I - Batch: 200 | Loss: 1.942 | Acc: 88.531% | Wgt Acc: 85.976%
	I - Batch: 250 | Loss: 1.966 | Acc: 88.125% | Wgt Acc: 85.357%
	I - Batch: 300 | Loss: 1.964 | Acc: 88.417% | Wgt Acc: 85.796%
	I - Batch: 350 | Loss: 1.975 | Acc: 88.232% | Wgt Acc: 85.677%
I - num batch: 364
I - Train -- Loss: 1.974 | Acc: 88.272% | Wgt Acc: 85.688% | LR: 1.250000e-04 | Dur: 229.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    1.    0.    7.   60.]
 [   0.  372.   37.    0.    1.]
 [   2.  290.  890.    4.  102.]
 [   9.    2.    5.  679.   60.]
 [  29.    3.   42.   28. 2540.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.730 | Acc: 55.625% | Wgt Acc: 52.676%
I - num batch: 87
I - Val -- Loss: 5.743 | Acc: 57.543% | Wgt Acc: 53.597% | Dur: 42.04s
I - Confusion Matrix: [row->prediction - col->label]
[[153.  11.  19.  49.  24.]
 [  2. 105.  25.   0.  14.]
 [  6.  80. 149.  22.  55.]
 [ 16.  16.  14.  85.  29.]
 [ 22.  56.  83.  48. 309.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 1.855 | Acc: 90.250% | Wgt Acc: 86.785%
	I - Batch: 100 | Loss: 1.920 | Acc: 89.688% | Wgt Acc: 86.847%
	I - Batch: 150 | Loss: 1.937 | Acc: 89.000% | Wgt Acc: 86.034%
	I - Batch: 200 | Loss: 1.940 | Acc: 89.219% | Wgt Acc: 86.461%
	I - Batch: 250 | Loss: 1.964 | Acc: 88.525% | Wgt Acc: 85.843%
	I - Batch: 300 | Loss: 2.037 | Acc: 87.521% | Wgt Acc: 84.818%
	I - Batch: 350 | Loss: 2.045 | Acc: 87.304% | Wgt Acc: 84.627%
I - num batch: 364
I - Train -- Loss: 2.047 | Acc: 87.326% | Wgt Acc: 84.708% | LR: 1.250000e-04 | Dur: 229.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    1.    2.   28.   58.]
 [   0.  384.   52.    0.    1.]
 [   5.  276.  863.    3.  122.]
 [  13.    2.    6.  663.   58.]
 [  30.    5.   51.   24. 2524.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.806 | Acc: 52.125% | Wgt Acc: 47.053%
I - num batch: 87
I - Val -- Loss: 5.767 | Acc: 56.897% | Wgt Acc: 49.589% | Dur: 42.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   0.   6.  18.  12.]
 [  1.  83.  11.   1.   3.]
 [  1.  93. 136.  10.  40.]
 [ 50.  19.  17. 124.  22.]
 [ 52.  73. 120.  51. 354.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 1.983 | Acc: 88.500% | Wgt Acc: 84.355%
	I - Batch: 100 | Loss: 2.020 | Acc: 86.875% | Wgt Acc: 82.626%
	I - Batch: 150 | Loss: 1.973 | Acc: 87.833% | Wgt Acc: 84.104%
	I - Batch: 200 | Loss: 1.989 | Acc: 87.781% | Wgt Acc: 83.939%
	I - Batch: 250 | Loss: 2.024 | Acc: 87.225% | Wgt Acc: 83.563%
	I - Batch: 300 | Loss: 2.031 | Acc: 87.333% | Wgt Acc: 83.961%
	I - Batch: 350 | Loss: 2.032 | Acc: 87.268% | Wgt Acc: 83.977%
I - num batch: 364
I - Train -- Loss: 2.030 | Acc: 87.291% | Wgt Acc: 84.072% | LR: 1.250000e-04 | Dur: 229.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 634.    1.    2.   16.   61.]
 [   0.  351.   51.    0.    0.]
 [   4.  309.  877.    6.   99.]
 [  21.    2.    4.  669.   58.]
 [  33.    5.   40.   27. 2545.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.790 | Acc: 50.000% | Wgt Acc: 45.848%
I - num batch: 87
I - Val -- Loss: 5.770 | Acc: 55.029% | Wgt Acc: 48.887% | Dur: 42.06s
I - Confusion Matrix: [row->prediction - col->label]
[[151.  17.  15.  61.  38.]
 [  0.  78.  26.   0.   5.]
 [  3.  73. 103.   5.  21.]
 [ 17.  17.  24.  92.  25.]
 [ 28.  83. 122.  46. 342.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 2.003 | Acc: 87.500% | Wgt Acc: 86.595%
	I - Batch: 100 | Loss: 1.937 | Acc: 88.812% | Wgt Acc: 87.858%
	I - Batch: 150 | Loss: 1.936 | Acc: 88.500% | Wgt Acc: 87.091%
	I - Batch: 200 | Loss: 1.950 | Acc: 88.188% | Wgt Acc: 86.363%
	I - Batch: 250 | Loss: 1.963 | Acc: 88.175% | Wgt Acc: 86.271%
	I - Batch: 300 | Loss: 1.956 | Acc: 88.167% | Wgt Acc: 86.285%
	I - Batch: 350 | Loss: 1.958 | Acc: 88.286% | Wgt Acc: 86.204%
I - num batch: 364
I - Train -- Loss: 1.961 | Acc: 88.289% | Wgt Acc: 86.250% | LR: 1.250000e-04 | Dur: 228.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    3.    4.   73.]
 [   0.  401.   68.    0.    0.]
 [   2.  260.  856.    2.  107.]
 [   4.    3.    4.  688.   55.]
 [  25.    4.   43.   24. 2528.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.823 | Acc: 51.875% | Wgt Acc: 47.374%
I - num batch: 87
I - Val -- Loss: 5.794 | Acc: 55.029% | Wgt Acc: 48.907% | Dur: 41.70s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   6.  16.  33.  30.]
 [  0.  62.   8.   0.   0.]
 [  5. 106. 147.  13.  49.]
 [ 30.  22.  20. 105.  29.]
 [ 35.  72.  99.  53. 323.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 1.894 | Acc: 91.625% | Wgt Acc: 88.993%
	I - Batch: 100 | Loss: 1.907 | Acc: 90.250% | Wgt Acc: 87.106%
	I - Batch: 150 | Loss: 1.915 | Acc: 90.250% | Wgt Acc: 87.306%
	I - Batch: 200 | Loss: 1.985 | Acc: 88.312% | Wgt Acc: 85.132%
	I - Batch: 250 | Loss: 1.990 | Acc: 88.100% | Wgt Acc: 85.066%
	I - Batch: 300 | Loss: 1.982 | Acc: 88.208% | Wgt Acc: 85.432%
	I - Batch: 350 | Loss: 1.983 | Acc: 88.000% | Wgt Acc: 85.271%
I - num batch: 364
I - Train -- Loss: 1.982 | Acc: 88.014% | Wgt Acc: 85.291% | LR: 1.250000e-04 | Dur: 227.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 650.    1.    0.   11.   51.]
 [   1.  374.   55.    0.    1.]
 [   3.  285.  875.    6.  117.]
 [   7.    4.    6.  674.   49.]
 [  31.    4.   38.   27. 2545.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.852 | Acc: 50.625% | Wgt Acc: 44.323%
I - num batch: 87
I - Val -- Loss: 5.814 | Acc: 55.891% | Wgt Acc: 47.679% | Dur: 41.71s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   3.  13.  58.  21.]
 [  0.  59.  10.   0.   1.]
 [  4. 109. 142.  13.  35.]
 [ 15.  14.  10.  79.  14.]
 [ 42.  83. 115.  54. 360.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 1.860 | Acc: 91.000% | Wgt Acc: 88.028%
	I - Batch: 100 | Loss: 1.876 | Acc: 89.812% | Wgt Acc: 87.187%
	I - Batch: 150 | Loss: 1.913 | Acc: 88.917% | Wgt Acc: 85.963%
	I - Batch: 200 | Loss: 1.931 | Acc: 89.094% | Wgt Acc: 86.332%
	I - Batch: 250 | Loss: 1.935 | Acc: 88.875% | Wgt Acc: 86.306%
	I - Batch: 300 | Loss: 1.928 | Acc: 89.250% | Wgt Acc: 86.748%
	I - Batch: 350 | Loss: 1.936 | Acc: 88.982% | Wgt Acc: 86.428%
I - num batch: 364
I - Train -- Loss: 1.932 | Acc: 89.149% | Wgt Acc: 86.658% | LR: 1.250000e-04 | Dur: 229.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    0.    1.    8.   65.]
 [   0.  384.   39.    0.    2.]
 [   5.  280.  895.    2.   96.]
 [   8.    3.    5.  692.   39.]
 [  27.    1.   34.   16. 2561.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.933 | Acc: 46.750% | Wgt Acc: 40.262%
I - num batch: 87
I - Val -- Loss: 5.840 | Acc: 53.448% | Wgt Acc: 45.191% | Dur: 42.19s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   3.  14.  33.  17.]
 [  0.  51.   6.   0.   2.]
 [  4.  94. 104.  10.  37.]
 [ 13.  11.   9.  93.  14.]
 [ 47. 109. 157.  68. 361.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 1.981 | Acc: 86.875% | Wgt Acc: 83.387%
	I - Batch: 100 | Loss: 1.940 | Acc: 88.562% | Wgt Acc: 85.456%
	I - Batch: 150 | Loss: 1.925 | Acc: 89.417% | Wgt Acc: 86.725%
	I - Batch: 200 | Loss: 1.916 | Acc: 89.750% | Wgt Acc: 87.136%
	I - Batch: 250 | Loss: 1.916 | Acc: 89.650% | Wgt Acc: 87.130%
	I - Batch: 300 | Loss: 1.932 | Acc: 89.104% | Wgt Acc: 86.505%
	I - Batch: 350 | Loss: 1.936 | Acc: 89.054% | Wgt Acc: 86.414%
I - num batch: 364
I - Train -- Loss: 1.939 | Acc: 88.822% | Wgt Acc: 86.214% | LR: 1.250000e-04 | Dur: 229.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 655.    1.    0.    8.   65.]
 [   0.  365.   26.    0.    3.]
 [   0.  299.  910.    5.   95.]
 [   7.    2.   11.  685.   50.]
 [  30.    1.   27.   20. 2550.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.787 | Acc: 51.125% | Wgt Acc: 46.687%
I - num batch: 87
I - Val -- Loss: 5.781 | Acc: 53.951% | Wgt Acc: 48.297% | Dur: 42.21s
I - Confusion Matrix: [row->prediction - col->label]
[[154.   5.  12.  70.  42.]
 [  3.  59.  12.   2.   6.]
 [  7. 111. 144.  14.  54.]
 [ 14.   7.  10.  81.  16.]
 [ 21.  86. 112.  37. 313.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 1.963 | Acc: 89.750% | Wgt Acc: 88.794%
	I - Batch: 100 | Loss: 1.954 | Acc: 88.562% | Wgt Acc: 86.612%
	I - Batch: 150 | Loss: 1.966 | Acc: 88.292% | Wgt Acc: 86.320%
	I - Batch: 200 | Loss: 1.951 | Acc: 88.156% | Wgt Acc: 86.076%
	I - Batch: 250 | Loss: 1.957 | Acc: 87.950% | Wgt Acc: 85.629%
	I - Batch: 300 | Loss: 1.949 | Acc: 87.938% | Wgt Acc: 85.350%
	I - Batch: 350 | Loss: 1.953 | Acc: 87.821% | Wgt Acc: 85.354%
I - num batch: 364
I - Train -- Loss: 1.948 | Acc: 87.997% | Wgt Acc: 85.592% | LR: 1.250000e-04 | Dur: 229.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 660.    0.    0.   11.   47.]
 [   0.  380.   64.    1.    1.]
 [   3.  281.  864.    1.  138.]
 [   8.    3.    5.  680.   44.]
 [  21.    4.   41.   25. 2533.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.933 | Acc: 48.250% | Wgt Acc: 43.263%
I - num batch: 87
I - Val -- Loss: 5.872 | Acc: 54.239% | Wgt Acc: 46.642% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   9.  16.  47.  27.]
 [  0.  52.   6.   0.   2.]
 [  2.  64.  98.   6.  16.]
 [ 20.  24.  17. 101.  28.]
 [ 31. 119. 153.  50. 358.]]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 1.976 | Acc: 86.875% | Wgt Acc: 84.129%
	I - Batch: 100 | Loss: 1.960 | Acc: 87.312% | Wgt Acc: 85.014%
	I - Batch: 150 | Loss: 1.956 | Acc: 88.042% | Wgt Acc: 85.950%
	I - Batch: 200 | Loss: 1.941 | Acc: 89.031% | Wgt Acc: 87.102%
	I - Batch: 250 | Loss: 1.935 | Acc: 89.200% | Wgt Acc: 87.042%
	I - Batch: 300 | Loss: 1.935 | Acc: 89.146% | Wgt Acc: 86.992%
	I - Batch: 350 | Loss: 1.929 | Acc: 89.125% | Wgt Acc: 86.849%
I - num batch: 364
I - Train -- Loss: 1.925 | Acc: 89.286% | Wgt Acc: 87.067% | LR: 1.250000e-04 | Dur: 229.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    2.    0.    9.   60.]
 [   0.  402.   50.    0.    4.]
 [   1.  259.  882.    2.  101.]
 [  11.    3.    6.  692.   40.]
 [  22.    2.   36.   15. 2558.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.814 | Acc: 53.125% | Wgt Acc: 49.423%
I - num batch: 87
I - Val -- Loss: 5.803 | Acc: 56.537% | Wgt Acc: 51.105% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[145.  15.  19.  47.  43.]
 [  0.  89.  19.   2.   3.]
 [  3.  66. 114.   6.  26.]
 [ 18.  20.  19. 103.  23.]
 [ 33.  78. 119.  46. 336.]]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 1.797 | Acc: 92.250% | Wgt Acc: 91.019%
	I - Batch: 100 | Loss: 1.849 | Acc: 91.312% | Wgt Acc: 89.317%
	I - Batch: 150 | Loss: 1.928 | Acc: 89.833% | Wgt Acc: 88.126%
	I - Batch: 200 | Loss: 1.936 | Acc: 89.562% | Wgt Acc: 87.745%
	I - Batch: 250 | Loss: 1.954 | Acc: 88.825% | Wgt Acc: 86.606%
	I - Batch: 300 | Loss: 1.957 | Acc: 88.521% | Wgt Acc: 86.181%
	I - Batch: 350 | Loss: 1.959 | Acc: 88.607% | Wgt Acc: 86.320%
I - num batch: 364
I - Train -- Loss: 1.954 | Acc: 88.753% | Wgt Acc: 86.538% | LR: 1.250000e-04 | Dur: 225.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    1.    2.    7.   64.]
 [   0.  397.   41.    0.    2.]
 [   3.  266.  893.    1.   94.]
 [  13.    3.    2.  683.   66.]
 [  25.    1.   36.   27. 2537.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.917 | Acc: 51.000% | Wgt Acc: 44.978%
I - num batch: 87
I - Val -- Loss: 5.847 | Acc: 55.603% | Wgt Acc: 47.396% | Dur: 42.94s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   3.   7.  22.   8.]
 [  1.  66.  11.   2.   1.]
 [  4.  83. 119.   6.  29.]
 [ 34.  21.  25. 110.  27.]
 [ 47.  95. 128.  64. 366.]]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 1.883 | Acc: 90.500% | Wgt Acc: 88.269%
	I - Batch: 100 | Loss: 1.883 | Acc: 90.125% | Wgt Acc: 87.838%
	I - Batch: 150 | Loss: 1.904 | Acc: 89.500% | Wgt Acc: 87.133%
	I - Batch: 200 | Loss: 1.913 | Acc: 89.219% | Wgt Acc: 86.636%
	I - Batch: 250 | Loss: 1.918 | Acc: 89.100% | Wgt Acc: 86.331%
	I - Batch: 300 | Loss: 1.903 | Acc: 89.479% | Wgt Acc: 86.959%
	I - Batch: 350 | Loss: 1.896 | Acc: 89.500% | Wgt Acc: 87.091%
I - num batch: 364
I - Train -- Loss: 1.898 | Acc: 89.424% | Wgt Acc: 87.064% | LR: 1.250000e-04 | Dur: 233.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    1.    1.    3.   57.]
 [   0.  391.   51.    1.    1.]
 [   0.  272.  889.    1.   97.]
 [   8.    2.    3.  691.   42.]
 [  21.    2.   30.   22. 2566.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.731 | Acc: 56.500% | Wgt Acc: 54.246%
I - num batch: 87
I - Val -- Loss: 5.740 | Acc: 59.411% | Wgt Acc: 55.639% | Dur: 42.90s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   2.  20.  35.  23.]
 [  0. 115.  24.   2.   9.]
 [  2.  83. 150.  10.  60.]
 [ 25.  14.  12. 118.  24.]
 [ 43.  54.  84.  39. 315.]]

I - Local maximum validation set accuracy:  59.41

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 1.958 | Acc: 86.625% | Wgt Acc: 83.553%
	I - Batch: 100 | Loss: 1.968 | Acc: 87.062% | Wgt Acc: 84.275%
	I - Batch: 150 | Loss: 1.930 | Acc: 88.375% | Wgt Acc: 85.515%
	I - Batch: 200 | Loss: 1.943 | Acc: 87.656% | Wgt Acc: 84.597%
	I - Batch: 250 | Loss: 1.969 | Acc: 87.525% | Wgt Acc: 84.636%
	I - Batch: 300 | Loss: 1.953 | Acc: 88.208% | Wgt Acc: 85.703%
	I - Batch: 350 | Loss: 1.940 | Acc: 88.357% | Wgt Acc: 85.918%
I - num batch: 364
I - Train -- Loss: 1.938 | Acc: 88.426% | Wgt Acc: 86.064% | LR: 1.250000e-04 | Dur: 233.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 649.    2.    0.    3.   76.]
 [   0.  380.   49.    0.    1.]
 [   2.  282.  898.    7.  101.]
 [   9.    3.    5.  684.   54.]
 [  32.    1.   22.   24. 2531.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.915 | Acc: 50.625% | Wgt Acc: 44.751%
I - num batch: 87
I - Val -- Loss: 5.845 | Acc: 55.963% | Wgt Acc: 47.392% | Dur: 42.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 91.   0.   2.  13.   5.]
 [  0.  95.  19.   1.   7.]
 [  3.  70. 114.   8.  24.]
 [ 29.  10.  13. 102.  18.]
 [ 76.  93. 142.  80. 377.]]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 1.917 | Acc: 89.125% | Wgt Acc: 87.115%
	I - Batch: 100 | Loss: 1.891 | Acc: 89.938% | Wgt Acc: 87.995%
	I - Batch: 150 | Loss: 1.868 | Acc: 90.375% | Wgt Acc: 88.412%
	I - Batch: 200 | Loss: 1.879 | Acc: 90.250% | Wgt Acc: 88.232%
	I - Batch: 250 | Loss: 1.884 | Acc: 90.100% | Wgt Acc: 87.850%
	I - Batch: 300 | Loss: 1.878 | Acc: 90.188% | Wgt Acc: 87.904%
	I - Batch: 350 | Loss: 1.889 | Acc: 90.232% | Wgt Acc: 87.980%
I - num batch: 364
I - Train -- Loss: 1.890 | Acc: 90.163% | Wgt Acc: 87.872% | LR: 1.250000e-04 | Dur: 233.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    1.    3.    5.   47.]
 [   0.  405.   36.    0.    0.]
 [   2.  256.  898.    3.   79.]
 [   7.    3.    6.  693.   54.]
 [  19.    3.   31.   17. 2583.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.842 | Acc: 51.000% | Wgt Acc: 45.874%
I - num batch: 87
I - Val -- Loss: 5.816 | Acc: 55.316% | Wgt Acc: 48.146% | Dur: 42.97s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   7.   7.  36.  17.]
 [  0.  64.  10.   1.   3.]
 [  1.  98. 122.   7.  28.]
 [ 23.  18.  24. 105.  34.]
 [ 45.  81. 127.  55. 349.]]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 1.886 | Acc: 90.125% | Wgt Acc: 87.661%
	I - Batch: 100 | Loss: 1.890 | Acc: 90.250% | Wgt Acc: 87.997%
	I - Batch: 150 | Loss: 1.871 | Acc: 90.583% | Wgt Acc: 88.261%
	I - Batch: 200 | Loss: 1.876 | Acc: 90.062% | Wgt Acc: 87.851%
	I - Batch: 250 | Loss: 1.873 | Acc: 90.225% | Wgt Acc: 88.057%
	I - Batch: 300 | Loss: 1.893 | Acc: 89.542% | Wgt Acc: 86.885%
	I - Batch: 350 | Loss: 1.895 | Acc: 89.589% | Wgt Acc: 87.033%
I - num batch: 364
I - Train -- Loss: 1.892 | Acc: 89.733% | Wgt Acc: 87.228% | LR: 1.250000e-04 | Dur: 233.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 660.    1.    3.    8.   55.]
 [   0.  383.   29.    0.    3.]
 [   1.  277.  908.    3.   87.]
 [  10.    5.    6.  692.   43.]
 [  21.    2.   28.   15. 2575.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.790 | Acc: 55.500% | Wgt Acc: 52.620%
I - num batch: 87
I - Val -- Loss: 5.781 | Acc: 59.267% | Wgt Acc: 54.889% | Dur: 42.98s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   5.  11.  37.  26.]
 [  0. 114.  25.   2.   8.]
 [  4.  59. 122.   5.  38.]
 [ 25.  18.  26. 109.  25.]
 [ 24.  72. 106.  51. 334.]]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 1.950 | Acc: 88.625% | Wgt Acc: 86.882%
	I - Batch: 100 | Loss: 1.994 | Acc: 87.500% | Wgt Acc: 85.310%
	I - Batch: 150 | Loss: 1.963 | Acc: 87.708% | Wgt Acc: 85.405%
	I - Batch: 200 | Loss: 1.940 | Acc: 88.281% | Wgt Acc: 85.931%
	I - Batch: 250 | Loss: 1.941 | Acc: 88.550% | Wgt Acc: 86.172%
	I - Batch: 300 | Loss: 1.946 | Acc: 88.354% | Wgt Acc: 85.814%
	I - Batch: 350 | Loss: 1.936 | Acc: 88.714% | Wgt Acc: 86.308%
I - num batch: 364
I - Train -- Loss: 1.927 | Acc: 88.839% | Wgt Acc: 86.447% | LR: 1.250000e-04 | Dur: 233.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 653.    1.    0.   12.   52.]
 [   0.  388.   33.    0.    1.]
 [   2.  270.  901.    3.  108.]
 [  15.    3.    5.  679.   57.]
 [  22.    6.   35.   24. 2545.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.903 | Acc: 51.125% | Wgt Acc: 45.041%
I - num batch: 87
I - Val -- Loss: 5.845 | Acc: 56.753% | Wgt Acc: 48.772% | Dur: 42.88s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   2.   8.  26.  19.]
 [  0.  76.   9.   0.   3.]
 [  9. 101. 138.  19.  34.]
 [  8.   4.   3.  78.  11.]
 [ 48.  85. 132.  81. 364.]]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 1.921 | Acc: 87.125% | Wgt Acc: 83.801%
	I - Batch: 100 | Loss: 1.932 | Acc: 87.375% | Wgt Acc: 84.091%
	I - Batch: 150 | Loss: 1.902 | Acc: 88.875% | Wgt Acc: 86.007%
	I - Batch: 200 | Loss: 1.898 | Acc: 88.938% | Wgt Acc: 86.252%
	I - Batch: 250 | Loss: 1.879 | Acc: 89.800% | Wgt Acc: 87.361%
	I - Batch: 300 | Loss: 1.891 | Acc: 89.354% | Wgt Acc: 87.023%
	I - Batch: 350 | Loss: 1.890 | Acc: 89.625% | Wgt Acc: 87.288%
I - num batch: 364
I - Train -- Loss: 1.893 | Acc: 89.579% | Wgt Acc: 87.342% | LR: 1.250000e-04 | Dur: 233.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    2.    5.   44.]
 [   0.  386.   28.    0.    2.]
 [   1.  278.  911.    1.  111.]
 [   4.    3.    5.  690.   50.]
 [  21.    1.   28.   22. 2556.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.826 | Acc: 53.625% | Wgt Acc: 47.935%
I - num batch: 87
I - Val -- Loss: 5.798 | Acc: 57.184% | Wgt Acc: 49.960% | Dur: 42.92s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   1.   8.  21.  10.]
 [  0.  75.   7.   0.   3.]
 [ 14. 119. 177.  18.  64.]
 [ 22.   7.   9.  88.  14.]
 [ 47.  66.  89.  77. 340.]]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 1.804 | Acc: 92.500% | Wgt Acc: 89.669%
	I - Batch: 100 | Loss: 1.833 | Acc: 91.312% | Wgt Acc: 88.578%
	I - Batch: 150 | Loss: 1.861 | Acc: 90.417% | Wgt Acc: 87.397%
	I - Batch: 200 | Loss: 1.878 | Acc: 90.438% | Wgt Acc: 87.813%
	I - Batch: 250 | Loss: 1.872 | Acc: 90.800% | Wgt Acc: 88.437%
	I - Batch: 300 | Loss: 1.874 | Acc: 90.854% | Wgt Acc: 88.476%
	I - Batch: 350 | Loss: 1.869 | Acc: 90.982% | Wgt Acc: 88.729%
I - num batch: 364
I - Train -- Loss: 1.871 | Acc: 90.886% | Wgt Acc: 88.600% | LR: 1.250000e-04 | Dur: 233.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    1.    2.    2.   38.]
 [   0.  424.   37.    0.    4.]
 [   0.  237.  902.    4.   76.]
 [   3.    4.    4.  692.   40.]
 [  27.    2.   29.   20. 2605.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.866 | Acc: 51.500% | Wgt Acc: 47.399%
I - num batch: 87
I - Val -- Loss: 5.827 | Acc: 56.106% | Wgt Acc: 49.669% | Dur: 42.96s
I - Confusion Matrix: [row->prediction - col->label]
[[151.   3.  17.  46.  31.]
 [  0.  64.   6.   0.   3.]
 [  3.  97. 137.   9.  41.]
 [ 12.   8.  18.  91.  18.]
 [ 33.  96. 112.  58. 338.]]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 1.831 | Acc: 91.000% | Wgt Acc: 87.958%
	I - Batch: 100 | Loss: 1.829 | Acc: 91.688% | Wgt Acc: 89.207%
	I - Batch: 150 | Loss: 1.829 | Acc: 91.500% | Wgt Acc: 89.207%
	I - Batch: 200 | Loss: 1.834 | Acc: 91.406% | Wgt Acc: 89.173%
	I - Batch: 250 | Loss: 1.832 | Acc: 91.300% | Wgt Acc: 88.975%
	I - Batch: 300 | Loss: 1.830 | Acc: 91.646% | Wgt Acc: 89.303%
	I - Batch: 350 | Loss: 1.825 | Acc: 91.607% | Wgt Acc: 89.148%
I - num batch: 364
I - Train -- Loss: 1.826 | Acc: 91.660% | Wgt Acc: 89.193% | LR: 1.250000e-04 | Dur: 233.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    1.    2.    3.   45.]
 [   0.  408.   10.    0.    0.]
 [   1.  255.  936.    1.   66.]
 [   1.    2.    2.  695.   28.]
 [  23.    2.   24.   19. 2624.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.739 | Acc: 54.125% | Wgt Acc: 51.037%
I - num batch: 87
I - Val -- Loss: 5.735 | Acc: 57.256% | Wgt Acc: 52.433% | Dur: 43.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   0.  10.  13.  13.]
 [  0. 128.  51.   1.  14.]
 [  4.  45. 101.   9.  27.]
 [ 54.  28.  30. 132.  40.]
 [ 42.  67.  98.  49. 337.]]

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 1.810 | Acc: 91.625% | Wgt Acc: 89.336%
	I - Batch: 100 | Loss: 1.801 | Acc: 92.188% | Wgt Acc: 90.359%
	I - Batch: 150 | Loss: 1.801 | Acc: 92.042% | Wgt Acc: 89.795%
	I - Batch: 200 | Loss: 1.825 | Acc: 91.500% | Wgt Acc: 88.995%
	I - Batch: 250 | Loss: 1.827 | Acc: 91.200% | Wgt Acc: 88.633%
	I - Batch: 300 | Loss: 1.822 | Acc: 91.458% | Wgt Acc: 88.848%
	I - Batch: 350 | Loss: 1.824 | Acc: 91.071% | Wgt Acc: 88.234%
I - num batch: 364
I - Train -- Loss: 1.827 | Acc: 91.058% | Wgt Acc: 88.331% | LR: 1.250000e-04 | Dur: 233.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    1.    2.    1.   50.]
 [   0.  386.   25.    0.    1.]
 [   2.  276.  919.    3.   55.]
 [   2.    3.    4.  700.   34.]
 [  21.    2.   24.   14. 2623.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.808 | Acc: 53.625% | Wgt Acc: 48.358%
I - num batch: 87
I - Val -- Loss: 5.793 | Acc: 57.256% | Wgt Acc: 50.271% | Dur: 43.15s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   4.   7.  36.  15.]
 [  0.  57.   0.   1.   0.]
 [  8. 124. 148.  12.  42.]
 [ 25.  17.  24. 112.  28.]
 [ 32.  66. 111.  43. 346.]]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 1.843 | Acc: 93.500% | Wgt Acc: 91.661%
	I - Batch: 100 | Loss: 1.805 | Acc: 93.125% | Wgt Acc: 91.059%
	I - Batch: 150 | Loss: 1.818 | Acc: 92.708% | Wgt Acc: 90.771%
	I - Batch: 200 | Loss: 1.819 | Acc: 92.594% | Wgt Acc: 90.444%
	I - Batch: 250 | Loss: 1.817 | Acc: 92.725% | Wgt Acc: 90.658%
	I - Batch: 300 | Loss: 1.817 | Acc: 92.354% | Wgt Acc: 90.130%
	I - Batch: 350 | Loss: 1.822 | Acc: 92.375% | Wgt Acc: 90.314%
I - num batch: 364
I - Train -- Loss: 1.819 | Acc: 92.485% | Wgt Acc: 90.494% | LR: 1.250000e-04 | Dur: 233.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    1.    1.    6.   43.]
 [   0.  450.   25.    0.    0.]
 [   0.  212.  925.    1.   55.]
 [   1.    2.    2.  697.   32.]
 [  18.    3.   21.   14. 2633.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.935 | Acc: 51.250% | Wgt Acc: 45.502%
I - num batch: 87
I - Val -- Loss: 5.865 | Acc: 56.466% | Wgt Acc: 48.433% | Dur: 43.10s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   4.   9.  39.  19.]
 [  0.  68.   8.   0.   1.]
 [  2.  95. 120.   5.  28.]
 [ 17.   5.   7.  91.  14.]
 [ 42.  96. 146.  69. 369.]]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 1.860 | Acc: 91.375% | Wgt Acc: 88.671%
	I - Batch: 100 | Loss: 2.009 | Acc: 88.188% | Wgt Acc: 85.579%
	I - Batch: 150 | Loss: 2.105 | Acc: 86.333% | Wgt Acc: 83.412%
	I - Batch: 200 | Loss: 2.088 | Acc: 86.719% | Wgt Acc: 84.141%
	I - Batch: 250 | Loss: 2.059 | Acc: 87.450% | Wgt Acc: 84.974%
	I - Batch: 300 | Loss: 2.032 | Acc: 88.188% | Wgt Acc: 85.840%
	I - Batch: 350 | Loss: 2.013 | Acc: 88.357% | Wgt Acc: 85.882%
I - num batch: 364
I - Train -- Loss: 2.008 | Acc: 88.444% | Wgt Acc: 86.009% | LR: 1.250000e-04 | Dur: 233.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 634.    1.    2.   21.   64.]
 [   0.  405.   28.    0.    2.]
 [   2.  254.  899.    3.   86.]
 [  27.    4.    7.  668.   74.]
 [  29.    4.   38.   26. 2537.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.800 | Acc: 56.625% | Wgt Acc: 51.951%
I - num batch: 87
I - Val -- Loss: 5.792 | Acc: 59.195% | Wgt Acc: 53.202% | Dur: 43.09s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   7.   8.  28.  19.]
 [  1.  89.  16.   0.   1.]
 [  3.  81. 138.  19.  39.]
 [ 35.  13.  18. 118.  24.]
 [ 29.  78. 110.  39. 348.]]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 1.880 | Acc: 89.875% | Wgt Acc: 86.640%
	I - Batch: 100 | Loss: 1.912 | Acc: 90.750% | Wgt Acc: 88.054%
	I - Batch: 150 | Loss: 1.881 | Acc: 91.208% | Wgt Acc: 88.776%
	I - Batch: 200 | Loss: 1.913 | Acc: 90.188% | Wgt Acc: 87.760%
	I - Batch: 250 | Loss: 1.924 | Acc: 89.875% | Wgt Acc: 87.507%
	I - Batch: 300 | Loss: 1.920 | Acc: 90.333% | Wgt Acc: 88.187%
	I - Batch: 350 | Loss: 1.920 | Acc: 90.161% | Wgt Acc: 87.906%
I - num batch: 364
I - Train -- Loss: 1.915 | Acc: 90.215% | Wgt Acc: 87.951% | LR: 1.250000e-04 | Dur: 233.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 655.    2.    3.    4.   52.]
 [   0.  415.   29.    2.    4.]
 [   0.  245.  903.    0.   78.]
 [  11.    3.    5.  691.   47.]
 [  26.    3.   34.   21. 2582.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.741 | Acc: 56.000% | Wgt Acc: 53.628%
I - num batch: 87
I - Val -- Loss: 5.733 | Acc: 59.052% | Wgt Acc: 55.244% | Dur: 43.10s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   4.  13.  51.  23.]
 [  0. 125.  26.   2.  15.]
 [  8.  72. 158.  14.  62.]
 [ 16.  12.   9.  82.  18.]
 [ 31.  55.  84.  55. 313.]]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 1.903 | Acc: 90.250% | Wgt Acc: 87.408%
	I - Batch: 100 | Loss: 1.863 | Acc: 90.500% | Wgt Acc: 87.608%
	I - Batch: 150 | Loss: 1.869 | Acc: 90.417% | Wgt Acc: 87.524%
	I - Batch: 200 | Loss: 1.848 | Acc: 90.875% | Wgt Acc: 88.160%
	I - Batch: 250 | Loss: 1.842 | Acc: 91.025% | Wgt Acc: 88.365%
	I - Batch: 300 | Loss: 1.853 | Acc: 90.979% | Wgt Acc: 88.388%
	I - Batch: 350 | Loss: 1.856 | Acc: 90.964% | Wgt Acc: 88.381%
I - num batch: 364
I - Train -- Loss: 1.860 | Acc: 90.765% | Wgt Acc: 88.091% | LR: 1.250000e-04 | Dur: 233.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    1.    1.    6.   48.]
 [   0.  407.   37.    0.    1.]
 [   3.  253.  903.    4.   62.]
 [   6.    2.    4.  693.   33.]
 [  27.    5.   29.   15. 2619.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.857 | Acc: 51.250% | Wgt Acc: 44.934%
I - num batch: 87
I - Val -- Loss: 5.816 | Acc: 56.897% | Wgt Acc: 48.724% | Dur: 42.44s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   7.  13.  52.  20.]
 [  0.  50.   5.   0.   1.]
 [  5. 108. 140.   7.  30.]
 [ 20.  11.  16. 100.  16.]
 [ 36.  92. 116.  45. 364.]]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 1.928 | Acc: 89.625% | Wgt Acc: 88.525%
	I - Batch: 100 | Loss: 1.866 | Acc: 90.625% | Wgt Acc: 88.882%
	I - Batch: 150 | Loss: 1.854 | Acc: 91.292% | Wgt Acc: 89.795%
	I - Batch: 200 | Loss: 1.862 | Acc: 91.312% | Wgt Acc: 89.659%
	I - Batch: 250 | Loss: 1.864 | Acc: 91.275% | Wgt Acc: 89.598%
	I - Batch: 300 | Loss: 1.867 | Acc: 90.958% | Wgt Acc: 89.085%
	I - Batch: 350 | Loss: 1.873 | Acc: 90.714% | Wgt Acc: 88.781%
I - num batch: 364
I - Train -- Loss: 1.874 | Acc: 90.696% | Wgt Acc: 88.752% | LR: 1.250000e-04 | Dur: 228.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    2.    2.   10.   46.]
 [   0.  432.   29.    0.    2.]
 [   2.  229.  912.    2.   98.]
 [   5.    0.    4.  688.   38.]
 [  22.    5.   27.   18. 2579.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.710 | Acc: 59.125% | Wgt Acc: 55.287%
I - num batch: 87
I - Val -- Loss: 5.743 | Acc: 60.489% | Wgt Acc: 55.655% | Dur: 41.74s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   1.   4.  14.  12.]
 [  1. 115.  14.   7.  13.]
 [  8.  94. 197.  18.  74.]
 [ 41.   9.   8. 106.  14.]
 [ 43.  49.  67.  59. 318.]]

I - Local maximum validation set accuracy:  60.49

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 1.866 | Acc: 92.250% | Wgt Acc: 89.781%
	I - Batch: 100 | Loss: 1.899 | Acc: 91.188% | Wgt Acc: 89.384%
	I - Batch: 150 | Loss: 1.904 | Acc: 90.292% | Wgt Acc: 88.323%
	I - Batch: 200 | Loss: 1.891 | Acc: 90.719% | Wgt Acc: 88.555%
	I - Batch: 250 | Loss: 1.899 | Acc: 90.500% | Wgt Acc: 88.478%
	I - Batch: 300 | Loss: 1.899 | Acc: 90.646% | Wgt Acc: 88.871%
	I - Batch: 350 | Loss: 1.908 | Acc: 90.821% | Wgt Acc: 89.361%
I - num batch: 364
I - Train -- Loss: 1.909 | Acc: 90.817% | Wgt Acc: 89.446% | LR: 1.250000e-04 | Dur: 227.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 648.    0.    1.   10.   66.]
 [   1.  483.   35.    1.   10.]
 [   1.  177.  900.    3.   92.]
 [  12.    4.    4.  688.   33.]
 [  30.    4.   34.   16. 2562.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.881 | Acc: 50.875% | Wgt Acc: 45.766%
I - num batch: 87
I - Val -- Loss: 5.812 | Acc: 56.609% | Wgt Acc: 49.625% | Dur: 41.59s
I - Confusion Matrix: [row->prediction - col->label]
[[134.  13.  13.  60.  26.]
 [  3.  89.   9.   2.   5.]
 [  0.  50. 110.   0.  17.]
 [ 22.  18.  20.  95.  23.]
 [ 40.  98. 138.  47. 360.]]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 1.913 | Acc: 92.125% | Wgt Acc: 92.316%
	I - Batch: 100 | Loss: 1.900 | Acc: 92.438% | Wgt Acc: 92.611%
	I - Batch: 150 | Loss: 1.927 | Acc: 91.500% | Wgt Acc: 91.752%
	I - Batch: 200 | Loss: 1.916 | Acc: 91.781% | Wgt Acc: 91.999%
	I - Batch: 250 | Loss: 1.920 | Acc: 91.725% | Wgt Acc: 91.954%
	I - Batch: 300 | Loss: 1.905 | Acc: 92.000% | Wgt Acc: 92.407%
	I - Batch: 350 | Loss: 1.923 | Acc: 91.643% | Wgt Acc: 92.056%
I - num batch: 364
I - Train -- Loss: 1.924 | Acc: 91.642% | Wgt Acc: 91.980% | LR: 1.250000e-04 | Dur: 226.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    1.    3.    8.   53.]
 [   2.  625.   89.    1.   21.]
 [   1.   32.  825.    4.   88.]
 [   6.    5.    7.  684.   60.]
 [  29.    5.   50.   21. 2541.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.973 | Acc: 48.000% | Wgt Acc: 42.494%
I - num batch: 87
I - Val -- Loss: 5.877 | Acc: 54.741% | Wgt Acc: 46.889% | Dur: 41.28s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   8.   7.  21.  15.]
 [  0.  63.   8.   1.   3.]
 [  2.  50.  80.   2.   9.]
 [ 40.  21.  19. 135.  34.]
 [ 43. 126. 176.  45. 370.]]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 1.948 | Acc: 92.125% | Wgt Acc: 92.287%
	I - Batch: 100 | Loss: 1.921 | Acc: 92.062% | Wgt Acc: 92.348%
	I - Batch: 150 | Loss: 1.931 | Acc: 91.625% | Wgt Acc: 91.881%
	I - Batch: 200 | Loss: 1.906 | Acc: 92.031% | Wgt Acc: 92.299%
	I - Batch: 250 | Loss: 1.883 | Acc: 92.525% | Wgt Acc: 92.881%
	I - Batch: 300 | Loss: 1.867 | Acc: 93.000% | Wgt Acc: 93.326%
	I - Batch: 350 | Loss: 1.868 | Acc: 92.982% | Wgt Acc: 93.425%
I - num batch: 364
I - Train -- Loss: 1.867 | Acc: 92.984% | Wgt Acc: 93.426% | LR: 1.250000e-04 | Dur: 229.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    2.    3.    7.   61.]
 [   1.  629.   62.    3.   18.]
 [   0.   28.  872.    4.   72.]
 [   8.    2.    7.  683.   52.]
 [  20.    7.   30.   21. 2560.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.704 | Acc: 60.000% | Wgt Acc: 58.262%
I - num batch: 87
I - Val -- Loss: 5.693 | Acc: 63.003% | Wgt Acc: 60.743% | Dur: 42.08s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   8.  11.  23.  37.]
 [  1. 161.  29.   8.  21.]
 [  3.  40. 130.   3.  23.]
 [ 38.  10.  14. 130.  27.]
 [ 24.  49. 106.  40. 323.]]

I - Local maximum validation set accuracy:  63.00

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 1.741 | Acc: 95.625% | Wgt Acc: 96.153%
	I - Batch: 100 | Loss: 1.761 | Acc: 95.188% | Wgt Acc: 95.610%
	I - Batch: 150 | Loss: 1.758 | Acc: 94.917% | Wgt Acc: 95.305%
	I - Batch: 200 | Loss: 1.838 | Acc: 92.969% | Wgt Acc: 93.181%
	I - Batch: 250 | Loss: 1.858 | Acc: 92.650% | Wgt Acc: 92.888%
	I - Batch: 300 | Loss: 1.873 | Acc: 92.292% | Wgt Acc: 92.671%
	I - Batch: 350 | Loss: 1.876 | Acc: 92.304% | Wgt Acc: 92.713%
I - num batch: 364
I - Train -- Loss: 1.877 | Acc: 92.244% | Wgt Acc: 92.698% | LR: 1.250000e-04 | Dur: 229.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    1.    2.   10.   78.]
 [   0.  633.   89.    1.   14.]
 [   0.   27.  850.    1.   68.]
 [   7.    3.    5.  682.   58.]
 [  31.    4.   28.   24. 2545.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.806 | Acc: 54.750% | Wgt Acc: 52.525%
I - num batch: 87
I - Val -- Loss: 5.776 | Acc: 57.543% | Wgt Acc: 53.645% | Dur: 42.11s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   4.  13.  44.  36.]
 [  3. 101.  16.   2.   7.]
 [  5.  62. 126.   5.  38.]
 [ 25.  29.  28. 122.  35.]
 [ 29.  72. 107.  31. 315.]]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 1.829 | Acc: 94.250% | Wgt Acc: 94.118%
	I - Batch: 100 | Loss: 1.815 | Acc: 93.938% | Wgt Acc: 93.982%
	I - Batch: 150 | Loss: 1.816 | Acc: 93.792% | Wgt Acc: 94.072%
	I - Batch: 200 | Loss: 1.822 | Acc: 93.750% | Wgt Acc: 94.015%
	I - Batch: 250 | Loss: 1.831 | Acc: 93.575% | Wgt Acc: 93.840%
	I - Batch: 300 | Loss: 1.830 | Acc: 93.438% | Wgt Acc: 93.803%
	I - Batch: 350 | Loss: 1.839 | Acc: 93.304% | Wgt Acc: 93.651%
I - num batch: 364
I - Train -- Loss: 1.841 | Acc: 93.242% | Wgt Acc: 93.585% | LR: 1.250000e-04 | Dur: 229.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    1.    4.    6.   49.]
 [   3.  636.   67.    0.   11.]
 [   1.   24.  864.    1.   76.]
 [  10.    5.    4.  692.   51.]
 [  24.    2.   35.   19. 2576.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.869 | Acc: 52.750% | Wgt Acc: 48.496%
I - num batch: 87
I - Val -- Loss: 5.800 | Acc: 57.256% | Wgt Acc: 51.340% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   5.  13.  31.  35.]
 [  1.  79.   7.   3.   5.]
 [  4.  76. 126.   3.  29.]
 [ 21.  14.  19. 110.  21.]
 [ 32.  94. 125.  57. 341.]]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 1.872 | Acc: 92.750% | Wgt Acc: 92.231%
	I - Batch: 100 | Loss: 1.815 | Acc: 94.062% | Wgt Acc: 93.936%
	I - Batch: 150 | Loss: 1.827 | Acc: 93.458% | Wgt Acc: 93.459%
	I - Batch: 200 | Loss: 1.810 | Acc: 93.375% | Wgt Acc: 93.511%
	I - Batch: 250 | Loss: 1.788 | Acc: 93.700% | Wgt Acc: 93.905%
	I - Batch: 300 | Loss: 1.782 | Acc: 93.500% | Wgt Acc: 93.813%
	I - Batch: 350 | Loss: 1.770 | Acc: 93.750% | Wgt Acc: 93.996%
I - num batch: 364
I - Train -- Loss: 1.769 | Acc: 93.792% | Wgt Acc: 93.998% | LR: 1.250000e-04 | Dur: 229.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    1.    2.    3.   51.]
 [   1.  633.   65.    0.    8.]
 [   2.   25.  882.    1.   74.]
 [   6.    4.    3.  690.   37.]
 [  27.    5.   22.   24. 2593.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.739 | Acc: 56.250% | Wgt Acc: 51.151%
I - num batch: 87
I - Val -- Loss: 5.722 | Acc: 59.770% | Wgt Acc: 53.641% | Dur: 42.13s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   3.   5.  14.   7.]
 [  4. 108.  13.   6.   7.]
 [  9.  71. 176.  15.  62.]
 [ 26.   9.   9. 105.  15.]
 [ 57.  77.  87.  64. 340.]]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 1.599 | Acc: 96.500% | Wgt Acc: 96.776%
	I - Batch: 100 | Loss: 1.632 | Acc: 96.000% | Wgt Acc: 96.249%
	I - Batch: 150 | Loss: 1.642 | Acc: 95.333% | Wgt Acc: 95.661%
	I - Batch: 200 | Loss: 1.651 | Acc: 95.125% | Wgt Acc: 95.438%
	I - Batch: 250 | Loss: 1.656 | Acc: 94.950% | Wgt Acc: 95.367%
	I - Batch: 300 | Loss: 1.658 | Acc: 94.833% | Wgt Acc: 95.191%
	I - Batch: 350 | Loss: 1.652 | Acc: 94.964% | Wgt Acc: 95.289%
I - num batch: 364
I - Train -- Loss: 1.656 | Acc: 94.927% | Wgt Acc: 95.200% | LR: 1.250000e-04 | Dur: 229.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    2.    2.   38.]
 [   0.  631.   50.    1.   18.]
 [   0.   27.  902.    2.   60.]
 [   1.    2.    3.  699.   30.]
 [  20.    6.   17.   14. 2617.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.795 | Acc: 50.625% | Wgt Acc: 47.582%
I - num batch: 87
I - Val -- Loss: 5.751 | Acc: 56.034% | Wgt Acc: 51.527% | Dur: 42.14s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   1.   6.  22.  27.]
 [  0.  88.  14.   1.   4.]
 [  4.  48. 113.   7.  34.]
 [ 48.  33.  42. 134.  47.]
 [ 21.  98. 115.  40. 319.]]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 1.711 | Acc: 93.250% | Wgt Acc: 93.953%
	I - Batch: 100 | Loss: 1.641 | Acc: 94.750% | Wgt Acc: 95.160%
	I - Batch: 150 | Loss: 1.632 | Acc: 94.917% | Wgt Acc: 95.362%
	I - Batch: 200 | Loss: 1.633 | Acc: 94.938% | Wgt Acc: 95.244%
	I - Batch: 250 | Loss: 1.633 | Acc: 95.000% | Wgt Acc: 95.301%
	I - Batch: 300 | Loss: 1.638 | Acc: 94.792% | Wgt Acc: 95.178%
	I - Batch: 350 | Loss: 1.649 | Acc: 94.679% | Wgt Acc: 95.053%
I - num batch: 364
I - Train -- Loss: 1.647 | Acc: 94.669% | Wgt Acc: 95.090% | LR: 1.250000e-04 | Dur: 229.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    0.    2.    3.   41.]
 [   1.  637.   36.    2.    9.]
 [   3.   25.  905.    5.   72.]
 [   1.    3.    4.  695.   40.]
 [  20.    3.   27.   13. 2601.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.822 | Acc: 53.500% | Wgt Acc: 48.477%
I - num batch: 87
I - Val -- Loss: 5.786 | Acc: 57.328% | Wgt Acc: 50.566% | Dur: 42.10s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   4.  10.  23.  11.]
 [  0.  90.  20.   2.  11.]
 [  0.  56. 120.   8.  27.]
 [ 42.  22.  11. 112.  26.]
 [ 37.  96. 129.  59. 356.]]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 1.593 | Acc: 95.250% | Wgt Acc: 95.524%
	I - Batch: 100 | Loss: 1.600 | Acc: 95.438% | Wgt Acc: 95.906%
	I - Batch: 150 | Loss: 1.622 | Acc: 95.042% | Wgt Acc: 95.536%
	I - Batch: 200 | Loss: 1.632 | Acc: 95.125% | Wgt Acc: 95.290%
	I - Batch: 250 | Loss: 1.620 | Acc: 95.450% | Wgt Acc: 95.624%
	I - Batch: 300 | Loss: 1.618 | Acc: 95.396% | Wgt Acc: 95.590%
	I - Batch: 350 | Loss: 1.633 | Acc: 95.179% | Wgt Acc: 95.461%
I - num batch: 364
I - Train -- Loss: 1.634 | Acc: 95.202% | Wgt Acc: 95.504% | LR: 1.250000e-04 | Dur: 229.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    1.    4.    5.   36.]
 [   2.  650.   38.    0.   12.]
 [   2.   13.  909.    3.   49.]
 [   5.    1.    3.  691.   43.]
 [  20.    3.   20.   19. 2623.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.782 | Acc: 53.750% | Wgt Acc: 49.991%
I - num batch: 87
I - Val -- Loss: 5.763 | Acc: 57.399% | Wgt Acc: 51.982% | Dur: 42.14s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   5.  12.  41.  18.]
 [  4. 129.  39.  11.  23.]
 [  3.  11.  87.   8.  15.]
 [ 15.  22.  15.  88.  21.]
 [ 36. 101. 137.  56. 354.]]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 1.709 | Acc: 94.000% | Wgt Acc: 94.077%
	I - Batch: 100 | Loss: 1.754 | Acc: 92.625% | Wgt Acc: 93.008%
	I - Batch: 150 | Loss: 1.740 | Acc: 92.667% | Wgt Acc: 93.293%
	I - Batch: 200 | Loss: 1.722 | Acc: 93.250% | Wgt Acc: 93.715%
	I - Batch: 250 | Loss: 1.695 | Acc: 93.850% | Wgt Acc: 94.203%
	I - Batch: 300 | Loss: 1.687 | Acc: 94.083% | Wgt Acc: 94.417%
	I - Batch: 350 | Loss: 1.679 | Acc: 94.089% | Wgt Acc: 94.513%
I - num batch: 364
I - Train -- Loss: 1.679 | Acc: 94.119% | Wgt Acc: 94.498% | LR: 1.250000e-04 | Dur: 229.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    1.    2.    5.   55.]
 [   1.  636.   49.    0.   15.]
 [   2.   23.  881.    3.   68.]
 [  10.    5.    9.  695.   30.]
 [  13.    3.   33.   15. 2595.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.709 | Acc: 56.750% | Wgt Acc: 54.801%
I - num batch: 87
I - Val -- Loss: 5.693 | Acc: 60.920% | Wgt Acc: 57.059% | Dur: 42.33s
I - Confusion Matrix: [row->prediction - col->label]
[[152.   7.  20.  51.  33.]
 [  1. 137.  35.   9.  22.]
 [  2.  32. 115.   2.  16.]
 [ 17.  12.  15. 104.  20.]
 [ 27.  80. 105.  38. 340.]]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 1.695 | Acc: 93.375% | Wgt Acc: 93.595%
	I - Batch: 100 | Loss: 1.681 | Acc: 93.625% | Wgt Acc: 93.894%
	I - Batch: 150 | Loss: 1.674 | Acc: 93.792% | Wgt Acc: 93.981%
	I - Batch: 200 | Loss: 1.666 | Acc: 94.156% | Wgt Acc: 94.412%
	I - Batch: 250 | Loss: 1.659 | Acc: 94.250% | Wgt Acc: 94.439%
	I - Batch: 300 | Loss: 1.654 | Acc: 94.229% | Wgt Acc: 94.460%
	I - Batch: 350 | Loss: 1.656 | Acc: 94.250% | Wgt Acc: 94.499%
I - num batch: 364
I - Train -- Loss: 1.658 | Acc: 94.187% | Wgt Acc: 94.433% | LR: 1.250000e-04 | Dur: 232.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 659.    0.    1.    9.   60.]
 [   0.  627.   33.    3.   14.]
 [   2.   30.  911.    0.   59.]
 [  12.    2.    6.  688.   38.]
 [  19.    9.   23.   18. 2592.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.810 | Acc: 54.000% | Wgt Acc: 50.211%
I - num batch: 87
I - Val -- Loss: 5.767 | Acc: 58.836% | Wgt Acc: 52.875% | Dur: 42.87s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   1.  10.  23.  21.]
 [  1. 110.  18.   5.   6.]
 [  3.  45. 119.   6.  16.]
 [ 45.  14.  18. 121.  34.]
 [ 35.  98. 125.  49. 354.]]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 1.643 | Acc: 93.625% | Wgt Acc: 94.733%
	I - Batch: 100 | Loss: 1.679 | Acc: 92.750% | Wgt Acc: 94.214%
	I - Batch: 150 | Loss: 1.658 | Acc: 93.292% | Wgt Acc: 94.749%
	I - Batch: 200 | Loss: 1.646 | Acc: 93.688% | Wgt Acc: 94.953%
	I - Batch: 250 | Loss: 1.636 | Acc: 93.975% | Wgt Acc: 95.107%
	I - Batch: 300 | Loss: 1.639 | Acc: 94.021% | Wgt Acc: 95.024%
	I - Batch: 350 | Loss: 1.646 | Acc: 93.982% | Wgt Acc: 94.873%
I - num batch: 364
I - Train -- Loss: 1.642 | Acc: 94.084% | Wgt Acc: 94.985% | LR: 1.250000e-04 | Dur: 232.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    6.   57.]
 [   1.  642.   21.    1.   17.]
 [   0.   23.  922.    2.   86.]
 [   7.    2.    5.  688.   50.]
 [  18.    1.   26.   21. 2553.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.874 | Acc: 52.250% | Wgt Acc: 47.582%
I - num batch: 87
I - Val -- Loss: 5.812 | Acc: 56.609% | Wgt Acc: 50.203% | Dur: 42.83s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   6.   8.  24.  20.]
 [  0.  81.  15.   7.   7.]
 [  1.  41. 110.   1.  20.]
 [ 42.  23.  22. 122.  34.]
 [ 31. 117. 135.  50. 350.]]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 1.635 | Acc: 94.500% | Wgt Acc: 94.391%
	I - Batch: 100 | Loss: 1.659 | Acc: 94.125% | Wgt Acc: 94.332%
	I - Batch: 150 | Loss: 1.637 | Acc: 94.958% | Wgt Acc: 95.110%
	I - Batch: 200 | Loss: 1.653 | Acc: 94.531% | Wgt Acc: 94.782%
	I - Batch: 250 | Loss: 1.658 | Acc: 94.625% | Wgt Acc: 94.899%
	I - Batch: 300 | Loss: 1.660 | Acc: 94.500% | Wgt Acc: 94.805%
	I - Batch: 350 | Loss: 1.659 | Acc: 94.464% | Wgt Acc: 94.877%
I - num batch: 364
I - Train -- Loss: 1.663 | Acc: 94.342% | Wgt Acc: 94.709% | LR: 1.250000e-04 | Dur: 231.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    3.    1.    5.   47.]
 [   1.  642.   30.    0.   16.]
 [   2.   15.  910.    3.   55.]
 [   8.    2.    5.  690.   53.]
 [  29.    6.   28.   20. 2592.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.727 | Acc: 55.375% | Wgt Acc: 52.657%
I - num batch: 87
I - Val -- Loss: 5.709 | Acc: 58.549% | Wgt Acc: 54.666% | Dur: 42.71s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   7.  23.  55.  36.]
 [  3. 120.  25.   7.  16.]
 [ 12.  56. 141.  10.  41.]
 [ 18.   9.  10.  94.  21.]
 [ 23.  76.  91.  38. 317.]]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 1.593 | Acc: 95.625% | Wgt Acc: 96.202%
	I - Batch: 100 | Loss: 1.630 | Acc: 94.812% | Wgt Acc: 95.376%
	I - Batch: 150 | Loss: 1.605 | Acc: 95.292% | Wgt Acc: 95.965%
	I - Batch: 200 | Loss: 1.616 | Acc: 95.000% | Wgt Acc: 95.423%
	I - Batch: 250 | Loss: 1.633 | Acc: 94.775% | Wgt Acc: 95.183%
	I - Batch: 300 | Loss: 1.650 | Acc: 94.458% | Wgt Acc: 95.013%
	I - Batch: 350 | Loss: 1.654 | Acc: 94.500% | Wgt Acc: 95.030%
I - num batch: 364
I - Train -- Loss: 1.663 | Acc: 94.359% | Wgt Acc: 94.876% | LR: 1.250000e-04 | Dur: 230.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    3.    0.   14.   40.]
 [   1.  640.   26.    0.   19.]
 [   3.   19.  919.    0.   71.]
 [   8.    2.    4.  682.   51.]
 [  16.    4.   25.   22. 2582.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.813 | Acc: 51.000% | Wgt Acc: 46.794%
I - num batch: 87
I - Val -- Loss: 5.775 | Acc: 55.819% | Wgt Acc: 50.016% | Dur: 42.39s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   4.  10.  37.  16.]
 [  0.  57.   5.   1.   4.]
 [  2. 109. 141.  10.  42.]
 [ 33.  37.  34. 121.  45.]
 [ 30.  61. 100.  35. 324.]]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 1.685 | Acc: 93.750% | Wgt Acc: 93.732%
	I - Batch: 100 | Loss: 1.698 | Acc: 92.938% | Wgt Acc: 93.682%
	I - Batch: 150 | Loss: 1.684 | Acc: 93.375% | Wgt Acc: 94.051%
	I - Batch: 200 | Loss: 1.672 | Acc: 93.844% | Wgt Acc: 94.377%
	I - Batch: 250 | Loss: 1.659 | Acc: 94.175% | Wgt Acc: 94.621%
	I - Batch: 300 | Loss: 1.652 | Acc: 94.208% | Wgt Acc: 94.738%
	I - Batch: 350 | Loss: 1.637 | Acc: 94.536% | Wgt Acc: 95.051%
I - num batch: 364
I - Train -- Loss: 1.635 | Acc: 94.635% | Wgt Acc: 95.100% | LR: 1.250000e-04 | Dur: 230.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    2.    0.   10.   47.]
 [   2.  639.   18.    2.   14.]
 [   1.   19.  924.    1.   64.]
 [   6.    3.    3.  685.   47.]
 [  19.    5.   29.   20. 2591.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.946 | Acc: 50.500% | Wgt Acc: 45.079%
I - num batch: 87
I - Val -- Loss: 5.856 | Acc: 56.466% | Wgt Acc: 48.592% | Dur: 42.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   2.   2.  15.   9.]
 [  1.  98.  13.   2.   4.]
 [  5.  58.  94.   5.  23.]
 [ 39.  13.  20. 119.  18.]
 [ 56.  97. 161.  63. 377.]]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 1.536 | Acc: 96.125% | Wgt Acc: 97.028%
	I - Batch: 100 | Loss: 1.542 | Acc: 96.125% | Wgt Acc: 96.529%
	I - Batch: 150 | Loss: 1.553 | Acc: 96.000% | Wgt Acc: 96.425%
	I - Batch: 200 | Loss: 1.559 | Acc: 95.906% | Wgt Acc: 96.387%
	I - Batch: 250 | Loss: 1.563 | Acc: 96.050% | Wgt Acc: 96.445%
	I - Batch: 300 | Loss: 1.572 | Acc: 95.812% | Wgt Acc: 96.157%
	I - Batch: 350 | Loss: 1.606 | Acc: 95.179% | Wgt Acc: 95.536%
I - num batch: 364
I - Train -- Loss: 1.610 | Acc: 95.150% | Wgt Acc: 95.522% | LR: 1.250000e-04 | Dur: 231.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    1.    2.    7.   45.]
 [   2.  653.   17.    0.    9.]
 [   0.    9.  925.    2.   45.]
 [  14.    2.    8.  689.   52.]
 [  22.    3.   22.   20. 2612.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.868 | Acc: 52.625% | Wgt Acc: 47.343%
I - num batch: 87
I - Val -- Loss: 5.816 | Acc: 56.897% | Wgt Acc: 49.545% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   5.  13.  82.  28.]
 [  2. 102.  17.   5.   8.]
 [  3.  54. 141.   6.  23.]
 [  3.   8.   9.  47.  14.]
 [ 47.  99. 110.  64. 358.]]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 1.658 | Acc: 93.875% | Wgt Acc: 94.659%
	I - Batch: 100 | Loss: 1.656 | Acc: 94.375% | Wgt Acc: 94.998%
	I - Batch: 150 | Loss: 1.654 | Acc: 94.458% | Wgt Acc: 94.850%
	I - Batch: 200 | Loss: 1.642 | Acc: 94.688% | Wgt Acc: 95.084%
	I - Batch: 250 | Loss: 1.637 | Acc: 94.825% | Wgt Acc: 95.153%
	I - Batch: 300 | Loss: 1.626 | Acc: 94.896% | Wgt Acc: 95.242%
	I - Batch: 350 | Loss: 1.609 | Acc: 95.250% | Wgt Acc: 95.576%
I - num batch: 364
I - Train -- Loss: 1.609 | Acc: 95.236% | Wgt Acc: 95.620% | LR: 1.250000e-04 | Dur: 231.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    5.    0.   10.   63.]
 [   0.  643.   18.    2.    6.]
 [   1.   12.  932.    2.   43.]
 [   5.    2.    4.  686.   40.]
 [  20.    6.   20.   18. 2611.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.859 | Acc: 52.375% | Wgt Acc: 48.641%
I - num batch: 87
I - Val -- Loss: 5.806 | Acc: 57.974% | Wgt Acc: 52.253% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   5.   9.  28.  15.]
 [  1. 108.  11.   3.   9.]
 [  3.  42. 116.   5.  25.]
 [ 30.  20.  25. 122.  35.]
 [ 51.  93. 129.  46. 347.]]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 1.633 | Acc: 93.750% | Wgt Acc: 94.597%
	I - Batch: 100 | Loss: 1.643 | Acc: 94.188% | Wgt Acc: 94.489%
	I - Batch: 150 | Loss: 1.659 | Acc: 93.917% | Wgt Acc: 94.340%
	I - Batch: 200 | Loss: 1.698 | Acc: 93.312% | Wgt Acc: 93.954%
	I - Batch: 250 | Loss: 1.686 | Acc: 93.600% | Wgt Acc: 94.247%
	I - Batch: 300 | Loss: 1.683 | Acc: 93.562% | Wgt Acc: 94.245%
	I - Batch: 350 | Loss: 1.678 | Acc: 93.661% | Wgt Acc: 94.353%
I - num batch: 364
I - Train -- Loss: 1.678 | Acc: 93.672% | Wgt Acc: 94.355% | LR: 1.250000e-04 | Dur: 230.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    1.    2.    7.   47.]
 [   2.  631.   32.    2.   23.]
 [   1.   31.  907.    2.   92.]
 [   8.    2.    2.  687.   45.]
 [  15.    3.   31.   20. 2556.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.794 | Acc: 55.500% | Wgt Acc: 51.018%
I - num batch: 87
I - Val -- Loss: 5.761 | Acc: 58.980% | Wgt Acc: 53.170% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   2.  14.  37.  14.]
 [  2. 102.  18.  10.  11.]
 [  2.  68. 128.   8.  26.]
 [ 19.   9.  19.  98.  30.]
 [ 33.  87. 111.  51. 350.]]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 1.583 | Acc: 95.875% | Wgt Acc: 96.018%
	I - Batch: 100 | Loss: 1.561 | Acc: 96.250% | Wgt Acc: 96.790%
	I - Batch: 150 | Loss: 1.573 | Acc: 95.958% | Wgt Acc: 96.580%
	I - Batch: 200 | Loss: 1.584 | Acc: 95.594% | Wgt Acc: 96.128%
	I - Batch: 250 | Loss: 1.579 | Acc: 95.675% | Wgt Acc: 96.137%
	I - Batch: 300 | Loss: 1.577 | Acc: 95.688% | Wgt Acc: 96.177%
	I - Batch: 350 | Loss: 1.573 | Acc: 95.893% | Wgt Acc: 96.310%
I - num batch: 364
I - Train -- Loss: 1.569 | Acc: 95.976% | Wgt Acc: 96.412% | LR: 1.250000e-04 | Dur: 231.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    2.    3.   45.]
 [   1.  655.   12.    0.   15.]
 [   0.   10.  939.    1.   37.]
 [   9.    2.    0.  697.   37.]
 [  21.    1.   21.   17. 2629.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.790 | Acc: 56.625% | Wgt Acc: 53.263%
I - num batch: 87
I - Val -- Loss: 5.756 | Acc: 60.345% | Wgt Acc: 55.416% | Dur: 42.39s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   7.  11.  34.  28.]
 [  1. 108.  19.   6.   8.]
 [  4.  50. 123.   2.  16.]
 [ 27.  24.  30. 123.  33.]
 [ 27.  79. 107.  39. 346.]]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 1.552 | Acc: 96.000% | Wgt Acc: 96.498%
	I - Batch: 100 | Loss: 1.524 | Acc: 96.500% | Wgt Acc: 96.871%
	I - Batch: 150 | Loss: 1.521 | Acc: 96.667% | Wgt Acc: 96.950%
	I - Batch: 200 | Loss: 1.545 | Acc: 96.125% | Wgt Acc: 96.515%
	I - Batch: 250 | Loss: 1.563 | Acc: 95.750% | Wgt Acc: 96.213%
	I - Batch: 300 | Loss: 1.560 | Acc: 95.917% | Wgt Acc: 96.358%
	I - Batch: 350 | Loss: 1.556 | Acc: 96.054% | Wgt Acc: 96.468%
I - num batch: 364
I - Train -- Loss: 1.555 | Acc: 96.079% | Wgt Acc: 96.498% | LR: 1.250000e-04 | Dur: 231.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    0.    1.    7.   43.]
 [   1.  655.    9.    1.   12.]
 [   3.    6.  940.    1.   46.]
 [   5.    3.    5.  692.   29.]
 [  16.    4.   19.   17. 2633.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.956 | Acc: 49.375% | Wgt Acc: 43.295%
I - num batch: 87
I - Val -- Loss: 5.862 | Acc: 56.250% | Wgt Acc: 47.739% | Dur: 42.70s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   2.   3.  24.  11.]
 [  0.  80.  11.   3.   3.]
 [  1.  37. 103.   3.  13.]
 [ 22.  36.  23. 105.  23.]
 [ 62. 113. 150.  69. 381.]]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 1.540 | Acc: 95.500% | Wgt Acc: 96.071%
	I - Batch: 100 | Loss: 1.549 | Acc: 95.688% | Wgt Acc: 96.321%
	I - Batch: 150 | Loss: 1.538 | Acc: 96.125% | Wgt Acc: 96.729%
	I - Batch: 200 | Loss: 1.544 | Acc: 96.219% | Wgt Acc: 96.846%
	I - Batch: 250 | Loss: 1.559 | Acc: 96.025% | Wgt Acc: 96.606%
	I - Batch: 300 | Loss: 1.560 | Acc: 96.125% | Wgt Acc: 96.616%
	I - Batch: 350 | Loss: 1.566 | Acc: 95.946% | Wgt Acc: 96.473%
I - num batch: 364
I - Train -- Loss: 1.573 | Acc: 95.890% | Wgt Acc: 96.372% | LR: 1.250000e-04 | Dur: 231.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    1.    1.    5.   48.]
 [   0.  652.   18.    1.   10.]
 [   0.    9.  929.    1.   39.]
 [   3.    2.    4.  693.   38.]
 [  15.    4.   22.   18. 2628.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.807 | Acc: 55.750% | Wgt Acc: 51.592%
I - num batch: 87
I - Val -- Loss: 5.752 | Acc: 60.704% | Wgt Acc: 55.097% | Dur: 42.66s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   3.   5.  32.  14.]
 [  2. 111.  23.   5.  10.]
 [  5.  60. 137.   6.  40.]
 [ 14.  11.  13. 107.  14.]
 [ 41.  83. 112.  54. 353.]]

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 1.480 | Acc: 96.875% | Wgt Acc: 97.665%
	I - Batch: 100 | Loss: 1.497 | Acc: 96.750% | Wgt Acc: 97.693%
	I - Batch: 150 | Loss: 1.556 | Acc: 96.125% | Wgt Acc: 96.842%
	I - Batch: 200 | Loss: 1.596 | Acc: 95.406% | Wgt Acc: 95.912%
	I - Batch: 250 | Loss: 1.626 | Acc: 94.900% | Wgt Acc: 95.324%
	I - Batch: 300 | Loss: 1.630 | Acc: 94.750% | Wgt Acc: 95.290%
	I - Batch: 350 | Loss: 1.639 | Acc: 94.607% | Wgt Acc: 95.177%
I - num batch: 364
I - Train -- Loss: 1.645 | Acc: 94.549% | Wgt Acc: 95.073% | LR: 1.250000e-04 | Dur: 231.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    3.    3.   51.]
 [   0.  642.   39.    2.   22.]
 [   1.   20.  899.    3.   49.]
 [   3.    3.    4.  690.   46.]
 [  16.    3.   29.   20. 2595.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.768 | Acc: 54.500% | Wgt Acc: 51.913%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 58.190% | Wgt Acc: 53.824% | Dur: 42.77s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   3.  10.  38.  20.]
 [  1. 152.  62.  17.  23.]
 [  5.  34.  89.   7.  18.]
 [ 18.   9.  26.  90.  26.]
 [ 40.  70. 103.  52. 344.]]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 1.574 | Acc: 96.000% | Wgt Acc: 96.214%
	I - Batch: 100 | Loss: 1.588 | Acc: 95.812% | Wgt Acc: 96.273%
	I - Batch: 150 | Loss: 1.576 | Acc: 95.833% | Wgt Acc: 96.398%
	I - Batch: 200 | Loss: 1.577 | Acc: 95.906% | Wgt Acc: 96.502%
	I - Batch: 250 | Loss: 1.579 | Acc: 95.850% | Wgt Acc: 96.399%
	I - Batch: 300 | Loss: 1.576 | Acc: 95.938% | Wgt Acc: 96.497%
	I - Batch: 350 | Loss: 1.578 | Acc: 95.875% | Wgt Acc: 96.464%
I - num batch: 364
I - Train -- Loss: 1.580 | Acc: 95.804% | Wgt Acc: 96.456% | LR: 1.250000e-04 | Dur: 231.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    2.    3.   50.]
 [   0.  653.   19.    3.   18.]
 [   0.    8.  930.    0.   50.]
 [   5.    2.    2.  703.   29.]
 [  18.    5.   21.    9. 2616.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.026 | Acc: 49.125% | Wgt Acc: 43.226%
I - num batch: 87
I - Val -- Loss: 5.915 | Acc: 55.460% | Wgt Acc: 46.503% | Dur: 42.72s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   4.  11.  35.  13.]
 [  0.  77.   5.   1.   5.]
 [  3.  38.  85.   3.   9.]
 [ 14.   8.   7.  83.  13.]
 [ 46. 141. 182.  82. 391.]]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 1.754 | Acc: 92.875% | Wgt Acc: 92.531%
	I - Batch: 100 | Loss: 1.668 | Acc: 93.875% | Wgt Acc: 94.235%
	I - Batch: 150 | Loss: 1.643 | Acc: 94.458% | Wgt Acc: 94.928%
	I - Batch: 200 | Loss: 1.645 | Acc: 94.344% | Wgt Acc: 94.901%
	I - Batch: 250 | Loss: 1.655 | Acc: 94.200% | Wgt Acc: 94.859%
	I - Batch: 300 | Loss: 1.643 | Acc: 94.375% | Wgt Acc: 95.098%
	I - Batch: 350 | Loss: 1.640 | Acc: 94.393% | Wgt Acc: 95.103%
I - num batch: 364
I - Train -- Loss: 1.635 | Acc: 94.480% | Wgt Acc: 95.185% | LR: 1.250000e-04 | Dur: 232.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 665.    2.    4.    3.   46.]
 [   1.  641.   19.    2.   24.]
 [   1.   17.  913.    2.   67.]
 [   6.    4.    3.  697.   48.]
 [  19.    4.   35.   14. 2578.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.759 | Acc: 56.875% | Wgt Acc: 53.710%
I - num batch: 87
I - Val -- Loss: 5.745 | Acc: 59.698% | Wgt Acc: 54.989% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   3.  10.  45.  25.]
 [  1. 119.  24.   6.  12.]
 [  4.  47. 126.   4.  23.]
 [ 20.  22.  25. 103.  31.]
 [ 31.  77. 105.  46. 340.]]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 1.495 | Acc: 96.750% | Wgt Acc: 97.691%
	I - Batch: 100 | Loss: 1.524 | Acc: 96.812% | Wgt Acc: 97.457%
	I - Batch: 150 | Loss: 1.518 | Acc: 96.708% | Wgt Acc: 97.461%
	I - Batch: 200 | Loss: 1.502 | Acc: 97.062% | Wgt Acc: 97.627%
	I - Batch: 250 | Loss: 1.535 | Acc: 96.575% | Wgt Acc: 97.105%
	I - Batch: 300 | Loss: 1.534 | Acc: 96.646% | Wgt Acc: 97.113%
	I - Batch: 350 | Loss: 1.541 | Acc: 96.554% | Wgt Acc: 96.963%
I - num batch: 364
I - Train -- Loss: 1.544 | Acc: 96.509% | Wgt Acc: 96.933% | LR: 1.250000e-04 | Dur: 231.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    2.    2.    2.   33.]
 [   1.  651.   11.    0.    7.]
 [   1.    5.  944.    1.   52.]
 [   0.    3.    4.  701.   27.]
 [  18.    7.   13.   14. 2644.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.811 | Acc: 51.750% | Wgt Acc: 48.232%
I - num batch: 87
I - Val -- Loss: 5.781 | Acc: 56.825% | Wgt Acc: 50.853% | Dur: 42.42s
I - Confusion Matrix: [row->prediction - col->label]
[[163.  15.  25.  80.  46.]
 [  0.  84.   6.   6.   7.]
 [  5.  70. 139.   7.  16.]
 [ 13.  15.  19.  68.  25.]
 [ 18.  84. 101.  43. 337.]]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 1.556 | Acc: 96.250% | Wgt Acc: 96.417%
	I - Batch: 100 | Loss: 1.565 | Acc: 96.562% | Wgt Acc: 96.745%
	I - Batch: 150 | Loss: 1.541 | Acc: 96.917% | Wgt Acc: 97.240%
	I - Batch: 200 | Loss: 1.544 | Acc: 96.688% | Wgt Acc: 97.129%
	I - Batch: 250 | Loss: 1.552 | Acc: 96.425% | Wgt Acc: 96.953%
	I - Batch: 300 | Loss: 1.551 | Acc: 96.354% | Wgt Acc: 96.945%
	I - Batch: 350 | Loss: 1.550 | Acc: 96.393% | Wgt Acc: 96.942%
I - num batch: 364
I - Train -- Loss: 1.550 | Acc: 96.423% | Wgt Acc: 96.935% | LR: 1.250000e-04 | Dur: 230.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    1.    2.    2.   24.]
 [   0.  651.   10.    0.   16.]
 [   1.   10.  941.    3.   59.]
 [   2.    3.    3.  703.   26.]
 [  15.    3.   18.   10. 2638.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.915 | Acc: 52.375% | Wgt Acc: 46.851%
I - num batch: 87
I - Val -- Loss: 5.842 | Acc: 58.118% | Wgt Acc: 50.407% | Dur: 42.43s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   2.   7.  26.  12.]
 [  0.  80.  13.   4.   4.]
 [  2.  54. 112.   1.  15.]
 [ 34.  23.  22. 113.  24.]
 [ 35. 109. 136.  60. 376.]]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 1.551 | Acc: 96.125% | Wgt Acc: 96.424%
	I - Batch: 100 | Loss: 1.532 | Acc: 96.312% | Wgt Acc: 96.818%
	I - Batch: 150 | Loss: 1.554 | Acc: 96.125% | Wgt Acc: 96.527%
	I - Batch: 200 | Loss: 1.555 | Acc: 96.125% | Wgt Acc: 96.509%
	I - Batch: 250 | Loss: 1.553 | Acc: 96.075% | Wgt Acc: 96.600%
	I - Batch: 300 | Loss: 1.556 | Acc: 96.104% | Wgt Acc: 96.531%
	I - Batch: 350 | Loss: 1.559 | Acc: 95.982% | Wgt Acc: 96.356%
I - num batch: 364
I - Train -- Loss: 1.555 | Acc: 96.062% | Wgt Acc: 96.436% | LR: 1.250000e-04 | Dur: 230.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    1.    3.    1.   42.]
 [   1.  644.   15.    0.   14.]
 [   2.   12.  939.    0.   44.]
 [   3.    3.    2.  700.   29.]
 [  17.    8.   15.   17. 2634.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.776 | Acc: 57.125% | Wgt Acc: 54.631%
I - num batch: 87
I - Val -- Loss: 5.751 | Acc: 61.422% | Wgt Acc: 57.469% | Dur: 42.40s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   1.   5.  40.  29.]
 [  0. 143.  35.   3.  18.]
 [  3.  23. 110.   7.  15.]
 [ 20.  14.  23. 109.  23.]
 [ 29.  87. 117.  45. 346.]]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 1.511 | Acc: 97.500% | Wgt Acc: 97.483%
	I - Batch: 100 | Loss: 1.542 | Acc: 96.375% | Wgt Acc: 97.016%
	I - Batch: 150 | Loss: 1.546 | Acc: 96.250% | Wgt Acc: 96.964%
	I - Batch: 200 | Loss: 1.548 | Acc: 96.125% | Wgt Acc: 96.829%
	I - Batch: 250 | Loss: 1.540 | Acc: 96.400% | Wgt Acc: 96.988%
	I - Batch: 300 | Loss: 1.566 | Acc: 96.042% | Wgt Acc: 96.449%
	I - Batch: 350 | Loss: 1.581 | Acc: 95.893% | Wgt Acc: 96.176%
I - num batch: 364
I - Train -- Loss: 1.581 | Acc: 95.856% | Wgt Acc: 96.154% | LR: 1.250000e-04 | Dur: 230.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    2.    0.    5.   48.]
 [   0.  644.   30.    1.   10.]
 [   0.    9.  919.    2.   35.]
 [   3.    5.    2.  700.   31.]
 [  17.    8.   23.   10. 2639.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.938 | Acc: 50.250% | Wgt Acc: 45.432%
I - num batch: 87
I - Val -- Loss: 5.856 | Acc: 56.322% | Wgt Acc: 48.684% | Dur: 42.44s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   0.   2.  23.  12.]
 [  0.  89.  15.   8.   7.]
 [  6.  39.  94.   5.  18.]
 [ 28.  11.  13. 109.  21.]
 [ 46. 129. 166.  59. 373.]]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 1.558 | Acc: 96.500% | Wgt Acc: 97.119%
	I - Batch: 100 | Loss: 1.572 | Acc: 95.938% | Wgt Acc: 96.464%
	I - Batch: 150 | Loss: 1.606 | Acc: 95.292% | Wgt Acc: 95.887%
	I - Batch: 200 | Loss: 1.612 | Acc: 95.344% | Wgt Acc: 95.830%
	I - Batch: 250 | Loss: 1.634 | Acc: 95.050% | Wgt Acc: 95.464%
	I - Batch: 300 | Loss: 1.641 | Acc: 94.917% | Wgt Acc: 95.221%
	I - Batch: 350 | Loss: 1.635 | Acc: 94.946% | Wgt Acc: 95.245%
I - num batch: 364
I - Train -- Loss: 1.638 | Acc: 94.927% | Wgt Acc: 95.251% | LR: 1.250000e-04 | Dur: 230.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    2.    2.    7.   43.]
 [   1.  634.   32.    1.   16.]
 [   0.   21.  917.    2.   61.]
 [  13.    2.    3.  696.   34.]
 [  14.    9.   20.   12. 2609.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.846 | Acc: 52.875% | Wgt Acc: 48.585%
I - num batch: 87
I - Val -- Loss: 5.805 | Acc: 58.764% | Wgt Acc: 52.831% | Dur: 42.50s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   0.   7.  29.  14.]
 [  0. 116.  26.   5.  14.]
 [  4.  33.  99.   5.  16.]
 [ 19.  17.  25. 109.  25.]
 [ 44. 102. 133.  56. 362.]]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 1.613 | Acc: 96.000% | Wgt Acc: 96.107%
	I - Batch: 100 | Loss: 1.625 | Acc: 95.250% | Wgt Acc: 95.698%
	I - Batch: 150 | Loss: 1.599 | Acc: 95.458% | Wgt Acc: 96.013%
	I - Batch: 200 | Loss: 1.582 | Acc: 95.719% | Wgt Acc: 96.261%
	I - Batch: 250 | Loss: 1.575 | Acc: 95.775% | Wgt Acc: 96.277%
	I - Batch: 300 | Loss: 1.592 | Acc: 95.583% | Wgt Acc: 96.050%
	I - Batch: 350 | Loss: 1.586 | Acc: 95.643% | Wgt Acc: 96.123%
I - num batch: 364
I - Train -- Loss: 1.588 | Acc: 95.546% | Wgt Acc: 96.093% | LR: 1.250000e-04 | Dur: 230.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    2.    1.    9.   46.]
 [   0.  650.    7.    2.   12.]
 [   2.    9.  945.    2.   49.]
 [   5.    2.    3.  686.   48.]
 [  18.    5.   18.   19. 2608.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.727 | Acc: 57.750% | Wgt Acc: 56.012%
I - num batch: 87
I - Val -- Loss: 5.712 | Acc: 60.776% | Wgt Acc: 57.868% | Dur: 42.35s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   5.   9.  29.  23.]
 [  2. 140.  31.   8.  24.]
 [  2.  28. 114.   3.  20.]
 [ 37.  31.  35. 131.  39.]
 [ 22.  64. 101.  33. 325.]]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 1.567 | Acc: 96.500% | Wgt Acc: 96.939%
	I - Batch: 100 | Loss: 1.554 | Acc: 96.750% | Wgt Acc: 97.135%
	I - Batch: 150 | Loss: 1.547 | Acc: 96.833% | Wgt Acc: 97.238%
	I - Batch: 200 | Loss: 1.544 | Acc: 96.812% | Wgt Acc: 97.186%
	I - Batch: 250 | Loss: 1.537 | Acc: 96.750% | Wgt Acc: 97.155%
	I - Batch: 300 | Loss: 1.538 | Acc: 96.646% | Wgt Acc: 97.054%
	I - Batch: 350 | Loss: 1.529 | Acc: 96.768% | Wgt Acc: 97.240%
I - num batch: 364
I - Train -- Loss: 1.527 | Acc: 96.819% | Wgt Acc: 97.266% | LR: 1.250000e-04 | Dur: 230.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    2.    1.    4.   40.]
 [   0.  655.    4.    0.   14.]
 [   2.    6.  954.    1.   28.]
 [   2.    3.    4.  699.   32.]
 [  15.    2.   11.   14. 2649.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.866 | Acc: 53.875% | Wgt Acc: 48.534%
I - num batch: 87
I - Val -- Loss: 5.805 | Acc: 58.693% | Wgt Acc: 51.188% | Dur: 42.48s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   2.   4.  16.  10.]
 [  1.  97.  18.   4.   6.]
 [  6.  46. 102.  10.  10.]
 [ 31.  17.  17. 114.  24.]
 [ 38. 106. 149.  60. 381.]]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 1.498 | Acc: 98.000% | Wgt Acc: 97.556%
	I - Batch: 100 | Loss: 1.481 | Acc: 97.938% | Wgt Acc: 97.935%
	I - Batch: 150 | Loss: 1.513 | Acc: 97.208% | Wgt Acc: 97.197%
	I - Batch: 200 | Loss: 1.587 | Acc: 95.781% | Wgt Acc: 95.917%
	I - Batch: 250 | Loss: 1.623 | Acc: 94.925% | Wgt Acc: 95.275%
	I - Batch: 300 | Loss: 1.645 | Acc: 94.542% | Wgt Acc: 94.955%
	I - Batch: 350 | Loss: 1.650 | Acc: 94.411% | Wgt Acc: 94.813%
I - num batch: 364
I - Train -- Loss: 1.650 | Acc: 94.411% | Wgt Acc: 94.808% | LR: 1.250000e-04 | Dur: 229.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    1.    1.   15.   58.]
 [   0.  646.   22.    1.   24.]
 [   0.   10.  921.    2.   46.]
 [  15.    3.    3.  683.   46.]
 [  26.    8.   27.   17. 2589.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.765 | Acc: 54.375% | Wgt Acc: 49.694%
I - num batch: 87
I - Val -- Loss: 5.744 | Acc: 57.615% | Wgt Acc: 51.994% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   3.   5.  27.  18.]
 [  0. 104.  21.   9.  12.]
 [  9.  73. 165.  12.  57.]
 [ 24.  10.  11.  93.  18.]
 [ 52.  78.  88.  63. 326.]]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 1.585 | Acc: 95.500% | Wgt Acc: 96.272%
	I - Batch: 100 | Loss: 1.649 | Acc: 94.250% | Wgt Acc: 94.767%
	I - Batch: 150 | Loss: 1.660 | Acc: 93.917% | Wgt Acc: 94.628%
	I - Batch: 200 | Loss: 1.643 | Acc: 94.281% | Wgt Acc: 95.005%
	I - Batch: 250 | Loss: 1.637 | Acc: 94.275% | Wgt Acc: 94.910%
	I - Batch: 300 | Loss: 1.629 | Acc: 94.438% | Wgt Acc: 95.026%
	I - Batch: 350 | Loss: 1.616 | Acc: 94.696% | Wgt Acc: 95.292%
I - num batch: 364
I - Train -- Loss: 1.617 | Acc: 94.669% | Wgt Acc: 95.261% | LR: 1.250000e-04 | Dur: 229.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    2.    0.   17.   63.]
 [   1.  651.   10.    2.   14.]
 [   0.    7.  931.    3.   63.]
 [  10.    3.    6.  681.   39.]
 [  23.    5.   27.   15. 2584.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.913 | Acc: 53.000% | Wgt Acc: 47.929%
I - num batch: 87
I - Val -- Loss: 5.836 | Acc: 57.830% | Wgt Acc: 50.746% | Dur: 42.04s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   3.   5.  24.  11.]
 [  3. 120.  33.   3.  15.]
 [  2.  36. 101.   4.  15.]
 [ 29.   9.  14.  99.  17.]
 [ 53. 100. 137.  74. 373.]]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 1.539 | Acc: 96.125% | Wgt Acc: 96.317%
	I - Batch: 100 | Loss: 1.518 | Acc: 97.000% | Wgt Acc: 97.068%
	I - Batch: 150 | Loss: 1.530 | Acc: 96.917% | Wgt Acc: 97.126%
	I - Batch: 200 | Loss: 1.536 | Acc: 96.625% | Wgt Acc: 96.956%
	I - Batch: 250 | Loss: 1.538 | Acc: 96.475% | Wgt Acc: 96.962%
	I - Batch: 300 | Loss: 1.550 | Acc: 96.146% | Wgt Acc: 96.711%
	I - Batch: 350 | Loss: 1.551 | Acc: 96.179% | Wgt Acc: 96.678%
I - num batch: 364
I - Train -- Loss: 1.560 | Acc: 95.993% | Wgt Acc: 96.520% | LR: 1.250000e-04 | Dur: 229.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    0.    2.   13.   36.]
 [   1.  656.    9.    0.   15.]
 [   1.    7.  933.    1.   62.]
 [   6.    2.    3.  687.   22.]
 [   6.    3.   27.   17. 2628.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.001 | Acc: 47.875% | Wgt Acc: 41.883%
I - num batch: 87
I - Val -- Loss: 5.901 | Acc: 53.017% | Wgt Acc: 44.525% | Dur: 42.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   0.   5.  12.   9.]
 [  0.  82.  18.   3.  10.]
 [  2.  38.  86.   7.  22.]
 [ 34.  21.  16. 105.  20.]
 [ 68. 127. 165.  77. 370.]]

I - Epoch: 200
I - Training: 
	I - Batch: 50 | Loss: 1.587 | Acc: 95.125% | Wgt Acc: 95.674%
	I - Batch: 100 | Loss: 1.593 | Acc: 95.625% | Wgt Acc: 95.779%
	I - Batch: 150 | Loss: 1.637 | Acc: 94.708% | Wgt Acc: 94.983%
	I - Batch: 200 | Loss: 1.647 | Acc: 94.406% | Wgt Acc: 94.865%
	I - Batch: 250 | Loss: 1.637 | Acc: 94.475% | Wgt Acc: 95.068%
	I - Batch: 300 | Loss: 1.658 | Acc: 94.104% | Wgt Acc: 94.597%
	I - Batch: 350 | Loss: 1.658 | Acc: 94.161% | Wgt Acc: 94.722%
I - num batch: 364
I - Train -- Loss: 1.658 | Acc: 94.187% | Wgt Acc: 94.752% | LR: 1.250000e-04 | Dur: 229.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 645.    2.    2.   17.   66.]
 [   2.  645.   16.    2.   21.]
 [   1.   11.  927.    0.   62.]
 [  14.    3.    3.  689.   43.]
 [  30.    7.   26.   10. 2571.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.742 | Acc: 56.250% | Wgt Acc: 53.597%
I - num batch: 87
I - Val -- Loss: 5.724 | Acc: 59.339% | Wgt Acc: 56.137% | Dur: 41.99s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   3.  10.  25.  17.]
 [  6. 142.  39.   9.  36.]
 [  8.  50. 131.  11.  43.]
 [ 31.   6.  18. 110.  19.]
 [ 27.  67.  92.  49. 316.]]

I - Epoch: 201
I - Training: 
	I - Batch: 50 | Loss: 1.627 | Acc: 95.000% | Wgt Acc: 95.597%
	I - Batch: 100 | Loss: 1.654 | Acc: 94.188% | Wgt Acc: 94.968%
	I - Batch: 150 | Loss: 1.628 | Acc: 94.708% | Wgt Acc: 95.359%
	I - Batch: 200 | Loss: 1.613 | Acc: 95.000% | Wgt Acc: 95.681%
	I - Batch: 250 | Loss: 1.595 | Acc: 95.175% | Wgt Acc: 95.930%
	I - Batch: 300 | Loss: 1.590 | Acc: 95.396% | Wgt Acc: 96.050%
	I - Batch: 350 | Loss: 1.596 | Acc: 95.375% | Wgt Acc: 95.982%
I - num batch: 364
I - Train -- Loss: 1.603 | Acc: 95.236% | Wgt Acc: 95.853% | LR: 1.250000e-04 | Dur: 229.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    1.    0.    9.   43.]
 [   0.  653.   14.    2.   25.]
 [   2.    6.  932.    5.   64.]
 [   4.    2.    6.  687.   31.]
 [  20.    6.   22.   15. 2600.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.757 | Acc: 55.375% | Wgt Acc: 51.813%
I - num batch: 87
I - Val -- Loss: 5.749 | Acc: 58.693% | Wgt Acc: 53.924% | Dur: 41.90s
I - Confusion Matrix: [row->prediction - col->label]
[[155.   9.  18.  66.  31.]
 [  1. 112.  20.   6.  14.]
 [  2.  50. 134.   4.  27.]
 [ 16.  19.  16.  83.  26.]
 [ 25.  78. 102.  45. 333.]]

I - Epoch: 202
I - Training: 
	I - Batch: 50 | Loss: 1.538 | Acc: 96.000% | Wgt Acc: 96.346%
	I - Batch: 100 | Loss: 1.517 | Acc: 96.562% | Wgt Acc: 96.901%
	I - Batch: 150 | Loss: 1.533 | Acc: 96.083% | Wgt Acc: 96.725%
	I - Batch: 200 | Loss: 1.529 | Acc: 96.344% | Wgt Acc: 97.024%
	I - Batch: 250 | Loss: 1.514 | Acc: 96.525% | Wgt Acc: 97.131%
	I - Batch: 300 | Loss: 1.514 | Acc: 96.562% | Wgt Acc: 97.109%
	I - Batch: 350 | Loss: 1.506 | Acc: 96.732% | Wgt Acc: 97.298%
I - num batch: 364
I - Train -- Loss: 1.504 | Acc: 96.715% | Wgt Acc: 97.312% | LR: 1.250000e-04 | Dur: 228.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    2.    0.    2.   44.]
 [   0.  660.    2.    0.   11.]
 [   1.    2.  950.    1.   40.]
 [   4.    2.    3.  703.   28.]
 [  16.    2.   19.   12. 2640.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.743 | Acc: 56.250% | Wgt Acc: 52.273%
I - num batch: 87
I - Val -- Loss: 5.742 | Acc: 58.980% | Wgt Acc: 53.812% | Dur: 41.87s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   5.  15.  44.  23.]
 [  1. 107.  23.   5.  18.]
 [  7.  74. 129.  10.  28.]
 [ 19.  15.  16.  97.  21.]
 [ 25.  67. 107.  48. 341.]]

I - Epoch: 203
I - Training: 
	I - Batch: 50 | Loss: 1.490 | Acc: 97.500% | Wgt Acc: 97.786%
	I - Batch: 100 | Loss: 1.526 | Acc: 97.062% | Wgt Acc: 97.338%
	I - Batch: 150 | Loss: 1.537 | Acc: 96.792% | Wgt Acc: 97.139%
	I - Batch: 200 | Loss: 1.558 | Acc: 96.406% | Wgt Acc: 96.743%
	I - Batch: 250 | Loss: 1.574 | Acc: 95.875% | Wgt Acc: 96.359%
	I - Batch: 300 | Loss: 1.584 | Acc: 95.646% | Wgt Acc: 96.238%
	I - Batch: 350 | Loss: 1.586 | Acc: 95.446% | Wgt Acc: 96.004%
I - num batch: 364
I - Train -- Loss: 1.585 | Acc: 95.477% | Wgt Acc: 96.028% | LR: 1.250000e-04 | Dur: 228.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    0.    0.    4.   46.]
 [   0.  648.   10.    1.   13.]
 [   0.   11.  943.    4.   49.]
 [   4.    3.    3.  692.   49.]
 [  25.    6.   18.   17. 2606.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.742 | Acc: 54.375% | Wgt Acc: 53.452%
I - num batch: 87
I - Val -- Loss: 5.719 | Acc: 58.405% | Wgt Acc: 56.767% | Dur: 41.92s
I - Confusion Matrix: [row->prediction - col->label]
[[147.  10.  16.  48.  36.]
 [  5. 136.  42.   3.  21.]
 [  6.  41. 122.   6.  43.]
 [ 25.  24.  26. 116.  39.]
 [ 16.  57.  84.  31. 292.]]

I - Epoch: 204
I - Training: 
	I - Batch: 50 | Loss: 1.474 | Acc: 98.000% | Wgt Acc: 98.378%
	I - Batch: 100 | Loss: 1.507 | Acc: 97.062% | Wgt Acc: 97.573%
	I - Batch: 150 | Loss: 1.514 | Acc: 96.583% | Wgt Acc: 97.314%
	I - Batch: 200 | Loss: 1.531 | Acc: 95.938% | Wgt Acc: 96.604%
	I - Batch: 250 | Loss: 1.531 | Acc: 96.050% | Wgt Acc: 96.699%
	I - Batch: 300 | Loss: 1.524 | Acc: 96.229% | Wgt Acc: 96.822%
	I - Batch: 350 | Loss: 1.525 | Acc: 96.232% | Wgt Acc: 96.845%
I - num batch: 364
I - Train -- Loss: 1.524 | Acc: 96.217% | Wgt Acc: 96.839% | LR: 1.250000e-04 | Dur: 228.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    1.    1.   64.]
 [   0.  651.    5.    1.   13.]
 [   2.    7.  946.    0.   28.]
 [   1.    4.    4.  705.   34.]
 [  20.    6.   18.   11. 2624.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.860 | Acc: 53.625% | Wgt Acc: 48.452%
I - num batch: 87
I - Val -- Loss: 5.819 | Acc: 58.836% | Wgt Acc: 51.356% | Dur: 41.92s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   3.   7.  25.   9.]
 [  2.  97.  12.   4.   9.]
 [  9.  62. 124.   8.  25.]
 [ 23.   8.   9.  94.  14.]
 [ 35.  98. 138.  73. 374.]]

I - Epoch: 205
I - Training: 
	I - Batch: 50 | Loss: 1.518 | Acc: 96.875% | Wgt Acc: 97.394%
	I - Batch: 100 | Loss: 1.467 | Acc: 97.625% | Wgt Acc: 98.269%
	I - Batch: 150 | Loss: 1.476 | Acc: 97.583% | Wgt Acc: 98.093%
	I - Batch: 200 | Loss: 1.486 | Acc: 97.344% | Wgt Acc: 97.874%
	I - Batch: 250 | Loss: 1.488 | Acc: 97.375% | Wgt Acc: 97.832%
	I - Batch: 300 | Loss: 1.494 | Acc: 97.188% | Wgt Acc: 97.547%
	I - Batch: 350 | Loss: 1.501 | Acc: 97.107% | Wgt Acc: 97.429%
I - num batch: 364
I - Train -- Loss: 1.502 | Acc: 97.008% | Wgt Acc: 97.397% | LR: 1.250000e-04 | Dur: 228.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    1.    0.    2.   30.]
 [   0.  659.    5.    0.    8.]
 [   3.    3.  949.    2.   25.]
 [   1.    3.    6.  699.   40.]
 [  14.    2.   14.   15. 2660.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.920 | Acc: 50.375% | Wgt Acc: 44.007%
I - num batch: 87
I - Val -- Loss: 5.850 | Acc: 55.532% | Wgt Acc: 47.484% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   4.   7.  44.  22.]
 [  1.  56.   4.   0.   3.]
 [  4.  66. 125.   6.  23.]
 [ 19.  19.  13. 101.  22.]
 [ 45. 123. 141.  53. 361.]]

I - Epoch: 206
I - Training: 
	I - Batch: 50 | Loss: 1.505 | Acc: 97.125% | Wgt Acc: 97.066%
	I - Batch: 100 | Loss: 1.509 | Acc: 96.938% | Wgt Acc: 97.022%
	I - Batch: 150 | Loss: 1.507 | Acc: 96.833% | Wgt Acc: 97.189%
	I - Batch: 200 | Loss: 1.504 | Acc: 96.938% | Wgt Acc: 97.347%
	I - Batch: 250 | Loss: 1.495 | Acc: 97.150% | Wgt Acc: 97.583%
	I - Batch: 300 | Loss: 1.491 | Acc: 97.292% | Wgt Acc: 97.691%
	I - Batch: 350 | Loss: 1.488 | Acc: 97.375% | Wgt Acc: 97.818%
I - num batch: 364
I - Train -- Loss: 1.489 | Acc: 97.300% | Wgt Acc: 97.758% | LR: 1.250000e-04 | Dur: 228.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    1.    1.    1.   36.]
 [   0.  661.    2.    0.    5.]
 [   0.    2.  956.    1.   29.]
 [   2.    1.    4.  702.   30.]
 [  14.    3.   11.   14. 2663.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.843 | Acc: 50.250% | Wgt Acc: 47.740%
I - num batch: 87
I - Val -- Loss: 5.805 | Acc: 54.885% | Wgt Acc: 50.989% | Dur: 41.90s
I - Confusion Matrix: [row->prediction - col->label]
[[175.  13.  26.  96.  72.]
 [  3. 125.  25.   8.  17.]
 [  2.  36.  92.   2.  14.]
 [  6.   9.   7.  53.   9.]
 [ 13.  85. 140.  45. 319.]]

I - Epoch: 207
I - Training: 
	I - Batch: 50 | Loss: 1.631 | Acc: 94.250% | Wgt Acc: 94.421%
	I - Batch: 100 | Loss: 1.609 | Acc: 94.562% | Wgt Acc: 95.204%
	I - Batch: 150 | Loss: 1.570 | Acc: 95.417% | Wgt Acc: 96.078%
	I - Batch: 200 | Loss: 1.581 | Acc: 95.500% | Wgt Acc: 95.961%
	I - Batch: 250 | Loss: 1.581 | Acc: 95.475% | Wgt Acc: 95.988%
	I - Batch: 300 | Loss: 1.590 | Acc: 95.208% | Wgt Acc: 95.821%
	I - Batch: 350 | Loss: 1.588 | Acc: 95.250% | Wgt Acc: 95.873%
I - num batch: 364
I - Train -- Loss: 1.587 | Acc: 95.236% | Wgt Acc: 95.857% | LR: 1.250000e-04 | Dur: 228.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    2.    2.   11.   49.]
 [   0.  649.   12.    1.   18.]
 [   0.   13.  936.    1.   57.]
 [   6.    1.    4.  688.   41.]
 [  19.    3.   20.   17. 2598.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.704 | Acc: 57.750% | Wgt Acc: 55.135%
I - num batch: 87
I - Val -- Loss: 5.711 | Acc: 60.129% | Wgt Acc: 56.684% | Dur: 41.87s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   3.   6.  25.  14.]
 [  5. 142.  44.   6.  32.]
 [  3.  43. 122.   7.  26.]
 [ 32.  15.  29. 131.  33.]
 [ 43.  65.  89.  35. 326.]]

I - Epoch: 208
I - Training: 
	I - Batch: 50 | Loss: 1.620 | Acc: 95.125% | Wgt Acc: 94.918%
	I - Batch: 100 | Loss: 1.703 | Acc: 92.750% | Wgt Acc: 93.213%
	I - Batch: 150 | Loss: 1.706 | Acc: 92.583% | Wgt Acc: 93.180%
	I - Batch: 200 | Loss: 1.677 | Acc: 93.375% | Wgt Acc: 94.039%
	I - Batch: 250 | Loss: 1.655 | Acc: 94.000% | Wgt Acc: 94.641%
	I - Batch: 300 | Loss: 1.630 | Acc: 94.625% | Wgt Acc: 95.185%
	I - Batch: 350 | Loss: 1.609 | Acc: 95.036% | Wgt Acc: 95.557%
I - num batch: 364
I - Train -- Loss: 1.605 | Acc: 95.116% | Wgt Acc: 95.630% | LR: 1.250000e-04 | Dur: 228.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    0.    2.    5.   39.]
 [   0.  641.   23.    0.   19.]
 [   0.   17.  922.    0.   61.]
 [   4.    4.    2.  696.   40.]
 [  20.    6.   25.   17. 2604.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.715 | Acc: 55.375% | Wgt Acc: 51.983%
I - num batch: 87
I - Val -- Loss: 5.717 | Acc: 59.555% | Wgt Acc: 55.140% | Dur: 41.91s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   9.  21.  14.]
 [  2. 125.  40.  12.  32.]
 [  6.  61. 141.   9.  34.]
 [ 35.  13.  16. 114.  22.]
 [ 36.  67.  84.  48. 329.]]

I - Epoch: 209
I - Training: 
	I - Batch: 50 | Loss: 1.509 | Acc: 96.750% | Wgt Acc: 97.618%
	I - Batch: 100 | Loss: 1.480 | Acc: 97.750% | Wgt Acc: 98.300%
	I - Batch: 150 | Loss: 1.474 | Acc: 97.792% | Wgt Acc: 98.145%
	I - Batch: 200 | Loss: 1.494 | Acc: 97.438% | Wgt Acc: 97.969%
	I - Batch: 250 | Loss: 1.492 | Acc: 97.400% | Wgt Acc: 97.946%
	I - Batch: 300 | Loss: 1.493 | Acc: 97.417% | Wgt Acc: 97.916%
	I - Batch: 350 | Loss: 1.486 | Acc: 97.429% | Wgt Acc: 97.933%
I - num batch: 364
I - Train -- Loss: 1.489 | Acc: 97.403% | Wgt Acc: 97.874% | LR: 1.250000e-04 | Dur: 228.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    2.    0.    0.   25.]
 [   0.  660.    4.    0.    7.]
 [   0.    3.  952.    0.   34.]
 [   0.    1.    3.  704.   30.]
 [  11.    2.   15.   14. 2667.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.006 | Acc: 45.875% | Wgt Acc: 38.661%
I - num batch: 87
I - Val -- Loss: 5.905 | Acc: 54.454% | Wgt Acc: 44.569% | Dur: 41.68s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   0.  10.  32.   9.]
 [  0.  66.   5.   2.   4.]
 [  4.  68. 116.  12.  23.]
 [  8.   5.   7.  62.   8.]
 [ 60. 129. 152.  96. 387.]]

I - Epoch: 210
I - Training: 
	I - Batch: 50 | Loss: 1.584 | Acc: 96.000% | Wgt Acc: 96.654%
	I - Batch: 100 | Loss: 1.588 | Acc: 95.500% | Wgt Acc: 96.291%
	I - Batch: 150 | Loss: 1.573 | Acc: 95.792% | Wgt Acc: 96.529%
	I - Batch: 200 | Loss: 1.578 | Acc: 95.438% | Wgt Acc: 96.200%
	I - Batch: 250 | Loss: 1.571 | Acc: 95.400% | Wgt Acc: 96.293%
	I - Batch: 300 | Loss: 1.568 | Acc: 95.542% | Wgt Acc: 96.380%
	I - Batch: 350 | Loss: 1.568 | Acc: 95.518% | Wgt Acc: 96.339%
I - num batch: 364
I - Train -- Loss: 1.566 | Acc: 95.563% | Wgt Acc: 96.387% | LR: 1.250000e-04 | Dur: 227.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    3.    0.    5.   59.]
 [   1.  656.    3.    0.    8.]
 [   0.    5.  949.    1.   59.]
 [   9.    1.    5.  698.   44.]
 [  21.    3.   17.   14. 2593.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.778 | Acc: 55.750% | Wgt Acc: 52.821%
I - num batch: 87
I - Val -- Loss: 5.763 | Acc: 59.626% | Wgt Acc: 55.551% | Dur: 41.64s
I - Confusion Matrix: [row->prediction - col->label]
[[157.   4.  11.  44.  31.]
 [  2. 113.  24.   5.  17.]
 [  2.  44. 113.   4.  15.]
 [ 14.  19.  28. 112.  33.]
 [ 24.  88. 114.  39. 335.]]

I - Epoch: 211
I - Training: 
	I - Batch: 50 | Loss: 1.467 | Acc: 97.500% | Wgt Acc: 98.099%
	I - Batch: 100 | Loss: 1.462 | Acc: 97.562% | Wgt Acc: 98.123%
	I - Batch: 150 | Loss: 1.457 | Acc: 97.667% | Wgt Acc: 98.084%
	I - Batch: 200 | Loss: 1.454 | Acc: 97.719% | Wgt Acc: 98.203%
	I - Batch: 250 | Loss: 1.464 | Acc: 97.625% | Wgt Acc: 98.095%
	I - Batch: 300 | Loss: 1.476 | Acc: 97.354% | Wgt Acc: 97.853%
	I - Batch: 350 | Loss: 1.489 | Acc: 97.161% | Wgt Acc: 97.587%
I - num batch: 364
I - Train -- Loss: 1.486 | Acc: 97.231% | Wgt Acc: 97.664% | LR: 1.250000e-04 | Dur: 227.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    1.    0.    1.   25.]
 [   1.  661.    3.    1.   12.]
 [   1.    2.  948.    1.   39.]
 [   1.    1.    5.  706.   22.]
 [  15.    3.   18.    9. 2665.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.788 | Acc: 53.625% | Wgt Acc: 49.953%
I - num batch: 87
I - Val -- Loss: 5.762 | Acc: 59.626% | Wgt Acc: 53.984% | Dur: 41.72s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   4.   5.  23.  16.]
 [  1. 105.  17.   6.  11.]
 [  3.  54. 109.   4.  15.]
 [ 33.  19.  31. 129.  32.]
 [ 32.  86. 128.  42. 357.]]

I - Epoch: 212
I - Training: 
	I - Batch: 50 | Loss: 1.445 | Acc: 98.125% | Wgt Acc: 98.476%
	I - Batch: 100 | Loss: 1.455 | Acc: 98.000% | Wgt Acc: 98.199%
	I - Batch: 150 | Loss: 1.488 | Acc: 97.333% | Wgt Acc: 97.547%
	I - Batch: 200 | Loss: 1.497 | Acc: 97.094% | Wgt Acc: 97.370%
	I - Batch: 250 | Loss: 1.496 | Acc: 97.025% | Wgt Acc: 97.449%
	I - Batch: 300 | Loss: 1.501 | Acc: 97.000% | Wgt Acc: 97.451%
	I - Batch: 350 | Loss: 1.498 | Acc: 97.036% | Wgt Acc: 97.502%
I - num batch: 364
I - Train -- Loss: 1.499 | Acc: 97.042% | Wgt Acc: 97.481% | LR: 1.250000e-04 | Dur: 227.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    0.    1.    1.   31.]
 [   0.  653.    4.    0.   12.]
 [   1.    7.  951.    1.   43.]
 [   4.    3.    2.  708.   20.]
 [  13.    5.   16.    8. 2657.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.789 | Acc: 55.250% | Wgt Acc: 50.356%
I - num batch: 87
I - Val -- Loss: 5.755 | Acc: 60.201% | Wgt Acc: 54.131% | Dur: 41.64s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   4.   7.  33.  12.]
 [  0.  85.   7.   4.  10.]
 [  4.  69. 147.   6.  23.]
 [ 21.  22.  33. 114.  35.]
 [ 33.  88.  96.  47. 351.]]

I - Epoch: 213
I - Training: 
	I - Batch: 50 | Loss: 1.596 | Acc: 95.750% | Wgt Acc: 95.969%
	I - Batch: 100 | Loss: 1.587 | Acc: 95.688% | Wgt Acc: 95.685%
	I - Batch: 150 | Loss: 1.567 | Acc: 96.000% | Wgt Acc: 96.170%
	I - Batch: 200 | Loss: 1.581 | Acc: 95.688% | Wgt Acc: 95.974%
	I - Batch: 250 | Loss: 1.581 | Acc: 95.600% | Wgt Acc: 95.846%
	I - Batch: 300 | Loss: 1.572 | Acc: 95.625% | Wgt Acc: 96.005%
	I - Batch: 350 | Loss: 1.580 | Acc: 95.536% | Wgt Acc: 95.984%
I - num batch: 364
I - Train -- Loss: 1.584 | Acc: 95.512% | Wgt Acc: 95.951% | LR: 1.250000e-04 | Dur: 227.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    2.    3.   10.   35.]
 [   0.  647.   23.    1.   17.]
 [   0.   13.  921.    0.   53.]
 [   7.    2.    4.  693.   37.]
 [  13.    4.   23.   14. 2621.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.779 | Acc: 55.125% | Wgt Acc: 52.613%
I - num batch: 87
I - Val -- Loss: 5.755 | Acc: 59.626% | Wgt Acc: 55.727% | Dur: 41.72s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   8.  14.  33.  35.]
 [  0. 116.  20.   7.  13.]
 [  4.  41. 132.   8.  31.]
 [ 31.  14.  23. 118.  27.]
 [ 25.  89. 101.  38. 325.]]

I - Epoch: 214
I - Training: 
	I - Batch: 50 | Loss: 1.594 | Acc: 95.500% | Wgt Acc: 95.933%
	I - Batch: 100 | Loss: 1.583 | Acc: 95.625% | Wgt Acc: 95.987%
	I - Batch: 150 | Loss: 1.551 | Acc: 96.000% | Wgt Acc: 96.547%
	I - Batch: 200 | Loss: 1.540 | Acc: 96.281% | Wgt Acc: 96.831%
	I - Batch: 250 | Loss: 1.537 | Acc: 96.475% | Wgt Acc: 96.869%
	I - Batch: 300 | Loss: 1.525 | Acc: 96.729% | Wgt Acc: 97.139%
	I - Batch: 350 | Loss: 1.521 | Acc: 96.750% | Wgt Acc: 97.176%
I - num batch: 364
I - Train -- Loss: 1.523 | Acc: 96.750% | Wgt Acc: 97.140% | LR: 1.250000e-04 | Dur: 227.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    1.    1.   32.]
 [   0.  653.   16.    0.   12.]
 [   0.    9.  943.    1.   40.]
 [   0.    2.    2.  696.   25.]
 [  12.    4.   12.   20. 2654.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.796 | Acc: 54.875% | Wgt Acc: 51.113%
I - num batch: 87
I - Val -- Loss: 5.777 | Acc: 59.698% | Wgt Acc: 54.339% | Dur: 41.66s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   3.  10.  42.  24.]
 [  0. 137.  46.   5.  20.]
 [  4.  26. 105.   6.  13.]
 [ 10.   7.   9.  89.  15.]
 [ 44.  95. 120.  62. 359.]]

I - Epoch: 215
I - Training: 
	I - Batch: 50 | Loss: 1.504 | Acc: 97.000% | Wgt Acc: 97.282%
	I - Batch: 100 | Loss: 1.485 | Acc: 97.438% | Wgt Acc: 97.784%
	I - Batch: 150 | Loss: 1.485 | Acc: 97.625% | Wgt Acc: 97.889%
	I - Batch: 200 | Loss: 1.469 | Acc: 97.875% | Wgt Acc: 98.149%
	I - Batch: 250 | Loss: 1.472 | Acc: 97.800% | Wgt Acc: 98.016%
	I - Batch: 300 | Loss: 1.471 | Acc: 97.792% | Wgt Acc: 98.011%
	I - Batch: 350 | Loss: 1.472 | Acc: 97.768% | Wgt Acc: 97.977%
I - num batch: 364
I - Train -- Loss: 1.475 | Acc: 97.696% | Wgt Acc: 97.886% | LR: 1.250000e-04 | Dur: 227.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    0.    2.    5.   25.]
 [   0.  661.    4.    1.    9.]
 [   0.    2.  947.    0.   18.]
 [   4.    3.    4.  705.   19.]
 [  12.    2.   17.    7. 2692.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.814 | Acc: 55.000% | Wgt Acc: 50.684%
I - num batch: 87
I - Val -- Loss: 5.790 | Acc: 59.986% | Wgt Acc: 54.032% | Dur: 41.66s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   6.   9.  35.  17.]
 [  0.  85.   4.   2.   5.]
 [  0.  58. 137.   6.  31.]
 [ 21.  17.  29. 116.  26.]
 [ 33. 102. 111.  45. 352.]]

I - Epoch: 216
I - Training: 
	I - Batch: 50 | Loss: 1.528 | Acc: 96.125% | Wgt Acc: 96.771%
	I - Batch: 100 | Loss: 1.518 | Acc: 96.875% | Wgt Acc: 97.462%
	I - Batch: 150 | Loss: 1.492 | Acc: 97.375% | Wgt Acc: 97.820%
	I - Batch: 200 | Loss: 1.497 | Acc: 97.219% | Wgt Acc: 97.617%
	I - Batch: 250 | Loss: 1.519 | Acc: 96.675% | Wgt Acc: 97.029%
	I - Batch: 300 | Loss: 1.570 | Acc: 95.792% | Wgt Acc: 95.963%
	I - Batch: 350 | Loss: 1.577 | Acc: 95.661% | Wgt Acc: 95.919%
I - num batch: 364
I - Train -- Loss: 1.580 | Acc: 95.598% | Wgt Acc: 95.895% | LR: 1.250000e-04 | Dur: 227.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    1.    0.    3.   28.]
 [   0.  634.   23.    0.   23.]
 [   0.   21.  925.    3.   63.]
 [   4.    2.    5.  701.   21.]
 [  17.   10.   21.   11. 2628.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.786 | Acc: 53.500% | Wgt Acc: 49.184%
I - num batch: 87
I - Val -- Loss: 5.764 | Acc: 57.615% | Wgt Acc: 52.034% | Dur: 41.67s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   3.   1.  51.  21.]
 [  1. 104.  30.   5.  16.]
 [  5.  64. 134.   8.  35.]
 [ 13.  13.  18.  84.  21.]
 [ 38.  84. 107.  56. 338.]]

I - Epoch: 217
I - Training: 
	I - Batch: 50 | Loss: 1.650 | Acc: 93.625% | Wgt Acc: 94.841%
	I - Batch: 100 | Loss: 1.607 | Acc: 94.500% | Wgt Acc: 95.716%
	I - Batch: 150 | Loss: 1.571 | Acc: 95.583% | Wgt Acc: 96.403%
	I - Batch: 200 | Loss: 1.557 | Acc: 95.781% | Wgt Acc: 96.719%
	I - Batch: 250 | Loss: 1.550 | Acc: 95.850% | Wgt Acc: 96.677%
	I - Batch: 300 | Loss: 1.552 | Acc: 95.875% | Wgt Acc: 96.668%
	I - Batch: 350 | Loss: 1.546 | Acc: 96.143% | Wgt Acc: 96.863%
I - num batch: 364
I - Train -- Loss: 1.542 | Acc: 96.251% | Wgt Acc: 96.945% | LR: 1.250000e-04 | Dur: 229.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    1.    0.    3.   35.]
 [   1.  653.    8.    0.   12.]
 [   0.    8.  940.    1.   64.]
 [   4.    2.    4.  705.   28.]
 [  12.    4.   22.    9. 2624.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.880 | Acc: 52.875% | Wgt Acc: 47.960%
I - num batch: 87
I - Val -- Loss: 5.828 | Acc: 57.615% | Wgt Acc: 51.324% | Dur: 42.01s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   7.  14.  45.  29.]
 [  1.  75.   2.   1.   3.]
 [  4.  56. 127.   6.  26.]
 [ 18.  21.  24. 102.  25.]
 [ 26. 109. 123.  50. 348.]]

I - Epoch: 218
I - Training: 
	I - Batch: 50 | Loss: 1.447 | Acc: 98.375% | Wgt Acc: 98.351%
	I - Batch: 100 | Loss: 1.483 | Acc: 97.688% | Wgt Acc: 97.881%
	I - Batch: 150 | Loss: 1.483 | Acc: 97.458% | Wgt Acc: 97.943%
	I - Batch: 200 | Loss: 1.494 | Acc: 97.250% | Wgt Acc: 97.774%
	I - Batch: 250 | Loss: 1.485 | Acc: 97.500% | Wgt Acc: 97.998%
	I - Batch: 300 | Loss: 1.479 | Acc: 97.583% | Wgt Acc: 98.061%
	I - Batch: 350 | Loss: 1.473 | Acc: 97.661% | Wgt Acc: 98.103%
I - num batch: 364
I - Train -- Loss: 1.477 | Acc: 97.541% | Wgt Acc: 97.998% | LR: 1.250000e-04 | Dur: 229.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    1.    3.   25.]
 [   0.  658.    4.    0.   15.]
 [   0.    4.  957.    1.   34.]
 [   3.    3.    3.  703.   19.]
 [   5.    3.    9.   11. 2670.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.762 | Acc: 56.625% | Wgt Acc: 52.765%
I - num batch: 87
I - Val -- Loss: 5.748 | Acc: 59.339% | Wgt Acc: 54.112% | Dur: 41.97s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   5.   9.  20.  12.]
 [  1. 111.  22.   4.  10.]
 [  2.  51. 127.   7.  15.]
 [ 41.  39.  34. 129.  51.]
 [ 39.  62.  98.  44. 343.]]

I - Epoch: 219
I - Training: 
	I - Batch: 50 | Loss: 1.490 | Acc: 97.000% | Wgt Acc: 97.491%
	I - Batch: 100 | Loss: 1.463 | Acc: 97.562% | Wgt Acc: 97.920%
	I - Batch: 150 | Loss: 1.457 | Acc: 97.625% | Wgt Acc: 97.993%
	I - Batch: 200 | Loss: 1.463 | Acc: 97.594% | Wgt Acc: 97.959%
	I - Batch: 250 | Loss: 1.456 | Acc: 97.775% | Wgt Acc: 98.127%
	I - Batch: 300 | Loss: 1.456 | Acc: 97.854% | Wgt Acc: 98.179%
	I - Batch: 350 | Loss: 1.451 | Acc: 97.982% | Wgt Acc: 98.275%
I - num batch: 364
I - Train -- Loss: 1.450 | Acc: 98.057% | Wgt Acc: 98.343% | LR: 1.250000e-04 | Dur: 228.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    0.    1.   15.]
 [   0.  660.    5.    0.    8.]
 [   0.    3.  958.    0.   26.]
 [   0.    1.    3.  710.   20.]
 [  12.    2.    8.    7. 2694.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.844 | Acc: 52.750% | Wgt Acc: 47.841%
I - num batch: 87
I - Val -- Loss: 5.798 | Acc: 58.190% | Wgt Acc: 51.228% | Dur: 41.91s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   6.  20.  19.]
 [  0.  93.  13.   1.   9.]
 [  2.  47. 113.   4.  13.]
 [ 28.  16.  17. 118.  24.]
 [ 49. 110. 141.  61. 366.]]

I - Epoch: 220
I - Training: 
	I - Batch: 50 | Loss: 1.424 | Acc: 98.750% | Wgt Acc: 98.992%
	I - Batch: 100 | Loss: 1.455 | Acc: 98.375% | Wgt Acc: 98.665%
	I - Batch: 150 | Loss: 1.448 | Acc: 98.333% | Wgt Acc: 98.663%
	I - Batch: 200 | Loss: 1.445 | Acc: 98.438% | Wgt Acc: 98.710%
	I - Batch: 250 | Loss: 1.453 | Acc: 98.275% | Wgt Acc: 98.496%
	I - Batch: 300 | Loss: 1.456 | Acc: 98.167% | Wgt Acc: 98.412%
	I - Batch: 350 | Loss: 1.461 | Acc: 98.089% | Wgt Acc: 98.321%
I - num batch: 364
I - Train -- Loss: 1.461 | Acc: 98.005% | Wgt Acc: 98.286% | LR: 1.250000e-04 | Dur: 228.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    2.    2.   24.]
 [   1.  663.    6.    2.    3.]
 [   0.    3.  953.    0.   21.]
 [   0.    2.    3.  706.   20.]
 [   9.    0.   10.    8. 2695.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.893 | Acc: 52.125% | Wgt Acc: 46.674%
I - num batch: 87
I - Val -- Loss: 5.823 | Acc: 57.399% | Wgt Acc: 50.259% | Dur: 41.93s
I - Confusion Matrix: [row->prediction - col->label]
[[148.  10.  20.  59.  29.]
 [  1.  96.  11.   3.   3.]
 [  3.  54. 118.   8.  23.]
 [ 12.   9.   8.  72.  11.]
 [ 35.  99. 133.  62. 365.]]

I - Epoch: 221
I - Training: 
	I - Batch: 50 | Loss: 1.494 | Acc: 97.000% | Wgt Acc: 97.969%
	I - Batch: 100 | Loss: 1.530 | Acc: 96.188% | Wgt Acc: 96.867%
	I - Batch: 150 | Loss: 1.546 | Acc: 95.917% | Wgt Acc: 96.416%
	I - Batch: 200 | Loss: 1.541 | Acc: 96.094% | Wgt Acc: 96.610%
	I - Batch: 250 | Loss: 1.533 | Acc: 96.300% | Wgt Acc: 96.891%
	I - Batch: 300 | Loss: 1.531 | Acc: 96.417% | Wgt Acc: 96.913%
	I - Batch: 350 | Loss: 1.521 | Acc: 96.625% | Wgt Acc: 97.073%
I - num batch: 364
I - Train -- Loss: 1.522 | Acc: 96.664% | Wgt Acc: 97.111% | LR: 1.250000e-04 | Dur: 228.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    4.    0.    2.   46.]
 [   0.  654.    8.    0.    8.]
 [   1.    7.  946.    0.   33.]
 [   1.    0.    3.  703.   29.]
 [  19.    3.   17.   13. 2647.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.879 | Acc: 53.000% | Wgt Acc: 47.412%
I - num batch: 87
I - Val -- Loss: 5.816 | Acc: 57.615% | Wgt Acc: 50.167% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   9.   7.  35.  22.]
 [  0.  98.  11.   4.   8.]
 [  4.  47. 122.   6.  16.]
 [ 22.   3.   9.  90.  17.]
 [ 49. 111. 141.  69. 368.]]

I - Epoch: 222
I - Training: 
	I - Batch: 50 | Loss: 1.570 | Acc: 94.875% | Wgt Acc: 96.323%
	I - Batch: 100 | Loss: 1.595 | Acc: 94.812% | Wgt Acc: 96.096%
	I - Batch: 150 | Loss: 1.596 | Acc: 94.917% | Wgt Acc: 96.066%
	I - Batch: 200 | Loss: 1.583 | Acc: 95.344% | Wgt Acc: 96.343%
	I - Batch: 250 | Loss: 1.571 | Acc: 95.350% | Wgt Acc: 96.338%
	I - Batch: 300 | Loss: 1.553 | Acc: 95.667% | Wgt Acc: 96.572%
	I - Batch: 350 | Loss: 1.546 | Acc: 95.839% | Wgt Acc: 96.709%
I - num batch: 364
I - Train -- Loss: 1.545 | Acc: 95.821% | Wgt Acc: 96.665% | LR: 1.250000e-04 | Dur: 228.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    4.    4.   45.]
 [   1.  659.    8.    1.   13.]
 [   0.    3.  934.    1.   59.]
 [   4.    3.    3.  701.   40.]
 [  15.    3.   25.   11. 2606.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.768 | Acc: 54.250% | Wgt Acc: 50.268%
I - num batch: 87
I - Val -- Loss: 5.743 | Acc: 58.549% | Wgt Acc: 53.270% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   7.  11.  28.  20.]
 [  0. 113.  25.   6.  18.]
 [  6.  61. 119.   7.  23.]
 [ 19.  23.  16. 105.  26.]
 [ 40.  64. 119.  58. 344.]]

I - Epoch: 223
I - Training: 
	I - Batch: 50 | Loss: 1.486 | Acc: 97.000% | Wgt Acc: 97.937%
	I - Batch: 100 | Loss: 1.484 | Acc: 97.188% | Wgt Acc: 97.891%
	I - Batch: 150 | Loss: 1.498 | Acc: 96.875% | Wgt Acc: 97.512%
	I - Batch: 200 | Loss: 1.502 | Acc: 96.844% | Wgt Acc: 97.374%
	I - Batch: 250 | Loss: 1.515 | Acc: 96.625% | Wgt Acc: 97.211%
	I - Batch: 300 | Loss: 1.536 | Acc: 96.271% | Wgt Acc: 96.819%
	I - Batch: 350 | Loss: 1.562 | Acc: 95.804% | Wgt Acc: 96.299%
I - num batch: 364
I - Train -- Loss: 1.568 | Acc: 95.666% | Wgt Acc: 96.146% | LR: 1.250000e-04 | Dur: 228.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 660.    0.    0.    7.   41.]
 [   2.  652.    7.    0.   17.]
 [   0.    7.  942.    2.   53.]
 [  14.    5.    2.  693.   36.]
 [  16.    4.   23.   16. 2616.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.729 | Acc: 54.875% | Wgt Acc: 52.210%
I - num batch: 87
I - Val -- Loss: 5.712 | Acc: 58.190% | Wgt Acc: 54.658% | Dur: 41.93s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   5.  13.  37.  28.]
 [  0.  84.  16.   2.   7.]
 [  6.  92. 168.  10.  62.]
 [ 36.  20.  25. 124.  38.]
 [ 19.  67.  68.  31. 296.]]

I - Epoch: 224
I - Training: 
	I - Batch: 50 | Loss: 1.562 | Acc: 95.750% | Wgt Acc: 96.490%
	I - Batch: 100 | Loss: 1.560 | Acc: 95.875% | Wgt Acc: 96.524%
	I - Batch: 150 | Loss: 1.557 | Acc: 95.833% | Wgt Acc: 96.628%
	I - Batch: 200 | Loss: 1.555 | Acc: 95.875% | Wgt Acc: 96.719%
	I - Batch: 250 | Loss: 1.561 | Acc: 95.775% | Wgt Acc: 96.480%
	I - Batch: 300 | Loss: 1.548 | Acc: 96.062% | Wgt Acc: 96.723%
	I - Batch: 350 | Loss: 1.544 | Acc: 96.089% | Wgt Acc: 96.757%
I - num batch: 364
I - Train -- Loss: 1.543 | Acc: 96.096% | Wgt Acc: 96.755% | LR: 1.250000e-04 | Dur: 228.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    2.    0.    2.   45.]
 [   2.  659.    8.    0.    6.]
 [   0.    4.  947.    0.   42.]
 [   5.    1.    2.  696.   51.]
 [  18.    2.   17.   20. 2619.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.927 | Acc: 51.250% | Wgt Acc: 45.741%
I - num batch: 87
I - Val -- Loss: 5.836 | Acc: 58.477% | Wgt Acc: 51.180% | Dur: 41.99s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   0.   6.   9.   8.]
 [  0.  98.  21.   1.   8.]
 [  1.  46. 113.   5.  16.]
 [ 39.  15.  15. 127.  27.]
 [ 55. 109. 135.  62. 372.]]

I - Epoch: 225
I - Training: 
	I - Batch: 50 | Loss: 1.500 | Acc: 97.250% | Wgt Acc: 97.875%
	I - Batch: 100 | Loss: 1.518 | Acc: 96.875% | Wgt Acc: 97.457%
	I - Batch: 150 | Loss: 1.530 | Acc: 96.458% | Wgt Acc: 96.989%
	I - Batch: 200 | Loss: 1.555 | Acc: 96.125% | Wgt Acc: 96.719%
	I - Batch: 250 | Loss: 1.551 | Acc: 96.175% | Wgt Acc: 96.726%
	I - Batch: 300 | Loss: 1.549 | Acc: 96.229% | Wgt Acc: 96.862%
	I - Batch: 350 | Loss: 1.537 | Acc: 96.482% | Wgt Acc: 97.116%
I - num batch: 364
I - Train -- Loss: 1.541 | Acc: 96.320% | Wgt Acc: 97.020% | LR: 1.250000e-04 | Dur: 228.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    1.    0.    4.   38.]
 [   1.  657.    9.    0.   11.]
 [   0.    7.  943.    0.   50.]
 [   7.    2.    4.  703.   39.]
 [  11.    1.   18.   11. 2625.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.852 | Acc: 53.500% | Wgt Acc: 48.774%
I - num batch: 87
I - Val -- Loss: 5.800 | Acc: 58.549% | Wgt Acc: 52.014% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   6.   6.  20.  13.]
 [  0. 121.  28.   2.  14.]
 [  4.  33. 109.  13.  16.]
 [ 23.  15.  13. 102.  22.]
 [ 55.  93. 134.  67. 366.]]

I - Epoch: 226
I - Training: 
	I - Batch: 50 | Loss: 1.531 | Acc: 96.250% | Wgt Acc: 97.392%
	I - Batch: 100 | Loss: 1.546 | Acc: 96.000% | Wgt Acc: 96.948%
	I - Batch: 150 | Loss: 1.582 | Acc: 95.375% | Wgt Acc: 96.065%
	I - Batch: 200 | Loss: 1.602 | Acc: 94.844% | Wgt Acc: 95.652%
	I - Batch: 250 | Loss: 1.605 | Acc: 95.000% | Wgt Acc: 95.715%
	I - Batch: 300 | Loss: 1.604 | Acc: 95.083% | Wgt Acc: 95.755%
	I - Batch: 350 | Loss: 1.596 | Acc: 95.196% | Wgt Acc: 95.821%
I - num batch: 364
I - Train -- Loss: 1.600 | Acc: 95.047% | Wgt Acc: 95.671% | LR: 1.250000e-04 | Dur: 228.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    0.    1.   17.   54.]
 [   1.  656.    9.    1.   19.]
 [   3.    7.  941.    5.   55.]
 [   8.    2.    6.  676.   44.]
 [  17.    3.   17.   19. 2591.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.796 | Acc: 54.875% | Wgt Acc: 51.100%
I - num batch: 87
I - Val -- Loss: 5.777 | Acc: 59.267% | Wgt Acc: 54.060% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[152.  11.  13.  53.  30.]
 [  2. 103.  22.   3.  14.]
 [  2.  58. 120.   5.  16.]
 [ 17.  15.  25. 104.  25.]
 [ 26.  81. 110.  39. 346.]]

I - Epoch: 227
I - Training: 
	I - Batch: 50 | Loss: 1.617 | Acc: 94.875% | Wgt Acc: 95.376%
	I - Batch: 100 | Loss: 1.554 | Acc: 96.562% | Wgt Acc: 96.884%
	I - Batch: 150 | Loss: 1.541 | Acc: 96.542% | Wgt Acc: 96.920%
	I - Batch: 200 | Loss: 1.535 | Acc: 96.625% | Wgt Acc: 96.891%
	I - Batch: 250 | Loss: 1.526 | Acc: 96.850% | Wgt Acc: 97.141%
	I - Batch: 300 | Loss: 1.523 | Acc: 96.896% | Wgt Acc: 97.225%
	I - Batch: 350 | Loss: 1.526 | Acc: 96.714% | Wgt Acc: 97.044%
I - num batch: 364
I - Train -- Loss: 1.525 | Acc: 96.647% | Wgt Acc: 97.020% | LR: 1.250000e-04 | Dur: 228.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    2.    0.    1.   41.]
 [   1.  648.    8.    0.   10.]
 [   1.    8.  955.    0.   32.]
 [   6.    3.    4.  707.   34.]
 [  20.    7.    7.   10. 2646.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.768 | Acc: 54.625% | Wgt Acc: 50.369%
I - num batch: 87
I - Val -- Loss: 5.768 | Acc: 58.621% | Wgt Acc: 53.107% | Dur: 42.01s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   6.  11.  43.  21.]
 [  2. 104.  16.   4.   9.]
 [  4.  67. 141.   9.  35.]
 [ 28.  13.  22.  98.  27.]
 [ 31.  78. 100.  50. 339.]]

I - Epoch: 228
I - Training: 
	I - Batch: 50 | Loss: 1.473 | Acc: 97.125% | Wgt Acc: 97.714%
	I - Batch: 100 | Loss: 1.489 | Acc: 96.750% | Wgt Acc: 97.329%
	I - Batch: 150 | Loss: 1.485 | Acc: 97.000% | Wgt Acc: 97.530%
	I - Batch: 200 | Loss: 1.492 | Acc: 96.719% | Wgt Acc: 97.366%
	I - Batch: 250 | Loss: 1.493 | Acc: 96.750% | Wgt Acc: 97.337%
	I - Batch: 300 | Loss: 1.499 | Acc: 96.667% | Wgt Acc: 97.202%
	I - Batch: 350 | Loss: 1.495 | Acc: 96.696% | Wgt Acc: 97.298%
I - num batch: 364
I - Train -- Loss: 1.496 | Acc: 96.681% | Wgt Acc: 97.276% | LR: 1.250000e-04 | Dur: 228.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    1.    3.    0.   38.]
 [   1.  661.    5.    1.   10.]
 [   1.    0.  945.    1.   50.]
 [   3.    2.    2.  703.   24.]
 [  15.    4.   19.   13. 2641.]]

I - Validation: 
	I - Batch: 50 | Loss: 6.006 | Acc: 48.500% | Wgt Acc: 41.990%
I - num batch: 87
I - Val -- Loss: 5.902 | Acc: 56.034% | Wgt Acc: 46.949% | Dur: 41.90s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   8.  11.  39.  18.]
 [  0.  88.  17.   3.   3.]
 [  1.  28.  82.   4.   5.]
 [ 11.   6.   5.  77.   7.]
 [ 52. 138. 175.  81. 398.]]

I - Epoch: 229
I - Training: 
	I - Batch: 50 | Loss: 1.485 | Acc: 96.875% | Wgt Acc: 97.779%
	I - Batch: 100 | Loss: 1.478 | Acc: 97.125% | Wgt Acc: 97.807%
	I - Batch: 150 | Loss: 1.480 | Acc: 97.167% | Wgt Acc: 97.594%
	I - Batch: 200 | Loss: 1.476 | Acc: 97.312% | Wgt Acc: 97.784%
	I - Batch: 250 | Loss: 1.470 | Acc: 97.500% | Wgt Acc: 97.922%
	I - Batch: 300 | Loss: 1.465 | Acc: 97.583% | Wgt Acc: 98.039%
	I - Batch: 350 | Loss: 1.462 | Acc: 97.589% | Wgt Acc: 98.041%
I - num batch: 364
I - Train -- Loss: 1.463 | Acc: 97.592% | Wgt Acc: 98.035% | LR: 1.250000e-04 | Dur: 228.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    1.    1.   25.]
 [   0.  659.    7.    0.    3.]
 [   1.    5.  955.    0.   31.]
 [   2.    2.    2.  706.   31.]
 [   7.    2.    9.   11. 2673.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.814 | Acc: 53.625% | Wgt Acc: 50.400%
I - num batch: 87
I - Val -- Loss: 5.775 | Acc: 57.328% | Wgt Acc: 52.560% | Dur: 41.90s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  14.  25.  60.  57.]
 [  0.  95.   8.   2.   2.]
 [  3.  38. 121.   4.  13.]
 [ 23.  17.  26.  96.  30.]
 [ 16. 104. 110.  42. 329.]]

I - Epoch: 230
I - Training: 
	I - Batch: 50 | Loss: 1.451 | Acc: 97.625% | Wgt Acc: 98.329%
	I - Batch: 100 | Loss: 1.459 | Acc: 97.562% | Wgt Acc: 98.249%
	I - Batch: 150 | Loss: 1.461 | Acc: 97.875% | Wgt Acc: 98.367%
	I - Batch: 200 | Loss: 1.454 | Acc: 98.031% | Wgt Acc: 98.510%
	I - Batch: 250 | Loss: 1.447 | Acc: 98.150% | Wgt Acc: 98.568%
	I - Batch: 300 | Loss: 1.449 | Acc: 98.188% | Wgt Acc: 98.580%
	I - Batch: 350 | Loss: 1.451 | Acc: 97.982% | Wgt Acc: 98.446%
I - num batch: 364
I - Train -- Loss: 1.452 | Acc: 97.902% | Wgt Acc: 98.413% | LR: 1.250000e-04 | Dur: 229.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    0.   28.]
 [   1.  662.    1.    0.   10.]
 [   0.    1.  958.    1.   35.]
 [   1.    3.    3.  713.   12.]
 [   8.    2.   12.    4. 2678.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.730 | Acc: 53.375% | Wgt Acc: 48.931%
I - num batch: 87
I - Val -- Loss: 5.719 | Acc: 58.477% | Wgt Acc: 52.636% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   8.  26.  17.]
 [  2. 111.  22.   7.  13.]
 [  3.  70. 155.  10.  50.]
 [ 25.  19.  16.  93.  13.]
 [ 52.  66.  89.  68. 338.]]

I - Epoch: 231
I - Training: 
	I - Batch: 50 | Loss: 1.415 | Acc: 99.125% | Wgt Acc: 99.214%
	I - Batch: 100 | Loss: 1.415 | Acc: 98.750% | Wgt Acc: 99.042%
	I - Batch: 150 | Loss: 1.426 | Acc: 98.583% | Wgt Acc: 98.844%
	I - Batch: 200 | Loss: 1.436 | Acc: 98.281% | Wgt Acc: 98.645%
	I - Batch: 250 | Loss: 1.440 | Acc: 98.125% | Wgt Acc: 98.552%
	I - Batch: 300 | Loss: 1.441 | Acc: 98.000% | Wgt Acc: 98.477%
	I - Batch: 350 | Loss: 1.459 | Acc: 97.804% | Wgt Acc: 98.147%
I - num batch: 364
I - Train -- Loss: 1.462 | Acc: 97.782% | Wgt Acc: 98.129% | LR: 1.250000e-04 | Dur: 228.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    0.    1.    5.   29.]
 [   0.  658.    1.    0.    9.]
 [   0.    1.  962.    0.   26.]
 [   2.    2.    1.  704.   18.]
 [   9.    7.    9.    9. 2681.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.809 | Acc: 52.750% | Wgt Acc: 47.519%
I - num batch: 87
I - Val -- Loss: 5.773 | Acc: 57.615% | Wgt Acc: 51.699% | Dur: 41.98s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   9.  13.  28.  19.]
 [  0.  94.  11.   3.  16.]
 [  9.  70. 148.   9.  35.]
 [ 34.  12.  14. 114.  26.]
 [ 45.  83. 104.  50. 335.]]

I - Epoch: 232
I - Training: 
	I - Batch: 50 | Loss: 1.565 | Acc: 96.375% | Wgt Acc: 96.620%
	I - Batch: 100 | Loss: 1.658 | Acc: 94.812% | Wgt Acc: 94.903%
	I - Batch: 150 | Loss: 1.695 | Acc: 93.583% | Wgt Acc: 93.903%
	I - Batch: 200 | Loss: 1.712 | Acc: 93.531% | Wgt Acc: 93.755%
	I - Batch: 250 | Loss: 1.722 | Acc: 93.375% | Wgt Acc: 93.502%
	I - Batch: 300 | Loss: 1.715 | Acc: 93.542% | Wgt Acc: 93.612%
	I - Batch: 350 | Loss: 1.705 | Acc: 93.679% | Wgt Acc: 93.928%
I - num batch: 364
I - Train -- Loss: 1.700 | Acc: 93.723% | Wgt Acc: 94.000% | LR: 1.250000e-04 | Dur: 228.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 653.    2.    2.   18.   49.]
 [   1.  636.   33.    2.   26.]
 [   2.   18.  903.    5.   66.]
 [  13.    2.    5.  678.   42.]
 [  23.   10.   31.   15. 2580.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.710 | Acc: 55.250% | Wgt Acc: 52.273%
I - num batch: 87
I - Val -- Loss: 5.714 | Acc: 60.129% | Wgt Acc: 55.842% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[150.   4.  15.  65.  30.]
 [  2. 148.  40.   9.  18.]
 [  1.  27. 111.   6.  16.]
 [ 16.   6.  16.  83.  22.]
 [ 30.  83. 108.  41. 345.]]

I - Epoch: 233
I - Training: 
	I - Batch: 50 | Loss: 1.636 | Acc: 94.125% | Wgt Acc: 94.889%
	I - Batch: 100 | Loss: 1.612 | Acc: 94.938% | Wgt Acc: 95.485%
	I - Batch: 150 | Loss: 1.589 | Acc: 95.542% | Wgt Acc: 95.792%
	I - Batch: 200 | Loss: 1.563 | Acc: 95.969% | Wgt Acc: 96.253%
	I - Batch: 250 | Loss: 1.568 | Acc: 95.950% | Wgt Acc: 96.115%
	I - Batch: 300 | Loss: 1.558 | Acc: 96.146% | Wgt Acc: 96.420%
	I - Batch: 350 | Loss: 1.571 | Acc: 95.964% | Wgt Acc: 96.209%
I - num batch: 364
I - Train -- Loss: 1.572 | Acc: 95.942% | Wgt Acc: 96.171% | LR: 1.250000e-04 | Dur: 232.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    3.    2.    6.   38.]
 [   0.  636.    9.    1.   19.]
 [   1.   15.  939.    4.   40.]
 [  11.    3.    5.  698.   29.]
 [  11.   11.   19.    9. 2637.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.889 | Acc: 51.250% | Wgt Acc: 46.655%
I - num batch: 87
I - Val -- Loss: 5.808 | Acc: 56.968% | Wgt Acc: 50.347% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   5.  15.  38.  14.]
 [  1.  95.  20.   2.  10.]
 [  2.  23.  90.   5.   6.]
 [ 30.  40.  33. 113.  37.]
 [ 35. 105. 132.  46. 364.]]

I - Epoch: 234
I - Training: 
	I - Batch: 50 | Loss: 1.614 | Acc: 95.000% | Wgt Acc: 95.629%
	I - Batch: 100 | Loss: 1.583 | Acc: 95.688% | Wgt Acc: 96.203%
	I - Batch: 150 | Loss: 1.562 | Acc: 95.875% | Wgt Acc: 96.457%
	I - Batch: 200 | Loss: 1.551 | Acc: 96.094% | Wgt Acc: 96.671%
	I - Batch: 250 | Loss: 1.546 | Acc: 96.275% | Wgt Acc: 96.820%
	I - Batch: 300 | Loss: 1.530 | Acc: 96.500% | Wgt Acc: 97.108%
	I - Batch: 350 | Loss: 1.524 | Acc: 96.696% | Wgt Acc: 97.253%
I - num batch: 364
I - Train -- Loss: 1.521 | Acc: 96.767% | Wgt Acc: 97.298% | LR: 1.250000e-04 | Dur: 233.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    1.    3.    1.   42.]
 [   0.  654.    5.    0.   11.]
 [   0.    6.  954.    1.   42.]
 [   0.    3.    2.  703.   25.]
 [  19.    4.   10.   13. 2643.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.916 | Acc: 50.125% | Wgt Acc: 43.856%
I - num batch: 87
I - Val -- Loss: 5.849 | Acc: 56.968% | Wgt Acc: 48.644% | Dur: 43.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   0.   1.  16.  12.]
 [  0.  87.   8.   0.   9.]
 [  5.  62. 130.  14.  22.]
 [ 34.  12.  11. 108.  16.]
 [ 64. 107. 140.  66. 372.]]

I - Epoch: 235
I - Training: 
	I - Batch: 50 | Loss: 1.460 | Acc: 97.750% | Wgt Acc: 98.172%
	I - Batch: 100 | Loss: 1.469 | Acc: 97.375% | Wgt Acc: 97.891%
	I - Batch: 150 | Loss: 1.477 | Acc: 97.417% | Wgt Acc: 98.010%
	I - Batch: 200 | Loss: 1.475 | Acc: 97.531% | Wgt Acc: 98.029%
	I - Batch: 250 | Loss: 1.473 | Acc: 97.550% | Wgt Acc: 98.000%
	I - Batch: 300 | Loss: 1.482 | Acc: 97.375% | Wgt Acc: 97.867%
	I - Batch: 350 | Loss: 1.488 | Acc: 97.232% | Wgt Acc: 97.769%
I - num batch: 364
I - Train -- Loss: 1.491 | Acc: 97.214% | Wgt Acc: 97.710% | LR: 1.250000e-04 | Dur: 233.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    1.    0.   33.]
 [   0.  657.    4.    0.    3.]
 [   0.    5.  951.    0.   33.]
 [   1.    2.    4.  705.   34.]
 [  11.    4.   14.   13. 2660.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.868 | Acc: 53.125% | Wgt Acc: 47.733%
I - num batch: 87
I - Val -- Loss: 5.811 | Acc: 59.052% | Wgt Acc: 51.683% | Dur: 43.03s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   0.   9.  19.  12.]
 [  1. 116.  26.   2.  11.]
 [  3.  39. 115.  10.  17.]
 [ 19.   6.   5.  97.  13.]
 [ 60. 107. 135.  76. 378.]]

I - Epoch: 236
I - Training: 
	I - Batch: 50 | Loss: 1.495 | Acc: 97.125% | Wgt Acc: 96.989%
	I - Batch: 100 | Loss: 1.501 | Acc: 96.938% | Wgt Acc: 97.219%
	I - Batch: 150 | Loss: 1.488 | Acc: 97.333% | Wgt Acc: 97.766%
	I - Batch: 200 | Loss: 1.496 | Acc: 97.094% | Wgt Acc: 97.478%
	I - Batch: 250 | Loss: 1.490 | Acc: 97.225% | Wgt Acc: 97.637%
	I - Batch: 300 | Loss: 1.482 | Acc: 97.396% | Wgt Acc: 97.782%
	I - Batch: 350 | Loss: 1.479 | Acc: 97.429% | Wgt Acc: 97.817%
I - num batch: 364
I - Train -- Loss: 1.479 | Acc: 97.438% | Wgt Acc: 97.823% | LR: 1.250000e-04 | Dur: 233.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    0.    2.    0.   34.]
 [   0.  662.    4.    0.    7.]
 [   0.    1.  956.    0.   26.]
 [   0.    2.    1.  702.   25.]
 [  17.    3.   11.   16. 2671.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.835 | Acc: 53.375% | Wgt Acc: 48.887%
I - num batch: 87
I - Val -- Loss: 5.786 | Acc: 58.477% | Wgt Acc: 51.858% | Dur: 43.13s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   1.  12.  46.  23.]
 [  4. 110.  20.   6.  13.]
 [  6.  43. 120.   8.  20.]
 [ 10.   6.   4.  82.  12.]
 [ 40. 108. 134.  62. 363.]]

I - Epoch: 237
I - Training: 
	I - Batch: 50 | Loss: 1.524 | Acc: 96.750% | Wgt Acc: 97.371%
	I - Batch: 100 | Loss: 1.487 | Acc: 97.688% | Wgt Acc: 98.186%
	I - Batch: 150 | Loss: 1.487 | Acc: 97.625% | Wgt Acc: 98.039%
	I - Batch: 200 | Loss: 1.495 | Acc: 97.188% | Wgt Acc: 97.864%
	I - Batch: 250 | Loss: 1.482 | Acc: 97.425% | Wgt Acc: 98.065%
	I - Batch: 300 | Loss: 1.476 | Acc: 97.521% | Wgt Acc: 98.134%
	I - Batch: 350 | Loss: 1.474 | Acc: 97.464% | Wgt Acc: 98.001%
I - num batch: 364
I - Train -- Loss: 1.473 | Acc: 97.472% | Wgt Acc: 98.012% | LR: 1.250000e-04 | Dur: 233.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    0.    0.   35.]
 [   0.  660.    5.    0.   10.]
 [   1.    1.  956.    1.   33.]
 [   3.    2.    0.  708.   21.]
 [   8.    5.   13.    9. 2664.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.769 | Acc: 54.875% | Wgt Acc: 49.991%
I - num batch: 87
I - Val -- Loss: 5.741 | Acc: 59.052% | Wgt Acc: 52.704% | Dur: 42.97s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   1.   6.  27.  11.]
 [  2. 120.  27.   6.  19.]
 [  7.  67. 149.  18.  33.]
 [ 24.   9.   9.  93.  17.]
 [ 57.  71.  99.  60. 351.]]

I - Epoch: 238
I - Training: 
	I - Batch: 50 | Loss: 1.450 | Acc: 98.250% | Wgt Acc: 98.473%
	I - Batch: 100 | Loss: 1.487 | Acc: 97.000% | Wgt Acc: 97.670%
	I - Batch: 150 | Loss: 1.474 | Acc: 97.125% | Wgt Acc: 97.836%
	I - Batch: 200 | Loss: 1.497 | Acc: 96.812% | Wgt Acc: 97.516%
	I - Batch: 250 | Loss: 1.488 | Acc: 97.025% | Wgt Acc: 97.710%
	I - Batch: 300 | Loss: 1.487 | Acc: 97.104% | Wgt Acc: 97.789%
	I - Batch: 350 | Loss: 1.479 | Acc: 97.321% | Wgt Acc: 97.909%
I - num batch: 364
I - Train -- Loss: 1.481 | Acc: 97.317% | Wgt Acc: 97.886% | LR: 1.250000e-04 | Dur: 233.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    1.    1.    3.   29.]
 [   2.  661.    4.    1.   15.]
 [   0.    1.  956.    1.   41.]
 [   1.    2.    0.  704.   20.]
 [   9.    3.   13.    9. 2658.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.799 | Acc: 56.000% | Wgt Acc: 51.983%
I - num batch: 87
I - Val -- Loss: 5.771 | Acc: 59.914% | Wgt Acc: 54.622% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   1.   9.  29.  15.]
 [  1. 137.  35.  11.  21.]
 [  6.  47. 128.   9.  35.]
 [ 11.   9.   9.  94.  10.]
 [ 56.  74. 109.  61. 350.]]

I - Epoch: 239
I - Training: 
	I - Batch: 50 | Loss: 1.443 | Acc: 98.375% | Wgt Acc: 98.845%
	I - Batch: 100 | Loss: 1.413 | Acc: 98.750% | Wgt Acc: 99.113%
	I - Batch: 150 | Loss: 1.412 | Acc: 98.833% | Wgt Acc: 99.175%
	I - Batch: 200 | Loss: 1.427 | Acc: 98.469% | Wgt Acc: 98.866%
	I - Batch: 250 | Loss: 1.429 | Acc: 98.500% | Wgt Acc: 98.800%
	I - Batch: 300 | Loss: 1.435 | Acc: 98.292% | Wgt Acc: 98.602%
	I - Batch: 350 | Loss: 1.435 | Acc: 98.393% | Wgt Acc: 98.684%
I - num batch: 364
I - Train -- Loss: 1.436 | Acc: 98.315% | Wgt Acc: 98.636% | LR: 1.250000e-04 | Dur: 231.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    0.    2.   21.]
 [   0.  665.    1.    0.    5.]
 [   0.    1.  965.    0.   18.]
 [   1.    2.    1.  709.   21.]
 [  11.    0.    7.    7. 2698.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.901 | Acc: 52.500% | Wgt Acc: 47.721%
I - num batch: 87
I - Val -- Loss: 5.835 | Acc: 58.261% | Wgt Acc: 51.232% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   3.  22.   9.]
 [  1. 112.  21.   3.  12.]
 [  0.  29. 100.   3.   7.]
 [ 26.  10.  17. 108.  29.]
 [ 55. 115. 149.  68. 374.]]

I - Epoch: 240
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 98.125% | Wgt Acc: 98.278%
	I - Batch: 100 | Loss: 1.446 | Acc: 98.000% | Wgt Acc: 98.312%
	I - Batch: 150 | Loss: 1.459 | Acc: 97.542% | Wgt Acc: 98.028%
	I - Batch: 200 | Loss: 1.462 | Acc: 97.469% | Wgt Acc: 97.887%
	I - Batch: 250 | Loss: 1.458 | Acc: 97.500% | Wgt Acc: 97.909%
	I - Batch: 300 | Loss: 1.452 | Acc: 97.688% | Wgt Acc: 98.092%
	I - Batch: 350 | Loss: 1.452 | Acc: 97.732% | Wgt Acc: 98.139%
I - num batch: 364
I - Train -- Loss: 1.452 | Acc: 97.713% | Wgt Acc: 98.140% | LR: 1.250000e-04 | Dur: 231.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    1.    1.   33.]
 [   0.  659.    1.    0.    8.]
 [   0.    2.  959.    2.   32.]
 [   0.    2.    0.  706.   14.]
 [  10.    5.   13.    9. 2676.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.808 | Acc: 55.500% | Wgt Acc: 51.182%
I - num batch: 87
I - Val -- Loss: 5.757 | Acc: 60.201% | Wgt Acc: 54.263% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   1.   9.  24.  16.]
 [  0. 114.  23.   1.  10.]
 [  3.  45. 117.   5.  15.]
 [ 34.  20.  25. 122.  28.]
 [ 39.  88. 116.  52. 362.]]

I - Epoch: 241
I - Training: 
	I - Batch: 50 | Loss: 1.418 | Acc: 98.625% | Wgt Acc: 98.916%
	I - Batch: 100 | Loss: 1.431 | Acc: 98.375% | Wgt Acc: 98.584%
	I - Batch: 150 | Loss: 1.449 | Acc: 98.125% | Wgt Acc: 98.309%
	I - Batch: 200 | Loss: 1.440 | Acc: 98.438% | Wgt Acc: 98.627%
	I - Batch: 250 | Loss: 1.439 | Acc: 98.375% | Wgt Acc: 98.610%
	I - Batch: 300 | Loss: 1.441 | Acc: 98.354% | Wgt Acc: 98.637%
	I - Batch: 350 | Loss: 1.445 | Acc: 98.321% | Wgt Acc: 98.562%
I - num batch: 364
I - Train -- Loss: 1.445 | Acc: 98.349% | Wgt Acc: 98.580% | LR: 1.250000e-04 | Dur: 231.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    1.    0.    1.   22.]
 [   0.  661.    3.    0.    4.]
 [   1.    3.  963.    1.   20.]
 [   1.    2.    1.  711.   13.]
 [  10.    1.    7.    5. 2704.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.861 | Acc: 52.875% | Wgt Acc: 48.503%
I - num batch: 87
I - Val -- Loss: 5.796 | Acc: 57.830% | Wgt Acc: 52.130% | Dur: 42.58s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   6.  11.  36.  29.]
 [  0. 106.  19.   4.  10.]
 [  3.  26.  81.   3.   5.]
 [ 23.  25.  23. 112.  27.]
 [ 27. 105. 156.  49. 360.]]

I - Epoch: 242
I - Training: 
	I - Batch: 50 | Loss: 1.419 | Acc: 98.250% | Wgt Acc: 98.865%
	I - Batch: 100 | Loss: 1.437 | Acc: 98.125% | Wgt Acc: 98.472%
	I - Batch: 150 | Loss: 1.426 | Acc: 98.458% | Wgt Acc: 98.708%
	I - Batch: 200 | Loss: 1.421 | Acc: 98.625% | Wgt Acc: 98.925%
	I - Batch: 250 | Loss: 1.420 | Acc: 98.600% | Wgt Acc: 98.894%
	I - Batch: 300 | Loss: 1.422 | Acc: 98.562% | Wgt Acc: 98.803%
	I - Batch: 350 | Loss: 1.425 | Acc: 98.429% | Wgt Acc: 98.651%
I - num batch: 364
I - Train -- Loss: 1.426 | Acc: 98.418% | Wgt Acc: 98.612% | LR: 1.250000e-04 | Dur: 230.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    0.    4.   20.]
 [   0.  662.    1.    0.    5.]
 [   0.    1.  961.    0.   16.]
 [   1.    3.    1.  707.   13.]
 [   7.    2.   11.    7. 2709.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.792 | Acc: 54.250% | Wgt Acc: 49.537%
I - num batch: 87
I - Val -- Loss: 5.775 | Acc: 58.693% | Wgt Acc: 52.173% | Dur: 41.96s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   0.   8.  15.   9.]
 [  1. 107.  15.   7.  11.]
 [ 12.  75. 151.   9.  42.]
 [ 32.  12.  16. 110.  20.]
 [ 54.  74. 100.  63. 349.]]

I - Epoch: 243
I - Training: 
	I - Batch: 50 | Loss: 1.440 | Acc: 97.875% | Wgt Acc: 98.320%
	I - Batch: 100 | Loss: 1.429 | Acc: 98.062% | Wgt Acc: 98.448%
	I - Batch: 150 | Loss: 1.422 | Acc: 98.208% | Wgt Acc: 98.544%
	I - Batch: 200 | Loss: 1.446 | Acc: 97.875% | Wgt Acc: 98.084%
	I - Batch: 250 | Loss: 1.446 | Acc: 97.975% | Wgt Acc: 98.232%
	I - Batch: 300 | Loss: 1.455 | Acc: 97.875% | Wgt Acc: 98.068%
	I - Batch: 350 | Loss: 1.464 | Acc: 97.732% | Wgt Acc: 97.923%
I - num batch: 364
I - Train -- Loss: 1.468 | Acc: 97.661% | Wgt Acc: 97.862% | LR: 1.250000e-04 | Dur: 228.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    1.    0.    4.   45.]
 [   0.  659.    1.    1.    5.]
 [   0.    2.  966.    0.   17.]
 [   8.    3.    0.  703.   13.]
 [  16.    3.    7.   10. 2683.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.607 | Acc: 59.125% | Wgt Acc: 59.713%
I - num batch: 87
I - Val -- Loss: 5.645 | Acc: 60.489% | Wgt Acc: 60.472% | Dur: 41.85s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   9.  11.  36.  20.]
 [  4. 172.  49.  22.  54.]
 [  6.  36. 137.   7.  44.]
 [ 22.  17.  22. 113.  36.]
 [ 24.  34.  71.  26. 277.]]

I - Epoch: 244
I - Training: 
	I - Batch: 50 | Loss: 1.576 | Acc: 95.125% | Wgt Acc: 95.721%
	I - Batch: 100 | Loss: 1.543 | Acc: 95.688% | Wgt Acc: 96.253%
	I - Batch: 150 | Loss: 1.529 | Acc: 96.292% | Wgt Acc: 96.808%
	I - Batch: 200 | Loss: 1.503 | Acc: 96.812% | Wgt Acc: 97.294%
	I - Batch: 250 | Loss: 1.488 | Acc: 97.075% | Wgt Acc: 97.570%
	I - Batch: 300 | Loss: 1.485 | Acc: 97.167% | Wgt Acc: 97.594%
	I - Batch: 350 | Loss: 1.481 | Acc: 97.286% | Wgt Acc: 97.699%
I - num batch: 364
I - Train -- Loss: 1.482 | Acc: 97.248% | Wgt Acc: 97.676% | LR: 1.250000e-04 | Dur: 228.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    0.    1.    2.   34.]
 [   1.  657.    9.    1.   15.]
 [   0.    4.  955.    2.   24.]
 [   6.    3.    1.  703.   27.]
 [   8.    4.    8.   10. 2663.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.899 | Acc: 49.875% | Wgt Acc: 44.354%
I - num batch: 87
I - Val -- Loss: 5.833 | Acc: 56.034% | Wgt Acc: 48.309% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   5.   6.  36.  19.]
 [  2. 112.  32.   5.   4.]
 [  5.  25.  83.   9.  15.]
 [ 10.  16.   6.  77.  13.]
 [ 54. 110. 163.  77. 380.]]

I - Epoch: 245
I - Training: 
	I - Batch: 50 | Loss: 1.457 | Acc: 97.875% | Wgt Acc: 97.888%
	I - Batch: 100 | Loss: 1.469 | Acc: 97.625% | Wgt Acc: 97.879%
	I - Batch: 150 | Loss: 1.473 | Acc: 97.542% | Wgt Acc: 97.779%
	I - Batch: 200 | Loss: 1.469 | Acc: 97.719% | Wgt Acc: 97.964%
	I - Batch: 250 | Loss: 1.500 | Acc: 97.175% | Wgt Acc: 97.445%
	I - Batch: 300 | Loss: 1.531 | Acc: 96.667% | Wgt Acc: 96.908%
	I - Batch: 350 | Loss: 1.532 | Acc: 96.643% | Wgt Acc: 96.948%
I - num batch: 364
I - Train -- Loss: 1.534 | Acc: 96.561% | Wgt Acc: 96.916% | LR: 1.250000e-04 | Dur: 228.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    2.    1.    6.   29.]
 [   1.  648.   19.    0.   22.]
 [   1.   10.  939.    1.   34.]
 [   2.    1.    1.  697.   27.]
 [   8.    7.   14.   14. 2651.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.801 | Acc: 55.625% | Wgt Acc: 52.267%
I - num batch: 87
I - Val -- Loss: 5.764 | Acc: 60.489% | Wgt Acc: 55.025% | Dur: 41.80s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   1.  13.  41.  14.]
 [  1. 129.  18.   5.  18.]
 [  3.  28. 108.   4.  12.]
 [ 27.  24.  19. 109.  25.]
 [ 34.  86. 132.  45. 362.]]

I - Epoch: 246
I - Training: 
	I - Batch: 50 | Loss: 1.585 | Acc: 95.125% | Wgt Acc: 95.057%
	I - Batch: 100 | Loss: 1.572 | Acc: 95.688% | Wgt Acc: 95.991%
	I - Batch: 150 | Loss: 1.540 | Acc: 96.458% | Wgt Acc: 96.764%
	I - Batch: 200 | Loss: 1.518 | Acc: 96.781% | Wgt Acc: 97.169%
	I - Batch: 250 | Loss: 1.520 | Acc: 96.675% | Wgt Acc: 97.035%
	I - Batch: 300 | Loss: 1.513 | Acc: 96.708% | Wgt Acc: 97.171%
	I - Batch: 350 | Loss: 1.512 | Acc: 96.732% | Wgt Acc: 97.232%
I - num batch: 364
I - Train -- Loss: 1.515 | Acc: 96.698% | Wgt Acc: 97.206% | LR: 1.250000e-04 | Dur: 228.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    1.    1.   12.   47.]
 [   0.  657.    5.    0.   12.]
 [   0.    3.  961.    0.   35.]
 [   7.    2.    0.  692.   29.]
 [  12.    5.    7.   14. 2640.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.694 | Acc: 56.875% | Wgt Acc: 55.003%
I - num batch: 87
I - Val -- Loss: 5.713 | Acc: 59.411% | Wgt Acc: 56.624% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   6.   5.  30.  22.]
 [  2. 132.  29.  11.  22.]
 [  9.  59. 136.  11.  50.]
 [ 25.  17.  18. 112.  29.]
 [ 24.  54. 102.  40. 308.]]

I - Epoch: 247
I - Training: 
	I - Batch: 50 | Loss: 1.522 | Acc: 95.250% | Wgt Acc: 96.782%
	I - Batch: 100 | Loss: 1.508 | Acc: 96.188% | Wgt Acc: 96.978%
	I - Batch: 150 | Loss: 1.496 | Acc: 96.708% | Wgt Acc: 97.435%
	I - Batch: 200 | Loss: 1.498 | Acc: 96.688% | Wgt Acc: 97.392%
	I - Batch: 250 | Loss: 1.489 | Acc: 96.975% | Wgt Acc: 97.595%
	I - Batch: 300 | Loss: 1.481 | Acc: 97.250% | Wgt Acc: 97.734%
	I - Batch: 350 | Loss: 1.480 | Acc: 97.250% | Wgt Acc: 97.741%
I - num batch: 364
I - Train -- Loss: 1.483 | Acc: 97.197% | Wgt Acc: 97.710% | LR: 1.250000e-04 | Dur: 228.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    1.    0.    3.   24.]
 [   0.  657.    4.    0.   12.]
 [   1.    2.  950.    0.   42.]
 [   3.    3.    1.  705.   26.]
 [   7.    5.   19.   10. 2659.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.706 | Acc: 55.000% | Wgt Acc: 53.906%
I - num batch: 87
I - Val -- Loss: 5.706 | Acc: 58.764% | Wgt Acc: 56.078% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   4.  18.  37.  18.]
 [  5. 174.  85.  11.  38.]
 [  3.  11.  67.   0.  14.]
 [ 29.  17.  17. 117.  29.]
 [ 34.  62. 103.  39. 332.]]

I - Epoch: 248
I - Training: 
	I - Batch: 50 | Loss: 1.484 | Acc: 96.375% | Wgt Acc: 97.202%
	I - Batch: 100 | Loss: 1.480 | Acc: 96.938% | Wgt Acc: 97.434%
	I - Batch: 150 | Loss: 1.463 | Acc: 97.417% | Wgt Acc: 97.782%
	I - Batch: 200 | Loss: 1.494 | Acc: 97.000% | Wgt Acc: 97.291%
	I - Batch: 250 | Loss: 1.514 | Acc: 96.575% | Wgt Acc: 97.050%
	I - Batch: 300 | Loss: 1.507 | Acc: 96.792% | Wgt Acc: 97.194%
	I - Batch: 350 | Loss: 1.509 | Acc: 96.839% | Wgt Acc: 97.194%
I - num batch: 364
I - Train -- Loss: 1.509 | Acc: 96.836% | Wgt Acc: 97.214% | LR: 1.250000e-04 | Dur: 228.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    3.    0.   16.   35.]
 [   0.  659.    1.    1.   10.]
 [   2.    1.  958.    0.   27.]
 [   6.    2.    1.  692.   39.]
 [  14.    3.   14.    9. 2652.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.978 | Acc: 49.625% | Wgt Acc: 43.156%
I - num batch: 87
I - Val -- Loss: 5.878 | Acc: 56.897% | Wgt Acc: 48.102% | Dur: 41.82s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   1.   0.  23.  13.]
 [  0.  92.   7.   3.   7.]
 [  3.  41. 112.   4.  12.]
 [ 15.  12.  17.  80.  12.]
 [ 60. 122. 154.  94. 387.]]

I - Epoch: 249
I - Training: 
	I - Batch: 50 | Loss: 1.587 | Acc: 95.000% | Wgt Acc: 95.511%
	I - Batch: 100 | Loss: 1.639 | Acc: 94.188% | Wgt Acc: 94.933%
	I - Batch: 150 | Loss: 1.621 | Acc: 94.417% | Wgt Acc: 95.230%
	I - Batch: 200 | Loss: 1.617 | Acc: 94.625% | Wgt Acc: 95.279%
	I - Batch: 250 | Loss: 1.613 | Acc: 94.625% | Wgt Acc: 95.284%
	I - Batch: 300 | Loss: 1.601 | Acc: 94.896% | Wgt Acc: 95.510%
	I - Batch: 350 | Loss: 1.588 | Acc: 95.214% | Wgt Acc: 95.785%
I - num batch: 364
I - Train -- Loss: 1.583 | Acc: 95.322% | Wgt Acc: 95.865% | LR: 1.250000e-04 | Dur: 228.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    1.    0.    4.   52.]
 [   1.  643.   14.    1.   21.]
 [   0.   12.  936.    3.   59.]
 [   3.    5.    3.  692.   27.]
 [  20.    7.   21.   18. 2604.]]

I - Validation: 
	I - Batch: 50 | Loss: 5.720 | Acc: 55.250% | Wgt Acc: 51.958%
I - num batch: 87
I - Val -- Loss: 5.695 | Acc: 59.483% | Wgt Acc: 54.965% | Dur: 41.84s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   3.   2.  23.  10.]
 [  2. 141.  45.   8.  28.]
 [  8.  31. 117.   6.  28.]
 [ 34.  17.  21. 119.  25.]
 [ 44.  76. 105.  48. 340.]]

I - Maximum validation set accuracy in current training:  63.00
