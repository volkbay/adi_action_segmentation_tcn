Thu Sep 29 22:21:25 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.21, 0.26, 0.24, 0.21, 0.08], 'classWeightsFlag': True, 'dataConfig': {'bulkPickles': True, 'dataCount': 5, 'loadData2memory': True, 'multiplyData': False, 'tossFirstLastFrames': True, 'doubleClasses': [1, 2]}, 'dataPath': '/data/processed/Kinetics/', 'epochNo': 200, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 5, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 22, 'validationAccThr': 60, 'weightDecay': 0.001}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Tossed a data with insufficient frame number.
I - Tossed a data with insufficient frame number.
I - Number of frames greater than dataset description, tossed data with #frames =  964
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  5815
I - Label distribution: [ 692.  668.  974.  718. 2763.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Tossed a data with insufficient frame number.
I - Test set length:  1392
I - Label distribution: [199. 268. 290. 204. 431.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([1352,  816,  864, 1608, 1155,  953, 3752, 5428,  444, 3267, 4268, 3959,
         496, 2253,  951, 5105])
I - Initializing model TCNv5
I - Number of Model Parameters: 529216
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv5                                    [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-61                        [16, 64, 32, 32]          --
│    └─Empty: 2-62                       [16, 64, 32, 32]          --
│    └─Clamp: 2-63                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-64          --                        --
│    └─One: 2-65                         [1]                       --
│    └─OutputScale: 2-66                 --                        --
│    └─Empty: 2-67                       [64, 64, 3, 3]            --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64]                      --
│    └─Empty: 2-70                       [64]                      --
│    └─BatchNorm2d: 2-71                 [16, 64, 32, 32]          --
│    └─Scaler: 2-72                      [16, 64, 32, 32]          --
│    └─ReLU: 2-73                        [16, 64, 32, 32]          --
│    └─Empty: 2-74                       [16, 64, 32, 32]          --
│    └─Clamp: 2-75                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-76                   [16, 64, 16, 16]          --
│    └─Empty: 2-77                       [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-79          --                        --
│    └─One: 2-80                         [1]                       --
│    └─OutputScale: 2-81                 --                        --
│    └─Empty: 2-82                       [64, 64, 3, 3]            --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64]                      --
│    └─Empty: 2-85                       [64]                      --
│    └─BatchNorm2d: 2-86                 [16, 64, 16, 16]          --
│    └─Scaler: 2-87                      [16, 64, 16, 16]          --
│    └─ReLU: 2-88                        [16, 64, 16, 16]          --
│    └─Empty: 2-89                       [16, 64, 16, 16]          --
│    └─Clamp: 2-90                       [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-91          --                        --
│    └─One: 2-92                         [1]                       --
│    └─OutputScale: 2-93                 --                        --
│    └─Empty: 2-94                       [64, 64, 3, 3]            --
│    └─Empty: 2-95                       [64, 64, 3, 3]            --
│    └─Empty: 2-96                       [64]                      --
│    └─Empty: 2-97                       [64]                      --
│    └─BatchNorm2d: 2-98                 [16, 64, 16, 16]          --
│    └─Scaler: 2-99                      [16, 64, 16, 16]          --
│    └─ReLU: 2-100                       [16, 64, 16, 16]          --
│    └─Empty: 2-101                      [16, 64, 16, 16]          --
│    └─Clamp: 2-102                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-103                  [16, 64, 8, 8]            --
│    └─Empty: 2-104                      [16, 64, 8, 8]            --
│    └─Empty: 2-105                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-106         --                        --
│    └─One: 2-107                        [1]                       --
│    └─OutputScale: 2-108                --                        --
│    └─Empty: 2-109                      [64, 64, 3, 3]            --
│    └─Empty: 2-110                      [64, 64, 3, 3]            --
│    └─Empty: 2-111                      [64]                      --
│    └─Empty: 2-112                      [64]                      --
│    └─BatchNorm2d: 2-113                [16, 64, 8, 8]            --
│    └─Scaler: 2-114                     [16, 64, 8, 8]            --
│    └─ReLU: 2-115                       [16, 64, 8, 8]            --
│    └─Empty: 2-116                      [16, 64, 8, 8]            --
│    └─Clamp: 2-117                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-118         --                        --
│    └─One: 2-119                        [1]                       --
│    └─OutputScale: 2-120                --                        --
│    └─Empty: 2-121                      [64, 64, 1, 1]            --
│    └─Empty: 2-122                      [64, 64, 1, 1]            --
│    └─Empty: 2-123                      [64]                      --
│    └─Empty: 2-124                      [64]                      --
│    └─BatchNorm2d: 2-125                [16, 64, 8, 8]            --
│    └─Scaler: 2-126                     [16, 64, 8, 8]            --
│    └─ReLU: 2-127                       [16, 64, 8, 8]            --
│    └─Empty: 2-128                      [16, 64, 8, 8]            --
│    └─Clamp: 2-129                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-130                  [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Empty: 2-132                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-133         --                        --
│    └─One: 2-134                        [1]                       --
│    └─OutputScale: 2-135                --                        --
│    └─Empty: 2-136                      [64, 64, 3, 3]            --
│    └─Empty: 2-137                      [64, 64, 3, 3]            --
│    └─Empty: 2-138                      [64]                      --
│    └─Empty: 2-139                      [64]                      --
│    └─BatchNorm2d: 2-140                [16, 64, 8, 8]            --
│    └─Scaler: 2-141                     [16, 64, 8, 8]            --
│    └─ReLU: 2-142                       [16, 64, 8, 8]            --
│    └─Empty: 2-143                      [16, 64, 8, 8]            --
│    └─Clamp: 2-144                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-145                  [16, 64, 4, 4]            --
│    └─Empty: 2-146                      [16, 64, 4, 4]            --
│    └─Empty: 2-147                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-148         --                        --
│    └─One: 2-149                        [1]                       --
│    └─OutputScale: 2-150                --                        --
│    └─Empty: 2-151                      [64, 64, 3, 3]            --
│    └─Empty: 2-152                      [64, 64, 3, 3]            --
│    └─Empty: 2-153                      [64]                      --
│    └─Empty: 2-154                      [64]                      --
│    └─BatchNorm2d: 2-155                [16, 64, 4, 4]            --
│    └─Scaler: 2-156                     [16, 64, 4, 4]            --
│    └─ReLU: 2-157                       [16, 64, 4, 4]            --
│    └─Empty: 2-158                      [16, 64, 4, 4]            --
│    └─Clamp: 2-159                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-160         --                        --
│    └─One: 2-161                        [1]                       --
│    └─OutputScale: 2-162                --                        --
│    └─Empty: 2-163                      [64, 64, 1, 1]            --
│    └─Empty: 2-164                      [64, 64, 1, 1]            --
│    └─Empty: 2-165                      [64]                      --
│    └─Empty: 2-166                      [64]                      --
│    └─BatchNorm2d: 2-167                [16, 64, 4, 4]            --
│    └─Scaler: 2-168                     [16, 64, 4, 4]            --
│    └─ReLU: 2-169                       [16, 64, 4, 4]            --
│    └─Empty: 2-170                      [16, 64, 4, 4]            --
│    └─Clamp: 2-171                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-172                  [16, 64, 4, 4]            --
│    └─Empty: 2-173                      [16, 64, 4, 4]            --
│    └─Empty: 2-174                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-175         --                        --
│    └─One: 2-176                        [1]                       --
│    └─OutputScale: 2-177                --                        --
│    └─Empty: 2-178                      [64, 64, 3, 3]            --
│    └─Empty: 2-179                      [64, 64, 3, 3]            --
│    └─Empty: 2-180                      [64]                      --
│    └─Empty: 2-181                      [64]                      --
│    └─BatchNorm2d: 2-182                [16, 64, 4, 4]            --
│    └─Scaler: 2-183                     [16, 64, 4, 4]            --
│    └─ReLU: 2-184                       [16, 64, 4, 4]            --
│    └─Empty: 2-185                      [16, 64, 4, 4]            --
│    └─Clamp: 2-186                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-187                  [16, 64, 2, 2]            --
│    └─Empty: 2-188                      [16, 64, 2, 2]            --
│    └─Empty: 2-189                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-190         --                        --
│    └─One: 2-191                        [1]                       --
│    └─OutputScale: 2-192                --                        --
│    └─Empty: 2-193                      [64, 64, 1, 1]            --
│    └─Empty: 2-194                      [64, 64, 1, 1]            --
│    └─Empty: 2-195                      [64]                      --
│    └─Empty: 2-196                      [64]                      --
│    └─BatchNorm2d: 2-197                [16, 64, 2, 2]            --
│    └─Scaler: 2-198                     [16, 64, 2, 2]            --
│    └─ReLU: 2-199                       [16, 64, 2, 2]            --
│    └─Empty: 2-200                      [16, 64, 2, 2]            --
│    └─Clamp: 2-201                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-202         --                        --
│    └─One: 2-203                        [1]                       --
│    └─OutputScale: 2-204                --                        --
│    └─Empty: 2-205                      [64, 64, 1, 1]            --
│    └─Empty: 2-206                      [64, 64, 1, 1]            --
│    └─Empty: 2-207                      [64]                      --
│    └─Empty: 2-208                      [64]                      --
│    └─BatchNorm2d: 2-209                [16, 64, 2, 2]            --
│    └─Scaler: 2-210                     [16, 64, 2, 2]            --
│    └─ReLU: 2-211                       [16, 64, 2, 2]            --
│    └─Empty: 2-212                      [16, 64, 2, 2]            --
│    └─Clamp: 2-213                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-214                  [16, 64, 2, 2]            --
│    └─Empty: 2-215                      [16, 64, 2, 2]            --
│    └─Empty: 2-216                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-217         --                        --
│    └─One: 2-218                        [1]                       --
│    └─OutputScale: 2-219                --                        --
│    └─Empty: 2-220                      [64, 64, 3, 3]            --
│    └─Empty: 2-221                      [64, 64, 3, 3]            --
│    └─Empty: 2-222                      [64]                      --
│    └─Empty: 2-223                      [64]                      --
│    └─BatchNorm2d: 2-224                [16, 64, 2, 2]            --
│    └─Scaler: 2-225                     [16, 64, 2, 2]            --
│    └─ReLU: 2-226                       [16, 64, 2, 2]            --
│    └─Empty: 2-227                      [16, 64, 2, 2]            --
│    └─Clamp: 2-228                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-229         --                        --
│    └─One: 2-230                        [1]                       --
│    └─OutputScale: 2-231                --                        --
│    └─Empty: 2-232                      [64, 48, 1, 1]            --
│    └─Empty: 2-233                      [64, 48, 1, 1]            --
│    └─Empty: 2-234                      [64]                      --
│    └─Empty: 2-235                      [64]                      --
│    └─BatchNorm2d: 2-236                [16, 64, 64, 64]          --
│    └─Scaler: 2-237                     [16, 64, 64, 64]          --
│    └─ReLU: 2-238                       [16, 64, 64, 64]          --
│    └─Empty: 2-239                      [16, 64, 64, 64]          --
│    └─Clamp: 2-240                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-241         --                        --
│    └─One: 2-242                        [1]                       --
│    └─OutputScale: 2-243                --                        --
│    └─Empty: 2-244                      [64, 64, 3, 3]            --
│    └─Empty: 2-245                      [64, 64, 3, 3]            --
│    └─Empty: 2-246                      [64]                      --
│    └─Empty: 2-247                      [64]                      --
│    └─BatchNorm2d: 2-248                [16, 64, 64, 64]          --
│    └─Scaler: 2-249                     [16, 64, 64, 64]          --
│    └─ReLU: 2-250                       [16, 64, 64, 64]          --
│    └─Empty: 2-251                      [16, 64, 64, 64]          --
│    └─Clamp: 2-252                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-253         --                        --
│    └─One: 2-254                        [1]                       --
│    └─OutputScale: 2-255                --                        --
│    └─Empty: 2-256                      [64, 64, 1, 1]            --
│    └─Empty: 2-257                      [64, 64, 1, 1]            --
│    └─Empty: 2-258                      [64]                      --
│    └─Empty: 2-259                      [64]                      --
│    └─BatchNorm2d: 2-260                [16, 64, 64, 64]          --
│    └─Scaler: 2-261                     [16, 64, 64, 64]          --
│    └─ReLU: 2-262                       [16, 64, 64, 64]          --
│    └─Empty: 2-263                      [16, 64, 64, 64]          --
│    └─Clamp: 2-264                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-265         --                        --
│    └─One: 2-266                        [1]                       --
│    └─OutputScale: 2-267                --                        --
│    └─Empty: 2-268                      [64, 64, 3, 3]            --
│    └─Empty: 2-269                      [64, 64, 3, 3]            --
│    └─Empty: 2-270                      [64]                      --
│    └─Empty: 2-271                      [64]                      --
│    └─BatchNorm2d: 2-272                [16, 64, 64, 64]          --
│    └─Scaler: 2-273                     [16, 64, 64, 64]          --
│    └─ReLU: 2-274                       [16, 64, 64, 64]          --
│    └─Empty: 2-275                      [16, 64, 64, 64]          --
│    └─Clamp: 2-276                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-277                  [16, 64, 32, 32]          --
│    └─Empty: 2-278                      [16, 64, 32, 32]          --
│    └─Empty: 2-279                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-280         --                        --
│    └─One: 2-281                        [1]                       --
│    └─OutputScale: 2-282                --                        --
│    └─Empty: 2-283                      [64, 64, 3, 3]            --
│    └─Empty: 2-284                      [64, 64, 3, 3]            --
│    └─Empty: 2-285                      [64]                      --
│    └─Empty: 2-286                      [64]                      --
│    └─BatchNorm2d: 2-287                [16, 64, 32, 32]          --
│    └─Scaler: 2-288                     [16, 64, 32, 32]          --
│    └─ReLU: 2-289                       [16, 64, 32, 32]          --
│    └─Empty: 2-290                      [16, 64, 32, 32]          --
│    └─Clamp: 2-291                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-292         --                        --
│    └─One: 2-293                        [1]                       --
│    └─OutputScale: 2-294                --                        --
│    └─Empty: 2-295                      [64, 64, 3, 3]            --
│    └─Empty: 2-296                      [64, 64, 3, 3]            --
│    └─Empty: 2-297                      [64]                      --
│    └─Empty: 2-298                      [64]                      --
│    └─BatchNorm2d: 2-299                [16, 64, 32, 32]          --
│    └─Scaler: 2-300                     [16, 64, 32, 32]          --
│    └─ReLU: 2-301                       [16, 64, 32, 32]          --
│    └─Empty: 2-302                      [16, 64, 32, 32]          --
│    └─Clamp: 2-303                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-304                  [16, 64, 16, 16]          --
│    └─Empty: 2-305                      [16, 64, 16, 16]          --
│    └─Empty: 2-306                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-307         --                        --
│    └─One: 2-308                        [1]                       --
│    └─OutputScale: 2-309                --                        --
│    └─Empty: 2-310                      [64, 64, 3, 3]            --
│    └─Empty: 2-311                      [64, 64, 3, 3]            --
│    └─Empty: 2-312                      [64]                      --
│    └─Empty: 2-313                      [64]                      --
│    └─BatchNorm2d: 2-314                [16, 64, 16, 16]          --
│    └─Scaler: 2-315                     [16, 64, 16, 16]          --
│    └─ReLU: 2-316                       [16, 64, 16, 16]          --
│    └─Empty: 2-317                      [16, 64, 16, 16]          --
│    └─Clamp: 2-318                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-319         --                        --
│    └─One: 2-320                        [1]                       --
│    └─OutputScale: 2-321                --                        --
│    └─Empty: 2-322                      [64, 64, 3, 3]            --
│    └─Empty: 2-323                      [64, 64, 3, 3]            --
│    └─Empty: 2-324                      [64]                      --
│    └─Empty: 2-325                      [64]                      --
│    └─BatchNorm2d: 2-326                [16, 64, 16, 16]          --
│    └─Scaler: 2-327                     [16, 64, 16, 16]          --
│    └─ReLU: 2-328                       [16, 64, 16, 16]          --
│    └─Empty: 2-329                      [16, 64, 16, 16]          --
│    └─Clamp: 2-330                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-331                  [16, 64, 8, 8]            --
│    └─Empty: 2-332                      [16, 64, 8, 8]            --
│    └─Empty: 2-333                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-334         --                        --
│    └─One: 2-335                        [1]                       --
│    └─OutputScale: 2-336                --                        --
│    └─Empty: 2-337                      [64, 64, 3, 3]            --
│    └─Empty: 2-338                      [64, 64, 3, 3]            --
│    └─Empty: 2-339                      [64]                      --
│    └─Empty: 2-340                      [64]                      --
│    └─BatchNorm2d: 2-341                [16, 64, 8, 8]            --
│    └─Scaler: 2-342                     [16, 64, 8, 8]            --
│    └─ReLU: 2-343                       [16, 64, 8, 8]            --
│    └─Empty: 2-344                      [16, 64, 8, 8]            --
│    └─Clamp: 2-345                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-346         --                        --
│    └─One: 2-347                        [1]                       --
│    └─OutputScale: 2-348                --                        --
│    └─Empty: 2-349                      [64, 64, 1, 1]            --
│    └─Empty: 2-350                      [64, 64, 1, 1]            --
│    └─Empty: 2-351                      [64]                      --
│    └─Empty: 2-352                      [64]                      --
│    └─BatchNorm2d: 2-353                [16, 64, 8, 8]            --
│    └─Scaler: 2-354                     [16, 64, 8, 8]            --
│    └─ReLU: 2-355                       [16, 64, 8, 8]            --
│    └─Empty: 2-356                      [16, 64, 8, 8]            --
│    └─Clamp: 2-357                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-358                  [16, 64, 8, 8]            --
│    └─Empty: 2-359                      [16, 64, 8, 8]            --
│    └─Empty: 2-360                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-361         --                        --
│    └─One: 2-362                        [1]                       --
│    └─OutputScale: 2-363                --                        --
│    └─Empty: 2-364                      [64, 64, 3, 3]            --
│    └─Empty: 2-365                      [64, 64, 3, 3]            --
│    └─Empty: 2-366                      [64]                      --
│    └─Empty: 2-367                      [64]                      --
│    └─BatchNorm2d: 2-368                [16, 64, 8, 8]            --
│    └─Scaler: 2-369                     [16, 64, 8, 8]            --
│    └─ReLU: 2-370                       [16, 64, 8, 8]            --
│    └─Empty: 2-371                      [16, 64, 8, 8]            --
│    └─Clamp: 2-372                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-373                  [16, 64, 4, 4]            --
│    └─Empty: 2-374                      [16, 64, 4, 4]            --
│    └─Empty: 2-375                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-376         --                        --
│    └─One: 2-377                        [1]                       --
│    └─OutputScale: 2-378                --                        --
│    └─Empty: 2-379                      [64, 64, 3, 3]            --
│    └─Empty: 2-380                      [64, 64, 3, 3]            --
│    └─Empty: 2-381                      [64]                      --
│    └─Empty: 2-382                      [64]                      --
│    └─BatchNorm2d: 2-383                [16, 64, 4, 4]            --
│    └─Scaler: 2-384                     [16, 64, 4, 4]            --
│    └─ReLU: 2-385                       [16, 64, 4, 4]            --
│    └─Empty: 2-386                      [16, 64, 4, 4]            --
│    └─Clamp: 2-387                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-388         --                        --
│    └─One: 2-389                        [1]                       --
│    └─OutputScale: 2-390                --                        --
│    └─Empty: 2-391                      [64, 64, 1, 1]            --
│    └─Empty: 2-392                      [64, 64, 1, 1]            --
│    └─Empty: 2-393                      [64]                      --
│    └─Empty: 2-394                      [64]                      --
│    └─BatchNorm2d: 2-395                [16, 64, 4, 4]            --
│    └─Scaler: 2-396                     [16, 64, 4, 4]            --
│    └─ReLU: 2-397                       [16, 64, 4, 4]            --
│    └─Empty: 2-398                      [16, 64, 4, 4]            --
│    └─Clamp: 2-399                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-400                  [16, 64, 4, 4]            --
│    └─Empty: 2-401                      [16, 64, 4, 4]            --
│    └─Empty: 2-402                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-403         --                        --
│    └─One: 2-404                        [1]                       --
│    └─OutputScale: 2-405                --                        --
│    └─Empty: 2-406                      [64, 64, 3, 3]            --
│    └─Empty: 2-407                      [64, 64, 3, 3]            --
│    └─Empty: 2-408                      [64]                      --
│    └─Empty: 2-409                      [64]                      --
│    └─BatchNorm2d: 2-410                [16, 64, 4, 4]            --
│    └─Scaler: 2-411                     [16, 64, 4, 4]            --
│    └─ReLU: 2-412                       [16, 64, 4, 4]            --
│    └─Empty: 2-413                      [16, 64, 4, 4]            --
│    └─Clamp: 2-414                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-415                  [16, 64, 2, 2]            --
│    └─Empty: 2-416                      [16, 64, 2, 2]            --
│    └─Empty: 2-417                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-418         --                        --
│    └─One: 2-419                        [1]                       --
│    └─OutputScale: 2-420                --                        --
│    └─Empty: 2-421                      [64, 64, 1, 1]            --
│    └─Empty: 2-422                      [64, 64, 1, 1]            --
│    └─Empty: 2-423                      [64]                      --
│    └─Empty: 2-424                      [64]                      --
│    └─BatchNorm2d: 2-425                [16, 64, 2, 2]            --
│    └─Scaler: 2-426                     [16, 64, 2, 2]            --
│    └─ReLU: 2-427                       [16, 64, 2, 2]            --
│    └─Empty: 2-428                      [16, 64, 2, 2]            --
│    └─Clamp: 2-429                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-430         --                        --
│    └─One: 2-431                        [1]                       --
│    └─OutputScale: 2-432                --                        --
│    └─Empty: 2-433                      [64, 64, 1, 1]            --
│    └─Empty: 2-434                      [64, 64, 1, 1]            --
│    └─Empty: 2-435                      [64]                      --
│    └─Empty: 2-436                      [64]                      --
│    └─BatchNorm2d: 2-437                [16, 64, 2, 2]            --
│    └─Scaler: 2-438                     [16, 64, 2, 2]            --
│    └─ReLU: 2-439                       [16, 64, 2, 2]            --
│    └─Empty: 2-440                      [16, 64, 2, 2]            --
│    └─Clamp: 2-441                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-442                  [16, 64, 2, 2]            --
│    └─Empty: 2-443                      [16, 64, 2, 2]            --
│    └─Empty: 2-444                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-445         --                        --
│    └─One: 2-446                        [1]                       --
│    └─OutputScale: 2-447                --                        --
│    └─Empty: 2-448                      [64, 64, 3, 3]            --
│    └─Empty: 2-449                      [64, 64, 3, 3]            --
│    └─Empty: 2-450                      [64]                      --
│    └─Empty: 2-451                      [64]                      --
│    └─BatchNorm2d: 2-452                [16, 64, 2, 2]            --
│    └─Scaler: 2-453                     [16, 64, 2, 2]            --
│    └─ReLU: 2-454                       [16, 64, 2, 2]            --
│    └─Empty: 2-455                      [16, 64, 2, 2]            --
│    └─Clamp: 2-456                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-457         --                        --
│    └─One: 2-458                        [1]                       --
│    └─OutputScale: 2-459                --                        --
│    └─Empty: 2-460                      [64, 48, 1, 1]            --
│    └─Empty: 2-461                      [64, 48, 1, 1]            --
│    └─Empty: 2-462                      [64]                      --
│    └─Empty: 2-463                      [64]                      --
│    └─BatchNorm2d: 2-464                [16, 64, 64, 64]          --
│    └─Scaler: 2-465                     [16, 64, 64, 64]          --
│    └─ReLU: 2-466                       [16, 64, 64, 64]          --
│    └─Empty: 2-467                      [16, 64, 64, 64]          --
│    └─Clamp: 2-468                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-469         --                        --
│    └─One: 2-470                        [1]                       --
│    └─OutputScale: 2-471                --                        --
│    └─Empty: 2-472                      [64, 64, 3, 3]            --
│    └─Empty: 2-473                      [64, 64, 3, 3]            --
│    └─Empty: 2-474                      [64]                      --
│    └─Empty: 2-475                      [64]                      --
│    └─BatchNorm2d: 2-476                [16, 64, 64, 64]          --
│    └─Scaler: 2-477                     [16, 64, 64, 64]          --
│    └─ReLU: 2-478                       [16, 64, 64, 64]          --
│    └─Empty: 2-479                      [16, 64, 64, 64]          --
│    └─Clamp: 2-480                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-481         --                        --
│    └─One: 2-482                        [1]                       --
│    └─OutputScale: 2-483                --                        --
│    └─Empty: 2-484                      [64, 64, 1, 1]            --
│    └─Empty: 2-485                      [64, 64, 1, 1]            --
│    └─Empty: 2-486                      [64]                      --
│    └─Empty: 2-487                      [64]                      --
│    └─BatchNorm2d: 2-488                [16, 64, 64, 64]          --
│    └─Scaler: 2-489                     [16, 64, 64, 64]          --
│    └─ReLU: 2-490                       [16, 64, 64, 64]          --
│    └─Empty: 2-491                      [16, 64, 64, 64]          --
│    └─Clamp: 2-492                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-493         --                        --
│    └─One: 2-494                        [1]                       --
│    └─OutputScale: 2-495                --                        --
│    └─Empty: 2-496                      [64, 64, 3, 3]            --
│    └─Empty: 2-497                      [64, 64, 3, 3]            --
│    └─Empty: 2-498                      [64]                      --
│    └─Empty: 2-499                      [64]                      --
│    └─BatchNorm2d: 2-500                [16, 64, 64, 64]          --
│    └─Scaler: 2-501                     [16, 64, 64, 64]          --
│    └─ReLU: 2-502                       [16, 64, 64, 64]          --
│    └─Empty: 2-503                      [16, 64, 64, 64]          --
│    └─Clamp: 2-504                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-505                  [16, 64, 32, 32]          --
│    └─Empty: 2-506                      [16, 64, 32, 32]          --
│    └─Empty: 2-507                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-508         --                        --
│    └─One: 2-509                        [1]                       --
│    └─OutputScale: 2-510                --                        --
│    └─Empty: 2-511                      [64, 64, 3, 3]            --
│    └─Empty: 2-512                      [64, 64, 3, 3]            --
│    └─Empty: 2-513                      [64]                      --
│    └─Empty: 2-514                      [64]                      --
│    └─BatchNorm2d: 2-515                [16, 64, 32, 32]          --
│    └─Scaler: 2-516                     [16, 64, 32, 32]          --
│    └─ReLU: 2-517                       [16, 64, 32, 32]          --
│    └─Empty: 2-518                      [16, 64, 32, 32]          --
│    └─Clamp: 2-519                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-520         --                        --
│    └─One: 2-521                        [1]                       --
│    └─OutputScale: 2-522                --                        --
│    └─Empty: 2-523                      [64, 64, 3, 3]            --
│    └─Empty: 2-524                      [64, 64, 3, 3]            --
│    └─Empty: 2-525                      [64]                      --
│    └─Empty: 2-526                      [64]                      --
│    └─BatchNorm2d: 2-527                [16, 64, 32, 32]          --
│    └─Scaler: 2-528                     [16, 64, 32, 32]          --
│    └─ReLU: 2-529                       [16, 64, 32, 32]          --
│    └─Empty: 2-530                      [16, 64, 32, 32]          --
│    └─Clamp: 2-531                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-532                  [16, 64, 16, 16]          --
│    └─Empty: 2-533                      [16, 64, 16, 16]          --
│    └─Empty: 2-534                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-535         --                        --
│    └─One: 2-536                        [1]                       --
│    └─OutputScale: 2-537                --                        --
│    └─Empty: 2-538                      [64, 64, 3, 3]            --
│    └─Empty: 2-539                      [64, 64, 3, 3]            --
│    └─Empty: 2-540                      [64]                      --
│    └─Empty: 2-541                      [64]                      --
│    └─BatchNorm2d: 2-542                [16, 64, 16, 16]          --
│    └─Scaler: 2-543                     [16, 64, 16, 16]          --
│    └─ReLU: 2-544                       [16, 64, 16, 16]          --
│    └─Empty: 2-545                      [16, 64, 16, 16]          --
│    └─Clamp: 2-546                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-547         --                        --
│    └─One: 2-548                        [1]                       --
│    └─OutputScale: 2-549                --                        --
│    └─Empty: 2-550                      [64, 64, 3, 3]            --
│    └─Empty: 2-551                      [64, 64, 3, 3]            --
│    └─Empty: 2-552                      [64]                      --
│    └─Empty: 2-553                      [64]                      --
│    └─BatchNorm2d: 2-554                [16, 64, 16, 16]          --
│    └─Scaler: 2-555                     [16, 64, 16, 16]          --
│    └─ReLU: 2-556                       [16, 64, 16, 16]          --
│    └─Empty: 2-557                      [16, 64, 16, 16]          --
│    └─Clamp: 2-558                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-559                  [16, 64, 8, 8]            --
│    └─Empty: 2-560                      [16, 64, 8, 8]            --
│    └─Empty: 2-561                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-562         --                        --
│    └─One: 2-563                        [1]                       --
│    └─OutputScale: 2-564                --                        --
│    └─Empty: 2-565                      [64, 64, 3, 3]            --
│    └─Empty: 2-566                      [64, 64, 3, 3]            --
│    └─Empty: 2-567                      [64]                      --
│    └─Empty: 2-568                      [64]                      --
│    └─BatchNorm2d: 2-569                [16, 64, 8, 8]            --
│    └─Scaler: 2-570                     [16, 64, 8, 8]            --
│    └─ReLU: 2-571                       [16, 64, 8, 8]            --
│    └─Empty: 2-572                      [16, 64, 8, 8]            --
│    └─Clamp: 2-573                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-574         --                        --
│    └─One: 2-575                        [1]                       --
│    └─OutputScale: 2-576                --                        --
│    └─Empty: 2-577                      [64, 64, 1, 1]            --
│    └─Empty: 2-578                      [64, 64, 1, 1]            --
│    └─Empty: 2-579                      [64]                      --
│    └─Empty: 2-580                      [64]                      --
│    └─BatchNorm2d: 2-581                [16, 64, 8, 8]            --
│    └─Scaler: 2-582                     [16, 64, 8, 8]            --
│    └─ReLU: 2-583                       [16, 64, 8, 8]            --
│    └─Empty: 2-584                      [16, 64, 8, 8]            --
│    └─Clamp: 2-585                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-586                  [16, 64, 8, 8]            --
│    └─Empty: 2-587                      [16, 64, 8, 8]            --
│    └─Empty: 2-588                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-589         --                        --
│    └─One: 2-590                        [1]                       --
│    └─OutputScale: 2-591                --                        --
│    └─Empty: 2-592                      [64, 64, 3, 3]            --
│    └─Empty: 2-593                      [64, 64, 3, 3]            --
│    └─Empty: 2-594                      [64]                      --
│    └─Empty: 2-595                      [64]                      --
│    └─BatchNorm2d: 2-596                [16, 64, 8, 8]            --
│    └─Scaler: 2-597                     [16, 64, 8, 8]            --
│    └─ReLU: 2-598                       [16, 64, 8, 8]            --
│    └─Empty: 2-599                      [16, 64, 8, 8]            --
│    └─Clamp: 2-600                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-601                  [16, 64, 4, 4]            --
│    └─Empty: 2-602                      [16, 64, 4, 4]            --
│    └─Empty: 2-603                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-604         --                        --
│    └─One: 2-605                        [1]                       --
│    └─OutputScale: 2-606                --                        --
│    └─Empty: 2-607                      [64, 64, 3, 3]            --
│    └─Empty: 2-608                      [64, 64, 3, 3]            --
│    └─Empty: 2-609                      [64]                      --
│    └─Empty: 2-610                      [64]                      --
│    └─BatchNorm2d: 2-611                [16, 64, 4, 4]            --
│    └─Scaler: 2-612                     [16, 64, 4, 4]            --
│    └─ReLU: 2-613                       [16, 64, 4, 4]            --
│    └─Empty: 2-614                      [16, 64, 4, 4]            --
│    └─Clamp: 2-615                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-616         --                        --
│    └─One: 2-617                        [1]                       --
│    └─OutputScale: 2-618                --                        --
│    └─Empty: 2-619                      [64, 64, 1, 1]            --
│    └─Empty: 2-620                      [64, 64, 1, 1]            --
│    └─Empty: 2-621                      [64]                      --
│    └─Empty: 2-622                      [64]                      --
│    └─BatchNorm2d: 2-623                [16, 64, 4, 4]            --
│    └─Scaler: 2-624                     [16, 64, 4, 4]            --
│    └─ReLU: 2-625                       [16, 64, 4, 4]            --
│    └─Empty: 2-626                      [16, 64, 4, 4]            --
│    └─Clamp: 2-627                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-628                  [16, 64, 4, 4]            --
│    └─Empty: 2-629                      [16, 64, 4, 4]            --
│    └─Empty: 2-630                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-631         --                        --
│    └─One: 2-632                        [1]                       --
│    └─OutputScale: 2-633                --                        --
│    └─Empty: 2-634                      [64, 64, 3, 3]            --
│    └─Empty: 2-635                      [64, 64, 3, 3]            --
│    └─Empty: 2-636                      [64]                      --
│    └─Empty: 2-637                      [64]                      --
│    └─BatchNorm2d: 2-638                [16, 64, 4, 4]            --
│    └─Scaler: 2-639                     [16, 64, 4, 4]            --
│    └─ReLU: 2-640                       [16, 64, 4, 4]            --
│    └─Empty: 2-641                      [16, 64, 4, 4]            --
│    └─Clamp: 2-642                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-643                  [16, 64, 2, 2]            --
│    └─Empty: 2-644                      [16, 64, 2, 2]            --
│    └─Empty: 2-645                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-646         --                        --
│    └─One: 2-647                        [1]                       --
│    └─OutputScale: 2-648                --                        --
│    └─Empty: 2-649                      [64, 64, 1, 1]            --
│    └─Empty: 2-650                      [64, 64, 1, 1]            --
│    └─Empty: 2-651                      [64]                      --
│    └─Empty: 2-652                      [64]                      --
│    └─BatchNorm2d: 2-653                [16, 64, 2, 2]            --
│    └─Scaler: 2-654                     [16, 64, 2, 2]            --
│    └─ReLU: 2-655                       [16, 64, 2, 2]            --
│    └─Empty: 2-656                      [16, 64, 2, 2]            --
│    └─Clamp: 2-657                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-658         --                        --
│    └─One: 2-659                        [1]                       --
│    └─OutputScale: 2-660                --                        --
│    └─Empty: 2-661                      [64, 64, 1, 1]            --
│    └─Empty: 2-662                      [64, 64, 1, 1]            --
│    └─Empty: 2-663                      [64]                      --
│    └─Empty: 2-664                      [64]                      --
│    └─BatchNorm2d: 2-665                [16, 64, 2, 2]            --
│    └─Scaler: 2-666                     [16, 64, 2, 2]            --
│    └─ReLU: 2-667                       [16, 64, 2, 2]            --
│    └─Empty: 2-668                      [16, 64, 2, 2]            --
│    └─Clamp: 2-669                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-670                  [16, 64, 2, 2]            --
│    └─Empty: 2-671                      [16, 64, 2, 2]            --
│    └─Empty: 2-672                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-673         --                        --
│    └─One: 2-674                        [1]                       --
│    └─OutputScale: 2-675                --                        --
│    └─Empty: 2-676                      [64, 64, 3, 3]            --
│    └─Empty: 2-677                      [64, 64, 3, 3]            --
│    └─Empty: 2-678                      [64]                      --
│    └─Empty: 2-679                      [64]                      --
│    └─BatchNorm2d: 2-680                [16, 64, 2, 2]            --
│    └─Scaler: 2-681                     [16, 64, 2, 2]            --
│    └─ReLU: 2-682                       [16, 64, 2, 2]            --
│    └─Empty: 2-683                      [16, 64, 2, 2]            --
│    └─Clamp: 2-684                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-685         --                        --
│    └─One: 2-686                        [1]                       --
│    └─OutputScale: 2-687                --                        --
│    └─Empty: 2-688                      [64, 48, 1, 1]            --
│    └─Empty: 2-689                      [64, 48, 1, 1]            --
│    └─Empty: 2-690                      [64]                      --
│    └─Empty: 2-691                      [64]                      --
│    └─BatchNorm2d: 2-692                [16, 64, 64, 64]          --
│    └─Scaler: 2-693                     [16, 64, 64, 64]          --
│    └─ReLU: 2-694                       [16, 64, 64, 64]          --
│    └─Empty: 2-695                      [16, 64, 64, 64]          --
│    └─Clamp: 2-696                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-697         --                        --
│    └─One: 2-698                        [1]                       --
│    └─OutputScale: 2-699                --                        --
│    └─Empty: 2-700                      [64, 64, 3, 3]            --
│    └─Empty: 2-701                      [64, 64, 3, 3]            --
│    └─Empty: 2-702                      [64]                      --
│    └─Empty: 2-703                      [64]                      --
│    └─BatchNorm2d: 2-704                [16, 64, 64, 64]          --
│    └─Scaler: 2-705                     [16, 64, 64, 64]          --
│    └─ReLU: 2-706                       [16, 64, 64, 64]          --
│    └─Empty: 2-707                      [16, 64, 64, 64]          --
│    └─Clamp: 2-708                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-709         --                        --
│    └─One: 2-710                        [1]                       --
│    └─OutputScale: 2-711                --                        --
│    └─Empty: 2-712                      [64, 64, 1, 1]            --
│    └─Empty: 2-713                      [64, 64, 1, 1]            --
│    └─Empty: 2-714                      [64]                      --
│    └─Empty: 2-715                      [64]                      --
│    └─BatchNorm2d: 2-716                [16, 64, 64, 64]          --
│    └─Scaler: 2-717                     [16, 64, 64, 64]          --
│    └─ReLU: 2-718                       [16, 64, 64, 64]          --
│    └─Empty: 2-719                      [16, 64, 64, 64]          --
│    └─Clamp: 2-720                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-721         --                        --
│    └─One: 2-722                        [1]                       --
│    └─OutputScale: 2-723                --                        --
│    └─Empty: 2-724                      [64, 64, 3, 3]            --
│    └─Empty: 2-725                      [64, 64, 3, 3]            --
│    └─Empty: 2-726                      [64]                      --
│    └─Empty: 2-727                      [64]                      --
│    └─BatchNorm2d: 2-728                [16, 64, 64, 64]          --
│    └─Scaler: 2-729                     [16, 64, 64, 64]          --
│    └─ReLU: 2-730                       [16, 64, 64, 64]          --
│    └─Empty: 2-731                      [16, 64, 64, 64]          --
│    └─Clamp: 2-732                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-733                  [16, 64, 32, 32]          --
│    └─Empty: 2-734                      [16, 64, 32, 32]          --
│    └─Empty: 2-735                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-736         --                        --
│    └─One: 2-737                        [1]                       --
│    └─OutputScale: 2-738                --                        --
│    └─Empty: 2-739                      [64, 64, 3, 3]            --
│    └─Empty: 2-740                      [64, 64, 3, 3]            --
│    └─Empty: 2-741                      [64]                      --
│    └─Empty: 2-742                      [64]                      --
│    └─BatchNorm2d: 2-743                [16, 64, 32, 32]          --
│    └─Scaler: 2-744                     [16, 64, 32, 32]          --
│    └─ReLU: 2-745                       [16, 64, 32, 32]          --
│    └─Empty: 2-746                      [16, 64, 32, 32]          --
│    └─Clamp: 2-747                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-748         --                        --
│    └─One: 2-749                        [1]                       --
│    └─OutputScale: 2-750                --                        --
│    └─Empty: 2-751                      [64, 64, 3, 3]            --
│    └─Empty: 2-752                      [64, 64, 3, 3]            --
│    └─Empty: 2-753                      [64]                      --
│    └─Empty: 2-754                      [64]                      --
│    └─BatchNorm2d: 2-755                [16, 64, 32, 32]          --
│    └─Scaler: 2-756                     [16, 64, 32, 32]          --
│    └─ReLU: 2-757                       [16, 64, 32, 32]          --
│    └─Empty: 2-758                      [16, 64, 32, 32]          --
│    └─Clamp: 2-759                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-760                  [16, 64, 16, 16]          --
│    └─Empty: 2-761                      [16, 64, 16, 16]          --
│    └─Empty: 2-762                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-763         --                        --
│    └─One: 2-764                        [1]                       --
│    └─OutputScale: 2-765                --                        --
│    └─Empty: 2-766                      [64, 64, 3, 3]            --
│    └─Empty: 2-767                      [64, 64, 3, 3]            --
│    └─Empty: 2-768                      [64]                      --
│    └─Empty: 2-769                      [64]                      --
│    └─BatchNorm2d: 2-770                [16, 64, 16, 16]          --
│    └─Scaler: 2-771                     [16, 64, 16, 16]          --
│    └─ReLU: 2-772                       [16, 64, 16, 16]          --
│    └─Empty: 2-773                      [16, 64, 16, 16]          --
│    └─Clamp: 2-774                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-775         --                        --
│    └─One: 2-776                        [1]                       --
│    └─OutputScale: 2-777                --                        --
│    └─Empty: 2-778                      [64, 64, 3, 3]            --
│    └─Empty: 2-779                      [64, 64, 3, 3]            --
│    └─Empty: 2-780                      [64]                      --
│    └─Empty: 2-781                      [64]                      --
│    └─BatchNorm2d: 2-782                [16, 64, 16, 16]          --
│    └─Scaler: 2-783                     [16, 64, 16, 16]          --
│    └─ReLU: 2-784                       [16, 64, 16, 16]          --
│    └─Empty: 2-785                      [16, 64, 16, 16]          --
│    └─Clamp: 2-786                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-787                  [16, 64, 8, 8]            --
│    └─Empty: 2-788                      [16, 64, 8, 8]            --
│    └─Empty: 2-789                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-790         --                        --
│    └─One: 2-791                        [1]                       --
│    └─OutputScale: 2-792                --                        --
│    └─Empty: 2-793                      [64, 64, 3, 3]            --
│    └─Empty: 2-794                      [64, 64, 3, 3]            --
│    └─Empty: 2-795                      [64]                      --
│    └─Empty: 2-796                      [64]                      --
│    └─BatchNorm2d: 2-797                [16, 64, 8, 8]            --
│    └─Scaler: 2-798                     [16, 64, 8, 8]            --
│    └─ReLU: 2-799                       [16, 64, 8, 8]            --
│    └─Empty: 2-800                      [16, 64, 8, 8]            --
│    └─Clamp: 2-801                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-802         --                        --
│    └─One: 2-803                        [1]                       --
│    └─OutputScale: 2-804                --                        --
│    └─Empty: 2-805                      [64, 64, 1, 1]            --
│    └─Empty: 2-806                      [64, 64, 1, 1]            --
│    └─Empty: 2-807                      [64]                      --
│    └─Empty: 2-808                      [64]                      --
│    └─BatchNorm2d: 2-809                [16, 64, 8, 8]            --
│    └─Scaler: 2-810                     [16, 64, 8, 8]            --
│    └─ReLU: 2-811                       [16, 64, 8, 8]            --
│    └─Empty: 2-812                      [16, 64, 8, 8]            --
│    └─Clamp: 2-813                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-814                  [16, 64, 8, 8]            --
│    └─Empty: 2-815                      [16, 64, 8, 8]            --
│    └─Empty: 2-816                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-817         --                        --
│    └─One: 2-818                        [1]                       --
│    └─OutputScale: 2-819                --                        --
│    └─Empty: 2-820                      [64, 64, 3, 3]            --
│    └─Empty: 2-821                      [64, 64, 3, 3]            --
│    └─Empty: 2-822                      [64]                      --
│    └─Empty: 2-823                      [64]                      --
│    └─BatchNorm2d: 2-824                [16, 64, 8, 8]            --
│    └─Scaler: 2-825                     [16, 64, 8, 8]            --
│    └─ReLU: 2-826                       [16, 64, 8, 8]            --
│    └─Empty: 2-827                      [16, 64, 8, 8]            --
│    └─Clamp: 2-828                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-829                  [16, 64, 4, 4]            --
│    └─Empty: 2-830                      [16, 64, 4, 4]            --
│    └─Empty: 2-831                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-832         --                        --
│    └─One: 2-833                        [1]                       --
│    └─OutputScale: 2-834                --                        --
│    └─Empty: 2-835                      [64, 64, 3, 3]            --
│    └─Empty: 2-836                      [64, 64, 3, 3]            --
│    └─Empty: 2-837                      [64]                      --
│    └─Empty: 2-838                      [64]                      --
│    └─BatchNorm2d: 2-839                [16, 64, 4, 4]            --
│    └─Scaler: 2-840                     [16, 64, 4, 4]            --
│    └─ReLU: 2-841                       [16, 64, 4, 4]            --
│    └─Empty: 2-842                      [16, 64, 4, 4]            --
│    └─Clamp: 2-843                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-844         --                        --
│    └─One: 2-845                        [1]                       --
│    └─OutputScale: 2-846                --                        --
│    └─Empty: 2-847                      [64, 64, 1, 1]            --
│    └─Empty: 2-848                      [64, 64, 1, 1]            --
│    └─Empty: 2-849                      [64]                      --
│    └─Empty: 2-850                      [64]                      --
│    └─BatchNorm2d: 2-851                [16, 64, 4, 4]            --
│    └─Scaler: 2-852                     [16, 64, 4, 4]            --
│    └─ReLU: 2-853                       [16, 64, 4, 4]            --
│    └─Empty: 2-854                      [16, 64, 4, 4]            --
│    └─Clamp: 2-855                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-856                  [16, 64, 4, 4]            --
│    └─Empty: 2-857                      [16, 64, 4, 4]            --
│    └─Empty: 2-858                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-859         --                        --
│    └─One: 2-860                        [1]                       --
│    └─OutputScale: 2-861                --                        --
│    └─Empty: 2-862                      [64, 64, 3, 3]            --
│    └─Empty: 2-863                      [64, 64, 3, 3]            --
│    └─Empty: 2-864                      [64]                      --
│    └─Empty: 2-865                      [64]                      --
│    └─BatchNorm2d: 2-866                [16, 64, 4, 4]            --
│    └─Scaler: 2-867                     [16, 64, 4, 4]            --
│    └─ReLU: 2-868                       [16, 64, 4, 4]            --
│    └─Empty: 2-869                      [16, 64, 4, 4]            --
│    └─Clamp: 2-870                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-871                  [16, 64, 2, 2]            --
│    └─Empty: 2-872                      [16, 64, 2, 2]            --
│    └─Empty: 2-873                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-874         --                        --
│    └─One: 2-875                        [1]                       --
│    └─OutputScale: 2-876                --                        --
│    └─Empty: 2-877                      [64, 64, 1, 1]            --
│    └─Empty: 2-878                      [64, 64, 1, 1]            --
│    └─Empty: 2-879                      [64]                      --
│    └─Empty: 2-880                      [64]                      --
│    └─BatchNorm2d: 2-881                [16, 64, 2, 2]            --
│    └─Scaler: 2-882                     [16, 64, 2, 2]            --
│    └─ReLU: 2-883                       [16, 64, 2, 2]            --
│    └─Empty: 2-884                      [16, 64, 2, 2]            --
│    └─Clamp: 2-885                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-886         --                        --
│    └─One: 2-887                        [1]                       --
│    └─OutputScale: 2-888                --                        --
│    └─Empty: 2-889                      [64, 64, 1, 1]            --
│    └─Empty: 2-890                      [64, 64, 1, 1]            --
│    └─Empty: 2-891                      [64]                      --
│    └─Empty: 2-892                      [64]                      --
│    └─BatchNorm2d: 2-893                [16, 64, 2, 2]            --
│    └─Scaler: 2-894                     [16, 64, 2, 2]            --
│    └─ReLU: 2-895                       [16, 64, 2, 2]            --
│    └─Empty: 2-896                      [16, 64, 2, 2]            --
│    └─Clamp: 2-897                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-898                  [16, 64, 2, 2]            --
│    └─Empty: 2-899                      [16, 64, 2, 2]            --
│    └─Empty: 2-900                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-901         --                        --
│    └─One: 2-902                        [1]                       --
│    └─OutputScale: 2-903                --                        --
│    └─Empty: 2-904                      [64, 64, 3, 3]            --
│    └─Empty: 2-905                      [64, 64, 3, 3]            --
│    └─Empty: 2-906                      [64]                      --
│    └─Empty: 2-907                      [64]                      --
│    └─BatchNorm2d: 2-908                [16, 64, 2, 2]            --
│    └─Scaler: 2-909                     [16, 64, 2, 2]            --
│    └─ReLU: 2-910                       [16, 64, 2, 2]            --
│    └─Empty: 2-911                      [16, 64, 2, 2]            --
│    └─Clamp: 2-912                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-913         --                        --
│    └─One: 2-914                        [1]                       --
│    └─OutputScale: 2-915                --                        --
│    └─Empty: 2-916                      [64, 48, 1, 1]            --
│    └─Empty: 2-917                      [64, 48, 1, 1]            --
│    └─Empty: 2-918                      [64]                      --
│    └─Empty: 2-919                      [64]                      --
│    └─BatchNorm2d: 2-920                [16, 64, 64, 64]          --
│    └─Scaler: 2-921                     [16, 64, 64, 64]          --
│    └─ReLU: 2-922                       [16, 64, 64, 64]          --
│    └─Empty: 2-923                      [16, 64, 64, 64]          --
│    └─Clamp: 2-924                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-925         --                        --
│    └─One: 2-926                        [1]                       --
│    └─OutputScale: 2-927                --                        --
│    └─Empty: 2-928                      [64, 64, 3, 3]            --
│    └─Empty: 2-929                      [64, 64, 3, 3]            --
│    └─Empty: 2-930                      [64]                      --
│    └─Empty: 2-931                      [64]                      --
│    └─BatchNorm2d: 2-932                [16, 64, 64, 64]          --
│    └─Scaler: 2-933                     [16, 64, 64, 64]          --
│    └─ReLU: 2-934                       [16, 64, 64, 64]          --
│    └─Empty: 2-935                      [16, 64, 64, 64]          --
│    └─Clamp: 2-936                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-937         --                        --
│    └─One: 2-938                        [1]                       --
│    └─OutputScale: 2-939                --                        --
│    └─Empty: 2-940                      [64, 64, 1, 1]            --
│    └─Empty: 2-941                      [64, 64, 1, 1]            --
│    └─Empty: 2-942                      [64]                      --
│    └─Empty: 2-943                      [64]                      --
│    └─BatchNorm2d: 2-944                [16, 64, 64, 64]          --
│    └─Scaler: 2-945                     [16, 64, 64, 64]          --
│    └─ReLU: 2-946                       [16, 64, 64, 64]          --
│    └─Empty: 2-947                      [16, 64, 64, 64]          --
│    └─Clamp: 2-948                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-949         --                        --
│    └─One: 2-950                        [1]                       --
│    └─OutputScale: 2-951                --                        --
│    └─Empty: 2-952                      [64, 64, 3, 3]            --
│    └─Empty: 2-953                      [64, 64, 3, 3]            --
│    └─Empty: 2-954                      [64]                      --
│    └─Empty: 2-955                      [64]                      --
│    └─BatchNorm2d: 2-956                [16, 64, 64, 64]          --
│    └─Scaler: 2-957                     [16, 64, 64, 64]          --
│    └─ReLU: 2-958                       [16, 64, 64, 64]          --
│    └─Empty: 2-959                      [16, 64, 64, 64]          --
│    └─Clamp: 2-960                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-961                  [16, 64, 32, 32]          --
│    └─Empty: 2-962                      [16, 64, 32, 32]          --
│    └─Empty: 2-963                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-964         --                        --
│    └─One: 2-965                        [1]                       --
│    └─OutputScale: 2-966                --                        --
│    └─Empty: 2-967                      [64, 64, 3, 3]            --
│    └─Empty: 2-968                      [64, 64, 3, 3]            --
│    └─Empty: 2-969                      [64]                      --
│    └─Empty: 2-970                      [64]                      --
│    └─BatchNorm2d: 2-971                [16, 64, 32, 32]          --
│    └─Scaler: 2-972                     [16, 64, 32, 32]          --
│    └─ReLU: 2-973                       [16, 64, 32, 32]          --
│    └─Empty: 2-974                      [16, 64, 32, 32]          --
│    └─Clamp: 2-975                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-976         --                        --
│    └─One: 2-977                        [1]                       --
│    └─OutputScale: 2-978                --                        --
│    └─Empty: 2-979                      [64, 64, 3, 3]            --
│    └─Empty: 2-980                      [64, 64, 3, 3]            --
│    └─Empty: 2-981                      [64]                      --
│    └─Empty: 2-982                      [64]                      --
│    └─BatchNorm2d: 2-983                [16, 64, 32, 32]          --
│    └─Scaler: 2-984                     [16, 64, 32, 32]          --
│    └─ReLU: 2-985                       [16, 64, 32, 32]          --
│    └─Empty: 2-986                      [16, 64, 32, 32]          --
│    └─Clamp: 2-987                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-988                  [16, 64, 16, 16]          --
│    └─Empty: 2-989                      [16, 64, 16, 16]          --
│    └─Empty: 2-990                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-991         --                        --
│    └─One: 2-992                        [1]                       --
│    └─OutputScale: 2-993                --                        --
│    └─Empty: 2-994                      [64, 64, 3, 3]            --
│    └─Empty: 2-995                      [64, 64, 3, 3]            --
│    └─Empty: 2-996                      [64]                      --
│    └─Empty: 2-997                      [64]                      --
│    └─BatchNorm2d: 2-998                [16, 64, 16, 16]          --
│    └─Scaler: 2-999                     [16, 64, 16, 16]          --
│    └─ReLU: 2-1000                      [16, 64, 16, 16]          --
│    └─Empty: 2-1001                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1002                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1003        --                        --
│    └─One: 2-1004                       [1]                       --
│    └─OutputScale: 2-1005               --                        --
│    └─Empty: 2-1006                     [64, 64, 3, 3]            --
│    └─Empty: 2-1007                     [64, 64, 3, 3]            --
│    └─Empty: 2-1008                     [64]                      --
│    └─Empty: 2-1009                     [64]                      --
│    └─BatchNorm2d: 2-1010               [16, 64, 16, 16]          --
│    └─Scaler: 2-1011                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1012                      [16, 64, 16, 16]          --
│    └─Empty: 2-1013                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1014                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1015                 [16, 64, 8, 8]            --
│    └─Empty: 2-1016                     [16, 64, 8, 8]            --
│    └─Empty: 2-1017                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1018        --                        --
│    └─One: 2-1019                       [1]                       --
│    └─OutputScale: 2-1020               --                        --
│    └─Empty: 2-1021                     [64, 64, 3, 3]            --
│    └─Empty: 2-1022                     [64, 64, 3, 3]            --
│    └─Empty: 2-1023                     [64]                      --
│    └─Empty: 2-1024                     [64]                      --
│    └─BatchNorm2d: 2-1025               [16, 64, 8, 8]            --
│    └─Scaler: 2-1026                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1027                      [16, 64, 8, 8]            --
│    └─Empty: 2-1028                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1029                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1030        --                        --
│    └─One: 2-1031                       [1]                       --
│    └─OutputScale: 2-1032               --                        --
│    └─Empty: 2-1033                     [64, 64, 1, 1]            --
│    └─Empty: 2-1034                     [64, 64, 1, 1]            --
│    └─Empty: 2-1035                     [64]                      --
│    └─Empty: 2-1036                     [64]                      --
│    └─BatchNorm2d: 2-1037               [16, 64, 8, 8]            --
│    └─Scaler: 2-1038                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1039                      [16, 64, 8, 8]            --
│    └─Empty: 2-1040                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1041                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1042                 [16, 64, 8, 8]            --
│    └─Empty: 2-1043                     [16, 64, 8, 8]            --
│    └─Empty: 2-1044                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1045        --                        --
│    └─One: 2-1046                       [1]                       --
│    └─OutputScale: 2-1047               --                        --
│    └─Empty: 2-1048                     [64, 64, 3, 3]            --
│    └─Empty: 2-1049                     [64, 64, 3, 3]            --
│    └─Empty: 2-1050                     [64]                      --
│    └─Empty: 2-1051                     [64]                      --
│    └─BatchNorm2d: 2-1052               [16, 64, 8, 8]            --
│    └─Scaler: 2-1053                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1054                      [16, 64, 8, 8]            --
│    └─Empty: 2-1055                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1056                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1057                 [16, 64, 4, 4]            --
│    └─Empty: 2-1058                     [16, 64, 4, 4]            --
│    └─Empty: 2-1059                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1060        --                        --
│    └─One: 2-1061                       [1]                       --
│    └─OutputScale: 2-1062               --                        --
│    └─Empty: 2-1063                     [64, 64, 3, 3]            --
│    └─Empty: 2-1064                     [64, 64, 3, 3]            --
│    └─Empty: 2-1065                     [64]                      --
│    └─Empty: 2-1066                     [64]                      --
│    └─BatchNorm2d: 2-1067               [16, 64, 4, 4]            --
│    └─Scaler: 2-1068                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1069                      [16, 64, 4, 4]            --
│    └─Empty: 2-1070                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1071                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1072        --                        --
│    └─One: 2-1073                       [1]                       --
│    └─OutputScale: 2-1074               --                        --
│    └─Empty: 2-1075                     [64, 64, 1, 1]            --
│    └─Empty: 2-1076                     [64, 64, 1, 1]            --
│    └─Empty: 2-1077                     [64]                      --
│    └─Empty: 2-1078                     [64]                      --
│    └─BatchNorm2d: 2-1079               [16, 64, 4, 4]            --
│    └─Scaler: 2-1080                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1081                      [16, 64, 4, 4]            --
│    └─Empty: 2-1082                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1083                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1084                 [16, 64, 4, 4]            --
│    └─Empty: 2-1085                     [16, 64, 4, 4]            --
│    └─Empty: 2-1086                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1087        --                        --
│    └─One: 2-1088                       [1]                       --
│    └─OutputScale: 2-1089               --                        --
│    └─Empty: 2-1090                     [64, 64, 3, 3]            --
│    └─Empty: 2-1091                     [64, 64, 3, 3]            --
│    └─Empty: 2-1092                     [64]                      --
│    └─Empty: 2-1093                     [64]                      --
│    └─BatchNorm2d: 2-1094               [16, 64, 4, 4]            --
│    └─Scaler: 2-1095                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1096                      [16, 64, 4, 4]            --
│    └─Empty: 2-1097                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1098                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1099                 [16, 64, 2, 2]            --
│    └─Empty: 2-1100                     [16, 64, 2, 2]            --
│    └─Empty: 2-1101                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1102        --                        --
│    └─One: 2-1103                       [1]                       --
│    └─OutputScale: 2-1104               --                        --
│    └─Empty: 2-1105                     [64, 64, 1, 1]            --
│    └─Empty: 2-1106                     [64, 64, 1, 1]            --
│    └─Empty: 2-1107                     [64]                      --
│    └─Empty: 2-1108                     [64]                      --
│    └─BatchNorm2d: 2-1109               [16, 64, 2, 2]            --
│    └─Scaler: 2-1110                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1111                      [16, 64, 2, 2]            --
│    └─Empty: 2-1112                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1113                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1114        --                        --
│    └─One: 2-1115                       [1]                       --
│    └─OutputScale: 2-1116               --                        --
│    └─Empty: 2-1117                     [64, 64, 1, 1]            --
│    └─Empty: 2-1118                     [64, 64, 1, 1]            --
│    └─Empty: 2-1119                     [64]                      --
│    └─Empty: 2-1120                     [64]                      --
│    └─BatchNorm2d: 2-1121               [16, 64, 2, 2]            --
│    └─Scaler: 2-1122                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1123                      [16, 64, 2, 2]            --
│    └─Empty: 2-1124                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1125                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1126                 [16, 64, 2, 2]            --
│    └─Empty: 2-1127                     [16, 64, 2, 2]            --
│    └─Empty: 2-1128                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1129        --                        --
│    └─One: 2-1130                       [1]                       --
│    └─OutputScale: 2-1131               --                        --
│    └─Empty: 2-1132                     [64, 64, 3, 3]            --
│    └─Empty: 2-1133                     [64, 64, 3, 3]            --
│    └─Empty: 2-1134                     [64]                      --
│    └─Empty: 2-1135                     [64]                      --
│    └─BatchNorm2d: 2-1136               [16, 64, 2, 2]            --
│    └─Scaler: 2-1137                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1138                      [16, 64, 2, 2]            --
│    └─Empty: 2-1139                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1140                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1141        --                        --
│    └─One: 2-1142                       [1]                       --
│    └─OutputScale: 2-1143               --                        --
│    └─Empty: 2-1144                     [64, 48, 1, 1]            --
│    └─Empty: 2-1145                     [64, 48, 1, 1]            --
│    └─Empty: 2-1146                     [64]                      --
│    └─Empty: 2-1147                     [64]                      --
│    └─BatchNorm2d: 2-1148               [16, 64, 64, 64]          --
│    └─Scaler: 2-1149                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1150                      [16, 64, 64, 64]          --
│    └─Empty: 2-1151                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1152                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1153        --                        --
│    └─One: 2-1154                       [1]                       --
│    └─OutputScale: 2-1155               --                        --
│    └─Empty: 2-1156                     [64, 64, 3, 3]            --
│    └─Empty: 2-1157                     [64, 64, 3, 3]            --
│    └─Empty: 2-1158                     [64]                      --
│    └─Empty: 2-1159                     [64]                      --
│    └─BatchNorm2d: 2-1160               [16, 64, 64, 64]          --
│    └─Scaler: 2-1161                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1162                      [16, 64, 64, 64]          --
│    └─Empty: 2-1163                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1164                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1165        --                        --
│    └─One: 2-1166                       [1]                       --
│    └─OutputScale: 2-1167               --                        --
│    └─Empty: 2-1168                     [64, 64, 1, 1]            --
│    └─Empty: 2-1169                     [64, 64, 1, 1]            --
│    └─Empty: 2-1170                     [64]                      --
│    └─Empty: 2-1171                     [64]                      --
│    └─BatchNorm2d: 2-1172               [16, 64, 64, 64]          --
│    └─Scaler: 2-1173                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1174                      [16, 64, 64, 64]          --
│    └─Empty: 2-1175                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1176                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1177        --                        --
│    └─One: 2-1178                       [1]                       --
│    └─OutputScale: 2-1179               --                        --
│    └─Empty: 2-1180                     [64, 64, 3, 3]            --
│    └─Empty: 2-1181                     [64, 64, 3, 3]            --
│    └─Empty: 2-1182                     [64]                      --
│    └─Empty: 2-1183                     [64]                      --
│    └─BatchNorm2d: 2-1184               [16, 64, 64, 64]          --
│    └─Scaler: 2-1185                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1186                      [16, 64, 64, 64]          --
│    └─Empty: 2-1187                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1188                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1189                 [16, 64, 32, 32]          --
│    └─Empty: 2-1190                     [16, 64, 32, 32]          --
│    └─Empty: 2-1191                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1192        --                        --
│    └─One: 2-1193                       [1]                       --
│    └─OutputScale: 2-1194               --                        --
│    └─Empty: 2-1195                     [64, 64, 3, 3]            --
│    └─Empty: 2-1196                     [64, 64, 3, 3]            --
│    └─Empty: 2-1197                     [64]                      --
│    └─Empty: 2-1198                     [64]                      --
│    └─BatchNorm2d: 2-1199               [16, 64, 32, 32]          --
│    └─Scaler: 2-1200                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1201                      [16, 64, 32, 32]          --
│    └─Empty: 2-1202                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1203                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1204        --                        --
│    └─One: 2-1205                       [1]                       --
│    └─OutputScale: 2-1206               --                        --
│    └─Empty: 2-1207                     [64, 64, 3, 3]            --
│    └─Empty: 2-1208                     [64, 64, 3, 3]            --
│    └─Empty: 2-1209                     [64]                      --
│    └─Empty: 2-1210                     [64]                      --
│    └─BatchNorm2d: 2-1211               [16, 64, 32, 32]          --
│    └─Scaler: 2-1212                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1213                      [16, 64, 32, 32]          --
│    └─Empty: 2-1214                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1215                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1216                 [16, 64, 16, 16]          --
│    └─Empty: 2-1217                     [16, 64, 16, 16]          --
│    └─Empty: 2-1218                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1219        --                        --
│    └─One: 2-1220                       [1]                       --
│    └─OutputScale: 2-1221               --                        --
│    └─Empty: 2-1222                     [64, 64, 3, 3]            --
│    └─Empty: 2-1223                     [64, 64, 3, 3]            --
│    └─Empty: 2-1224                     [64]                      --
│    └─Empty: 2-1225                     [64]                      --
│    └─BatchNorm2d: 2-1226               [16, 64, 16, 16]          --
│    └─Scaler: 2-1227                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1228                      [16, 64, 16, 16]          --
│    └─Empty: 2-1229                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1230                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1231        --                        --
│    └─One: 2-1232                       [1]                       --
│    └─OutputScale: 2-1233               --                        --
│    └─Empty: 2-1234                     [64, 64, 3, 3]            --
│    └─Empty: 2-1235                     [64, 64, 3, 3]            --
│    └─Empty: 2-1236                     [64]                      --
│    └─Empty: 2-1237                     [64]                      --
│    └─BatchNorm2d: 2-1238               [16, 64, 16, 16]          --
│    └─Scaler: 2-1239                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1240                      [16, 64, 16, 16]          --
│    └─Empty: 2-1241                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1242                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1243                 [16, 64, 8, 8]            --
│    └─Empty: 2-1244                     [16, 64, 8, 8]            --
│    └─Empty: 2-1245                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1246        --                        --
│    └─One: 2-1247                       [1]                       --
│    └─OutputScale: 2-1248               --                        --
│    └─Empty: 2-1249                     [64, 64, 3, 3]            --
│    └─Empty: 2-1250                     [64, 64, 3, 3]            --
│    └─Empty: 2-1251                     [64]                      --
│    └─Empty: 2-1252                     [64]                      --
│    └─BatchNorm2d: 2-1253               [16, 64, 8, 8]            --
│    └─Scaler: 2-1254                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1255                      [16, 64, 8, 8]            --
│    └─Empty: 2-1256                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1257                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1258        --                        --
│    └─One: 2-1259                       [1]                       --
│    └─OutputScale: 2-1260               --                        --
│    └─Empty: 2-1261                     [64, 64, 1, 1]            --
│    └─Empty: 2-1262                     [64, 64, 1, 1]            --
│    └─Empty: 2-1263                     [64]                      --
│    └─Empty: 2-1264                     [64]                      --
│    └─BatchNorm2d: 2-1265               [16, 64, 8, 8]            --
│    └─Scaler: 2-1266                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1267                      [16, 64, 8, 8]            --
│    └─Empty: 2-1268                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1269                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1270                 [16, 64, 8, 8]            --
│    └─Empty: 2-1271                     [16, 64, 8, 8]            --
│    └─Empty: 2-1272                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1273        --                        --
│    └─One: 2-1274                       [1]                       --
│    └─OutputScale: 2-1275               --                        --
│    └─Empty: 2-1276                     [64, 64, 3, 3]            --
│    └─Empty: 2-1277                     [64, 64, 3, 3]            --
│    └─Empty: 2-1278                     [64]                      --
│    └─Empty: 2-1279                     [64]                      --
│    └─BatchNorm2d: 2-1280               [16, 64, 8, 8]            --
│    └─Scaler: 2-1281                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1282                      [16, 64, 8, 8]            --
│    └─Empty: 2-1283                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1284                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1285                 [16, 64, 4, 4]            --
│    └─Empty: 2-1286                     [16, 64, 4, 4]            --
│    └─Empty: 2-1287                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1288        --                        --
│    └─One: 2-1289                       [1]                       --
│    └─OutputScale: 2-1290               --                        --
│    └─Empty: 2-1291                     [64, 64, 3, 3]            --
│    └─Empty: 2-1292                     [64, 64, 3, 3]            --
│    └─Empty: 2-1293                     [64]                      --
│    └─Empty: 2-1294                     [64]                      --
│    └─BatchNorm2d: 2-1295               [16, 64, 4, 4]            --
│    └─Scaler: 2-1296                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1297                      [16, 64, 4, 4]            --
│    └─Empty: 2-1298                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1299                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1300        --                        --
│    └─One: 2-1301                       [1]                       --
│    └─OutputScale: 2-1302               --                        --
│    └─Empty: 2-1303                     [64, 64, 1, 1]            --
│    └─Empty: 2-1304                     [64, 64, 1, 1]            --
│    └─Empty: 2-1305                     [64]                      --
│    └─Empty: 2-1306                     [64]                      --
│    └─BatchNorm2d: 2-1307               [16, 64, 4, 4]            --
│    └─Scaler: 2-1308                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1309                      [16, 64, 4, 4]            --
│    └─Empty: 2-1310                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1311                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1312                 [16, 64, 4, 4]            --
│    └─Empty: 2-1313                     [16, 64, 4, 4]            --
│    └─Empty: 2-1314                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1315        --                        --
│    └─One: 2-1316                       [1]                       --
│    └─OutputScale: 2-1317               --                        --
│    └─Empty: 2-1318                     [64, 64, 3, 3]            --
│    └─Empty: 2-1319                     [64, 64, 3, 3]            --
│    └─Empty: 2-1320                     [64]                      --
│    └─Empty: 2-1321                     [64]                      --
│    └─BatchNorm2d: 2-1322               [16, 64, 4, 4]            --
│    └─Scaler: 2-1323                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1324                      [16, 64, 4, 4]            --
│    └─Empty: 2-1325                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1326                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1327                 [16, 64, 2, 2]            --
│    └─Empty: 2-1328                     [16, 64, 2, 2]            --
│    └─Empty: 2-1329                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1330        --                        --
│    └─One: 2-1331                       [1]                       --
│    └─OutputScale: 2-1332               --                        --
│    └─Empty: 2-1333                     [64, 64, 1, 1]            --
│    └─Empty: 2-1334                     [64, 64, 1, 1]            --
│    └─Empty: 2-1335                     [64]                      --
│    └─Empty: 2-1336                     [64]                      --
│    └─BatchNorm2d: 2-1337               [16, 64, 2, 2]            --
│    └─Scaler: 2-1338                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1339                      [16, 64, 2, 2]            --
│    └─Empty: 2-1340                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1341                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1342        --                        --
│    └─One: 2-1343                       [1]                       --
│    └─OutputScale: 2-1344               --                        --
│    └─Empty: 2-1345                     [64, 64, 1, 1]            --
│    └─Empty: 2-1346                     [64, 64, 1, 1]            --
│    └─Empty: 2-1347                     [64]                      --
│    └─Empty: 2-1348                     [64]                      --
│    └─BatchNorm2d: 2-1349               [16, 64, 2, 2]            --
│    └─Scaler: 2-1350                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1351                      [16, 64, 2, 2]            --
│    └─Empty: 2-1352                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1353                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1354                 [16, 64, 2, 2]            --
│    └─Empty: 2-1355                     [16, 64, 2, 2]            --
│    └─Empty: 2-1356                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1357        --                        --
│    └─One: 2-1358                       [1]                       --
│    └─OutputScale: 2-1359               --                        --
│    └─Empty: 2-1360                     [64, 64, 3, 3]            --
│    └─Empty: 2-1361                     [64, 64, 3, 3]            --
│    └─Empty: 2-1362                     [64]                      --
│    └─Empty: 2-1363                     [64]                      --
│    └─BatchNorm2d: 2-1364               [16, 64, 2, 2]            --
│    └─Scaler: 2-1365                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1366                      [16, 64, 2, 2]            --
│    └─Empty: 2-1367                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1368                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1369        --                        --
│    └─One: 2-1370                       [1]                       --
│    └─OutputScale: 2-1371               --                        --
│    └─Empty: 2-1372                     [64, 48, 1, 1]            --
│    └─Empty: 2-1373                     [64, 48, 1, 1]            --
│    └─Empty: 2-1374                     [64]                      --
│    └─Empty: 2-1375                     [64]                      --
│    └─BatchNorm2d: 2-1376               [16, 64, 64, 64]          --
│    └─Scaler: 2-1377                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1378                      [16, 64, 64, 64]          --
│    └─Empty: 2-1379                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1380                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1381        --                        --
│    └─One: 2-1382                       [1]                       --
│    └─OutputScale: 2-1383               --                        --
│    └─Empty: 2-1384                     [64, 64, 3, 3]            --
│    └─Empty: 2-1385                     [64, 64, 3, 3]            --
│    └─Empty: 2-1386                     [64]                      --
│    └─Empty: 2-1387                     [64]                      --
│    └─BatchNorm2d: 2-1388               [16, 64, 64, 64]          --
│    └─Scaler: 2-1389                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1390                      [16, 64, 64, 64]          --
│    └─Empty: 2-1391                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1392                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1393        --                        --
│    └─One: 2-1394                       [1]                       --
│    └─OutputScale: 2-1395               --                        --
│    └─Empty: 2-1396                     [64, 64, 1, 1]            --
│    └─Empty: 2-1397                     [64, 64, 1, 1]            --
│    └─Empty: 2-1398                     [64]                      --
│    └─Empty: 2-1399                     [64]                      --
│    └─BatchNorm2d: 2-1400               [16, 64, 64, 64]          --
│    └─Scaler: 2-1401                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1402                      [16, 64, 64, 64]          --
│    └─Empty: 2-1403                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1404                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1405        --                        --
│    └─One: 2-1406                       [1]                       --
│    └─OutputScale: 2-1407               --                        --
│    └─Empty: 2-1408                     [64, 64, 3, 3]            --
│    └─Empty: 2-1409                     [64, 64, 3, 3]            --
│    └─Empty: 2-1410                     [64]                      --
│    └─Empty: 2-1411                     [64]                      --
│    └─BatchNorm2d: 2-1412               [16, 64, 64, 64]          --
│    └─Scaler: 2-1413                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1414                      [16, 64, 64, 64]          --
│    └─Empty: 2-1415                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1416                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1417                 [16, 64, 32, 32]          --
│    └─Empty: 2-1418                     [16, 64, 32, 32]          --
│    └─Empty: 2-1419                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1420        --                        --
│    └─One: 2-1421                       [1]                       --
│    └─OutputScale: 2-1422               --                        --
│    └─Empty: 2-1423                     [64, 64, 3, 3]            --
│    └─Empty: 2-1424                     [64, 64, 3, 3]            --
│    └─Empty: 2-1425                     [64]                      --
│    └─Empty: 2-1426                     [64]                      --
│    └─BatchNorm2d: 2-1427               [16, 64, 32, 32]          --
│    └─Scaler: 2-1428                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1429                      [16, 64, 32, 32]          --
│    └─Empty: 2-1430                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1431                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1432        --                        --
│    └─One: 2-1433                       [1]                       --
│    └─OutputScale: 2-1434               --                        --
│    └─Empty: 2-1435                     [64, 64, 3, 3]            --
│    └─Empty: 2-1436                     [64, 64, 3, 3]            --
│    └─Empty: 2-1437                     [64]                      --
│    └─Empty: 2-1438                     [64]                      --
│    └─BatchNorm2d: 2-1439               [16, 64, 32, 32]          --
│    └─Scaler: 2-1440                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1441                      [16, 64, 32, 32]          --
│    └─Empty: 2-1442                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1443                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1444                 [16, 64, 16, 16]          --
│    └─Empty: 2-1445                     [16, 64, 16, 16]          --
│    └─Empty: 2-1446                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1447        --                        --
│    └─One: 2-1448                       [1]                       --
│    └─OutputScale: 2-1449               --                        --
│    └─Empty: 2-1450                     [64, 64, 3, 3]            --
│    └─Empty: 2-1451                     [64, 64, 3, 3]            --
│    └─Empty: 2-1452                     [64]                      --
│    └─Empty: 2-1453                     [64]                      --
│    └─BatchNorm2d: 2-1454               [16, 64, 16, 16]          --
│    └─Scaler: 2-1455                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1456                      [16, 64, 16, 16]          --
│    └─Empty: 2-1457                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1458                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1459        --                        --
│    └─One: 2-1460                       [1]                       --
│    └─OutputScale: 2-1461               --                        --
│    └─Empty: 2-1462                     [64, 64, 3, 3]            --
│    └─Empty: 2-1463                     [64, 64, 3, 3]            --
│    └─Empty: 2-1464                     [64]                      --
│    └─Empty: 2-1465                     [64]                      --
│    └─BatchNorm2d: 2-1466               [16, 64, 16, 16]          --
│    └─Scaler: 2-1467                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1468                      [16, 64, 16, 16]          --
│    └─Empty: 2-1469                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1470                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1471                 [16, 64, 8, 8]            --
│    └─Empty: 2-1472                     [16, 64, 8, 8]            --
│    └─Empty: 2-1473                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1474        --                        --
│    └─One: 2-1475                       [1]                       --
│    └─OutputScale: 2-1476               --                        --
│    └─Empty: 2-1477                     [64, 64, 3, 3]            --
│    └─Empty: 2-1478                     [64, 64, 3, 3]            --
│    └─Empty: 2-1479                     [64]                      --
│    └─Empty: 2-1480                     [64]                      --
│    └─BatchNorm2d: 2-1481               [16, 64, 8, 8]            --
│    └─Scaler: 2-1482                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1483                      [16, 64, 8, 8]            --
│    └─Empty: 2-1484                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1485                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1486        --                        --
│    └─One: 2-1487                       [1]                       --
│    └─OutputScale: 2-1488               --                        --
│    └─Empty: 2-1489                     [64, 64, 1, 1]            --
│    └─Empty: 2-1490                     [64, 64, 1, 1]            --
│    └─Empty: 2-1491                     [64]                      --
│    └─Empty: 2-1492                     [64]                      --
│    └─BatchNorm2d: 2-1493               [16, 64, 8, 8]            --
│    └─Scaler: 2-1494                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1495                      [16, 64, 8, 8]            --
│    └─Empty: 2-1496                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1497                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1498                 [16, 64, 8, 8]            --
│    └─Empty: 2-1499                     [16, 64, 8, 8]            --
│    └─Empty: 2-1500                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1501        --                        --
│    └─One: 2-1502                       [1]                       --
│    └─OutputScale: 2-1503               --                        --
│    └─Empty: 2-1504                     [64, 64, 3, 3]            --
│    └─Empty: 2-1505                     [64, 64, 3, 3]            --
│    └─Empty: 2-1506                     [64]                      --
│    └─Empty: 2-1507                     [64]                      --
│    └─BatchNorm2d: 2-1508               [16, 64, 8, 8]            --
│    └─Scaler: 2-1509                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1510                      [16, 64, 8, 8]            --
│    └─Empty: 2-1511                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1512                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1513                 [16, 64, 4, 4]            --
│    └─Empty: 2-1514                     [16, 64, 4, 4]            --
│    └─Empty: 2-1515                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1516        --                        --
│    └─One: 2-1517                       [1]                       --
│    └─OutputScale: 2-1518               --                        --
│    └─Empty: 2-1519                     [64, 64, 3, 3]            --
│    └─Empty: 2-1520                     [64, 64, 3, 3]            --
│    └─Empty: 2-1521                     [64]                      --
│    └─Empty: 2-1522                     [64]                      --
│    └─BatchNorm2d: 2-1523               [16, 64, 4, 4]            --
│    └─Scaler: 2-1524                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1525                      [16, 64, 4, 4]            --
│    └─Empty: 2-1526                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1527                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1528        --                        --
│    └─One: 2-1529                       [1]                       --
│    └─OutputScale: 2-1530               --                        --
│    └─Empty: 2-1531                     [64, 64, 1, 1]            --
│    └─Empty: 2-1532                     [64, 64, 1, 1]            --
│    └─Empty: 2-1533                     [64]                      --
│    └─Empty: 2-1534                     [64]                      --
│    └─BatchNorm2d: 2-1535               [16, 64, 4, 4]            --
│    └─Scaler: 2-1536                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1537                      [16, 64, 4, 4]            --
│    └─Empty: 2-1538                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1539                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1540                 [16, 64, 4, 4]            --
│    └─Empty: 2-1541                     [16, 64, 4, 4]            --
│    └─Empty: 2-1542                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1543        --                        --
│    └─One: 2-1544                       [1]                       --
│    └─OutputScale: 2-1545               --                        --
│    └─Empty: 2-1546                     [64, 64, 3, 3]            --
│    └─Empty: 2-1547                     [64, 64, 3, 3]            --
│    └─Empty: 2-1548                     [64]                      --
│    └─Empty: 2-1549                     [64]                      --
│    └─BatchNorm2d: 2-1550               [16, 64, 4, 4]            --
│    └─Scaler: 2-1551                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1552                      [16, 64, 4, 4]            --
│    └─Empty: 2-1553                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1554                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1555                 [16, 64, 2, 2]            --
│    └─Empty: 2-1556                     [16, 64, 2, 2]            --
│    └─Empty: 2-1557                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1558        --                        --
│    └─One: 2-1559                       [1]                       --
│    └─OutputScale: 2-1560               --                        --
│    └─Empty: 2-1561                     [64, 64, 1, 1]            --
│    └─Empty: 2-1562                     [64, 64, 1, 1]            --
│    └─Empty: 2-1563                     [64]                      --
│    └─Empty: 2-1564                     [64]                      --
│    └─BatchNorm2d: 2-1565               [16, 64, 2, 2]            --
│    └─Scaler: 2-1566                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1567                      [16, 64, 2, 2]            --
│    └─Empty: 2-1568                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1569                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1570        --                        --
│    └─One: 2-1571                       [1]                       --
│    └─OutputScale: 2-1572               --                        --
│    └─Empty: 2-1573                     [64, 64, 1, 1]            --
│    └─Empty: 2-1574                     [64, 64, 1, 1]            --
│    └─Empty: 2-1575                     [64]                      --
│    └─Empty: 2-1576                     [64]                      --
│    └─BatchNorm2d: 2-1577               [16, 64, 2, 2]            --
│    └─Scaler: 2-1578                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1579                      [16, 64, 2, 2]            --
│    └─Empty: 2-1580                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1581                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1582                 [16, 64, 2, 2]            --
│    └─Empty: 2-1583                     [16, 64, 2, 2]            --
│    └─Empty: 2-1584                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1585        --                        --
│    └─One: 2-1586                       [1]                       --
│    └─OutputScale: 2-1587               --                        --
│    └─Empty: 2-1588                     [64, 64, 3, 3]            --
│    └─Empty: 2-1589                     [64, 64, 3, 3]            --
│    └─Empty: 2-1590                     [64]                      --
│    └─Empty: 2-1591                     [64]                      --
│    └─BatchNorm2d: 2-1592               [16, 64, 2, 2]            --
│    └─Scaler: 2-1593                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1594                      [16, 64, 2, 2]            --
│    └─Empty: 2-1595                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1596                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1597        --                        --
│    └─One: 2-1598                       [1]                       --
│    └─OutputScale: 2-1599               --                        --
│    └─Empty: 2-1600                     [64, 48, 1, 1]            --
│    └─Empty: 2-1601                     [64, 48, 1, 1]            --
│    └─Empty: 2-1602                     [64]                      --
│    └─Empty: 2-1603                     [64]                      --
│    └─BatchNorm2d: 2-1604               [16, 64, 64, 64]          --
│    └─Scaler: 2-1605                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1606                      [16, 64, 64, 64]          --
│    └─Empty: 2-1607                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1608                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1609        --                        --
│    └─One: 2-1610                       [1]                       --
│    └─OutputScale: 2-1611               --                        --
│    └─Empty: 2-1612                     [64, 64, 3, 3]            --
│    └─Empty: 2-1613                     [64, 64, 3, 3]            --
│    └─Empty: 2-1614                     [64]                      --
│    └─Empty: 2-1615                     [64]                      --
│    └─BatchNorm2d: 2-1616               [16, 64, 64, 64]          --
│    └─Scaler: 2-1617                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1618                      [16, 64, 64, 64]          --
│    └─Empty: 2-1619                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1620                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1621        --                        --
│    └─One: 2-1622                       [1]                       --
│    └─OutputScale: 2-1623               --                        --
│    └─Empty: 2-1624                     [64, 64, 1, 1]            --
│    └─Empty: 2-1625                     [64, 64, 1, 1]            --
│    └─Empty: 2-1626                     [64]                      --
│    └─Empty: 2-1627                     [64]                      --
│    └─BatchNorm2d: 2-1628               [16, 64, 64, 64]          --
│    └─Scaler: 2-1629                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1630                      [16, 64, 64, 64]          --
│    └─Empty: 2-1631                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1632                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1633        --                        --
│    └─One: 2-1634                       [1]                       --
│    └─OutputScale: 2-1635               --                        --
│    └─Empty: 2-1636                     [64, 64, 3, 3]            --
│    └─Empty: 2-1637                     [64, 64, 3, 3]            --
│    └─Empty: 2-1638                     [64]                      --
│    └─Empty: 2-1639                     [64]                      --
│    └─BatchNorm2d: 2-1640               [16, 64, 64, 64]          --
│    └─Scaler: 2-1641                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1642                      [16, 64, 64, 64]          --
│    └─Empty: 2-1643                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1644                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1645                 [16, 64, 32, 32]          --
│    └─Empty: 2-1646                     [16, 64, 32, 32]          --
│    └─Empty: 2-1647                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1648        --                        --
│    └─One: 2-1649                       [1]                       --
│    └─OutputScale: 2-1650               --                        --
│    └─Empty: 2-1651                     [64, 64, 3, 3]            --
│    └─Empty: 2-1652                     [64, 64, 3, 3]            --
│    └─Empty: 2-1653                     [64]                      --
│    └─Empty: 2-1654                     [64]                      --
│    └─BatchNorm2d: 2-1655               [16, 64, 32, 32]          --
│    └─Scaler: 2-1656                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1657                      [16, 64, 32, 32]          --
│    └─Empty: 2-1658                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1659                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1660        --                        --
│    └─One: 2-1661                       [1]                       --
│    └─OutputScale: 2-1662               --                        --
│    └─Empty: 2-1663                     [64, 64, 3, 3]            --
│    └─Empty: 2-1664                     [64, 64, 3, 3]            --
│    └─Empty: 2-1665                     [64]                      --
│    └─Empty: 2-1666                     [64]                      --
│    └─BatchNorm2d: 2-1667               [16, 64, 32, 32]          --
│    └─Scaler: 2-1668                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1669                      [16, 64, 32, 32]          --
│    └─Empty: 2-1670                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1671                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1672                 [16, 64, 16, 16]          --
│    └─Empty: 2-1673                     [16, 64, 16, 16]          --
│    └─Empty: 2-1674                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1675        --                        --
│    └─One: 2-1676                       [1]                       --
│    └─OutputScale: 2-1677               --                        --
│    └─Empty: 2-1678                     [64, 64, 3, 3]            --
│    └─Empty: 2-1679                     [64, 64, 3, 3]            --
│    └─Empty: 2-1680                     [64]                      --
│    └─Empty: 2-1681                     [64]                      --
│    └─BatchNorm2d: 2-1682               [16, 64, 16, 16]          --
│    └─Scaler: 2-1683                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1684                      [16, 64, 16, 16]          --
│    └─Empty: 2-1685                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1686                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1687        --                        --
│    └─One: 2-1688                       [1]                       --
│    └─OutputScale: 2-1689               --                        --
│    └─Empty: 2-1690                     [64, 64, 3, 3]            --
│    └─Empty: 2-1691                     [64, 64, 3, 3]            --
│    └─Empty: 2-1692                     [64]                      --
│    └─Empty: 2-1693                     [64]                      --
│    └─BatchNorm2d: 2-1694               [16, 64, 16, 16]          --
│    └─Scaler: 2-1695                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1696                      [16, 64, 16, 16]          --
│    └─Empty: 2-1697                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1698                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1699                 [16, 64, 8, 8]            --
│    └─Empty: 2-1700                     [16, 64, 8, 8]            --
│    └─Empty: 2-1701                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1702        --                        --
│    └─One: 2-1703                       [1]                       --
│    └─OutputScale: 2-1704               --                        --
│    └─Empty: 2-1705                     [64, 64, 3, 3]            --
│    └─Empty: 2-1706                     [64, 64, 3, 3]            --
│    └─Empty: 2-1707                     [64]                      --
│    └─Empty: 2-1708                     [64]                      --
│    └─BatchNorm2d: 2-1709               [16, 64, 8, 8]            --
│    └─Scaler: 2-1710                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1711                      [16, 64, 8, 8]            --
│    └─Empty: 2-1712                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1713                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1714        --                        --
│    └─One: 2-1715                       [1]                       --
│    └─OutputScale: 2-1716               --                        --
│    └─Empty: 2-1717                     [64, 64, 1, 1]            --
│    └─Empty: 2-1718                     [64, 64, 1, 1]            --
│    └─Empty: 2-1719                     [64]                      --
│    └─Empty: 2-1720                     [64]                      --
│    └─BatchNorm2d: 2-1721               [16, 64, 8, 8]            --
│    └─Scaler: 2-1722                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1723                      [16, 64, 8, 8]            --
│    └─Empty: 2-1724                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1725                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1726                 [16, 64, 8, 8]            --
│    └─Empty: 2-1727                     [16, 64, 8, 8]            --
│    └─Empty: 2-1728                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1729        --                        --
│    └─One: 2-1730                       [1]                       --
│    └─OutputScale: 2-1731               --                        --
│    └─Empty: 2-1732                     [64, 64, 3, 3]            --
│    └─Empty: 2-1733                     [64, 64, 3, 3]            --
│    └─Empty: 2-1734                     [64]                      --
│    └─Empty: 2-1735                     [64]                      --
│    └─BatchNorm2d: 2-1736               [16, 64, 8, 8]            --
│    └─Scaler: 2-1737                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1738                      [16, 64, 8, 8]            --
│    └─Empty: 2-1739                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1740                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1741                 [16, 64, 4, 4]            --
│    └─Empty: 2-1742                     [16, 64, 4, 4]            --
│    └─Empty: 2-1743                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1744        --                        --
│    └─One: 2-1745                       [1]                       --
│    └─OutputScale: 2-1746               --                        --
│    └─Empty: 2-1747                     [64, 64, 3, 3]            --
│    └─Empty: 2-1748                     [64, 64, 3, 3]            --
│    └─Empty: 2-1749                     [64]                      --
│    └─Empty: 2-1750                     [64]                      --
│    └─BatchNorm2d: 2-1751               [16, 64, 4, 4]            --
│    └─Scaler: 2-1752                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1753                      [16, 64, 4, 4]            --
│    └─Empty: 2-1754                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1755                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1756        --                        --
│    └─One: 2-1757                       [1]                       --
│    └─OutputScale: 2-1758               --                        --
│    └─Empty: 2-1759                     [64, 64, 1, 1]            --
│    └─Empty: 2-1760                     [64, 64, 1, 1]            --
│    └─Empty: 2-1761                     [64]                      --
│    └─Empty: 2-1762                     [64]                      --
│    └─BatchNorm2d: 2-1763               [16, 64, 4, 4]            --
│    └─Scaler: 2-1764                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1765                      [16, 64, 4, 4]            --
│    └─Empty: 2-1766                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1767                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1768                 [16, 64, 4, 4]            --
│    └─Empty: 2-1769                     [16, 64, 4, 4]            --
│    └─Empty: 2-1770                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1771        --                        --
│    └─One: 2-1772                       [1]                       --
│    └─OutputScale: 2-1773               --                        --
│    └─Empty: 2-1774                     [64, 64, 3, 3]            --
│    └─Empty: 2-1775                     [64, 64, 3, 3]            --
│    └─Empty: 2-1776                     [64]                      --
│    └─Empty: 2-1777                     [64]                      --
│    └─BatchNorm2d: 2-1778               [16, 64, 4, 4]            --
│    └─Scaler: 2-1779                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1780                      [16, 64, 4, 4]            --
│    └─Empty: 2-1781                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1782                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1783                 [16, 64, 2, 2]            --
│    └─Empty: 2-1784                     [16, 64, 2, 2]            --
│    └─Empty: 2-1785                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1786        --                        --
│    └─One: 2-1787                       [1]                       --
│    └─OutputScale: 2-1788               --                        --
│    └─Empty: 2-1789                     [64, 64, 1, 1]            --
│    └─Empty: 2-1790                     [64, 64, 1, 1]            --
│    └─Empty: 2-1791                     [64]                      --
│    └─Empty: 2-1792                     [64]                      --
│    └─BatchNorm2d: 2-1793               [16, 64, 2, 2]            --
│    └─Scaler: 2-1794                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1795                      [16, 64, 2, 2]            --
│    └─Empty: 2-1796                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1797                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1798        --                        --
│    └─One: 2-1799                       [1]                       --
│    └─OutputScale: 2-1800               --                        --
│    └─Empty: 2-1801                     [64, 64, 1, 1]            --
│    └─Empty: 2-1802                     [64, 64, 1, 1]            --
│    └─Empty: 2-1803                     [64]                      --
│    └─Empty: 2-1804                     [64]                      --
│    └─BatchNorm2d: 2-1805               [16, 64, 2, 2]            --
│    └─Scaler: 2-1806                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1807                      [16, 64, 2, 2]            --
│    └─Empty: 2-1808                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1809                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1810                 [16, 64, 2, 2]            --
│    └─Empty: 2-1811                     [16, 64, 2, 2]            --
│    └─Empty: 2-1812                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1813        --                        --
│    └─One: 2-1814                       [1]                       --
│    └─OutputScale: 2-1815               --                        --
│    └─Empty: 2-1816                     [64, 64, 3, 3]            --
│    └─Empty: 2-1817                     [64, 64, 3, 3]            --
│    └─Empty: 2-1818                     [64]                      --
│    └─Empty: 2-1819                     [64]                      --
│    └─BatchNorm2d: 2-1820               [16, 64, 2, 2]            --
│    └─Scaler: 2-1821                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1822                      [16, 64, 2, 2]            --
│    └─Empty: 2-1823                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1824                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1825        --                        --
│    └─One: 2-1826                       [1]                       --
│    └─OutputScale: 2-1827               --                        --
│    └─Empty: 2-1828                     [64, 48, 1, 1]            --
│    └─Empty: 2-1829                     [64, 48, 1, 1]            --
│    └─Empty: 2-1830                     [64]                      --
│    └─Empty: 2-1831                     [64]                      --
│    └─BatchNorm2d: 2-1832               [16, 64, 64, 64]          --
│    └─Scaler: 2-1833                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1834                      [16, 64, 64, 64]          --
│    └─Empty: 2-1835                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1836                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1837        --                        --
│    └─One: 2-1838                       [1]                       --
│    └─OutputScale: 2-1839               --                        --
│    └─Empty: 2-1840                     [64, 64, 3, 3]            --
│    └─Empty: 2-1841                     [64, 64, 3, 3]            --
│    └─Empty: 2-1842                     [64]                      --
│    └─Empty: 2-1843                     [64]                      --
│    └─BatchNorm2d: 2-1844               [16, 64, 64, 64]          --
│    └─Scaler: 2-1845                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1846                      [16, 64, 64, 64]          --
│    └─Empty: 2-1847                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1848                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1849        --                        --
│    └─One: 2-1850                       [1]                       --
│    └─OutputScale: 2-1851               --                        --
│    └─Empty: 2-1852                     [64, 64, 1, 1]            --
│    └─Empty: 2-1853                     [64, 64, 1, 1]            --
│    └─Empty: 2-1854                     [64]                      --
│    └─Empty: 2-1855                     [64]                      --
│    └─BatchNorm2d: 2-1856               [16, 64, 64, 64]          --
│    └─Scaler: 2-1857                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1858                      [16, 64, 64, 64]          --
│    └─Empty: 2-1859                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1860                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1861        --                        --
│    └─One: 2-1862                       [1]                       --
│    └─OutputScale: 2-1863               --                        --
│    └─Empty: 2-1864                     [64, 64, 3, 3]            --
│    └─Empty: 2-1865                     [64, 64, 3, 3]            --
│    └─Empty: 2-1866                     [64]                      --
│    └─Empty: 2-1867                     [64]                      --
│    └─BatchNorm2d: 2-1868               [16, 64, 64, 64]          --
│    └─Scaler: 2-1869                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1870                      [16, 64, 64, 64]          --
│    └─Empty: 2-1871                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1872                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1873                 [16, 64, 32, 32]          --
│    └─Empty: 2-1874                     [16, 64, 32, 32]          --
│    └─Empty: 2-1875                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1876        --                        --
│    └─One: 2-1877                       [1]                       --
│    └─OutputScale: 2-1878               --                        --
│    └─Empty: 2-1879                     [64, 64, 3, 3]            --
│    └─Empty: 2-1880                     [64, 64, 3, 3]            --
│    └─Empty: 2-1881                     [64]                      --
│    └─Empty: 2-1882                     [64]                      --
│    └─BatchNorm2d: 2-1883               [16, 64, 32, 32]          --
│    └─Scaler: 2-1884                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1885                      [16, 64, 32, 32]          --
│    └─Empty: 2-1886                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1887                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1888        --                        --
│    └─One: 2-1889                       [1]                       --
│    └─OutputScale: 2-1890               --                        --
│    └─Empty: 2-1891                     [64, 64, 3, 3]            --
│    └─Empty: 2-1892                     [64, 64, 3, 3]            --
│    └─Empty: 2-1893                     [64]                      --
│    └─Empty: 2-1894                     [64]                      --
│    └─BatchNorm2d: 2-1895               [16, 64, 32, 32]          --
│    └─Scaler: 2-1896                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1897                      [16, 64, 32, 32]          --
│    └─Empty: 2-1898                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1899                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1900                 [16, 64, 16, 16]          --
│    └─Empty: 2-1901                     [16, 64, 16, 16]          --
│    └─Empty: 2-1902                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1903        --                        --
│    └─One: 2-1904                       [1]                       --
│    └─OutputScale: 2-1905               --                        --
│    └─Empty: 2-1906                     [64, 64, 3, 3]            --
│    └─Empty: 2-1907                     [64, 64, 3, 3]            --
│    └─Empty: 2-1908                     [64]                      --
│    └─Empty: 2-1909                     [64]                      --
│    └─BatchNorm2d: 2-1910               [16, 64, 16, 16]          --
│    └─Scaler: 2-1911                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1912                      [16, 64, 16, 16]          --
│    └─Empty: 2-1913                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1914                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1915        --                        --
│    └─One: 2-1916                       [1]                       --
│    └─OutputScale: 2-1917               --                        --
│    └─Empty: 2-1918                     [64, 64, 3, 3]            --
│    └─Empty: 2-1919                     [64, 64, 3, 3]            --
│    └─Empty: 2-1920                     [64]                      --
│    └─Empty: 2-1921                     [64]                      --
│    └─BatchNorm2d: 2-1922               [16, 64, 16, 16]          --
│    └─Scaler: 2-1923                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1924                      [16, 64, 16, 16]          --
│    └─Empty: 2-1925                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1926                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1927                 [16, 64, 8, 8]            --
│    └─Empty: 2-1928                     [16, 64, 8, 8]            --
│    └─Empty: 2-1929                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1930        --                        --
│    └─One: 2-1931                       [1]                       --
│    └─OutputScale: 2-1932               --                        --
│    └─Empty: 2-1933                     [64, 64, 3, 3]            --
│    └─Empty: 2-1934                     [64, 64, 3, 3]            --
│    └─Empty: 2-1935                     [64]                      --
│    └─Empty: 2-1936                     [64]                      --
│    └─BatchNorm2d: 2-1937               [16, 64, 8, 8]            --
│    └─Scaler: 2-1938                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1939                      [16, 64, 8, 8]            --
│    └─Empty: 2-1940                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1941                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1942        --                        --
│    └─One: 2-1943                       [1]                       --
│    └─OutputScale: 2-1944               --                        --
│    └─Empty: 2-1945                     [64, 64, 1, 1]            --
│    └─Empty: 2-1946                     [64, 64, 1, 1]            --
│    └─Empty: 2-1947                     [64]                      --
│    └─Empty: 2-1948                     [64]                      --
│    └─BatchNorm2d: 2-1949               [16, 64, 8, 8]            --
│    └─Scaler: 2-1950                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1951                      [16, 64, 8, 8]            --
│    └─Empty: 2-1952                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1953                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1954                 [16, 64, 8, 8]            --
│    └─Empty: 2-1955                     [16, 64, 8, 8]            --
│    └─Empty: 2-1956                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1957        --                        --
│    └─One: 2-1958                       [1]                       --
│    └─OutputScale: 2-1959               --                        --
│    └─Empty: 2-1960                     [64, 64, 3, 3]            --
│    └─Empty: 2-1961                     [64, 64, 3, 3]            --
│    └─Empty: 2-1962                     [64]                      --
│    └─Empty: 2-1963                     [64]                      --
│    └─BatchNorm2d: 2-1964               [16, 64, 8, 8]            --
│    └─Scaler: 2-1965                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1966                      [16, 64, 8, 8]            --
│    └─Empty: 2-1967                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1968                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1969                 [16, 64, 4, 4]            --
│    └─Empty: 2-1970                     [16, 64, 4, 4]            --
│    └─Empty: 2-1971                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1972        --                        --
│    └─One: 2-1973                       [1]                       --
│    └─OutputScale: 2-1974               --                        --
│    └─Empty: 2-1975                     [64, 64, 3, 3]            --
│    └─Empty: 2-1976                     [64, 64, 3, 3]            --
│    └─Empty: 2-1977                     [64]                      --
│    └─Empty: 2-1978                     [64]                      --
│    └─BatchNorm2d: 2-1979               [16, 64, 4, 4]            --
│    └─Scaler: 2-1980                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1981                      [16, 64, 4, 4]            --
│    └─Empty: 2-1982                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1983                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1984        --                        --
│    └─One: 2-1985                       [1]                       --
│    └─OutputScale: 2-1986               --                        --
│    └─Empty: 2-1987                     [64, 64, 1, 1]            --
│    └─Empty: 2-1988                     [64, 64, 1, 1]            --
│    └─Empty: 2-1989                     [64]                      --
│    └─Empty: 2-1990                     [64]                      --
│    └─BatchNorm2d: 2-1991               [16, 64, 4, 4]            --
│    └─Scaler: 2-1992                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1993                      [16, 64, 4, 4]            --
│    └─Empty: 2-1994                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1995                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1996                 [16, 64, 4, 4]            --
│    └─Empty: 2-1997                     [16, 64, 4, 4]            --
│    └─Empty: 2-1998                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1999        --                        --
│    └─One: 2-2000                       [1]                       --
│    └─OutputScale: 2-2001               --                        --
│    └─Empty: 2-2002                     [64, 64, 3, 3]            --
│    └─Empty: 2-2003                     [64, 64, 3, 3]            --
│    └─Empty: 2-2004                     [64]                      --
│    └─Empty: 2-2005                     [64]                      --
│    └─BatchNorm2d: 2-2006               [16, 64, 4, 4]            --
│    └─Scaler: 2-2007                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2008                      [16, 64, 4, 4]            --
│    └─Empty: 2-2009                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2010                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2011                 [16, 64, 2, 2]            --
│    └─Empty: 2-2012                     [16, 64, 2, 2]            --
│    └─Empty: 2-2013                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2014        --                        --
│    └─One: 2-2015                       [1]                       --
│    └─OutputScale: 2-2016               --                        --
│    └─Empty: 2-2017                     [64, 64, 1, 1]            --
│    └─Empty: 2-2018                     [64, 64, 1, 1]            --
│    └─Empty: 2-2019                     [64]                      --
│    └─Empty: 2-2020                     [64]                      --
│    └─BatchNorm2d: 2-2021               [16, 64, 2, 2]            --
│    └─Scaler: 2-2022                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2023                      [16, 64, 2, 2]            --
│    └─Empty: 2-2024                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2025                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2026        --                        --
│    └─One: 2-2027                       [1]                       --
│    └─OutputScale: 2-2028               --                        --
│    └─Empty: 2-2029                     [64, 64, 1, 1]            --
│    └─Empty: 2-2030                     [64, 64, 1, 1]            --
│    └─Empty: 2-2031                     [64]                      --
│    └─Empty: 2-2032                     [64]                      --
│    └─BatchNorm2d: 2-2033               [16, 64, 2, 2]            --
│    └─Scaler: 2-2034                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2035                      [16, 64, 2, 2]            --
│    └─Empty: 2-2036                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2037                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2038                 [16, 64, 2, 2]            --
│    └─Empty: 2-2039                     [16, 64, 2, 2]            --
│    └─Empty: 2-2040                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2041        --                        --
│    └─One: 2-2042                       [1]                       --
│    └─OutputScale: 2-2043               --                        --
│    └─Empty: 2-2044                     [64, 64, 3, 3]            --
│    └─Empty: 2-2045                     [64, 64, 3, 3]            --
│    └─Empty: 2-2046                     [64]                      --
│    └─Empty: 2-2047                     [64]                      --
│    └─BatchNorm2d: 2-2048               [16, 64, 2, 2]            --
│    └─Scaler: 2-2049                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2050                      [16, 64, 2, 2]            --
│    └─Empty: 2-2051                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2052                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2053        --                        --
│    └─One: 2-2054                       [1]                       --
│    └─OutputScale: 2-2055               --                        --
│    └─Empty: 2-2056                     [64, 48, 1, 1]            --
│    └─Empty: 2-2057                     [64, 48, 1, 1]            --
│    └─Empty: 2-2058                     [64]                      --
│    └─Empty: 2-2059                     [64]                      --
│    └─BatchNorm2d: 2-2060               [16, 64, 64, 64]          --
│    └─Scaler: 2-2061                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2062                      [16, 64, 64, 64]          --
│    └─Empty: 2-2063                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2064                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2065        --                        --
│    └─One: 2-2066                       [1]                       --
│    └─OutputScale: 2-2067               --                        --
│    └─Empty: 2-2068                     [64, 64, 3, 3]            --
│    └─Empty: 2-2069                     [64, 64, 3, 3]            --
│    └─Empty: 2-2070                     [64]                      --
│    └─Empty: 2-2071                     [64]                      --
│    └─BatchNorm2d: 2-2072               [16, 64, 64, 64]          --
│    └─Scaler: 2-2073                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2074                      [16, 64, 64, 64]          --
│    └─Empty: 2-2075                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2076                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2077        --                        --
│    └─One: 2-2078                       [1]                       --
│    └─OutputScale: 2-2079               --                        --
│    └─Empty: 2-2080                     [64, 64, 1, 1]            --
│    └─Empty: 2-2081                     [64, 64, 1, 1]            --
│    └─Empty: 2-2082                     [64]                      --
│    └─Empty: 2-2083                     [64]                      --
│    └─BatchNorm2d: 2-2084               [16, 64, 64, 64]          --
│    └─Scaler: 2-2085                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2086                      [16, 64, 64, 64]          --
│    └─Empty: 2-2087                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2088                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2089        --                        --
│    └─One: 2-2090                       [1]                       --
│    └─OutputScale: 2-2091               --                        --
│    └─Empty: 2-2092                     [64, 64, 3, 3]            --
│    └─Empty: 2-2093                     [64, 64, 3, 3]            --
│    └─Empty: 2-2094                     [64]                      --
│    └─Empty: 2-2095                     [64]                      --
│    └─BatchNorm2d: 2-2096               [16, 64, 64, 64]          --
│    └─Scaler: 2-2097                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2098                      [16, 64, 64, 64]          --
│    └─Empty: 2-2099                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2100                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2101                 [16, 64, 32, 32]          --
│    └─Empty: 2-2102                     [16, 64, 32, 32]          --
│    └─Empty: 2-2103                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2104        --                        --
│    └─One: 2-2105                       [1]                       --
│    └─OutputScale: 2-2106               --                        --
│    └─Empty: 2-2107                     [64, 64, 3, 3]            --
│    └─Empty: 2-2108                     [64, 64, 3, 3]            --
│    └─Empty: 2-2109                     [64]                      --
│    └─Empty: 2-2110                     [64]                      --
│    └─BatchNorm2d: 2-2111               [16, 64, 32, 32]          --
│    └─Scaler: 2-2112                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2113                      [16, 64, 32, 32]          --
│    └─Empty: 2-2114                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2115                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2116        --                        --
│    └─One: 2-2117                       [1]                       --
│    └─OutputScale: 2-2118               --                        --
│    └─Empty: 2-2119                     [64, 64, 3, 3]            --
│    └─Empty: 2-2120                     [64, 64, 3, 3]            --
│    └─Empty: 2-2121                     [64]                      --
│    └─Empty: 2-2122                     [64]                      --
│    └─BatchNorm2d: 2-2123               [16, 64, 32, 32]          --
│    └─Scaler: 2-2124                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2125                      [16, 64, 32, 32]          --
│    └─Empty: 2-2126                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2127                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2128                 [16, 64, 16, 16]          --
│    └─Empty: 2-2129                     [16, 64, 16, 16]          --
│    └─Empty: 2-2130                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2131        --                        --
│    └─One: 2-2132                       [1]                       --
│    └─OutputScale: 2-2133               --                        --
│    └─Empty: 2-2134                     [64, 64, 3, 3]            --
│    └─Empty: 2-2135                     [64, 64, 3, 3]            --
│    └─Empty: 2-2136                     [64]                      --
│    └─Empty: 2-2137                     [64]                      --
│    └─BatchNorm2d: 2-2138               [16, 64, 16, 16]          --
│    └─Scaler: 2-2139                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2140                      [16, 64, 16, 16]          --
│    └─Empty: 2-2141                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2142                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2143        --                        --
│    └─One: 2-2144                       [1]                       --
│    └─OutputScale: 2-2145               --                        --
│    └─Empty: 2-2146                     [64, 64, 3, 3]            --
│    └─Empty: 2-2147                     [64, 64, 3, 3]            --
│    └─Empty: 2-2148                     [64]                      --
│    └─Empty: 2-2149                     [64]                      --
│    └─BatchNorm2d: 2-2150               [16, 64, 16, 16]          --
│    └─Scaler: 2-2151                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2152                      [16, 64, 16, 16]          --
│    └─Empty: 2-2153                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2154                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2155                 [16, 64, 8, 8]            --
│    └─Empty: 2-2156                     [16, 64, 8, 8]            --
│    └─Empty: 2-2157                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2158        --                        --
│    └─One: 2-2159                       [1]                       --
│    └─OutputScale: 2-2160               --                        --
│    └─Empty: 2-2161                     [64, 64, 3, 3]            --
│    └─Empty: 2-2162                     [64, 64, 3, 3]            --
│    └─Empty: 2-2163                     [64]                      --
│    └─Empty: 2-2164                     [64]                      --
│    └─BatchNorm2d: 2-2165               [16, 64, 8, 8]            --
│    └─Scaler: 2-2166                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2167                      [16, 64, 8, 8]            --
│    └─Empty: 2-2168                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2169                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2170        --                        --
│    └─One: 2-2171                       [1]                       --
│    └─OutputScale: 2-2172               --                        --
│    └─Empty: 2-2173                     [64, 64, 1, 1]            --
│    └─Empty: 2-2174                     [64, 64, 1, 1]            --
│    └─Empty: 2-2175                     [64]                      --
│    └─Empty: 2-2176                     [64]                      --
│    └─BatchNorm2d: 2-2177               [16, 64, 8, 8]            --
│    └─Scaler: 2-2178                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2179                      [16, 64, 8, 8]            --
│    └─Empty: 2-2180                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2181                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2182                 [16, 64, 8, 8]            --
│    └─Empty: 2-2183                     [16, 64, 8, 8]            --
│    └─Empty: 2-2184                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2185        --                        --
│    └─One: 2-2186                       [1]                       --
│    └─OutputScale: 2-2187               --                        --
│    └─Empty: 2-2188                     [64, 64, 3, 3]            --
│    └─Empty: 2-2189                     [64, 64, 3, 3]            --
│    └─Empty: 2-2190                     [64]                      --
│    └─Empty: 2-2191                     [64]                      --
│    └─BatchNorm2d: 2-2192               [16, 64, 8, 8]            --
│    └─Scaler: 2-2193                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2194                      [16, 64, 8, 8]            --
│    └─Empty: 2-2195                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2196                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2197                 [16, 64, 4, 4]            --
│    └─Empty: 2-2198                     [16, 64, 4, 4]            --
│    └─Empty: 2-2199                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2200        --                        --
│    └─One: 2-2201                       [1]                       --
│    └─OutputScale: 2-2202               --                        --
│    └─Empty: 2-2203                     [64, 64, 3, 3]            --
│    └─Empty: 2-2204                     [64, 64, 3, 3]            --
│    └─Empty: 2-2205                     [64]                      --
│    └─Empty: 2-2206                     [64]                      --
│    └─BatchNorm2d: 2-2207               [16, 64, 4, 4]            --
│    └─Scaler: 2-2208                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2209                      [16, 64, 4, 4]            --
│    └─Empty: 2-2210                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2211                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2212        --                        --
│    └─One: 2-2213                       [1]                       --
│    └─OutputScale: 2-2214               --                        --
│    └─Empty: 2-2215                     [64, 64, 1, 1]            --
│    └─Empty: 2-2216                     [64, 64, 1, 1]            --
│    └─Empty: 2-2217                     [64]                      --
│    └─Empty: 2-2218                     [64]                      --
│    └─BatchNorm2d: 2-2219               [16, 64, 4, 4]            --
│    └─Scaler: 2-2220                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2221                      [16, 64, 4, 4]            --
│    └─Empty: 2-2222                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2223                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2224                 [16, 64, 4, 4]            --
│    └─Empty: 2-2225                     [16, 64, 4, 4]            --
│    └─Empty: 2-2226                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2227        --                        --
│    └─One: 2-2228                       [1]                       --
│    └─OutputScale: 2-2229               --                        --
│    └─Empty: 2-2230                     [64, 64, 3, 3]            --
│    └─Empty: 2-2231                     [64, 64, 3, 3]            --
│    └─Empty: 2-2232                     [64]                      --
│    └─Empty: 2-2233                     [64]                      --
│    └─BatchNorm2d: 2-2234               [16, 64, 4, 4]            --
│    └─Scaler: 2-2235                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2236                      [16, 64, 4, 4]            --
│    └─Empty: 2-2237                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2238                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2239                 [16, 64, 2, 2]            --
│    └─Empty: 2-2240                     [16, 64, 2, 2]            --
│    └─Empty: 2-2241                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2242        --                        --
│    └─One: 2-2243                       [1]                       --
│    └─OutputScale: 2-2244               --                        --
│    └─Empty: 2-2245                     [64, 64, 1, 1]            --
│    └─Empty: 2-2246                     [64, 64, 1, 1]            --
│    └─Empty: 2-2247                     [64]                      --
│    └─Empty: 2-2248                     [64]                      --
│    └─BatchNorm2d: 2-2249               [16, 64, 2, 2]            --
│    └─Scaler: 2-2250                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2251                      [16, 64, 2, 2]            --
│    └─Empty: 2-2252                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2253                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2254        --                        --
│    └─One: 2-2255                       [1]                       --
│    └─OutputScale: 2-2256               --                        --
│    └─Empty: 2-2257                     [64, 64, 1, 1]            --
│    └─Empty: 2-2258                     [64, 64, 1, 1]            --
│    └─Empty: 2-2259                     [64]                      --
│    └─Empty: 2-2260                     [64]                      --
│    └─BatchNorm2d: 2-2261               [16, 64, 2, 2]            --
│    └─Scaler: 2-2262                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2263                      [16, 64, 2, 2]            --
│    └─Empty: 2-2264                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2265                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2266                 [16, 64, 2, 2]            --
│    └─Empty: 2-2267                     [16, 64, 2, 2]            --
│    └─Empty: 2-2268                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2269        --                        --
│    └─One: 2-2270                       [1]                       --
│    └─OutputScale: 2-2271               --                        --
│    └─Empty: 2-2272                     [64, 64, 3, 3]            --
│    └─Empty: 2-2273                     [64, 64, 3, 3]            --
│    └─Empty: 2-2274                     [64]                      --
│    └─Empty: 2-2275                     [64]                      --
│    └─BatchNorm2d: 2-2276               [16, 64, 2, 2]            --
│    └─Scaler: 2-2277                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2278                      [16, 64, 2, 2]            --
│    └─Empty: 2-2279                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2280                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2281        --                        --
│    └─One: 2-2282                       [1]                       --
│    └─OutputScale: 2-2283               --                        --
│    └─Empty: 2-2284                     [64, 48, 1, 1]            --
│    └─Empty: 2-2285                     [64, 48, 1, 1]            --
│    └─Empty: 2-2286                     [64]                      --
│    └─Empty: 2-2287                     [64]                      --
│    └─BatchNorm2d: 2-2288               [16, 64, 64, 64]          --
│    └─Scaler: 2-2289                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2290                      [16, 64, 64, 64]          --
│    └─Empty: 2-2291                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2292                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2293        --                        --
│    └─One: 2-2294                       [1]                       --
│    └─OutputScale: 2-2295               --                        --
│    └─Empty: 2-2296                     [64, 64, 3, 3]            --
│    └─Empty: 2-2297                     [64, 64, 3, 3]            --
│    └─Empty: 2-2298                     [64]                      --
│    └─Empty: 2-2299                     [64]                      --
│    └─BatchNorm2d: 2-2300               [16, 64, 64, 64]          --
│    └─Scaler: 2-2301                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2302                      [16, 64, 64, 64]          --
│    └─Empty: 2-2303                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2304                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2305        --                        --
│    └─One: 2-2306                       [1]                       --
│    └─OutputScale: 2-2307               --                        --
│    └─Empty: 2-2308                     [64, 64, 1, 1]            --
│    └─Empty: 2-2309                     [64, 64, 1, 1]            --
│    └─Empty: 2-2310                     [64]                      --
│    └─Empty: 2-2311                     [64]                      --
│    └─BatchNorm2d: 2-2312               [16, 64, 64, 64]          --
│    └─Scaler: 2-2313                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2314                      [16, 64, 64, 64]          --
│    └─Empty: 2-2315                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2316                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2317        --                        --
│    └─One: 2-2318                       [1]                       --
│    └─OutputScale: 2-2319               --                        --
│    └─Empty: 2-2320                     [64, 64, 3, 3]            --
│    └─Empty: 2-2321                     [64, 64, 3, 3]            --
│    └─Empty: 2-2322                     [64]                      --
│    └─Empty: 2-2323                     [64]                      --
│    └─BatchNorm2d: 2-2324               [16, 64, 64, 64]          --
│    └─Scaler: 2-2325                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2326                      [16, 64, 64, 64]          --
│    └─Empty: 2-2327                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2328                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2329                 [16, 64, 32, 32]          --
│    └─Empty: 2-2330                     [16, 64, 32, 32]          --
│    └─Empty: 2-2331                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2332        --                        --
│    └─One: 2-2333                       [1]                       --
│    └─OutputScale: 2-2334               --                        --
│    └─Empty: 2-2335                     [64, 64, 3, 3]            --
│    └─Empty: 2-2336                     [64, 64, 3, 3]            --
│    └─Empty: 2-2337                     [64]                      --
│    └─Empty: 2-2338                     [64]                      --
│    └─BatchNorm2d: 2-2339               [16, 64, 32, 32]          --
│    └─Scaler: 2-2340                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2341                      [16, 64, 32, 32]          --
│    └─Empty: 2-2342                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2343                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2344        --                        --
│    └─One: 2-2345                       [1]                       --
│    └─OutputScale: 2-2346               --                        --
│    └─Empty: 2-2347                     [64, 64, 3, 3]            --
│    └─Empty: 2-2348                     [64, 64, 3, 3]            --
│    └─Empty: 2-2349                     [64]                      --
│    └─Empty: 2-2350                     [64]                      --
│    └─BatchNorm2d: 2-2351               [16, 64, 32, 32]          --
│    └─Scaler: 2-2352                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2353                      [16, 64, 32, 32]          --
│    └─Empty: 2-2354                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2355                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2356                 [16, 64, 16, 16]          --
│    └─Empty: 2-2357                     [16, 64, 16, 16]          --
│    └─Empty: 2-2358                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2359        --                        --
│    └─One: 2-2360                       [1]                       --
│    └─OutputScale: 2-2361               --                        --
│    └─Empty: 2-2362                     [64, 64, 3, 3]            --
│    └─Empty: 2-2363                     [64, 64, 3, 3]            --
│    └─Empty: 2-2364                     [64]                      --
│    └─Empty: 2-2365                     [64]                      --
│    └─BatchNorm2d: 2-2366               [16, 64, 16, 16]          --
│    └─Scaler: 2-2367                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2368                      [16, 64, 16, 16]          --
│    └─Empty: 2-2369                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2370                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2371        --                        --
│    └─One: 2-2372                       [1]                       --
│    └─OutputScale: 2-2373               --                        --
│    └─Empty: 2-2374                     [64, 64, 3, 3]            --
│    └─Empty: 2-2375                     [64, 64, 3, 3]            --
│    └─Empty: 2-2376                     [64]                      --
│    └─Empty: 2-2377                     [64]                      --
│    └─BatchNorm2d: 2-2378               [16, 64, 16, 16]          --
│    └─Scaler: 2-2379                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2380                      [16, 64, 16, 16]          --
│    └─Empty: 2-2381                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2382                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2383                 [16, 64, 8, 8]            --
│    └─Empty: 2-2384                     [16, 64, 8, 8]            --
│    └─Empty: 2-2385                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2386        --                        --
│    └─One: 2-2387                       [1]                       --
│    └─OutputScale: 2-2388               --                        --
│    └─Empty: 2-2389                     [64, 64, 3, 3]            --
│    └─Empty: 2-2390                     [64, 64, 3, 3]            --
│    └─Empty: 2-2391                     [64]                      --
│    └─Empty: 2-2392                     [64]                      --
│    └─BatchNorm2d: 2-2393               [16, 64, 8, 8]            --
│    └─Scaler: 2-2394                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2395                      [16, 64, 8, 8]            --
│    └─Empty: 2-2396                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2397                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2398        --                        --
│    └─One: 2-2399                       [1]                       --
│    └─OutputScale: 2-2400               --                        --
│    └─Empty: 2-2401                     [64, 64, 1, 1]            --
│    └─Empty: 2-2402                     [64, 64, 1, 1]            --
│    └─Empty: 2-2403                     [64]                      --
│    └─Empty: 2-2404                     [64]                      --
│    └─BatchNorm2d: 2-2405               [16, 64, 8, 8]            --
│    └─Scaler: 2-2406                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2407                      [16, 64, 8, 8]            --
│    └─Empty: 2-2408                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2409                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2410                 [16, 64, 8, 8]            --
│    └─Empty: 2-2411                     [16, 64, 8, 8]            --
│    └─Empty: 2-2412                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2413        --                        --
│    └─One: 2-2414                       [1]                       --
│    └─OutputScale: 2-2415               --                        --
│    └─Empty: 2-2416                     [64, 64, 3, 3]            --
│    └─Empty: 2-2417                     [64, 64, 3, 3]            --
│    └─Empty: 2-2418                     [64]                      --
│    └─Empty: 2-2419                     [64]                      --
│    └─BatchNorm2d: 2-2420               [16, 64, 8, 8]            --
│    └─Scaler: 2-2421                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2422                      [16, 64, 8, 8]            --
│    └─Empty: 2-2423                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2424                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2425                 [16, 64, 4, 4]            --
│    └─Empty: 2-2426                     [16, 64, 4, 4]            --
│    └─Empty: 2-2427                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2428        --                        --
│    └─One: 2-2429                       [1]                       --
│    └─OutputScale: 2-2430               --                        --
│    └─Empty: 2-2431                     [64, 64, 3, 3]            --
│    └─Empty: 2-2432                     [64, 64, 3, 3]            --
│    └─Empty: 2-2433                     [64]                      --
│    └─Empty: 2-2434                     [64]                      --
│    └─BatchNorm2d: 2-2435               [16, 64, 4, 4]            --
│    └─Scaler: 2-2436                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2437                      [16, 64, 4, 4]            --
│    └─Empty: 2-2438                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2439                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2440        --                        --
│    └─One: 2-2441                       [1]                       --
│    └─OutputScale: 2-2442               --                        --
│    └─Empty: 2-2443                     [64, 64, 1, 1]            --
│    └─Empty: 2-2444                     [64, 64, 1, 1]            --
│    └─Empty: 2-2445                     [64]                      --
│    └─Empty: 2-2446                     [64]                      --
│    └─BatchNorm2d: 2-2447               [16, 64, 4, 4]            --
│    └─Scaler: 2-2448                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2449                      [16, 64, 4, 4]            --
│    └─Empty: 2-2450                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2451                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2452                 [16, 64, 4, 4]            --
│    └─Empty: 2-2453                     [16, 64, 4, 4]            --
│    └─Empty: 2-2454                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2455        --                        --
│    └─One: 2-2456                       [1]                       --
│    └─OutputScale: 2-2457               --                        --
│    └─Empty: 2-2458                     [64, 64, 3, 3]            --
│    └─Empty: 2-2459                     [64, 64, 3, 3]            --
│    └─Empty: 2-2460                     [64]                      --
│    └─Empty: 2-2461                     [64]                      --
│    └─BatchNorm2d: 2-2462               [16, 64, 4, 4]            --
│    └─Scaler: 2-2463                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2464                      [16, 64, 4, 4]            --
│    └─Empty: 2-2465                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2466                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2467                 [16, 64, 2, 2]            --
│    └─Empty: 2-2468                     [16, 64, 2, 2]            --
│    └─Empty: 2-2469                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2470        --                        --
│    └─One: 2-2471                       [1]                       --
│    └─OutputScale: 2-2472               --                        --
│    └─Empty: 2-2473                     [64, 64, 1, 1]            --
│    └─Empty: 2-2474                     [64, 64, 1, 1]            --
│    └─Empty: 2-2475                     [64]                      --
│    └─Empty: 2-2476                     [64]                      --
│    └─BatchNorm2d: 2-2477               [16, 64, 2, 2]            --
│    └─Scaler: 2-2478                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2479                      [16, 64, 2, 2]            --
│    └─Empty: 2-2480                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2481                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2482        --                        --
│    └─One: 2-2483                       [1]                       --
│    └─OutputScale: 2-2484               --                        --
│    └─Empty: 2-2485                     [64, 64, 1, 1]            --
│    └─Empty: 2-2486                     [64, 64, 1, 1]            --
│    └─Empty: 2-2487                     [64]                      --
│    └─Empty: 2-2488                     [64]                      --
│    └─BatchNorm2d: 2-2489               [16, 64, 2, 2]            --
│    └─Scaler: 2-2490                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2491                      [16, 64, 2, 2]            --
│    └─Empty: 2-2492                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2493                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2494                 [16, 64, 2, 2]            --
│    └─Empty: 2-2495                     [16, 64, 2, 2]            --
│    └─Empty: 2-2496                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2497        --                        --
│    └─One: 2-2498                       [1]                       --
│    └─OutputScale: 2-2499               --                        --
│    └─Empty: 2-2500                     [64, 64, 3, 3]            --
│    └─Empty: 2-2501                     [64, 64, 3, 3]            --
│    └─Empty: 2-2502                     [64]                      --
│    └─Empty: 2-2503                     [64]                      --
│    └─BatchNorm2d: 2-2504               [16, 64, 2, 2]            --
│    └─Scaler: 2-2505                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2506                      [16, 64, 2, 2]            --
│    └─Empty: 2-2507                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2508                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2509        --                        --
│    └─One: 2-2510                       [1]                       --
│    └─OutputScale: 2-2511               --                        --
│    └─Empty: 2-2512                     [64, 48, 1, 1]            --
│    └─Empty: 2-2513                     [64, 48, 1, 1]            --
│    └─Empty: 2-2514                     [64]                      --
│    └─Empty: 2-2515                     [64]                      --
│    └─BatchNorm2d: 2-2516               [16, 64, 64, 64]          --
│    └─Scaler: 2-2517                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2518                      [16, 64, 64, 64]          --
│    └─Empty: 2-2519                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2520                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2521        --                        --
│    └─One: 2-2522                       [1]                       --
│    └─OutputScale: 2-2523               --                        --
│    └─Empty: 2-2524                     [64, 64, 3, 3]            --
│    └─Empty: 2-2525                     [64, 64, 3, 3]            --
│    └─Empty: 2-2526                     [64]                      --
│    └─Empty: 2-2527                     [64]                      --
│    └─BatchNorm2d: 2-2528               [16, 64, 64, 64]          --
│    └─Scaler: 2-2529                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2530                      [16, 64, 64, 64]          --
│    └─Empty: 2-2531                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2532                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2533        --                        --
│    └─One: 2-2534                       [1]                       --
│    └─OutputScale: 2-2535               --                        --
│    └─Empty: 2-2536                     [64, 64, 1, 1]            --
│    └─Empty: 2-2537                     [64, 64, 1, 1]            --
│    └─Empty: 2-2538                     [64]                      --
│    └─Empty: 2-2539                     [64]                      --
│    └─BatchNorm2d: 2-2540               [16, 64, 64, 64]          --
│    └─Scaler: 2-2541                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2542                      [16, 64, 64, 64]          --
│    └─Empty: 2-2543                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2544                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2545        --                        --
│    └─One: 2-2546                       [1]                       --
│    └─OutputScale: 2-2547               --                        --
│    └─Empty: 2-2548                     [64, 64, 3, 3]            --
│    └─Empty: 2-2549                     [64, 64, 3, 3]            --
│    └─Empty: 2-2550                     [64]                      --
│    └─Empty: 2-2551                     [64]                      --
│    └─BatchNorm2d: 2-2552               [16, 64, 64, 64]          --
│    └─Scaler: 2-2553                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2554                      [16, 64, 64, 64]          --
│    └─Empty: 2-2555                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2556                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2557                 [16, 64, 32, 32]          --
│    └─Empty: 2-2558                     [16, 64, 32, 32]          --
│    └─Empty: 2-2559                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2560        --                        --
│    └─One: 2-2561                       [1]                       --
│    └─OutputScale: 2-2562               --                        --
│    └─Empty: 2-2563                     [64, 64, 3, 3]            --
│    └─Empty: 2-2564                     [64, 64, 3, 3]            --
│    └─Empty: 2-2565                     [64]                      --
│    └─Empty: 2-2566                     [64]                      --
│    └─BatchNorm2d: 2-2567               [16, 64, 32, 32]          --
│    └─Scaler: 2-2568                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2569                      [16, 64, 32, 32]          --
│    └─Empty: 2-2570                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2571                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2572        --                        --
│    └─One: 2-2573                       [1]                       --
│    └─OutputScale: 2-2574               --                        --
│    └─Empty: 2-2575                     [64, 64, 3, 3]            --
│    └─Empty: 2-2576                     [64, 64, 3, 3]            --
│    └─Empty: 2-2577                     [64]                      --
│    └─Empty: 2-2578                     [64]                      --
│    └─BatchNorm2d: 2-2579               [16, 64, 32, 32]          --
│    └─Scaler: 2-2580                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2581                      [16, 64, 32, 32]          --
│    └─Empty: 2-2582                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2583                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2584                 [16, 64, 16, 16]          --
│    └─Empty: 2-2585                     [16, 64, 16, 16]          --
│    └─Empty: 2-2586                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2587        --                        --
│    └─One: 2-2588                       [1]                       --
│    └─OutputScale: 2-2589               --                        --
│    └─Empty: 2-2590                     [64, 64, 3, 3]            --
│    └─Empty: 2-2591                     [64, 64, 3, 3]            --
│    └─Empty: 2-2592                     [64]                      --
│    └─Empty: 2-2593                     [64]                      --
│    └─BatchNorm2d: 2-2594               [16, 64, 16, 16]          --
│    └─Scaler: 2-2595                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2596                      [16, 64, 16, 16]          --
│    └─Empty: 2-2597                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2598                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2599        --                        --
│    └─One: 2-2600                       [1]                       --
│    └─OutputScale: 2-2601               --                        --
│    └─Empty: 2-2602                     [64, 64, 3, 3]            --
│    └─Empty: 2-2603                     [64, 64, 3, 3]            --
│    └─Empty: 2-2604                     [64]                      --
│    └─Empty: 2-2605                     [64]                      --
│    └─BatchNorm2d: 2-2606               [16, 64, 16, 16]          --
│    └─Scaler: 2-2607                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2608                      [16, 64, 16, 16]          --
│    └─Empty: 2-2609                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2610                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2611                 [16, 64, 8, 8]            --
│    └─Empty: 2-2612                     [16, 64, 8, 8]            --
│    └─Empty: 2-2613                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2614        --                        --
│    └─One: 2-2615                       [1]                       --
│    └─OutputScale: 2-2616               --                        --
│    └─Empty: 2-2617                     [64, 64, 3, 3]            --
│    └─Empty: 2-2618                     [64, 64, 3, 3]            --
│    └─Empty: 2-2619                     [64]                      --
│    └─Empty: 2-2620                     [64]                      --
│    └─BatchNorm2d: 2-2621               [16, 64, 8, 8]            --
│    └─Scaler: 2-2622                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2623                      [16, 64, 8, 8]            --
│    └─Empty: 2-2624                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2625                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2626        --                        --
│    └─One: 2-2627                       [1]                       --
│    └─OutputScale: 2-2628               --                        --
│    └─Empty: 2-2629                     [64, 64, 1, 1]            --
│    └─Empty: 2-2630                     [64, 64, 1, 1]            --
│    └─Empty: 2-2631                     [64]                      --
│    └─Empty: 2-2632                     [64]                      --
│    └─BatchNorm2d: 2-2633               [16, 64, 8, 8]            --
│    └─Scaler: 2-2634                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2635                      [16, 64, 8, 8]            --
│    └─Empty: 2-2636                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2637                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2638                 [16, 64, 8, 8]            --
│    └─Empty: 2-2639                     [16, 64, 8, 8]            --
│    └─Empty: 2-2640                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2641        --                        --
│    └─One: 2-2642                       [1]                       --
│    └─OutputScale: 2-2643               --                        --
│    └─Empty: 2-2644                     [64, 64, 3, 3]            --
│    └─Empty: 2-2645                     [64, 64, 3, 3]            --
│    └─Empty: 2-2646                     [64]                      --
│    └─Empty: 2-2647                     [64]                      --
│    └─BatchNorm2d: 2-2648               [16, 64, 8, 8]            --
│    └─Scaler: 2-2649                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2650                      [16, 64, 8, 8]            --
│    └─Empty: 2-2651                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2652                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2653                 [16, 64, 4, 4]            --
│    └─Empty: 2-2654                     [16, 64, 4, 4]            --
│    └─Empty: 2-2655                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2656        --                        --
│    └─One: 2-2657                       [1]                       --
│    └─OutputScale: 2-2658               --                        --
│    └─Empty: 2-2659                     [64, 64, 3, 3]            --
│    └─Empty: 2-2660                     [64, 64, 3, 3]            --
│    └─Empty: 2-2661                     [64]                      --
│    └─Empty: 2-2662                     [64]                      --
│    └─BatchNorm2d: 2-2663               [16, 64, 4, 4]            --
│    └─Scaler: 2-2664                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2665                      [16, 64, 4, 4]            --
│    └─Empty: 2-2666                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2667                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2668        --                        --
│    └─One: 2-2669                       [1]                       --
│    └─OutputScale: 2-2670               --                        --
│    └─Empty: 2-2671                     [64, 64, 1, 1]            --
│    └─Empty: 2-2672                     [64, 64, 1, 1]            --
│    └─Empty: 2-2673                     [64]                      --
│    └─Empty: 2-2674                     [64]                      --
│    └─BatchNorm2d: 2-2675               [16, 64, 4, 4]            --
│    └─Scaler: 2-2676                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2677                      [16, 64, 4, 4]            --
│    └─Empty: 2-2678                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2679                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2680                 [16, 64, 4, 4]            --
│    └─Empty: 2-2681                     [16, 64, 4, 4]            --
│    └─Empty: 2-2682                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2683        --                        --
│    └─One: 2-2684                       [1]                       --
│    └─OutputScale: 2-2685               --                        --
│    └─Empty: 2-2686                     [64, 64, 3, 3]            --
│    └─Empty: 2-2687                     [64, 64, 3, 3]            --
│    └─Empty: 2-2688                     [64]                      --
│    └─Empty: 2-2689                     [64]                      --
│    └─BatchNorm2d: 2-2690               [16, 64, 4, 4]            --
│    └─Scaler: 2-2691                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2692                      [16, 64, 4, 4]            --
│    └─Empty: 2-2693                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2694                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2695                 [16, 64, 2, 2]            --
│    └─Empty: 2-2696                     [16, 64, 2, 2]            --
│    └─Empty: 2-2697                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2698        --                        --
│    └─One: 2-2699                       [1]                       --
│    └─OutputScale: 2-2700               --                        --
│    └─Empty: 2-2701                     [64, 64, 1, 1]            --
│    └─Empty: 2-2702                     [64, 64, 1, 1]            --
│    └─Empty: 2-2703                     [64]                      --
│    └─Empty: 2-2704                     [64]                      --
│    └─BatchNorm2d: 2-2705               [16, 64, 2, 2]            --
│    └─Scaler: 2-2706                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2707                      [16, 64, 2, 2]            --
│    └─Empty: 2-2708                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2709                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2710        --                        --
│    └─One: 2-2711                       [1]                       --
│    └─OutputScale: 2-2712               --                        --
│    └─Empty: 2-2713                     [64, 64, 1, 1]            --
│    └─Empty: 2-2714                     [64, 64, 1, 1]            --
│    └─Empty: 2-2715                     [64]                      --
│    └─Empty: 2-2716                     [64]                      --
│    └─BatchNorm2d: 2-2717               [16, 64, 2, 2]            --
│    └─Scaler: 2-2718                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2719                      [16, 64, 2, 2]            --
│    └─Empty: 2-2720                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2721                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2722                 [16, 64, 2, 2]            --
│    └─Empty: 2-2723                     [16, 64, 2, 2]            --
│    └─Empty: 2-2724                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2725        --                        --
│    └─One: 2-2726                       [1]                       --
│    └─OutputScale: 2-2727               --                        --
│    └─Empty: 2-2728                     [64, 64, 3, 3]            --
│    └─Empty: 2-2729                     [64, 64, 3, 3]            --
│    └─Empty: 2-2730                     [64]                      --
│    └─Empty: 2-2731                     [64]                      --
│    └─BatchNorm2d: 2-2732               [16, 64, 2, 2]            --
│    └─Scaler: 2-2733                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2734                      [16, 64, 2, 2]            --
│    └─Empty: 2-2735                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2736                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2737        --                        --
│    └─One: 2-2738                       [1]                       --
│    └─OutputScale: 2-2739               --                        --
│    └─Empty: 2-2740                     [64, 48, 1, 1]            --
│    └─Empty: 2-2741                     [64, 48, 1, 1]            --
│    └─Empty: 2-2742                     [64]                      --
│    └─Empty: 2-2743                     [64]                      --
│    └─BatchNorm2d: 2-2744               [16, 64, 64, 64]          --
│    └─Scaler: 2-2745                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2746                      [16, 64, 64, 64]          --
│    └─Empty: 2-2747                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2748                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2749        --                        --
│    └─One: 2-2750                       [1]                       --
│    └─OutputScale: 2-2751               --                        --
│    └─Empty: 2-2752                     [64, 64, 3, 3]            --
│    └─Empty: 2-2753                     [64, 64, 3, 3]            --
│    └─Empty: 2-2754                     [64]                      --
│    └─Empty: 2-2755                     [64]                      --
│    └─BatchNorm2d: 2-2756               [16, 64, 64, 64]          --
│    └─Scaler: 2-2757                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2758                      [16, 64, 64, 64]          --
│    └─Empty: 2-2759                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2760                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2761        --                        --
│    └─One: 2-2762                       [1]                       --
│    └─OutputScale: 2-2763               --                        --
│    └─Empty: 2-2764                     [64, 64, 1, 1]            --
│    └─Empty: 2-2765                     [64, 64, 1, 1]            --
│    └─Empty: 2-2766                     [64]                      --
│    └─Empty: 2-2767                     [64]                      --
│    └─BatchNorm2d: 2-2768               [16, 64, 64, 64]          --
│    └─Scaler: 2-2769                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2770                      [16, 64, 64, 64]          --
│    └─Empty: 2-2771                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2772                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2773        --                        --
│    └─One: 2-2774                       [1]                       --
│    └─OutputScale: 2-2775               --                        --
│    └─Empty: 2-2776                     [64, 64, 3, 3]            --
│    └─Empty: 2-2777                     [64, 64, 3, 3]            --
│    └─Empty: 2-2778                     [64]                      --
│    └─Empty: 2-2779                     [64]                      --
│    └─BatchNorm2d: 2-2780               [16, 64, 64, 64]          --
│    └─Scaler: 2-2781                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2782                      [16, 64, 64, 64]          --
│    └─Empty: 2-2783                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2784                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2785                 [16, 64, 32, 32]          --
│    └─Empty: 2-2786                     [16, 64, 32, 32]          --
│    └─Empty: 2-2787                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2788        --                        --
│    └─One: 2-2789                       [1]                       --
│    └─OutputScale: 2-2790               --                        --
│    └─Empty: 2-2791                     [64, 64, 3, 3]            --
│    └─Empty: 2-2792                     [64, 64, 3, 3]            --
│    └─Empty: 2-2793                     [64]                      --
│    └─Empty: 2-2794                     [64]                      --
│    └─BatchNorm2d: 2-2795               [16, 64, 32, 32]          --
│    └─Scaler: 2-2796                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2797                      [16, 64, 32, 32]          --
│    └─Empty: 2-2798                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2799                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2800        --                        --
│    └─One: 2-2801                       [1]                       --
│    └─OutputScale: 2-2802               --                        --
│    └─Empty: 2-2803                     [64, 64, 3, 3]            --
│    └─Empty: 2-2804                     [64, 64, 3, 3]            --
│    └─Empty: 2-2805                     [64]                      --
│    └─Empty: 2-2806                     [64]                      --
│    └─BatchNorm2d: 2-2807               [16, 64, 32, 32]          --
│    └─Scaler: 2-2808                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2809                      [16, 64, 32, 32]          --
│    └─Empty: 2-2810                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2811                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2812                 [16, 64, 16, 16]          --
│    └─Empty: 2-2813                     [16, 64, 16, 16]          --
│    └─Empty: 2-2814                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2815        --                        --
│    └─One: 2-2816                       [1]                       --
│    └─OutputScale: 2-2817               --                        --
│    └─Empty: 2-2818                     [64, 64, 3, 3]            --
│    └─Empty: 2-2819                     [64, 64, 3, 3]            --
│    └─Empty: 2-2820                     [64]                      --
│    └─Empty: 2-2821                     [64]                      --
│    └─BatchNorm2d: 2-2822               [16, 64, 16, 16]          --
│    └─Scaler: 2-2823                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2824                      [16, 64, 16, 16]          --
│    └─Empty: 2-2825                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2826                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2827        --                        --
│    └─One: 2-2828                       [1]                       --
│    └─OutputScale: 2-2829               --                        --
│    └─Empty: 2-2830                     [64, 64, 3, 3]            --
│    └─Empty: 2-2831                     [64, 64, 3, 3]            --
│    └─Empty: 2-2832                     [64]                      --
│    └─Empty: 2-2833                     [64]                      --
│    └─BatchNorm2d: 2-2834               [16, 64, 16, 16]          --
│    └─Scaler: 2-2835                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2836                      [16, 64, 16, 16]          --
│    └─Empty: 2-2837                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2838                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2839                 [16, 64, 8, 8]            --
│    └─Empty: 2-2840                     [16, 64, 8, 8]            --
│    └─Empty: 2-2841                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2842        --                        --
│    └─One: 2-2843                       [1]                       --
│    └─OutputScale: 2-2844               --                        --
│    └─Empty: 2-2845                     [64, 64, 3, 3]            --
│    └─Empty: 2-2846                     [64, 64, 3, 3]            --
│    └─Empty: 2-2847                     [64]                      --
│    └─Empty: 2-2848                     [64]                      --
│    └─BatchNorm2d: 2-2849               [16, 64, 8, 8]            --
│    └─Scaler: 2-2850                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2851                      [16, 64, 8, 8]            --
│    └─Empty: 2-2852                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2853                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2854        --                        --
│    └─One: 2-2855                       [1]                       --
│    └─OutputScale: 2-2856               --                        --
│    └─Empty: 2-2857                     [64, 64, 1, 1]            --
│    └─Empty: 2-2858                     [64, 64, 1, 1]            --
│    └─Empty: 2-2859                     [64]                      --
│    └─Empty: 2-2860                     [64]                      --
│    └─BatchNorm2d: 2-2861               [16, 64, 8, 8]            --
│    └─Scaler: 2-2862                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2863                      [16, 64, 8, 8]            --
│    └─Empty: 2-2864                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2865                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2866                 [16, 64, 8, 8]            --
│    └─Empty: 2-2867                     [16, 64, 8, 8]            --
│    └─Empty: 2-2868                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2869        --                        --
│    └─One: 2-2870                       [1]                       --
│    └─OutputScale: 2-2871               --                        --
│    └─Empty: 2-2872                     [64, 64, 3, 3]            --
│    └─Empty: 2-2873                     [64, 64, 3, 3]            --
│    └─Empty: 2-2874                     [64]                      --
│    └─Empty: 2-2875                     [64]                      --
│    └─BatchNorm2d: 2-2876               [16, 64, 8, 8]            --
│    └─Scaler: 2-2877                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2878                      [16, 64, 8, 8]            --
│    └─Empty: 2-2879                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2880                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2881                 [16, 64, 4, 4]            --
│    └─Empty: 2-2882                     [16, 64, 4, 4]            --
│    └─Empty: 2-2883                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2884        --                        --
│    └─One: 2-2885                       [1]                       --
│    └─OutputScale: 2-2886               --                        --
│    └─Empty: 2-2887                     [64, 64, 3, 3]            --
│    └─Empty: 2-2888                     [64, 64, 3, 3]            --
│    └─Empty: 2-2889                     [64]                      --
│    └─Empty: 2-2890                     [64]                      --
│    └─BatchNorm2d: 2-2891               [16, 64, 4, 4]            --
│    └─Scaler: 2-2892                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2893                      [16, 64, 4, 4]            --
│    └─Empty: 2-2894                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2895                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2896        --                        --
│    └─One: 2-2897                       [1]                       --
│    └─OutputScale: 2-2898               --                        --
│    └─Empty: 2-2899                     [64, 64, 1, 1]            --
│    └─Empty: 2-2900                     [64, 64, 1, 1]            --
│    └─Empty: 2-2901                     [64]                      --
│    └─Empty: 2-2902                     [64]                      --
│    └─BatchNorm2d: 2-2903               [16, 64, 4, 4]            --
│    └─Scaler: 2-2904                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2905                      [16, 64, 4, 4]            --
│    └─Empty: 2-2906                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2907                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2908                 [16, 64, 4, 4]            --
│    └─Empty: 2-2909                     [16, 64, 4, 4]            --
│    └─Empty: 2-2910                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2911        --                        --
│    └─One: 2-2912                       [1]                       --
│    └─OutputScale: 2-2913               --                        --
│    └─Empty: 2-2914                     [64, 64, 3, 3]            --
│    └─Empty: 2-2915                     [64, 64, 3, 3]            --
│    └─Empty: 2-2916                     [64]                      --
│    └─Empty: 2-2917                     [64]                      --
│    └─BatchNorm2d: 2-2918               [16, 64, 4, 4]            --
│    └─Scaler: 2-2919                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2920                      [16, 64, 4, 4]            --
│    └─Empty: 2-2921                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2922                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2923                 [16, 64, 2, 2]            --
│    └─Empty: 2-2924                     [16, 64, 2, 2]            --
│    └─Empty: 2-2925                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2926        --                        --
│    └─One: 2-2927                       [1]                       --
│    └─OutputScale: 2-2928               --                        --
│    └─Empty: 2-2929                     [64, 64, 1, 1]            --
│    └─Empty: 2-2930                     [64, 64, 1, 1]            --
│    └─Empty: 2-2931                     [64]                      --
│    └─Empty: 2-2932                     [64]                      --
│    └─BatchNorm2d: 2-2933               [16, 64, 2, 2]            --
│    └─Scaler: 2-2934                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2935                      [16, 64, 2, 2]            --
│    └─Empty: 2-2936                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2937                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2938        --                        --
│    └─One: 2-2939                       [1]                       --
│    └─OutputScale: 2-2940               --                        --
│    └─Empty: 2-2941                     [64, 64, 1, 1]            --
│    └─Empty: 2-2942                     [64, 64, 1, 1]            --
│    └─Empty: 2-2943                     [64]                      --
│    └─Empty: 2-2944                     [64]                      --
│    └─BatchNorm2d: 2-2945               [16, 64, 2, 2]            --
│    └─Scaler: 2-2946                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2947                      [16, 64, 2, 2]            --
│    └─Empty: 2-2948                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2949                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2950                 [16, 64, 2, 2]            --
│    └─Empty: 2-2951                     [16, 64, 2, 2]            --
│    └─Empty: 2-2952                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2953        --                        --
│    └─One: 2-2954                       [1]                       --
│    └─OutputScale: 2-2955               --                        --
│    └─Empty: 2-2956                     [64, 64, 3, 3]            --
│    └─Empty: 2-2957                     [64, 64, 3, 3]            --
│    └─Empty: 2-2958                     [64]                      --
│    └─Empty: 2-2959                     [64]                      --
│    └─BatchNorm2d: 2-2960               [16, 64, 2, 2]            --
│    └─Scaler: 2-2961                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2962                      [16, 64, 2, 2]            --
│    └─Empty: 2-2963                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2964                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2965        --                        --
│    └─One: 2-2966                       [1]                       --
│    └─OutputScale: 2-2967               --                        --
│    └─Empty: 2-2968                     [64, 48, 1, 1]            --
│    └─Empty: 2-2969                     [64, 48, 1, 1]            --
│    └─Empty: 2-2970                     [64]                      --
│    └─Empty: 2-2971                     [64]                      --
│    └─BatchNorm2d: 2-2972               [16, 64, 64, 64]          --
│    └─Scaler: 2-2973                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2974                      [16, 64, 64, 64]          --
│    └─Empty: 2-2975                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2976                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2977        --                        --
│    └─One: 2-2978                       [1]                       --
│    └─OutputScale: 2-2979               --                        --
│    └─Empty: 2-2980                     [64, 64, 3, 3]            --
│    └─Empty: 2-2981                     [64, 64, 3, 3]            --
│    └─Empty: 2-2982                     [64]                      --
│    └─Empty: 2-2983                     [64]                      --
│    └─BatchNorm2d: 2-2984               [16, 64, 64, 64]          --
│    └─Scaler: 2-2985                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2986                      [16, 64, 64, 64]          --
│    └─Empty: 2-2987                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2988                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2989        --                        --
│    └─One: 2-2990                       [1]                       --
│    └─OutputScale: 2-2991               --                        --
│    └─Empty: 2-2992                     [64, 64, 1, 1]            --
│    └─Empty: 2-2993                     [64, 64, 1, 1]            --
│    └─Empty: 2-2994                     [64]                      --
│    └─Empty: 2-2995                     [64]                      --
│    └─BatchNorm2d: 2-2996               [16, 64, 64, 64]          --
│    └─Scaler: 2-2997                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2998                      [16, 64, 64, 64]          --
│    └─Empty: 2-2999                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3000                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3001        --                        --
│    └─One: 2-3002                       [1]                       --
│    └─OutputScale: 2-3003               --                        --
│    └─Empty: 2-3004                     [64, 64, 3, 3]            --
│    └─Empty: 2-3005                     [64, 64, 3, 3]            --
│    └─Empty: 2-3006                     [64]                      --
│    └─Empty: 2-3007                     [64]                      --
│    └─BatchNorm2d: 2-3008               [16, 64, 64, 64]          --
│    └─Scaler: 2-3009                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3010                      [16, 64, 64, 64]          --
│    └─Empty: 2-3011                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3012                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3013                 [16, 64, 32, 32]          --
│    └─Empty: 2-3014                     [16, 64, 32, 32]          --
│    └─Empty: 2-3015                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3016        --                        --
│    └─One: 2-3017                       [1]                       --
│    └─OutputScale: 2-3018               --                        --
│    └─Empty: 2-3019                     [64, 64, 3, 3]            --
│    └─Empty: 2-3020                     [64, 64, 3, 3]            --
│    └─Empty: 2-3021                     [64]                      --
│    └─Empty: 2-3022                     [64]                      --
│    └─BatchNorm2d: 2-3023               [16, 64, 32, 32]          --
│    └─Scaler: 2-3024                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3025                      [16, 64, 32, 32]          --
│    └─Empty: 2-3026                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3027                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3028        --                        --
│    └─One: 2-3029                       [1]                       --
│    └─OutputScale: 2-3030               --                        --
│    └─Empty: 2-3031                     [64, 64, 3, 3]            --
│    └─Empty: 2-3032                     [64, 64, 3, 3]            --
│    └─Empty: 2-3033                     [64]                      --
│    └─Empty: 2-3034                     [64]                      --
│    └─BatchNorm2d: 2-3035               [16, 64, 32, 32]          --
│    └─Scaler: 2-3036                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3037                      [16, 64, 32, 32]          --
│    └─Empty: 2-3038                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3039                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3040                 [16, 64, 16, 16]          --
│    └─Empty: 2-3041                     [16, 64, 16, 16]          --
│    └─Empty: 2-3042                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3043        --                        --
│    └─One: 2-3044                       [1]                       --
│    └─OutputScale: 2-3045               --                        --
│    └─Empty: 2-3046                     [64, 64, 3, 3]            --
│    └─Empty: 2-3047                     [64, 64, 3, 3]            --
│    └─Empty: 2-3048                     [64]                      --
│    └─Empty: 2-3049                     [64]                      --
│    └─BatchNorm2d: 2-3050               [16, 64, 16, 16]          --
│    └─Scaler: 2-3051                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3052                      [16, 64, 16, 16]          --
│    └─Empty: 2-3053                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3054                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3055        --                        --
│    └─One: 2-3056                       [1]                       --
│    └─OutputScale: 2-3057               --                        --
│    └─Empty: 2-3058                     [64, 64, 3, 3]            --
│    └─Empty: 2-3059                     [64, 64, 3, 3]            --
│    └─Empty: 2-3060                     [64]                      --
│    └─Empty: 2-3061                     [64]                      --
│    └─BatchNorm2d: 2-3062               [16, 64, 16, 16]          --
│    └─Scaler: 2-3063                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3064                      [16, 64, 16, 16]          --
│    └─Empty: 2-3065                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3066                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3067                 [16, 64, 8, 8]            --
│    └─Empty: 2-3068                     [16, 64, 8, 8]            --
│    └─Empty: 2-3069                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3070        --                        --
│    └─One: 2-3071                       [1]                       --
│    └─OutputScale: 2-3072               --                        --
│    └─Empty: 2-3073                     [64, 64, 3, 3]            --
│    └─Empty: 2-3074                     [64, 64, 3, 3]            --
│    └─Empty: 2-3075                     [64]                      --
│    └─Empty: 2-3076                     [64]                      --
│    └─BatchNorm2d: 2-3077               [16, 64, 8, 8]            --
│    └─Scaler: 2-3078                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3079                      [16, 64, 8, 8]            --
│    └─Empty: 2-3080                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3081                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3082        --                        --
│    └─One: 2-3083                       [1]                       --
│    └─OutputScale: 2-3084               --                        --
│    └─Empty: 2-3085                     [64, 64, 1, 1]            --
│    └─Empty: 2-3086                     [64, 64, 1, 1]            --
│    └─Empty: 2-3087                     [64]                      --
│    └─Empty: 2-3088                     [64]                      --
│    └─BatchNorm2d: 2-3089               [16, 64, 8, 8]            --
│    └─Scaler: 2-3090                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3091                      [16, 64, 8, 8]            --
│    └─Empty: 2-3092                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3093                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3094                 [16, 64, 8, 8]            --
│    └─Empty: 2-3095                     [16, 64, 8, 8]            --
│    └─Empty: 2-3096                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3097        --                        --
│    └─One: 2-3098                       [1]                       --
│    └─OutputScale: 2-3099               --                        --
│    └─Empty: 2-3100                     [64, 64, 3, 3]            --
│    └─Empty: 2-3101                     [64, 64, 3, 3]            --
│    └─Empty: 2-3102                     [64]                      --
│    └─Empty: 2-3103                     [64]                      --
│    └─BatchNorm2d: 2-3104               [16, 64, 8, 8]            --
│    └─Scaler: 2-3105                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3106                      [16, 64, 8, 8]            --
│    └─Empty: 2-3107                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3108                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3109                 [16, 64, 4, 4]            --
│    └─Empty: 2-3110                     [16, 64, 4, 4]            --
│    └─Empty: 2-3111                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3112        --                        --
│    └─One: 2-3113                       [1]                       --
│    └─OutputScale: 2-3114               --                        --
│    └─Empty: 2-3115                     [64, 64, 3, 3]            --
│    └─Empty: 2-3116                     [64, 64, 3, 3]            --
│    └─Empty: 2-3117                     [64]                      --
│    └─Empty: 2-3118                     [64]                      --
│    └─BatchNorm2d: 2-3119               [16, 64, 4, 4]            --
│    └─Scaler: 2-3120                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3121                      [16, 64, 4, 4]            --
│    └─Empty: 2-3122                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3123                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3124        --                        --
│    └─One: 2-3125                       [1]                       --
│    └─OutputScale: 2-3126               --                        --
│    └─Empty: 2-3127                     [64, 64, 1, 1]            --
│    └─Empty: 2-3128                     [64, 64, 1, 1]            --
│    └─Empty: 2-3129                     [64]                      --
│    └─Empty: 2-3130                     [64]                      --
│    └─BatchNorm2d: 2-3131               [16, 64, 4, 4]            --
│    └─Scaler: 2-3132                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3133                      [16, 64, 4, 4]            --
│    └─Empty: 2-3134                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3135                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3136                 [16, 64, 4, 4]            --
│    └─Empty: 2-3137                     [16, 64, 4, 4]            --
│    └─Empty: 2-3138                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3139        --                        --
│    └─One: 2-3140                       [1]                       --
│    └─OutputScale: 2-3141               --                        --
│    └─Empty: 2-3142                     [64, 64, 3, 3]            --
│    └─Empty: 2-3143                     [64, 64, 3, 3]            --
│    └─Empty: 2-3144                     [64]                      --
│    └─Empty: 2-3145                     [64]                      --
│    └─BatchNorm2d: 2-3146               [16, 64, 4, 4]            --
│    └─Scaler: 2-3147                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3148                      [16, 64, 4, 4]            --
│    └─Empty: 2-3149                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3150                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3151                 [16, 64, 2, 2]            --
│    └─Empty: 2-3152                     [16, 64, 2, 2]            --
│    └─Empty: 2-3153                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3154        --                        --
│    └─One: 2-3155                       [1]                       --
│    └─OutputScale: 2-3156               --                        --
│    └─Empty: 2-3157                     [64, 64, 1, 1]            --
│    └─Empty: 2-3158                     [64, 64, 1, 1]            --
│    └─Empty: 2-3159                     [64]                      --
│    └─Empty: 2-3160                     [64]                      --
│    └─BatchNorm2d: 2-3161               [16, 64, 2, 2]            --
│    └─Scaler: 2-3162                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3163                      [16, 64, 2, 2]            --
│    └─Empty: 2-3164                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3165                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3166        --                        --
│    └─One: 2-3167                       [1]                       --
│    └─OutputScale: 2-3168               --                        --
│    └─Empty: 2-3169                     [64, 64, 1, 1]            --
│    └─Empty: 2-3170                     [64, 64, 1, 1]            --
│    └─Empty: 2-3171                     [64]                      --
│    └─Empty: 2-3172                     [64]                      --
│    └─BatchNorm2d: 2-3173               [16, 64, 2, 2]            --
│    └─Scaler: 2-3174                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3175                      [16, 64, 2, 2]            --
│    └─Empty: 2-3176                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3177                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3178                 [16, 64, 2, 2]            --
│    └─Empty: 2-3179                     [16, 64, 2, 2]            --
│    └─Empty: 2-3180                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3181        --                        --
│    └─One: 2-3182                       [1]                       --
│    └─OutputScale: 2-3183               --                        --
│    └─Empty: 2-3184                     [64, 64, 3, 3]            --
│    └─Empty: 2-3185                     [64, 64, 3, 3]            --
│    └─Empty: 2-3186                     [64]                      --
│    └─Empty: 2-3187                     [64]                      --
│    └─BatchNorm2d: 2-3188               [16, 64, 2, 2]            --
│    └─Scaler: 2-3189                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3190                      [16, 64, 2, 2]            --
│    └─Empty: 2-3191                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3192                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3193        --                        --
│    └─One: 2-3194                       [1]                       --
│    └─OutputScale: 2-3195               --                        --
│    └─Empty: 2-3196                     [64, 48, 1, 1]            --
│    └─Empty: 2-3197                     [64, 48, 1, 1]            --
│    └─Empty: 2-3198                     [64]                      --
│    └─Empty: 2-3199                     [64]                      --
│    └─BatchNorm2d: 2-3200               [16, 64, 64, 64]          --
│    └─Scaler: 2-3201                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3202                      [16, 64, 64, 64]          --
│    └─Empty: 2-3203                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3204                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3205        --                        --
│    └─One: 2-3206                       [1]                       --
│    └─OutputScale: 2-3207               --                        --
│    └─Empty: 2-3208                     [64, 64, 3, 3]            --
│    └─Empty: 2-3209                     [64, 64, 3, 3]            --
│    └─Empty: 2-3210                     [64]                      --
│    └─Empty: 2-3211                     [64]                      --
│    └─BatchNorm2d: 2-3212               [16, 64, 64, 64]          --
│    └─Scaler: 2-3213                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3214                      [16, 64, 64, 64]          --
│    └─Empty: 2-3215                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3216                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3217        --                        --
│    └─One: 2-3218                       [1]                       --
│    └─OutputScale: 2-3219               --                        --
│    └─Empty: 2-3220                     [64, 64, 1, 1]            --
│    └─Empty: 2-3221                     [64, 64, 1, 1]            --
│    └─Empty: 2-3222                     [64]                      --
│    └─Empty: 2-3223                     [64]                      --
│    └─BatchNorm2d: 2-3224               [16, 64, 64, 64]          --
│    └─Scaler: 2-3225                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3226                      [16, 64, 64, 64]          --
│    └─Empty: 2-3227                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3228                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3229        --                        --
│    └─One: 2-3230                       [1]                       --
│    └─OutputScale: 2-3231               --                        --
│    └─Empty: 2-3232                     [64, 64, 3, 3]            --
│    └─Empty: 2-3233                     [64, 64, 3, 3]            --
│    └─Empty: 2-3234                     [64]                      --
│    └─Empty: 2-3235                     [64]                      --
│    └─BatchNorm2d: 2-3236               [16, 64, 64, 64]          --
│    └─Scaler: 2-3237                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3238                      [16, 64, 64, 64]          --
│    └─Empty: 2-3239                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3240                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3241                 [16, 64, 32, 32]          --
│    └─Empty: 2-3242                     [16, 64, 32, 32]          --
│    └─Empty: 2-3243                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3244        --                        --
│    └─One: 2-3245                       [1]                       --
│    └─OutputScale: 2-3246               --                        --
│    └─Empty: 2-3247                     [64, 64, 3, 3]            --
│    └─Empty: 2-3248                     [64, 64, 3, 3]            --
│    └─Empty: 2-3249                     [64]                      --
│    └─Empty: 2-3250                     [64]                      --
│    └─BatchNorm2d: 2-3251               [16, 64, 32, 32]          --
│    └─Scaler: 2-3252                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3253                      [16, 64, 32, 32]          --
│    └─Empty: 2-3254                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3255                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3256        --                        --
│    └─One: 2-3257                       [1]                       --
│    └─OutputScale: 2-3258               --                        --
│    └─Empty: 2-3259                     [64, 64, 3, 3]            --
│    └─Empty: 2-3260                     [64, 64, 3, 3]            --
│    └─Empty: 2-3261                     [64]                      --
│    └─Empty: 2-3262                     [64]                      --
│    └─BatchNorm2d: 2-3263               [16, 64, 32, 32]          --
│    └─Scaler: 2-3264                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3265                      [16, 64, 32, 32]          --
│    └─Empty: 2-3266                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3267                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3268                 [16, 64, 16, 16]          --
│    └─Empty: 2-3269                     [16, 64, 16, 16]          --
│    └─Empty: 2-3270                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3271        --                        --
│    └─One: 2-3272                       [1]                       --
│    └─OutputScale: 2-3273               --                        --
│    └─Empty: 2-3274                     [64, 64, 3, 3]            --
│    └─Empty: 2-3275                     [64, 64, 3, 3]            --
│    └─Empty: 2-3276                     [64]                      --
│    └─Empty: 2-3277                     [64]                      --
│    └─BatchNorm2d: 2-3278               [16, 64, 16, 16]          --
│    └─Scaler: 2-3279                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3280                      [16, 64, 16, 16]          --
│    └─Empty: 2-3281                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3282                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3283        --                        --
│    └─One: 2-3284                       [1]                       --
│    └─OutputScale: 2-3285               --                        --
│    └─Empty: 2-3286                     [64, 64, 3, 3]            --
│    └─Empty: 2-3287                     [64, 64, 3, 3]            --
│    └─Empty: 2-3288                     [64]                      --
│    └─Empty: 2-3289                     [64]                      --
│    └─BatchNorm2d: 2-3290               [16, 64, 16, 16]          --
│    └─Scaler: 2-3291                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3292                      [16, 64, 16, 16]          --
│    └─Empty: 2-3293                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3294                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3295                 [16, 64, 8, 8]            --
│    └─Empty: 2-3296                     [16, 64, 8, 8]            --
│    └─Empty: 2-3297                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3298        --                        --
│    └─One: 2-3299                       [1]                       --
│    └─OutputScale: 2-3300               --                        --
│    └─Empty: 2-3301                     [64, 64, 3, 3]            --
│    └─Empty: 2-3302                     [64, 64, 3, 3]            --
│    └─Empty: 2-3303                     [64]                      --
│    └─Empty: 2-3304                     [64]                      --
│    └─BatchNorm2d: 2-3305               [16, 64, 8, 8]            --
│    └─Scaler: 2-3306                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3307                      [16, 64, 8, 8]            --
│    └─Empty: 2-3308                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3309                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3310        --                        --
│    └─One: 2-3311                       [1]                       --
│    └─OutputScale: 2-3312               --                        --
│    └─Empty: 2-3313                     [64, 64, 1, 1]            --
│    └─Empty: 2-3314                     [64, 64, 1, 1]            --
│    └─Empty: 2-3315                     [64]                      --
│    └─Empty: 2-3316                     [64]                      --
│    └─BatchNorm2d: 2-3317               [16, 64, 8, 8]            --
│    └─Scaler: 2-3318                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3319                      [16, 64, 8, 8]            --
│    └─Empty: 2-3320                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3321                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3322                 [16, 64, 8, 8]            --
│    └─Empty: 2-3323                     [16, 64, 8, 8]            --
│    └─Empty: 2-3324                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3325        --                        --
│    └─One: 2-3326                       [1]                       --
│    └─OutputScale: 2-3327               --                        --
│    └─Empty: 2-3328                     [64, 64, 3, 3]            --
│    └─Empty: 2-3329                     [64, 64, 3, 3]            --
│    └─Empty: 2-3330                     [64]                      --
│    └─Empty: 2-3331                     [64]                      --
│    └─BatchNorm2d: 2-3332               [16, 64, 8, 8]            --
│    └─Scaler: 2-3333                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3334                      [16, 64, 8, 8]            --
│    └─Empty: 2-3335                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3336                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3337                 [16, 64, 4, 4]            --
│    └─Empty: 2-3338                     [16, 64, 4, 4]            --
│    └─Empty: 2-3339                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3340        --                        --
│    └─One: 2-3341                       [1]                       --
│    └─OutputScale: 2-3342               --                        --
│    └─Empty: 2-3343                     [64, 64, 3, 3]            --
│    └─Empty: 2-3344                     [64, 64, 3, 3]            --
│    └─Empty: 2-3345                     [64]                      --
│    └─Empty: 2-3346                     [64]                      --
│    └─BatchNorm2d: 2-3347               [16, 64, 4, 4]            --
│    └─Scaler: 2-3348                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3349                      [16, 64, 4, 4]            --
│    └─Empty: 2-3350                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3351                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3352        --                        --
│    └─One: 2-3353                       [1]                       --
│    └─OutputScale: 2-3354               --                        --
│    └─Empty: 2-3355                     [64, 64, 1, 1]            --
│    └─Empty: 2-3356                     [64, 64, 1, 1]            --
│    └─Empty: 2-3357                     [64]                      --
│    └─Empty: 2-3358                     [64]                      --
│    └─BatchNorm2d: 2-3359               [16, 64, 4, 4]            --
│    └─Scaler: 2-3360                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3361                      [16, 64, 4, 4]            --
│    └─Empty: 2-3362                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3363                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3364                 [16, 64, 4, 4]            --
│    └─Empty: 2-3365                     [16, 64, 4, 4]            --
│    └─Empty: 2-3366                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3367        --                        --
│    └─One: 2-3368                       [1]                       --
│    └─OutputScale: 2-3369               --                        --
│    └─Empty: 2-3370                     [64, 64, 3, 3]            --
│    └─Empty: 2-3371                     [64, 64, 3, 3]            --
│    └─Empty: 2-3372                     [64]                      --
│    └─Empty: 2-3373                     [64]                      --
│    └─BatchNorm2d: 2-3374               [16, 64, 4, 4]            --
│    └─Scaler: 2-3375                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3376                      [16, 64, 4, 4]            --
│    └─Empty: 2-3377                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3378                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3379                 [16, 64, 2, 2]            --
│    └─Empty: 2-3380                     [16, 64, 2, 2]            --
│    └─Empty: 2-3381                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3382        --                        --
│    └─One: 2-3383                       [1]                       --
│    └─OutputScale: 2-3384               --                        --
│    └─Empty: 2-3385                     [64, 64, 1, 1]            --
│    └─Empty: 2-3386                     [64, 64, 1, 1]            --
│    └─Empty: 2-3387                     [64]                      --
│    └─Empty: 2-3388                     [64]                      --
│    └─BatchNorm2d: 2-3389               [16, 64, 2, 2]            --
│    └─Scaler: 2-3390                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3391                      [16, 64, 2, 2]            --
│    └─Empty: 2-3392                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3393                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3394        --                        --
│    └─One: 2-3395                       [1]                       --
│    └─OutputScale: 2-3396               --                        --
│    └─Empty: 2-3397                     [64, 64, 1, 1]            --
│    └─Empty: 2-3398                     [64, 64, 1, 1]            --
│    └─Empty: 2-3399                     [64]                      --
│    └─Empty: 2-3400                     [64]                      --
│    └─BatchNorm2d: 2-3401               [16, 64, 2, 2]            --
│    └─Scaler: 2-3402                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3403                      [16, 64, 2, 2]            --
│    └─Empty: 2-3404                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3405                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3406                 [16, 64, 2, 2]            --
│    └─Empty: 2-3407                     [16, 64, 2, 2]            --
│    └─Empty: 2-3408                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3409        --                        --
│    └─One: 2-3410                       [1]                       --
│    └─OutputScale: 2-3411               --                        --
│    └─Empty: 2-3412                     [64, 64, 3, 3]            --
│    └─Empty: 2-3413                     [64, 64, 3, 3]            --
│    └─Empty: 2-3414                     [64]                      --
│    └─Empty: 2-3415                     [64]                      --
│    └─BatchNorm2d: 2-3416               [16, 64, 2, 2]            --
│    └─Scaler: 2-3417                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3418                      [16, 64, 2, 2]            --
│    └─Empty: 2-3419                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3420                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3421        --                        --
│    └─One: 2-3422                       [1]                       --
│    └─OutputScale: 2-3423               --                        --
│    └─Empty: 2-3424                     [64, 48, 1, 1]            --
│    └─Empty: 2-3425                     [64, 48, 1, 1]            --
│    └─Empty: 2-3426                     [64]                      --
│    └─Empty: 2-3427                     [64]                      --
│    └─BatchNorm2d: 2-3428               [16, 64, 64, 64]          --
│    └─Scaler: 2-3429                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3430                      [16, 64, 64, 64]          --
│    └─Empty: 2-3431                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3432                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3433        --                        --
│    └─One: 2-3434                       [1]                       --
│    └─OutputScale: 2-3435               --                        --
│    └─Empty: 2-3436                     [64, 64, 3, 3]            --
│    └─Empty: 2-3437                     [64, 64, 3, 3]            --
│    └─Empty: 2-3438                     [64]                      --
│    └─Empty: 2-3439                     [64]                      --
│    └─BatchNorm2d: 2-3440               [16, 64, 64, 64]          --
│    └─Scaler: 2-3441                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3442                      [16, 64, 64, 64]          --
│    └─Empty: 2-3443                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3444                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3445        --                        --
│    └─One: 2-3446                       [1]                       --
│    └─OutputScale: 2-3447               --                        --
│    └─Empty: 2-3448                     [64, 64, 1, 1]            --
│    └─Empty: 2-3449                     [64, 64, 1, 1]            --
│    └─Empty: 2-3450                     [64]                      --
│    └─Empty: 2-3451                     [64]                      --
│    └─BatchNorm2d: 2-3452               [16, 64, 64, 64]          --
│    └─Scaler: 2-3453                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3454                      [16, 64, 64, 64]          --
│    └─Empty: 2-3455                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3456                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3457        --                        --
│    └─One: 2-3458                       [1]                       --
│    └─OutputScale: 2-3459               --                        --
│    └─Empty: 2-3460                     [64, 64, 3, 3]            --
│    └─Empty: 2-3461                     [64, 64, 3, 3]            --
│    └─Empty: 2-3462                     [64]                      --
│    └─Empty: 2-3463                     [64]                      --
│    └─BatchNorm2d: 2-3464               [16, 64, 64, 64]          --
│    └─Scaler: 2-3465                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3466                      [16, 64, 64, 64]          --
│    └─Empty: 2-3467                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3468                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3469                 [16, 64, 32, 32]          --
│    └─Empty: 2-3470                     [16, 64, 32, 32]          --
│    └─Empty: 2-3471                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3472        --                        --
│    └─One: 2-3473                       [1]                       --
│    └─OutputScale: 2-3474               --                        --
│    └─Empty: 2-3475                     [64, 64, 3, 3]            --
│    └─Empty: 2-3476                     [64, 64, 3, 3]            --
│    └─Empty: 2-3477                     [64]                      --
│    └─Empty: 2-3478                     [64]                      --
│    └─BatchNorm2d: 2-3479               [16, 64, 32, 32]          --
│    └─Scaler: 2-3480                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3481                      [16, 64, 32, 32]          --
│    └─Empty: 2-3482                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3483                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3484        --                        --
│    └─One: 2-3485                       [1]                       --
│    └─OutputScale: 2-3486               --                        --
│    └─Empty: 2-3487                     [64, 64, 3, 3]            --
│    └─Empty: 2-3488                     [64, 64, 3, 3]            --
│    └─Empty: 2-3489                     [64]                      --
│    └─Empty: 2-3490                     [64]                      --
│    └─BatchNorm2d: 2-3491               [16, 64, 32, 32]          --
│    └─Scaler: 2-3492                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3493                      [16, 64, 32, 32]          --
│    └─Empty: 2-3494                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3495                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3496                 [16, 64, 16, 16]          --
│    └─Empty: 2-3497                     [16, 64, 16, 16]          --
│    └─Empty: 2-3498                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3499        --                        --
│    └─One: 2-3500                       [1]                       --
│    └─OutputScale: 2-3501               --                        --
│    └─Empty: 2-3502                     [64, 64, 3, 3]            --
│    └─Empty: 2-3503                     [64, 64, 3, 3]            --
│    └─Empty: 2-3504                     [64]                      --
│    └─Empty: 2-3505                     [64]                      --
│    └─BatchNorm2d: 2-3506               [16, 64, 16, 16]          --
│    └─Scaler: 2-3507                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3508                      [16, 64, 16, 16]          --
│    └─Empty: 2-3509                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3510                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3511        --                        --
│    └─One: 2-3512                       [1]                       --
│    └─OutputScale: 2-3513               --                        --
│    └─Empty: 2-3514                     [64, 64, 3, 3]            --
│    └─Empty: 2-3515                     [64, 64, 3, 3]            --
│    └─Empty: 2-3516                     [64]                      --
│    └─Empty: 2-3517                     [64]                      --
│    └─BatchNorm2d: 2-3518               [16, 64, 16, 16]          --
│    └─Scaler: 2-3519                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3520                      [16, 64, 16, 16]          --
│    └─Empty: 2-3521                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3522                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3523                 [16, 64, 8, 8]            --
│    └─Empty: 2-3524                     [16, 64, 8, 8]            --
│    └─Empty: 2-3525                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3526        --                        --
│    └─One: 2-3527                       [1]                       --
│    └─OutputScale: 2-3528               --                        --
│    └─Empty: 2-3529                     [64, 64, 3, 3]            --
│    └─Empty: 2-3530                     [64, 64, 3, 3]            --
│    └─Empty: 2-3531                     [64]                      --
│    └─Empty: 2-3532                     [64]                      --
│    └─BatchNorm2d: 2-3533               [16, 64, 8, 8]            --
│    └─Scaler: 2-3534                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3535                      [16, 64, 8, 8]            --
│    └─Empty: 2-3536                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3537                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3538        --                        --
│    └─One: 2-3539                       [1]                       --
│    └─OutputScale: 2-3540               --                        --
│    └─Empty: 2-3541                     [64, 64, 1, 1]            --
│    └─Empty: 2-3542                     [64, 64, 1, 1]            --
│    └─Empty: 2-3543                     [64]                      --
│    └─Empty: 2-3544                     [64]                      --
│    └─BatchNorm2d: 2-3545               [16, 64, 8, 8]            --
│    └─Scaler: 2-3546                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3547                      [16, 64, 8, 8]            --
│    └─Empty: 2-3548                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3549                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3550                 [16, 64, 8, 8]            --
│    └─Empty: 2-3551                     [16, 64, 8, 8]            --
│    └─Empty: 2-3552                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3553        --                        --
│    └─One: 2-3554                       [1]                       --
│    └─OutputScale: 2-3555               --                        --
│    └─Empty: 2-3556                     [64, 64, 3, 3]            --
│    └─Empty: 2-3557                     [64, 64, 3, 3]            --
│    └─Empty: 2-3558                     [64]                      --
│    └─Empty: 2-3559                     [64]                      --
│    └─BatchNorm2d: 2-3560               [16, 64, 8, 8]            --
│    └─Scaler: 2-3561                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3562                      [16, 64, 8, 8]            --
│    └─Empty: 2-3563                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3564                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3565                 [16, 64, 4, 4]            --
│    └─Empty: 2-3566                     [16, 64, 4, 4]            --
│    └─Empty: 2-3567                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3568        --                        --
│    └─One: 2-3569                       [1]                       --
│    └─OutputScale: 2-3570               --                        --
│    └─Empty: 2-3571                     [64, 64, 3, 3]            --
│    └─Empty: 2-3572                     [64, 64, 3, 3]            --
│    └─Empty: 2-3573                     [64]                      --
│    └─Empty: 2-3574                     [64]                      --
│    └─BatchNorm2d: 2-3575               [16, 64, 4, 4]            --
│    └─Scaler: 2-3576                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3577                      [16, 64, 4, 4]            --
│    └─Empty: 2-3578                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3579                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3580        --                        --
│    └─One: 2-3581                       [1]                       --
│    └─OutputScale: 2-3582               --                        --
│    └─Empty: 2-3583                     [64, 64, 1, 1]            --
│    └─Empty: 2-3584                     [64, 64, 1, 1]            --
│    └─Empty: 2-3585                     [64]                      --
│    └─Empty: 2-3586                     [64]                      --
│    └─BatchNorm2d: 2-3587               [16, 64, 4, 4]            --
│    └─Scaler: 2-3588                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3589                      [16, 64, 4, 4]            --
│    └─Empty: 2-3590                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3591                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3592                 [16, 64, 4, 4]            --
│    └─Empty: 2-3593                     [16, 64, 4, 4]            --
│    └─Empty: 2-3594                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3595        --                        --
│    └─One: 2-3596                       [1]                       --
│    └─OutputScale: 2-3597               --                        --
│    └─Empty: 2-3598                     [64, 64, 3, 3]            --
│    └─Empty: 2-3599                     [64, 64, 3, 3]            --
│    └─Empty: 2-3600                     [64]                      --
│    └─Empty: 2-3601                     [64]                      --
│    └─BatchNorm2d: 2-3602               [16, 64, 4, 4]            --
│    └─Scaler: 2-3603                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3604                      [16, 64, 4, 4]            --
│    └─Empty: 2-3605                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3606                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3607                 [16, 64, 2, 2]            --
│    └─Empty: 2-3608                     [16, 64, 2, 2]            --
│    └─Empty: 2-3609                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3610        --                        --
│    └─One: 2-3611                       [1]                       --
│    └─OutputScale: 2-3612               --                        --
│    └─Empty: 2-3613                     [64, 64, 1, 1]            --
│    └─Empty: 2-3614                     [64, 64, 1, 1]            --
│    └─Empty: 2-3615                     [64]                      --
│    └─Empty: 2-3616                     [64]                      --
│    └─BatchNorm2d: 2-3617               [16, 64, 2, 2]            --
│    └─Scaler: 2-3618                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3619                      [16, 64, 2, 2]            --
│    └─Empty: 2-3620                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3621                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3622        --                        --
│    └─One: 2-3623                       [1]                       --
│    └─OutputScale: 2-3624               --                        --
│    └─Empty: 2-3625                     [64, 64, 1, 1]            --
│    └─Empty: 2-3626                     [64, 64, 1, 1]            --
│    └─Empty: 2-3627                     [64]                      --
│    └─Empty: 2-3628                     [64]                      --
│    └─BatchNorm2d: 2-3629               [16, 64, 2, 2]            --
│    └─Scaler: 2-3630                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3631                      [16, 64, 2, 2]            --
│    └─Empty: 2-3632                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3633                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3634                 [16, 64, 2, 2]            --
│    └─Empty: 2-3635                     [16, 64, 2, 2]            --
│    └─Empty: 2-3636                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3637        --                        --
│    └─One: 2-3638                       [1]                       --
│    └─OutputScale: 2-3639               --                        --
│    └─Empty: 2-3640                     [64, 64, 3, 3]            --
│    └─Empty: 2-3641                     [64, 64, 3, 3]            --
│    └─Empty: 2-3642                     [64]                      --
│    └─Empty: 2-3643                     [64]                      --
│    └─BatchNorm2d: 2-3644               [16, 64, 2, 2]            --
│    └─Scaler: 2-3645                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3646                      [16, 64, 2, 2]            --
│    └─Empty: 2-3647                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3648                     [16, 64, 2, 2]            --
├─Conv1d: 1-273                          [16, 64, 16]              16,454
│    └─OutputShiftSqueeze: 2-3649        --                        --
│    └─One: 2-3650                       [1]                       --
│    └─OutputScale: 2-3651               --                        --
│    └─Empty: 2-3652                     [64, 256, 1]              --
│    └─Empty: 2-3653                     [64, 256, 1]              --
│    └─Empty: 2-3654                     [64]                      --
│    └─Empty: 2-3655                     [64]                      --
│    └─Scaler: 2-3656                    [16, 64, 16]              --
│    └─Empty: 2-3657                     [16, 64, 16]              --
│    └─Empty: 2-3658                     [16, 64, 16]              --
│    └─Clamp: 2-3659                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3660        --                        --
│    └─One: 2-3661                       [1]                       --
│    └─OutputScale: 2-3662               --                        --
│    └─Empty: 2-3663                     [64, 64, 3]               --
│    └─Empty: 2-3664                     [64, 64, 3]               --
│    └─Empty: 2-3665                     [64]                      --
│    └─Empty: 2-3666                     [64]                      --
│    └─BatchNorm1d: 2-3667               [16, 64, 16]              --
│    └─Scaler: 2-3668                    [16, 64, 16]              --
│    └─ReLU: 2-3669                      [16, 64, 16]              --
│    └─Empty: 2-3670                     [16, 64, 16]              --
│    └─Clamp: 2-3671                     [16, 64, 16]              --
├─Conv1d: 1-275                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3672        --                        --
│    └─One: 2-3673                       [1]                       --
│    └─OutputScale: 2-3674               --                        --
│    └─Empty: 2-3675                     [64, 64, 1]               --
│    └─Empty: 2-3676                     [64, 64, 1]               --
│    └─Empty: 2-3677                     [64]                      --
│    └─Empty: 2-3678                     [64]                      --
│    └─Scaler: 2-3679                    [16, 64, 16]              --
│    └─Empty: 2-3680                     [16, 64, 16]              --
│    └─Empty: 2-3681                     [16, 64, 16]              --
│    └─Clamp: 2-3682                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-276               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3683        --                        --
│    └─One: 2-3684                       [1]                       --
│    └─OutputScale: 2-3685               --                        --
│    └─Empty: 2-3686                     [64, 64, 3]               --
│    └─Empty: 2-3687                     [64, 64, 3]               --
│    └─Empty: 2-3688                     [64]                      --
│    └─Empty: 2-3689                     [64]                      --
│    └─BatchNorm1d: 2-3690               [16, 64, 16]              --
│    └─Scaler: 2-3691                    [16, 64, 16]              --
│    └─ReLU: 2-3692                      [16, 64, 16]              --
│    └─Empty: 2-3693                     [16, 64, 16]              --
│    └─Clamp: 2-3694                     [16, 64, 16]              --
├─Conv1d: 1-277                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3695        --                        --
│    └─One: 2-3696                       [1]                       --
│    └─OutputScale: 2-3697               --                        --
│    └─Empty: 2-3698                     [64, 64, 1]               --
│    └─Empty: 2-3699                     [64, 64, 1]               --
│    └─Empty: 2-3700                     [64]                      --
│    └─Empty: 2-3701                     [64]                      --
│    └─Scaler: 2-3702                    [16, 64, 16]              --
│    └─Empty: 2-3703                     [16, 64, 16]              --
│    └─Empty: 2-3704                     [16, 64, 16]              --
│    └─Clamp: 2-3705                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-278               [16, 64, 12]              12,358
│    └─OutputShiftSqueeze: 2-3706        --                        --
│    └─One: 2-3707                       [1]                       --
│    └─OutputScale: 2-3708               --                        --
│    └─Empty: 2-3709                     [64, 64, 3]               --
│    └─Empty: 2-3710                     [64, 64, 3]               --
│    └─Empty: 2-3711                     [64]                      --
│    └─Empty: 2-3712                     [64]                      --
│    └─BatchNorm1d: 2-3713               [16, 64, 12]              --
│    └─Scaler: 2-3714                    [16, 64, 12]              --
│    └─ReLU: 2-3715                      [16, 64, 12]              --
│    └─Empty: 2-3716                     [16, 64, 12]              --
│    └─Clamp: 2-3717                     [16, 64, 12]              --
├─Conv1d: 1-279                          [16, 64, 12]              4,166
│    └─OutputShiftSqueeze: 2-3718        --                        --
│    └─One: 2-3719                       [1]                       --
│    └─OutputScale: 2-3720               --                        --
│    └─Empty: 2-3721                     [64, 64, 1]               --
│    └─Empty: 2-3722                     [64, 64, 1]               --
│    └─Empty: 2-3723                     [64]                      --
│    └─Empty: 2-3724                     [64]                      --
│    └─Scaler: 2-3725                    [16, 64, 12]              --
│    └─Empty: 2-3726                     [16, 64, 12]              --
│    └─Empty: 2-3727                     [16, 64, 12]              --
│    └─Clamp: 2-3728                     [16, 64, 12]              --
├─FusedConv1dBNReLU: 1-280               [16, 64, 8]               12,358
│    └─OutputShiftSqueeze: 2-3729        --                        --
│    └─One: 2-3730                       [1]                       --
│    └─OutputScale: 2-3731               --                        --
│    └─Empty: 2-3732                     [64, 64, 3]               --
│    └─Empty: 2-3733                     [64, 64, 3]               --
│    └─Empty: 2-3734                     [64]                      --
│    └─Empty: 2-3735                     [64]                      --
│    └─BatchNorm1d: 2-3736               [16, 64, 8]               --
│    └─Scaler: 2-3737                    [16, 64, 8]               --
│    └─ReLU: 2-3738                      [16, 64, 8]               --
│    └─Empty: 2-3739                     [16, 64, 8]               --
│    └─Clamp: 2-3740                     [16, 64, 8]               --
├─Conv1d: 1-281                          [16, 64, 8]               4,166
│    └─OutputShiftSqueeze: 2-3741        --                        --
│    └─One: 2-3742                       [1]                       --
│    └─OutputScale: 2-3743               --                        --
│    └─Empty: 2-3744                     [64, 64, 1]               --
│    └─Empty: 2-3745                     [64, 64, 1]               --
│    └─Empty: 2-3746                     [64]                      --
│    └─Empty: 2-3747                     [64]                      --
│    └─Scaler: 2-3748                    [16, 64, 8]               --
│    └─Empty: 2-3749                     [16, 64, 8]               --
│    └─Empty: 2-3750                     [16, 64, 8]               --
│    └─Clamp: 2-3751                     [16, 64, 8]               --
├─FusedLinearReLU: 1-282                 [16, 32]                  16,422
│    └─OutputShiftSqueeze: 2-3752        --                        --
│    └─One: 2-3753                       [1]                       --
│    └─OutputScale: 2-3754               --                        --
│    └─Empty: 2-3755                     [32, 512]                 --
│    └─Empty: 2-3756                     [32, 512]                 --
│    └─Empty: 2-3757                     [32]                      --
│    └─Empty: 2-3758                     [32]                      --
│    └─Scaler: 2-3759                    [16, 32]                  --
│    └─ReLU: 2-3760                      [16, 32]                  --
│    └─Empty: 2-3761                     [16, 32]                  --
│    └─Clamp: 2-3762                     [16, 32]                  --
├─Linear: 1-283                          [16, 5]                   166
│    └─OutputShiftSqueeze: 2-3763        --                        --
│    └─One: 2-3764                       [1]                       --
│    └─OutputScale: 2-3765               --                        --
│    └─Empty: 2-3766                     [5, 32]                   --
│    └─Empty: 2-3767                     [5, 32]                   --
│    └─Empty: 2-3768                     [16, 5]                   --
│    └─Empty: 2-3769                     [16, 5]                   --
│    └─Clamp: 2-3770                     [16, 5]                   --
==========================================================================================
Total params: 529,384
Trainable params: 529,216
Non-trainable params: 168
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.576 | Acc: 39.250% | Wgt Acc: 25.109%
	I - Batch: 100 | Loss: 1.562 | Acc: 40.250% | Wgt Acc: 26.469%
	I - Batch: 150 | Loss: 1.544 | Acc: 41.333% | Wgt Acc: 27.550%
	I - Batch: 200 | Loss: 1.521 | Acc: 40.344% | Wgt Acc: 27.786%
	I - Batch: 250 | Loss: 1.541 | Acc: 36.300% | Wgt Acc: 27.255%
	I - Batch: 300 | Loss: 1.543 | Acc: 35.229% | Wgt Acc: 26.945%
	I - Batch: 350 | Loss: 1.548 | Acc: 32.875% | Wgt Acc: 26.625%
I - num batch: 364
I - Train -- Loss: 1.549 | Acc: 32.244% | Wgt Acc: 26.393% | LR: 1.000000e-03 | Dur: 229.04s
I - Confusion Matrix: [row->prediction - col->label]
[[  90.   49.   56.  107.  198.]
 [  16.    2.    9.    5.   34.]
 [ 222.  271.  392.  261. 1071.]
 [ 150.   39.   54.  148.  217.]
 [ 214.  307.  463.  197. 1243.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.593 | Acc: 25.625% | Wgt Acc: 25.147%
I - num batch: 87
I - Val -- Loss: 1.579 | Acc: 25.431% | Wgt Acc: 24.761% | Dur: 42.52s
I - Confusion Matrix: [row->prediction - col->label]
[[  6.   5.   6.  12.   7.]
 [  0.   0.   0.   0.   0.]
 [ 74. 180. 218. 101. 294.]
 [  0.   0.   0.   0.   0.]
 [119.  83.  66.  91. 130.]]

I - Local maximum validation set accuracy:  25.43

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.543 | Acc: 30.500% | Wgt Acc: 27.427%
	I - Batch: 100 | Loss: 1.527 | Acc: 36.750% | Wgt Acc: 27.829%
	I - Batch: 150 | Loss: 1.530 | Acc: 33.750% | Wgt Acc: 28.037%
	I - Batch: 200 | Loss: 1.523 | Acc: 30.562% | Wgt Acc: 28.219%
	I - Batch: 250 | Loss: 1.515 | Acc: 30.225% | Wgt Acc: 28.194%
	I - Batch: 300 | Loss: 1.507 | Acc: 29.271% | Wgt Acc: 29.165%
	I - Batch: 350 | Loss: 1.501 | Acc: 28.875% | Wgt Acc: 29.194%
I - num batch: 364
I - Train -- Loss: 1.499 | Acc: 28.839% | Wgt Acc: 29.327% | LR: 1.000000e-03 | Dur: 227.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 292.   71.   96.  252.  372.]
 [   7.   21.   33.    4.   88.]
 [ 178.  358.  484.  213. 1337.]
 [ 124.   49.   76.  137.  223.]
 [  91.  169.  285.  112.  743.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.430 | Acc: 31.750% | Wgt Acc: 35.249%
I - num batch: 87
I - Val -- Loss: 1.414 | Acc: 28.233% | Wgt Acc: 34.150% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[123.  11.  17. 123.  48.]
 [  1.   0.   0.   0.   0.]
 [ 45. 249. 251.  65. 362.]
 [ 12.   1.   4.   5.   7.]
 [ 18.   7.  18.  11.  14.]]

I - Local maximum validation set accuracy:  28.23

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 1.408 | Acc: 25.625% | Wgt Acc: 34.264%
	I - Batch: 100 | Loss: 1.446 | Acc: 25.562% | Wgt Acc: 31.583%
	I - Batch: 150 | Loss: 1.475 | Acc: 24.375% | Wgt Acc: 30.539%
	I - Batch: 200 | Loss: 1.476 | Acc: 28.469% | Wgt Acc: 30.147%
	I - Batch: 250 | Loss: 1.475 | Acc: 28.100% | Wgt Acc: 30.667%
	I - Batch: 300 | Loss: 1.477 | Acc: 27.500% | Wgt Acc: 30.502%
	I - Batch: 350 | Loss: 1.476 | Acc: 29.571% | Wgt Acc: 30.329%
I - num batch: 364
I - Train -- Loss: 1.477 | Acc: 29.475% | Wgt Acc: 30.309% | LR: 1.000000e-03 | Dur: 228.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 278.   66.   85.  272.  314.]
 [   0.    1.    1.    0.    0.]
 [ 131.  350.  535.  169. 1442.]
 [ 189.   47.   81.  163.  270.]
 [  94.  204.  272.  114.  737.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.498 | Acc: 27.500% | Wgt Acc: 16.650%
I - num batch: 87
I - Val -- Loss: 1.484 | Acc: 35.057% | Wgt Acc: 20.941% | Dur: 42.67s
I - Confusion Matrix: [row->prediction - col->label]
[[111.  23.  32. 121.  52.]
 [  0.   0.   0.   0.   0.]
 [  3.   4.   4.   6.   6.]
 [  0.   0.   0.   0.   0.]
 [ 85. 241. 254.  77. 373.]]

I - Local maximum validation set accuracy:  35.06

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 1.475 | Acc: 38.750% | Wgt Acc: 29.826%
	I - Batch: 100 | Loss: 1.442 | Acc: 38.750% | Wgt Acc: 30.593%
	I - Batch: 150 | Loss: 1.447 | Acc: 33.542% | Wgt Acc: 31.435%
	I - Batch: 200 | Loss: 1.436 | Acc: 31.781% | Wgt Acc: 32.205%
	I - Batch: 250 | Loss: 1.448 | Acc: 34.200% | Wgt Acc: 31.815%
	I - Batch: 300 | Loss: 1.450 | Acc: 33.562% | Wgt Acc: 31.507%
	I - Batch: 350 | Loss: 1.456 | Acc: 35.679% | Wgt Acc: 31.542%
I - num batch: 364
I - Train -- Loss: 1.455 | Acc: 36.131% | Wgt Acc: 31.481% | LR: 1.000000e-03 | Dur: 227.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 359.   51.  113.  328.  352.]
 [   0.    0.    0.    0.    0.]
 [  90.  260.  386.  116. 1025.]
 [ 121.   34.   42.  112.  142.]
 [ 122.  323.  433.  162. 1244.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.466 | Acc: 28.125% | Wgt Acc: 18.592%
I - num batch: 87
I - Val -- Loss: 1.447 | Acc: 36.422% | Wgt Acc: 23.143% | Dur: 41.87s
I - Confusion Matrix: [row->prediction - col->label]
[[148.  30.  46. 145.  72.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 51. 238. 244.  59. 359.]]

I - Local maximum validation set accuracy:  36.42

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 1.454 | Acc: 48.750% | Wgt Acc: 31.549%
	I - Batch: 100 | Loss: 1.446 | Acc: 42.812% | Wgt Acc: 30.794%
	I - Batch: 150 | Loss: 1.442 | Acc: 40.250% | Wgt Acc: 30.735%
	I - Batch: 200 | Loss: 1.442 | Acc: 37.594% | Wgt Acc: 31.445%
	I - Batch: 250 | Loss: 1.436 | Acc: 39.475% | Wgt Acc: 31.476%
	I - Batch: 300 | Loss: 1.435 | Acc: 40.854% | Wgt Acc: 31.520%
	I - Batch: 350 | Loss: 1.437 | Acc: 38.518% | Wgt Acc: 31.966%
I - num batch: 364
I - Train -- Loss: 1.438 | Acc: 37.936% | Wgt Acc: 31.945% | LR: 1.000000e-03 | Dur: 226.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 342.   68.  121.  326.  337.]
 [   0.    0.    1.    0.    0.]
 [  65.  211.  340.   99.  868.]
 [ 180.   37.   62.  154.  188.]
 [ 105.  352.  450.  139. 1370.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.488 | Acc: 31.250% | Wgt Acc: 35.279%
I - num batch: 87
I - Val -- Loss: 1.471 | Acc: 28.161% | Wgt Acc: 34.746% | Dur: 42.09s
I - Confusion Matrix: [row->prediction - col->label]
[[117.  11.  15. 103.  32.]
 [  0.   0.   0.   0.   0.]
 [ 75. 249. 266.  88. 392.]
 [  2.   3.   0.   5.   3.]
 [  5.   5.   9.   8.   4.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 1.398 | Acc: 40.250% | Wgt Acc: 32.134%
	I - Batch: 100 | Loss: 1.404 | Acc: 40.062% | Wgt Acc: 34.354%
	I - Batch: 150 | Loss: 1.419 | Acc: 35.000% | Wgt Acc: 34.595%
	I - Batch: 200 | Loss: 1.426 | Acc: 36.000% | Wgt Acc: 33.631%
	I - Batch: 250 | Loss: 1.429 | Acc: 37.775% | Wgt Acc: 32.699%
	I - Batch: 300 | Loss: 1.433 | Acc: 38.500% | Wgt Acc: 32.846%
	I - Batch: 350 | Loss: 1.438 | Acc: 38.768% | Wgt Acc: 32.078%
I - num batch: 364
I - Train -- Loss: 1.440 | Acc: 38.194% | Wgt Acc: 32.022% | LR: 1.000000e-03 | Dur: 226.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 446.   61.   96.  386.  424.]
 [   0.    0.    0.    0.    0.]
 [  68.  226.  341.   89.  890.]
 [  59.   14.   20.   45.   60.]
 [ 119.  367.  517.  198. 1389.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.456 | Acc: 31.125% | Wgt Acc: 34.446%
I - num batch: 87
I - Val -- Loss: 1.470 | Acc: 27.730% | Wgt Acc: 33.190% | Dur: 42.01s
I - Confusion Matrix: [row->prediction - col->label]
[[  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 59. 257. 265.  76. 378.]
 [119.   8.  14.  96.  28.]
 [ 21.   3.  11.  32.  25.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 1.445 | Acc: 24.625% | Wgt Acc: 32.333%
	I - Batch: 100 | Loss: 1.430 | Acc: 27.312% | Wgt Acc: 35.165%
	I - Batch: 150 | Loss: 1.443 | Acc: 30.792% | Wgt Acc: 34.441%
	I - Batch: 200 | Loss: 1.461 | Acc: 32.312% | Wgt Acc: 32.530%
	I - Batch: 250 | Loss: 1.464 | Acc: 31.700% | Wgt Acc: 31.303%
	I - Batch: 300 | Loss: 1.460 | Acc: 30.875% | Wgt Acc: 32.023%
	I - Batch: 350 | Loss: 1.454 | Acc: 30.911% | Wgt Acc: 32.101%
I - num batch: 364
I - Train -- Loss: 1.454 | Acc: 31.316% | Wgt Acc: 31.901% | LR: 1.000000e-03 | Dur: 226.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 356.   62.  110.  325.  380.]
 [   0.    0.    0.    0.    0.]
 [  84.  361.  521.  124. 1405.]
 [ 157.   28.   59.  151.  185.]
 [  95.  217.  284.  118.  793.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.492 | Acc: 28.375% | Wgt Acc: 17.416%
I - num batch: 87
I - Val -- Loss: 1.467 | Acc: 36.494% | Wgt Acc: 21.766% | Dur: 43.10s
I - Confusion Matrix: [row->prediction - col->label]
[[120.  13.  15. 108.  43.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 79. 255. 275.  96. 388.]]

I - Local maximum validation set accuracy:  36.49

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 1.499 | Acc: 41.375% | Wgt Acc: 27.302%
	I - Batch: 100 | Loss: 1.486 | Acc: 37.500% | Wgt Acc: 29.550%
	I - Batch: 150 | Loss: 1.489 | Acc: 32.542% | Wgt Acc: 30.166%
	I - Batch: 200 | Loss: 1.493 | Acc: 32.594% | Wgt Acc: 29.706%
	I - Batch: 250 | Loss: 1.489 | Acc: 32.475% | Wgt Acc: 29.935%
	I - Batch: 300 | Loss: 1.480 | Acc: 31.646% | Wgt Acc: 30.430%
	I - Batch: 350 | Loss: 1.477 | Acc: 31.000% | Wgt Acc: 30.875%
I - num batch: 364
I - Train -- Loss: 1.478 | Acc: 30.851% | Wgt Acc: 30.885% | LR: 1.000000e-03 | Dur: 232.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 360.   75.  107.  319.  403.]
 [   0.    0.    0.    0.    0.]
 [ 115.  364.  540.  176. 1427.]
 [  94.   18.   21.   68.  107.]
 [ 123.  211.  306.  155.  826.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.562 | Acc: 29.750% | Wgt Acc: 28.669%
I - num batch: 87
I - Val -- Loss: 1.521 | Acc: 30.603% | Wgt Acc: 30.013% | Dur: 43.49s
I - Confusion Matrix: [row->prediction - col->label]
[[167.  89.  71. 146. 148.]
 [  0.   0.   0.   0.   0.]
 [ 14. 104. 136.  24. 160.]
 [  0.   0.   0.   0.   0.]
 [ 18.  75.  83.  34. 123.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 1.460 | Acc: 30.250% | Wgt Acc: 33.946%
	I - Batch: 100 | Loss: 1.453 | Acc: 28.750% | Wgt Acc: 34.181%
	I - Batch: 150 | Loss: 1.459 | Acc: 28.125% | Wgt Acc: 33.655%
	I - Batch: 200 | Loss: 1.464 | Acc: 27.406% | Wgt Acc: 32.484%
	I - Batch: 250 | Loss: 1.462 | Acc: 27.450% | Wgt Acc: 31.818%
	I - Batch: 300 | Loss: 1.462 | Acc: 27.104% | Wgt Acc: 31.829%
	I - Batch: 350 | Loss: 1.467 | Acc: 28.821% | Wgt Acc: 31.316%
I - num batch: 364
I - Train -- Loss: 1.465 | Acc: 28.650% | Wgt Acc: 31.301% | LR: 1.000000e-03 | Dur: 232.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 378.   71.  124.  363.  452.]
 [   0.    0.    0.    0.    0.]
 [ 111.  426.  615.  167. 1578.]
 [  84.   21.   26.   66.  126.]
 [ 119.  150.  209.  122.  607.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.413 | Acc: 34.375% | Wgt Acc: 37.074%
I - num batch: 87
I - Val -- Loss: 1.402 | Acc: 31.753% | Wgt Acc: 36.224% | Dur: 43.41s
I - Confusion Matrix: [row->prediction - col->label]
[[144.  18.  21. 135.  58.]
 [  0.   0.   0.   0.   0.]
 [ 38. 234. 247.  50. 322.]
 [  0.   0.   0.   0.   0.]
 [ 17.  16.  22.  19.  51.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 1.447 | Acc: 31.125% | Wgt Acc: 34.772%
	I - Batch: 100 | Loss: 1.453 | Acc: 29.938% | Wgt Acc: 31.226%
	I - Batch: 150 | Loss: 1.457 | Acc: 31.958% | Wgt Acc: 30.525%
	I - Batch: 200 | Loss: 1.453 | Acc: 30.312% | Wgt Acc: 31.675%
	I - Batch: 250 | Loss: 1.449 | Acc: 28.950% | Wgt Acc: 31.971%
	I - Batch: 300 | Loss: 1.456 | Acc: 29.292% | Wgt Acc: 31.524%
	I - Batch: 350 | Loss: 1.452 | Acc: 30.214% | Wgt Acc: 31.747%
I - num batch: 364
I - Train -- Loss: 1.451 | Acc: 30.198% | Wgt Acc: 31.933% | LR: 1.000000e-03 | Dur: 231.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 401.   69.  126.  346.  460.]
 [   0.    0.    0.    0.    1.]
 [  94.  397.  557.  148. 1427.]
 [  97.   34.   53.  104.  181.]
 [ 100.  168.  238.  120.  694.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.451 | Acc: 32.000% | Wgt Acc: 31.077%
I - num batch: 87
I - Val -- Loss: 1.426 | Acc: 31.753% | Wgt Acc: 31.464% | Dur: 43.49s
I - Confusion Matrix: [row->prediction - col->label]
[[138.  29.  24. 133.  63.]
 [  0.   0.   0.   0.   0.]
 [ 16. 174. 175.  21. 239.]
 [  0.   0.   0.   0.   0.]
 [ 45.  65.  91.  50. 129.]]

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 1.466 | Acc: 28.375% | Wgt Acc: 30.472%
	I - Batch: 100 | Loss: 1.460 | Acc: 30.875% | Wgt Acc: 31.980%
	I - Batch: 150 | Loss: 1.451 | Acc: 30.083% | Wgt Acc: 32.526%
	I - Batch: 200 | Loss: 1.447 | Acc: 30.125% | Wgt Acc: 31.917%
	I - Batch: 250 | Loss: 1.454 | Acc: 32.875% | Wgt Acc: 32.263%
	I - Batch: 300 | Loss: 1.448 | Acc: 31.812% | Wgt Acc: 32.640%
	I - Batch: 350 | Loss: 1.443 | Acc: 31.393% | Wgt Acc: 33.036%
I - num batch: 364
I - Train -- Loss: 1.443 | Acc: 31.247% | Wgt Acc: 33.102% | LR: 5.000000e-04 | Dur: 231.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 503.   72.  133.  399.  547.]
 [   0.    0.    0.    0.    0.]
 [  72.  440.  594.  144. 1490.]
 [   1.    2.    5.    2.    8.]
 [ 116.  154.  242.  173.  718.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.408 | Acc: 34.875% | Wgt Acc: 36.266%
I - num batch: 87
I - Val -- Loss: 1.388 | Acc: 32.543% | Wgt Acc: 35.911% | Dur: 43.41s
I - Confusion Matrix: [row->prediction - col->label]
[[163.  27.  40. 148.  92.]
 [  0.   0.   0.   0.   0.]
 [ 18. 210. 221.  32. 270.]
 [  0.   0.   0.   0.   0.]
 [ 18.  31.  29.  24.  69.]]

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 1.417 | Acc: 30.625% | Wgt Acc: 33.941%
	I - Batch: 100 | Loss: 1.424 | Acc: 29.875% | Wgt Acc: 34.403%
	I - Batch: 150 | Loss: 1.427 | Acc: 31.417% | Wgt Acc: 33.488%
	I - Batch: 200 | Loss: 1.422 | Acc: 31.188% | Wgt Acc: 33.385%
	I - Batch: 250 | Loss: 1.418 | Acc: 30.700% | Wgt Acc: 33.656%
	I - Batch: 300 | Loss: 1.418 | Acc: 31.229% | Wgt Acc: 33.814%
	I - Batch: 350 | Loss: 1.417 | Acc: 30.839% | Wgt Acc: 33.842%
I - num batch: 364
I - Train -- Loss: 1.416 | Acc: 30.834% | Wgt Acc: 33.960% | LR: 5.000000e-04 | Dur: 231.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 501.   70.  123.  421.  427.]
 [   0.    0.    0.    0.    0.]
 [  69.  475.  654.  141. 1695.]
 [   1.    4.    2.    6.    9.]
 [ 121.  119.  195.  150.  632.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.418 | Acc: 33.750% | Wgt Acc: 34.673%
I - num batch: 87
I - Val -- Loss: 1.402 | Acc: 31.250% | Wgt Acc: 33.817% | Dur: 43.43s
I - Confusion Matrix: [row->prediction - col->label]
[[146.  21.  23. 124.  55.]
 [  0.   0.   0.   0.   0.]
 [ 26. 204. 210.  32. 297.]
 [  0.   0.   0.   0.   0.]
 [ 27.  43.  57.  48.  79.]]

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 1.389 | Acc: 27.125% | Wgt Acc: 34.284%
	I - Batch: 100 | Loss: 1.400 | Acc: 27.688% | Wgt Acc: 35.094%
	I - Batch: 150 | Loss: 1.407 | Acc: 27.750% | Wgt Acc: 34.778%
	I - Batch: 200 | Loss: 1.405 | Acc: 28.188% | Wgt Acc: 34.755%
	I - Batch: 250 | Loss: 1.407 | Acc: 27.350% | Wgt Acc: 33.684%
	I - Batch: 300 | Loss: 1.404 | Acc: 27.458% | Wgt Acc: 33.925%
	I - Batch: 350 | Loss: 1.413 | Acc: 29.054% | Wgt Acc: 33.107%
I - num batch: 364
I - Train -- Loss: 1.411 | Acc: 29.819% | Wgt Acc: 33.104% | LR: 5.000000e-04 | Dur: 231.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 502.   58.  113.  421.  460.]
 [   0.    0.    0.    0.    0.]
 [  83.  473.  634.  151. 1692.]
 [  11.    2.    6.    5.   18.]
 [  96.  135.  221.  141.  593.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.437 | Acc: 28.000% | Wgt Acc: 19.817%
I - num batch: 87
I - Val -- Loss: 1.396 | Acc: 35.704% | Wgt Acc: 24.645% | Dur: 43.34s
I - Confusion Matrix: [row->prediction - col->label]
[[162.  15.  33. 128.  75.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 15.  26.  16.  22.  43.]
 [ 22. 227. 241.  54. 313.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 1.396 | Acc: 30.750% | Wgt Acc: 33.866%
	I - Batch: 100 | Loss: 1.411 | Acc: 28.312% | Wgt Acc: 32.815%
	I - Batch: 150 | Loss: 1.427 | Acc: 29.667% | Wgt Acc: 32.278%
	I - Batch: 200 | Loss: 1.423 | Acc: 29.312% | Wgt Acc: 32.945%
	I - Batch: 250 | Loss: 1.424 | Acc: 29.575% | Wgt Acc: 32.676%
	I - Batch: 300 | Loss: 1.423 | Acc: 29.542% | Wgt Acc: 32.559%
	I - Batch: 350 | Loss: 1.423 | Acc: 29.268% | Wgt Acc: 32.751%
I - num batch: 364
I - Train -- Loss: 1.424 | Acc: 29.252% | Wgt Acc: 32.809% | LR: 5.000000e-04 | Dur: 232.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 473.   65.  124.  419.  541.]
 [   0.    0.    0.    0.    0.]
 [  66.  445.  614.  113. 1565.]
 [  58.   22.   39.   58.  101.]
 [  95.  136.  197.  128.  556.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.442 | Acc: 32.125% | Wgt Acc: 33.454%
I - num batch: 87
I - Val -- Loss: 1.412 | Acc: 30.244% | Wgt Acc: 33.229% | Dur: 43.55s
I - Confusion Matrix: [row->prediction - col->label]
[[146.  40.  38. 146.  77.]
 [  0.   0.   0.   0.   0.]
 [ 18. 192. 201.  30. 269.]
 [  8.   4.  13.   8.  19.]
 [ 27.  32.  38.  20.  66.]]

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 1.401 | Acc: 28.000% | Wgt Acc: 33.331%
	I - Batch: 100 | Loss: 1.410 | Acc: 27.812% | Wgt Acc: 34.018%
	I - Batch: 150 | Loss: 1.417 | Acc: 28.125% | Wgt Acc: 33.660%
	I - Batch: 200 | Loss: 1.409 | Acc: 31.844% | Wgt Acc: 33.472%
	I - Batch: 250 | Loss: 1.406 | Acc: 32.125% | Wgt Acc: 34.424%
	I - Batch: 300 | Loss: 1.409 | Acc: 31.667% | Wgt Acc: 34.046%
	I - Batch: 350 | Loss: 1.406 | Acc: 31.964% | Wgt Acc: 34.176%
I - num batch: 364
I - Train -- Loss: 1.407 | Acc: 31.814% | Wgt Acc: 34.066% | LR: 5.000000e-04 | Dur: 232.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.   59.   99.  386.  360.]
 [   0.    0.    0.    0.    0.]
 [  69.  424.  604.  111. 1517.]
 [  72.   29.   38.   78.  181.]
 [  88.  156.  233.  143.  705.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.412 | Acc: 32.625% | Wgt Acc: 33.472%
I - num batch: 87
I - Val -- Loss: 1.385 | Acc: 32.256% | Wgt Acc: 34.332% | Dur: 43.62s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   8.  13. 112.  30.]
 [  0.   0.   0.   0.   0.]
 [ 16. 195. 204.  26. 262.]
 [ 28.  14.  21.  29.  49.]
 [ 29.  51.  52.  37.  90.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 1.367 | Acc: 31.000% | Wgt Acc: 36.699%
	I - Batch: 100 | Loss: 1.387 | Acc: 29.562% | Wgt Acc: 35.026%
	I - Batch: 150 | Loss: 1.403 | Acc: 30.000% | Wgt Acc: 33.090%
	I - Batch: 200 | Loss: 1.404 | Acc: 29.500% | Wgt Acc: 33.022%
	I - Batch: 250 | Loss: 1.404 | Acc: 29.000% | Wgt Acc: 33.100%
	I - Batch: 300 | Loss: 1.404 | Acc: 28.104% | Wgt Acc: 32.859%
	I - Batch: 350 | Loss: 1.406 | Acc: 28.321% | Wgt Acc: 33.485%
I - num batch: 364
I - Train -- Loss: 1.405 | Acc: 28.151% | Wgt Acc: 33.352% | LR: 5.000000e-04 | Dur: 232.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 442.   41.   82.  359.  332.]
 [   0.    0.    0.    0.    0.]
 [  78.  495.  666.  146. 1772.]
 [  85.   31.   65.  103.  233.]
 [  87.  101.  161.  110.  426.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.416 | Acc: 33.000% | Wgt Acc: 34.207%
I - num batch: 87
I - Val -- Loss: 1.391 | Acc: 31.178% | Wgt Acc: 34.123% | Dur: 43.76s
I - Confusion Matrix: [row->prediction - col->label]
[[144.  14.  23. 134.  60.]
 [  0.   0.   0.   0.   0.]
 [ 15. 167. 187.  19. 227.]
 [ 29.  44.  52.  37.  78.]
 [ 11.  43.  28.  14.  66.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 1.401 | Acc: 27.875% | Wgt Acc: 33.289%
	I - Batch: 100 | Loss: 1.396 | Acc: 28.750% | Wgt Acc: 33.070%
	I - Batch: 150 | Loss: 1.385 | Acc: 29.417% | Wgt Acc: 33.789%
	I - Batch: 200 | Loss: 1.388 | Acc: 29.938% | Wgt Acc: 33.877%
	I - Batch: 250 | Loss: 1.389 | Acc: 30.325% | Wgt Acc: 34.841%
	I - Batch: 300 | Loss: 1.402 | Acc: 30.646% | Wgt Acc: 34.993%
	I - Batch: 350 | Loss: 1.407 | Acc: 30.589% | Wgt Acc: 34.322%
I - num batch: 364
I - Train -- Loss: 1.407 | Acc: 30.662% | Wgt Acc: 34.319% | LR: 5.000000e-04 | Dur: 232.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 453.   40.   78.  351.  345.]
 [   0.    0.    0.    0.    0.]
 [  78.  458.  683.  132. 1681.]
 [  44.   20.   43.   50.  140.]
 [ 117.  150.  170.  185.  597.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.449 | Acc: 31.375% | Wgt Acc: 30.556%
I - num batch: 87
I - Val -- Loss: 1.418 | Acc: 32.399% | Wgt Acc: 31.476% | Dur: 43.77s
I - Confusion Matrix: [row->prediction - col->label]
[[140.  21.  22. 125.  65.]
 [  0.   0.   0.   0.   0.]
 [  7. 143. 152.  18. 199.]
 [ 15.  17.  14.  21.  29.]
 [ 37.  87. 102.  40. 138.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 1.441 | Acc: 39.500% | Wgt Acc: 29.511%
	I - Batch: 100 | Loss: 1.424 | Acc: 36.875% | Wgt Acc: 31.811%
	I - Batch: 150 | Loss: 1.421 | Acc: 33.792% | Wgt Acc: 31.644%
	I - Batch: 200 | Loss: 1.413 | Acc: 33.875% | Wgt Acc: 32.344%
	I - Batch: 250 | Loss: 1.413 | Acc: 32.625% | Wgt Acc: 32.414%
	I - Batch: 300 | Loss: 1.409 | Acc: 32.083% | Wgt Acc: 32.478%
	I - Batch: 350 | Loss: 1.403 | Acc: 32.321% | Wgt Acc: 32.991%
I - num batch: 364
I - Train -- Loss: 1.401 | Acc: 32.313% | Wgt Acc: 33.145% | LR: 5.000000e-04 | Dur: 232.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 405.   42.   59.  341.  369.]
 [   0.    0.    0.    0.    0.]
 [  48.  404.  585.   89. 1472.]
 [  74.   25.   36.   76.  109.]
 [ 165.  197.  294.  212.  813.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.384 | Acc: 33.250% | Wgt Acc: 33.668%
I - num batch: 87
I - Val -- Loss: 1.378 | Acc: 33.405% | Wgt Acc: 34.347% | Dur: 43.96s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   8.  16.  94.  26.]
 [  0.   0.   0.   0.   0.]
 [ 17. 199. 206.  26. 275.]
 [ 13.   3.   6.  25.  14.]
 [ 51.  58.  62.  59. 116.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 1.409 | Acc: 34.875% | Wgt Acc: 33.527%
	I - Batch: 100 | Loss: 1.425 | Acc: 37.688% | Wgt Acc: 31.676%
	I - Batch: 150 | Loss: 1.415 | Acc: 33.875% | Wgt Acc: 32.448%
	I - Batch: 200 | Loss: 1.412 | Acc: 33.625% | Wgt Acc: 33.520%
	I - Batch: 250 | Loss: 1.405 | Acc: 33.475% | Wgt Acc: 33.822%
	I - Batch: 300 | Loss: 1.403 | Acc: 33.354% | Wgt Acc: 33.612%
	I - Batch: 350 | Loss: 1.401 | Acc: 33.786% | Wgt Acc: 33.794%
I - num batch: 364
I - Train -- Loss: 1.399 | Acc: 33.844% | Wgt Acc: 33.789% | LR: 5.000000e-04 | Dur: 232.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 432.   32.   79.  337.  305.]
 [   0.    0.    0.    0.    0.]
 [  51.  374.  529.   74. 1376.]
 [  86.   24.   55.  109.  184.]
 [ 123.  238.  311.  198.  898.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.404 | Acc: 34.000% | Wgt Acc: 29.074%
I - num batch: 87
I - Val -- Loss: 1.374 | Acc: 37.069% | Wgt Acc: 31.189% | Dur: 43.72s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   8.  13. 112.  38.]
 [  0.   0.   0.   0.   0.]
 [  2.  74.  97.   2.  94.]
 [ 28.  18.  26.  45.  63.]
 [ 31. 168. 154.  45. 236.]]

I - Local maximum validation set accuracy:  37.07

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 1.404 | Acc: 40.375% | Wgt Acc: 30.156%
	I - Batch: 100 | Loss: 1.389 | Acc: 39.875% | Wgt Acc: 33.032%
	I - Batch: 150 | Loss: 1.394 | Acc: 39.042% | Wgt Acc: 32.632%
	I - Batch: 200 | Loss: 1.395 | Acc: 38.406% | Wgt Acc: 32.388%
	I - Batch: 250 | Loss: 1.393 | Acc: 37.250% | Wgt Acc: 32.893%
	I - Batch: 300 | Loss: 1.389 | Acc: 36.708% | Wgt Acc: 33.962%
	I - Batch: 350 | Loss: 1.383 | Acc: 36.304% | Wgt Acc: 34.218%
I - num batch: 364
I - Train -- Loss: 1.383 | Acc: 36.131% | Wgt Acc: 34.170% | LR: 5.000000e-04 | Dur: 232.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 413.   24.   63.  315.  276.]
 [   0.    0.    0.    0.    0.]
 [  31.  358.  530.   58. 1282.]
 [  61.   14.   24.   72.  119.]
 [ 187.  272.  357.  273. 1086.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.376 | Acc: 33.250% | Wgt Acc: 34.875%
I - num batch: 87
I - Val -- Loss: 1.355 | Acc: 32.399% | Wgt Acc: 35.284% | Dur: 43.78s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   4.  11. 105.  24.]
 [  0.   0.   0.   0.   0.]
 [ 21. 212. 220.  42. 313.]
 [ 19.   7.  12.  23.  16.]
 [ 29.  45.  47.  34.  78.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 1.375 | Acc: 28.875% | Wgt Acc: 33.899%
	I - Batch: 100 | Loss: 1.369 | Acc: 29.375% | Wgt Acc: 34.233%
	I - Batch: 150 | Loss: 1.369 | Acc: 29.750% | Wgt Acc: 34.563%
	I - Batch: 200 | Loss: 1.378 | Acc: 30.000% | Wgt Acc: 33.938%
	I - Batch: 250 | Loss: 1.367 | Acc: 31.850% | Wgt Acc: 34.413%
	I - Batch: 300 | Loss: 1.368 | Acc: 32.750% | Wgt Acc: 34.495%
	I - Batch: 350 | Loss: 1.369 | Acc: 33.375% | Wgt Acc: 34.493%
I - num batch: 364
I - Train -- Loss: 1.370 | Acc: 33.568% | Wgt Acc: 34.607% | LR: 2.500000e-04 | Dur: 232.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 410.   22.   49.  335.  233.]
 [   0.    0.    0.    0.    0.]
 [  43.  433.  620.   86. 1477.]
 [ 102.   28.   41.   87.  218.]
 [ 137.  185.  264.  210.  835.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.372 | Acc: 34.875% | Wgt Acc: 32.155%
I - num batch: 87
I - Val -- Loss: 1.343 | Acc: 36.853% | Wgt Acc: 33.922% | Dur: 43.68s
I - Confusion Matrix: [row->prediction - col->label]
[[151.   9.  19. 119.  49.]
 [  0.   0.   0.   0.   0.]
 [  2. 134. 141.   8. 153.]
 [ 16.  21.  14.  34.  42.]
 [ 30. 104. 116.  43. 187.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 1.392 | Acc: 36.750% | Wgt Acc: 34.579%
	I - Batch: 100 | Loss: 1.369 | Acc: 36.562% | Wgt Acc: 36.487%
	I - Batch: 150 | Loss: 1.373 | Acc: 35.542% | Wgt Acc: 36.422%
	I - Batch: 200 | Loss: 1.369 | Acc: 34.812% | Wgt Acc: 35.859%
	I - Batch: 250 | Loss: 1.368 | Acc: 35.325% | Wgt Acc: 36.094%
	I - Batch: 300 | Loss: 1.368 | Acc: 35.562% | Wgt Acc: 36.088%
	I - Batch: 350 | Loss: 1.366 | Acc: 35.304% | Wgt Acc: 35.990%
I - num batch: 364
I - Train -- Loss: 1.368 | Acc: 35.305% | Wgt Acc: 35.947% | LR: 2.500000e-04 | Dur: 232.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 483.   37.   73.  384.  335.]
 [   0.    0.    0.    0.    0.]
 [  45.  427.  612.   65. 1391.]
 [  50.   10.   33.   57.  136.]
 [ 114.  194.  256.  212.  901.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.381 | Acc: 34.750% | Wgt Acc: 33.203%
I - num batch: 87
I - Val -- Loss: 1.354 | Acc: 35.273% | Wgt Acc: 33.732% | Dur: 43.87s
I - Confusion Matrix: [row->prediction - col->label]
[[141.  13.  20. 139.  48.]
 [  0.   0.   0.   0.   0.]
 [  4. 167. 179.  14. 203.]
 [  9.   5.  11.   7.  16.]
 [ 45.  83.  80.  44. 164.]]

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 1.362 | Acc: 41.500% | Wgt Acc: 38.282%
	I - Batch: 100 | Loss: 1.357 | Acc: 40.750% | Wgt Acc: 36.324%
	I - Batch: 150 | Loss: 1.352 | Acc: 39.208% | Wgt Acc: 36.811%
	I - Batch: 200 | Loss: 1.366 | Acc: 37.625% | Wgt Acc: 35.202%
	I - Batch: 250 | Loss: 1.365 | Acc: 37.950% | Wgt Acc: 35.012%
	I - Batch: 300 | Loss: 1.369 | Acc: 38.562% | Wgt Acc: 34.946%
	I - Batch: 350 | Loss: 1.372 | Acc: 38.911% | Wgt Acc: 35.024%
I - num batch: 364
I - Train -- Loss: 1.371 | Acc: 39.089% | Wgt Acc: 35.180% | LR: 2.500000e-04 | Dur: 232.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 449.   26.   62.  349.  278.]
 [   0.    0.    0.    0.    0.]
 [  35.  358.  491.   57. 1119.]
 [  50.   10.   20.   50.   83.]
 [ 158.  274.  401.  262. 1283.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.362 | Acc: 36.125% | Wgt Acc: 32.112%
I - num batch: 87
I - Val -- Loss: 1.338 | Acc: 38.075% | Wgt Acc: 34.018% | Dur: 43.71s
I - Confusion Matrix: [row->prediction - col->label]
[[151.  10.  20. 119.  44.]
 [  0.   0.   0.   0.   0.]
 [  2. 127. 143.   9. 146.]
 [  8.   8.  13.  23.  28.]
 [ 38. 123. 114.  53. 213.]]

I - Local maximum validation set accuracy:  38.07

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 1.352 | Acc: 40.125% | Wgt Acc: 36.093%
	I - Batch: 100 | Loss: 1.348 | Acc: 38.625% | Wgt Acc: 36.517%
	I - Batch: 150 | Loss: 1.366 | Acc: 37.042% | Wgt Acc: 35.633%
	I - Batch: 200 | Loss: 1.370 | Acc: 35.969% | Wgt Acc: 34.756%
	I - Batch: 250 | Loss: 1.363 | Acc: 36.750% | Wgt Acc: 35.925%
	I - Batch: 300 | Loss: 1.361 | Acc: 36.625% | Wgt Acc: 35.858%
	I - Batch: 350 | Loss: 1.366 | Acc: 36.929% | Wgt Acc: 35.708%
I - num batch: 364
I - Train -- Loss: 1.365 | Acc: 36.853% | Wgt Acc: 35.618% | LR: 2.500000e-04 | Dur: 233.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 441.   20.   49.  312.  242.]
 [   0.    0.    0.    0.    0.]
 [  30.  390.  548.   66. 1270.]
 [  82.   24.   39.   99.  196.]
 [ 139.  234.  338.  241. 1055.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.372 | Acc: 35.500% | Wgt Acc: 32.351%
I - num batch: 87
I - Val -- Loss: 1.347 | Acc: 38.218% | Wgt Acc: 34.901% | Dur: 43.72s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   4.   5.  81.  17.]
 [  0.   0.   0.   0.   0.]
 [  5. 177. 179.  17. 196.]
 [ 31.   7.   8.  39.  11.]
 [ 56.  80.  98.  67. 207.]]

I - Local maximum validation set accuracy:  38.22

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 1.374 | Acc: 36.875% | Wgt Acc: 34.967%
	I - Batch: 100 | Loss: 1.356 | Acc: 37.375% | Wgt Acc: 35.557%
	I - Batch: 150 | Loss: 1.359 | Acc: 38.042% | Wgt Acc: 36.256%
	I - Batch: 200 | Loss: 1.361 | Acc: 37.906% | Wgt Acc: 36.177%
	I - Batch: 250 | Loss: 1.364 | Acc: 38.000% | Wgt Acc: 36.028%
	I - Batch: 300 | Loss: 1.360 | Acc: 37.833% | Wgt Acc: 36.077%
	I - Batch: 350 | Loss: 1.359 | Acc: 37.661% | Wgt Acc: 36.173%
I - num batch: 364
I - Train -- Loss: 1.361 | Acc: 37.455% | Wgt Acc: 36.078% | LR: 2.500000e-04 | Dur: 232.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 425.   20.   44.  304.  209.]
 [   0.    0.    0.    0.    0.]
 [  29.  379.  540.   50. 1209.]
 [ 106.   33.   64.  136.  268.]
 [ 132.  236.  326.  228. 1077.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.367 | Acc: 35.750% | Wgt Acc: 35.243%
I - num batch: 87
I - Val -- Loss: 1.346 | Acc: 34.339% | Wgt Acc: 35.338% | Dur: 43.26s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   3.   3.  76.  13.]
 [  0.   0.   0.   0.   0.]
 [ 10. 192. 209.  24. 258.]
 [ 49.  11.  16.  49.  42.]
 [ 38.  62.  62.  55. 118.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 1.340 | Acc: 32.250% | Wgt Acc: 36.019%
	I - Batch: 100 | Loss: 1.346 | Acc: 32.875% | Wgt Acc: 36.719%
	I - Batch: 150 | Loss: 1.340 | Acc: 32.958% | Wgt Acc: 36.213%
	I - Batch: 200 | Loss: 1.344 | Acc: 35.219% | Wgt Acc: 36.726%
	I - Batch: 250 | Loss: 1.348 | Acc: 35.625% | Wgt Acc: 35.747%
	I - Batch: 300 | Loss: 1.348 | Acc: 35.812% | Wgt Acc: 35.341%
	I - Batch: 350 | Loss: 1.349 | Acc: 35.661% | Wgt Acc: 35.288%
I - num batch: 364
I - Train -- Loss: 1.349 | Acc: 35.856% | Wgt Acc: 35.599% | LR: 1.250000e-04 | Dur: 230.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 434.   19.   32.  333.  213.]
 [   0.    0.    0.    0.    0.]
 [  27.  381.  571.   61. 1311.]
 [ 101.   28.   69.  112.  271.]
 [ 130.  240.  302.  212.  968.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.413 | Acc: 34.000% | Wgt Acc: 33.246%
I - num batch: 87
I - Val -- Loss: 1.371 | Acc: 34.555% | Wgt Acc: 34.007% | Dur: 43.23s
I - Confusion Matrix: [row->prediction - col->label]
[[158.  18.  25. 143.  66.]
 [  0.   0.   0.   0.   0.]
 [  3. 135. 160.   7. 162.]
 [ 22.  31.  27.  25.  65.]
 [ 16.  84.  78.  29. 138.]]

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 1.340 | Acc: 33.125% | Wgt Acc: 34.718%
	I - Batch: 100 | Loss: 1.336 | Acc: 35.812% | Wgt Acc: 37.993%
	I - Batch: 150 | Loss: 1.332 | Acc: 34.917% | Wgt Acc: 37.313%
	I - Batch: 200 | Loss: 1.330 | Acc: 35.250% | Wgt Acc: 36.878%
	I - Batch: 250 | Loss: 1.337 | Acc: 34.575% | Wgt Acc: 36.296%
	I - Batch: 300 | Loss: 1.343 | Acc: 34.396% | Wgt Acc: 36.213%
	I - Batch: 350 | Loss: 1.338 | Acc: 34.732% | Wgt Acc: 36.600%
I - num batch: 364
I - Train -- Loss: 1.339 | Acc: 34.669% | Wgt Acc: 36.595% | LR: 1.250000e-04 | Dur: 231.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 434.   17.   34.  332.  215.]
 [   0.    0.    0.    0.    0.]
 [  30.  450.  646.   75. 1503.]
 [ 105.   24.   56.  133.  242.]
 [ 123.  177.  238.  178.  803.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.346 | Acc: 36.750% | Wgt Acc: 37.332%
I - num batch: 87
I - Val -- Loss: 1.335 | Acc: 34.986% | Wgt Acc: 36.994% | Dur: 43.18s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   5.   7.  84.  19.]
 [  0.   0.   0.   0.   0.]
 [ 15. 212. 228.  32. 289.]
 [ 30.   6.  13.  32.  19.]
 [ 31.  45.  42.  56. 104.]]

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 1.368 | Acc: 33.000% | Wgt Acc: 36.492%
	I - Batch: 100 | Loss: 1.338 | Acc: 34.062% | Wgt Acc: 37.405%
	I - Batch: 150 | Loss: 1.337 | Acc: 33.958% | Wgt Acc: 37.216%
	I - Batch: 200 | Loss: 1.336 | Acc: 33.688% | Wgt Acc: 36.911%
	I - Batch: 250 | Loss: 1.332 | Acc: 33.550% | Wgt Acc: 36.935%
	I - Batch: 300 | Loss: 1.333 | Acc: 33.979% | Wgt Acc: 37.301%
	I - Batch: 350 | Loss: 1.342 | Acc: 33.911% | Wgt Acc: 36.835%
I - num batch: 364
I - Train -- Loss: 1.339 | Acc: 34.394% | Wgt Acc: 37.287% | LR: 1.250000e-04 | Dur: 231.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 442.   15.   41.  323.  205.]
 [   0.    0.    0.    0.    0.]
 [  41.  486.  694.  102. 1563.]
 [ 103.   19.   43.  125.  256.]
 [ 106.  148.  196.  168.  739.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.355 | Acc: 37.625% | Wgt Acc: 35.592%
I - num batch: 87
I - Val -- Loss: 1.332 | Acc: 38.362% | Wgt Acc: 36.693% | Dur: 43.16s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   2.   5.  67.  15.]
 [  0.   0.   0.   0.   0.]
 [  9. 193. 198.  15. 213.]
 [ 46.  11.  14.  55.  24.]
 [ 42.  62.  73.  67. 179.]]

I - Local maximum validation set accuracy:  38.36

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 1.377 | Acc: 33.875% | Wgt Acc: 35.382%
	I - Batch: 100 | Loss: 1.345 | Acc: 35.188% | Wgt Acc: 36.288%
	I - Batch: 150 | Loss: 1.336 | Acc: 36.083% | Wgt Acc: 37.669%
	I - Batch: 200 | Loss: 1.336 | Acc: 36.219% | Wgt Acc: 37.721%
	I - Batch: 250 | Loss: 1.333 | Acc: 36.325% | Wgt Acc: 38.105%
	I - Batch: 300 | Loss: 1.331 | Acc: 36.896% | Wgt Acc: 38.344%
	I - Batch: 350 | Loss: 1.333 | Acc: 36.732% | Wgt Acc: 38.026%
I - num batch: 364
I - Train -- Loss: 1.331 | Acc: 36.698% | Wgt Acc: 37.965% | LR: 1.250000e-04 | Dur: 231.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 450.   11.   40.  317.  195.]
 [   0.    0.    0.    0.    0.]
 [  24.  445.  654.   71. 1389.]
 [ 106.   30.   48.  132.  281.]
 [ 112.  182.  232.  198.  898.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.358 | Acc: 35.875% | Wgt Acc: 37.521%
I - num batch: 87
I - Val -- Loss: 1.352 | Acc: 33.836% | Wgt Acc: 37.420% | Dur: 43.28s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   2.   3.  71.  12.]
 [  0.   0.   0.   0.   0.]
 [ 31. 239. 251.  44. 334.]
 [ 24.   3.   7.  33.  10.]
 [ 32.  24.  29.  56.  75.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 1.312 | Acc: 35.500% | Wgt Acc: 39.338%
	I - Batch: 100 | Loss: 1.330 | Acc: 34.938% | Wgt Acc: 37.988%
	I - Batch: 150 | Loss: 1.331 | Acc: 36.917% | Wgt Acc: 37.515%
	I - Batch: 200 | Loss: 1.328 | Acc: 37.438% | Wgt Acc: 38.145%
	I - Batch: 250 | Loss: 1.334 | Acc: 37.650% | Wgt Acc: 38.000%
	I - Batch: 300 | Loss: 1.336 | Acc: 38.125% | Wgt Acc: 37.725%
	I - Batch: 350 | Loss: 1.332 | Acc: 38.107% | Wgt Acc: 37.437%
I - num batch: 364
I - Train -- Loss: 1.331 | Acc: 38.263% | Wgt Acc: 37.618% | LR: 1.250000e-04 | Dur: 231.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 437.   15.   28.  316.  209.]
 [   0.    0.    0.    0.    0.]
 [  35.  437.  612.   74. 1279.]
 [  85.   19.   38.  116.  215.]
 [ 135.  197.  296.  212. 1060.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.326 | Acc: 37.250% | Wgt Acc: 36.743%
I - num batch: 87
I - Val -- Loss: 1.305 | Acc: 37.213% | Wgt Acc: 37.327% | Dur: 43.37s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   8.  13. 114.  33.]
 [  0.   0.   0.   0.   0.]
 [ 13. 206. 213.  19. 238.]
 [ 16.   6.   9.  27.  16.]
 [ 36.  48.  55.  44. 144.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 1.308 | Acc: 37.125% | Wgt Acc: 39.299%
	I - Batch: 100 | Loss: 1.308 | Acc: 37.562% | Wgt Acc: 39.810%
	I - Batch: 150 | Loss: 1.320 | Acc: 36.625% | Wgt Acc: 39.028%
	I - Batch: 200 | Loss: 1.309 | Acc: 36.625% | Wgt Acc: 39.268%
	I - Batch: 250 | Loss: 1.314 | Acc: 36.400% | Wgt Acc: 38.825%
	I - Batch: 300 | Loss: 1.314 | Acc: 37.250% | Wgt Acc: 38.940%
	I - Batch: 350 | Loss: 1.317 | Acc: 36.982% | Wgt Acc: 38.415%
I - num batch: 364
I - Train -- Loss: 1.320 | Acc: 36.767% | Wgt Acc: 38.147% | LR: 1.250000e-04 | Dur: 231.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 442.   12.   27.  300.  204.]
 [   0.    0.    0.    0.    0.]
 [  35.  469.  669.   79. 1452.]
 [  85.   15.   40.  132.  212.]
 [ 130.  172.  238.  207.  895.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.318 | Acc: 37.125% | Wgt Acc: 35.420%
I - num batch: 87
I - Val -- Loss: 1.302 | Acc: 39.152% | Wgt Acc: 37.122% | Dur: 43.37s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   3.   5.  77.  14.]
 [  0.   0.   0.   0.   0.]
 [  6. 170. 197.  12. 201.]
 [ 30.   5.  10.  40.  28.]
 [ 43.  90.  78.  75. 188.]]

I - Local maximum validation set accuracy:  39.15

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 1.321 | Acc: 41.000% | Wgt Acc: 34.856%
	I - Batch: 100 | Loss: 1.314 | Acc: 40.625% | Wgt Acc: 37.278%
	I - Batch: 150 | Loss: 1.323 | Acc: 38.375% | Wgt Acc: 36.107%
	I - Batch: 200 | Loss: 1.320 | Acc: 38.031% | Wgt Acc: 36.650%
	I - Batch: 250 | Loss: 1.317 | Acc: 38.250% | Wgt Acc: 37.793%
	I - Batch: 300 | Loss: 1.316 | Acc: 38.083% | Wgt Acc: 37.679%
	I - Batch: 350 | Loss: 1.316 | Acc: 38.000% | Wgt Acc: 37.752%
I - num batch: 364
I - Train -- Loss: 1.315 | Acc: 38.005% | Wgt Acc: 37.879% | LR: 1.250000e-04 | Dur: 231.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 437.    8.   22.  304.  186.]
 [   0.    0.    0.    0.    0.]
 [  28.  447.  637.   66. 1359.]
 [ 102.   20.   44.  113.  195.]
 [ 125.  193.  271.  235. 1023.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.364 | Acc: 34.000% | Wgt Acc: 34.489%
I - num batch: 87
I - Val -- Loss: 1.356 | Acc: 32.399% | Wgt Acc: 34.177% | Dur: 43.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 88.   0.   2.  43.   8.]
 [  0.   0.   0.   0.   0.]
 [ 16. 227. 233.  43. 313.]
 [ 39.   3.   2.  27.   7.]
 [ 56.  38.  53.  91. 103.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 1.305 | Acc: 37.750% | Wgt Acc: 38.737%
	I - Batch: 100 | Loss: 1.295 | Acc: 38.000% | Wgt Acc: 40.006%
	I - Batch: 150 | Loss: 1.295 | Acc: 37.208% | Wgt Acc: 39.237%
	I - Batch: 200 | Loss: 1.311 | Acc: 35.969% | Wgt Acc: 37.908%
	I - Batch: 250 | Loss: 1.311 | Acc: 36.050% | Wgt Acc: 38.234%
	I - Batch: 300 | Loss: 1.312 | Acc: 36.125% | Wgt Acc: 37.884%
	I - Batch: 350 | Loss: 1.307 | Acc: 36.732% | Wgt Acc: 38.456%
I - num batch: 364
I - Train -- Loss: 1.307 | Acc: 36.664% | Wgt Acc: 38.559% | LR: 1.250000e-04 | Dur: 231.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 453.   14.   30.  335.  211.]
 [   0.    0.    0.    0.    0.]
 [  34.  477.  708.   76. 1493.]
 [  91.   16.   33.  106.  194.]
 [ 114.  161.  203.  201.  865.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.408 | Acc: 34.375% | Wgt Acc: 33.148%
I - num batch: 87
I - Val -- Loss: 1.378 | Acc: 34.411% | Wgt Acc: 33.817% | Dur: 43.33s
I - Confusion Matrix: [row->prediction - col->label]
[[170.  20.  32. 153.  96.]
 [  0.   0.   0.   0.   0.]
 [  3. 138. 149.   6. 143.]
 [ 17.  20.  23.  24.  56.]
 [  9.  90.  86.  21. 136.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 1.290 | Acc: 35.000% | Wgt Acc: 37.039%
	I - Batch: 100 | Loss: 1.299 | Acc: 36.188% | Wgt Acc: 36.819%
	I - Batch: 150 | Loss: 1.296 | Acc: 37.542% | Wgt Acc: 37.750%
	I - Batch: 200 | Loss: 1.298 | Acc: 38.594% | Wgt Acc: 38.872%
	I - Batch: 250 | Loss: 1.298 | Acc: 39.275% | Wgt Acc: 39.330%
	I - Batch: 300 | Loss: 1.304 | Acc: 39.042% | Wgt Acc: 39.039%
	I - Batch: 350 | Loss: 1.306 | Acc: 39.286% | Wgt Acc: 39.276%
I - num batch: 364
I - Train -- Loss: 1.307 | Acc: 39.398% | Wgt Acc: 39.356% | LR: 1.250000e-04 | Dur: 231.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 450.   16.   30.  318.  218.]
 [   0.    0.    0.    0.    0.]
 [  18.  444.  651.   64. 1278.]
 [ 106.   15.   31.  138.  215.]
 [ 118.  193.  262.  198. 1052.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.321 | Acc: 38.125% | Wgt Acc: 36.811%
I - num batch: 87
I - Val -- Loss: 1.294 | Acc: 40.014% | Wgt Acc: 38.879% | Dur: 43.36s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   3.   4.  57.  12.]
 [  0.   0.   0.   0.   0.]
 [  8. 182. 195.  12. 202.]
 [ 40.  10.  13.  68.  45.]
 [ 29.  73.  78.  67. 172.]]

I - Local maximum validation set accuracy:  40.01

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 1.305 | Acc: 38.750% | Wgt Acc: 39.986%
	I - Batch: 100 | Loss: 1.297 | Acc: 40.938% | Wgt Acc: 42.004%
	I - Batch: 150 | Loss: 1.299 | Acc: 38.875% | Wgt Acc: 39.922%
	I - Batch: 200 | Loss: 1.301 | Acc: 38.250% | Wgt Acc: 39.405%
	I - Batch: 250 | Loss: 1.299 | Acc: 38.550% | Wgt Acc: 40.172%
	I - Batch: 300 | Loss: 1.297 | Acc: 37.958% | Wgt Acc: 39.589%
	I - Batch: 350 | Loss: 1.300 | Acc: 38.321% | Wgt Acc: 39.858%
I - num batch: 364
I - Train -- Loss: 1.299 | Acc: 38.280% | Wgt Acc: 39.881% | LR: 1.250000e-04 | Dur: 231.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 449.    9.   27.  291.  185.]
 [   0.    0.    0.    0.    0.]
 [  28.  457.  700.   72. 1403.]
 [  96.   18.   35.  156.  254.]
 [ 119.  184.  212.  199.  921.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.364 | Acc: 35.750% | Wgt Acc: 36.688%
I - num batch: 87
I - Val -- Loss: 1.343 | Acc: 35.632% | Wgt Acc: 37.594% | Dur: 43.38s
I - Confusion Matrix: [row->prediction - col->label]
[[130.  10.   7.  82.  27.]
 [  0.   0.   0.   0.   0.]
 [ 15. 193. 221.  29. 262.]
 [ 25.  16.  14.  40.  37.]
 [ 29.  49.  48.  53. 105.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 1.314 | Acc: 38.375% | Wgt Acc: 40.492%
	I - Batch: 100 | Loss: 1.311 | Acc: 37.688% | Wgt Acc: 39.548%
	I - Batch: 150 | Loss: 1.305 | Acc: 40.125% | Wgt Acc: 40.146%
	I - Batch: 200 | Loss: 1.305 | Acc: 40.594% | Wgt Acc: 39.994%
	I - Batch: 250 | Loss: 1.298 | Acc: 41.225% | Wgt Acc: 40.005%
	I - Batch: 300 | Loss: 1.310 | Acc: 41.542% | Wgt Acc: 39.402%
	I - Batch: 350 | Loss: 1.312 | Acc: 42.232% | Wgt Acc: 39.712%
I - num batch: 364
I - Train -- Loss: 1.311 | Acc: 42.184% | Wgt Acc: 39.655% | LR: 1.250000e-04 | Dur: 229.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 414.    8.   14.  269.  177.]
 [   0.    0.    0.    0.    0.]
 [  16.  409.  597.   56. 1043.]
 [ 124.   24.   60.  162.  263.]
 [ 138.  227.  303.  231. 1280.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.306 | Acc: 38.375% | Wgt Acc: 34.275%
I - num batch: 87
I - Val -- Loss: 1.281 | Acc: 41.523% | Wgt Acc: 36.565% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   4.   4.  88.  20.]
 [  0.   0.   0.   0.   0.]
 [  4. 168. 178.  12. 147.]
 [ 24.   8.  14.  26.  16.]
 [ 45.  88.  94.  78. 248.]]

I - Local maximum validation set accuracy:  41.52

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 1.248 | Acc: 42.750% | Wgt Acc: 39.203%
	I - Batch: 100 | Loss: 1.296 | Acc: 42.250% | Wgt Acc: 37.140%
	I - Batch: 150 | Loss: 1.297 | Acc: 42.667% | Wgt Acc: 37.537%
	I - Batch: 200 | Loss: 1.288 | Acc: 43.438% | Wgt Acc: 38.918%
	I - Batch: 250 | Loss: 1.300 | Acc: 43.725% | Wgt Acc: 38.940%
	I - Batch: 300 | Loss: 1.296 | Acc: 44.792% | Wgt Acc: 39.498%
	I - Batch: 350 | Loss: 1.297 | Acc: 45.393% | Wgt Acc: 39.953%
I - num batch: 364
I - Train -- Loss: 1.298 | Acc: 45.503% | Wgt Acc: 39.941% | LR: 1.250000e-04 | Dur: 228.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 454.    5.   27.  313.  193.]
 [   0.    0.    0.    0.    0.]
 [  14.  364.  539.   35.  837.]
 [  78.   15.   31.   95.  175.]
 [ 146.  284.  377.  275. 1558.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.304 | Acc: 39.125% | Wgt Acc: 36.382%
I - num batch: 87
I - Val -- Loss: 1.285 | Acc: 39.943% | Wgt Acc: 36.855% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   2.   4.  73.  17.]
 [  0.   0.   0.   0.   0.]
 [  9. 188. 188.  15. 177.]
 [ 41.   8.   8.  41.  28.]
 [ 31.  70.  90.  75. 209.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 1.273 | Acc: 43.000% | Wgt Acc: 42.471%
	I - Batch: 100 | Loss: 1.280 | Acc: 46.000% | Wgt Acc: 41.813%
	I - Batch: 150 | Loss: 1.277 | Acc: 47.208% | Wgt Acc: 42.269%
	I - Batch: 200 | Loss: 1.269 | Acc: 47.312% | Wgt Acc: 42.586%
	I - Batch: 250 | Loss: 1.278 | Acc: 46.400% | Wgt Acc: 41.536%
	I - Batch: 300 | Loss: 1.286 | Acc: 46.000% | Wgt Acc: 41.227%
	I - Batch: 350 | Loss: 1.287 | Acc: 46.268% | Wgt Acc: 41.098%
I - num batch: 364
I - Train -- Loss: 1.284 | Acc: 46.500% | Wgt Acc: 41.312% | LR: 1.250000e-04 | Dur: 228.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 454.   13.   30.  339.  201.]
 [   0.    0.    0.    0.    0.]
 [  20.  394.  564.   40.  792.]
 [  88.   19.   33.  126.  210.]
 [ 130.  242.  347.  213. 1560.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.334 | Acc: 37.500% | Wgt Acc: 33.399%
I - num batch: 87
I - Val -- Loss: 1.300 | Acc: 40.374% | Wgt Acc: 35.249% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   5.  10. 119.  27.]
 [  0.   0.   0.   0.   0.]
 [  2. 122. 129.   7.  88.]
 [ 27.  19.  36.  49.  79.]
 [ 23. 122. 115.  29. 237.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 1.287 | Acc: 46.875% | Wgt Acc: 39.910%
	I - Batch: 100 | Loss: 1.275 | Acc: 46.438% | Wgt Acc: 40.106%
	I - Batch: 150 | Loss: 1.282 | Acc: 46.750% | Wgt Acc: 40.221%
	I - Batch: 200 | Loss: 1.285 | Acc: 46.406% | Wgt Acc: 40.722%
	I - Batch: 250 | Loss: 1.279 | Acc: 46.950% | Wgt Acc: 41.306%
	I - Batch: 300 | Loss: 1.279 | Acc: 46.833% | Wgt Acc: 41.652%
	I - Batch: 350 | Loss: 1.277 | Acc: 46.875% | Wgt Acc: 41.910%
I - num batch: 364
I - Train -- Loss: 1.276 | Acc: 46.844% | Wgt Acc: 41.933% | LR: 1.250000e-04 | Dur: 228.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 403.   10.   10.  257.  137.]
 [   0.    0.    0.    0.    0.]
 [  24.  403.  572.   36.  773.]
 [ 164.   27.   43.  199.  303.]
 [ 101.  228.  349.  226. 1550.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.443 | Acc: 33.875% | Wgt Acc: 30.428%
I - num batch: 87
I - Val -- Loss: 1.400 | Acc: 36.638% | Wgt Acc: 32.250% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[163.  23.  30. 149.  74.]
 [  0.   0.   0.   0.   0.]
 [  2.  84. 109.   2.  61.]
 [ 21.  28.  30.  30.  88.]
 [ 13. 133. 121.  23. 208.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 1.252 | Acc: 46.750% | Wgt Acc: 42.016%
	I - Batch: 100 | Loss: 1.261 | Acc: 47.312% | Wgt Acc: 42.347%
	I - Batch: 150 | Loss: 1.267 | Acc: 48.083% | Wgt Acc: 41.637%
	I - Batch: 200 | Loss: 1.260 | Acc: 48.438% | Wgt Acc: 41.894%
	I - Batch: 250 | Loss: 1.254 | Acc: 48.125% | Wgt Acc: 41.821%
	I - Batch: 300 | Loss: 1.256 | Acc: 47.688% | Wgt Acc: 41.531%
	I - Batch: 350 | Loss: 1.261 | Acc: 47.661% | Wgt Acc: 41.441%
I - num batch: 364
I - Train -- Loss: 1.261 | Acc: 47.773% | Wgt Acc: 41.545% | LR: 1.250000e-04 | Dur: 228.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 445.    9.   15.  322.  171.]
 [   0.    0.    0.    0.    0.]
 [  13.  397.  534.   28.  629.]
 [ 116.   26.   43.  143.  307.]
 [ 118.  236.  382.  225. 1656.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.412 | Acc: 36.250% | Wgt Acc: 31.775%
I - num batch: 87
I - Val -- Loss: 1.354 | Acc: 39.511% | Wgt Acc: 34.533% | Dur: 42.65s
I - Confusion Matrix: [row->prediction - col->label]
[[154.  10.  20. 124.  53.]
 [  0.   0.   0.   0.   0.]
 [  2.  93. 121.   1.  66.]
 [ 24.  28.  34.  45.  82.]
 [ 19. 137. 115.  34. 230.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 1.243 | Acc: 50.750% | Wgt Acc: 44.670%
	I - Batch: 100 | Loss: 1.240 | Acc: 49.688% | Wgt Acc: 44.215%
	I - Batch: 150 | Loss: 1.248 | Acc: 48.833% | Wgt Acc: 43.671%
	I - Batch: 200 | Loss: 1.254 | Acc: 48.188% | Wgt Acc: 42.718%
	I - Batch: 250 | Loss: 1.255 | Acc: 48.225% | Wgt Acc: 43.160%
	I - Batch: 300 | Loss: 1.252 | Acc: 48.042% | Wgt Acc: 43.182%
	I - Batch: 350 | Loss: 1.257 | Acc: 47.696% | Wgt Acc: 42.875%
I - num batch: 364
I - Train -- Loss: 1.256 | Acc: 47.859% | Wgt Acc: 43.034% | LR: 1.250000e-04 | Dur: 228.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 424.    9.   16.  281.  149.]
 [   0.    0.    0.    0.    0.]
 [  18.  427.  598.   35.  735.]
 [ 141.   19.   46.  188.  306.]
 [ 109.  213.  314.  214. 1573.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.351 | Acc: 36.625% | Wgt Acc: 30.421%
I - num batch: 87
I - Val -- Loss: 1.331 | Acc: 41.667% | Wgt Acc: 33.566% | Dur: 42.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   0.   3.  31.   5.]
 [  0.   0.   0.   0.   0.]
 [  5. 153. 144.   9. 104.]
 [ 60.   3.   6.  64.  19.]
 [ 65. 112. 137. 100. 303.]]

I - Local maximum validation set accuracy:  41.67

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 1.264 | Acc: 49.750% | Wgt Acc: 44.320%
	I - Batch: 100 | Loss: 1.240 | Acc: 50.312% | Wgt Acc: 45.762%
	I - Batch: 150 | Loss: 1.243 | Acc: 49.750% | Wgt Acc: 44.866%
	I - Batch: 200 | Loss: 1.262 | Acc: 48.938% | Wgt Acc: 43.783%
	I - Batch: 250 | Loss: 1.262 | Acc: 48.775% | Wgt Acc: 43.719%
	I - Batch: 300 | Loss: 1.260 | Acc: 48.250% | Wgt Acc: 43.241%
	I - Batch: 350 | Loss: 1.254 | Acc: 48.429% | Wgt Acc: 43.609%
I - num batch: 364
I - Train -- Loss: 1.255 | Acc: 48.375% | Wgt Acc: 43.502% | LR: 1.250000e-04 | Dur: 228.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 400.    7.   10.  250.  144.]
 [   0.    0.    0.    0.    0.]
 [  28.  438.  593.   43.  693.]
 [ 160.   12.   50.  233.  339.]
 [ 104.  211.  321.  192. 1587.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.430 | Acc: 35.500% | Wgt Acc: 30.458%
I - num batch: 87
I - Val -- Loss: 1.370 | Acc: 38.578% | Wgt Acc: 33.004% | Dur: 42.46s
I - Confusion Matrix: [row->prediction - col->label]
[[154.  17.  15. 130.  53.]
 [  0.   0.   0.   0.   0.]
 [  2.  96. 102.   3.  38.]
 [ 28.  33.  45.  46. 105.]
 [ 15. 122. 128.  25. 235.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 1.208 | Acc: 54.625% | Wgt Acc: 48.660%
	I - Batch: 100 | Loss: 1.224 | Acc: 52.500% | Wgt Acc: 47.214%
	I - Batch: 150 | Loss: 1.220 | Acc: 51.375% | Wgt Acc: 46.771%
	I - Batch: 200 | Loss: 1.216 | Acc: 50.719% | Wgt Acc: 45.692%
	I - Batch: 250 | Loss: 1.218 | Acc: 50.200% | Wgt Acc: 45.577%
	I - Batch: 300 | Loss: 1.222 | Acc: 50.500% | Wgt Acc: 45.568%
	I - Batch: 350 | Loss: 1.229 | Acc: 50.768% | Wgt Acc: 45.561%
I - num batch: 364
I - Train -- Loss: 1.228 | Acc: 50.662% | Wgt Acc: 45.588% | LR: 1.250000e-04 | Dur: 228.03s
I - Confusion Matrix: [row->prediction - col->label]
[[ 430.    3.   14.  247.  138.]
 [   0.    0.    0.    0.    0.]
 [  16.  466.  617.   51.  621.]
 [ 151.   22.   49.  240.  345.]
 [  95.  177.  294.  180. 1659.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.314 | Acc: 41.375% | Wgt Acc: 37.178%
I - num batch: 87
I - Val -- Loss: 1.271 | Acc: 44.468% | Wgt Acc: 39.409% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   9.   8.  99.  26.]
 [  0.   0.   0.   0.   0.]
 [  4. 153. 162.   7.  82.]
 [ 31.  17.  31.  60.  69.]
 [ 21.  89.  89.  38. 254.]]

I - Local maximum validation set accuracy:  44.47

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 1.216 | Acc: 50.125% | Wgt Acc: 45.945%
	I - Batch: 100 | Loss: 1.218 | Acc: 50.500% | Wgt Acc: 45.775%
	I - Batch: 150 | Loss: 1.212 | Acc: 50.542% | Wgt Acc: 45.425%
	I - Batch: 200 | Loss: 1.214 | Acc: 49.844% | Wgt Acc: 45.137%
	I - Batch: 250 | Loss: 1.224 | Acc: 49.200% | Wgt Acc: 44.544%
	I - Batch: 300 | Loss: 1.231 | Acc: 49.104% | Wgt Acc: 44.004%
	I - Batch: 350 | Loss: 1.225 | Acc: 49.464% | Wgt Acc: 44.261%
I - num batch: 364
I - Train -- Loss: 1.227 | Acc: 49.338% | Wgt Acc: 44.329% | LR: 1.250000e-04 | Dur: 228.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 413.    5.   11.  260.  124.]
 [   0.    0.    0.    0.    0.]
 [  19.  450.  599.   47.  617.]
 [ 165.   22.   46.  237.  402.]
 [  95.  191.  318.  174. 1620.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.404 | Acc: 36.625% | Wgt Acc: 33.227%
I - num batch: 87
I - Val -- Loss: 1.330 | Acc: 40.086% | Wgt Acc: 36.050% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   8.  11. 125.  35.]
 [  0.   0.   0.   0.   0.]
 [  2. 137. 148.   6.  65.]
 [ 37.  32.  52.  45. 112.]
 [ 14.  91.  79.  28. 219.]]

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 1.254 | Acc: 47.875% | Wgt Acc: 42.848%
	I - Batch: 100 | Loss: 1.215 | Acc: 49.375% | Wgt Acc: 44.973%
	I - Batch: 150 | Loss: 1.225 | Acc: 49.083% | Wgt Acc: 44.298%
	I - Batch: 200 | Loss: 1.231 | Acc: 49.625% | Wgt Acc: 44.335%
	I - Batch: 250 | Loss: 1.220 | Acc: 49.700% | Wgt Acc: 44.306%
	I - Batch: 300 | Loss: 1.209 | Acc: 50.708% | Wgt Acc: 45.238%
	I - Batch: 350 | Loss: 1.206 | Acc: 51.250% | Wgt Acc: 45.590%
I - num batch: 364
I - Train -- Loss: 1.207 | Acc: 51.109% | Wgt Acc: 45.427% | LR: 1.250000e-04 | Dur: 228.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 395.    4.   11.  256.  117.]
 [   0.    0.    0.    0.    0.]
 [  24.  481.  628.   39.  550.]
 [ 188.   18.   53.  234.  381.]
 [  85.  165.  282.  189. 1715.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.337 | Acc: 38.875% | Wgt Acc: 35.751%
I - num batch: 87
I - Val -- Loss: 1.275 | Acc: 43.247% | Wgt Acc: 38.659% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   5.   5.  79.  18.]
 [  0.   0.   0.   0.   0.]
 [  9. 174. 173.  20. 106.]
 [ 47.  11.  23.  65.  63.]
 [ 23.  78.  89.  40. 244.]]

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 1.182 | Acc: 51.250% | Wgt Acc: 46.704%
	I - Batch: 100 | Loss: 1.173 | Acc: 51.938% | Wgt Acc: 46.336%
	I - Batch: 150 | Loss: 1.169 | Acc: 51.292% | Wgt Acc: 46.093%
	I - Batch: 200 | Loss: 1.176 | Acc: 51.375% | Wgt Acc: 45.872%
	I - Batch: 250 | Loss: 1.173 | Acc: 51.725% | Wgt Acc: 46.347%
	I - Batch: 300 | Loss: 1.177 | Acc: 51.646% | Wgt Acc: 46.374%
	I - Batch: 350 | Loss: 1.186 | Acc: 51.196% | Wgt Acc: 45.786%
I - num batch: 364
I - Train -- Loss: 1.186 | Acc: 51.092% | Wgt Acc: 45.691% | LR: 1.250000e-04 | Dur: 228.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 415.    5.    6.  252.  119.]
 [   0.    0.    0.    0.    0.]
 [   9.  489.  621.   43.  590.]
 [ 171.   22.   50.  242.  361.]
 [  97.  152.  297.  181. 1693.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.322 | Acc: 40.750% | Wgt Acc: 36.884%
I - num batch: 87
I - Val -- Loss: 1.266 | Acc: 43.534% | Wgt Acc: 38.709% | Dur: 42.54s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   6.   9.  98.  20.]
 [  0.   0.   0.   0.   0.]
 [  7. 145. 171.   5.  84.]
 [ 51.  20.  31.  61.  78.]
 [ 16.  97.  79.  40. 249.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 1.180 | Acc: 53.250% | Wgt Acc: 47.830%
	I - Batch: 100 | Loss: 1.180 | Acc: 54.125% | Wgt Acc: 47.397%
	I - Batch: 150 | Loss: 1.176 | Acc: 53.083% | Wgt Acc: 47.340%
	I - Batch: 200 | Loss: 1.179 | Acc: 52.375% | Wgt Acc: 47.033%
	I - Batch: 250 | Loss: 1.183 | Acc: 52.150% | Wgt Acc: 46.598%
	I - Batch: 300 | Loss: 1.187 | Acc: 52.021% | Wgt Acc: 46.530%
	I - Batch: 350 | Loss: 1.196 | Acc: 51.839% | Wgt Acc: 46.237%
I - num batch: 364
I - Train -- Loss: 1.197 | Acc: 51.608% | Wgt Acc: 46.074% | LR: 1.250000e-04 | Dur: 228.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 403.    4.    8.  261.  120.]
 [   0.    0.    0.    0.    0.]
 [  13.  476.  646.   48.  609.]
 [ 158.   23.   36.  232.  314.]
 [ 118.  165.  284.  177. 1720.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.309 | Acc: 40.375% | Wgt Acc: 34.495%
I - num batch: 87
I - Val -- Loss: 1.261 | Acc: 45.259% | Wgt Acc: 37.981% | Dur: 42.66s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   3.   4.  76.   9.]
 [  0.   0.   0.   0.   0.]
 [  5. 153. 144.   7.  77.]
 [ 43.  14.  29.  71.  49.]
 [ 32.  98. 113.  50. 296.]]

I - Local maximum validation set accuracy:  45.26

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 1.201 | Acc: 50.125% | Wgt Acc: 46.335%
	I - Batch: 100 | Loss: 1.161 | Acc: 51.812% | Wgt Acc: 48.040%
	I - Batch: 150 | Loss: 1.167 | Acc: 51.208% | Wgt Acc: 47.323%
	I - Batch: 200 | Loss: 1.179 | Acc: 51.438% | Wgt Acc: 46.960%
	I - Batch: 250 | Loss: 1.178 | Acc: 51.625% | Wgt Acc: 46.895%
	I - Batch: 300 | Loss: 1.181 | Acc: 51.583% | Wgt Acc: 46.669%
	I - Batch: 350 | Loss: 1.175 | Acc: 51.750% | Wgt Acc: 46.919%
I - num batch: 364
I - Train -- Loss: 1.177 | Acc: 51.591% | Wgt Acc: 46.734% | LR: 1.250000e-04 | Dur: 228.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 433.    4.   11.  292.  125.]
 [   0.    0.    0.    0.    0.]
 [  21.  521.  683.   58.  657.]
 [ 139.   14.   34.  204.  301.]
 [  99.  129.  246.  164. 1680.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.287 | Acc: 43.250% | Wgt Acc: 40.333%
I - num batch: 87
I - Val -- Loss: 1.240 | Acc: 44.612% | Wgt Acc: 41.163% | Dur: 42.64s
I - Confusion Matrix: [row->prediction - col->label]
[[140.   5.   8.  96.  23.]
 [  0.   0.   0.   0.   0.]
 [  5. 175. 182.  11.  90.]
 [ 39.  21.  38.  72.  91.]
 [ 15.  67.  62.  25. 227.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 1.127 | Acc: 51.500% | Wgt Acc: 45.913%
	I - Batch: 100 | Loss: 1.148 | Acc: 51.438% | Wgt Acc: 46.432%
	I - Batch: 150 | Loss: 1.139 | Acc: 51.875% | Wgt Acc: 46.834%
	I - Batch: 200 | Loss: 1.150 | Acc: 52.188% | Wgt Acc: 46.854%
	I - Batch: 250 | Loss: 1.157 | Acc: 53.000% | Wgt Acc: 47.222%
	I - Batch: 300 | Loss: 1.159 | Acc: 52.458% | Wgt Acc: 47.128%
	I - Batch: 350 | Loss: 1.159 | Acc: 52.982% | Wgt Acc: 47.526%
I - num batch: 364
I - Train -- Loss: 1.157 | Acc: 53.087% | Wgt Acc: 47.591% | LR: 1.250000e-04 | Dur: 228.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 381.    4.    8.  230.  103.]
 [   0.    0.    0.    0.    0.]
 [  17.  536.  646.   54.  504.]
 [ 204.   24.   44.  309.  405.]
 [  90.  104.  276.  125. 1751.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.435 | Acc: 36.500% | Wgt Acc: 30.930%
I - num batch: 87
I - Val -- Loss: 1.419 | Acc: 42.672% | Wgt Acc: 33.972% | Dur: 42.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 58.   0.   2.  23.   2.]
 [  0.   0.   0.   0.   0.]
 [ 13. 174. 172.  36. 100.]
 [ 42.   3.   4.  40.   5.]
 [ 86.  91. 112. 105. 324.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 1.105 | Acc: 56.625% | Wgt Acc: 50.985%
	I - Batch: 100 | Loss: 1.124 | Acc: 54.938% | Wgt Acc: 49.335%
	I - Batch: 150 | Loss: 1.128 | Acc: 53.875% | Wgt Acc: 49.345%
	I - Batch: 200 | Loss: 1.134 | Acc: 54.000% | Wgt Acc: 48.889%
	I - Batch: 250 | Loss: 1.140 | Acc: 53.700% | Wgt Acc: 48.222%
	I - Batch: 300 | Loss: 1.140 | Acc: 54.188% | Wgt Acc: 48.551%
	I - Batch: 350 | Loss: 1.146 | Acc: 53.929% | Wgt Acc: 48.257%
I - num batch: 364
I - Train -- Loss: 1.146 | Acc: 53.998% | Wgt Acc: 48.325% | LR: 1.250000e-04 | Dur: 228.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 421.    7.    7.  259.  120.]
 [   0.    0.    0.    0.    0.]
 [  15.  512.  670.   51.  535.]
 [ 174.   23.   45.  259.  318.]
 [  82.  126.  252.  149. 1790.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.250 | Acc: 45.500% | Wgt Acc: 41.485%
I - num batch: 87
I - Val -- Loss: 1.230 | Acc: 48.420% | Wgt Acc: 43.233% | Dur: 42.72s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   5.  64.  12.]
 [  0.   0.   0.   0.   0.]
 [  5. 185. 193.  23.  93.]
 [ 48.  18.  26.  90.  52.]
 [ 29.  63.  66.  27. 274.]]

I - Local maximum validation set accuracy:  48.42

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 1.125 | Acc: 53.750% | Wgt Acc: 47.420%
	I - Batch: 100 | Loss: 1.127 | Acc: 53.938% | Wgt Acc: 47.950%
	I - Batch: 150 | Loss: 1.138 | Acc: 54.208% | Wgt Acc: 47.528%
	I - Batch: 200 | Loss: 1.140 | Acc: 54.531% | Wgt Acc: 48.381%
	I - Batch: 250 | Loss: 1.151 | Acc: 53.825% | Wgt Acc: 48.094%
	I - Batch: 300 | Loss: 1.145 | Acc: 53.729% | Wgt Acc: 48.131%
	I - Batch: 350 | Loss: 1.153 | Acc: 53.661% | Wgt Acc: 47.744%
I - num batch: 364
I - Train -- Loss: 1.152 | Acc: 53.689% | Wgt Acc: 47.788% | LR: 1.250000e-04 | Dur: 228.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 405.    1.    8.  271.  133.]
 [   0.    0.    0.    0.    0.]
 [  14.  539.  687.   63.  538.]
 [ 156.   23.   40.  227.  289.]
 [ 117.  105.  239.  157. 1803.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.286 | Acc: 42.875% | Wgt Acc: 37.129%
I - num batch: 87
I - Val -- Loss: 1.240 | Acc: 47.917% | Wgt Acc: 40.218% | Dur: 42.64s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   2.   4.  70.  10.]
 [  0.   0.   0.   0.   0.]
 [  5. 177. 173.  16.  73.]
 [ 28.   7.  15.  58.  30.]
 [ 48.  82.  98.  60. 318.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 1.065 | Acc: 58.125% | Wgt Acc: 52.009%
	I - Batch: 100 | Loss: 1.077 | Acc: 57.688% | Wgt Acc: 51.694%
	I - Batch: 150 | Loss: 1.093 | Acc: 56.708% | Wgt Acc: 50.009%
	I - Batch: 200 | Loss: 1.120 | Acc: 55.875% | Wgt Acc: 48.968%
	I - Batch: 250 | Loss: 1.124 | Acc: 54.750% | Wgt Acc: 48.548%
	I - Batch: 300 | Loss: 1.124 | Acc: 54.792% | Wgt Acc: 48.796%
	I - Batch: 350 | Loss: 1.121 | Acc: 54.893% | Wgt Acc: 48.914%
I - num batch: 364
I - Train -- Loss: 1.121 | Acc: 54.858% | Wgt Acc: 48.944% | LR: 1.250000e-04 | Dur: 228.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 444.    4.    7.  285.  129.]
 [   0.    4.    5.    1.    0.]
 [  12.  543.  682.   45.  510.]
 [ 133.   17.   45.  229.  293.]
 [ 103.  100.  235.  158. 1831.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.597 | Acc: 35.000% | Wgt Acc: 31.481%
I - num batch: 87
I - Val -- Loss: 1.526 | Acc: 36.710% | Wgt Acc: 33.391% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[179.  33.  53. 169. 118.]
 [  0.   5.   1.   0.   0.]
 [  1. 109. 114.   4.  34.]
 [ 15.  59.  47.  23.  89.]
 [  4.  62.  75.   8. 190.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 1.072 | Acc: 59.125% | Wgt Acc: 52.280%
	I - Batch: 100 | Loss: 1.098 | Acc: 56.500% | Wgt Acc: 49.188%
	I - Batch: 150 | Loss: 1.099 | Acc: 56.792% | Wgt Acc: 51.254%
	I - Batch: 200 | Loss: 1.109 | Acc: 56.438% | Wgt Acc: 50.645%
	I - Batch: 250 | Loss: 1.113 | Acc: 55.700% | Wgt Acc: 49.821%
	I - Batch: 300 | Loss: 1.118 | Acc: 55.146% | Wgt Acc: 49.667%
	I - Batch: 350 | Loss: 1.118 | Acc: 55.179% | Wgt Acc: 49.586%
I - num batch: 364
I - Train -- Loss: 1.117 | Acc: 55.271% | Wgt Acc: 49.514% | LR: 1.250000e-04 | Dur: 228.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 444.    4.    7.  275.  132.]
 [   0.    6.    2.    1.    0.]
 [  14.  542.  682.   51.  465.]
 [ 147.   33.   49.  252.  336.]
 [  87.   83.  234.  139. 1830.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.302 | Acc: 42.875% | Wgt Acc: 37.938%
I - num batch: 87
I - Val -- Loss: 1.271 | Acc: 46.193% | Wgt Acc: 39.854% | Dur: 42.71s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   6.  10.  87.  15.]
 [  0.   6.   4.   2.   0.]
 [ 10. 182. 174.  23.  91.]
 [ 26.  12.  12.  50.  36.]
 [ 39.  62.  90.  42. 289.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 1.111 | Acc: 56.500% | Wgt Acc: 50.032%
	I - Batch: 100 | Loss: 1.116 | Acc: 55.812% | Wgt Acc: 49.755%
	I - Batch: 150 | Loss: 1.112 | Acc: 56.083% | Wgt Acc: 50.583%
	I - Batch: 200 | Loss: 1.099 | Acc: 56.375% | Wgt Acc: 50.454%
	I - Batch: 250 | Loss: 1.101 | Acc: 56.225% | Wgt Acc: 50.105%
	I - Batch: 300 | Loss: 1.099 | Acc: 56.417% | Wgt Acc: 50.350%
	I - Batch: 350 | Loss: 1.105 | Acc: 55.804% | Wgt Acc: 49.853%
I - num batch: 364
I - Train -- Loss: 1.107 | Acc: 55.752% | Wgt Acc: 49.788% | LR: 1.250000e-04 | Dur: 228.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 436.    3.    7.  285.  133.]
 [   1.    8.    8.    2.    6.]
 [  13.  535.  710.   54.  504.]
 [ 137.   19.   36.  225.  257.]
 [ 105.  103.  213.  152. 1863.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.222 | Acc: 44.625% | Wgt Acc: 41.712%
I - num batch: 87
I - Val -- Loss: 1.226 | Acc: 46.121% | Wgt Acc: 42.482% | Dur: 42.56s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   1.   2.  55.   5.]
 [  0.   1.   0.   1.   0.]
 [ 12. 222. 225.  38. 156.]
 [ 46.   7.  16.  68.  25.]
 [ 38.  37.  47.  42. 245.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 1.008 | Acc: 58.750% | Wgt Acc: 53.755%
	I - Batch: 100 | Loss: 1.056 | Acc: 58.250% | Wgt Acc: 52.193%
	I - Batch: 150 | Loss: 1.070 | Acc: 57.333% | Wgt Acc: 51.661%
	I - Batch: 200 | Loss: 1.063 | Acc: 57.219% | Wgt Acc: 51.504%
	I - Batch: 250 | Loss: 1.071 | Acc: 56.725% | Wgt Acc: 51.138%
	I - Batch: 300 | Loss: 1.074 | Acc: 55.917% | Wgt Acc: 50.465%
	I - Batch: 350 | Loss: 1.087 | Acc: 55.554% | Wgt Acc: 50.047%
I - num batch: 364
I - Train -- Loss: 1.087 | Acc: 55.787% | Wgt Acc: 50.242% | LR: 1.250000e-04 | Dur: 228.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 439.    4.    4.  280.  153.]
 [   0.    9.    5.    0.    1.]
 [  11.  563.  726.   50.  503.]
 [ 138.   20.   34.  232.  268.]
 [ 104.   72.  205.  156. 1838.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.353 | Acc: 39.500% | Wgt Acc: 34.256%
I - num batch: 87
I - Val -- Loss: 1.306 | Acc: 44.037% | Wgt Acc: 37.490% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   4.   6.  61.   9.]
 [  0.   4.   0.   0.   0.]
 [  9. 156. 136.  27.  54.]
 [ 70.  23.  34.  96.  90.]
 [ 21.  81. 114.  20. 278.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 1.099 | Acc: 53.375% | Wgt Acc: 46.397%
	I - Batch: 100 | Loss: 1.071 | Acc: 56.125% | Wgt Acc: 49.448%
	I - Batch: 150 | Loss: 1.070 | Acc: 57.167% | Wgt Acc: 50.953%
	I - Batch: 200 | Loss: 1.070 | Acc: 57.438% | Wgt Acc: 51.146%
	I - Batch: 250 | Loss: 1.077 | Acc: 56.850% | Wgt Acc: 50.734%
	I - Batch: 300 | Loss: 1.085 | Acc: 56.396% | Wgt Acc: 50.297%
	I - Batch: 350 | Loss: 1.082 | Acc: 56.143% | Wgt Acc: 50.276%
I - num batch: 364
I - Train -- Loss: 1.080 | Acc: 56.199% | Wgt Acc: 50.336% | LR: 1.250000e-04 | Dur: 228.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 404.    4.    6.  239.  135.]
 [   0.    2.    4.    1.    0.]
 [  14.  572.  707.   49.  459.]
 [ 193.   11.   40.  292.  306.]
 [  81.   79.  217.  137. 1863.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.286 | Acc: 42.500% | Wgt Acc: 38.110%
I - num batch: 87
I - Val -- Loss: 1.257 | Acc: 46.552% | Wgt Acc: 40.284% | Dur: 42.50s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   4.   8.  67.  12.]
 [  0.   0.   0.   0.   0.]
 [ 10. 200. 199.  28. 105.]
 [ 33.   4.  12.  51.  22.]
 [ 50.  60.  71.  58. 292.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 1.067 | Acc: 57.375% | Wgt Acc: 50.919%
	I - Batch: 100 | Loss: 1.069 | Acc: 56.625% | Wgt Acc: 50.982%
	I - Batch: 150 | Loss: 1.063 | Acc: 56.708% | Wgt Acc: 50.428%
	I - Batch: 200 | Loss: 1.069 | Acc: 57.188% | Wgt Acc: 50.438%
	I - Batch: 250 | Loss: 1.064 | Acc: 57.050% | Wgt Acc: 50.210%
	I - Batch: 300 | Loss: 1.060 | Acc: 56.979% | Wgt Acc: 50.779%
	I - Batch: 350 | Loss: 1.057 | Acc: 57.161% | Wgt Acc: 51.275%
I - num batch: 364
I - Train -- Loss: 1.058 | Acc: 57.283% | Wgt Acc: 51.366% | LR: 1.250000e-04 | Dur: 228.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 475.    3.    4.  313.  175.]
 [   1.   10.    9.    1.    4.]
 [  15.  567.  726.   36.  463.]
 [ 113.   16.   34.  221.  222.]
 [  88.   72.  201.  147. 1899.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.321 | Acc: 41.000% | Wgt Acc: 38.367%
I - num batch: 87
I - Val -- Loss: 1.301 | Acc: 42.601% | Wgt Acc: 40.187% | Dur: 42.46s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   7.  13.  86.  33.]
 [  0.   1.   0.   0.   0.]
 [ 11. 199. 184.  32. 134.]
 [ 32.  23.  30.  71.  62.]
 [ 21.  38.  63.  15. 202.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 1.067 | Acc: 56.000% | Wgt Acc: 51.410%
	I - Batch: 100 | Loss: 1.064 | Acc: 58.000% | Wgt Acc: 52.646%
	I - Batch: 150 | Loss: 1.055 | Acc: 58.333% | Wgt Acc: 52.980%
	I - Batch: 200 | Loss: 1.053 | Acc: 57.906% | Wgt Acc: 52.255%
	I - Batch: 250 | Loss: 1.049 | Acc: 57.650% | Wgt Acc: 52.031%
	I - Batch: 300 | Loss: 1.058 | Acc: 57.646% | Wgt Acc: 51.981%
	I - Batch: 350 | Loss: 1.058 | Acc: 57.411% | Wgt Acc: 51.877%
I - num batch: 364
I - Train -- Loss: 1.055 | Acc: 57.678% | Wgt Acc: 52.111% | LR: 1.250000e-04 | Dur: 228.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 483.    4.    7.  276.  173.]
 [   0.    2.    1.    0.    0.]
 [  14.  577.  743.   48.  452.]
 [ 110.   23.   37.  242.  254.]
 [  85.   62.  186.  152. 1884.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.403 | Acc: 40.375% | Wgt Acc: 35.610%
I - num batch: 87
I - Val -- Loss: 1.328 | Acc: 44.325% | Wgt Acc: 39.015% | Dur: 42.92s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  11.  21. 118.  53.]
 [  0.   0.   0.   0.   0.]
 [  5. 139. 142.   7.  45.]
 [ 20.  52.  44.  64.  79.]
 [ 17.  66.  83.  15. 254.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.996 | Acc: 59.500% | Wgt Acc: 54.328%
	I - Batch: 100 | Loss: 1.007 | Acc: 58.312% | Wgt Acc: 52.290%
	I - Batch: 150 | Loss: 1.003 | Acc: 57.583% | Wgt Acc: 51.962%
	I - Batch: 200 | Loss: 1.007 | Acc: 58.438% | Wgt Acc: 52.757%
	I - Batch: 250 | Loss: 1.013 | Acc: 58.150% | Wgt Acc: 52.722%
	I - Batch: 300 | Loss: 1.017 | Acc: 58.146% | Wgt Acc: 52.603%
	I - Batch: 350 | Loss: 1.034 | Acc: 57.821% | Wgt Acc: 51.899%
I - num batch: 364
I - Train -- Loss: 1.036 | Acc: 57.971% | Wgt Acc: 52.045% | LR: 1.250000e-04 | Dur: 229.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 442.    2.    4.  262.  131.]
 [   0.    3.    1.    0.    0.]
 [  14.  589.  732.   34.  441.]
 [ 146.   17.   38.  280.  277.]
 [  90.   57.  199.  142. 1914.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.219 | Acc: 43.500% | Wgt Acc: 41.938%
I - num batch: 87
I - Val -- Loss: 1.238 | Acc: 43.534% | Wgt Acc: 41.821% | Dur: 42.90s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   2.   6.  65.  14.]
 [  0.   2.   2.   4.   1.]
 [  9. 212. 206.  31. 148.]
 [ 53.  20.  30.  84.  72.]
 [ 19.  32.  46.  20. 196.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 1.028 | Acc: 57.375% | Wgt Acc: 49.775%
	I - Batch: 100 | Loss: 1.020 | Acc: 60.062% | Wgt Acc: 52.978%
	I - Batch: 150 | Loss: 1.013 | Acc: 60.208% | Wgt Acc: 53.652%
	I - Batch: 200 | Loss: 1.030 | Acc: 58.656% | Wgt Acc: 52.399%
	I - Batch: 250 | Loss: 1.035 | Acc: 58.775% | Wgt Acc: 52.780%
	I - Batch: 300 | Loss: 1.032 | Acc: 58.125% | Wgt Acc: 52.407%
	I - Batch: 350 | Loss: 1.036 | Acc: 58.036% | Wgt Acc: 52.098%
I - num batch: 364
I - Train -- Loss: 1.037 | Acc: 58.091% | Wgt Acc: 52.118% | LR: 1.250000e-04 | Dur: 229.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 427.    1.    2.  250.  154.]
 [   0.    0.    1.    0.    0.]
 [   8.  584.  732.   37.  417.]
 [ 145.   21.   35.  300.  273.]
 [ 112.   62.  204.  131. 1919.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.400 | Acc: 41.250% | Wgt Acc: 34.465%
I - num batch: 87
I - Val -- Loss: 1.325 | Acc: 46.552% | Wgt Acc: 38.024% | Dur: 42.85s
I - Confusion Matrix: [row->prediction - col->label]
[[154.  10.  11. 130.  41.]
 [  0.   0.   0.   0.   0.]
 [  1. 152. 143.  10.  35.]
 [  8.  33.  26.  27.  31.]
 [ 36.  73. 110.  37. 324.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 1.022 | Acc: 59.125% | Wgt Acc: 52.800%
	I - Batch: 100 | Loss: 1.009 | Acc: 59.562% | Wgt Acc: 53.389%
	I - Batch: 150 | Loss: 1.007 | Acc: 60.250% | Wgt Acc: 54.428%
	I - Batch: 200 | Loss: 1.010 | Acc: 59.906% | Wgt Acc: 53.975%
	I - Batch: 250 | Loss: 1.000 | Acc: 60.200% | Wgt Acc: 54.579%
	I - Batch: 300 | Loss: 1.002 | Acc: 60.042% | Wgt Acc: 54.153%
	I - Batch: 350 | Loss: 1.006 | Acc: 60.071% | Wgt Acc: 54.139%
I - num batch: 364
I - Train -- Loss: 1.000 | Acc: 60.275% | Wgt Acc: 54.351% | LR: 1.250000e-04 | Dur: 229.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 478.    1.    1.  269.  177.]
 [   0.    1.    0.    0.    0.]
 [   8.  597.  768.   30.  392.]
 [ 119.   24.   34.  284.  220.]
 [  87.   45.  171.  135. 1974.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.311 | Acc: 44.875% | Wgt Acc: 39.273%
I - num batch: 87
I - Val -- Loss: 1.258 | Acc: 48.851% | Wgt Acc: 41.677% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   5.   6.  62.  29.]
 [  0.   0.   0.   0.   0.]
 [ 10. 189. 173.  29.  76.]
 [ 25.   7.  18.  68.  16.]
 [ 35.  67.  93.  45. 310.]]

I - Local maximum validation set accuracy:  48.85

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 1.003 | Acc: 59.750% | Wgt Acc: 53.252%
	I - Batch: 100 | Loss: 0.987 | Acc: 60.062% | Wgt Acc: 55.394%
	I - Batch: 150 | Loss: 0.989 | Acc: 60.292% | Wgt Acc: 55.246%
	I - Batch: 200 | Loss: 0.988 | Acc: 60.281% | Wgt Acc: 54.616%
	I - Batch: 250 | Loss: 0.990 | Acc: 60.450% | Wgt Acc: 54.415%
	I - Batch: 300 | Loss: 0.997 | Acc: 59.917% | Wgt Acc: 54.153%
	I - Batch: 350 | Loss: 0.996 | Acc: 60.125% | Wgt Acc: 54.384%
I - num batch: 364
I - Train -- Loss: 0.996 | Acc: 60.155% | Wgt Acc: 54.364% | LR: 1.250000e-04 | Dur: 229.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 461.    0.    5.  223.  165.]
 [   0.    0.    1.    0.    0.]
 [   9.  598.  762.   34.  404.]
 [ 124.   12.   25.  315.  234.]
 [  98.   58.  181.  146. 1960.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.271 | Acc: 44.625% | Wgt Acc: 39.286%
I - num batch: 87
I - Val -- Loss: 1.225 | Acc: 48.420% | Wgt Acc: 41.662% | Dur: 42.99s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   2.   4.  85.  22.]
 [  0.   3.   0.   0.   0.]
 [  7. 188. 174.  17.  70.]
 [ 21.  11.  25.  65.  37.]
 [ 41.  64.  87.  37. 302.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.950 | Acc: 62.625% | Wgt Acc: 56.037%
	I - Batch: 100 | Loss: 0.956 | Acc: 62.625% | Wgt Acc: 56.264%
	I - Batch: 150 | Loss: 0.963 | Acc: 61.292% | Wgt Acc: 54.938%
	I - Batch: 200 | Loss: 0.967 | Acc: 61.438% | Wgt Acc: 55.167%
	I - Batch: 250 | Loss: 0.976 | Acc: 60.675% | Wgt Acc: 54.593%
	I - Batch: 300 | Loss: 0.977 | Acc: 60.729% | Wgt Acc: 55.032%
	I - Batch: 350 | Loss: 0.979 | Acc: 60.821% | Wgt Acc: 55.064%
I - num batch: 364
I - Train -- Loss: 0.983 | Acc: 60.688% | Wgt Acc: 54.958% | LR: 1.250000e-04 | Dur: 228.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 433.    0.    1.  222.  148.]
 [   0.   11.    8.    2.    3.]
 [  13.  598.  779.   42.  384.]
 [ 167.   15.   28.  330.  252.]
 [  79.   44.  158.  122. 1976.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.373 | Acc: 42.125% | Wgt Acc: 36.480%
I - num batch: 87
I - Val -- Loss: 1.314 | Acc: 48.635% | Wgt Acc: 40.776% | Dur: 42.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   4.   2.  43.  11.]
 [  0.   6.   2.   0.   1.]
 [  7. 160. 167.  23.  68.]
 [ 40.  14.  16.  81.  27.]
 [ 53.  84. 103.  57. 324.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.955 | Acc: 61.000% | Wgt Acc: 53.384%
	I - Batch: 100 | Loss: 0.974 | Acc: 61.188% | Wgt Acc: 54.663%
	I - Batch: 150 | Loss: 0.974 | Acc: 60.792% | Wgt Acc: 54.682%
	I - Batch: 200 | Loss: 0.977 | Acc: 60.000% | Wgt Acc: 54.310%
	I - Batch: 250 | Loss: 0.972 | Acc: 60.825% | Wgt Acc: 54.840%
	I - Batch: 300 | Loss: 0.977 | Acc: 61.021% | Wgt Acc: 55.024%
	I - Batch: 350 | Loss: 0.980 | Acc: 60.732% | Wgt Acc: 55.031%
I - num batch: 364
I - Train -- Loss: 0.982 | Acc: 60.791% | Wgt Acc: 55.104% | LR: 1.250000e-04 | Dur: 228.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 427.    0.    1.  189.  164.]
 [   0.   17.    6.    2.    1.]
 [   9.  604.  759.   37.  386.]
 [ 169.    8.   39.  359.  239.]
 [  87.   39.  169.  131. 1973.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.314 | Acc: 43.750% | Wgt Acc: 38.446%
I - num batch: 87
I - Val -- Loss: 1.250 | Acc: 48.922% | Wgt Acc: 41.720% | Dur: 42.74s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   4.   4.  59.  17.]
 [  0.   3.   0.   0.   0.]
 [  5. 183. 156.  16.  57.]
 [ 48.  17.  26.  95.  49.]
 [ 27.  61. 104.  34. 308.]]

I - Local maximum validation set accuracy:  48.92

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.976 | Acc: 61.000% | Wgt Acc: 55.398%
	I - Batch: 100 | Loss: 0.963 | Acc: 61.812% | Wgt Acc: 55.180%
	I - Batch: 150 | Loss: 0.974 | Acc: 61.958% | Wgt Acc: 55.607%
	I - Batch: 200 | Loss: 0.971 | Acc: 62.031% | Wgt Acc: 55.945%
	I - Batch: 250 | Loss: 0.965 | Acc: 62.200% | Wgt Acc: 56.492%
	I - Batch: 300 | Loss: 0.966 | Acc: 62.021% | Wgt Acc: 56.202%
	I - Batch: 350 | Loss: 0.965 | Acc: 61.643% | Wgt Acc: 55.932%
I - num batch: 364
I - Train -- Loss: 0.963 | Acc: 61.737% | Wgt Acc: 56.060% | LR: 1.250000e-04 | Dur: 228.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 443.    0.    2.  200.  159.]
 [   0.    4.    0.    0.    0.]
 [   8.  604.  790.   48.  364.]
 [ 149.   11.   25.  357.  244.]
 [  92.   49.  157.  113. 1996.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.278 | Acc: 44.375% | Wgt Acc: 41.626%
I - num batch: 87
I - Val -- Loss: 1.256 | Acc: 46.408% | Wgt Acc: 43.210% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   3.   7.  57.  25.]
 [  0.   0.   0.   0.   0.]
 [ 11. 213. 205.  38. 136.]
 [ 48.  12.  19.  89.  38.]
 [ 20.  40.  59.  20. 232.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.918 | Acc: 62.375% | Wgt Acc: 55.656%
	I - Batch: 100 | Loss: 0.927 | Acc: 62.688% | Wgt Acc: 56.504%
	I - Batch: 150 | Loss: 0.924 | Acc: 62.500% | Wgt Acc: 57.288%
	I - Batch: 200 | Loss: 0.927 | Acc: 62.531% | Wgt Acc: 56.942%
	I - Batch: 250 | Loss: 0.940 | Acc: 61.750% | Wgt Acc: 55.945%
	I - Batch: 300 | Loss: 0.944 | Acc: 61.562% | Wgt Acc: 55.926%
	I - Batch: 350 | Loss: 0.945 | Acc: 61.821% | Wgt Acc: 56.347%
I - num batch: 364
I - Train -- Loss: 0.943 | Acc: 61.978% | Wgt Acc: 56.460% | LR: 1.250000e-04 | Dur: 230.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 440.    0.    3.  211.  166.]
 [   0.   98.   80.    2.   14.]
 [   8.  523.  702.   31.  361.]
 [ 155.   14.   29.  358.  216.]
 [  89.   33.  160.  116. 2006.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.232 | Acc: 49.250% | Wgt Acc: 47.127%
I - num batch: 87
I - Val -- Loss: 1.226 | Acc: 49.497% | Wgt Acc: 46.739% | Dur: 43.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   1.   3.  23.   9.]
 [  0.  99.  67.   7.   9.]
 [  5. 105. 134.  28. 105.]
 [ 98.  23.  40. 129.  55.]
 [ 22.  40.  46.  17. 253.]]

I - Local maximum validation set accuracy:  49.50

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.907 | Acc: 65.250% | Wgt Acc: 61.460%
	I - Batch: 100 | Loss: 0.938 | Acc: 63.438% | Wgt Acc: 59.735%
	I - Batch: 150 | Loss: 0.931 | Acc: 63.875% | Wgt Acc: 59.116%
	I - Batch: 200 | Loss: 0.936 | Acc: 63.000% | Wgt Acc: 58.009%
	I - Batch: 250 | Loss: 0.932 | Acc: 63.575% | Wgt Acc: 58.995%
	I - Batch: 300 | Loss: 0.937 | Acc: 63.250% | Wgt Acc: 58.971%
	I - Batch: 350 | Loss: 0.940 | Acc: 62.946% | Wgt Acc: 58.384%
I - num batch: 364
I - Train -- Loss: 0.938 | Acc: 63.147% | Wgt Acc: 58.574% | LR: 1.250000e-04 | Dur: 230.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 440.    0.    2.  181.  157.]
 [   1.  173.  120.    2.   13.]
 [   8.  444.  683.   31.  380.]
 [ 160.   17.   30.  386.  223.]
 [  83.   34.  139.  118. 1990.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.235 | Acc: 51.875% | Wgt Acc: 48.763%
I - num batch: 87
I - Val -- Loss: 1.212 | Acc: 52.227% | Wgt Acc: 48.442% | Dur: 43.05s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   3.   6.  75.  25.]
 [  3. 108.  72.   6.  14.]
 [  3.  94. 121.  15.  64.]
 [ 25.  18.  28.  79.  47.]
 [ 30.  45.  63.  29. 281.]]

I - Local maximum validation set accuracy:  52.23

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.901 | Acc: 65.125% | Wgt Acc: 61.062%
	I - Batch: 100 | Loss: 0.894 | Acc: 64.625% | Wgt Acc: 61.320%
	I - Batch: 150 | Loss: 0.895 | Acc: 65.458% | Wgt Acc: 61.671%
	I - Batch: 200 | Loss: 0.908 | Acc: 64.906% | Wgt Acc: 60.797%
	I - Batch: 250 | Loss: 0.911 | Acc: 63.900% | Wgt Acc: 59.466%
	I - Batch: 300 | Loss: 0.916 | Acc: 64.021% | Wgt Acc: 59.485%
	I - Batch: 350 | Loss: 0.914 | Acc: 64.446% | Wgt Acc: 59.962%
I - num batch: 364
I - Train -- Loss: 0.912 | Acc: 64.471% | Wgt Acc: 59.955% | LR: 1.250000e-04 | Dur: 230.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 432.    0.    1.  174.  139.]
 [   0.  283.  220.    5.   30.]
 [   6.  352.  590.   19.  340.]
 [ 163.    6.   16.  407.  217.]
 [  91.   27.  147.  113. 2037.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.390 | Acc: 45.125% | Wgt Acc: 38.998%
I - num batch: 87
I - Val -- Loss: 1.328 | Acc: 50.359% | Wgt Acc: 42.358% | Dur: 43.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   2.   3.  35.  10.]
 [  0.  57.  30.   5.   7.]
 [  5. 105. 111.  17.  42.]
 [ 58.  16.  25.  99.  34.]
 [ 40.  88. 121.  48. 338.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.898 | Acc: 66.125% | Wgt Acc: 62.417%
	I - Batch: 100 | Loss: 0.889 | Acc: 66.375% | Wgt Acc: 62.463%
	I - Batch: 150 | Loss: 0.893 | Acc: 66.167% | Wgt Acc: 62.154%
	I - Batch: 200 | Loss: 0.911 | Acc: 65.125% | Wgt Acc: 60.991%
	I - Batch: 250 | Loss: 0.906 | Acc: 65.400% | Wgt Acc: 61.277%
	I - Batch: 300 | Loss: 0.906 | Acc: 65.542% | Wgt Acc: 61.481%
	I - Batch: 350 | Loss: 0.909 | Acc: 65.446% | Wgt Acc: 61.283%
I - num batch: 364
I - Train -- Loss: 0.906 | Acc: 65.641% | Wgt Acc: 61.438% | LR: 1.250000e-04 | Dur: 230.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 436.    0.    0.  155.  134.]
 [   1.  326.  237.    3.   29.]
 [   5.  302.  573.   31.  305.]
 [ 163.   13.   28.  428.  241.]
 [  87.   27.  136.  101. 2054.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.327 | Acc: 46.375% | Wgt Acc: 42.183%
I - num batch: 87
I - Val -- Loss: 1.286 | Acc: 51.724% | Wgt Acc: 46.352% | Dur: 43.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   2.   2.  39.  13.]
 [  0.  77.  51.   6.  10.]
 [  8. 112. 124.  15.  51.]
 [ 63.  22.  33. 122.  57.]
 [ 31.  55.  80.  22. 300.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.886 | Acc: 64.625% | Wgt Acc: 61.005%
	I - Batch: 100 | Loss: 0.879 | Acc: 65.125% | Wgt Acc: 60.902%
	I - Batch: 150 | Loss: 0.883 | Acc: 65.708% | Wgt Acc: 60.873%
	I - Batch: 200 | Loss: 0.880 | Acc: 65.844% | Wgt Acc: 61.017%
	I - Batch: 250 | Loss: 0.889 | Acc: 65.550% | Wgt Acc: 60.771%
	I - Batch: 300 | Loss: 0.897 | Acc: 65.625% | Wgt Acc: 60.784%
	I - Batch: 350 | Loss: 0.899 | Acc: 65.518% | Wgt Acc: 60.709%
I - num batch: 364
I - Train -- Loss: 0.896 | Acc: 65.658% | Wgt Acc: 60.832% | LR: 1.250000e-04 | Dur: 230.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 424.    0.    0.  173.  119.]
 [   1.  315.  239.    3.   31.]
 [   4.  308.  571.   26.  305.]
 [ 166.    4.   30.  414.  214.]
 [  97.   41.  134.  102. 2094.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.420 | Acc: 45.500% | Wgt Acc: 39.684%
I - num batch: 87
I - Val -- Loss: 1.320 | Acc: 51.293% | Wgt Acc: 43.512% | Dur: 43.09s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   4.   3.  62.  14.]
 [  0.  41.  21.   3.   2.]
 [  3. 125. 133.   6.  53.]
 [ 24.  20.  20.  83.  27.]
 [ 50.  78. 113.  50. 335.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.886 | Acc: 65.750% | Wgt Acc: 62.044%
	I - Batch: 100 | Loss: 0.903 | Acc: 64.938% | Wgt Acc: 60.614%
	I - Batch: 150 | Loss: 0.885 | Acc: 66.875% | Wgt Acc: 62.299%
	I - Batch: 200 | Loss: 0.874 | Acc: 67.344% | Wgt Acc: 63.038%
	I - Batch: 250 | Loss: 0.872 | Acc: 67.300% | Wgt Acc: 62.820%
	I - Batch: 300 | Loss: 0.870 | Acc: 67.229% | Wgt Acc: 62.958%
	I - Batch: 350 | Loss: 0.871 | Acc: 67.250% | Wgt Acc: 63.010%
I - num batch: 364
I - Train -- Loss: 0.873 | Acc: 67.171% | Wgt Acc: 63.024% | LR: 1.250000e-04 | Dur: 230.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 437.    0.    0.  154.  145.]
 [   0.  327.  225.    4.   21.]
 [   4.  304.  602.   24.  310.]
 [ 155.   14.   22.  448.  195.]
 [  96.   23.  125.   88. 2092.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.302 | Acc: 50.500% | Wgt Acc: 45.810%
I - num batch: 87
I - Val -- Loss: 1.250 | Acc: 53.233% | Wgt Acc: 47.529% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[146.   7.  10.  72.  26.]
 [  0.  79.  64.   7.  10.]
 [  5. 116. 127.  11.  68.]
 [ 13.  10.  14.  77.  15.]
 [ 35.  56.  75.  37. 312.]]

I - Local maximum validation set accuracy:  53.23

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.876 | Acc: 69.375% | Wgt Acc: 65.076%
	I - Batch: 100 | Loss: 0.867 | Acc: 68.500% | Wgt Acc: 63.549%
	I - Batch: 150 | Loss: 0.868 | Acc: 68.833% | Wgt Acc: 64.258%
	I - Batch: 200 | Loss: 0.879 | Acc: 68.500% | Wgt Acc: 64.195%
	I - Batch: 250 | Loss: 0.874 | Acc: 68.475% | Wgt Acc: 64.389%
	I - Batch: 300 | Loss: 0.874 | Acc: 67.958% | Wgt Acc: 63.906%
	I - Batch: 350 | Loss: 0.869 | Acc: 68.125% | Wgt Acc: 64.186%
I - num batch: 364
I - Train -- Loss: 0.868 | Acc: 68.203% | Wgt Acc: 64.384% | LR: 1.250000e-04 | Dur: 230.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 443.    1.    1.  148.  145.]
 [   0.  351.  219.    4.   25.]
 [   5.  279.  613.   20.  297.]
 [ 155.    7.   18.  455.  192.]
 [  89.   30.  123.   91. 2104.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.405 | Acc: 46.375% | Wgt Acc: 40.015%
I - num batch: 87
I - Val -- Loss: 1.350 | Acc: 51.724% | Wgt Acc: 43.504% | Dur: 43.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   0.   4.  22.  10.]
 [  0.  33.  17.   5.   3.]
 [  9. 132. 147.  10.  55.]
 [ 44.  11.  13. 103.  18.]
 [ 54.  92. 109.  64. 345.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.860 | Acc: 68.500% | Wgt Acc: 65.932%
	I - Batch: 100 | Loss: 0.843 | Acc: 67.500% | Wgt Acc: 64.836%
	I - Batch: 150 | Loss: 0.833 | Acc: 68.625% | Wgt Acc: 65.327%
	I - Batch: 200 | Loss: 0.836 | Acc: 68.688% | Wgt Acc: 65.345%
	I - Batch: 250 | Loss: 0.845 | Acc: 67.775% | Wgt Acc: 64.172%
	I - Batch: 300 | Loss: 0.849 | Acc: 68.000% | Wgt Acc: 64.237%
	I - Batch: 350 | Loss: 0.853 | Acc: 67.857% | Wgt Acc: 64.042%
I - num batch: 364
I - Train -- Loss: 0.853 | Acc: 67.756% | Wgt Acc: 64.032% | LR: 1.250000e-04 | Dur: 230.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 468.    0.    0.  156.  127.]
 [   1.  331.  216.    3.   24.]
 [   5.  303.  616.   23.  321.]
 [ 135.    9.   20.  445.  211.]
 [  83.   25.  122.   91. 2080.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.498 | Acc: 44.875% | Wgt Acc: 37.350%
I - num batch: 87
I - Val -- Loss: 1.400 | Acc: 49.784% | Wgt Acc: 40.296% | Dur: 43.25s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   7.  12.  77.  23.]
 [  0.   6.   3.   2.   1.]
 [  1. 144. 135.   7.  41.]
 [ 12.  10.  11.  61.  14.]
 [ 47. 101. 129.  57. 352.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.834 | Acc: 69.250% | Wgt Acc: 65.483%
	I - Batch: 100 | Loss: 0.798 | Acc: 70.438% | Wgt Acc: 66.835%
	I - Batch: 150 | Loss: 0.810 | Acc: 69.750% | Wgt Acc: 66.764%
	I - Batch: 200 | Loss: 0.818 | Acc: 69.344% | Wgt Acc: 66.513%
	I - Batch: 250 | Loss: 0.831 | Acc: 69.000% | Wgt Acc: 66.100%
	I - Batch: 300 | Loss: 0.831 | Acc: 69.062% | Wgt Acc: 66.064%
	I - Batch: 350 | Loss: 0.830 | Acc: 69.554% | Wgt Acc: 66.220%
I - num batch: 364
I - Train -- Loss: 0.828 | Acc: 69.647% | Wgt Acc: 66.326% | LR: 1.250000e-04 | Dur: 229.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 485.    0.    1.  160.  172.]
 [   1.  353.  177.    4.   20.]
 [   3.  291.  655.   21.  257.]
 [ 127.    3.   18.  445.  202.]
 [  76.   21.  123.   88. 2112.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.430 | Acc: 46.500% | Wgt Acc: 42.827%
I - num batch: 87
I - Val -- Loss: 1.349 | Acc: 50.000% | Wgt Acc: 45.551% | Dur: 42.83s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   2.   6.  34.  14.]
 [  1.  96.  53.   3.  13.]
 [  4.  63.  83.  11.  39.]
 [ 59.  48.  58. 138.  90.]
 [ 31.  59.  90.  18. 275.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.797 | Acc: 71.250% | Wgt Acc: 68.397%
	I - Batch: 100 | Loss: 0.809 | Acc: 70.562% | Wgt Acc: 67.659%
	I - Batch: 150 | Loss: 0.820 | Acc: 69.708% | Wgt Acc: 66.480%
	I - Batch: 200 | Loss: 0.826 | Acc: 68.938% | Wgt Acc: 65.923%
	I - Batch: 250 | Loss: 0.828 | Acc: 68.875% | Wgt Acc: 65.666%
	I - Batch: 300 | Loss: 0.832 | Acc: 68.896% | Wgt Acc: 65.524%
	I - Batch: 350 | Loss: 0.830 | Acc: 69.286% | Wgt Acc: 66.040%
I - num batch: 364
I - Train -- Loss: 0.833 | Acc: 69.063% | Wgt Acc: 65.776% | LR: 1.250000e-04 | Dur: 229.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 473.    0.    0.  152.  152.]
 [   0.  376.  191.    5.   20.]
 [   3.  266.  620.   23.  300.]
 [ 135.    6.   17.  450.  194.]
 [  81.   20.  146.   88. 2097.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.493 | Acc: 47.250% | Wgt Acc: 41.258%
I - num batch: 87
I - Val -- Loss: 1.395 | Acc: 50.575% | Wgt Acc: 43.179% | Dur: 42.71s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   3.   5.  53.  20.]
 [  0.  39.  25.   1.   5.]
 [  6. 108. 117.   6.  42.]
 [ 29.  31.  33. 103.  43.]
 [ 40.  87. 110.  41. 321.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.821 | Acc: 69.875% | Wgt Acc: 66.651%
	I - Batch: 100 | Loss: 0.817 | Acc: 70.062% | Wgt Acc: 67.605%
	I - Batch: 150 | Loss: 0.812 | Acc: 70.542% | Wgt Acc: 68.253%
	I - Batch: 200 | Loss: 0.814 | Acc: 70.438% | Wgt Acc: 68.245%
	I - Batch: 250 | Loss: 0.806 | Acc: 71.225% | Wgt Acc: 68.943%
	I - Batch: 300 | Loss: 0.809 | Acc: 70.500% | Wgt Acc: 68.407%
	I - Batch: 350 | Loss: 0.813 | Acc: 70.571% | Wgt Acc: 68.142%
I - num batch: 364
I - Train -- Loss: 0.810 | Acc: 70.645% | Wgt Acc: 68.230% | LR: 1.250000e-04 | Dur: 230.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 493.    0.    2.  136.  172.]
 [   1.  393.  187.    2.   25.]
 [   1.  242.  652.   16.  307.]
 [ 119.    6.   21.  485.  174.]
 [  78.   27.  112.   79. 2085.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.493 | Acc: 46.375% | Wgt Acc: 39.378%
I - num batch: 87
I - Val -- Loss: 1.401 | Acc: 51.149% | Wgt Acc: 42.029% | Dur: 43.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 86.   2.   2.  23.   9.]
 [  0.  47.  30.   5.   3.]
 [  3.  95. 109.   7.  29.]
 [ 59.  29.  21. 112.  32.]
 [ 51.  95. 128.  57. 358.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.792 | Acc: 72.875% | Wgt Acc: 69.976%
	I - Batch: 100 | Loss: 0.793 | Acc: 71.438% | Wgt Acc: 68.635%
	I - Batch: 150 | Loss: 0.801 | Acc: 70.917% | Wgt Acc: 68.225%
	I - Batch: 200 | Loss: 0.790 | Acc: 71.312% | Wgt Acc: 68.818%
	I - Batch: 250 | Loss: 0.788 | Acc: 71.900% | Wgt Acc: 69.612%
	I - Batch: 300 | Loss: 0.784 | Acc: 72.354% | Wgt Acc: 69.835%
	I - Batch: 350 | Loss: 0.784 | Acc: 72.411% | Wgt Acc: 69.914%
I - num batch: 364
I - Train -- Loss: 0.784 | Acc: 72.399% | Wgt Acc: 69.786% | LR: 1.250000e-04 | Dur: 230.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 483.    0.    0.  116.  146.]
 [   2.  424.  201.    5.   29.]
 [   5.  222.  652.   11.  271.]
 [ 115.    5.   21.  500.  166.]
 [  87.   17.  100.   86. 2151.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.379 | Acc: 51.875% | Wgt Acc: 48.217%
I - num batch: 87
I - Val -- Loss: 1.330 | Acc: 53.736% | Wgt Acc: 48.709% | Dur: 43.19s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   3.   9.  60.  22.]
 [  3. 102.  56.   9.  13.]
 [  3.  72. 111.   7.  54.]
 [ 27.  28.  28.  95.  37.]
 [ 31.  63.  86.  33. 305.]]

I - Local maximum validation set accuracy:  53.74

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.789 | Acc: 72.500% | Wgt Acc: 70.487%
	I - Batch: 100 | Loss: 0.765 | Acc: 72.688% | Wgt Acc: 71.214%
	I - Batch: 150 | Loss: 0.767 | Acc: 72.875% | Wgt Acc: 71.203%
	I - Batch: 200 | Loss: 0.777 | Acc: 72.375% | Wgt Acc: 70.262%
	I - Batch: 250 | Loss: 0.773 | Acc: 72.800% | Wgt Acc: 70.487%
	I - Batch: 300 | Loss: 0.774 | Acc: 72.771% | Wgt Acc: 70.347%
	I - Batch: 350 | Loss: 0.781 | Acc: 72.286% | Wgt Acc: 69.837%
I - num batch: 364
I - Train -- Loss: 0.781 | Acc: 72.244% | Wgt Acc: 69.806% | LR: 1.250000e-04 | Dur: 230.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 474.    1.    0.  118.  153.]
 [   2.  440.  213.    6.   14.]
 [   2.  203.  651.   17.  276.]
 [ 115.    6.   12.  495.  179.]
 [  99.   18.   98.   82. 2141.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.360 | Acc: 47.875% | Wgt Acc: 44.983%
I - num batch: 87
I - Val -- Loss: 1.339 | Acc: 50.216% | Wgt Acc: 46.558% | Dur: 43.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 64.   1.   3.  22.  12.]
 [  3. 120.  78.  14.  17.]
 [  6.  65. 113.  14.  69.]
 [102.  25.  27. 126.  57.]
 [ 24.  57.  69.  28. 276.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.764 | Acc: 74.500% | Wgt Acc: 72.021%
	I - Batch: 100 | Loss: 0.753 | Acc: 74.312% | Wgt Acc: 71.718%
	I - Batch: 150 | Loss: 0.745 | Acc: 74.542% | Wgt Acc: 71.794%
	I - Batch: 200 | Loss: 0.735 | Acc: 74.875% | Wgt Acc: 72.224%
	I - Batch: 250 | Loss: 0.749 | Acc: 74.275% | Wgt Acc: 71.790%
	I - Batch: 300 | Loss: 0.755 | Acc: 74.000% | Wgt Acc: 71.645%
	I - Batch: 350 | Loss: 0.756 | Acc: 74.018% | Wgt Acc: 71.597%
I - num batch: 364
I - Train -- Loss: 0.757 | Acc: 74.136% | Wgt Acc: 71.633% | LR: 1.250000e-04 | Dur: 230.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 511.    0.    1.  104.  137.]
 [   1.  447.  194.    7.   24.]
 [   3.  199.  649.    6.  254.]
 [ 113.   10.   10.  513.  157.]
 [  64.   12.  120.   88. 2191.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.444 | Acc: 48.500% | Wgt Acc: 42.728%
I - num batch: 87
I - Val -- Loss: 1.401 | Acc: 52.586% | Wgt Acc: 45.083% | Dur: 43.23s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   5.  10.  36.  10.]
 [  0.  42.  20.   6.   5.]
 [  4. 127. 158.   9.  51.]
 [ 37.  20.  14.  84.  26.]
 [ 49.  74.  88.  69. 339.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.741 | Acc: 73.000% | Wgt Acc: 71.046%
	I - Batch: 100 | Loss: 0.729 | Acc: 73.625% | Wgt Acc: 71.269%
	I - Batch: 150 | Loss: 0.742 | Acc: 73.917% | Wgt Acc: 71.422%
	I - Batch: 200 | Loss: 0.756 | Acc: 72.781% | Wgt Acc: 70.457%
	I - Batch: 250 | Loss: 0.754 | Acc: 73.350% | Wgt Acc: 71.087%
	I - Batch: 300 | Loss: 0.744 | Acc: 73.625% | Wgt Acc: 71.664%
	I - Batch: 350 | Loss: 0.738 | Acc: 74.232% | Wgt Acc: 72.312%
I - num batch: 364
I - Train -- Loss: 0.740 | Acc: 74.136% | Wgt Acc: 72.203% | LR: 1.250000e-04 | Dur: 230.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 500.    0.    0.  116.  152.]
 [   0.  441.  181.    3.   31.]
 [   3.  204.  696.   10.  274.]
 [ 113.    6.   13.  515.  147.]
 [  76.   17.   84.   74. 2159.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.299 | Acc: 51.750% | Wgt Acc: 49.443%
I - num batch: 87
I - Val -- Loss: 1.261 | Acc: 54.885% | Wgt Acc: 52.165% | Dur: 43.26s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   4.  11.  60.  26.]
 [  3. 119.  72.   7.  25.]
 [  6.  78. 134.   9.  71.]
 [ 27.  19.  20. 102.  35.]
 [ 28.  48.  53.  26. 274.]]

I - Local maximum validation set accuracy:  54.89

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.727 | Acc: 76.875% | Wgt Acc: 74.740%
	I - Batch: 100 | Loss: 0.703 | Acc: 77.000% | Wgt Acc: 75.084%
	I - Batch: 150 | Loss: 0.690 | Acc: 77.625% | Wgt Acc: 75.778%
	I - Batch: 200 | Loss: 0.710 | Acc: 76.250% | Wgt Acc: 74.465%
	I - Batch: 250 | Loss: 0.719 | Acc: 75.675% | Wgt Acc: 73.631%
	I - Batch: 300 | Loss: 0.716 | Acc: 75.729% | Wgt Acc: 73.965%
	I - Batch: 350 | Loss: 0.720 | Acc: 75.321% | Wgt Acc: 73.589%
I - num batch: 364
I - Train -- Loss: 0.721 | Acc: 75.357% | Wgt Acc: 73.624% | LR: 1.250000e-04 | Dur: 230.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 509.    0.    0.  108.  148.]
 [   1.  485.  172.   10.   15.]
 [   1.  167.  685.    9.  259.]
 [ 116.    7.   19.  516.  154.]
 [  65.    9.   98.   75. 2187.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.594 | Acc: 47.625% | Wgt Acc: 41.583%
I - num batch: 87
I - Val -- Loss: 1.503 | Acc: 52.371% | Wgt Acc: 44.518% | Dur: 43.21s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   8.  12.  75.  30.]
 [  0.  80.  39.   4.   7.]
 [  5.  66.  93.   1.  29.]
 [ 12.  42.  22.  69.  20.]
 [ 40.  72. 124.  55. 345.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.740 | Acc: 73.875% | Wgt Acc: 72.536%
	I - Batch: 100 | Loss: 0.725 | Acc: 74.688% | Wgt Acc: 73.564%
	I - Batch: 150 | Loss: 0.721 | Acc: 74.500% | Wgt Acc: 73.036%
	I - Batch: 200 | Loss: 0.733 | Acc: 74.250% | Wgt Acc: 72.658%
	I - Batch: 250 | Loss: 0.735 | Acc: 73.875% | Wgt Acc: 72.316%
	I - Batch: 300 | Loss: 0.729 | Acc: 74.229% | Wgt Acc: 72.822%
	I - Batch: 350 | Loss: 0.727 | Acc: 74.268% | Wgt Acc: 73.008%
I - num batch: 364
I - Train -- Loss: 0.728 | Acc: 74.394% | Wgt Acc: 73.203% | LR: 1.250000e-04 | Dur: 230.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 513.    0.    0.   96.  169.]
 [   1.  475.  170.    8.   23.]
 [   1.  172.  678.    8.  287.]
 [ 101.    5.   22.  539.  163.]
 [  76.   16.  104.   67. 2121.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.540 | Acc: 49.000% | Wgt Acc: 45.883%
I - num batch: 87
I - Val -- Loss: 1.440 | Acc: 50.934% | Wgt Acc: 47.343% | Dur: 43.25s
I - Confusion Matrix: [row->prediction - col->label]
[[144.   6.  13.  64.  55.]
 [  2.  85.  49.   3.   8.]
 [  2.  60. 104.   0.  42.]
 [ 36.  61.  51. 115.  65.]
 [ 15.  56.  73.  22. 261.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.657 | Acc: 77.875% | Wgt Acc: 76.910%
	I - Batch: 100 | Loss: 0.683 | Acc: 76.500% | Wgt Acc: 75.175%
	I - Batch: 150 | Loss: 0.719 | Acc: 75.250% | Wgt Acc: 73.698%
	I - Batch: 200 | Loss: 0.727 | Acc: 74.812% | Wgt Acc: 73.062%
	I - Batch: 250 | Loss: 0.723 | Acc: 74.875% | Wgt Acc: 73.409%
	I - Batch: 300 | Loss: 0.716 | Acc: 75.271% | Wgt Acc: 73.830%
	I - Batch: 350 | Loss: 0.712 | Acc: 75.518% | Wgt Acc: 73.853%
I - num batch: 364
I - Train -- Loss: 0.711 | Acc: 75.512% | Wgt Acc: 73.967% | LR: 1.250000e-04 | Dur: 230.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 502.    0.    1.  114.  148.]
 [   2.  485.  172.   11.   20.]
 [   3.  161.  706.    7.  246.]
 [ 109.    5.   10.  516.  167.]
 [  76.   17.   85.   70. 2182.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.379 | Acc: 52.750% | Wgt Acc: 49.975%
I - num batch: 87
I - Val -- Loss: 1.324 | Acc: 53.879% | Wgt Acc: 50.091% | Dur: 43.29s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   4.  17.  75.  42.]
 [  0.  84.  32.   7.   7.]
 [  4. 105. 155.   4.  76.]
 [ 18.  22.  22.  80.  22.]
 [ 30.  53.  64.  38. 284.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.678 | Acc: 77.500% | Wgt Acc: 77.171%
	I - Batch: 100 | Loss: 0.657 | Acc: 77.562% | Wgt Acc: 77.841%
	I - Batch: 150 | Loss: 0.666 | Acc: 76.750% | Wgt Acc: 76.619%
	I - Batch: 200 | Loss: 0.664 | Acc: 77.219% | Wgt Acc: 77.027%
	I - Batch: 250 | Loss: 0.657 | Acc: 77.475% | Wgt Acc: 77.297%
	I - Batch: 300 | Loss: 0.661 | Acc: 77.438% | Wgt Acc: 77.095%
	I - Batch: 350 | Loss: 0.665 | Acc: 77.375% | Wgt Acc: 77.129%
I - num batch: 364
I - Train -- Loss: 0.669 | Acc: 77.300% | Wgt Acc: 76.897% | LR: 1.250000e-04 | Dur: 230.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 527.    0.    0.   68.  145.]
 [   1.  508.  145.    6.   32.]
 [   0.  141.  743.    7.  275.]
 [  86.    7.   11.  558.  152.]
 [  78.   12.   75.   79. 2159.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.410 | Acc: 50.500% | Wgt Acc: 46.006%
I - num batch: 87
I - Val -- Loss: 1.367 | Acc: 53.807% | Wgt Acc: 47.734% | Dur: 43.23s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   4.  47.  10.]
 [  0.  96.  40.  11.  16.]
 [  2.  80. 134.  10.  57.]
 [ 28.  17.  12.  70.  19.]
 [ 49.  73. 100.  66. 329.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.687 | Acc: 78.625% | Wgt Acc: 77.878%
	I - Batch: 100 | Loss: 0.677 | Acc: 78.250% | Wgt Acc: 77.855%
	I - Batch: 150 | Loss: 0.687 | Acc: 77.583% | Wgt Acc: 76.759%
	I - Batch: 200 | Loss: 0.670 | Acc: 78.219% | Wgt Acc: 77.104%
	I - Batch: 250 | Loss: 0.661 | Acc: 78.425% | Wgt Acc: 77.237%
	I - Batch: 300 | Loss: 0.659 | Acc: 78.396% | Wgt Acc: 77.391%
	I - Batch: 350 | Loss: 0.661 | Acc: 78.286% | Wgt Acc: 77.394%
I - num batch: 364
I - Train -- Loss: 0.660 | Acc: 78.349% | Wgt Acc: 77.469% | LR: 1.250000e-04 | Dur: 230.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 510.    2.    0.   90.  156.]
 [   2.  512.  121.    6.   26.]
 [   1.  137.  763.    2.  237.]
 [  96.    5.   13.  548.  121.]
 [  83.   12.   77.   72. 2223.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.465 | Acc: 52.125% | Wgt Acc: 48.003%
I - num batch: 87
I - Val -- Loss: 1.419 | Acc: 54.598% | Wgt Acc: 48.922% | Dur: 43.21s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   5.   8.  38.  26.]
 [  3. 103.  45.   7.   9.]
 [  4.  58. 126.   6.  55.]
 [ 31.  24.  15.  95.  17.]
 [ 49.  78.  96.  58. 324.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.612 | Acc: 81.625% | Wgt Acc: 81.418%
	I - Batch: 100 | Loss: 0.627 | Acc: 80.375% | Wgt Acc: 79.422%
	I - Batch: 150 | Loss: 0.634 | Acc: 79.708% | Wgt Acc: 78.638%
	I - Batch: 200 | Loss: 0.628 | Acc: 79.906% | Wgt Acc: 79.148%
	I - Batch: 250 | Loss: 0.631 | Acc: 79.500% | Wgt Acc: 79.009%
	I - Batch: 300 | Loss: 0.630 | Acc: 79.292% | Wgt Acc: 78.939%
	I - Batch: 350 | Loss: 0.631 | Acc: 79.161% | Wgt Acc: 78.762%
I - num batch: 364
I - Train -- Loss: 0.630 | Acc: 79.175% | Wgt Acc: 78.796% | LR: 1.250000e-04 | Dur: 230.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 530.    0.    0.   82.  149.]
 [   1.  527.  127.    9.   17.]
 [   1.  126.  772.    7.  251.]
 [  89.    7.    7.  561.  132.]
 [  71.    8.   68.   59. 2214.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.464 | Acc: 50.125% | Wgt Acc: 46.796%
I - num batch: 87
I - Val -- Loss: 1.475 | Acc: 51.580% | Wgt Acc: 46.902% | Dur: 43.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 68.   0.   4.  18.  12.]
 [  1.  76.  12.  10.  13.]
 [  9. 118. 187.  28.  89.]
 [ 51.   9.  14.  87.  17.]
 [ 70.  65.  73.  61. 300.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.578 | Acc: 83.000% | Wgt Acc: 82.577%
	I - Batch: 100 | Loss: 0.593 | Acc: 81.062% | Wgt Acc: 80.987%
	I - Batch: 150 | Loss: 0.586 | Acc: 81.500% | Wgt Acc: 81.696%
	I - Batch: 200 | Loss: 0.595 | Acc: 81.062% | Wgt Acc: 81.249%
	I - Batch: 250 | Loss: 0.592 | Acc: 81.375% | Wgt Acc: 81.401%
	I - Batch: 300 | Loss: 0.602 | Acc: 80.521% | Wgt Acc: 80.713%
	I - Batch: 350 | Loss: 0.604 | Acc: 80.304% | Wgt Acc: 80.528%
I - num batch: 364
I - Train -- Loss: 0.607 | Acc: 80.155% | Wgt Acc: 80.368% | LR: 1.250000e-04 | Dur: 230.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 548.    0.    0.   97.  160.]
 [   1.  546.   97.    7.   21.]
 [   1.  110.  800.    3.  240.]
 [  86.    4.    6.  559.  134.]
 [  56.    8.   71.   52. 2208.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.344 | Acc: 52.875% | Wgt Acc: 50.858%
I - num batch: 87
I - Val -- Loss: 1.339 | Acc: 53.807% | Wgt Acc: 51.295% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   1.  11.  26.  16.]
 [  3. 109.  43.  13.  17.]
 [ 10.  92. 159.  23.  98.]
 [ 45.  20.  23. 110.  31.]
 [ 39.  46.  54.  32. 269.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.639 | Acc: 79.750% | Wgt Acc: 79.633%
	I - Batch: 100 | Loss: 0.604 | Acc: 80.188% | Wgt Acc: 80.389%
	I - Batch: 150 | Loss: 0.598 | Acc: 80.042% | Wgt Acc: 80.076%
	I - Batch: 200 | Loss: 0.596 | Acc: 80.625% | Wgt Acc: 80.423%
	I - Batch: 250 | Loss: 0.600 | Acc: 80.200% | Wgt Acc: 80.332%
	I - Batch: 300 | Loss: 0.604 | Acc: 79.812% | Wgt Acc: 79.856%
	I - Batch: 350 | Loss: 0.604 | Acc: 79.839% | Wgt Acc: 79.884%
I - num batch: 364
I - Train -- Loss: 0.604 | Acc: 79.948% | Wgt Acc: 79.930% | LR: 1.250000e-04 | Dur: 229.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 526.    0.    0.   77.  165.]
 [   2.  547.  108.    6.   25.]
 [   1.  102.  782.    6.  249.]
 [  88.    8.    4.  578.  108.]
 [  75.   11.   80.   51. 2216.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.728 | Acc: 47.750% | Wgt Acc: 42.967%
I - num batch: 87
I - Val -- Loss: 1.664 | Acc: 51.437% | Wgt Acc: 44.359% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   6.  15.  68.  38.]
 [  2.  74.  15.   1.   7.]
 [  0.  67. 111.   8.  32.]
 [ 19.  37.  23.  65.  25.]
 [ 41.  84. 126.  62. 329.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.594 | Acc: 80.375% | Wgt Acc: 81.752%
	I - Batch: 100 | Loss: 0.585 | Acc: 81.188% | Wgt Acc: 81.918%
	I - Batch: 150 | Loss: 0.585 | Acc: 81.083% | Wgt Acc: 81.648%
	I - Batch: 200 | Loss: 0.601 | Acc: 79.969% | Wgt Acc: 80.483%
	I - Batch: 250 | Loss: 0.600 | Acc: 80.025% | Wgt Acc: 80.594%
	I - Batch: 300 | Loss: 0.613 | Acc: 79.146% | Wgt Acc: 79.525%
	I - Batch: 350 | Loss: 0.615 | Acc: 79.268% | Wgt Acc: 79.515%
I - num batch: 364
I - Train -- Loss: 0.616 | Acc: 79.209% | Wgt Acc: 79.382% | LR: 1.250000e-04 | Dur: 229.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 536.    0.    0.   69.  154.]
 [   2.  534.  107.    9.   33.]
 [   0.  118.  784.    1.  254.]
 [  86.    7.   14.  571.  141.]
 [  68.    9.   69.   68. 2181.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.544 | Acc: 51.000% | Wgt Acc: 45.712%
I - num batch: 87
I - Val -- Loss: 1.504 | Acc: 55.029% | Wgt Acc: 47.676% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   3.   7.  65.  15.]
 [  0.  74.  14.   4.   8.]
 [  4.  90. 142.   6.  40.]
 [ 10.  20.  13.  63.  17.]
 [ 49.  81. 114.  66. 351.]]

I - Local maximum validation set accuracy:  55.03

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.596 | Acc: 80.875% | Wgt Acc: 80.794%
	I - Batch: 100 | Loss: 0.565 | Acc: 81.938% | Wgt Acc: 81.986%
	I - Batch: 150 | Loss: 0.562 | Acc: 82.833% | Wgt Acc: 82.844%
	I - Batch: 200 | Loss: 0.562 | Acc: 82.406% | Wgt Acc: 82.500%
	I - Batch: 250 | Loss: 0.572 | Acc: 81.825% | Wgt Acc: 81.868%
	I - Batch: 300 | Loss: 0.574 | Acc: 81.750% | Wgt Acc: 81.742%
	I - Batch: 350 | Loss: 0.580 | Acc: 81.375% | Wgt Acc: 81.375%
I - num batch: 364
I - Train -- Loss: 0.578 | Acc: 81.582% | Wgt Acc: 81.609% | LR: 1.250000e-04 | Dur: 228.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 550.    0.    0.   72.  127.]
 [   1.  552.   87.    7.   17.]
 [   2.  101.  808.    1.  236.]
 [  72.    6.   10.  576.  125.]
 [  67.    9.   69.   62. 2258.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.621 | Acc: 49.125% | Wgt Acc: 43.611%
I - num batch: 87
I - Val -- Loss: 1.498 | Acc: 54.167% | Wgt Acc: 46.817% | Dur: 42.57s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   4.   9.  52.  15.]
 [  1.  56.  16.   0.   5.]
 [  4. 106. 156.   8.  52.]
 [ 17.  16.  11.  71.  14.]
 [ 51.  86.  98.  73. 345.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.559 | Acc: 81.375% | Wgt Acc: 81.025%
	I - Batch: 100 | Loss: 0.530 | Acc: 83.500% | Wgt Acc: 83.417%
	I - Batch: 150 | Loss: 0.533 | Acc: 83.208% | Wgt Acc: 83.444%
	I - Batch: 200 | Loss: 0.536 | Acc: 82.938% | Wgt Acc: 83.275%
	I - Batch: 250 | Loss: 0.547 | Acc: 82.125% | Wgt Acc: 82.351%
	I - Batch: 300 | Loss: 0.554 | Acc: 81.500% | Wgt Acc: 81.739%
	I - Batch: 350 | Loss: 0.560 | Acc: 81.304% | Wgt Acc: 81.560%
I - num batch: 364
I - Train -- Loss: 0.563 | Acc: 81.135% | Wgt Acc: 81.372% | LR: 1.250000e-04 | Dur: 228.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 538.    0.    0.   61.  142.]
 [   2.  553.   88.    4.   13.]
 [   0.   98.  807.    4.  242.]
 [  66.    8.    6.  587.  133.]
 [  86.    9.   73.   62. 2233.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.478 | Acc: 51.250% | Wgt Acc: 48.346%
I - num batch: 87
I - Val -- Loss: 1.428 | Acc: 53.807% | Wgt Acc: 50.157% | Dur: 42.53s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   7.  12.  39.  27.]
 [  2. 110.  33.   6.  18.]
 [  7.  82. 146.  14.  65.]
 [ 37.  20.  17.  92.  32.]
 [ 41.  49.  82.  53. 289.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.533 | Acc: 83.625% | Wgt Acc: 83.829%
	I - Batch: 100 | Loss: 0.524 | Acc: 83.812% | Wgt Acc: 84.285%
	I - Batch: 150 | Loss: 0.525 | Acc: 84.292% | Wgt Acc: 84.258%
	I - Batch: 200 | Loss: 0.541 | Acc: 82.844% | Wgt Acc: 82.884%
	I - Batch: 250 | Loss: 0.545 | Acc: 82.375% | Wgt Acc: 82.568%
	I - Batch: 300 | Loss: 0.546 | Acc: 82.292% | Wgt Acc: 82.677%
	I - Batch: 350 | Loss: 0.543 | Acc: 82.500% | Wgt Acc: 82.898%
I - num batch: 364
I - Train -- Loss: 0.542 | Acc: 82.494% | Wgt Acc: 82.904% | LR: 1.250000e-04 | Dur: 228.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 554.    0.    0.   54.  155.]
 [   1.  568.   67.    4.   25.]
 [   0.   92.  818.    2.  209.]
 [  62.    3.    6.  597.  114.]
 [  75.    5.   83.   61. 2260.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.539 | Acc: 52.875% | Wgt Acc: 49.436%
I - num batch: 87
I - Val -- Loss: 1.481 | Acc: 55.172% | Wgt Acc: 50.671% | Dur: 42.60s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   6.  15.  44.  31.]
 [  2. 101.  25.   5.  12.]
 [  5.  54. 133.   9.  48.]
 [ 38.  38.  27. 103.  37.]
 [ 26.  69.  90.  43. 303.]]

I - Local maximum validation set accuracy:  55.17

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.512 | Acc: 82.125% | Wgt Acc: 83.491%
	I - Batch: 100 | Loss: 0.514 | Acc: 83.562% | Wgt Acc: 84.240%
	I - Batch: 150 | Loss: 0.512 | Acc: 83.542% | Wgt Acc: 84.169%
	I - Batch: 200 | Loss: 0.510 | Acc: 83.406% | Wgt Acc: 83.967%
	I - Batch: 250 | Loss: 0.509 | Acc: 83.475% | Wgt Acc: 84.165%
	I - Batch: 300 | Loss: 0.509 | Acc: 83.750% | Wgt Acc: 84.310%
	I - Batch: 350 | Loss: 0.514 | Acc: 83.571% | Wgt Acc: 84.076%
I - num batch: 364
I - Train -- Loss: 0.516 | Acc: 83.422% | Wgt Acc: 83.888% | LR: 1.250000e-04 | Dur: 228.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 587.    0.    0.   53.  149.]
 [   1.  570.   78.    5.   21.]
 [   0.   87.  818.    3.  204.]
 [  54.    3.    4.  598.  111.]
 [  50.    8.   74.   59. 2278.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.490 | Acc: 51.750% | Wgt Acc: 50.080%
I - num batch: 87
I - Val -- Loss: 1.423 | Acc: 54.310% | Wgt Acc: 52.285% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   5.  16.  45.  48.]
 [  2. 115.  42.   9.  11.]
 [  3.  60. 142.  11.  57.]
 [ 34.  43.  38. 102.  56.]
 [ 22.  45.  52.  37. 259.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.526 | Acc: 82.500% | Wgt Acc: 84.103%
	I - Batch: 100 | Loss: 0.541 | Acc: 82.312% | Wgt Acc: 82.939%
	I - Batch: 150 | Loss: 0.532 | Acc: 82.750% | Wgt Acc: 83.487%
	I - Batch: 200 | Loss: 0.522 | Acc: 83.031% | Wgt Acc: 83.720%
	I - Batch: 250 | Loss: 0.524 | Acc: 83.125% | Wgt Acc: 83.554%
	I - Batch: 300 | Loss: 0.524 | Acc: 83.146% | Wgt Acc: 83.532%
	I - Batch: 350 | Loss: 0.517 | Acc: 83.214% | Wgt Acc: 83.796%
I - num batch: 364
I - Train -- Loss: 0.514 | Acc: 83.371% | Wgt Acc: 83.995% | LR: 1.250000e-04 | Dur: 228.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 573.    0.    0.   47.  133.]
 [   1.  575.   71.    8.   16.]
 [   1.   81.  829.    3.  221.]
 [  60.    4.    5.  601.  123.]
 [  57.    8.   69.   59. 2270.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.611 | Acc: 51.625% | Wgt Acc: 45.865%
I - num batch: 87
I - Val -- Loss: 1.568 | Acc: 55.244% | Wgt Acc: 47.757% | Dur: 42.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 82.   0.   5.  18.  11.]
 [  1.  92.  13.   3.   5.]
 [  4.  54. 124.   6.  29.]
 [ 53.  27.  25. 114.  29.]
 [ 59.  95. 123.  63. 357.]]

I - Local maximum validation set accuracy:  55.24

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.447 | Acc: 86.250% | Wgt Acc: 86.368%
	I - Batch: 100 | Loss: 0.451 | Acc: 86.625% | Wgt Acc: 87.084%
	I - Batch: 150 | Loss: 0.468 | Acc: 85.292% | Wgt Acc: 85.854%
	I - Batch: 200 | Loss: 0.470 | Acc: 85.031% | Wgt Acc: 85.602%
	I - Batch: 250 | Loss: 0.481 | Acc: 84.425% | Wgt Acc: 85.051%
	I - Batch: 300 | Loss: 0.472 | Acc: 84.979% | Wgt Acc: 85.621%
	I - Batch: 350 | Loss: 0.478 | Acc: 84.750% | Wgt Acc: 85.324%
I - num batch: 364
I - Train -- Loss: 0.479 | Acc: 84.643% | Wgt Acc: 85.189% | LR: 1.250000e-04 | Dur: 228.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 570.    0.    0.   62.  133.]
 [   1.  595.   66.    6.   21.]
 [   0.   68.  845.    2.  182.]
 [  61.    4.    4.  596.  111.]
 [  60.    1.   59.   52. 2316.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.790 | Acc: 48.500% | Wgt Acc: 43.696%
I - num batch: 87
I - Val -- Loss: 1.771 | Acc: 49.928% | Wgt Acc: 43.957% | Dur: 42.54s
I - Confusion Matrix: [row->prediction - col->label]
[[168.  16.  25. 111.  75.]
 [  3.  75.  15.   3.   9.]
 [  4.  58. 109.   4.  29.]
 [  3.  16.  10.  40.  15.]
 [ 21. 103. 131.  46. 303.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.475 | Acc: 85.750% | Wgt Acc: 86.107%
	I - Batch: 100 | Loss: 0.458 | Acc: 86.250% | Wgt Acc: 87.052%
	I - Batch: 150 | Loss: 0.462 | Acc: 85.833% | Wgt Acc: 86.708%
	I - Batch: 200 | Loss: 0.465 | Acc: 85.812% | Wgt Acc: 86.666%
	I - Batch: 250 | Loss: 0.470 | Acc: 85.525% | Wgt Acc: 86.291%
	I - Batch: 300 | Loss: 0.478 | Acc: 84.938% | Wgt Acc: 85.638%
	I - Batch: 350 | Loss: 0.474 | Acc: 85.071% | Wgt Acc: 85.733%
I - num batch: 364
I - Train -- Loss: 0.473 | Acc: 85.142% | Wgt Acc: 85.828% | LR: 1.250000e-04 | Dur: 228.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 586.    0.    0.   43.  128.]
 [   0.  599.   63.    6.   22.]
 [   1.   55.  841.    3.  172.]
 [  50.    6.    2.  607.  123.]
 [  55.    8.   68.   59. 2318.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.644 | Acc: 47.375% | Wgt Acc: 42.784%
I - num batch: 87
I - Val -- Loss: 1.592 | Acc: 50.862% | Wgt Acc: 44.781% | Dur: 42.48s
I - Confusion Matrix: [row->prediction - col->label]
[[136.  10.  17.  72.  32.]
 [  0.  50.  10.   1.   6.]
 [  4. 120. 148.  13.  67.]
 [ 16.  23.  18.  67.  19.]
 [ 43.  65.  97.  51. 307.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.489 | Acc: 83.875% | Wgt Acc: 83.775%
	I - Batch: 100 | Loss: 0.467 | Acc: 85.062% | Wgt Acc: 85.909%
	I - Batch: 150 | Loss: 0.476 | Acc: 84.542% | Wgt Acc: 85.239%
	I - Batch: 200 | Loss: 0.466 | Acc: 84.875% | Wgt Acc: 85.586%
	I - Batch: 250 | Loss: 0.471 | Acc: 84.750% | Wgt Acc: 85.369%
	I - Batch: 300 | Loss: 0.469 | Acc: 84.729% | Wgt Acc: 85.316%
	I - Batch: 350 | Loss: 0.473 | Acc: 84.714% | Wgt Acc: 85.173%
I - num batch: 364
I - Train -- Loss: 0.473 | Acc: 84.626% | Wgt Acc: 85.146% | LR: 1.250000e-04 | Dur: 228.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 580.    0.    0.   44.  138.]
 [   0.  587.   69.    7.   23.]
 [   1.   66.  839.    4.  180.]
 [  48.    8.    6.  602.  109.]
 [  63.    7.   60.   61. 2313.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.439 | Acc: 53.500% | Wgt Acc: 50.049%
I - num batch: 87
I - Val -- Loss: 1.405 | Acc: 54.885% | Wgt Acc: 50.176% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   1.   7.  18.  17.]
 [  2.  94.  29.   5.  14.]
 [  3.  72. 130.   6.  43.]
 [ 60.  45.  30. 143.  54.]
 [ 40.  56.  94.  32. 303.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.429 | Acc: 86.375% | Wgt Acc: 87.062%
	I - Batch: 100 | Loss: 0.444 | Acc: 85.938% | Wgt Acc: 86.969%
	I - Batch: 150 | Loss: 0.440 | Acc: 85.958% | Wgt Acc: 86.880%
	I - Batch: 200 | Loss: 0.433 | Acc: 86.500% | Wgt Acc: 87.446%
	I - Batch: 250 | Loss: 0.434 | Acc: 86.650% | Wgt Acc: 87.647%
	I - Batch: 300 | Loss: 0.435 | Acc: 86.521% | Wgt Acc: 87.372%
	I - Batch: 350 | Loss: 0.431 | Acc: 86.750% | Wgt Acc: 87.700%
I - num batch: 364
I - Train -- Loss: 0.435 | Acc: 86.604% | Wgt Acc: 87.544% | LR: 1.250000e-04 | Dur: 228.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 585.    0.    0.   32.  121.]
 [   0.  612.   46.    4.   15.]
 [   1.   47.  870.    1.  178.]
 [  52.    3.    3.  624.  104.]
 [  54.    6.   55.   57. 2345.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.565 | Acc: 53.250% | Wgt Acc: 48.934%
I - num batch: 87
I - Val -- Loss: 1.528 | Acc: 56.825% | Wgt Acc: 51.237% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   7.  17.  48.  23.]
 [  1.  93.  14.   6.  10.]
 [  3.  79. 151.   8.  39.]
 [ 25.  24.  15.  86.  29.]
 [ 39.  65.  93.  56. 330.]]

I - Local maximum validation set accuracy:  56.82

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.478 | Acc: 82.250% | Wgt Acc: 84.432%
	I - Batch: 100 | Loss: 0.451 | Acc: 84.062% | Wgt Acc: 85.747%
	I - Batch: 150 | Loss: 0.454 | Acc: 83.833% | Wgt Acc: 85.509%
	I - Batch: 200 | Loss: 0.449 | Acc: 84.375% | Wgt Acc: 85.806%
	I - Batch: 250 | Loss: 0.453 | Acc: 84.275% | Wgt Acc: 85.778%
	I - Batch: 300 | Loss: 0.458 | Acc: 84.271% | Wgt Acc: 85.575%
	I - Batch: 350 | Loss: 0.452 | Acc: 84.607% | Wgt Acc: 85.947%
I - num batch: 364
I - Train -- Loss: 0.452 | Acc: 84.678% | Wgt Acc: 85.954% | LR: 1.250000e-04 | Dur: 227.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 572.    0.    0.   43.  139.]
 [   1.  608.   55.    5.   17.]
 [   1.   45.  850.    2.  219.]
 [  52.    8.    4.  623.  117.]
 [  66.    7.   65.   45. 2271.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.635 | Acc: 50.500% | Wgt Acc: 46.073%
I - num batch: 87
I - Val -- Loss: 1.584 | Acc: 53.520% | Wgt Acc: 47.595% | Dur: 42.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 84.   2.  12.  18.  20.]
 [  2.  90.  25.  11.  15.]
 [  5.  76. 134.  10.  42.]
 [ 63.  26.  17. 114.  31.]
 [ 45.  74. 102.  51. 323.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.422 | Acc: 86.750% | Wgt Acc: 87.896%
	I - Batch: 100 | Loss: 0.431 | Acc: 85.438% | Wgt Acc: 87.118%
	I - Batch: 150 | Loss: 0.458 | Acc: 84.417% | Wgt Acc: 85.652%
	I - Batch: 200 | Loss: 0.448 | Acc: 85.031% | Wgt Acc: 86.055%
	I - Batch: 250 | Loss: 0.447 | Acc: 85.475% | Wgt Acc: 86.356%
	I - Batch: 300 | Loss: 0.443 | Acc: 85.625% | Wgt Acc: 86.507%
	I - Batch: 350 | Loss: 0.453 | Acc: 85.304% | Wgt Acc: 86.212%
I - num batch: 364
I - Train -- Loss: 0.451 | Acc: 85.262% | Wgt Acc: 86.152% | LR: 1.250000e-04 | Dur: 227.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 581.    0.    0.   34.  127.]
 [   0.  597.   53.    7.   23.]
 [   1.   57.  856.    5.  192.]
 [  51.    7.    2.  615.  112.]
 [  59.    7.   63.   57. 2309.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.519 | Acc: 54.375% | Wgt Acc: 50.404%
I - num batch: 87
I - Val -- Loss: 1.444 | Acc: 56.753% | Wgt Acc: 52.084% | Dur: 42.19s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   3.   8.  38.  19.]
 [  6. 121.  52.   8.  18.]
 [  3.  52. 128.   6.  42.]
 [ 33.  33.  31. 106.  35.]
 [ 39.  59.  71.  46. 317.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.403 | Acc: 87.750% | Wgt Acc: 87.831%
	I - Batch: 100 | Loss: 0.397 | Acc: 87.625% | Wgt Acc: 88.626%
	I - Batch: 150 | Loss: 0.397 | Acc: 87.750% | Wgt Acc: 88.664%
	I - Batch: 200 | Loss: 0.406 | Acc: 87.656% | Wgt Acc: 88.383%
	I - Batch: 250 | Loss: 0.409 | Acc: 87.275% | Wgt Acc: 88.065%
	I - Batch: 300 | Loss: 0.412 | Acc: 87.333% | Wgt Acc: 87.939%
	I - Batch: 350 | Loss: 0.412 | Acc: 87.268% | Wgt Acc: 87.855%
I - num batch: 364
I - Train -- Loss: 0.412 | Acc: 87.257% | Wgt Acc: 87.849% | LR: 1.250000e-04 | Dur: 227.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 590.    0.    0.   36.  112.]
 [   0.  604.   42.    8.   13.]
 [   1.   53.  876.    0.  154.]
 [  35.    5.    1.  621.  101.]
 [  66.    6.   55.   53. 2383.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.509 | Acc: 54.125% | Wgt Acc: 50.037%
I - num batch: 87
I - Val -- Loss: 1.539 | Acc: 55.747% | Wgt Acc: 50.083% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   6.  10.  20.  12.]
 [  1.  98.  26.   5.  12.]
 [  5.  71. 131.   7.  40.]
 [ 50.  22.  26. 120.  41.]
 [ 42.  71.  97.  52. 326.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.349 | Acc: 91.000% | Wgt Acc: 92.352%
	I - Batch: 100 | Loss: 0.365 | Acc: 89.438% | Wgt Acc: 90.870%
	I - Batch: 150 | Loss: 0.384 | Acc: 88.250% | Wgt Acc: 89.409%
	I - Batch: 200 | Loss: 0.396 | Acc: 87.375% | Wgt Acc: 88.465%
	I - Batch: 250 | Loss: 0.404 | Acc: 86.900% | Wgt Acc: 88.058%
	I - Batch: 300 | Loss: 0.406 | Acc: 86.938% | Wgt Acc: 87.892%
	I - Batch: 350 | Loss: 0.408 | Acc: 86.696% | Wgt Acc: 87.736%
I - num batch: 364
I - Train -- Loss: 0.408 | Acc: 86.776% | Wgt Acc: 87.816% | LR: 1.250000e-04 | Dur: 228.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 600.    0.    0.   37.  128.]
 [   0.  612.   41.    3.   22.]
 [   0.   48.  871.    2.  162.]
 [  33.    4.    1.  621.  109.]
 [  59.    4.   61.   55. 2342.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.817 | Acc: 48.750% | Wgt Acc: 42.747%
I - num batch: 87
I - Val -- Loss: 1.727 | Acc: 54.885% | Wgt Acc: 46.720% | Dur: 42.42s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   4.   9.  43.  23.]
 [  1.  78.   9.   3.   6.]
 [  3.  65. 132.   7.  24.]
 [ 18.  18.  10.  65.  12.]
 [ 54. 103. 130.  86. 366.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.346 | Acc: 88.875% | Wgt Acc: 90.722%
	I - Batch: 100 | Loss: 0.354 | Acc: 88.562% | Wgt Acc: 89.926%
	I - Batch: 150 | Loss: 0.372 | Acc: 87.833% | Wgt Acc: 88.923%
	I - Batch: 200 | Loss: 0.373 | Acc: 87.625% | Wgt Acc: 88.935%
	I - Batch: 250 | Loss: 0.385 | Acc: 87.350% | Wgt Acc: 88.402%
	I - Batch: 300 | Loss: 0.398 | Acc: 86.833% | Wgt Acc: 87.811%
	I - Batch: 350 | Loss: 0.401 | Acc: 86.911% | Wgt Acc: 87.782%
I - num batch: 364
I - Train -- Loss: 0.400 | Acc: 86.913% | Wgt Acc: 87.748% | LR: 1.250000e-04 | Dur: 228.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 599.    0.    0.   47.  132.]
 [   2.  603.   42.    5.   14.]
 [   0.   56.  874.    2.  166.]
 [  34.    5.    2.  621.   94.]
 [  57.    4.   56.   43. 2357.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.676 | Acc: 51.000% | Wgt Acc: 46.661%
I - num batch: 87
I - Val -- Loss: 1.605 | Acc: 54.095% | Wgt Acc: 48.582% | Dur: 42.54s
I - Confusion Matrix: [row->prediction - col->label]
[[150.  10.  17.  60.  31.]
 [  1. 108.  54.   6.  17.]
 [  4.  59. 107.  10.  44.]
 [ 11.  28.  28.  71.  22.]
 [ 33.  63.  84.  57. 317.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.373 | Acc: 89.375% | Wgt Acc: 89.563%
	I - Batch: 100 | Loss: 0.380 | Acc: 88.812% | Wgt Acc: 88.796%
	I - Batch: 150 | Loss: 0.387 | Acc: 88.000% | Wgt Acc: 88.451%
	I - Batch: 200 | Loss: 0.383 | Acc: 87.969% | Wgt Acc: 88.786%
	I - Batch: 250 | Loss: 0.393 | Acc: 87.775% | Wgt Acc: 88.451%
	I - Batch: 300 | Loss: 0.395 | Acc: 87.521% | Wgt Acc: 88.317%
	I - Batch: 350 | Loss: 0.393 | Acc: 87.464% | Wgt Acc: 88.442%
I - num batch: 364
I - Train -- Loss: 0.394 | Acc: 87.463% | Wgt Acc: 88.406% | LR: 1.250000e-04 | Dur: 228.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 591.    0.    0.   39.  114.]
 [   2.  620.   33.    6.   20.]
 [   0.   40.  885.    2.  168.]
 [  38.    6.    4.  619.   90.]
 [  61.    2.   52.   52. 2371.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.643 | Acc: 52.500% | Wgt Acc: 47.813%
I - num batch: 87
I - Val -- Loss: 1.576 | Acc: 55.603% | Wgt Acc: 49.816% | Dur: 42.58s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   5.  10.  24.  29.]
 [  2. 104.  36.   4.  11.]
 [  2.  57. 112.   9.  23.]
 [ 53.  36.  24. 124.  42.]
 [ 34.  66. 108.  43. 326.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.365 | Acc: 89.375% | Wgt Acc: 89.287%
	I - Batch: 100 | Loss: 0.367 | Acc: 89.000% | Wgt Acc: 89.700%
	I - Batch: 150 | Loss: 0.362 | Acc: 89.167% | Wgt Acc: 90.056%
	I - Batch: 200 | Loss: 0.364 | Acc: 88.344% | Wgt Acc: 89.602%
	I - Batch: 250 | Loss: 0.361 | Acc: 88.425% | Wgt Acc: 89.658%
	I - Batch: 300 | Loss: 0.362 | Acc: 88.583% | Wgt Acc: 89.708%
	I - Batch: 350 | Loss: 0.367 | Acc: 88.554% | Wgt Acc: 89.708%
I - num batch: 364
I - Train -- Loss: 0.367 | Acc: 88.358% | Wgt Acc: 89.596% | LR: 1.250000e-04 | Dur: 228.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 599.    0.    0.   30.  127.]
 [   0.  619.   33.    3.   24.]
 [   0.   38.  907.    1.  139.]
 [  35.    6.    2.  638.   98.]
 [  58.    5.   32.   46. 2375.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.550 | Acc: 54.875% | Wgt Acc: 51.415%
I - num batch: 87
I - Val -- Loss: 1.516 | Acc: 56.753% | Wgt Acc: 52.471% | Dur: 42.62s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   7.  19.  53.  34.]
 [  1.  81.   9.   3.  12.]
 [  4.  86. 163.   7.  45.]
 [ 31.  31.  28. 110.  38.]
 [ 29.  63.  71.  31. 302.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.365 | Acc: 88.500% | Wgt Acc: 90.024%
	I - Batch: 100 | Loss: 0.354 | Acc: 89.312% | Wgt Acc: 90.452%
	I - Batch: 150 | Loss: 0.346 | Acc: 89.667% | Wgt Acc: 90.717%
	I - Batch: 200 | Loss: 0.335 | Acc: 89.969% | Wgt Acc: 91.173%
	I - Batch: 250 | Loss: 0.336 | Acc: 89.875% | Wgt Acc: 90.986%
	I - Batch: 300 | Loss: 0.338 | Acc: 89.854% | Wgt Acc: 90.932%
	I - Batch: 350 | Loss: 0.341 | Acc: 89.732% | Wgt Acc: 90.824%
I - num batch: 364
I - Train -- Loss: 0.340 | Acc: 89.699% | Wgt Acc: 90.815% | LR: 1.250000e-04 | Dur: 228.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 612.    0.    0.   23.  103.]
 [   0.  630.   20.    2.   12.]
 [   0.   34.  909.    2.  132.]
 [  31.    1.    2.  646.   97.]
 [  49.    3.   43.   45. 2419.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.809 | Acc: 46.375% | Wgt Acc: 40.652%
I - num batch: 87
I - Val -- Loss: 1.699 | Acc: 51.437% | Wgt Acc: 44.588% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   1.  11.  47.  15.]
 [  0.  77.  23.   4.  10.]
 [  6.  70. 117.  14.  49.]
 [ 18.  36.  16.  68.  30.]
 [ 48.  84. 123.  71. 327.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.358 | Acc: 89.375% | Wgt Acc: 89.576%
	I - Batch: 100 | Loss: 0.366 | Acc: 89.062% | Wgt Acc: 89.382%
	I - Batch: 150 | Loss: 0.375 | Acc: 88.375% | Wgt Acc: 88.832%
	I - Batch: 200 | Loss: 0.370 | Acc: 88.469% | Wgt Acc: 89.063%
	I - Batch: 250 | Loss: 0.365 | Acc: 88.600% | Wgt Acc: 89.194%
	I - Batch: 300 | Loss: 0.365 | Acc: 88.500% | Wgt Acc: 89.187%
	I - Batch: 350 | Loss: 0.370 | Acc: 88.196% | Wgt Acc: 88.954%
I - num batch: 364
I - Train -- Loss: 0.369 | Acc: 88.289% | Wgt Acc: 89.026% | LR: 1.250000e-04 | Dur: 227.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 597.    0.    0.   27.  104.]
 [   0.  619.   31.    8.    9.]
 [   0.   38.  885.    0.  141.]
 [  32.    8.    0.  629.  105.]
 [  63.    3.   58.   54. 2404.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.614 | Acc: 51.125% | Wgt Acc: 46.900%
I - num batch: 87
I - Val -- Loss: 1.549 | Acc: 54.023% | Wgt Acc: 49.545% | Dur: 42.64s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   5.   5.  22.  20.]
 [  1. 104.  26.   4.  14.]
 [  2.  42. 104.   1.  34.]
 [ 61.  57.  44. 144.  69.]
 [ 29.  60. 111.  33. 294.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.309 | Acc: 91.000% | Wgt Acc: 91.863%
	I - Batch: 100 | Loss: 0.312 | Acc: 90.812% | Wgt Acc: 91.781%
	I - Batch: 150 | Loss: 0.324 | Acc: 90.167% | Wgt Acc: 91.026%
	I - Batch: 200 | Loss: 0.338 | Acc: 89.469% | Wgt Acc: 90.376%
	I - Batch: 250 | Loss: 0.337 | Acc: 89.150% | Wgt Acc: 90.187%
	I - Batch: 300 | Loss: 0.335 | Acc: 89.271% | Wgt Acc: 90.439%
	I - Batch: 350 | Loss: 0.334 | Acc: 89.429% | Wgt Acc: 90.549%
I - num batch: 364
I - Train -- Loss: 0.332 | Acc: 89.561% | Wgt Acc: 90.654% | LR: 1.250000e-04 | Dur: 228.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 616.    0.    0.   28.   99.]
 [   0.  635.   28.    6.   22.]
 [   0.   22.  894.    1.  140.]
 [  27.    6.    2.  647.   86.]
 [  49.    5.   50.   36. 2416.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.595 | Acc: 54.125% | Wgt Acc: 49.835%
I - num batch: 87
I - Val -- Loss: 1.591 | Acc: 55.532% | Wgt Acc: 50.416% | Dur: 42.57s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   4.   5.  22.  12.]
 [  2.  78.  14.   8.   9.]
 [  5.  92. 175.  15.  68.]
 [ 33.  24.  12. 103.  25.]
 [ 59.  70.  84.  56. 317.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.346 | Acc: 89.000% | Wgt Acc: 90.528%
	I - Batch: 100 | Loss: 0.363 | Acc: 88.750% | Wgt Acc: 89.838%
	I - Batch: 150 | Loss: 0.370 | Acc: 88.167% | Wgt Acc: 89.106%
	I - Batch: 200 | Loss: 0.373 | Acc: 87.812% | Wgt Acc: 88.889%
	I - Batch: 250 | Loss: 0.361 | Acc: 88.150% | Wgt Acc: 89.187%
	I - Batch: 300 | Loss: 0.359 | Acc: 88.354% | Wgt Acc: 89.356%
	I - Batch: 350 | Loss: 0.358 | Acc: 88.232% | Wgt Acc: 89.284%
I - num batch: 364
I - Train -- Loss: 0.355 | Acc: 88.392% | Wgt Acc: 89.431% | LR: 1.250000e-04 | Dur: 227.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 599.    0.    0.   30.  115.]
 [   0.  630.   28.    2.   18.]
 [   2.   28.  893.    2.  137.]
 [  34.    4.    1.  627.  102.]
 [  57.    6.   52.   57. 2391.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.711 | Acc: 51.500% | Wgt Acc: 46.649%
I - num batch: 87
I - Val -- Loss: 1.677 | Acc: 54.310% | Wgt Acc: 47.633% | Dur: 42.69s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   3.  11.  40.  13.]
 [  1.  82.  11.   8.   6.]
 [  7.  85. 156.  11.  56.]
 [ 11.  17.   8.  53.  14.]
 [ 57.  81. 104.  92. 342.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.303 | Acc: 90.875% | Wgt Acc: 92.249%
	I - Batch: 100 | Loss: 0.293 | Acc: 91.125% | Wgt Acc: 92.204%
	I - Batch: 150 | Loss: 0.288 | Acc: 91.083% | Wgt Acc: 92.069%
	I - Batch: 200 | Loss: 0.289 | Acc: 91.094% | Wgt Acc: 92.034%
	I - Batch: 250 | Loss: 0.292 | Acc: 90.825% | Wgt Acc: 91.887%
	I - Batch: 300 | Loss: 0.305 | Acc: 90.417% | Wgt Acc: 91.410%
	I - Batch: 350 | Loss: 0.307 | Acc: 90.321% | Wgt Acc: 91.281%
I - num batch: 364
I - Train -- Loss: 0.307 | Acc: 90.335% | Wgt Acc: 91.297% | LR: 1.250000e-04 | Dur: 228.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 611.    0.    0.   22.  110.]
 [   0.  632.   22.    1.   14.]
 [   1.   30.  912.    1.  119.]
 [  26.    2.    0.  652.   74.]
 [  54.    4.   40.   42. 2446.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.727 | Acc: 52.625% | Wgt Acc: 47.660%
I - num batch: 87
I - Val -- Loss: 1.670 | Acc: 54.957% | Wgt Acc: 48.678% | Dur: 42.89s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   5.  11.  25.  20.]
 [  1.  76.   9.   1.   9.]
 [  3.  86. 154.  10.  40.]
 [ 35.  27.  17. 102.  29.]
 [ 60.  74.  99.  66. 333.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.294 | Acc: 91.375% | Wgt Acc: 92.528%
	I - Batch: 100 | Loss: 0.299 | Acc: 91.125% | Wgt Acc: 92.175%
	I - Batch: 150 | Loss: 0.301 | Acc: 90.542% | Wgt Acc: 91.656%
	I - Batch: 200 | Loss: 0.311 | Acc: 90.000% | Wgt Acc: 91.021%
	I - Batch: 250 | Loss: 0.319 | Acc: 89.725% | Wgt Acc: 90.536%
	I - Batch: 300 | Loss: 0.320 | Acc: 89.625% | Wgt Acc: 90.428%
	I - Batch: 350 | Loss: 0.316 | Acc: 89.804% | Wgt Acc: 90.675%
I - num batch: 364
I - Train -- Loss: 0.315 | Acc: 89.837% | Wgt Acc: 90.684% | LR: 1.250000e-04 | Dur: 228.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 614.    0.    0.   20.  104.]
 [   0.  622.   32.    5.   14.]
 [   2.   34.  904.    1.  130.]
 [  33.    9.    0.  647.   78.]
 [  43.    3.   38.   45. 2437.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.635 | Acc: 54.750% | Wgt Acc: 49.853%
I - num batch: 87
I - Val -- Loss: 1.599 | Acc: 57.615% | Wgt Acc: 50.641% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   4.   8.  31.  11.]
 [  2. 100.  25.   6.  11.]
 [  3.  67. 141.   8.  33.]
 [ 24.  22.  15.  88.  16.]
 [ 57.  75. 101.  71. 360.]]

I - Local maximum validation set accuracy:  57.61

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.288 | Acc: 91.000% | Wgt Acc: 92.305%
	I - Batch: 100 | Loss: 0.287 | Acc: 91.062% | Wgt Acc: 92.074%
	I - Batch: 150 | Loss: 0.303 | Acc: 90.292% | Wgt Acc: 91.168%
	I - Batch: 200 | Loss: 0.318 | Acc: 89.781% | Wgt Acc: 90.578%
	I - Batch: 250 | Loss: 0.315 | Acc: 89.750% | Wgt Acc: 90.523%
	I - Batch: 300 | Loss: 0.326 | Acc: 89.333% | Wgt Acc: 90.102%
	I - Batch: 350 | Loss: 0.328 | Acc: 89.107% | Wgt Acc: 90.000%
I - num batch: 364
I - Train -- Loss: 0.326 | Acc: 89.149% | Wgt Acc: 89.989% | LR: 1.250000e-04 | Dur: 225.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 613.    0.    0.   25.  117.]
 [   0.  629.   41.    8.   17.]
 [   1.   32.  880.    0.  135.]
 [  23.    2.    1.  643.   75.]
 [  55.    5.   52.   42. 2419.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.622 | Acc: 53.625% | Wgt Acc: 49.155%
I - num batch: 87
I - Val -- Loss: 1.548 | Acc: 56.250% | Wgt Acc: 51.175% | Dur: 41.83s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   2.   9.  21.  14.]
 [  2. 117.  45.   6.  14.]
 [  3.  41. 114.   7.  29.]
 [ 52.  37.  30. 127.  55.]
 [ 36.  71.  92.  43. 319.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.305 | Acc: 90.250% | Wgt Acc: 91.308%
	I - Batch: 100 | Loss: 0.304 | Acc: 90.000% | Wgt Acc: 91.082%
	I - Batch: 150 | Loss: 0.300 | Acc: 90.250% | Wgt Acc: 91.220%
	I - Batch: 200 | Loss: 0.305 | Acc: 89.969% | Wgt Acc: 91.148%
	I - Batch: 250 | Loss: 0.297 | Acc: 90.375% | Wgt Acc: 91.454%
	I - Batch: 300 | Loss: 0.301 | Acc: 90.375% | Wgt Acc: 91.455%
	I - Batch: 350 | Loss: 0.299 | Acc: 90.589% | Wgt Acc: 91.400%
I - num batch: 364
I - Train -- Loss: 0.299 | Acc: 90.542% | Wgt Acc: 91.288% | LR: 1.250000e-04 | Dur: 225.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 619.    0.    0.   26.   87.]
 [   0.  627.   30.    4.   12.]
 [   0.   29.  903.    0.  130.]
 [  29.    4.    3.  654.   72.]
 [  44.    8.   38.   34. 2462.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.796 | Acc: 50.750% | Wgt Acc: 46.349%
I - num batch: 87
I - Val -- Loss: 1.759 | Acc: 53.089% | Wgt Acc: 47.459% | Dur: 41.81s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   8.  12.  52.  29.]
 [  0. 107.  55.   6.  21.]
 [  6.  51. 110.   9.  44.]
 [ 19.  32.  19.  72.  20.]
 [ 41.  70.  94.  65. 317.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.310 | Acc: 89.375% | Wgt Acc: 90.392%
	I - Batch: 100 | Loss: 0.291 | Acc: 91.062% | Wgt Acc: 91.947%
	I - Batch: 150 | Loss: 0.295 | Acc: 90.750% | Wgt Acc: 91.669%
	I - Batch: 200 | Loss: 0.297 | Acc: 90.562% | Wgt Acc: 91.542%
	I - Batch: 250 | Loss: 0.297 | Acc: 90.600% | Wgt Acc: 91.516%
	I - Batch: 300 | Loss: 0.294 | Acc: 90.833% | Wgt Acc: 91.873%
	I - Batch: 350 | Loss: 0.288 | Acc: 91.071% | Wgt Acc: 92.044%
I - num batch: 364
I - Train -- Loss: 0.290 | Acc: 90.972% | Wgt Acc: 91.983% | LR: 1.250000e-04 | Dur: 229.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 635.    0.    0.   16.  103.]
 [   0.  626.   20.    2.   15.]
 [   0.   32.  918.    0.  112.]
 [  20.    3.    1.  655.   77.]
 [  37.    7.   35.   45. 2456.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.812 | Acc: 53.375% | Wgt Acc: 49.240%
I - num batch: 87
I - Val -- Loss: 1.763 | Acc: 55.244% | Wgt Acc: 49.518% | Dur: 43.02s
I - Confusion Matrix: [row->prediction - col->label]
[[139.   7.  21.  50.  45.]
 [  0. 108.  24.   4.  12.]
 [  1.  40. 106.   3.  25.]
 [ 27.  38.  29.  92.  25.]
 [ 32.  75. 110.  55. 324.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.347 | Acc: 87.500% | Wgt Acc: 89.271%
	I - Batch: 100 | Loss: 0.314 | Acc: 89.500% | Wgt Acc: 90.928%
	I - Batch: 150 | Loss: 0.292 | Acc: 90.542% | Wgt Acc: 91.924%
	I - Batch: 200 | Loss: 0.289 | Acc: 90.750% | Wgt Acc: 91.943%
	I - Batch: 250 | Loss: 0.288 | Acc: 90.950% | Wgt Acc: 92.076%
	I - Batch: 300 | Loss: 0.289 | Acc: 90.688% | Wgt Acc: 91.873%
	I - Batch: 350 | Loss: 0.294 | Acc: 90.411% | Wgt Acc: 91.530%
I - num batch: 364
I - Train -- Loss: 0.292 | Acc: 90.507% | Wgt Acc: 91.593% | LR: 1.250000e-04 | Dur: 230.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 615.    0.    0.   22.  107.]
 [   0.  637.   23.    2.   21.]
 [   0.   20.  912.    0.  118.]
 [  27.    4.    1.  656.   74.]
 [  50.    7.   38.   38. 2443.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.943 | Acc: 48.500% | Wgt Acc: 43.929%
I - num batch: 87
I - Val -- Loss: 1.849 | Acc: 51.437% | Wgt Acc: 45.861% | Dur: 43.12s
I - Confusion Matrix: [row->prediction - col->label]
[[142.  10.  19.  53.  55.]
 [  1.  73.  24.   1.   9.]
 [  1.  41.  86.   4.  19.]
 [ 38.  62.  39. 122.  55.]
 [ 17.  82. 122.  24. 293.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.275 | Acc: 91.750% | Wgt Acc: 92.850%
	I - Batch: 100 | Loss: 0.271 | Acc: 92.062% | Wgt Acc: 92.558%
	I - Batch: 150 | Loss: 0.272 | Acc: 92.250% | Wgt Acc: 92.890%
	I - Batch: 200 | Loss: 0.277 | Acc: 92.000% | Wgt Acc: 92.580%
	I - Batch: 250 | Loss: 0.277 | Acc: 91.775% | Wgt Acc: 92.407%
	I - Batch: 300 | Loss: 0.287 | Acc: 91.354% | Wgt Acc: 91.924%
	I - Batch: 350 | Loss: 0.290 | Acc: 91.179% | Wgt Acc: 91.820%
I - num batch: 364
I - Train -- Loss: 0.290 | Acc: 91.230% | Wgt Acc: 91.845% | LR: 1.250000e-04 | Dur: 230.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 622.    0.    0.   24.   80.]
 [   0.  628.   28.    2.   20.]
 [   0.   31.  910.    0.   98.]
 [  25.    3.    0.  656.   76.]
 [  45.    6.   36.   36. 2489.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.681 | Acc: 53.750% | Wgt Acc: 49.106%
I - num batch: 87
I - Val -- Loss: 1.654 | Acc: 54.526% | Wgt Acc: 49.530% | Dur: 42.97s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   4.   8.  28.  18.]
 [  1.  98.  27.   6.  17.]
 [  6.  57. 133.  16.  42.]
 [ 44.  44.  34. 107.  44.]
 [ 37.  65.  88.  47. 310.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.231 | Acc: 92.375% | Wgt Acc: 93.519%
	I - Batch: 100 | Loss: 0.241 | Acc: 92.500% | Wgt Acc: 93.682%
	I - Batch: 150 | Loss: 0.258 | Acc: 92.125% | Wgt Acc: 93.079%
	I - Batch: 200 | Loss: 0.265 | Acc: 92.062% | Wgt Acc: 92.937%
	I - Batch: 250 | Loss: 0.272 | Acc: 91.375% | Wgt Acc: 92.522%
	I - Batch: 300 | Loss: 0.268 | Acc: 91.583% | Wgt Acc: 92.746%
	I - Batch: 350 | Loss: 0.269 | Acc: 91.536% | Wgt Acc: 92.576%
I - num batch: 364
I - Train -- Loss: 0.267 | Acc: 91.625% | Wgt Acc: 92.667% | LR: 1.250000e-04 | Dur: 230.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 630.    0.    0.   17.   83.]
 [   0.  638.   11.    4.   16.]
 [   1.   17.  925.    2.  119.]
 [  20.    7.    0.  660.   70.]
 [  41.    6.   38.   35. 2475.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.837 | Acc: 51.500% | Wgt Acc: 45.595%
I - num batch: 87
I - Val -- Loss: 1.807 | Acc: 55.029% | Wgt Acc: 47.467% | Dur: 43.26s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   3.  11.  36.  13.]
 [  1.  96.  23.   3.   9.]
 [  2.  60. 109.  10.  30.]
 [ 24.  20.  18.  86.  23.]
 [ 53.  89. 129.  69. 356.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.272 | Acc: 92.500% | Wgt Acc: 92.232%
	I - Batch: 100 | Loss: 0.252 | Acc: 92.688% | Wgt Acc: 93.210%
	I - Batch: 150 | Loss: 0.254 | Acc: 92.375% | Wgt Acc: 93.003%
	I - Batch: 200 | Loss: 0.259 | Acc: 92.000% | Wgt Acc: 92.728%
	I - Batch: 250 | Loss: 0.262 | Acc: 91.975% | Wgt Acc: 92.667%
	I - Batch: 300 | Loss: 0.265 | Acc: 91.604% | Wgt Acc: 92.458%
	I - Batch: 350 | Loss: 0.264 | Acc: 91.607% | Wgt Acc: 92.409%
I - num batch: 364
I - Train -- Loss: 0.268 | Acc: 91.453% | Wgt Acc: 92.262% | LR: 1.250000e-04 | Dur: 230.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 615.    0.    0.   17.  102.]
 [   0.  633.   23.    5.   11.]
 [   0.   30.  922.    0.   94.]
 [  20.    0.    2.  663.   71.]
 [  57.    5.   27.   33. 2485.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.453 | Acc: 56.750% | Wgt Acc: 53.363%
I - num batch: 87
I - Val -- Loss: 1.473 | Acc: 58.333% | Wgt Acc: 53.706% | Dur: 43.02s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   3.   8.  23.  12.]
 [  3. 142.  60.  12.  25.]
 [  5.  41. 122.   8.  31.]
 [ 46.  26.  10. 118.  36.]
 [ 42.  56.  90.  43. 327.]]

I - Local maximum validation set accuracy:  58.33

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.267 | Acc: 92.125% | Wgt Acc: 92.842%
	I - Batch: 100 | Loss: 0.243 | Acc: 93.312% | Wgt Acc: 94.102%
	I - Batch: 150 | Loss: 0.242 | Acc: 93.333% | Wgt Acc: 94.135%
	I - Batch: 200 | Loss: 0.237 | Acc: 93.250% | Wgt Acc: 94.117%
	I - Batch: 250 | Loss: 0.239 | Acc: 93.050% | Wgt Acc: 93.939%
	I - Batch: 300 | Loss: 0.240 | Acc: 92.938% | Wgt Acc: 93.865%
	I - Batch: 350 | Loss: 0.232 | Acc: 93.071% | Wgt Acc: 94.070%
I - num batch: 364
I - Train -- Loss: 0.230 | Acc: 93.173% | Wgt Acc: 94.153% | LR: 1.250000e-04 | Dur: 228.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 643.    0.    0.   19.   80.]
 [   0.  651.   11.    3.   11.]
 [   0.   13.  935.    0.   83.]
 [  17.    1.    0.  667.   67.]
 [  32.    3.   28.   29. 2522.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.942 | Acc: 52.125% | Wgt Acc: 46.808%
I - num batch: 87
I - Val -- Loss: 1.820 | Acc: 55.460% | Wgt Acc: 49.127% | Dur: 42.49s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   9.  14.  34.  39.]
 [  0.  92.  18.   5.  10.]
 [  3.  40. 104.   3.  16.]
 [ 51.  50.  40. 127.  36.]
 [ 26.  77. 114.  35. 330.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.209 | Acc: 93.875% | Wgt Acc: 94.718%
	I - Batch: 100 | Loss: 0.233 | Acc: 93.125% | Wgt Acc: 93.936%
	I - Batch: 150 | Loss: 0.239 | Acc: 92.583% | Wgt Acc: 93.409%
	I - Batch: 200 | Loss: 0.234 | Acc: 92.969% | Wgt Acc: 93.706%
	I - Batch: 250 | Loss: 0.240 | Acc: 92.825% | Wgt Acc: 93.583%
	I - Batch: 300 | Loss: 0.238 | Acc: 92.917% | Wgt Acc: 93.731%
	I - Batch: 350 | Loss: 0.237 | Acc: 92.982% | Wgt Acc: 93.840%
I - num batch: 364
I - Train -- Loss: 0.238 | Acc: 92.829% | Wgt Acc: 93.774% | LR: 1.250000e-04 | Dur: 227.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 632.    0.    0.   16.   81.]
 [   0.  650.   14.    4.   11.]
 [   0.   13.  934.    0.   88.]
 [  22.    0.    0.  666.   67.]
 [  38.    5.   26.   32. 2516.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.713 | Acc: 54.625% | Wgt Acc: 50.012%
I - num batch: 87
I - Val -- Loss: 1.637 | Acc: 57.759% | Wgt Acc: 52.316% | Dur: 42.94s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   5.   9.  28.  20.]
 [  1. 109.  32.  11.  16.]
 [  4.  58. 135.   6.  30.]
 [ 39.  29.  23. 116.  33.]
 [ 43.  67.  91.  43. 332.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.233 | Acc: 92.875% | Wgt Acc: 94.453%
	I - Batch: 100 | Loss: 0.244 | Acc: 92.750% | Wgt Acc: 93.725%
	I - Batch: 150 | Loss: 0.248 | Acc: 92.417% | Wgt Acc: 93.459%
	I - Batch: 200 | Loss: 0.243 | Acc: 92.594% | Wgt Acc: 93.571%
	I - Batch: 250 | Loss: 0.238 | Acc: 92.775% | Wgt Acc: 93.694%
	I - Batch: 300 | Loss: 0.247 | Acc: 92.479% | Wgt Acc: 93.258%
	I - Batch: 350 | Loss: 0.245 | Acc: 92.571% | Wgt Acc: 93.279%
I - num batch: 364
I - Train -- Loss: 0.247 | Acc: 92.451% | Wgt Acc: 93.200% | LR: 1.250000e-04 | Dur: 226.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 630.    0.    0.   22.   73.]
 [   0.  644.   19.    3.   12.]
 [   0.   20.  921.    1.   93.]
 [  17.    2.    0.  665.   69.]
 [  45.    2.   34.   27. 2516.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.140 | Acc: 47.375% | Wgt Acc: 41.754%
I - num batch: 87
I - Val -- Loss: 2.029 | Acc: 51.724% | Wgt Acc: 44.154% | Dur: 41.71s
I - Confusion Matrix: [row->prediction - col->label]
[[138.  15.  21.  51.  51.]
 [  0.  58.   5.   1.   2.]
 [  2.  66. 118.   7.  23.]
 [ 17.  33.  10.  71.  20.]
 [ 42.  96. 136.  74. 335.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.255 | Acc: 91.000% | Wgt Acc: 92.456%
	I - Batch: 100 | Loss: 0.257 | Acc: 91.875% | Wgt Acc: 92.839%
	I - Batch: 150 | Loss: 0.254 | Acc: 91.958% | Wgt Acc: 92.880%
	I - Batch: 200 | Loss: 0.254 | Acc: 91.781% | Wgt Acc: 92.902%
	I - Batch: 250 | Loss: 0.256 | Acc: 91.725% | Wgt Acc: 92.769%
	I - Batch: 300 | Loss: 0.250 | Acc: 91.958% | Wgt Acc: 92.976%
	I - Batch: 350 | Loss: 0.251 | Acc: 91.911% | Wgt Acc: 92.902%
I - num batch: 364
I - Train -- Loss: 0.250 | Acc: 91.952% | Wgt Acc: 92.927% | LR: 1.250000e-04 | Dur: 225.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 633.    0.    0.   11.   91.]
 [   0.  636.   16.    3.   15.]
 [   0.   22.  923.    1.   99.]
 [  14.    2.    2.  669.   72.]
 [  45.    8.   33.   34. 2486.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.953 | Acc: 53.000% | Wgt Acc: 47.648%
I - num batch: 87
I - Val -- Loss: 1.872 | Acc: 55.747% | Wgt Acc: 48.705% | Dur: 41.09s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   5.  16.  50.  25.]
 [  0.  88.  22.   2.   6.]
 [  2.  41. 120.   4.  27.]
 [ 17.  44.  22.  86.  26.]
 [ 45.  90. 110.  62. 347.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.208 | Acc: 94.125% | Wgt Acc: 95.051%
	I - Batch: 100 | Loss: 0.194 | Acc: 94.250% | Wgt Acc: 95.047%
	I - Batch: 150 | Loss: 0.204 | Acc: 94.125% | Wgt Acc: 94.528%
	I - Batch: 200 | Loss: 0.217 | Acc: 93.125% | Wgt Acc: 93.961%
	I - Batch: 250 | Loss: 0.225 | Acc: 92.925% | Wgt Acc: 93.672%
	I - Batch: 300 | Loss: 0.230 | Acc: 92.938% | Wgt Acc: 93.564%
	I - Batch: 350 | Loss: 0.232 | Acc: 92.929% | Wgt Acc: 93.577%
I - num batch: 364
I - Train -- Loss: 0.234 | Acc: 92.812% | Wgt Acc: 93.528% | LR: 1.250000e-04 | Dur: 222.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 635.    0.    0.   19.   85.]
 [   0.  644.   16.    5.   16.]
 [   1.   19.  927.    0.   78.]
 [  18.    4.    0.  663.   56.]
 [  38.    1.   31.   31. 2528.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.762 | Acc: 51.125% | Wgt Acc: 47.329%
I - num batch: 87
I - Val -- Loss: 1.722 | Acc: 55.244% | Wgt Acc: 49.588% | Dur: 41.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 88.   0.   6.  20.   7.]
 [  2. 101.  10.   2.   8.]
 [  6.  82. 167.  19.  68.]
 [ 27.  21.  11.  79.  14.]
 [ 76.  64.  96.  84. 334.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.239 | Acc: 92.000% | Wgt Acc: 93.037%
	I - Batch: 100 | Loss: 0.223 | Acc: 93.125% | Wgt Acc: 93.976%
	I - Batch: 150 | Loss: 0.213 | Acc: 93.458% | Wgt Acc: 94.298%
	I - Batch: 200 | Loss: 0.207 | Acc: 93.594% | Wgt Acc: 94.518%
	I - Batch: 250 | Loss: 0.206 | Acc: 93.650% | Wgt Acc: 94.547%
	I - Batch: 300 | Loss: 0.213 | Acc: 93.396% | Wgt Acc: 94.302%
	I - Batch: 350 | Loss: 0.217 | Acc: 93.286% | Wgt Acc: 94.221%
I - num batch: 364
I - Train -- Loss: 0.219 | Acc: 93.190% | Wgt Acc: 94.100% | LR: 1.250000e-04 | Dur: 223.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 636.    0.    0.    6.   87.]
 [   0.  642.   19.    3.   14.]
 [   0.   20.  931.    0.   76.]
 [  11.    2.    0.  687.   63.]
 [  45.    4.   24.   22. 2523.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.142 | Acc: 44.375% | Wgt Acc: 37.283%
I - num batch: 87
I - Val -- Loss: 2.042 | Acc: 50.072% | Wgt Acc: 40.474% | Dur: 41.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   1.   6.  18.   6.]
 [  0.  69.  10.   7.   7.]
 [  6.  57. 104.  11.  19.]
 [ 40.  38.  19.  80.  27.]
 [ 81. 103. 151.  88. 372.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.190 | Acc: 94.000% | Wgt Acc: 94.969%
	I - Batch: 100 | Loss: 0.205 | Acc: 93.312% | Wgt Acc: 94.297%
	I - Batch: 150 | Loss: 0.204 | Acc: 93.542% | Wgt Acc: 94.499%
	I - Batch: 200 | Loss: 0.211 | Acc: 93.312% | Wgt Acc: 94.246%
	I - Batch: 250 | Loss: 0.213 | Acc: 93.150% | Wgt Acc: 94.118%
	I - Batch: 300 | Loss: 0.211 | Acc: 93.271% | Wgt Acc: 94.180%
	I - Batch: 350 | Loss: 0.211 | Acc: 93.393% | Wgt Acc: 94.277%
I - num batch: 364
I - Train -- Loss: 0.211 | Acc: 93.396% | Wgt Acc: 94.329% | LR: 1.250000e-04 | Dur: 223.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    0.    0.   10.   78.]
 [   0.  646.   14.    2.   16.]
 [   0.   18.  937.    0.   72.]
 [  19.    1.    2.  668.   68.]
 [  22.    3.   21.   38. 2529.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.101 | Acc: 48.375% | Wgt Acc: 45.203%
I - num batch: 87
I - Val -- Loss: 1.975 | Acc: 50.359% | Wgt Acc: 46.287% | Dur: 41.31s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  13.  20.  67.  68.]
 [  1. 104.  44.   5.  16.]
 [  2.  20.  72.   3.  20.]
 [ 21.  54.  55.  99.  58.]
 [ 18.  77.  99.  30. 269.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.225 | Acc: 93.625% | Wgt Acc: 93.918%
	I - Batch: 100 | Loss: 0.217 | Acc: 93.062% | Wgt Acc: 93.884%
	I - Batch: 150 | Loss: 0.215 | Acc: 93.125% | Wgt Acc: 93.879%
	I - Batch: 200 | Loss: 0.227 | Acc: 92.562% | Wgt Acc: 93.443%
	I - Batch: 250 | Loss: 0.229 | Acc: 92.400% | Wgt Acc: 93.424%
	I - Batch: 300 | Loss: 0.219 | Acc: 92.896% | Wgt Acc: 93.790%
	I - Batch: 350 | Loss: 0.226 | Acc: 92.696% | Wgt Acc: 93.555%
I - num batch: 364
I - Train -- Loss: 0.226 | Acc: 92.657% | Wgt Acc: 93.540% | LR: 1.250000e-04 | Dur: 223.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 628.    1.    0.   14.   80.]
 [   1.  642.   14.    3.   18.]
 [   0.   16.  932.    0.   92.]
 [  12.    5.    1.  673.   60.]
 [  51.    4.   27.   28. 2513.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.752 | Acc: 54.125% | Wgt Acc: 51.519%
I - num batch: 87
I - Val -- Loss: 1.696 | Acc: 55.388% | Wgt Acc: 51.740% | Dur: 41.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 87.   4.  11.  23.  17.]
 [  5. 131.  54.  10.  24.]
 [  8.  43. 128.  12.  40.]
 [ 60.  35.  30. 128.  53.]
 [ 39.  55.  67.  31. 297.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.212 | Acc: 93.000% | Wgt Acc: 93.915%
	I - Batch: 100 | Loss: 0.225 | Acc: 92.375% | Wgt Acc: 93.316%
	I - Batch: 150 | Loss: 0.237 | Acc: 91.958% | Wgt Acc: 92.882%
	I - Batch: 200 | Loss: 0.229 | Acc: 92.406% | Wgt Acc: 93.331%
	I - Batch: 250 | Loss: 0.225 | Acc: 92.575% | Wgt Acc: 93.498%
	I - Batch: 300 | Loss: 0.235 | Acc: 92.167% | Wgt Acc: 93.086%
	I - Batch: 350 | Loss: 0.236 | Acc: 92.286% | Wgt Acc: 93.113%
I - num batch: 364
I - Train -- Loss: 0.235 | Acc: 92.365% | Wgt Acc: 93.175% | LR: 1.250000e-04 | Dur: 224.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 626.    0.    0.   14.   92.]
 [   0.  641.   22.    6.   17.]
 [   0.   20.  923.    0.   85.]
 [  16.    4.    0.  672.   60.]
 [  50.    3.   29.   26. 2509.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.031 | Acc: 48.875% | Wgt Acc: 42.177%
I - num batch: 87
I - Val -- Loss: 1.970 | Acc: 51.580% | Wgt Acc: 43.547% | Dur: 42.02s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   9.  17.  40.  23.]
 [  1.  89.  50.   6.   9.]
 [  2.  23.  54.   3.  20.]
 [ 21.  73.  38.  99.  38.]
 [ 40.  74. 131.  56. 341.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.215 | Acc: 93.750% | Wgt Acc: 94.608%
	I - Batch: 100 | Loss: 0.236 | Acc: 91.938% | Wgt Acc: 92.900%
	I - Batch: 150 | Loss: 0.234 | Acc: 91.917% | Wgt Acc: 92.916%
	I - Batch: 200 | Loss: 0.231 | Acc: 92.031% | Wgt Acc: 93.175%
	I - Batch: 250 | Loss: 0.226 | Acc: 92.300% | Wgt Acc: 93.486%
	I - Batch: 300 | Loss: 0.226 | Acc: 92.438% | Wgt Acc: 93.557%
	I - Batch: 350 | Loss: 0.223 | Acc: 92.643% | Wgt Acc: 93.756%
I - num batch: 364
I - Train -- Loss: 0.224 | Acc: 92.709% | Wgt Acc: 93.796% | LR: 1.250000e-04 | Dur: 224.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 633.    0.    0.   19.   86.]
 [   0.  654.   13.    2.   14.]
 [   0.    7.  931.    1.   90.]
 [  20.    2.    1.  669.   69.]
 [  39.    5.   29.   27. 2504.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.960 | Acc: 50.750% | Wgt Acc: 45.203%
I - num batch: 87
I - Val -- Loss: 1.848 | Acc: 54.526% | Wgt Acc: 48.164% | Dur: 41.84s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   4.  17.  33.  25.]
 [  0.  86.  19.   4.   7.]
 [  1.  32.  96.   3.  21.]
 [ 41.  57.  41. 126.  54.]
 [ 30.  89. 117.  38. 324.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.182 | Acc: 94.875% | Wgt Acc: 95.837%
	I - Batch: 100 | Loss: 0.193 | Acc: 94.688% | Wgt Acc: 95.178%
	I - Batch: 150 | Loss: 0.196 | Acc: 94.500% | Wgt Acc: 94.866%
	I - Batch: 200 | Loss: 0.207 | Acc: 93.938% | Wgt Acc: 94.520%
	I - Batch: 250 | Loss: 0.205 | Acc: 93.925% | Wgt Acc: 94.496%
	I - Batch: 300 | Loss: 0.207 | Acc: 93.708% | Wgt Acc: 94.313%
	I - Batch: 350 | Loss: 0.214 | Acc: 93.464% | Wgt Acc: 94.032%
I - num batch: 364
I - Train -- Loss: 0.215 | Acc: 93.396% | Wgt Acc: 94.010% | LR: 1.250000e-04 | Dur: 224.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    0.    0.   16.   78.]
 [   0.  641.   19.    4.   12.]
 [   0.   20.  925.    1.   88.]
 [  16.    4.    1.  674.   38.]
 [  32.    3.   29.   23. 2547.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.037 | Acc: 49.875% | Wgt Acc: 45.602%
I - num batch: 87
I - Val -- Loss: 1.929 | Acc: 52.658% | Wgt Acc: 47.695% | Dur: 41.81s
I - Confusion Matrix: [row->prediction - col->label]
[[139.  14.  21.  48.  54.]
 [  0.  91.  32.   5.  11.]
 [  5.  45. 108.   8.  26.]
 [ 28.  53.  40.  99.  44.]
 [ 27.  65.  89.  44. 296.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.198 | Acc: 93.250% | Wgt Acc: 94.497%
	I - Batch: 100 | Loss: 0.213 | Acc: 92.625% | Wgt Acc: 93.592%
	I - Batch: 150 | Loss: 0.220 | Acc: 92.625% | Wgt Acc: 93.513%
	I - Batch: 200 | Loss: 0.219 | Acc: 92.688% | Wgt Acc: 93.498%
	I - Batch: 250 | Loss: 0.218 | Acc: 92.750% | Wgt Acc: 93.662%
	I - Batch: 300 | Loss: 0.217 | Acc: 93.021% | Wgt Acc: 93.906%
	I - Batch: 350 | Loss: 0.219 | Acc: 92.946% | Wgt Acc: 93.857%
I - num batch: 364
I - Train -- Loss: 0.218 | Acc: 93.070% | Wgt Acc: 93.936% | LR: 1.250000e-04 | Dur: 224.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    0.    0.   15.   83.]
 [   0.  643.   14.    6.   12.]
 [   1.   16.  932.    0.   82.]
 [  17.    5.    1.  669.   62.]
 [  30.    4.   27.   28. 2524.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.815 | Acc: 51.000% | Wgt Acc: 45.626%
I - num batch: 87
I - Val -- Loss: 1.741 | Acc: 54.598% | Wgt Acc: 48.144% | Dur: 41.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   1.  10.  31.  14.]
 [  3. 120.  43.   9.  13.]
 [  1.  32.  87.   1.  23.]
 [ 51.  43.  30. 122.  44.]
 [ 50.  72. 120.  41. 337.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.181 | Acc: 94.625% | Wgt Acc: 95.224%
	I - Batch: 100 | Loss: 0.196 | Acc: 93.562% | Wgt Acc: 94.527%
	I - Batch: 150 | Loss: 0.194 | Acc: 93.792% | Wgt Acc: 94.546%
	I - Batch: 200 | Loss: 0.197 | Acc: 93.750% | Wgt Acc: 94.317%
	I - Batch: 250 | Loss: 0.207 | Acc: 93.475% | Wgt Acc: 93.983%
	I - Batch: 300 | Loss: 0.210 | Acc: 93.229% | Wgt Acc: 93.837%
	I - Batch: 350 | Loss: 0.207 | Acc: 93.321% | Wgt Acc: 94.013%
I - num batch: 364
I - Train -- Loss: 0.207 | Acc: 93.310% | Wgt Acc: 93.981% | LR: 1.250000e-04 | Dur: 223.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 642.    0.    0.   13.   77.]
 [   0.  645.   21.    1.   14.]
 [   1.   16.  927.    0.   71.]
 [  12.    2.    3.  669.   58.]
 [  37.    5.   23.   35. 2543.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.981 | Acc: 50.375% | Wgt Acc: 45.265%
I - num batch: 87
I - Val -- Loss: 1.896 | Acc: 54.670% | Wgt Acc: 47.552% | Dur: 41.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   0.  11.  33.   9.]
 [  0.  99.  22.   7.   8.]
 [  5.  51. 142.   9.  46.]
 [ 24.  22.  13.  67.  13.]
 [ 72.  96. 102.  88. 355.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.164 | Acc: 94.750% | Wgt Acc: 96.060%
	I - Batch: 100 | Loss: 0.180 | Acc: 94.188% | Wgt Acc: 95.103%
	I - Batch: 150 | Loss: 0.190 | Acc: 93.875% | Wgt Acc: 94.467%
	I - Batch: 200 | Loss: 0.198 | Acc: 93.406% | Wgt Acc: 94.128%
	I - Batch: 250 | Loss: 0.192 | Acc: 93.700% | Wgt Acc: 94.409%
	I - Batch: 300 | Loss: 0.186 | Acc: 93.958% | Wgt Acc: 94.710%
	I - Batch: 350 | Loss: 0.188 | Acc: 94.036% | Wgt Acc: 94.755%
I - num batch: 364
I - Train -- Loss: 0.192 | Acc: 94.015% | Wgt Acc: 94.702% | LR: 1.250000e-04 | Dur: 224.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 636.    0.    0.    8.   79.]
 [   0.  649.   12.    3.   14.]
 [   0.   14.  938.    1.   65.]
 [  18.    3.    1.  682.   43.]
 [  38.    2.   23.   24. 2562.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.148 | Acc: 49.625% | Wgt Acc: 44.119%
I - num batch: 87
I - Val -- Loss: 2.077 | Acc: 52.586% | Wgt Acc: 44.642% | Dur: 41.55s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   4.   9.  39.  12.]
 [  1.  64.   6.   3.   7.]
 [  4.  86. 157.   9.  46.]
 [ 11.  12.   7.  46.  10.]
 [ 74. 102. 111. 107. 356.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.203 | Acc: 92.250% | Wgt Acc: 93.555%
	I - Batch: 100 | Loss: 0.208 | Acc: 92.812% | Wgt Acc: 93.797%
	I - Batch: 150 | Loss: 0.204 | Acc: 93.292% | Wgt Acc: 94.200%
	I - Batch: 200 | Loss: 0.198 | Acc: 93.781% | Wgt Acc: 94.643%
	I - Batch: 250 | Loss: 0.193 | Acc: 94.050% | Wgt Acc: 94.818%
	I - Batch: 300 | Loss: 0.192 | Acc: 93.958% | Wgt Acc: 94.796%
	I - Batch: 350 | Loss: 0.189 | Acc: 94.107% | Wgt Acc: 94.928%
I - num batch: 364
I - Train -- Loss: 0.189 | Acc: 94.170% | Wgt Acc: 94.940% | LR: 1.250000e-04 | Dur: 223.97s
I - Confusion Matrix: [row->prediction - col->label]
[[ 646.    0.    0.   14.   68.]
 [   0.  650.   13.    2.   15.]
 [   0.   12.  938.    0.   73.]
 [  16.    0.    0.  682.   47.]
 [  30.    6.   23.   20. 2560.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.319 | Acc: 47.875% | Wgt Acc: 40.156%
I - num batch: 87
I - Val -- Loss: 2.174 | Acc: 52.874% | Wgt Acc: 42.788% | Dur: 41.53s
I - Confusion Matrix: [row->prediction - col->label]
[[143.  12.  13.  62.  21.]
 [  0.  53.   6.   1.   4.]
 [  2.  70. 109.   8.  17.]
 [  9.  29.  10.  47.   5.]
 [ 45. 104. 152.  86. 384.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.144 | Acc: 96.125% | Wgt Acc: 96.847%
	I - Batch: 100 | Loss: 0.168 | Acc: 95.125% | Wgt Acc: 95.973%
	I - Batch: 150 | Loss: 0.168 | Acc: 95.208% | Wgt Acc: 95.939%
	I - Batch: 200 | Loss: 0.163 | Acc: 95.250% | Wgt Acc: 96.136%
	I - Batch: 250 | Loss: 0.165 | Acc: 95.175% | Wgt Acc: 95.969%
	I - Batch: 300 | Loss: 0.172 | Acc: 94.792% | Wgt Acc: 95.668%
	I - Batch: 350 | Loss: 0.169 | Acc: 94.893% | Wgt Acc: 95.689%
I - num batch: 364
I - Train -- Loss: 0.168 | Acc: 94.961% | Wgt Acc: 95.748% | LR: 1.250000e-04 | Dur: 223.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    0.    0.   11.   66.]
 [   0.  654.    6.    1.    7.]
 [   0.    9.  945.    0.   60.]
 [   9.    1.    1.  687.   50.]
 [  27.    4.   22.   19. 2580.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.024 | Acc: 51.125% | Wgt Acc: 45.853%
I - num batch: 87
I - Val -- Loss: 1.947 | Acc: 55.029% | Wgt Acc: 47.699% | Dur: 41.41s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   5.  14.  49.  23.]
 [  1.  57.   3.   0.   2.]
 [  3.  85. 155.   7.  44.]
 [ 25.  28.  10.  77.  15.]
 [ 40.  93. 108.  71. 347.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.214 | Acc: 93.250% | Wgt Acc: 93.899%
	I - Batch: 100 | Loss: 0.202 | Acc: 93.938% | Wgt Acc: 94.616%
	I - Batch: 150 | Loss: 0.200 | Acc: 93.917% | Wgt Acc: 94.637%
	I - Batch: 200 | Loss: 0.204 | Acc: 93.719% | Wgt Acc: 94.248%
	I - Batch: 250 | Loss: 0.207 | Acc: 93.250% | Wgt Acc: 94.018%
	I - Batch: 300 | Loss: 0.197 | Acc: 93.625% | Wgt Acc: 94.386%
	I - Batch: 350 | Loss: 0.191 | Acc: 93.911% | Wgt Acc: 94.635%
I - num batch: 364
I - Train -- Loss: 0.190 | Acc: 93.929% | Wgt Acc: 94.665% | LR: 1.250000e-04 | Dur: 223.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 648.    0.    0.   17.   66.]
 [   0.  646.   14.    2.   21.]
 [   0.   12.  936.    1.   78.]
 [   9.    4.    0.  677.   43.]
 [  35.    6.   24.   21. 2555.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.987 | Acc: 53.375% | Wgt Acc: 48.346%
I - num batch: 87
I - Val -- Loss: 1.894 | Acc: 55.891% | Wgt Acc: 49.441% | Dur: 42.19s
I - Confusion Matrix: [row->prediction - col->label]
[[142.   6.  16.  46.  30.]
 [  0.  94.  15.   4.   9.]
 [  4.  53. 116.   7.  26.]
 [ 17.  39.  28.  89.  29.]
 [ 36.  76. 115.  58. 337.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.167 | Acc: 95.250% | Wgt Acc: 95.616%
	I - Batch: 100 | Loss: 0.170 | Acc: 94.375% | Wgt Acc: 95.233%
	I - Batch: 150 | Loss: 0.178 | Acc: 93.958% | Wgt Acc: 94.855%
	I - Batch: 200 | Loss: 0.178 | Acc: 94.125% | Wgt Acc: 94.892%
	I - Batch: 250 | Loss: 0.182 | Acc: 94.025% | Wgt Acc: 94.757%
	I - Batch: 300 | Loss: 0.191 | Acc: 93.729% | Wgt Acc: 94.464%
	I - Batch: 350 | Loss: 0.199 | Acc: 93.500% | Wgt Acc: 94.169%
I - num batch: 364
I - Train -- Loss: 0.203 | Acc: 93.414% | Wgt Acc: 94.070% | LR: 1.250000e-04 | Dur: 227.78s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    0.    0.   10.   76.]
 [   0.  646.   10.    9.   14.]
 [   0.   11.  928.    0.   74.]
 [  12.    4.    2.  667.   52.]
 [  36.    7.   34.   32. 2547.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.739 | Acc: 55.125% | Wgt Acc: 51.029%
I - num batch: 87
I - Val -- Loss: 1.686 | Acc: 57.759% | Wgt Acc: 52.053% | Dur: 42.40s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   4.   8.  35.  19.]
 [  0. 103.  16.   2.   3.]
 [  7.  64. 157.  16.  42.]
 [ 41.  35.  21.  94.  27.]
 [ 41.  62.  88.  57. 340.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.208 | Acc: 93.125% | Wgt Acc: 93.585%
	I - Batch: 100 | Loss: 0.199 | Acc: 93.562% | Wgt Acc: 94.098%
	I - Batch: 150 | Loss: 0.206 | Acc: 92.875% | Wgt Acc: 93.633%
	I - Batch: 200 | Loss: 0.202 | Acc: 92.969% | Wgt Acc: 93.862%
	I - Batch: 250 | Loss: 0.198 | Acc: 93.225% | Wgt Acc: 94.154%
	I - Batch: 300 | Loss: 0.194 | Acc: 93.375% | Wgt Acc: 94.236%
	I - Batch: 350 | Loss: 0.191 | Acc: 93.446% | Wgt Acc: 94.272%
I - num batch: 364
I - Train -- Loss: 0.194 | Acc: 93.328% | Wgt Acc: 94.156% | LR: 1.250000e-04 | Dur: 227.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 644.    0.    0.   19.   80.]
 [   0.  645.   10.    2.    9.]
 [   0.   19.  935.    0.   85.]
 [  12.    2.    0.  669.   55.]
 [  36.    2.   29.   28. 2534.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.804 | Acc: 54.250% | Wgt Acc: 50.760%
I - num batch: 87
I - Val -- Loss: 1.776 | Acc: 54.957% | Wgt Acc: 50.923% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 81.   7.   9.  19.  11.]
 [  2. 147.  65.  10.  26.]
 [  2.  15.  86.   2.  15.]
 [ 84.  46.  43. 151.  79.]
 [ 30.  53.  87.  22. 300.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.186 | Acc: 93.875% | Wgt Acc: 94.688%
	I - Batch: 100 | Loss: 0.188 | Acc: 93.875% | Wgt Acc: 94.698%
	I - Batch: 150 | Loss: 0.189 | Acc: 94.125% | Wgt Acc: 94.938%
	I - Batch: 200 | Loss: 0.184 | Acc: 94.281% | Wgt Acc: 95.017%
	I - Batch: 250 | Loss: 0.181 | Acc: 94.425% | Wgt Acc: 95.232%
	I - Batch: 300 | Loss: 0.182 | Acc: 94.458% | Wgt Acc: 95.159%
	I - Batch: 350 | Loss: 0.176 | Acc: 94.696% | Wgt Acc: 95.367%
I - num batch: 364
I - Train -- Loss: 0.174 | Acc: 94.721% | Wgt Acc: 95.416% | LR: 1.250000e-04 | Dur: 229.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    0.    1.   11.   57.]
 [   0.  657.    9.    2.   10.]
 [   0.    9.  940.    0.   68.]
 [  13.    0.    0.  679.   47.]
 [  28.    2.   24.   26. 2581.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.182 | Acc: 50.375% | Wgt Acc: 44.003%
I - num batch: 87
I - Val -- Loss: 2.064 | Acc: 54.310% | Wgt Acc: 45.544% | Dur: 42.99s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   7.  13.  34.  11.]
 [  1.  84.   9.   2.   5.]
 [  1.  52. 120.   8.  26.]
 [ 20.  21.  12.  70.  13.]
 [ 71. 104. 136.  90. 376.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.162 | Acc: 94.625% | Wgt Acc: 95.442%
	I - Batch: 100 | Loss: 0.164 | Acc: 94.750% | Wgt Acc: 95.568%
	I - Batch: 150 | Loss: 0.172 | Acc: 94.792% | Wgt Acc: 95.583%
	I - Batch: 200 | Loss: 0.175 | Acc: 94.812% | Wgt Acc: 95.429%
	I - Batch: 250 | Loss: 0.169 | Acc: 94.800% | Wgt Acc: 95.551%
	I - Batch: 300 | Loss: 0.166 | Acc: 94.938% | Wgt Acc: 95.639%
	I - Batch: 350 | Loss: 0.168 | Acc: 94.786% | Wgt Acc: 95.521%
I - num batch: 364
I - Train -- Loss: 0.166 | Acc: 94.858% | Wgt Acc: 95.577% | LR: 1.250000e-04 | Dur: 228.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    0.    0.    8.   56.]
 [   0.  654.    7.    4.   12.]
 [   0.    6.  943.    0.   72.]
 [  12.    3.    0.  686.   41.]
 [  29.    5.   24.   20. 2582.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.979 | Acc: 50.625% | Wgt Acc: 44.854%
I - num batch: 87
I - Val -- Loss: 1.874 | Acc: 54.813% | Wgt Acc: 47.142% | Dur: 41.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 82.   3.   4.  17.   6.]
 [  1.  77.   9.   5.   8.]
 [  4.  58. 125.   9.  26.]
 [ 58.  46.  29. 125.  37.]
 [ 54.  84. 123.  48. 354.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.170 | Acc: 95.000% | Wgt Acc: 95.250%
	I - Batch: 100 | Loss: 0.161 | Acc: 95.375% | Wgt Acc: 95.759%
	I - Batch: 150 | Loss: 0.163 | Acc: 95.125% | Wgt Acc: 95.772%
	I - Batch: 200 | Loss: 0.154 | Acc: 95.469% | Wgt Acc: 96.041%
	I - Batch: 250 | Loss: 0.158 | Acc: 95.125% | Wgt Acc: 95.813%
	I - Batch: 300 | Loss: 0.153 | Acc: 95.333% | Wgt Acc: 96.070%
	I - Batch: 350 | Loss: 0.153 | Acc: 95.214% | Wgt Acc: 95.944%
I - num batch: 364
I - Train -- Loss: 0.153 | Acc: 95.236% | Wgt Acc: 95.956% | LR: 1.250000e-04 | Dur: 225.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    0.    0.    8.   59.]
 [   0.  654.    8.    3.    8.]
 [   0.   11.  949.    1.   59.]
 [   8.    2.    2.  685.   45.]
 [  26.    1.   15.   21. 2592.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.887 | Acc: 54.500% | Wgt Acc: 49.975%
I - num batch: 87
I - Val -- Loss: 1.862 | Acc: 56.034% | Wgt Acc: 50.304% | Dur: 41.84s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   5.  16.  40.  29.]
 [  2. 102.  22.   4.  10.]
 [  5.  47. 124.   9.  24.]
 [ 36.  36.  24. 107.  40.]
 [ 37.  78. 104.  44. 328.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.143 | Acc: 95.750% | Wgt Acc: 96.192%
	I - Batch: 100 | Loss: 0.154 | Acc: 95.750% | Wgt Acc: 95.986%
	I - Batch: 150 | Loss: 0.159 | Acc: 95.125% | Wgt Acc: 95.540%
	I - Batch: 200 | Loss: 0.159 | Acc: 95.000% | Wgt Acc: 95.516%
	I - Batch: 250 | Loss: 0.167 | Acc: 94.800% | Wgt Acc: 95.392%
	I - Batch: 300 | Loss: 0.166 | Acc: 94.854% | Wgt Acc: 95.567%
	I - Batch: 350 | Loss: 0.162 | Acc: 95.071% | Wgt Acc: 95.756%
I - num batch: 364
I - Train -- Loss: 0.162 | Acc: 95.047% | Wgt Acc: 95.682% | LR: 1.250000e-04 | Dur: 225.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 655.    0.    0.   10.   53.]
 [   0.  650.   10.    4.   14.]
 [   0.    9.  944.    0.   55.]
 [   8.    1.    1.  687.   50.]
 [  29.    8.   19.   17. 2591.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.934 | Acc: 52.250% | Wgt Acc: 47.752%
I - num batch: 87
I - Val -- Loss: 1.822 | Acc: 55.460% | Wgt Acc: 49.120% | Dur: 41.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 85.   1.   4.  25.  14.]
 [  0. 114.  26.   5.  11.]
 [  2.  32. 110.   3.  24.]
 [ 60.  42.  28. 123.  42.]
 [ 52.  79. 122.  48. 340.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.151 | Acc: 95.750% | Wgt Acc: 96.131%
	I - Batch: 100 | Loss: 0.156 | Acc: 95.438% | Wgt Acc: 95.797%
	I - Batch: 150 | Loss: 0.151 | Acc: 95.458% | Wgt Acc: 96.092%
	I - Batch: 200 | Loss: 0.157 | Acc: 95.094% | Wgt Acc: 95.752%
	I - Batch: 250 | Loss: 0.158 | Acc: 94.975% | Wgt Acc: 95.639%
	I - Batch: 300 | Loss: 0.149 | Acc: 95.292% | Wgt Acc: 95.980%
	I - Batch: 350 | Loss: 0.149 | Acc: 95.304% | Wgt Acc: 95.984%
I - num batch: 364
I - Train -- Loss: 0.150 | Acc: 95.305% | Wgt Acc: 95.964% | LR: 1.250000e-04 | Dur: 225.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    0.    0.    9.   67.]
 [   1.  653.    5.    1.   11.]
 [   0.    8.  951.    0.   51.]
 [   8.    1.    0.  688.   36.]
 [  31.    6.   18.   20. 2598.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.844 | Acc: 53.875% | Wgt Acc: 50.294%
I - num batch: 87
I - Val -- Loss: 1.815 | Acc: 55.747% | Wgt Acc: 50.493% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   1.   7.  27.  14.]
 [  5. 128.  34.  15.  21.]
 [  7.  46. 125.   9.  36.]
 [ 47.  27.  26.  98.  32.]
 [ 43.  66.  98.  55. 328.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.167 | Acc: 95.375% | Wgt Acc: 95.420%
	I - Batch: 100 | Loss: 0.158 | Acc: 95.938% | Wgt Acc: 96.215%
	I - Batch: 150 | Loss: 0.156 | Acc: 95.542% | Wgt Acc: 96.037%
	I - Batch: 200 | Loss: 0.163 | Acc: 95.094% | Wgt Acc: 95.783%
	I - Batch: 250 | Loss: 0.162 | Acc: 95.275% | Wgt Acc: 95.853%
	I - Batch: 300 | Loss: 0.158 | Acc: 95.354% | Wgt Acc: 95.963%
	I - Batch: 350 | Loss: 0.155 | Acc: 95.464% | Wgt Acc: 96.084%
I - num batch: 364
I - Train -- Loss: 0.155 | Acc: 95.460% | Wgt Acc: 96.078% | LR: 1.250000e-04 | Dur: 225.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 652.    1.    0.   12.   62.]
 [   0.  658.    5.    1.    8.]
 [   1.    6.  954.    0.   49.]
 [  10.    1.    0.  680.   37.]
 [  29.    2.   15.   25. 2607.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.151 | Acc: 49.750% | Wgt Acc: 43.801%
I - num batch: 87
I - Val -- Loss: 2.034 | Acc: 53.089% | Wgt Acc: 45.238% | Dur: 41.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 86.   0.   9.  22.  13.]
 [  0.  77.   6.   2.   5.]
 [  5.  67. 116.   8.  28.]
 [ 50.  33.  17. 109.  34.]
 [ 58.  91. 142.  63. 351.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.131 | Acc: 96.375% | Wgt Acc: 96.827%
	I - Batch: 100 | Loss: 0.128 | Acc: 96.812% | Wgt Acc: 97.157%
	I - Batch: 150 | Loss: 0.131 | Acc: 96.292% | Wgt Acc: 96.795%
	I - Batch: 200 | Loss: 0.130 | Acc: 96.469% | Wgt Acc: 96.970%
	I - Batch: 250 | Loss: 0.131 | Acc: 96.400% | Wgt Acc: 96.857%
	I - Batch: 300 | Loss: 0.133 | Acc: 96.271% | Wgt Acc: 96.721%
	I - Batch: 350 | Loss: 0.133 | Acc: 96.107% | Wgt Acc: 96.656%
I - num batch: 364
I - Train -- Loss: 0.133 | Acc: 96.113% | Wgt Acc: 96.641% | LR: 1.250000e-04 | Dur: 226.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    0.    6.   55.]
 [   0.  655.   10.    1.    6.]
 [   0.    8.  953.    0.   49.]
 [   7.    1.    0.  693.   26.]
 [  24.    4.   11.   18. 2627.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.985 | Acc: 52.750% | Wgt Acc: 48.193%
I - num batch: 87
I - Val -- Loss: 1.913 | Acc: 55.388% | Wgt Acc: 49.015% | Dur: 41.86s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   6.  13.  51.  23.]
 [  0.  92.  17.   5.  11.]
 [  4.  68. 136.   9.  41.]
 [ 23.  25.  21.  79.  18.]
 [ 46.  77. 103.  60. 338.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.121 | Acc: 96.250% | Wgt Acc: 96.807%
	I - Batch: 100 | Loss: 0.137 | Acc: 96.000% | Wgt Acc: 96.606%
	I - Batch: 150 | Loss: 0.142 | Acc: 95.625% | Wgt Acc: 96.218%
	I - Batch: 200 | Loss: 0.147 | Acc: 95.469% | Wgt Acc: 96.094%
	I - Batch: 250 | Loss: 0.143 | Acc: 95.675% | Wgt Acc: 96.359%
	I - Batch: 300 | Loss: 0.140 | Acc: 95.938% | Wgt Acc: 96.511%
	I - Batch: 350 | Loss: 0.137 | Acc: 96.107% | Wgt Acc: 96.657%
I - num batch: 364
I - Train -- Loss: 0.139 | Acc: 96.096% | Wgt Acc: 96.604% | LR: 1.250000e-04 | Dur: 226.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    0.    0.   10.   53.]
 [   0.  657.    6.    1.    4.]
 [   0.    6.  954.    0.   42.]
 [   8.    1.    1.  685.   35.]
 [  21.    4.   13.   22. 2629.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.221 | Acc: 50.625% | Wgt Acc: 43.605%
I - num batch: 87
I - Val -- Loss: 2.115 | Acc: 54.741% | Wgt Acc: 45.842% | Dur: 41.94s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   4.  10.  22.  14.]
 [  0.  84.  17.   5.   8.]
 [  4.  43. 108.   8.  15.]
 [ 33.  29.  13.  89.  17.]
 [ 58. 108. 142.  80. 377.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.167 | Acc: 94.125% | Wgt Acc: 95.310%
	I - Batch: 100 | Loss: 0.168 | Acc: 94.438% | Wgt Acc: 95.154%
	I - Batch: 150 | Loss: 0.158 | Acc: 94.875% | Wgt Acc: 95.700%
	I - Batch: 200 | Loss: 0.160 | Acc: 94.625% | Wgt Acc: 95.387%
	I - Batch: 250 | Loss: 0.164 | Acc: 94.375% | Wgt Acc: 95.231%
	I - Batch: 300 | Loss: 0.160 | Acc: 94.625% | Wgt Acc: 95.387%
	I - Batch: 350 | Loss: 0.155 | Acc: 94.857% | Wgt Acc: 95.609%
I - num batch: 364
I - Train -- Loss: 0.155 | Acc: 94.824% | Wgt Acc: 95.592% | LR: 1.250000e-04 | Dur: 226.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 654.    0.    0.   10.   68.]
 [   0.  651.    6.    5.    8.]
 [   0.   11.  949.    0.   61.]
 [  10.    3.    0.  682.   48.]
 [  28.    3.   19.   21. 2578.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.039 | Acc: 53.625% | Wgt Acc: 47.635%
I - num batch: 87
I - Val -- Loss: 1.961 | Acc: 56.825% | Wgt Acc: 49.073% | Dur: 42.44s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   6.   8.  43.  19.]
 [  0.  95.  10.   2.   8.]
 [  2.  44. 113.   8.  19.]
 [ 26.  34.  20.  94.  20.]
 [ 47.  89. 139.  57. 365.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.121 | Acc: 97.250% | Wgt Acc: 97.345%
	I - Batch: 100 | Loss: 0.128 | Acc: 96.250% | Wgt Acc: 96.968%
	I - Batch: 150 | Loss: 0.137 | Acc: 96.000% | Wgt Acc: 96.563%
	I - Batch: 200 | Loss: 0.135 | Acc: 96.031% | Wgt Acc: 96.601%
	I - Batch: 250 | Loss: 0.134 | Acc: 96.000% | Wgt Acc: 96.639%
	I - Batch: 300 | Loss: 0.141 | Acc: 95.646% | Wgt Acc: 96.343%
	I - Batch: 350 | Loss: 0.144 | Acc: 95.643% | Wgt Acc: 96.289%
I - num batch: 364
I - Train -- Loss: 0.146 | Acc: 95.494% | Wgt Acc: 96.217% | LR: 1.250000e-04 | Dur: 227.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 657.    0.    0.    7.   65.]
 [   0.  656.    6.    3.    6.]
 [   0.    6.  947.    1.   64.]
 [  12.    4.    0.  695.   30.]
 [  23.    2.   21.   12. 2598.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.992 | Acc: 55.375% | Wgt Acc: 50.466%
I - num batch: 87
I - Val -- Loss: 1.908 | Acc: 57.184% | Wgt Acc: 51.190% | Dur: 41.93s
I - Confusion Matrix: [row->prediction - col->label]
[[148.   5.  15.  54.  37.]
 [  0.  98.  16.   7.   8.]
 [  4.  57. 147.   6.  32.]
 [  8.  20.  11.  63.  14.]
 [ 39.  88. 101.  74. 340.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.136 | Acc: 95.375% | Wgt Acc: 96.065%
	I - Batch: 100 | Loss: 0.133 | Acc: 95.688% | Wgt Acc: 96.098%
	I - Batch: 150 | Loss: 0.136 | Acc: 95.458% | Wgt Acc: 96.103%
	I - Batch: 200 | Loss: 0.140 | Acc: 95.625% | Wgt Acc: 96.161%
	I - Batch: 250 | Loss: 0.141 | Acc: 95.475% | Wgt Acc: 96.141%
	I - Batch: 300 | Loss: 0.137 | Acc: 95.812% | Wgt Acc: 96.405%
	I - Batch: 350 | Loss: 0.137 | Acc: 95.732% | Wgt Acc: 96.336%
I - num batch: 364
I - Train -- Loss: 0.136 | Acc: 95.787% | Wgt Acc: 96.392% | LR: 1.250000e-04 | Dur: 226.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    0.    0.    7.   57.]
 [   0.  658.    6.    3.   13.]
 [   0.    6.  948.    0.   55.]
 [   7.    0.    0.  694.   24.]
 [  29.    4.   20.   14. 2614.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.922 | Acc: 53.000% | Wgt Acc: 49.001%
I - num batch: 87
I - Val -- Loss: 1.847 | Acc: 56.034% | Wgt Acc: 50.675% | Dur: 42.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 90.   0.   3.  30.   9.]
 [  1. 108.  17.   6.  14.]
 [  8.  84. 172.  22.  62.]
 [ 27.   9.   8.  76.  12.]
 [ 73.  67.  90.  70. 334.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.118 | Acc: 96.500% | Wgt Acc: 96.895%
	I - Batch: 100 | Loss: 0.108 | Acc: 96.688% | Wgt Acc: 97.326%
	I - Batch: 150 | Loss: 0.119 | Acc: 96.292% | Wgt Acc: 96.959%
	I - Batch: 200 | Loss: 0.125 | Acc: 95.969% | Wgt Acc: 96.724%
	I - Batch: 250 | Loss: 0.126 | Acc: 95.925% | Wgt Acc: 96.632%
	I - Batch: 300 | Loss: 0.135 | Acc: 95.604% | Wgt Acc: 96.304%
	I - Batch: 350 | Loss: 0.135 | Acc: 95.571% | Wgt Acc: 96.302%
I - num batch: 364
I - Train -- Loss: 0.141 | Acc: 95.529% | Wgt Acc: 96.217% | LR: 1.250000e-04 | Dur: 228.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 659.    0.    0.    8.   59.]
 [   0.  657.    5.    3.    8.]
 [   0.    9.  953.    0.   53.]
 [   9.    1.    2.  683.   40.]
 [  24.    1.   14.   24. 2603.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.082 | Acc: 51.750% | Wgt Acc: 46.275%
I - num batch: 87
I - Val -- Loss: 1.997 | Acc: 55.675% | Wgt Acc: 47.900% | Dur: 42.59s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   7.  12.  35.  16.]
 [  0. 101.  18.   7.  12.]
 [  3.  30. 114.   7.  20.]
 [ 30.  27.  16.  84.  18.]
 [ 55. 103. 130.  71. 365.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 0.134 | Acc: 95.750% | Wgt Acc: 96.488%
	I - Batch: 100 | Loss: 0.138 | Acc: 95.500% | Wgt Acc: 96.249%
	I - Batch: 150 | Loss: 0.139 | Acc: 95.583% | Wgt Acc: 96.175%
	I - Batch: 200 | Loss: 0.138 | Acc: 95.562% | Wgt Acc: 96.277%
	I - Batch: 250 | Loss: 0.135 | Acc: 95.625% | Wgt Acc: 96.273%
	I - Batch: 300 | Loss: 0.139 | Acc: 95.417% | Wgt Acc: 96.052%
	I - Batch: 350 | Loss: 0.138 | Acc: 95.411% | Wgt Acc: 96.077%
I - num batch: 364
I - Train -- Loss: 0.137 | Acc: 95.477% | Wgt Acc: 96.134% | LR: 1.250000e-04 | Dur: 228.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    0.    0.    5.   58.]
 [   0.  654.    6.    2.    4.]
 [   0.    7.  945.    0.   69.]
 [   8.    3.    1.  696.   31.]
 [  28.    4.   22.   15. 2601.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.313 | Acc: 46.750% | Wgt Acc: 40.303%
I - num batch: 87
I - Val -- Loss: 2.174 | Acc: 51.796% | Wgt Acc: 43.148% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 84.   3.   7.  15.  14.]
 [  0.  95.  22.   7.  15.]
 [  4.  20.  71.   3.  11.]
 [ 57.  26.  27. 111.  31.]
 [ 54. 124. 163.  68. 360.]]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 0.141 | Acc: 95.375% | Wgt Acc: 96.125%
	I - Batch: 100 | Loss: 0.129 | Acc: 96.000% | Wgt Acc: 96.632%
	I - Batch: 150 | Loss: 0.125 | Acc: 96.333% | Wgt Acc: 96.805%
	I - Batch: 200 | Loss: 0.125 | Acc: 96.375% | Wgt Acc: 96.856%
	I - Batch: 250 | Loss: 0.122 | Acc: 96.600% | Wgt Acc: 96.988%
	I - Batch: 300 | Loss: 0.127 | Acc: 96.312% | Wgt Acc: 96.769%
	I - Batch: 350 | Loss: 0.134 | Acc: 95.982% | Wgt Acc: 96.501%
I - num batch: 364
I - Train -- Loss: 0.140 | Acc: 95.787% | Wgt Acc: 96.265% | LR: 1.250000e-04 | Dur: 228.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    0.    0.    7.   50.]
 [   0.  651.    7.    4.    6.]
 [   0.   12.  951.    1.   49.]
 [   4.    4.    0.  691.   37.]
 [  32.    1.   16.   15. 2621.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.128 | Acc: 53.250% | Wgt Acc: 48.193%
I - num batch: 87
I - Val -- Loss: 2.041 | Acc: 56.178% | Wgt Acc: 49.599% | Dur: 42.48s
I - Confusion Matrix: [row->prediction - col->label]
[[145.  11.  19.  53.  34.]
 [  2.  86.  12.   5.   8.]
 [  2.  53. 128.   9.  34.]
 [ 19.  25.  15.  83.  15.]
 [ 31.  93. 116.  54. 340.]]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 0.142 | Acc: 94.750% | Wgt Acc: 95.749%
	I - Batch: 100 | Loss: 0.132 | Acc: 95.438% | Wgt Acc: 96.289%
	I - Batch: 150 | Loss: 0.130 | Acc: 95.750% | Wgt Acc: 96.413%
	I - Batch: 200 | Loss: 0.128 | Acc: 95.938% | Wgt Acc: 96.577%
	I - Batch: 250 | Loss: 0.125 | Acc: 96.150% | Wgt Acc: 96.726%
	I - Batch: 300 | Loss: 0.122 | Acc: 96.375% | Wgt Acc: 96.907%
	I - Batch: 350 | Loss: 0.121 | Acc: 96.429% | Wgt Acc: 96.924%
I - num batch: 364
I - Train -- Loss: 0.122 | Acc: 96.371% | Wgt Acc: 96.840% | LR: 1.250000e-04 | Dur: 230.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    0.    0.    5.   51.]
 [   0.  654.    8.    1.   10.]
 [   0.   11.  950.    1.   35.]
 [   6.    1.    1.  702.   31.]
 [  24.    2.   15.    9. 2636.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.450 | Acc: 48.500% | Wgt Acc: 41.577%
I - num batch: 87
I - Val -- Loss: 2.287 | Acc: 54.095% | Wgt Acc: 44.135% | Dur: 43.10s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   2.   9.  20.   8.]
 [  0.  54.   6.   1.   4.]
 [  4.  60. 126.   6.  23.]
 [ 23.  10.  13.  83.   7.]
 [ 71. 142. 136.  94. 389.]]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 95.750% | Wgt Acc: 96.428%
	I - Batch: 100 | Loss: 0.123 | Acc: 96.312% | Wgt Acc: 96.978%
	I - Batch: 150 | Loss: 0.114 | Acc: 96.708% | Wgt Acc: 97.290%
	I - Batch: 200 | Loss: 0.125 | Acc: 96.312% | Wgt Acc: 96.911%
	I - Batch: 250 | Loss: 0.133 | Acc: 95.875% | Wgt Acc: 96.543%
	I - Batch: 300 | Loss: 0.138 | Acc: 95.729% | Wgt Acc: 96.416%
	I - Batch: 350 | Loss: 0.132 | Acc: 95.911% | Wgt Acc: 96.597%
I - num batch: 364
I - Train -- Loss: 0.131 | Acc: 95.993% | Wgt Acc: 96.637% | LR: 1.250000e-04 | Dur: 230.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 660.    0.    0.    6.   51.]
 [   0.  656.    5.    3.   11.]
 [   0.   10.  956.    0.   44.]
 [  10.    0.    0.  693.   40.]
 [  22.    2.   13.   16. 2617.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.411 | Acc: 47.250% | Wgt Acc: 40.940%
I - num batch: 87
I - Val -- Loss: 2.219 | Acc: 53.089% | Wgt Acc: 44.626% | Dur: 43.13s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   9.  11.  66.  24.]
 [  1.  67.   5.   2.   6.]
 [  3.  73. 132.   8.  29.]
 [ 12.  22.   9.  45.   9.]
 [ 51.  97. 133.  83. 363.]]

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 0.136 | Acc: 96.125% | Wgt Acc: 96.977%
	I - Batch: 100 | Loss: 0.127 | Acc: 96.750% | Wgt Acc: 97.367%
	I - Batch: 150 | Loss: 0.127 | Acc: 96.292% | Wgt Acc: 96.947%
	I - Batch: 200 | Loss: 0.135 | Acc: 95.906% | Wgt Acc: 96.636%
	I - Batch: 250 | Loss: 0.133 | Acc: 95.950% | Wgt Acc: 96.607%
	I - Batch: 300 | Loss: 0.132 | Acc: 95.938% | Wgt Acc: 96.624%
	I - Batch: 350 | Loss: 0.134 | Acc: 95.839% | Wgt Acc: 96.474%
I - num batch: 364
I - Train -- Loss: 0.133 | Acc: 95.890% | Wgt Acc: 96.544% | LR: 1.250000e-04 | Dur: 230.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    9.   49.]
 [   0.  658.    4.    7.    9.]
 [   0.    3.  953.    0.   55.]
 [   8.    5.    0.  685.   36.]
 [  18.    2.   17.   17. 2614.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.208 | Acc: 49.125% | Wgt Acc: 43.494%
I - num batch: 87
I - Val -- Loss: 2.037 | Acc: 54.167% | Wgt Acc: 46.604% | Dur: 43.23s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   5.  11.  32.   9.]
 [  1.  76.  16.   7.  13.]
 [  5.  81. 126.   8.  41.]
 [ 33.  28.  14.  94.  18.]
 [ 52.  78. 123.  63. 350.]]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 0.127 | Acc: 96.250% | Wgt Acc: 96.969%
	I - Batch: 100 | Loss: 0.142 | Acc: 95.375% | Wgt Acc: 95.849%
	I - Batch: 150 | Loss: 0.143 | Acc: 95.625% | Wgt Acc: 95.864%
	I - Batch: 200 | Loss: 0.139 | Acc: 95.875% | Wgt Acc: 96.197%
	I - Batch: 250 | Loss: 0.138 | Acc: 95.900% | Wgt Acc: 96.179%
	I - Batch: 300 | Loss: 0.133 | Acc: 96.083% | Wgt Acc: 96.372%
	I - Batch: 350 | Loss: 0.141 | Acc: 95.929% | Wgt Acc: 96.158%
I - num batch: 364
I - Train -- Loss: 0.144 | Acc: 95.701% | Wgt Acc: 96.019% | LR: 1.250000e-04 | Dur: 227.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 662.    0.    0.    9.   36.]
 [   0.  650.   13.    2.   12.]
 [   0.   13.  942.    0.   45.]
 [   7.    2.    0.  683.   42.]
 [  23.    3.   19.   24. 2628.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.896 | Acc: 52.125% | Wgt Acc: 49.994%
I - num batch: 87
I - Val -- Loss: 1.852 | Acc: 53.879% | Wgt Acc: 50.757% | Dur: 42.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 75.   5.   9.  14.  18.]
 [  2. 106.  19.   4.  17.]
 [  5.  44. 141.   7.  40.]
 [ 99.  57.  40. 152.  80.]
 [ 18.  56.  81.  27. 276.]]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 0.154 | Acc: 94.500% | Wgt Acc: 95.351%
	I - Batch: 100 | Loss: 0.128 | Acc: 96.062% | Wgt Acc: 96.681%
	I - Batch: 150 | Loss: 0.118 | Acc: 96.333% | Wgt Acc: 97.039%
	I - Batch: 200 | Loss: 0.124 | Acc: 95.938% | Wgt Acc: 96.554%
	I - Batch: 250 | Loss: 0.121 | Acc: 96.225% | Wgt Acc: 96.763%
	I - Batch: 300 | Loss: 0.118 | Acc: 96.271% | Wgt Acc: 96.866%
	I - Batch: 350 | Loss: 0.119 | Acc: 96.268% | Wgt Acc: 96.849%
I - num batch: 364
I - Train -- Loss: 0.119 | Acc: 96.217% | Wgt Acc: 96.852% | LR: 1.250000e-04 | Dur: 226.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    0.    5.   53.]
 [   0.  656.    2.    2.   12.]
 [   0.    5.  957.    0.   52.]
 [   8.    5.    0.  698.   23.]
 [  23.    2.   15.   13. 2623.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.120 | Acc: 51.125% | Wgt Acc: 45.246%
I - num batch: 87
I - Val -- Loss: 2.045 | Acc: 55.029% | Wgt Acc: 47.130% | Dur: 42.20s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   3.  12.  32.  12.]
 [  1.  81.  11.   2.   9.]
 [  3.  54. 131.  11.  29.]
 [ 34.  35.  14.  85.  19.]
 [ 54.  95. 122.  74. 362.]]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 0.122 | Acc: 95.875% | Wgt Acc: 96.653%
	I - Batch: 100 | Loss: 0.115 | Acc: 96.625% | Wgt Acc: 97.064%
	I - Batch: 150 | Loss: 0.107 | Acc: 96.792% | Wgt Acc: 97.268%
	I - Batch: 200 | Loss: 0.111 | Acc: 96.500% | Wgt Acc: 97.079%
	I - Batch: 250 | Loss: 0.113 | Acc: 96.475% | Wgt Acc: 97.050%
	I - Batch: 300 | Loss: 0.116 | Acc: 96.521% | Wgt Acc: 97.056%
	I - Batch: 350 | Loss: 0.116 | Acc: 96.429% | Wgt Acc: 96.997%
I - num batch: 364
I - Train -- Loss: 0.115 | Acc: 96.475% | Wgt Acc: 97.029% | LR: 1.250000e-04 | Dur: 226.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    0.    0.    4.   45.]
 [   0.  657.    3.    2.   10.]
 [   0.    5.  957.    0.   47.]
 [   6.    3.    0.  697.   26.]
 [  22.    3.   14.   15. 2635.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.941 | Acc: 53.500% | Wgt Acc: 48.346%
I - num batch: 87
I - Val -- Loss: 1.886 | Acc: 56.753% | Wgt Acc: 50.045% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   3.   8.  29.  16.]
 [  0. 117.  24.   5.  12.]
 [  3.  46. 115.   6.  18.]
 [ 45.  30.  29. 105.  32.]
 [ 51.  72. 114.  59. 353.]]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 0.117 | Acc: 96.500% | Wgt Acc: 96.593%
	I - Batch: 100 | Loss: 0.109 | Acc: 97.000% | Wgt Acc: 97.481%
	I - Batch: 150 | Loss: 0.118 | Acc: 96.333% | Wgt Acc: 97.005%
	I - Batch: 200 | Loss: 0.117 | Acc: 96.312% | Wgt Acc: 96.990%
	I - Batch: 250 | Loss: 0.116 | Acc: 96.325% | Wgt Acc: 97.046%
	I - Batch: 300 | Loss: 0.110 | Acc: 96.667% | Wgt Acc: 97.328%
	I - Batch: 350 | Loss: 0.107 | Acc: 96.786% | Wgt Acc: 97.440%
I - num batch: 364
I - Train -- Loss: 0.107 | Acc: 96.801% | Wgt Acc: 97.445% | LR: 1.250000e-04 | Dur: 226.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    6.   47.]
 [   0.  659.    1.    3.   10.]
 [   0.    2.  962.    0.   42.]
 [   3.    3.    0.  701.   26.]
 [  20.    4.   11.    8. 2638.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.941 | Acc: 55.500% | Wgt Acc: 51.905%
I - num batch: 87
I - Val -- Loss: 1.886 | Acc: 57.615% | Wgt Acc: 52.781% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[146.  10.  18.  62.  39.]
 [  4. 110.  20.   5.  12.]
 [  3.  43. 144.   7.  30.]
 [ 19.  35.  14.  80.  28.]
 [ 27.  70.  94.  50. 322.]]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 0.104 | Acc: 97.125% | Wgt Acc: 97.707%
	I - Batch: 100 | Loss: 0.108 | Acc: 96.875% | Wgt Acc: 97.491%
	I - Batch: 150 | Loss: 0.108 | Acc: 97.042% | Wgt Acc: 97.569%
	I - Batch: 200 | Loss: 0.107 | Acc: 96.906% | Wgt Acc: 97.473%
	I - Batch: 250 | Loss: 0.115 | Acc: 96.525% | Wgt Acc: 97.068%
	I - Batch: 300 | Loss: 0.110 | Acc: 96.708% | Wgt Acc: 97.243%
	I - Batch: 350 | Loss: 0.106 | Acc: 96.929% | Wgt Acc: 97.425%
I - num batch: 364
I - Train -- Loss: 0.105 | Acc: 96.956% | Wgt Acc: 97.455% | LR: 1.250000e-04 | Dur: 226.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    4.   43.]
 [   0.  661.    5.    2.    9.]
 [   0.    4.  955.    1.   40.]
 [   6.    0.    0.  701.   20.]
 [  16.    3.   14.   10. 2651.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.211 | Acc: 51.375% | Wgt Acc: 45.896%
I - num batch: 87
I - Val -- Loss: 2.112 | Acc: 55.603% | Wgt Acc: 47.552% | Dur: 42.03s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   5.  10.  31.  20.]
 [  0.  82.   3.   3.   5.]
 [  2.  60. 127.  11.  26.]
 [ 35.  21.   9.  86.  14.]
 [ 49. 100. 141.  73. 366.]]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 0.080 | Acc: 97.500% | Wgt Acc: 98.316%
	I - Batch: 100 | Loss: 0.084 | Acc: 97.812% | Wgt Acc: 98.291%
	I - Batch: 150 | Loss: 0.090 | Acc: 97.667% | Wgt Acc: 98.118%
	I - Batch: 200 | Loss: 0.091 | Acc: 97.531% | Wgt Acc: 98.034%
	I - Batch: 250 | Loss: 0.091 | Acc: 97.550% | Wgt Acc: 98.048%
	I - Batch: 300 | Loss: 0.098 | Acc: 97.146% | Wgt Acc: 97.719%
	I - Batch: 350 | Loss: 0.103 | Acc: 96.911% | Wgt Acc: 97.516%
I - num batch: 364
I - Train -- Loss: 0.105 | Acc: 96.819% | Wgt Acc: 97.443% | LR: 1.250000e-04 | Dur: 228.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 665.    0.    0.    7.   46.]
 [   0.  664.    1.    2.    4.]
 [   0.    1.  959.    1.   44.]
 [   8.    1.    0.  701.   28.]
 [  19.    2.   14.    7. 2641.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.034 | Acc: 54.375% | Wgt Acc: 49.259%
I - num batch: 87
I - Val -- Loss: 1.951 | Acc: 58.836% | Wgt Acc: 51.995% | Dur: 42.33s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   7.   6.  31.   8.]
 [  4. 101.  12.   5.  13.]
 [  3.  61. 150.  12.  31.]
 [ 27.  30.  12.  97.  16.]
 [ 57.  69. 110.  59. 363.]]

I - Local maximum validation set accuracy:  58.84

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 0.133 | Acc: 95.625% | Wgt Acc: 96.166%
	I - Batch: 100 | Loss: 0.113 | Acc: 96.188% | Wgt Acc: 96.767%
	I - Batch: 150 | Loss: 0.103 | Acc: 96.792% | Wgt Acc: 97.220%
	I - Batch: 200 | Loss: 0.108 | Acc: 96.625% | Wgt Acc: 97.120%
	I - Batch: 250 | Loss: 0.103 | Acc: 96.800% | Wgt Acc: 97.301%
	I - Batch: 300 | Loss: 0.107 | Acc: 96.667% | Wgt Acc: 97.228%
	I - Batch: 350 | Loss: 0.110 | Acc: 96.536% | Wgt Acc: 97.050%
I - num batch: 364
I - Train -- Loss: 0.111 | Acc: 96.440% | Wgt Acc: 97.000% | LR: 1.250000e-04 | Dur: 227.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    6.   49.]
 [   0.  659.    9.    0.   14.]
 [   0.    2.  950.    0.   43.]
 [   3.    2.    1.  700.   24.]
 [  23.    5.   14.   12. 2633.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.118 | Acc: 52.625% | Wgt Acc: 47.139%
I - num batch: 87
I - Val -- Loss: 2.064 | Acc: 55.244% | Wgt Acc: 47.893% | Dur: 42.30s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   6.  11.  27.  16.]
 [  0.  83.   9.   9.   8.]
 [  4.  59. 129.  13.  27.]
 [ 40.  37.  20. 100.  28.]
 [ 50.  83. 121.  55. 352.]]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 0.115 | Acc: 96.750% | Wgt Acc: 97.229%
	I - Batch: 100 | Loss: 0.118 | Acc: 96.438% | Wgt Acc: 97.022%
	I - Batch: 150 | Loss: 0.126 | Acc: 96.167% | Wgt Acc: 96.686%
	I - Batch: 200 | Loss: 0.124 | Acc: 96.094% | Wgt Acc: 96.743%
	I - Batch: 250 | Loss: 0.126 | Acc: 96.025% | Wgt Acc: 96.672%
	I - Batch: 300 | Loss: 0.122 | Acc: 96.292% | Wgt Acc: 96.904%
	I - Batch: 350 | Loss: 0.122 | Acc: 96.321% | Wgt Acc: 96.888%
I - num batch: 364
I - Train -- Loss: 0.123 | Acc: 96.268% | Wgt Acc: 96.814% | LR: 1.250000e-04 | Dur: 228.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    0.    0.    3.   50.]
 [   0.  655.    7.    0.   11.]
 [   0.    7.  952.    0.   42.]
 [  10.    2.    1.  699.   31.]
 [  19.    4.   14.   16. 2629.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.087 | Acc: 48.375% | Wgt Acc: 42.508%
I - num batch: 87
I - Val -- Loss: 2.055 | Acc: 52.443% | Wgt Acc: 44.332% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 78.   1.  10.  15.   6.]
 [  4. 108.  45.  14.  19.]
 [  3.  46.  97.   8.  32.]
 [ 43.  25.  12.  85.  12.]
 [ 71.  88. 126.  82. 362.]]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 0.116 | Acc: 96.000% | Wgt Acc: 96.566%
	I - Batch: 100 | Loss: 0.124 | Acc: 95.625% | Wgt Acc: 96.359%
	I - Batch: 150 | Loss: 0.119 | Acc: 95.917% | Wgt Acc: 96.672%
	I - Batch: 200 | Loss: 0.117 | Acc: 96.094% | Wgt Acc: 96.711%
	I - Batch: 250 | Loss: 0.119 | Acc: 96.000% | Wgt Acc: 96.602%
	I - Batch: 300 | Loss: 0.116 | Acc: 96.188% | Wgt Acc: 96.724%
	I - Batch: 350 | Loss: 0.117 | Acc: 96.196% | Wgt Acc: 96.782%
I - num batch: 364
I - Train -- Loss: 0.118 | Acc: 96.199% | Wgt Acc: 96.777% | LR: 1.250000e-04 | Dur: 229.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    4.   47.]
 [   0.  659.    8.    2.    9.]
 [   0.    7.  949.    0.   43.]
 [   1.    0.    0.  694.   38.]
 [  25.    2.   17.   18. 2626.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.148 | Acc: 52.375% | Wgt Acc: 46.710%
I - num batch: 87
I - Val -- Loss: 2.040 | Acc: 54.885% | Wgt Acc: 48.787% | Dur: 42.04s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   7.  14.  33.  38.]
 [  0.  87.  17.   3.  10.]
 [  1.  32. 100.   5.  16.]
 [ 49.  61.  35. 130.  46.]
 [ 23.  81. 124.  33. 321.]]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 0.093 | Acc: 97.125% | Wgt Acc: 97.805%
	I - Batch: 100 | Loss: 0.100 | Acc: 96.562% | Wgt Acc: 97.363%
	I - Batch: 150 | Loss: 0.093 | Acc: 97.042% | Wgt Acc: 97.695%
	I - Batch: 200 | Loss: 0.094 | Acc: 96.969% | Wgt Acc: 97.681%
	I - Batch: 250 | Loss: 0.096 | Acc: 96.900% | Wgt Acc: 97.578%
	I - Batch: 300 | Loss: 0.102 | Acc: 96.792% | Wgt Acc: 97.439%
	I - Batch: 350 | Loss: 0.104 | Acc: 96.768% | Wgt Acc: 97.383%
I - num batch: 364
I - Train -- Loss: 0.109 | Acc: 96.733% | Wgt Acc: 97.303% | LR: 1.250000e-04 | Dur: 223.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    0.    5.   55.]
 [   0.  661.    7.    0.    5.]
 [   0.    5.  960.    0.   34.]
 [   8.    0.    0.  701.   27.]
 [  23.    2.    7.   12. 2642.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.315 | Acc: 49.250% | Wgt Acc: 43.206%
I - num batch: 87
I - Val -- Loss: 2.259 | Acc: 52.945% | Wgt Acc: 45.002% | Dur: 41.56s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   5.  13.  26.  16.]
 [  2.  79.   9.   3.  15.]
 [  3.  65. 115.  13.  33.]
 [ 24.  20.  10.  78.  14.]
 [ 58.  99. 143.  84. 353.]]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 0.097 | Acc: 97.500% | Wgt Acc: 98.000%
	I - Batch: 100 | Loss: 0.092 | Acc: 97.688% | Wgt Acc: 97.988%
	I - Batch: 150 | Loss: 0.090 | Acc: 97.625% | Wgt Acc: 97.880%
	I - Batch: 200 | Loss: 0.101 | Acc: 97.031% | Wgt Acc: 97.409%
	I - Batch: 250 | Loss: 0.101 | Acc: 96.950% | Wgt Acc: 97.427%
	I - Batch: 300 | Loss: 0.102 | Acc: 96.979% | Wgt Acc: 97.322%
	I - Batch: 350 | Loss: 0.102 | Acc: 97.000% | Wgt Acc: 97.283%
I - num batch: 364
I - Train -- Loss: 0.103 | Acc: 96.956% | Wgt Acc: 97.259% | LR: 1.250000e-04 | Dur: 223.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    0.    5.   42.]
 [   0.  654.    7.    3.    4.]
 [   0.   11.  954.    0.   28.]
 [   8.    1.    0.  696.   27.]
 [  12.    2.   13.   14. 2662.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.559 | Acc: 46.250% | Wgt Acc: 38.992%
I - num batch: 87
I - Val -- Loss: 2.389 | Acc: 52.945% | Wgt Acc: 42.958% | Dur: 42.03s
I - Confusion Matrix: [row->prediction - col->label]
[[135.  13.  21.  45.  24.]
 [  1.  65.   7.   3.   5.]
 [  1.  37.  88.   6.  11.]
 [ 13.  26.  10.  67.   9.]
 [ 49. 127. 164.  83. 382.]]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 96.250% | Wgt Acc: 96.669%
	I - Batch: 100 | Loss: 0.102 | Acc: 96.875% | Wgt Acc: 97.262%
	I - Batch: 150 | Loss: 0.097 | Acc: 97.125% | Wgt Acc: 97.519%
	I - Batch: 200 | Loss: 0.110 | Acc: 96.656% | Wgt Acc: 97.051%
	I - Batch: 250 | Loss: 0.117 | Acc: 96.300% | Wgt Acc: 96.761%
	I - Batch: 300 | Loss: 0.111 | Acc: 96.562% | Wgt Acc: 97.017%
	I - Batch: 350 | Loss: 0.105 | Acc: 96.786% | Wgt Acc: 97.234%
I - num batch: 364
I - Train -- Loss: 0.104 | Acc: 96.836% | Wgt Acc: 97.284% | LR: 1.250000e-04 | Dur: 226.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    0.    0.   11.   43.]
 [   0.  659.    5.    2.    5.]
 [   0.    7.  959.    0.   33.]
 [   8.    0.    1.  693.   30.]
 [  16.    2.    9.   12. 2652.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.028 | Acc: 54.500% | Wgt Acc: 49.528%
I - num batch: 87
I - Val -- Loss: 1.965 | Acc: 57.328% | Wgt Acc: 50.598% | Dur: 42.05s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   5.  10.  20.   9.]
 [  2.  99.  17.   8.   9.]
 [  3.  45. 128.   6.  34.]
 [ 50.  37.  18. 120.  28.]
 [ 44.  82. 117.  50. 351.]]

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 0.094 | Acc: 97.125% | Wgt Acc: 97.395%
	I - Batch: 100 | Loss: 0.098 | Acc: 97.000% | Wgt Acc: 97.247%
	I - Batch: 150 | Loss: 0.100 | Acc: 96.917% | Wgt Acc: 97.169%
	I - Batch: 200 | Loss: 0.102 | Acc: 96.781% | Wgt Acc: 97.109%
	I - Batch: 250 | Loss: 0.105 | Acc: 96.800% | Wgt Acc: 97.120%
	I - Batch: 300 | Loss: 0.109 | Acc: 96.667% | Wgt Acc: 97.047%
	I - Batch: 350 | Loss: 0.109 | Acc: 96.643% | Wgt Acc: 97.071%
I - num batch: 364
I - Train -- Loss: 0.110 | Acc: 96.595% | Wgt Acc: 97.048% | LR: 1.250000e-04 | Dur: 226.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    8.   39.]
 [   0.  659.    3.    3.    6.]
 [   0.    4.  954.    0.   38.]
 [   7.    1.    0.  690.   35.]
 [  16.    4.   17.   17. 2645.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.478 | Acc: 47.125% | Wgt Acc: 40.131%
I - num batch: 87
I - Val -- Loss: 2.341 | Acc: 52.802% | Wgt Acc: 43.996% | Dur: 42.15s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   5.  18.  48.  26.]
 [  0.  82.  13.   3.   7.]
 [  2.  36.  85.   6.  17.]
 [ 26.  30.  11.  83.  17.]
 [ 50. 115. 163.  64. 364.]]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 0.119 | Acc: 96.250% | Wgt Acc: 96.871%
	I - Batch: 100 | Loss: 0.111 | Acc: 96.500% | Wgt Acc: 96.953%
	I - Batch: 150 | Loss: 0.113 | Acc: 96.417% | Wgt Acc: 96.857%
	I - Batch: 200 | Loss: 0.110 | Acc: 96.625% | Wgt Acc: 97.118%
	I - Batch: 250 | Loss: 0.112 | Acc: 96.500% | Wgt Acc: 97.057%
	I - Batch: 300 | Loss: 0.118 | Acc: 96.250% | Wgt Acc: 96.799%
	I - Batch: 350 | Loss: 0.121 | Acc: 96.125% | Wgt Acc: 96.614%
I - num batch: 364
I - Train -- Loss: 0.120 | Acc: 96.165% | Wgt Acc: 96.671% | LR: 1.250000e-04 | Dur: 226.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 656.    0.    0.    7.   46.]
 [   0.  658.    4.    5.   14.]
 [   0.    5.  958.    1.   37.]
 [   6.    3.    0.  688.   34.]
 [  30.    2.   12.   17. 2632.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.811 | Acc: 55.750% | Wgt Acc: 53.467%
I - num batch: 87
I - Val -- Loss: 1.797 | Acc: 56.609% | Wgt Acc: 54.182% | Dur: 42.07s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   8.  13.  39.  27.]
 [  2. 111.  25.   6.   9.]
 [  7.  67. 153.  13.  63.]
 [ 45.  33.  36. 124.  58.]
 [ 19.  49.  63.  22. 274.]]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 0.114 | Acc: 95.875% | Wgt Acc: 96.481%
	I - Batch: 100 | Loss: 0.114 | Acc: 96.312% | Wgt Acc: 96.713%
	I - Batch: 150 | Loss: 0.115 | Acc: 96.125% | Wgt Acc: 96.651%
	I - Batch: 200 | Loss: 0.115 | Acc: 96.219% | Wgt Acc: 96.741%
	I - Batch: 250 | Loss: 0.113 | Acc: 96.325% | Wgt Acc: 96.865%
	I - Batch: 300 | Loss: 0.116 | Acc: 96.167% | Wgt Acc: 96.731%
	I - Batch: 350 | Loss: 0.113 | Acc: 96.304% | Wgt Acc: 96.931%
I - num batch: 364
I - Train -- Loss: 0.113 | Acc: 96.337% | Wgt Acc: 96.918% | LR: 1.250000e-04 | Dur: 226.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 659.    1.    0.    9.   54.]
 [   0.  656.    2.    4.   12.]
 [   0.    5.  963.    0.   38.]
 [   8.    2.    0.  693.   28.]
 [  25.    4.    9.   12. 2631.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.309 | Acc: 49.375% | Wgt Acc: 43.145%
I - num batch: 87
I - Val -- Loss: 2.178 | Acc: 53.376% | Wgt Acc: 45.304% | Dur: 42.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   2.  10.  19.  12.]
 [  0.  78.  16.   6.   6.]
 [  1.  49. 105.   9.  21.]
 [ 41.  47.  23. 111.  38.]
 [ 62.  92. 136.  59. 354.]]

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 0.085 | Acc: 97.375% | Wgt Acc: 98.057%
	I - Batch: 100 | Loss: 0.082 | Acc: 97.375% | Wgt Acc: 98.168%
	I - Batch: 150 | Loss: 0.082 | Acc: 97.625% | Wgt Acc: 98.331%
	I - Batch: 200 | Loss: 0.082 | Acc: 97.594% | Wgt Acc: 98.279%
	I - Batch: 250 | Loss: 0.082 | Acc: 97.750% | Wgt Acc: 98.311%
	I - Batch: 300 | Loss: 0.082 | Acc: 97.708% | Wgt Acc: 98.249%
	I - Batch: 350 | Loss: 0.081 | Acc: 97.661% | Wgt Acc: 98.209%
I - num batch: 364
I - Train -- Loss: 0.081 | Acc: 97.644% | Wgt Acc: 98.184% | LR: 1.250000e-04 | Dur: 226.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    0.    0.   37.]
 [   0.  664.    2.    2.    5.]
 [   0.    2.  964.    0.   34.]
 [   2.    2.    0.  703.   20.]
 [  10.    0.    8.   13. 2667.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.371 | Acc: 48.625% | Wgt Acc: 42.600%
I - num batch: 87
I - Val -- Loss: 2.289 | Acc: 53.520% | Wgt Acc: 45.029% | Dur: 42.48s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   2.   6.  32.  18.]
 [  1.  93.  11.   0.   8.]
 [  3.  36. 103.   9.  25.]
 [ 20.  16.  12.  76.  12.]
 [ 70. 121. 158.  87. 368.]]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 0.071 | Acc: 98.000% | Wgt Acc: 98.355%
	I - Batch: 100 | Loss: 0.068 | Acc: 98.312% | Wgt Acc: 98.642%
	I - Batch: 150 | Loss: 0.079 | Acc: 97.917% | Wgt Acc: 98.248%
	I - Batch: 200 | Loss: 0.086 | Acc: 97.781% | Wgt Acc: 98.099%
	I - Batch: 250 | Loss: 0.090 | Acc: 97.650% | Wgt Acc: 97.972%
	I - Batch: 300 | Loss: 0.089 | Acc: 97.688% | Wgt Acc: 98.026%
	I - Batch: 350 | Loss: 0.089 | Acc: 97.589% | Wgt Acc: 97.965%
I - num batch: 364
I - Train -- Loss: 0.089 | Acc: 97.541% | Wgt Acc: 97.914% | LR: 1.250000e-04 | Dur: 228.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    6.   33.]
 [   0.  660.    1.    0.    4.]
 [   0.    5.  964.    0.   25.]
 [   7.    2.    0.  703.   26.]
 [  15.    1.    9.    9. 2675.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.316 | Acc: 51.125% | Wgt Acc: 44.695%
I - num batch: 87
I - Val -- Loss: 2.197 | Acc: 55.675% | Wgt Acc: 47.243% | Dur: 43.20s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   3.   8.  37.  14.]
 [  0.  87.  14.   6.  10.]
 [  2.  30. 124.   7.  21.]
 [ 22.  21.   9.  69.  11.]
 [ 55. 127. 135.  85. 375.]]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 0.099 | Acc: 97.250% | Wgt Acc: 97.683%
	I - Batch: 100 | Loss: 0.094 | Acc: 96.750% | Wgt Acc: 97.278%
	I - Batch: 150 | Loss: 0.096 | Acc: 96.708% | Wgt Acc: 97.228%
	I - Batch: 200 | Loss: 0.107 | Acc: 96.188% | Wgt Acc: 96.793%
	I - Batch: 250 | Loss: 0.109 | Acc: 96.125% | Wgt Acc: 96.751%
	I - Batch: 300 | Loss: 0.108 | Acc: 96.292% | Wgt Acc: 96.815%
	I - Batch: 350 | Loss: 0.109 | Acc: 96.304% | Wgt Acc: 96.786%
I - num batch: 364
I - Train -- Loss: 0.111 | Acc: 96.285% | Wgt Acc: 96.749% | LR: 1.250000e-04 | Dur: 230.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    0.    0.   10.   35.]
 [   0.  655.    6.    4.    6.]
 [   0.    8.  951.    0.   45.]
 [   9.    3.    0.  690.   42.]
 [  15.    2.   17.   14. 2635.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.273 | Acc: 50.250% | Wgt Acc: 44.131%
I - num batch: 87
I - Val -- Loss: 2.179 | Acc: 53.879% | Wgt Acc: 45.927% | Dur: 43.24s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   5.  14.  34.  23.]
 [  0. 109.  56.   6.  19.]
 [  0.  14.  58.   4.   5.]
 [ 30.  45.  24. 104.  30.]
 [ 44.  95. 138.  56. 354.]]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 0.096 | Acc: 97.500% | Wgt Acc: 97.594%
	I - Batch: 100 | Loss: 0.097 | Acc: 96.812% | Wgt Acc: 96.953%
	I - Batch: 150 | Loss: 0.107 | Acc: 96.083% | Wgt Acc: 96.542%
	I - Batch: 200 | Loss: 0.112 | Acc: 96.031% | Wgt Acc: 96.547%
	I - Batch: 250 | Loss: 0.113 | Acc: 96.075% | Wgt Acc: 96.535%
	I - Batch: 300 | Loss: 0.112 | Acc: 96.167% | Wgt Acc: 96.652%
	I - Batch: 350 | Loss: 0.112 | Acc: 96.107% | Wgt Acc: 96.588%
I - num batch: 364
I - Train -- Loss: 0.111 | Acc: 96.131% | Wgt Acc: 96.641% | LR: 1.250000e-04 | Dur: 227.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    8.   48.]
 [   0.  655.    4.    3.    6.]
 [   1.   10.  946.    0.   57.]
 [   3.    1.    1.  693.   25.]
 [  19.    2.   23.   14. 2627.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.284 | Acc: 50.250% | Wgt Acc: 45.528%
I - num batch: 87
I - Val -- Loss: 2.152 | Acc: 54.670% | Wgt Acc: 48.063% | Dur: 42.24s
I - Confusion Matrix: [row->prediction - col->label]
[[130.  10.  27.  55.  35.]
 [  1. 119.  23.   4.  13.]
 [  2.  28.  92.   5.  18.]
 [ 24.  29.  26.  79.  24.]
 [ 42.  82. 122.  61. 341.]]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 0.109 | Acc: 96.250% | Wgt Acc: 96.770%
	I - Batch: 100 | Loss: 0.111 | Acc: 96.375% | Wgt Acc: 96.752%
	I - Batch: 150 | Loss: 0.117 | Acc: 96.125% | Wgt Acc: 96.333%
	I - Batch: 200 | Loss: 0.119 | Acc: 95.906% | Wgt Acc: 96.218%
	I - Batch: 250 | Loss: 0.116 | Acc: 96.075% | Wgt Acc: 96.455%
	I - Batch: 300 | Loss: 0.110 | Acc: 96.312% | Wgt Acc: 96.704%
	I - Batch: 350 | Loss: 0.112 | Acc: 96.304% | Wgt Acc: 96.700%
I - num batch: 364
I - Train -- Loss: 0.113 | Acc: 96.285% | Wgt Acc: 96.693% | LR: 1.250000e-04 | Dur: 226.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    8.   41.]
 [   0.  655.    6.    3.   13.]
 [   0.    8.  951.    0.   43.]
 [   8.    3.    0.  688.   27.]
 [  18.    2.   17.   19. 2639.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.416 | Acc: 46.750% | Wgt Acc: 39.837%
I - num batch: 87
I - Val -- Loss: 2.310 | Acc: 51.724% | Wgt Acc: 42.432% | Dur: 42.13s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   6.  13.  28.  14.]
 [  0.  61.  12.   2.   5.]
 [  4.  55.  99.   8.  22.]
 [ 22.  26.  22.  87.  24.]
 [ 66. 120. 144.  79. 366.]]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 97.125% | Wgt Acc: 97.565%
	I - Batch: 100 | Loss: 0.110 | Acc: 96.750% | Wgt Acc: 97.012%
	I - Batch: 150 | Loss: 0.116 | Acc: 96.500% | Wgt Acc: 96.870%
	I - Batch: 200 | Loss: 0.111 | Acc: 96.781% | Wgt Acc: 97.130%
	I - Batch: 250 | Loss: 0.105 | Acc: 97.075% | Wgt Acc: 97.402%
	I - Batch: 300 | Loss: 0.101 | Acc: 97.104% | Wgt Acc: 97.480%
	I - Batch: 350 | Loss: 0.100 | Acc: 97.125% | Wgt Acc: 97.507%
I - num batch: 364
I - Train -- Loss: 0.099 | Acc: 97.111% | Wgt Acc: 97.494% | LR: 1.250000e-04 | Dur: 226.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 665.    0.    0.   11.   35.]
 [   0.  660.    1.    3.    5.]
 [   0.    4.  962.    1.   32.]
 [   7.    4.    0.  696.   27.]
 [  20.    0.   11.    7. 2664.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.166 | Acc: 51.500% | Wgt Acc: 46.380%
I - num batch: 87
I - Val -- Loss: 2.037 | Acc: 56.394% | Wgt Acc: 49.518% | Dur: 42.12s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   3.   6.  21.  10.]
 [  0. 103.  26.   8.  15.]
 [  3.  65. 141.   7.  36.]
 [ 23.  17.   5.  77.  14.]
 [ 65.  80. 112.  91. 356.]]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 0.108 | Acc: 97.125% | Wgt Acc: 97.736%
	I - Batch: 100 | Loss: 0.090 | Acc: 97.375% | Wgt Acc: 97.935%
	I - Batch: 150 | Loss: 0.094 | Acc: 97.417% | Wgt Acc: 97.728%
	I - Batch: 200 | Loss: 0.094 | Acc: 97.219% | Wgt Acc: 97.594%
	I - Batch: 250 | Loss: 0.091 | Acc: 97.325% | Wgt Acc: 97.691%
	I - Batch: 300 | Loss: 0.094 | Acc: 97.312% | Wgt Acc: 97.634%
	I - Batch: 350 | Loss: 0.094 | Acc: 97.232% | Wgt Acc: 97.618%
I - num batch: 364
I - Train -- Loss: 0.098 | Acc: 97.145% | Wgt Acc: 97.504% | LR: 1.250000e-04 | Dur: 226.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    1.    0.    7.   40.]
 [   0.  659.    6.    1.    6.]
 [   0.    6.  957.    0.   33.]
 [   7.    0.    0.  702.   19.]
 [  19.    2.   11.    8. 2665.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.273 | Acc: 49.500% | Wgt Acc: 44.860%
I - num batch: 87
I - Val -- Loss: 2.175 | Acc: 51.940% | Wgt Acc: 46.627% | Dur: 42.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   3.  10.  12.  11.]
 [  3.  95.  38.   4.  10.]
 [  0.  22.  88.   3.  16.]
 [ 87.  82.  62. 168.  96.]
 [ 35.  66.  92.  17. 298.]]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 0.125 | Acc: 96.250% | Wgt Acc: 96.766%
	I - Batch: 100 | Loss: 0.106 | Acc: 96.688% | Wgt Acc: 97.244%
	I - Batch: 150 | Loss: 0.106 | Acc: 96.750% | Wgt Acc: 97.284%
	I - Batch: 200 | Loss: 0.105 | Acc: 96.812% | Wgt Acc: 97.334%
	I - Batch: 250 | Loss: 0.102 | Acc: 96.750% | Wgt Acc: 97.298%
	I - Batch: 300 | Loss: 0.106 | Acc: 96.542% | Wgt Acc: 97.111%
	I - Batch: 350 | Loss: 0.105 | Acc: 96.571% | Wgt Acc: 97.094%
I - num batch: 364
I - Train -- Loss: 0.105 | Acc: 96.561% | Wgt Acc: 97.101% | LR: 1.250000e-04 | Dur: 227.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.    3.   44.]
 [   1.  663.    3.    1.    4.]
 [   0.    1.  956.    1.   43.]
 [   5.    4.    0.  690.   32.]
 [  20.    0.   15.   23. 2640.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.251 | Acc: 53.125% | Wgt Acc: 46.851%
I - num batch: 87
I - Val -- Loss: 2.141 | Acc: 55.819% | Wgt Acc: 47.622% | Dur: 42.36s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   3.  12.  31.  18.]
 [  2.  83.  12.   4.   7.]
 [  3.  57. 119.   8.  19.]
 [ 32.  18.  11.  96.  19.]
 [ 51. 107. 136.  65. 368.]]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 0.080 | Acc: 97.250% | Wgt Acc: 97.937%
	I - Batch: 100 | Loss: 0.105 | Acc: 96.750% | Wgt Acc: 97.220%
	I - Batch: 150 | Loss: 0.105 | Acc: 96.583% | Wgt Acc: 97.093%
	I - Batch: 200 | Loss: 0.102 | Acc: 96.562% | Wgt Acc: 97.046%
	I - Batch: 250 | Loss: 0.106 | Acc: 96.500% | Wgt Acc: 97.009%
	I - Batch: 300 | Loss: 0.103 | Acc: 96.562% | Wgt Acc: 97.131%
	I - Batch: 350 | Loss: 0.105 | Acc: 96.554% | Wgt Acc: 97.093%
I - num batch: 364
I - Train -- Loss: 0.105 | Acc: 96.561% | Wgt Acc: 97.054% | LR: 1.250000e-04 | Dur: 229.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    0.    0.    9.   41.]
 [   0.  660.    2.    3.    7.]
 [   0.    3.  955.    0.   41.]
 [  11.    3.    2.  691.   32.]
 [  14.    2.   15.   15. 2642.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.262 | Acc: 47.000% | Wgt Acc: 41.399%
I - num batch: 87
I - Val -- Loss: 2.207 | Acc: 51.365% | Wgt Acc: 43.585% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 47.   0.   4.   7.   5.]
 [  3. 109.  38.   6.  21.]
 [  2.  33.  97.   5.  20.]
 [ 73.  26.  20. 109.  32.]
 [ 74. 100. 131.  77. 353.]]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 0.127 | Acc: 95.625% | Wgt Acc: 96.247%
	I - Batch: 100 | Loss: 0.110 | Acc: 95.875% | Wgt Acc: 96.694%
	I - Batch: 150 | Loss: 0.101 | Acc: 96.333% | Wgt Acc: 97.027%
	I - Batch: 200 | Loss: 0.097 | Acc: 96.594% | Wgt Acc: 97.197%
	I - Batch: 250 | Loss: 0.095 | Acc: 96.950% | Wgt Acc: 97.461%
	I - Batch: 300 | Loss: 0.095 | Acc: 96.833% | Wgt Acc: 97.398%
	I - Batch: 350 | Loss: 0.093 | Acc: 96.875% | Wgt Acc: 97.471%
I - num batch: 364
I - Train -- Loss: 0.092 | Acc: 96.905% | Wgt Acc: 97.488% | LR: 1.250000e-04 | Dur: 230.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    6.   40.]
 [   0.  663.    3.    1.    6.]
 [   0.    2.  961.    0.   31.]
 [   3.    0.    0.  695.   40.]
 [  19.    3.   10.   16. 2646.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.367 | Acc: 50.500% | Wgt Acc: 44.039%
I - num batch: 87
I - Val -- Loss: 2.207 | Acc: 54.454% | Wgt Acc: 46.507% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   4.   7.  21.  15.]
 [  2.  84.  15.   3.  10.]
 [  2.  36.  98.   3.  15.]
 [ 50.  42.  26. 120.  36.]
 [ 44. 102. 144.  57. 355.]]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 98.375% | Wgt Acc: 98.660%
	I - Batch: 100 | Loss: 0.073 | Acc: 98.062% | Wgt Acc: 98.067%
	I - Batch: 150 | Loss: 0.075 | Acc: 98.125% | Wgt Acc: 98.186%
	I - Batch: 200 | Loss: 0.074 | Acc: 98.125% | Wgt Acc: 98.207%
	I - Batch: 250 | Loss: 0.075 | Acc: 98.000% | Wgt Acc: 98.190%
	I - Batch: 300 | Loss: 0.074 | Acc: 97.979% | Wgt Acc: 98.173%
	I - Batch: 350 | Loss: 0.074 | Acc: 97.982% | Wgt Acc: 98.182%
I - num batch: 364
I - Train -- Loss: 0.077 | Acc: 97.833% | Wgt Acc: 98.032% | LR: 1.250000e-04 | Dur: 227.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    0.    0.    2.   24.]
 [   0.  655.    2.    7.    4.]
 [   0.    5.  959.    0.   27.]
 [   1.    4.    0.  706.   17.]
 [  13.    4.   13.    3. 2691.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.145 | Acc: 52.875% | Wgt Acc: 47.880%
I - num batch: 87
I - Val -- Loss: 2.025 | Acc: 56.034% | Wgt Acc: 50.064% | Dur: 41.95s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   8.  17.  54.  27.]
 [  1. 106.  32.   6.  12.]
 [  1.  49. 114.   7.  35.]
 [ 22.  31.  34.  91.  25.]
 [ 38.  74.  93.  46. 332.]]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 0.104 | Acc: 96.750% | Wgt Acc: 97.123%
	I - Batch: 100 | Loss: 0.093 | Acc: 97.062% | Wgt Acc: 97.439%
	I - Batch: 150 | Loss: 0.083 | Acc: 97.458% | Wgt Acc: 97.772%
	I - Batch: 200 | Loss: 0.081 | Acc: 97.594% | Wgt Acc: 97.966%
	I - Batch: 250 | Loss: 0.082 | Acc: 97.625% | Wgt Acc: 97.966%
	I - Batch: 300 | Loss: 0.080 | Acc: 97.750% | Wgt Acc: 98.016%
	I - Batch: 350 | Loss: 0.082 | Acc: 97.714% | Wgt Acc: 97.966%
I - num batch: 364
I - Train -- Loss: 0.081 | Acc: 97.730% | Wgt Acc: 97.972% | LR: 1.250000e-04 | Dur: 226.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    0.    0.    1.   30.]
 [   0.  658.    6.    2.    2.]
 [   0.    8.  956.    0.   23.]
 [   3.    2.    0.  702.   22.]
 [   8.    0.   12.   13. 2686.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.261 | Acc: 52.000% | Wgt Acc: 46.159%
I - num batch: 87
I - Val -- Loss: 2.162 | Acc: 56.106% | Wgt Acc: 48.822% | Dur: 42.00s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   3.  17.  46.  17.]
 [  0. 100.  20.   5.  17.]
 [  3.  42. 114.   8.  25.]
 [  8.  24.  14.  73.  16.]
 [ 50.  99. 125.  72. 356.]]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 0.069 | Acc: 98.375% | Wgt Acc: 98.535%
	I - Batch: 100 | Loss: 0.091 | Acc: 97.500% | Wgt Acc: 97.716%
	I - Batch: 150 | Loss: 0.086 | Acc: 97.667% | Wgt Acc: 97.976%
	I - Batch: 200 | Loss: 0.088 | Acc: 97.594% | Wgt Acc: 97.963%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.650% | Wgt Acc: 98.077%
	I - Batch: 300 | Loss: 0.081 | Acc: 97.833% | Wgt Acc: 98.241%
	I - Batch: 350 | Loss: 0.078 | Acc: 97.911% | Wgt Acc: 98.289%
I - num batch: 364
I - Train -- Loss: 0.078 | Acc: 97.902% | Wgt Acc: 98.303% | LR: 1.250000e-04 | Dur: 225.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    0.    0.    4.   33.]
 [   0.  664.    3.    0.    5.]
 [   0.    3.  965.    0.   21.]
 [   4.    0.    0.  706.   21.]
 [  13.    1.    6.    8. 2683.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.223 | Acc: 52.000% | Wgt Acc: 46.520%
I - num batch: 87
I - Val -- Loss: 2.093 | Acc: 56.609% | Wgt Acc: 49.421% | Dur: 42.16s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   9.  10.  47.  23.]
 [  1. 111.  27.   4.  11.]
 [  3.  37. 107.   8.  17.]
 [ 19.  27.  25.  84.  22.]
 [ 48.  84. 121.  61. 358.]]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 0.088 | Acc: 97.625% | Wgt Acc: 97.768%
	I - Batch: 100 | Loss: 0.089 | Acc: 97.375% | Wgt Acc: 97.625%
	I - Batch: 150 | Loss: 0.090 | Acc: 97.333% | Wgt Acc: 97.587%
	I - Batch: 200 | Loss: 0.088 | Acc: 97.438% | Wgt Acc: 97.701%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.550% | Wgt Acc: 97.815%
	I - Batch: 300 | Loss: 0.083 | Acc: 97.625% | Wgt Acc: 97.867%
	I - Batch: 350 | Loss: 0.081 | Acc: 97.607% | Wgt Acc: 97.914%
I - num batch: 364
I - Train -- Loss: 0.080 | Acc: 97.627% | Wgt Acc: 97.931% | LR: 1.250000e-04 | Dur: 228.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    0.    0.    5.   24.]
 [   0.  663.    2.    1.    9.]
 [   0.    3.  964.    0.   28.]
 [   5.    0.    0.  699.   19.]
 [  19.    2.    8.   13. 2683.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.145 | Acc: 54.500% | Wgt Acc: 50.741%
I - num batch: 87
I - Val -- Loss: 2.121 | Acc: 56.178% | Wgt Acc: 51.012% | Dur: 42.61s
I - Confusion Matrix: [row->prediction - col->label]
[[157.  17.  27.  64.  54.]
 [  2. 113.  21.   5.  10.]
 [  1.  26. 105.   3.  17.]
 [ 15.  44.  16.  90.  33.]
 [ 24.  68. 121.  42. 317.]]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 0.074 | Acc: 97.625% | Wgt Acc: 98.289%
	I - Batch: 100 | Loss: 0.079 | Acc: 97.688% | Wgt Acc: 98.107%
	I - Batch: 150 | Loss: 0.083 | Acc: 97.667% | Wgt Acc: 98.003%
	I - Batch: 200 | Loss: 0.085 | Acc: 97.625% | Wgt Acc: 98.012%
	I - Batch: 250 | Loss: 0.091 | Acc: 97.350% | Wgt Acc: 97.678%
	I - Batch: 300 | Loss: 0.096 | Acc: 96.979% | Wgt Acc: 97.359%
	I - Batch: 350 | Loss: 0.091 | Acc: 97.286% | Wgt Acc: 97.632%
I - num batch: 364
I - Train -- Loss: 0.092 | Acc: 97.231% | Wgt Acc: 97.598% | LR: 1.250000e-04 | Dur: 228.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    0.    0.    6.   28.]
 [   0.  660.    5.    2.    9.]
 [   0.    4.  958.    0.   33.]
 [   7.    2.    0.  696.   26.]
 [  12.    2.   11.   14. 2667.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.992 | Acc: 53.125% | Wgt Acc: 49.026%
I - num batch: 87
I - Val -- Loss: 1.932 | Acc: 56.825% | Wgt Acc: 50.633% | Dur: 42.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 78.   0.   8.   9.   5.]
 [  5. 118.  27.  11.   9.]
 [  3.  52. 131.  11.  36.]
 [ 60.  18.  24. 117.  34.]
 [ 53.  80. 100.  56. 347.]]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 0.075 | Acc: 97.875% | Wgt Acc: 98.347%
	I - Batch: 100 | Loss: 0.076 | Acc: 98.000% | Wgt Acc: 98.253%
	I - Batch: 150 | Loss: 0.082 | Acc: 97.625% | Wgt Acc: 97.998%
	I - Batch: 200 | Loss: 0.083 | Acc: 97.531% | Wgt Acc: 97.763%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.350% | Wgt Acc: 97.590%
	I - Batch: 300 | Loss: 0.085 | Acc: 97.375% | Wgt Acc: 97.639%
	I - Batch: 350 | Loss: 0.089 | Acc: 97.196% | Wgt Acc: 97.509%
I - num batch: 364
I - Train -- Loss: 0.088 | Acc: 97.248% | Wgt Acc: 97.575% | LR: 1.250000e-04 | Dur: 229.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 665.    0.    0.    8.   37.]
 [   0.  657.    2.    2.    7.]
 [   0.    3.  962.    0.   30.]
 [  11.    1.    0.  701.   19.]
 [  16.    7.   10.    7. 2670.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.124 | Acc: 54.875% | Wgt Acc: 50.086%
I - num batch: 87
I - Val -- Loss: 2.123 | Acc: 56.178% | Wgt Acc: 50.230% | Dur: 42.80s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   7.  21.  48.  34.]
 [  0. 116.  30.   5.  15.]
 [  2.  30.  89.   7.  16.]
 [ 32.  41.  25. 112.  36.]
 [ 30.  74. 125.  32. 330.]]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 97.250% | Wgt Acc: 97.565%
	I - Batch: 100 | Loss: 0.101 | Acc: 97.312% | Wgt Acc: 97.445%
	I - Batch: 150 | Loss: 0.097 | Acc: 97.125% | Wgt Acc: 97.432%
	I - Batch: 200 | Loss: 0.094 | Acc: 97.125% | Wgt Acc: 97.498%
	I - Batch: 250 | Loss: 0.098 | Acc: 96.875% | Wgt Acc: 97.290%
	I - Batch: 300 | Loss: 0.096 | Acc: 96.938% | Wgt Acc: 97.329%
	I - Batch: 350 | Loss: 0.097 | Acc: 96.911% | Wgt Acc: 97.286%
I - num batch: 364
I - Train -- Loss: 0.097 | Acc: 96.922% | Wgt Acc: 97.296% | LR: 1.250000e-04 | Dur: 229.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 666.    0.    0.   10.   36.]
 [   0.  659.    3.    1.    6.]
 [   1.    5.  958.    0.   36.]
 [  10.    2.    0.  694.   26.]
 [  15.    2.   13.   13. 2659.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.260 | Acc: 51.125% | Wgt Acc: 45.700%
I - num batch: 87
I - Val -- Loss: 2.181 | Acc: 54.885% | Wgt Acc: 47.506% | Dur: 42.76s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   5.  11.  24.  10.]
 [  3. 109.  29.   2.  17.]
 [  2.  37. 109.   7.  23.]
 [ 20.  27.  14.  85.  24.]
 [ 70.  90. 127.  86. 357.]]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 0.098 | Acc: 96.250% | Wgt Acc: 97.017%
	I - Batch: 100 | Loss: 0.095 | Acc: 96.625% | Wgt Acc: 97.220%
	I - Batch: 150 | Loss: 0.098 | Acc: 96.542% | Wgt Acc: 97.056%
	I - Batch: 200 | Loss: 0.094 | Acc: 96.875% | Wgt Acc: 97.304%
	I - Batch: 250 | Loss: 0.087 | Acc: 97.250% | Wgt Acc: 97.651%
	I - Batch: 300 | Loss: 0.087 | Acc: 97.292% | Wgt Acc: 97.650%
	I - Batch: 350 | Loss: 0.087 | Acc: 97.232% | Wgt Acc: 97.609%
I - num batch: 364
I - Train -- Loss: 0.087 | Acc: 97.266% | Wgt Acc: 97.632% | LR: 1.250000e-04 | Dur: 228.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    0.    4.   38.]
 [   0.  658.    4.    2.    7.]
 [   0.    4.  958.    1.   28.]
 [   2.    2.    0.  701.   23.]
 [  18.    4.   12.   10. 2667.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.980 | Acc: 57.875% | Wgt Acc: 54.472%
I - num batch: 87
I - Val -- Loss: 1.913 | Acc: 59.124% | Wgt Acc: 54.665% | Dur: 42.76s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   5.  23.  38.  32.]
 [  4. 142.  35.  11.  24.]
 [  3.  29. 119.   4.  19.]
 [ 36.  38.  13. 106.  31.]
 [ 25.  54. 100.  45. 325.]]

I - Local maximum validation set accuracy:  59.12

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 0.092 | Acc: 97.125% | Wgt Acc: 97.345%
	I - Batch: 100 | Loss: 0.093 | Acc: 96.938% | Wgt Acc: 97.344%
	I - Batch: 150 | Loss: 0.093 | Acc: 97.042% | Wgt Acc: 97.424%
	I - Batch: 200 | Loss: 0.089 | Acc: 97.188% | Wgt Acc: 97.497%
	I - Batch: 250 | Loss: 0.086 | Acc: 97.400% | Wgt Acc: 97.640%
	I - Batch: 300 | Loss: 0.090 | Acc: 97.104% | Wgt Acc: 97.443%
	I - Batch: 350 | Loss: 0.088 | Acc: 97.071% | Wgt Acc: 97.453%
I - num batch: 364
I - Train -- Loss: 0.088 | Acc: 97.008% | Wgt Acc: 97.390% | LR: 1.250000e-04 | Dur: 229.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    6.   34.]
 [   0.  661.    8.    2.   12.]
 [   0.    4.  953.    0.   33.]
 [   6.    2.    0.  697.   24.]
 [  16.    1.   13.   13. 2660.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.184 | Acc: 53.875% | Wgt Acc: 48.940%
I - num batch: 87
I - Val -- Loss: 2.102 | Acc: 56.466% | Wgt Acc: 49.913% | Dur: 42.86s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   8.  14.  49.  37.]
 [  1.  97.  16.   3.   9.]
 [  0.  44. 126.   9.  23.]
 [ 20.  24.  13.  83.  18.]
 [ 42.  95. 121.  60. 344.]]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 0.098 | Acc: 96.875% | Wgt Acc: 97.521%
	I - Batch: 100 | Loss: 0.095 | Acc: 97.438% | Wgt Acc: 97.874%
	I - Batch: 150 | Loss: 0.089 | Acc: 97.375% | Wgt Acc: 97.799%
	I - Batch: 200 | Loss: 0.092 | Acc: 97.344% | Wgt Acc: 97.703%
	I - Batch: 250 | Loss: 0.089 | Acc: 97.450% | Wgt Acc: 97.807%
	I - Batch: 300 | Loss: 0.093 | Acc: 97.375% | Wgt Acc: 97.726%
	I - Batch: 350 | Loss: 0.094 | Acc: 97.268% | Wgt Acc: 97.653%
I - num batch: 364
I - Train -- Loss: 0.094 | Acc: 97.197% | Wgt Acc: 97.613% | LR: 1.250000e-04 | Dur: 229.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    3.   34.]
 [   0.  659.    4.    2.    6.]
 [   1.    5.  961.    0.   36.]
 [   5.    1.    0.  699.   24.]
 [  16.    3.    9.   14. 2663.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.343 | Acc: 48.125% | Wgt Acc: 42.312%
I - num batch: 87
I - Val -- Loss: 2.224 | Acc: 53.664% | Wgt Acc: 45.385% | Dur: 42.47s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   0.  12.  22.  11.]
 [  1.  87.  17.   2.   8.]
 [  3.  57. 121.  12.  29.]
 [ 27.  23.  11.  79.  17.]
 [ 74. 101. 129.  89. 366.]]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 0.073 | Acc: 98.250% | Wgt Acc: 98.428%
	I - Batch: 100 | Loss: 0.090 | Acc: 97.625% | Wgt Acc: 98.021%
	I - Batch: 150 | Loss: 0.085 | Acc: 97.792% | Wgt Acc: 98.216%
	I - Batch: 200 | Loss: 0.079 | Acc: 97.969% | Wgt Acc: 98.382%
	I - Batch: 250 | Loss: 0.081 | Acc: 97.875% | Wgt Acc: 98.333%
	I - Batch: 300 | Loss: 0.075 | Acc: 98.042% | Wgt Acc: 98.459%
	I - Batch: 350 | Loss: 0.073 | Acc: 98.089% | Wgt Acc: 98.482%
I - num batch: 364
I - Train -- Loss: 0.073 | Acc: 98.022% | Wgt Acc: 98.422% | LR: 1.250000e-04 | Dur: 229.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    0.    0.    1.   33.]
 [   0.  662.    1.    1.    5.]
 [   0.    2.  969.    1.   19.]
 [   0.    1.    0.  705.   20.]
 [  14.    3.    4.   10. 2686.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.564 | Acc: 46.625% | Wgt Acc: 39.978%
I - num batch: 87
I - Val -- Loss: 2.433 | Acc: 52.514% | Wgt Acc: 43.129% | Dur: 43.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 82.   1.   6.  16.   5.]
 [  2.  75.   9.   6.   3.]
 [  2.  53. 128.   9.  30.]
 [ 29.  20.   9.  64.  11.]
 [ 84. 119. 138. 109. 382.]]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 0.057 | Acc: 98.250% | Wgt Acc: 98.631%
	I - Batch: 100 | Loss: 0.055 | Acc: 98.438% | Wgt Acc: 98.670%
	I - Batch: 150 | Loss: 0.053 | Acc: 98.583% | Wgt Acc: 98.879%
	I - Batch: 200 | Loss: 0.054 | Acc: 98.656% | Wgt Acc: 98.893%
	I - Batch: 250 | Loss: 0.057 | Acc: 98.675% | Wgt Acc: 98.827%
	I - Batch: 300 | Loss: 0.057 | Acc: 98.604% | Wgt Acc: 98.795%
	I - Batch: 350 | Loss: 0.056 | Acc: 98.643% | Wgt Acc: 98.841%
I - num batch: 364
I - Train -- Loss: 0.057 | Acc: 98.590% | Wgt Acc: 98.786% | LR: 1.250000e-04 | Dur: 232.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 687.    0.    0.    4.   18.]
 [   0.  664.    4.    1.    8.]
 [   0.    2.  964.    0.   11.]
 [   1.    1.    0.  705.   13.]
 [   4.    1.    6.    8. 2713.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.318 | Acc: 50.000% | Wgt Acc: 43.758%
I - num batch: 87
I - Val -- Loss: 2.210 | Acc: 55.891% | Wgt Acc: 47.212% | Dur: 43.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   3.  11.  23.   7.]
 [  2. 108.  25.   3.   7.]
 [  1.  21.  87.   6.  15.]
 [ 44.  34.  22. 106.  22.]
 [ 55. 102. 145.  66. 380.]]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 0.047 | Acc: 99.250% | Wgt Acc: 99.388%
	I - Batch: 100 | Loss: 0.061 | Acc: 98.750% | Wgt Acc: 98.993%
	I - Batch: 150 | Loss: 0.060 | Acc: 98.792% | Wgt Acc: 99.035%
	I - Batch: 200 | Loss: 0.058 | Acc: 98.625% | Wgt Acc: 98.912%
	I - Batch: 250 | Loss: 0.057 | Acc: 98.600% | Wgt Acc: 98.866%
	I - Batch: 300 | Loss: 0.060 | Acc: 98.438% | Wgt Acc: 98.751%
	I - Batch: 350 | Loss: 0.067 | Acc: 98.071% | Wgt Acc: 98.429%
I - num batch: 364
I - Train -- Loss: 0.068 | Acc: 98.022% | Wgt Acc: 98.408% | LR: 1.250000e-04 | Dur: 233.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    0.    0.    1.   22.]
 [   1.  665.    2.    0.    5.]
 [   0.    2.  964.    0.   27.]
 [   0.    1.    0.  703.   22.]
 [  10.    0.    8.   14. 2687.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.233 | Acc: 51.750% | Wgt Acc: 46.533%
I - num batch: 87
I - Val -- Loss: 2.101 | Acc: 55.747% | Wgt Acc: 48.864% | Dur: 43.15s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   9.  12.  32.  17.]
 [  1.  80.  17.   2.   9.]
 [  3.  53. 121.   9.  20.]
 [ 32.  56.  36. 114.  44.]
 [ 43.  70. 104.  47. 341.]]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 0.072 | Acc: 98.375% | Wgt Acc: 98.365%
	I - Batch: 100 | Loss: 0.069 | Acc: 98.125% | Wgt Acc: 98.342%
	I - Batch: 150 | Loss: 0.063 | Acc: 98.292% | Wgt Acc: 98.491%
	I - Batch: 200 | Loss: 0.074 | Acc: 98.031% | Wgt Acc: 98.250%
	I - Batch: 250 | Loss: 0.082 | Acc: 97.625% | Wgt Acc: 97.836%
	I - Batch: 300 | Loss: 0.081 | Acc: 97.667% | Wgt Acc: 97.887%
	I - Batch: 350 | Loss: 0.085 | Acc: 97.500% | Wgt Acc: 97.793%
I - num batch: 364
I - Train -- Loss: 0.086 | Acc: 97.472% | Wgt Acc: 97.737% | LR: 1.250000e-04 | Dur: 229.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    4.   27.]
 [   1.  660.    7.    0.    7.]
 [   1.    5.  955.    1.   32.]
 [   7.    0.    0.  705.   18.]
 [  14.    3.   12.    8. 2679.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.488 | Acc: 48.375% | Wgt Acc: 41.834%
I - num batch: 87
I - Val -- Loss: 2.412 | Acc: 52.586% | Wgt Acc: 43.198% | Dur: 42.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 86.   0.   6.  13.   3.]
 [  0.  76.   6.   1.   6.]
 [  0.  58. 108.  10.  26.]
 [ 28.  15.  15.  84.  18.]
 [ 85. 119. 155.  96. 378.]]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 0.071 | Acc: 98.000% | Wgt Acc: 98.327%
	I - Batch: 100 | Loss: 0.077 | Acc: 97.875% | Wgt Acc: 98.053%
	I - Batch: 150 | Loss: 0.101 | Acc: 96.708% | Wgt Acc: 97.108%
	I - Batch: 200 | Loss: 0.099 | Acc: 96.750% | Wgt Acc: 97.100%
	I - Batch: 250 | Loss: 0.094 | Acc: 96.925% | Wgt Acc: 97.320%
	I - Batch: 300 | Loss: 0.092 | Acc: 96.979% | Wgt Acc: 97.398%
	I - Batch: 350 | Loss: 0.091 | Acc: 97.036% | Wgt Acc: 97.453%
I - num batch: 364
I - Train -- Loss: 0.091 | Acc: 96.991% | Wgt Acc: 97.420% | LR: 1.250000e-04 | Dur: 229.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    7.   35.]
 [   0.  660.    4.    1.    7.]
 [   0.    4.  958.    0.   26.]
 [   4.    2.    1.  696.   38.]
 [  19.    2.   11.   14. 2657.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.311 | Acc: 51.500% | Wgt Acc: 45.681%
I - num batch: 87
I - Val -- Loss: 2.192 | Acc: 56.106% | Wgt Acc: 47.947% | Dur: 42.78s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   4.  11.  39.  15.]
 [  0.  91.  12.   1.   7.]
 [  3.  39. 123.  11.  26.]
 [ 21.  25.  16.  74.  11.]
 [ 54. 109. 128.  79. 372.]]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 97.625% | Wgt Acc: 97.944%
	I - Batch: 100 | Loss: 0.071 | Acc: 98.062% | Wgt Acc: 98.445%
	I - Batch: 150 | Loss: 0.067 | Acc: 98.250% | Wgt Acc: 98.535%
	I - Batch: 200 | Loss: 0.069 | Acc: 98.094% | Wgt Acc: 98.381%
	I - Batch: 250 | Loss: 0.071 | Acc: 98.025% | Wgt Acc: 98.313%
	I - Batch: 300 | Loss: 0.079 | Acc: 97.792% | Wgt Acc: 98.067%
	I - Batch: 350 | Loss: 0.081 | Acc: 97.500% | Wgt Acc: 97.864%
I - num batch: 364
I - Train -- Loss: 0.080 | Acc: 97.541% | Wgt Acc: 97.883% | LR: 1.250000e-04 | Dur: 229.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    0.    0.    4.   24.]
 [   0.  660.    4.    2.   10.]
 [   0.    3.  959.    1.   26.]
 [   2.    2.    0.  700.   27.]
 [  13.    3.   11.   11. 2676.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.275 | Acc: 53.250% | Wgt Acc: 48.046%
I - num batch: 87
I - Val -- Loss: 2.203 | Acc: 56.681% | Wgt Acc: 49.669% | Dur: 42.76s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   2.  12.  26.  14.]
 [  3.  90.  16.   6.  10.]
 [  3.  56. 152.   6.  35.]
 [ 23.  14.   9.  83.  15.]
 [ 63. 106. 101.  83. 357.]]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 0.112 | Acc: 96.875% | Wgt Acc: 96.995%
	I - Batch: 100 | Loss: 0.106 | Acc: 96.812% | Wgt Acc: 97.096%
	I - Batch: 150 | Loss: 0.090 | Acc: 97.250% | Wgt Acc: 97.522%
	I - Batch: 200 | Loss: 0.087 | Acc: 97.438% | Wgt Acc: 97.679%
	I - Batch: 250 | Loss: 0.086 | Acc: 97.350% | Wgt Acc: 97.629%
	I - Batch: 300 | Loss: 0.086 | Acc: 97.458% | Wgt Acc: 97.708%
	I - Batch: 350 | Loss: 0.089 | Acc: 97.250% | Wgt Acc: 97.595%
I - num batch: 364
I - Train -- Loss: 0.088 | Acc: 97.300% | Wgt Acc: 97.626% | LR: 1.250000e-04 | Dur: 229.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 668.    0.    0.    5.   35.]
 [   0.  657.    3.    1.    8.]
 [   0.    6.  961.    1.   26.]
 [   4.    1.    1.  701.   23.]
 [  20.    4.    9.   10. 2671.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.445 | Acc: 48.500% | Wgt Acc: 42.398%
I - num batch: 87
I - Val -- Loss: 2.359 | Acc: 54.310% | Wgt Acc: 45.629% | Dur: 42.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   3.  14.  24.  12.]
 [  1. 102.  19.   5.  12.]
 [  2.  26.  93.   3.  17.]
 [ 22.  26.  19.  87.  15.]
 [ 75. 111. 145.  85. 375.]]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 0.072 | Acc: 98.000% | Wgt Acc: 98.306%
	I - Batch: 100 | Loss: 0.074 | Acc: 98.062% | Wgt Acc: 98.230%
	I - Batch: 150 | Loss: 0.086 | Acc: 97.667% | Wgt Acc: 97.919%
	I - Batch: 200 | Loss: 0.091 | Acc: 97.469% | Wgt Acc: 97.801%
	I - Batch: 250 | Loss: 0.094 | Acc: 97.175% | Wgt Acc: 97.527%
	I - Batch: 300 | Loss: 0.092 | Acc: 97.208% | Wgt Acc: 97.602%
	I - Batch: 350 | Loss: 0.091 | Acc: 97.232% | Wgt Acc: 97.632%
I - num batch: 364
I - Train -- Loss: 0.089 | Acc: 97.334% | Wgt Acc: 97.721% | LR: 1.250000e-04 | Dur: 232.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    0.    3.   34.]
 [   0.  659.    6.    0.    8.]
 [   0.    6.  960.    0.   35.]
 [   6.    1.    0.  701.   18.]
 [  14.    2.    8.   14. 2668.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.099 | Acc: 53.750% | Wgt Acc: 48.903%
I - num batch: 87
I - Val -- Loss: 2.085 | Acc: 56.537% | Wgt Acc: 49.971% | Dur: 43.52s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   8.  15.  36.  24.]
 [  2.  95.  19.   6.   9.]
 [  4.  54. 136.   9.  32.]
 [ 25.  21.  11.  85.  20.]
 [ 43.  90. 109.  68. 346.]]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 0.094 | Acc: 97.375% | Wgt Acc: 97.907%
	I - Batch: 100 | Loss: 0.085 | Acc: 97.562% | Wgt Acc: 97.968%
	I - Batch: 150 | Loss: 0.077 | Acc: 97.833% | Wgt Acc: 98.132%
	I - Batch: 200 | Loss: 0.083 | Acc: 97.594% | Wgt Acc: 97.845%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.550% | Wgt Acc: 97.787%
	I - Batch: 300 | Loss: 0.085 | Acc: 97.438% | Wgt Acc: 97.683%
	I - Batch: 350 | Loss: 0.084 | Acc: 97.429% | Wgt Acc: 97.747%
I - num batch: 364
I - Train -- Loss: 0.085 | Acc: 97.438% | Wgt Acc: 97.725% | LR: 1.250000e-04 | Dur: 230.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 673.    0.    0.    6.   30.]
 [   0.  661.    8.    2.    6.]
 [   0.    5.  955.    0.   29.]
 [   6.    0.    0.  700.   21.]
 [  13.    2.   11.   10. 2677.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.227 | Acc: 49.500% | Wgt Acc: 43.733%
I - num batch: 87
I - Val -- Loss: 2.170 | Acc: 54.526% | Wgt Acc: 46.058% | Dur: 43.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   6.  28.   6.]
 [  0.  87.  15.   7.  12.]
 [  2.  52. 121.   8.  22.]
 [ 27.  29.  11.  80.  19.]
 [ 71.  99. 137.  81. 372.]]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 98.125% | Wgt Acc: 98.479%
	I - Batch: 100 | Loss: 0.076 | Acc: 97.688% | Wgt Acc: 98.091%
	I - Batch: 150 | Loss: 0.078 | Acc: 97.542% | Wgt Acc: 97.910%
	I - Batch: 200 | Loss: 0.077 | Acc: 97.656% | Wgt Acc: 98.010%
	I - Batch: 250 | Loss: 0.080 | Acc: 97.600% | Wgt Acc: 97.961%
	I - Batch: 300 | Loss: 0.078 | Acc: 97.625% | Wgt Acc: 97.997%
	I - Batch: 350 | Loss: 0.077 | Acc: 97.768% | Wgt Acc: 98.102%
I - num batch: 364
I - Train -- Loss: 0.077 | Acc: 97.782% | Wgt Acc: 98.139% | LR: 1.250000e-04 | Dur: 230.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    0.    6.   24.]
 [   0.  661.    1.    0.    7.]
 [   0.    5.  964.    0.   35.]
 [   4.    0.    0.  707.   15.]
 [  16.    2.    9.    5. 2682.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.134 | Acc: 53.625% | Wgt Acc: 48.928%
I - num batch: 87
I - Val -- Loss: 2.093 | Acc: 56.178% | Wgt Acc: 49.785% | Dur: 43.04s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   4.  11.  23.  12.]
 [  1. 106.  15.   3.  19.]
 [  0.  34. 115.   3.  21.]
 [ 37.  49.  30. 117.  38.]
 [ 58.  75. 119.  58. 341.]]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 96.750% | Wgt Acc: 97.059%
	I - Batch: 100 | Loss: 0.078 | Acc: 97.500% | Wgt Acc: 97.769%
	I - Batch: 150 | Loss: 0.075 | Acc: 97.667% | Wgt Acc: 98.000%
	I - Batch: 200 | Loss: 0.078 | Acc: 97.656% | Wgt Acc: 98.017%
	I - Batch: 250 | Loss: 0.074 | Acc: 97.825% | Wgt Acc: 98.189%
	I - Batch: 300 | Loss: 0.073 | Acc: 97.917% | Wgt Acc: 98.234%
	I - Batch: 350 | Loss: 0.073 | Acc: 97.875% | Wgt Acc: 98.202%
I - num batch: 364
I - Train -- Loss: 0.072 | Acc: 97.868% | Wgt Acc: 98.198% | LR: 1.250000e-04 | Dur: 230.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    0.    0.    6.   30.]
 [   0.  662.    3.    2.    8.]
 [   0.    4.  963.    1.   23.]
 [   2.    1.    0.  701.   16.]
 [  11.    1.    8.    8. 2686.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.363 | Acc: 52.250% | Wgt Acc: 45.816%
I - num batch: 87
I - Val -- Loss: 2.304 | Acc: 54.813% | Wgt Acc: 46.701% | Dur: 43.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   6.   8.  21.  20.]
 [  0.  95.  12.   1.   6.]
 [  0.  21.  83.   4.   6.]
 [ 47.  48.  27. 126.  39.]
 [ 53.  98. 160.  52. 360.]]

I - Maximum validation set accuracy in current training:  59.12
