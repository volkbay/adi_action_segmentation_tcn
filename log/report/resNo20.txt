Wed Sep 28 17:16:25 2022
I - CONFIGURATION: {'batchSize': 16, 'bias': True, 'classWeights': [0.21, 0.26, 0.24, 0.21, 0.08], 'classWeightsFlag': True, 'dataConfig': {'multiplyData': False, 'bulkPickles': True, 'dataCount': 5, 'loadData2memory': True}, 'dataPath': '/data/processed/Kinetics/', 'epochNo': 200, 'foldRatio': 4, 'fps': 5, 'frameNoDataset': 50, 'frameNoModel': 16, 'imgSize': [256, 256], 'labels': ['pull ups', 'push up', 'situp', 'squat', 'background'], 'learningRate': 0.001, 'logBatchAt': 50, 'maxValidationAcc': 63.99870382372003, 'maxValidationTrainNo': 16, 'modelVersion': 5, 'schedulerFlag': True, 'schedulerGamma': 0.5, 'schedulerMilestones': [10, 20, 25], 'trainNo': 20, 'validationAccThr': 60, 'weightDecay': 0.001}
I - Running on device: cuda:0
I - Configuring device: MAX78000, simulate=False.
I - ========== TRAIN  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_001.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_002.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_003.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Loading file: dataset_004.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/train
I - Train set length:  5000
I - Label distribution: [ 694.  334.  487.  719. 2766.]
I - ========== TEST  SET ==========
I - Loading file: dataset_000.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Loading file: dataset_005.pkl in /data/processed/Kinetics/processed_4class_5fps_50frames_256x256/test
I - Test set length:  1114
I - Label distribution: [199. 134. 146. 204. 431.]
I - Batch size:  16  tensor shape:  torch.Size([16, 48, 64, 64])  data min-max:  tensor(-1.) tensor(0.9922)
I - Label min-max:  tensor(0) tensor(4) data number in dataset:  tensor([4055, 1453, 3796, 4816,  304, 3243, 2023, 4227, 4979, 3151, 2403,  452,
        3513, 4613, 3601, 4717])
I - Initializing model TCNv5
I - Number of Model Parameters: 529216
I - Model output shape:  torch.Size([16, 5])
I - Model summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TCNv5                                    [16, 5]                   --
├─FusedConv2dBNReLU: 1-1                 [16, 64, 64, 64]          3,142
│    └─OutputShiftSqueeze: 2-1           --                        --
│    └─One: 2-2                          [1]                       --
│    └─OutputScale: 2-3                  --                        --
│    └─Empty: 2-4                        [64, 48, 1, 1]            --
│    └─Empty: 2-5                        [64, 48, 1, 1]            --
│    └─Empty: 2-6                        [64]                      --
│    └─Empty: 2-7                        [64]                      --
│    └─BatchNorm2d: 2-8                  [16, 64, 64, 64]          --
│    └─Scaler: 2-9                       [16, 64, 64, 64]          --
│    └─ReLU: 2-10                        [16, 64, 64, 64]          --
│    └─Empty: 2-11                       [16, 64, 64, 64]          --
│    └─Clamp: 2-12                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-2                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-13          --                        --
│    └─One: 2-14                         [1]                       --
│    └─OutputScale: 2-15                 --                        --
│    └─Empty: 2-16                       [64, 64, 3, 3]            --
│    └─Empty: 2-17                       [64, 64, 3, 3]            --
│    └─Empty: 2-18                       [64]                      --
│    └─Empty: 2-19                       [64]                      --
│    └─BatchNorm2d: 2-20                 [16, 64, 64, 64]          --
│    └─Scaler: 2-21                      [16, 64, 64, 64]          --
│    └─ReLU: 2-22                        [16, 64, 64, 64]          --
│    └─Empty: 2-23                       [16, 64, 64, 64]          --
│    └─Clamp: 2-24                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-3                 [16, 64, 64, 64]          4,166
│    └─OutputShiftSqueeze: 2-25          --                        --
│    └─One: 2-26                         [1]                       --
│    └─OutputScale: 2-27                 --                        --
│    └─Empty: 2-28                       [64, 64, 1, 1]            --
│    └─Empty: 2-29                       [64, 64, 1, 1]            --
│    └─Empty: 2-30                       [64]                      --
│    └─Empty: 2-31                       [64]                      --
│    └─BatchNorm2d: 2-32                 [16, 64, 64, 64]          --
│    └─Scaler: 2-33                      [16, 64, 64, 64]          --
│    └─ReLU: 2-34                        [16, 64, 64, 64]          --
│    └─Empty: 2-35                       [16, 64, 64, 64]          --
│    └─Clamp: 2-36                       [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-4                 [16, 64, 64, 64]          36,934
│    └─OutputShiftSqueeze: 2-37          --                        --
│    └─One: 2-38                         [1]                       --
│    └─OutputScale: 2-39                 --                        --
│    └─Empty: 2-40                       [64, 64, 3, 3]            --
│    └─Empty: 2-41                       [64, 64, 3, 3]            --
│    └─Empty: 2-42                       [64]                      --
│    └─Empty: 2-43                       [64]                      --
│    └─BatchNorm2d: 2-44                 [16, 64, 64, 64]          --
│    └─Scaler: 2-45                      [16, 64, 64, 64]          --
│    └─ReLU: 2-46                        [16, 64, 64, 64]          --
│    └─Empty: 2-47                       [16, 64, 64, 64]          --
│    └─Clamp: 2-48                       [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-5          [16, 64, 32, 32]          36,934
│    └─MaxPool2d: 2-49                   [16, 64, 32, 32]          --
│    └─Empty: 2-50                       [16, 64, 32, 32]          --
│    └─Empty: 2-51                       [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-52          --                        --
│    └─One: 2-53                         [1]                       --
│    └─OutputScale: 2-54                 --                        --
│    └─Empty: 2-55                       [64, 64, 3, 3]            --
│    └─Empty: 2-56                       [64, 64, 3, 3]            --
│    └─Empty: 2-57                       [64]                      --
│    └─Empty: 2-58                       [64]                      --
│    └─BatchNorm2d: 2-59                 [16, 64, 32, 32]          --
│    └─Scaler: 2-60                      [16, 64, 32, 32]          --
│    └─ReLU: 2-61                        [16, 64, 32, 32]          --
│    └─Empty: 2-62                       [16, 64, 32, 32]          --
│    └─Clamp: 2-63                       [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-6                 [16, 64, 32, 32]          36,934
│    └─OutputShiftSqueeze: 2-64          --                        --
│    └─One: 2-65                         [1]                       --
│    └─OutputScale: 2-66                 --                        --
│    └─Empty: 2-67                       [64, 64, 3, 3]            --
│    └─Empty: 2-68                       [64, 64, 3, 3]            --
│    └─Empty: 2-69                       [64]                      --
│    └─Empty: 2-70                       [64]                      --
│    └─BatchNorm2d: 2-71                 [16, 64, 32, 32]          --
│    └─Scaler: 2-72                      [16, 64, 32, 32]          --
│    └─ReLU: 2-73                        [16, 64, 32, 32]          --
│    └─Empty: 2-74                       [16, 64, 32, 32]          --
│    └─Clamp: 2-75                       [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-7          [16, 64, 16, 16]          36,934
│    └─MaxPool2d: 2-76                   [16, 64, 16, 16]          --
│    └─Empty: 2-77                       [16, 64, 16, 16]          --
│    └─Empty: 2-78                       [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-79          --                        --
│    └─One: 2-80                         [1]                       --
│    └─OutputScale: 2-81                 --                        --
│    └─Empty: 2-82                       [64, 64, 3, 3]            --
│    └─Empty: 2-83                       [64, 64, 3, 3]            --
│    └─Empty: 2-84                       [64]                      --
│    └─Empty: 2-85                       [64]                      --
│    └─BatchNorm2d: 2-86                 [16, 64, 16, 16]          --
│    └─Scaler: 2-87                      [16, 64, 16, 16]          --
│    └─ReLU: 2-88                        [16, 64, 16, 16]          --
│    └─Empty: 2-89                       [16, 64, 16, 16]          --
│    └─Clamp: 2-90                       [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-8                 [16, 64, 16, 16]          36,934
│    └─OutputShiftSqueeze: 2-91          --                        --
│    └─One: 2-92                         [1]                       --
│    └─OutputScale: 2-93                 --                        --
│    └─Empty: 2-94                       [64, 64, 3, 3]            --
│    └─Empty: 2-95                       [64, 64, 3, 3]            --
│    └─Empty: 2-96                       [64]                      --
│    └─Empty: 2-97                       [64]                      --
│    └─BatchNorm2d: 2-98                 [16, 64, 16, 16]          --
│    └─Scaler: 2-99                      [16, 64, 16, 16]          --
│    └─ReLU: 2-100                       [16, 64, 16, 16]          --
│    └─Empty: 2-101                      [16, 64, 16, 16]          --
│    └─Clamp: 2-102                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-9          [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-103                  [16, 64, 8, 8]            --
│    └─Empty: 2-104                      [16, 64, 8, 8]            --
│    └─Empty: 2-105                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-106         --                        --
│    └─One: 2-107                        [1]                       --
│    └─OutputScale: 2-108                --                        --
│    └─Empty: 2-109                      [64, 64, 3, 3]            --
│    └─Empty: 2-110                      [64, 64, 3, 3]            --
│    └─Empty: 2-111                      [64]                      --
│    └─Empty: 2-112                      [64]                      --
│    └─BatchNorm2d: 2-113                [16, 64, 8, 8]            --
│    └─Scaler: 2-114                     [16, 64, 8, 8]            --
│    └─ReLU: 2-115                       [16, 64, 8, 8]            --
│    └─Empty: 2-116                      [16, 64, 8, 8]            --
│    └─Clamp: 2-117                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-10                [16, 64, 8, 8]            4,166
│    └─OutputShiftSqueeze: 2-118         --                        --
│    └─One: 2-119                        [1]                       --
│    └─OutputScale: 2-120                --                        --
│    └─Empty: 2-121                      [64, 64, 1, 1]            --
│    └─Empty: 2-122                      [64, 64, 1, 1]            --
│    └─Empty: 2-123                      [64]                      --
│    └─Empty: 2-124                      [64]                      --
│    └─BatchNorm2d: 2-125                [16, 64, 8, 8]            --
│    └─Scaler: 2-126                     [16, 64, 8, 8]            --
│    └─ReLU: 2-127                       [16, 64, 8, 8]            --
│    └─Empty: 2-128                      [16, 64, 8, 8]            --
│    └─Clamp: 2-129                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-11         [16, 64, 8, 8]            36,934
│    └─MaxPool2d: 2-130                  [16, 64, 8, 8]            --
│    └─Empty: 2-131                      [16, 64, 8, 8]            --
│    └─Empty: 2-132                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-133         --                        --
│    └─One: 2-134                        [1]                       --
│    └─OutputScale: 2-135                --                        --
│    └─Empty: 2-136                      [64, 64, 3, 3]            --
│    └─Empty: 2-137                      [64, 64, 3, 3]            --
│    └─Empty: 2-138                      [64]                      --
│    └─Empty: 2-139                      [64]                      --
│    └─BatchNorm2d: 2-140                [16, 64, 8, 8]            --
│    └─Scaler: 2-141                     [16, 64, 8, 8]            --
│    └─ReLU: 2-142                       [16, 64, 8, 8]            --
│    └─Empty: 2-143                      [16, 64, 8, 8]            --
│    └─Clamp: 2-144                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-12         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-145                  [16, 64, 4, 4]            --
│    └─Empty: 2-146                      [16, 64, 4, 4]            --
│    └─Empty: 2-147                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-148         --                        --
│    └─One: 2-149                        [1]                       --
│    └─OutputScale: 2-150                --                        --
│    └─Empty: 2-151                      [64, 64, 3, 3]            --
│    └─Empty: 2-152                      [64, 64, 3, 3]            --
│    └─Empty: 2-153                      [64]                      --
│    └─Empty: 2-154                      [64]                      --
│    └─BatchNorm2d: 2-155                [16, 64, 4, 4]            --
│    └─Scaler: 2-156                     [16, 64, 4, 4]            --
│    └─ReLU: 2-157                       [16, 64, 4, 4]            --
│    └─Empty: 2-158                      [16, 64, 4, 4]            --
│    └─Clamp: 2-159                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-13                [16, 64, 4, 4]            4,166
│    └─OutputShiftSqueeze: 2-160         --                        --
│    └─One: 2-161                        [1]                       --
│    └─OutputScale: 2-162                --                        --
│    └─Empty: 2-163                      [64, 64, 1, 1]            --
│    └─Empty: 2-164                      [64, 64, 1, 1]            --
│    └─Empty: 2-165                      [64]                      --
│    └─Empty: 2-166                      [64]                      --
│    └─BatchNorm2d: 2-167                [16, 64, 4, 4]            --
│    └─Scaler: 2-168                     [16, 64, 4, 4]            --
│    └─ReLU: 2-169                       [16, 64, 4, 4]            --
│    └─Empty: 2-170                      [16, 64, 4, 4]            --
│    └─Clamp: 2-171                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-14         [16, 64, 4, 4]            36,934
│    └─MaxPool2d: 2-172                  [16, 64, 4, 4]            --
│    └─Empty: 2-173                      [16, 64, 4, 4]            --
│    └─Empty: 2-174                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-175         --                        --
│    └─One: 2-176                        [1]                       --
│    └─OutputScale: 2-177                --                        --
│    └─Empty: 2-178                      [64, 64, 3, 3]            --
│    └─Empty: 2-179                      [64, 64, 3, 3]            --
│    └─Empty: 2-180                      [64]                      --
│    └─Empty: 2-181                      [64]                      --
│    └─BatchNorm2d: 2-182                [16, 64, 4, 4]            --
│    └─Scaler: 2-183                     [16, 64, 4, 4]            --
│    └─ReLU: 2-184                       [16, 64, 4, 4]            --
│    └─Empty: 2-185                      [16, 64, 4, 4]            --
│    └─Clamp: 2-186                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-15         [16, 64, 2, 2]            4,166
│    └─MaxPool2d: 2-187                  [16, 64, 2, 2]            --
│    └─Empty: 2-188                      [16, 64, 2, 2]            --
│    └─Empty: 2-189                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-190         --                        --
│    └─One: 2-191                        [1]                       --
│    └─OutputScale: 2-192                --                        --
│    └─Empty: 2-193                      [64, 64, 1, 1]            --
│    └─Empty: 2-194                      [64, 64, 1, 1]            --
│    └─Empty: 2-195                      [64]                      --
│    └─Empty: 2-196                      [64]                      --
│    └─BatchNorm2d: 2-197                [16, 64, 2, 2]            --
│    └─Scaler: 2-198                     [16, 64, 2, 2]            --
│    └─ReLU: 2-199                       [16, 64, 2, 2]            --
│    └─Empty: 2-200                      [16, 64, 2, 2]            --
│    └─Clamp: 2-201                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-16                [16, 64, 2, 2]            4,166
│    └─OutputShiftSqueeze: 2-202         --                        --
│    └─One: 2-203                        [1]                       --
│    └─OutputScale: 2-204                --                        --
│    └─Empty: 2-205                      [64, 64, 1, 1]            --
│    └─Empty: 2-206                      [64, 64, 1, 1]            --
│    └─Empty: 2-207                      [64]                      --
│    └─Empty: 2-208                      [64]                      --
│    └─BatchNorm2d: 2-209                [16, 64, 2, 2]            --
│    └─Scaler: 2-210                     [16, 64, 2, 2]            --
│    └─ReLU: 2-211                       [16, 64, 2, 2]            --
│    └─Empty: 2-212                      [16, 64, 2, 2]            --
│    └─Clamp: 2-213                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-17         [16, 64, 2, 2]            36,934
│    └─MaxPool2d: 2-214                  [16, 64, 2, 2]            --
│    └─Empty: 2-215                      [16, 64, 2, 2]            --
│    └─Empty: 2-216                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-217         --                        --
│    └─One: 2-218                        [1]                       --
│    └─OutputScale: 2-219                --                        --
│    └─Empty: 2-220                      [64, 64, 3, 3]            --
│    └─Empty: 2-221                      [64, 64, 3, 3]            --
│    └─Empty: 2-222                      [64]                      --
│    └─Empty: 2-223                      [64]                      --
│    └─BatchNorm2d: 2-224                [16, 64, 2, 2]            --
│    └─Scaler: 2-225                     [16, 64, 2, 2]            --
│    └─ReLU: 2-226                       [16, 64, 2, 2]            --
│    └─Empty: 2-227                      [16, 64, 2, 2]            --
│    └─Clamp: 2-228                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-18                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-229         --                        --
│    └─One: 2-230                        [1]                       --
│    └─OutputScale: 2-231                --                        --
│    └─Empty: 2-232                      [64, 48, 1, 1]            --
│    └─Empty: 2-233                      [64, 48, 1, 1]            --
│    └─Empty: 2-234                      [64]                      --
│    └─Empty: 2-235                      [64]                      --
│    └─BatchNorm2d: 2-236                [16, 64, 64, 64]          --
│    └─Scaler: 2-237                     [16, 64, 64, 64]          --
│    └─ReLU: 2-238                       [16, 64, 64, 64]          --
│    └─Empty: 2-239                      [16, 64, 64, 64]          --
│    └─Clamp: 2-240                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-19                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-241         --                        --
│    └─One: 2-242                        [1]                       --
│    └─OutputScale: 2-243                --                        --
│    └─Empty: 2-244                      [64, 64, 3, 3]            --
│    └─Empty: 2-245                      [64, 64, 3, 3]            --
│    └─Empty: 2-246                      [64]                      --
│    └─Empty: 2-247                      [64]                      --
│    └─BatchNorm2d: 2-248                [16, 64, 64, 64]          --
│    └─Scaler: 2-249                     [16, 64, 64, 64]          --
│    └─ReLU: 2-250                       [16, 64, 64, 64]          --
│    └─Empty: 2-251                      [16, 64, 64, 64]          --
│    └─Clamp: 2-252                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-20                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-253         --                        --
│    └─One: 2-254                        [1]                       --
│    └─OutputScale: 2-255                --                        --
│    └─Empty: 2-256                      [64, 64, 1, 1]            --
│    └─Empty: 2-257                      [64, 64, 1, 1]            --
│    └─Empty: 2-258                      [64]                      --
│    └─Empty: 2-259                      [64]                      --
│    └─BatchNorm2d: 2-260                [16, 64, 64, 64]          --
│    └─Scaler: 2-261                     [16, 64, 64, 64]          --
│    └─ReLU: 2-262                       [16, 64, 64, 64]          --
│    └─Empty: 2-263                      [16, 64, 64, 64]          --
│    └─Clamp: 2-264                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-21                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-265         --                        --
│    └─One: 2-266                        [1]                       --
│    └─OutputScale: 2-267                --                        --
│    └─Empty: 2-268                      [64, 64, 3, 3]            --
│    └─Empty: 2-269                      [64, 64, 3, 3]            --
│    └─Empty: 2-270                      [64]                      --
│    └─Empty: 2-271                      [64]                      --
│    └─BatchNorm2d: 2-272                [16, 64, 64, 64]          --
│    └─Scaler: 2-273                     [16, 64, 64, 64]          --
│    └─ReLU: 2-274                       [16, 64, 64, 64]          --
│    └─Empty: 2-275                      [16, 64, 64, 64]          --
│    └─Clamp: 2-276                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-22         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-277                  [16, 64, 32, 32]          --
│    └─Empty: 2-278                      [16, 64, 32, 32]          --
│    └─Empty: 2-279                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-280         --                        --
│    └─One: 2-281                        [1]                       --
│    └─OutputScale: 2-282                --                        --
│    └─Empty: 2-283                      [64, 64, 3, 3]            --
│    └─Empty: 2-284                      [64, 64, 3, 3]            --
│    └─Empty: 2-285                      [64]                      --
│    └─Empty: 2-286                      [64]                      --
│    └─BatchNorm2d: 2-287                [16, 64, 32, 32]          --
│    └─Scaler: 2-288                     [16, 64, 32, 32]          --
│    └─ReLU: 2-289                       [16, 64, 32, 32]          --
│    └─Empty: 2-290                      [16, 64, 32, 32]          --
│    └─Clamp: 2-291                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-23                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-292         --                        --
│    └─One: 2-293                        [1]                       --
│    └─OutputScale: 2-294                --                        --
│    └─Empty: 2-295                      [64, 64, 3, 3]            --
│    └─Empty: 2-296                      [64, 64, 3, 3]            --
│    └─Empty: 2-297                      [64]                      --
│    └─Empty: 2-298                      [64]                      --
│    └─BatchNorm2d: 2-299                [16, 64, 32, 32]          --
│    └─Scaler: 2-300                     [16, 64, 32, 32]          --
│    └─ReLU: 2-301                       [16, 64, 32, 32]          --
│    └─Empty: 2-302                      [16, 64, 32, 32]          --
│    └─Clamp: 2-303                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-24         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-304                  [16, 64, 16, 16]          --
│    └─Empty: 2-305                      [16, 64, 16, 16]          --
│    └─Empty: 2-306                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-307         --                        --
│    └─One: 2-308                        [1]                       --
│    └─OutputScale: 2-309                --                        --
│    └─Empty: 2-310                      [64, 64, 3, 3]            --
│    └─Empty: 2-311                      [64, 64, 3, 3]            --
│    └─Empty: 2-312                      [64]                      --
│    └─Empty: 2-313                      [64]                      --
│    └─BatchNorm2d: 2-314                [16, 64, 16, 16]          --
│    └─Scaler: 2-315                     [16, 64, 16, 16]          --
│    └─ReLU: 2-316                       [16, 64, 16, 16]          --
│    └─Empty: 2-317                      [16, 64, 16, 16]          --
│    └─Clamp: 2-318                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-25                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-319         --                        --
│    └─One: 2-320                        [1]                       --
│    └─OutputScale: 2-321                --                        --
│    └─Empty: 2-322                      [64, 64, 3, 3]            --
│    └─Empty: 2-323                      [64, 64, 3, 3]            --
│    └─Empty: 2-324                      [64]                      --
│    └─Empty: 2-325                      [64]                      --
│    └─BatchNorm2d: 2-326                [16, 64, 16, 16]          --
│    └─Scaler: 2-327                     [16, 64, 16, 16]          --
│    └─ReLU: 2-328                       [16, 64, 16, 16]          --
│    └─Empty: 2-329                      [16, 64, 16, 16]          --
│    └─Clamp: 2-330                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-26         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-331                  [16, 64, 8, 8]            --
│    └─Empty: 2-332                      [16, 64, 8, 8]            --
│    └─Empty: 2-333                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-334         --                        --
│    └─One: 2-335                        [1]                       --
│    └─OutputScale: 2-336                --                        --
│    └─Empty: 2-337                      [64, 64, 3, 3]            --
│    └─Empty: 2-338                      [64, 64, 3, 3]            --
│    └─Empty: 2-339                      [64]                      --
│    └─Empty: 2-340                      [64]                      --
│    └─BatchNorm2d: 2-341                [16, 64, 8, 8]            --
│    └─Scaler: 2-342                     [16, 64, 8, 8]            --
│    └─ReLU: 2-343                       [16, 64, 8, 8]            --
│    └─Empty: 2-344                      [16, 64, 8, 8]            --
│    └─Clamp: 2-345                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-27                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-346         --                        --
│    └─One: 2-347                        [1]                       --
│    └─OutputScale: 2-348                --                        --
│    └─Empty: 2-349                      [64, 64, 1, 1]            --
│    └─Empty: 2-350                      [64, 64, 1, 1]            --
│    └─Empty: 2-351                      [64]                      --
│    └─Empty: 2-352                      [64]                      --
│    └─BatchNorm2d: 2-353                [16, 64, 8, 8]            --
│    └─Scaler: 2-354                     [16, 64, 8, 8]            --
│    └─ReLU: 2-355                       [16, 64, 8, 8]            --
│    └─Empty: 2-356                      [16, 64, 8, 8]            --
│    └─Clamp: 2-357                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-28         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-358                  [16, 64, 8, 8]            --
│    └─Empty: 2-359                      [16, 64, 8, 8]            --
│    └─Empty: 2-360                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-361         --                        --
│    └─One: 2-362                        [1]                       --
│    └─OutputScale: 2-363                --                        --
│    └─Empty: 2-364                      [64, 64, 3, 3]            --
│    └─Empty: 2-365                      [64, 64, 3, 3]            --
│    └─Empty: 2-366                      [64]                      --
│    └─Empty: 2-367                      [64]                      --
│    └─BatchNorm2d: 2-368                [16, 64, 8, 8]            --
│    └─Scaler: 2-369                     [16, 64, 8, 8]            --
│    └─ReLU: 2-370                       [16, 64, 8, 8]            --
│    └─Empty: 2-371                      [16, 64, 8, 8]            --
│    └─Clamp: 2-372                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-29         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-373                  [16, 64, 4, 4]            --
│    └─Empty: 2-374                      [16, 64, 4, 4]            --
│    └─Empty: 2-375                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-376         --                        --
│    └─One: 2-377                        [1]                       --
│    └─OutputScale: 2-378                --                        --
│    └─Empty: 2-379                      [64, 64, 3, 3]            --
│    └─Empty: 2-380                      [64, 64, 3, 3]            --
│    └─Empty: 2-381                      [64]                      --
│    └─Empty: 2-382                      [64]                      --
│    └─BatchNorm2d: 2-383                [16, 64, 4, 4]            --
│    └─Scaler: 2-384                     [16, 64, 4, 4]            --
│    └─ReLU: 2-385                       [16, 64, 4, 4]            --
│    └─Empty: 2-386                      [16, 64, 4, 4]            --
│    └─Clamp: 2-387                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-30                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-388         --                        --
│    └─One: 2-389                        [1]                       --
│    └─OutputScale: 2-390                --                        --
│    └─Empty: 2-391                      [64, 64, 1, 1]            --
│    └─Empty: 2-392                      [64, 64, 1, 1]            --
│    └─Empty: 2-393                      [64]                      --
│    └─Empty: 2-394                      [64]                      --
│    └─BatchNorm2d: 2-395                [16, 64, 4, 4]            --
│    └─Scaler: 2-396                     [16, 64, 4, 4]            --
│    └─ReLU: 2-397                       [16, 64, 4, 4]            --
│    └─Empty: 2-398                      [16, 64, 4, 4]            --
│    └─Clamp: 2-399                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-31         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-400                  [16, 64, 4, 4]            --
│    └─Empty: 2-401                      [16, 64, 4, 4]            --
│    └─Empty: 2-402                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-403         --                        --
│    └─One: 2-404                        [1]                       --
│    └─OutputScale: 2-405                --                        --
│    └─Empty: 2-406                      [64, 64, 3, 3]            --
│    └─Empty: 2-407                      [64, 64, 3, 3]            --
│    └─Empty: 2-408                      [64]                      --
│    └─Empty: 2-409                      [64]                      --
│    └─BatchNorm2d: 2-410                [16, 64, 4, 4]            --
│    └─Scaler: 2-411                     [16, 64, 4, 4]            --
│    └─ReLU: 2-412                       [16, 64, 4, 4]            --
│    └─Empty: 2-413                      [16, 64, 4, 4]            --
│    └─Clamp: 2-414                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-32         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-415                  [16, 64, 2, 2]            --
│    └─Empty: 2-416                      [16, 64, 2, 2]            --
│    └─Empty: 2-417                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-418         --                        --
│    └─One: 2-419                        [1]                       --
│    └─OutputScale: 2-420                --                        --
│    └─Empty: 2-421                      [64, 64, 1, 1]            --
│    └─Empty: 2-422                      [64, 64, 1, 1]            --
│    └─Empty: 2-423                      [64]                      --
│    └─Empty: 2-424                      [64]                      --
│    └─BatchNorm2d: 2-425                [16, 64, 2, 2]            --
│    └─Scaler: 2-426                     [16, 64, 2, 2]            --
│    └─ReLU: 2-427                       [16, 64, 2, 2]            --
│    └─Empty: 2-428                      [16, 64, 2, 2]            --
│    └─Clamp: 2-429                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-33                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-430         --                        --
│    └─One: 2-431                        [1]                       --
│    └─OutputScale: 2-432                --                        --
│    └─Empty: 2-433                      [64, 64, 1, 1]            --
│    └─Empty: 2-434                      [64, 64, 1, 1]            --
│    └─Empty: 2-435                      [64]                      --
│    └─Empty: 2-436                      [64]                      --
│    └─BatchNorm2d: 2-437                [16, 64, 2, 2]            --
│    └─Scaler: 2-438                     [16, 64, 2, 2]            --
│    └─ReLU: 2-439                       [16, 64, 2, 2]            --
│    └─Empty: 2-440                      [16, 64, 2, 2]            --
│    └─Clamp: 2-441                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-34         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-442                  [16, 64, 2, 2]            --
│    └─Empty: 2-443                      [16, 64, 2, 2]            --
│    └─Empty: 2-444                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-445         --                        --
│    └─One: 2-446                        [1]                       --
│    └─OutputScale: 2-447                --                        --
│    └─Empty: 2-448                      [64, 64, 3, 3]            --
│    └─Empty: 2-449                      [64, 64, 3, 3]            --
│    └─Empty: 2-450                      [64]                      --
│    └─Empty: 2-451                      [64]                      --
│    └─BatchNorm2d: 2-452                [16, 64, 2, 2]            --
│    └─Scaler: 2-453                     [16, 64, 2, 2]            --
│    └─ReLU: 2-454                       [16, 64, 2, 2]            --
│    └─Empty: 2-455                      [16, 64, 2, 2]            --
│    └─Clamp: 2-456                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-35                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-457         --                        --
│    └─One: 2-458                        [1]                       --
│    └─OutputScale: 2-459                --                        --
│    └─Empty: 2-460                      [64, 48, 1, 1]            --
│    └─Empty: 2-461                      [64, 48, 1, 1]            --
│    └─Empty: 2-462                      [64]                      --
│    └─Empty: 2-463                      [64]                      --
│    └─BatchNorm2d: 2-464                [16, 64, 64, 64]          --
│    └─Scaler: 2-465                     [16, 64, 64, 64]          --
│    └─ReLU: 2-466                       [16, 64, 64, 64]          --
│    └─Empty: 2-467                      [16, 64, 64, 64]          --
│    └─Clamp: 2-468                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-36                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-469         --                        --
│    └─One: 2-470                        [1]                       --
│    └─OutputScale: 2-471                --                        --
│    └─Empty: 2-472                      [64, 64, 3, 3]            --
│    └─Empty: 2-473                      [64, 64, 3, 3]            --
│    └─Empty: 2-474                      [64]                      --
│    └─Empty: 2-475                      [64]                      --
│    └─BatchNorm2d: 2-476                [16, 64, 64, 64]          --
│    └─Scaler: 2-477                     [16, 64, 64, 64]          --
│    └─ReLU: 2-478                       [16, 64, 64, 64]          --
│    └─Empty: 2-479                      [16, 64, 64, 64]          --
│    └─Clamp: 2-480                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-37                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-481         --                        --
│    └─One: 2-482                        [1]                       --
│    └─OutputScale: 2-483                --                        --
│    └─Empty: 2-484                      [64, 64, 1, 1]            --
│    └─Empty: 2-485                      [64, 64, 1, 1]            --
│    └─Empty: 2-486                      [64]                      --
│    └─Empty: 2-487                      [64]                      --
│    └─BatchNorm2d: 2-488                [16, 64, 64, 64]          --
│    └─Scaler: 2-489                     [16, 64, 64, 64]          --
│    └─ReLU: 2-490                       [16, 64, 64, 64]          --
│    └─Empty: 2-491                      [16, 64, 64, 64]          --
│    └─Clamp: 2-492                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-38                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-493         --                        --
│    └─One: 2-494                        [1]                       --
│    └─OutputScale: 2-495                --                        --
│    └─Empty: 2-496                      [64, 64, 3, 3]            --
│    └─Empty: 2-497                      [64, 64, 3, 3]            --
│    └─Empty: 2-498                      [64]                      --
│    └─Empty: 2-499                      [64]                      --
│    └─BatchNorm2d: 2-500                [16, 64, 64, 64]          --
│    └─Scaler: 2-501                     [16, 64, 64, 64]          --
│    └─ReLU: 2-502                       [16, 64, 64, 64]          --
│    └─Empty: 2-503                      [16, 64, 64, 64]          --
│    └─Clamp: 2-504                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-39         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-505                  [16, 64, 32, 32]          --
│    └─Empty: 2-506                      [16, 64, 32, 32]          --
│    └─Empty: 2-507                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-508         --                        --
│    └─One: 2-509                        [1]                       --
│    └─OutputScale: 2-510                --                        --
│    └─Empty: 2-511                      [64, 64, 3, 3]            --
│    └─Empty: 2-512                      [64, 64, 3, 3]            --
│    └─Empty: 2-513                      [64]                      --
│    └─Empty: 2-514                      [64]                      --
│    └─BatchNorm2d: 2-515                [16, 64, 32, 32]          --
│    └─Scaler: 2-516                     [16, 64, 32, 32]          --
│    └─ReLU: 2-517                       [16, 64, 32, 32]          --
│    └─Empty: 2-518                      [16, 64, 32, 32]          --
│    └─Clamp: 2-519                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-40                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-520         --                        --
│    └─One: 2-521                        [1]                       --
│    └─OutputScale: 2-522                --                        --
│    └─Empty: 2-523                      [64, 64, 3, 3]            --
│    └─Empty: 2-524                      [64, 64, 3, 3]            --
│    └─Empty: 2-525                      [64]                      --
│    └─Empty: 2-526                      [64]                      --
│    └─BatchNorm2d: 2-527                [16, 64, 32, 32]          --
│    └─Scaler: 2-528                     [16, 64, 32, 32]          --
│    └─ReLU: 2-529                       [16, 64, 32, 32]          --
│    └─Empty: 2-530                      [16, 64, 32, 32]          --
│    └─Clamp: 2-531                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-41         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-532                  [16, 64, 16, 16]          --
│    └─Empty: 2-533                      [16, 64, 16, 16]          --
│    └─Empty: 2-534                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-535         --                        --
│    └─One: 2-536                        [1]                       --
│    └─OutputScale: 2-537                --                        --
│    └─Empty: 2-538                      [64, 64, 3, 3]            --
│    └─Empty: 2-539                      [64, 64, 3, 3]            --
│    └─Empty: 2-540                      [64]                      --
│    └─Empty: 2-541                      [64]                      --
│    └─BatchNorm2d: 2-542                [16, 64, 16, 16]          --
│    └─Scaler: 2-543                     [16, 64, 16, 16]          --
│    └─ReLU: 2-544                       [16, 64, 16, 16]          --
│    └─Empty: 2-545                      [16, 64, 16, 16]          --
│    └─Clamp: 2-546                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-42                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-547         --                        --
│    └─One: 2-548                        [1]                       --
│    └─OutputScale: 2-549                --                        --
│    └─Empty: 2-550                      [64, 64, 3, 3]            --
│    └─Empty: 2-551                      [64, 64, 3, 3]            --
│    └─Empty: 2-552                      [64]                      --
│    └─Empty: 2-553                      [64]                      --
│    └─BatchNorm2d: 2-554                [16, 64, 16, 16]          --
│    └─Scaler: 2-555                     [16, 64, 16, 16]          --
│    └─ReLU: 2-556                       [16, 64, 16, 16]          --
│    └─Empty: 2-557                      [16, 64, 16, 16]          --
│    └─Clamp: 2-558                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-43         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-559                  [16, 64, 8, 8]            --
│    └─Empty: 2-560                      [16, 64, 8, 8]            --
│    └─Empty: 2-561                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-562         --                        --
│    └─One: 2-563                        [1]                       --
│    └─OutputScale: 2-564                --                        --
│    └─Empty: 2-565                      [64, 64, 3, 3]            --
│    └─Empty: 2-566                      [64, 64, 3, 3]            --
│    └─Empty: 2-567                      [64]                      --
│    └─Empty: 2-568                      [64]                      --
│    └─BatchNorm2d: 2-569                [16, 64, 8, 8]            --
│    └─Scaler: 2-570                     [16, 64, 8, 8]            --
│    └─ReLU: 2-571                       [16, 64, 8, 8]            --
│    └─Empty: 2-572                      [16, 64, 8, 8]            --
│    └─Clamp: 2-573                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-44                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-574         --                        --
│    └─One: 2-575                        [1]                       --
│    └─OutputScale: 2-576                --                        --
│    └─Empty: 2-577                      [64, 64, 1, 1]            --
│    └─Empty: 2-578                      [64, 64, 1, 1]            --
│    └─Empty: 2-579                      [64]                      --
│    └─Empty: 2-580                      [64]                      --
│    └─BatchNorm2d: 2-581                [16, 64, 8, 8]            --
│    └─Scaler: 2-582                     [16, 64, 8, 8]            --
│    └─ReLU: 2-583                       [16, 64, 8, 8]            --
│    └─Empty: 2-584                      [16, 64, 8, 8]            --
│    └─Clamp: 2-585                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-45         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-586                  [16, 64, 8, 8]            --
│    └─Empty: 2-587                      [16, 64, 8, 8]            --
│    └─Empty: 2-588                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-589         --                        --
│    └─One: 2-590                        [1]                       --
│    └─OutputScale: 2-591                --                        --
│    └─Empty: 2-592                      [64, 64, 3, 3]            --
│    └─Empty: 2-593                      [64, 64, 3, 3]            --
│    └─Empty: 2-594                      [64]                      --
│    └─Empty: 2-595                      [64]                      --
│    └─BatchNorm2d: 2-596                [16, 64, 8, 8]            --
│    └─Scaler: 2-597                     [16, 64, 8, 8]            --
│    └─ReLU: 2-598                       [16, 64, 8, 8]            --
│    └─Empty: 2-599                      [16, 64, 8, 8]            --
│    └─Clamp: 2-600                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-46         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-601                  [16, 64, 4, 4]            --
│    └─Empty: 2-602                      [16, 64, 4, 4]            --
│    └─Empty: 2-603                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-604         --                        --
│    └─One: 2-605                        [1]                       --
│    └─OutputScale: 2-606                --                        --
│    └─Empty: 2-607                      [64, 64, 3, 3]            --
│    └─Empty: 2-608                      [64, 64, 3, 3]            --
│    └─Empty: 2-609                      [64]                      --
│    └─Empty: 2-610                      [64]                      --
│    └─BatchNorm2d: 2-611                [16, 64, 4, 4]            --
│    └─Scaler: 2-612                     [16, 64, 4, 4]            --
│    └─ReLU: 2-613                       [16, 64, 4, 4]            --
│    └─Empty: 2-614                      [16, 64, 4, 4]            --
│    └─Clamp: 2-615                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-47                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-616         --                        --
│    └─One: 2-617                        [1]                       --
│    └─OutputScale: 2-618                --                        --
│    └─Empty: 2-619                      [64, 64, 1, 1]            --
│    └─Empty: 2-620                      [64, 64, 1, 1]            --
│    └─Empty: 2-621                      [64]                      --
│    └─Empty: 2-622                      [64]                      --
│    └─BatchNorm2d: 2-623                [16, 64, 4, 4]            --
│    └─Scaler: 2-624                     [16, 64, 4, 4]            --
│    └─ReLU: 2-625                       [16, 64, 4, 4]            --
│    └─Empty: 2-626                      [16, 64, 4, 4]            --
│    └─Clamp: 2-627                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-48         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-628                  [16, 64, 4, 4]            --
│    └─Empty: 2-629                      [16, 64, 4, 4]            --
│    └─Empty: 2-630                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-631         --                        --
│    └─One: 2-632                        [1]                       --
│    └─OutputScale: 2-633                --                        --
│    └─Empty: 2-634                      [64, 64, 3, 3]            --
│    └─Empty: 2-635                      [64, 64, 3, 3]            --
│    └─Empty: 2-636                      [64]                      --
│    └─Empty: 2-637                      [64]                      --
│    └─BatchNorm2d: 2-638                [16, 64, 4, 4]            --
│    └─Scaler: 2-639                     [16, 64, 4, 4]            --
│    └─ReLU: 2-640                       [16, 64, 4, 4]            --
│    └─Empty: 2-641                      [16, 64, 4, 4]            --
│    └─Clamp: 2-642                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-49         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-643                  [16, 64, 2, 2]            --
│    └─Empty: 2-644                      [16, 64, 2, 2]            --
│    └─Empty: 2-645                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-646         --                        --
│    └─One: 2-647                        [1]                       --
│    └─OutputScale: 2-648                --                        --
│    └─Empty: 2-649                      [64, 64, 1, 1]            --
│    └─Empty: 2-650                      [64, 64, 1, 1]            --
│    └─Empty: 2-651                      [64]                      --
│    └─Empty: 2-652                      [64]                      --
│    └─BatchNorm2d: 2-653                [16, 64, 2, 2]            --
│    └─Scaler: 2-654                     [16, 64, 2, 2]            --
│    └─ReLU: 2-655                       [16, 64, 2, 2]            --
│    └─Empty: 2-656                      [16, 64, 2, 2]            --
│    └─Clamp: 2-657                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-50                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-658         --                        --
│    └─One: 2-659                        [1]                       --
│    └─OutputScale: 2-660                --                        --
│    └─Empty: 2-661                      [64, 64, 1, 1]            --
│    └─Empty: 2-662                      [64, 64, 1, 1]            --
│    └─Empty: 2-663                      [64]                      --
│    └─Empty: 2-664                      [64]                      --
│    └─BatchNorm2d: 2-665                [16, 64, 2, 2]            --
│    └─Scaler: 2-666                     [16, 64, 2, 2]            --
│    └─ReLU: 2-667                       [16, 64, 2, 2]            --
│    └─Empty: 2-668                      [16, 64, 2, 2]            --
│    └─Clamp: 2-669                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-51         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-670                  [16, 64, 2, 2]            --
│    └─Empty: 2-671                      [16, 64, 2, 2]            --
│    └─Empty: 2-672                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-673         --                        --
│    └─One: 2-674                        [1]                       --
│    └─OutputScale: 2-675                --                        --
│    └─Empty: 2-676                      [64, 64, 3, 3]            --
│    └─Empty: 2-677                      [64, 64, 3, 3]            --
│    └─Empty: 2-678                      [64]                      --
│    └─Empty: 2-679                      [64]                      --
│    └─BatchNorm2d: 2-680                [16, 64, 2, 2]            --
│    └─Scaler: 2-681                     [16, 64, 2, 2]            --
│    └─ReLU: 2-682                       [16, 64, 2, 2]            --
│    └─Empty: 2-683                      [16, 64, 2, 2]            --
│    └─Clamp: 2-684                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-52                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-685         --                        --
│    └─One: 2-686                        [1]                       --
│    └─OutputScale: 2-687                --                        --
│    └─Empty: 2-688                      [64, 48, 1, 1]            --
│    └─Empty: 2-689                      [64, 48, 1, 1]            --
│    └─Empty: 2-690                      [64]                      --
│    └─Empty: 2-691                      [64]                      --
│    └─BatchNorm2d: 2-692                [16, 64, 64, 64]          --
│    └─Scaler: 2-693                     [16, 64, 64, 64]          --
│    └─ReLU: 2-694                       [16, 64, 64, 64]          --
│    └─Empty: 2-695                      [16, 64, 64, 64]          --
│    └─Clamp: 2-696                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-53                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-697         --                        --
│    └─One: 2-698                        [1]                       --
│    └─OutputScale: 2-699                --                        --
│    └─Empty: 2-700                      [64, 64, 3, 3]            --
│    └─Empty: 2-701                      [64, 64, 3, 3]            --
│    └─Empty: 2-702                      [64]                      --
│    └─Empty: 2-703                      [64]                      --
│    └─BatchNorm2d: 2-704                [16, 64, 64, 64]          --
│    └─Scaler: 2-705                     [16, 64, 64, 64]          --
│    └─ReLU: 2-706                       [16, 64, 64, 64]          --
│    └─Empty: 2-707                      [16, 64, 64, 64]          --
│    └─Clamp: 2-708                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-54                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-709         --                        --
│    └─One: 2-710                        [1]                       --
│    └─OutputScale: 2-711                --                        --
│    └─Empty: 2-712                      [64, 64, 1, 1]            --
│    └─Empty: 2-713                      [64, 64, 1, 1]            --
│    └─Empty: 2-714                      [64]                      --
│    └─Empty: 2-715                      [64]                      --
│    └─BatchNorm2d: 2-716                [16, 64, 64, 64]          --
│    └─Scaler: 2-717                     [16, 64, 64, 64]          --
│    └─ReLU: 2-718                       [16, 64, 64, 64]          --
│    └─Empty: 2-719                      [16, 64, 64, 64]          --
│    └─Clamp: 2-720                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-55                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-721         --                        --
│    └─One: 2-722                        [1]                       --
│    └─OutputScale: 2-723                --                        --
│    └─Empty: 2-724                      [64, 64, 3, 3]            --
│    └─Empty: 2-725                      [64, 64, 3, 3]            --
│    └─Empty: 2-726                      [64]                      --
│    └─Empty: 2-727                      [64]                      --
│    └─BatchNorm2d: 2-728                [16, 64, 64, 64]          --
│    └─Scaler: 2-729                     [16, 64, 64, 64]          --
│    └─ReLU: 2-730                       [16, 64, 64, 64]          --
│    └─Empty: 2-731                      [16, 64, 64, 64]          --
│    └─Clamp: 2-732                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-56         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-733                  [16, 64, 32, 32]          --
│    └─Empty: 2-734                      [16, 64, 32, 32]          --
│    └─Empty: 2-735                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-736         --                        --
│    └─One: 2-737                        [1]                       --
│    └─OutputScale: 2-738                --                        --
│    └─Empty: 2-739                      [64, 64, 3, 3]            --
│    └─Empty: 2-740                      [64, 64, 3, 3]            --
│    └─Empty: 2-741                      [64]                      --
│    └─Empty: 2-742                      [64]                      --
│    └─BatchNorm2d: 2-743                [16, 64, 32, 32]          --
│    └─Scaler: 2-744                     [16, 64, 32, 32]          --
│    └─ReLU: 2-745                       [16, 64, 32, 32]          --
│    └─Empty: 2-746                      [16, 64, 32, 32]          --
│    └─Clamp: 2-747                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-57                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-748         --                        --
│    └─One: 2-749                        [1]                       --
│    └─OutputScale: 2-750                --                        --
│    └─Empty: 2-751                      [64, 64, 3, 3]            --
│    └─Empty: 2-752                      [64, 64, 3, 3]            --
│    └─Empty: 2-753                      [64]                      --
│    └─Empty: 2-754                      [64]                      --
│    └─BatchNorm2d: 2-755                [16, 64, 32, 32]          --
│    └─Scaler: 2-756                     [16, 64, 32, 32]          --
│    └─ReLU: 2-757                       [16, 64, 32, 32]          --
│    └─Empty: 2-758                      [16, 64, 32, 32]          --
│    └─Clamp: 2-759                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-58         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-760                  [16, 64, 16, 16]          --
│    └─Empty: 2-761                      [16, 64, 16, 16]          --
│    └─Empty: 2-762                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-763         --                        --
│    └─One: 2-764                        [1]                       --
│    └─OutputScale: 2-765                --                        --
│    └─Empty: 2-766                      [64, 64, 3, 3]            --
│    └─Empty: 2-767                      [64, 64, 3, 3]            --
│    └─Empty: 2-768                      [64]                      --
│    └─Empty: 2-769                      [64]                      --
│    └─BatchNorm2d: 2-770                [16, 64, 16, 16]          --
│    └─Scaler: 2-771                     [16, 64, 16, 16]          --
│    └─ReLU: 2-772                       [16, 64, 16, 16]          --
│    └─Empty: 2-773                      [16, 64, 16, 16]          --
│    └─Clamp: 2-774                      [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-59                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-775         --                        --
│    └─One: 2-776                        [1]                       --
│    └─OutputScale: 2-777                --                        --
│    └─Empty: 2-778                      [64, 64, 3, 3]            --
│    └─Empty: 2-779                      [64, 64, 3, 3]            --
│    └─Empty: 2-780                      [64]                      --
│    └─Empty: 2-781                      [64]                      --
│    └─BatchNorm2d: 2-782                [16, 64, 16, 16]          --
│    └─Scaler: 2-783                     [16, 64, 16, 16]          --
│    └─ReLU: 2-784                       [16, 64, 16, 16]          --
│    └─Empty: 2-785                      [16, 64, 16, 16]          --
│    └─Clamp: 2-786                      [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-60         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-787                  [16, 64, 8, 8]            --
│    └─Empty: 2-788                      [16, 64, 8, 8]            --
│    └─Empty: 2-789                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-790         --                        --
│    └─One: 2-791                        [1]                       --
│    └─OutputScale: 2-792                --                        --
│    └─Empty: 2-793                      [64, 64, 3, 3]            --
│    └─Empty: 2-794                      [64, 64, 3, 3]            --
│    └─Empty: 2-795                      [64]                      --
│    └─Empty: 2-796                      [64]                      --
│    └─BatchNorm2d: 2-797                [16, 64, 8, 8]            --
│    └─Scaler: 2-798                     [16, 64, 8, 8]            --
│    └─ReLU: 2-799                       [16, 64, 8, 8]            --
│    └─Empty: 2-800                      [16, 64, 8, 8]            --
│    └─Clamp: 2-801                      [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-61                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-802         --                        --
│    └─One: 2-803                        [1]                       --
│    └─OutputScale: 2-804                --                        --
│    └─Empty: 2-805                      [64, 64, 1, 1]            --
│    └─Empty: 2-806                      [64, 64, 1, 1]            --
│    └─Empty: 2-807                      [64]                      --
│    └─Empty: 2-808                      [64]                      --
│    └─BatchNorm2d: 2-809                [16, 64, 8, 8]            --
│    └─Scaler: 2-810                     [16, 64, 8, 8]            --
│    └─ReLU: 2-811                       [16, 64, 8, 8]            --
│    └─Empty: 2-812                      [16, 64, 8, 8]            --
│    └─Clamp: 2-813                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-62         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-814                  [16, 64, 8, 8]            --
│    └─Empty: 2-815                      [16, 64, 8, 8]            --
│    └─Empty: 2-816                      [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-817         --                        --
│    └─One: 2-818                        [1]                       --
│    └─OutputScale: 2-819                --                        --
│    └─Empty: 2-820                      [64, 64, 3, 3]            --
│    └─Empty: 2-821                      [64, 64, 3, 3]            --
│    └─Empty: 2-822                      [64]                      --
│    └─Empty: 2-823                      [64]                      --
│    └─BatchNorm2d: 2-824                [16, 64, 8, 8]            --
│    └─Scaler: 2-825                     [16, 64, 8, 8]            --
│    └─ReLU: 2-826                       [16, 64, 8, 8]            --
│    └─Empty: 2-827                      [16, 64, 8, 8]            --
│    └─Clamp: 2-828                      [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-63         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-829                  [16, 64, 4, 4]            --
│    └─Empty: 2-830                      [16, 64, 4, 4]            --
│    └─Empty: 2-831                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-832         --                        --
│    └─One: 2-833                        [1]                       --
│    └─OutputScale: 2-834                --                        --
│    └─Empty: 2-835                      [64, 64, 3, 3]            --
│    └─Empty: 2-836                      [64, 64, 3, 3]            --
│    └─Empty: 2-837                      [64]                      --
│    └─Empty: 2-838                      [64]                      --
│    └─BatchNorm2d: 2-839                [16, 64, 4, 4]            --
│    └─Scaler: 2-840                     [16, 64, 4, 4]            --
│    └─ReLU: 2-841                       [16, 64, 4, 4]            --
│    └─Empty: 2-842                      [16, 64, 4, 4]            --
│    └─Clamp: 2-843                      [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-64                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-844         --                        --
│    └─One: 2-845                        [1]                       --
│    └─OutputScale: 2-846                --                        --
│    └─Empty: 2-847                      [64, 64, 1, 1]            --
│    └─Empty: 2-848                      [64, 64, 1, 1]            --
│    └─Empty: 2-849                      [64]                      --
│    └─Empty: 2-850                      [64]                      --
│    └─BatchNorm2d: 2-851                [16, 64, 4, 4]            --
│    └─Scaler: 2-852                     [16, 64, 4, 4]            --
│    └─ReLU: 2-853                       [16, 64, 4, 4]            --
│    └─Empty: 2-854                      [16, 64, 4, 4]            --
│    └─Clamp: 2-855                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-65         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-856                  [16, 64, 4, 4]            --
│    └─Empty: 2-857                      [16, 64, 4, 4]            --
│    └─Empty: 2-858                      [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-859         --                        --
│    └─One: 2-860                        [1]                       --
│    └─OutputScale: 2-861                --                        --
│    └─Empty: 2-862                      [64, 64, 3, 3]            --
│    └─Empty: 2-863                      [64, 64, 3, 3]            --
│    └─Empty: 2-864                      [64]                      --
│    └─Empty: 2-865                      [64]                      --
│    └─BatchNorm2d: 2-866                [16, 64, 4, 4]            --
│    └─Scaler: 2-867                     [16, 64, 4, 4]            --
│    └─ReLU: 2-868                       [16, 64, 4, 4]            --
│    └─Empty: 2-869                      [16, 64, 4, 4]            --
│    └─Clamp: 2-870                      [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-66         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-871                  [16, 64, 2, 2]            --
│    └─Empty: 2-872                      [16, 64, 2, 2]            --
│    └─Empty: 2-873                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-874         --                        --
│    └─One: 2-875                        [1]                       --
│    └─OutputScale: 2-876                --                        --
│    └─Empty: 2-877                      [64, 64, 1, 1]            --
│    └─Empty: 2-878                      [64, 64, 1, 1]            --
│    └─Empty: 2-879                      [64]                      --
│    └─Empty: 2-880                      [64]                      --
│    └─BatchNorm2d: 2-881                [16, 64, 2, 2]            --
│    └─Scaler: 2-882                     [16, 64, 2, 2]            --
│    └─ReLU: 2-883                       [16, 64, 2, 2]            --
│    └─Empty: 2-884                      [16, 64, 2, 2]            --
│    └─Clamp: 2-885                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-67                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-886         --                        --
│    └─One: 2-887                        [1]                       --
│    └─OutputScale: 2-888                --                        --
│    └─Empty: 2-889                      [64, 64, 1, 1]            --
│    └─Empty: 2-890                      [64, 64, 1, 1]            --
│    └─Empty: 2-891                      [64]                      --
│    └─Empty: 2-892                      [64]                      --
│    └─BatchNorm2d: 2-893                [16, 64, 2, 2]            --
│    └─Scaler: 2-894                     [16, 64, 2, 2]            --
│    └─ReLU: 2-895                       [16, 64, 2, 2]            --
│    └─Empty: 2-896                      [16, 64, 2, 2]            --
│    └─Clamp: 2-897                      [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-68         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-898                  [16, 64, 2, 2]            --
│    └─Empty: 2-899                      [16, 64, 2, 2]            --
│    └─Empty: 2-900                      [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-901         --                        --
│    └─One: 2-902                        [1]                       --
│    └─OutputScale: 2-903                --                        --
│    └─Empty: 2-904                      [64, 64, 3, 3]            --
│    └─Empty: 2-905                      [64, 64, 3, 3]            --
│    └─Empty: 2-906                      [64]                      --
│    └─Empty: 2-907                      [64]                      --
│    └─BatchNorm2d: 2-908                [16, 64, 2, 2]            --
│    └─Scaler: 2-909                     [16, 64, 2, 2]            --
│    └─ReLU: 2-910                       [16, 64, 2, 2]            --
│    └─Empty: 2-911                      [16, 64, 2, 2]            --
│    └─Clamp: 2-912                      [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-69                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-913         --                        --
│    └─One: 2-914                        [1]                       --
│    └─OutputScale: 2-915                --                        --
│    └─Empty: 2-916                      [64, 48, 1, 1]            --
│    └─Empty: 2-917                      [64, 48, 1, 1]            --
│    └─Empty: 2-918                      [64]                      --
│    └─Empty: 2-919                      [64]                      --
│    └─BatchNorm2d: 2-920                [16, 64, 64, 64]          --
│    └─Scaler: 2-921                     [16, 64, 64, 64]          --
│    └─ReLU: 2-922                       [16, 64, 64, 64]          --
│    └─Empty: 2-923                      [16, 64, 64, 64]          --
│    └─Clamp: 2-924                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-70                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-925         --                        --
│    └─One: 2-926                        [1]                       --
│    └─OutputScale: 2-927                --                        --
│    └─Empty: 2-928                      [64, 64, 3, 3]            --
│    └─Empty: 2-929                      [64, 64, 3, 3]            --
│    └─Empty: 2-930                      [64]                      --
│    └─Empty: 2-931                      [64]                      --
│    └─BatchNorm2d: 2-932                [16, 64, 64, 64]          --
│    └─Scaler: 2-933                     [16, 64, 64, 64]          --
│    └─ReLU: 2-934                       [16, 64, 64, 64]          --
│    └─Empty: 2-935                      [16, 64, 64, 64]          --
│    └─Clamp: 2-936                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-71                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-937         --                        --
│    └─One: 2-938                        [1]                       --
│    └─OutputScale: 2-939                --                        --
│    └─Empty: 2-940                      [64, 64, 1, 1]            --
│    └─Empty: 2-941                      [64, 64, 1, 1]            --
│    └─Empty: 2-942                      [64]                      --
│    └─Empty: 2-943                      [64]                      --
│    └─BatchNorm2d: 2-944                [16, 64, 64, 64]          --
│    └─Scaler: 2-945                     [16, 64, 64, 64]          --
│    └─ReLU: 2-946                       [16, 64, 64, 64]          --
│    └─Empty: 2-947                      [16, 64, 64, 64]          --
│    └─Clamp: 2-948                      [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-72                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-949         --                        --
│    └─One: 2-950                        [1]                       --
│    └─OutputScale: 2-951                --                        --
│    └─Empty: 2-952                      [64, 64, 3, 3]            --
│    └─Empty: 2-953                      [64, 64, 3, 3]            --
│    └─Empty: 2-954                      [64]                      --
│    └─Empty: 2-955                      [64]                      --
│    └─BatchNorm2d: 2-956                [16, 64, 64, 64]          --
│    └─Scaler: 2-957                     [16, 64, 64, 64]          --
│    └─ReLU: 2-958                       [16, 64, 64, 64]          --
│    └─Empty: 2-959                      [16, 64, 64, 64]          --
│    └─Clamp: 2-960                      [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-73         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-961                  [16, 64, 32, 32]          --
│    └─Empty: 2-962                      [16, 64, 32, 32]          --
│    └─Empty: 2-963                      [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-964         --                        --
│    └─One: 2-965                        [1]                       --
│    └─OutputScale: 2-966                --                        --
│    └─Empty: 2-967                      [64, 64, 3, 3]            --
│    └─Empty: 2-968                      [64, 64, 3, 3]            --
│    └─Empty: 2-969                      [64]                      --
│    └─Empty: 2-970                      [64]                      --
│    └─BatchNorm2d: 2-971                [16, 64, 32, 32]          --
│    └─Scaler: 2-972                     [16, 64, 32, 32]          --
│    └─ReLU: 2-973                       [16, 64, 32, 32]          --
│    └─Empty: 2-974                      [16, 64, 32, 32]          --
│    └─Clamp: 2-975                      [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-74                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-976         --                        --
│    └─One: 2-977                        [1]                       --
│    └─OutputScale: 2-978                --                        --
│    └─Empty: 2-979                      [64, 64, 3, 3]            --
│    └─Empty: 2-980                      [64, 64, 3, 3]            --
│    └─Empty: 2-981                      [64]                      --
│    └─Empty: 2-982                      [64]                      --
│    └─BatchNorm2d: 2-983                [16, 64, 32, 32]          --
│    └─Scaler: 2-984                     [16, 64, 32, 32]          --
│    └─ReLU: 2-985                       [16, 64, 32, 32]          --
│    └─Empty: 2-986                      [16, 64, 32, 32]          --
│    └─Clamp: 2-987                      [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-75         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-988                  [16, 64, 16, 16]          --
│    └─Empty: 2-989                      [16, 64, 16, 16]          --
│    └─Empty: 2-990                      [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-991         --                        --
│    └─One: 2-992                        [1]                       --
│    └─OutputScale: 2-993                --                        --
│    └─Empty: 2-994                      [64, 64, 3, 3]            --
│    └─Empty: 2-995                      [64, 64, 3, 3]            --
│    └─Empty: 2-996                      [64]                      --
│    └─Empty: 2-997                      [64]                      --
│    └─BatchNorm2d: 2-998                [16, 64, 16, 16]          --
│    └─Scaler: 2-999                     [16, 64, 16, 16]          --
│    └─ReLU: 2-1000                      [16, 64, 16, 16]          --
│    └─Empty: 2-1001                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1002                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-76                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1003        --                        --
│    └─One: 2-1004                       [1]                       --
│    └─OutputScale: 2-1005               --                        --
│    └─Empty: 2-1006                     [64, 64, 3, 3]            --
│    └─Empty: 2-1007                     [64, 64, 3, 3]            --
│    └─Empty: 2-1008                     [64]                      --
│    └─Empty: 2-1009                     [64]                      --
│    └─BatchNorm2d: 2-1010               [16, 64, 16, 16]          --
│    └─Scaler: 2-1011                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1012                      [16, 64, 16, 16]          --
│    └─Empty: 2-1013                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1014                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-77         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1015                 [16, 64, 8, 8]            --
│    └─Empty: 2-1016                     [16, 64, 8, 8]            --
│    └─Empty: 2-1017                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1018        --                        --
│    └─One: 2-1019                       [1]                       --
│    └─OutputScale: 2-1020               --                        --
│    └─Empty: 2-1021                     [64, 64, 3, 3]            --
│    └─Empty: 2-1022                     [64, 64, 3, 3]            --
│    └─Empty: 2-1023                     [64]                      --
│    └─Empty: 2-1024                     [64]                      --
│    └─BatchNorm2d: 2-1025               [16, 64, 8, 8]            --
│    └─Scaler: 2-1026                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1027                      [16, 64, 8, 8]            --
│    └─Empty: 2-1028                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1029                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-78                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1030        --                        --
│    └─One: 2-1031                       [1]                       --
│    └─OutputScale: 2-1032               --                        --
│    └─Empty: 2-1033                     [64, 64, 1, 1]            --
│    └─Empty: 2-1034                     [64, 64, 1, 1]            --
│    └─Empty: 2-1035                     [64]                      --
│    └─Empty: 2-1036                     [64]                      --
│    └─BatchNorm2d: 2-1037               [16, 64, 8, 8]            --
│    └─Scaler: 2-1038                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1039                      [16, 64, 8, 8]            --
│    └─Empty: 2-1040                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1041                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-79         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1042                 [16, 64, 8, 8]            --
│    └─Empty: 2-1043                     [16, 64, 8, 8]            --
│    └─Empty: 2-1044                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1045        --                        --
│    └─One: 2-1046                       [1]                       --
│    └─OutputScale: 2-1047               --                        --
│    └─Empty: 2-1048                     [64, 64, 3, 3]            --
│    └─Empty: 2-1049                     [64, 64, 3, 3]            --
│    └─Empty: 2-1050                     [64]                      --
│    └─Empty: 2-1051                     [64]                      --
│    └─BatchNorm2d: 2-1052               [16, 64, 8, 8]            --
│    └─Scaler: 2-1053                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1054                      [16, 64, 8, 8]            --
│    └─Empty: 2-1055                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1056                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-80         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1057                 [16, 64, 4, 4]            --
│    └─Empty: 2-1058                     [16, 64, 4, 4]            --
│    └─Empty: 2-1059                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1060        --                        --
│    └─One: 2-1061                       [1]                       --
│    └─OutputScale: 2-1062               --                        --
│    └─Empty: 2-1063                     [64, 64, 3, 3]            --
│    └─Empty: 2-1064                     [64, 64, 3, 3]            --
│    └─Empty: 2-1065                     [64]                      --
│    └─Empty: 2-1066                     [64]                      --
│    └─BatchNorm2d: 2-1067               [16, 64, 4, 4]            --
│    └─Scaler: 2-1068                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1069                      [16, 64, 4, 4]            --
│    └─Empty: 2-1070                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1071                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-81                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1072        --                        --
│    └─One: 2-1073                       [1]                       --
│    └─OutputScale: 2-1074               --                        --
│    └─Empty: 2-1075                     [64, 64, 1, 1]            --
│    └─Empty: 2-1076                     [64, 64, 1, 1]            --
│    └─Empty: 2-1077                     [64]                      --
│    └─Empty: 2-1078                     [64]                      --
│    └─BatchNorm2d: 2-1079               [16, 64, 4, 4]            --
│    └─Scaler: 2-1080                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1081                      [16, 64, 4, 4]            --
│    └─Empty: 2-1082                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1083                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-82         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1084                 [16, 64, 4, 4]            --
│    └─Empty: 2-1085                     [16, 64, 4, 4]            --
│    └─Empty: 2-1086                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1087        --                        --
│    └─One: 2-1088                       [1]                       --
│    └─OutputScale: 2-1089               --                        --
│    └─Empty: 2-1090                     [64, 64, 3, 3]            --
│    └─Empty: 2-1091                     [64, 64, 3, 3]            --
│    └─Empty: 2-1092                     [64]                      --
│    └─Empty: 2-1093                     [64]                      --
│    └─BatchNorm2d: 2-1094               [16, 64, 4, 4]            --
│    └─Scaler: 2-1095                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1096                      [16, 64, 4, 4]            --
│    └─Empty: 2-1097                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1098                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-83         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1099                 [16, 64, 2, 2]            --
│    └─Empty: 2-1100                     [16, 64, 2, 2]            --
│    └─Empty: 2-1101                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1102        --                        --
│    └─One: 2-1103                       [1]                       --
│    └─OutputScale: 2-1104               --                        --
│    └─Empty: 2-1105                     [64, 64, 1, 1]            --
│    └─Empty: 2-1106                     [64, 64, 1, 1]            --
│    └─Empty: 2-1107                     [64]                      --
│    └─Empty: 2-1108                     [64]                      --
│    └─BatchNorm2d: 2-1109               [16, 64, 2, 2]            --
│    └─Scaler: 2-1110                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1111                      [16, 64, 2, 2]            --
│    └─Empty: 2-1112                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1113                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-84                [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1114        --                        --
│    └─One: 2-1115                       [1]                       --
│    └─OutputScale: 2-1116               --                        --
│    └─Empty: 2-1117                     [64, 64, 1, 1]            --
│    └─Empty: 2-1118                     [64, 64, 1, 1]            --
│    └─Empty: 2-1119                     [64]                      --
│    └─Empty: 2-1120                     [64]                      --
│    └─BatchNorm2d: 2-1121               [16, 64, 2, 2]            --
│    └─Scaler: 2-1122                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1123                      [16, 64, 2, 2]            --
│    └─Empty: 2-1124                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1125                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-85         [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1126                 [16, 64, 2, 2]            --
│    └─Empty: 2-1127                     [16, 64, 2, 2]            --
│    └─Empty: 2-1128                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1129        --                        --
│    └─One: 2-1130                       [1]                       --
│    └─OutputScale: 2-1131               --                        --
│    └─Empty: 2-1132                     [64, 64, 3, 3]            --
│    └─Empty: 2-1133                     [64, 64, 3, 3]            --
│    └─Empty: 2-1134                     [64]                      --
│    └─Empty: 2-1135                     [64]                      --
│    └─BatchNorm2d: 2-1136               [16, 64, 2, 2]            --
│    └─Scaler: 2-1137                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1138                      [16, 64, 2, 2]            --
│    └─Empty: 2-1139                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1140                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-86                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1141        --                        --
│    └─One: 2-1142                       [1]                       --
│    └─OutputScale: 2-1143               --                        --
│    └─Empty: 2-1144                     [64, 48, 1, 1]            --
│    └─Empty: 2-1145                     [64, 48, 1, 1]            --
│    └─Empty: 2-1146                     [64]                      --
│    └─Empty: 2-1147                     [64]                      --
│    └─BatchNorm2d: 2-1148               [16, 64, 64, 64]          --
│    └─Scaler: 2-1149                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1150                      [16, 64, 64, 64]          --
│    └─Empty: 2-1151                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1152                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-87                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1153        --                        --
│    └─One: 2-1154                       [1]                       --
│    └─OutputScale: 2-1155               --                        --
│    └─Empty: 2-1156                     [64, 64, 3, 3]            --
│    └─Empty: 2-1157                     [64, 64, 3, 3]            --
│    └─Empty: 2-1158                     [64]                      --
│    └─Empty: 2-1159                     [64]                      --
│    └─BatchNorm2d: 2-1160               [16, 64, 64, 64]          --
│    └─Scaler: 2-1161                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1162                      [16, 64, 64, 64]          --
│    └─Empty: 2-1163                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1164                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-88                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1165        --                        --
│    └─One: 2-1166                       [1]                       --
│    └─OutputScale: 2-1167               --                        --
│    └─Empty: 2-1168                     [64, 64, 1, 1]            --
│    └─Empty: 2-1169                     [64, 64, 1, 1]            --
│    └─Empty: 2-1170                     [64]                      --
│    └─Empty: 2-1171                     [64]                      --
│    └─BatchNorm2d: 2-1172               [16, 64, 64, 64]          --
│    └─Scaler: 2-1173                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1174                      [16, 64, 64, 64]          --
│    └─Empty: 2-1175                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1176                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-89                [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1177        --                        --
│    └─One: 2-1178                       [1]                       --
│    └─OutputScale: 2-1179               --                        --
│    └─Empty: 2-1180                     [64, 64, 3, 3]            --
│    └─Empty: 2-1181                     [64, 64, 3, 3]            --
│    └─Empty: 2-1182                     [64]                      --
│    └─Empty: 2-1183                     [64]                      --
│    └─BatchNorm2d: 2-1184               [16, 64, 64, 64]          --
│    └─Scaler: 2-1185                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1186                      [16, 64, 64, 64]          --
│    └─Empty: 2-1187                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1188                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-90         [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1189                 [16, 64, 32, 32]          --
│    └─Empty: 2-1190                     [16, 64, 32, 32]          --
│    └─Empty: 2-1191                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1192        --                        --
│    └─One: 2-1193                       [1]                       --
│    └─OutputScale: 2-1194               --                        --
│    └─Empty: 2-1195                     [64, 64, 3, 3]            --
│    └─Empty: 2-1196                     [64, 64, 3, 3]            --
│    └─Empty: 2-1197                     [64]                      --
│    └─Empty: 2-1198                     [64]                      --
│    └─BatchNorm2d: 2-1199               [16, 64, 32, 32]          --
│    └─Scaler: 2-1200                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1201                      [16, 64, 32, 32]          --
│    └─Empty: 2-1202                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1203                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-91                [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1204        --                        --
│    └─One: 2-1205                       [1]                       --
│    └─OutputScale: 2-1206               --                        --
│    └─Empty: 2-1207                     [64, 64, 3, 3]            --
│    └─Empty: 2-1208                     [64, 64, 3, 3]            --
│    └─Empty: 2-1209                     [64]                      --
│    └─Empty: 2-1210                     [64]                      --
│    └─BatchNorm2d: 2-1211               [16, 64, 32, 32]          --
│    └─Scaler: 2-1212                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1213                      [16, 64, 32, 32]          --
│    └─Empty: 2-1214                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1215                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-92         [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1216                 [16, 64, 16, 16]          --
│    └─Empty: 2-1217                     [16, 64, 16, 16]          --
│    └─Empty: 2-1218                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1219        --                        --
│    └─One: 2-1220                       [1]                       --
│    └─OutputScale: 2-1221               --                        --
│    └─Empty: 2-1222                     [64, 64, 3, 3]            --
│    └─Empty: 2-1223                     [64, 64, 3, 3]            --
│    └─Empty: 2-1224                     [64]                      --
│    └─Empty: 2-1225                     [64]                      --
│    └─BatchNorm2d: 2-1226               [16, 64, 16, 16]          --
│    └─Scaler: 2-1227                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1228                      [16, 64, 16, 16]          --
│    └─Empty: 2-1229                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1230                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-93                [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1231        --                        --
│    └─One: 2-1232                       [1]                       --
│    └─OutputScale: 2-1233               --                        --
│    └─Empty: 2-1234                     [64, 64, 3, 3]            --
│    └─Empty: 2-1235                     [64, 64, 3, 3]            --
│    └─Empty: 2-1236                     [64]                      --
│    └─Empty: 2-1237                     [64]                      --
│    └─BatchNorm2d: 2-1238               [16, 64, 16, 16]          --
│    └─Scaler: 2-1239                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1240                      [16, 64, 16, 16]          --
│    └─Empty: 2-1241                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1242                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-94         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1243                 [16, 64, 8, 8]            --
│    └─Empty: 2-1244                     [16, 64, 8, 8]            --
│    └─Empty: 2-1245                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1246        --                        --
│    └─One: 2-1247                       [1]                       --
│    └─OutputScale: 2-1248               --                        --
│    └─Empty: 2-1249                     [64, 64, 3, 3]            --
│    └─Empty: 2-1250                     [64, 64, 3, 3]            --
│    └─Empty: 2-1251                     [64]                      --
│    └─Empty: 2-1252                     [64]                      --
│    └─BatchNorm2d: 2-1253               [16, 64, 8, 8]            --
│    └─Scaler: 2-1254                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1255                      [16, 64, 8, 8]            --
│    └─Empty: 2-1256                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1257                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-95                [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1258        --                        --
│    └─One: 2-1259                       [1]                       --
│    └─OutputScale: 2-1260               --                        --
│    └─Empty: 2-1261                     [64, 64, 1, 1]            --
│    └─Empty: 2-1262                     [64, 64, 1, 1]            --
│    └─Empty: 2-1263                     [64]                      --
│    └─Empty: 2-1264                     [64]                      --
│    └─BatchNorm2d: 2-1265               [16, 64, 8, 8]            --
│    └─Scaler: 2-1266                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1267                      [16, 64, 8, 8]            --
│    └─Empty: 2-1268                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1269                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-96         [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1270                 [16, 64, 8, 8]            --
│    └─Empty: 2-1271                     [16, 64, 8, 8]            --
│    └─Empty: 2-1272                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1273        --                        --
│    └─One: 2-1274                       [1]                       --
│    └─OutputScale: 2-1275               --                        --
│    └─Empty: 2-1276                     [64, 64, 3, 3]            --
│    └─Empty: 2-1277                     [64, 64, 3, 3]            --
│    └─Empty: 2-1278                     [64]                      --
│    └─Empty: 2-1279                     [64]                      --
│    └─BatchNorm2d: 2-1280               [16, 64, 8, 8]            --
│    └─Scaler: 2-1281                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1282                      [16, 64, 8, 8]            --
│    └─Empty: 2-1283                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1284                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-97         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1285                 [16, 64, 4, 4]            --
│    └─Empty: 2-1286                     [16, 64, 4, 4]            --
│    └─Empty: 2-1287                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1288        --                        --
│    └─One: 2-1289                       [1]                       --
│    └─OutputScale: 2-1290               --                        --
│    └─Empty: 2-1291                     [64, 64, 3, 3]            --
│    └─Empty: 2-1292                     [64, 64, 3, 3]            --
│    └─Empty: 2-1293                     [64]                      --
│    └─Empty: 2-1294                     [64]                      --
│    └─BatchNorm2d: 2-1295               [16, 64, 4, 4]            --
│    └─Scaler: 2-1296                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1297                      [16, 64, 4, 4]            --
│    └─Empty: 2-1298                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1299                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-98                [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1300        --                        --
│    └─One: 2-1301                       [1]                       --
│    └─OutputScale: 2-1302               --                        --
│    └─Empty: 2-1303                     [64, 64, 1, 1]            --
│    └─Empty: 2-1304                     [64, 64, 1, 1]            --
│    └─Empty: 2-1305                     [64]                      --
│    └─Empty: 2-1306                     [64]                      --
│    └─BatchNorm2d: 2-1307               [16, 64, 4, 4]            --
│    └─Scaler: 2-1308                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1309                      [16, 64, 4, 4]            --
│    └─Empty: 2-1310                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1311                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-99         [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1312                 [16, 64, 4, 4]            --
│    └─Empty: 2-1313                     [16, 64, 4, 4]            --
│    └─Empty: 2-1314                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1315        --                        --
│    └─One: 2-1316                       [1]                       --
│    └─OutputScale: 2-1317               --                        --
│    └─Empty: 2-1318                     [64, 64, 3, 3]            --
│    └─Empty: 2-1319                     [64, 64, 3, 3]            --
│    └─Empty: 2-1320                     [64]                      --
│    └─Empty: 2-1321                     [64]                      --
│    └─BatchNorm2d: 2-1322               [16, 64, 4, 4]            --
│    └─Scaler: 2-1323                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1324                      [16, 64, 4, 4]            --
│    └─Empty: 2-1325                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1326                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-100        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1327                 [16, 64, 2, 2]            --
│    └─Empty: 2-1328                     [16, 64, 2, 2]            --
│    └─Empty: 2-1329                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1330        --                        --
│    └─One: 2-1331                       [1]                       --
│    └─OutputScale: 2-1332               --                        --
│    └─Empty: 2-1333                     [64, 64, 1, 1]            --
│    └─Empty: 2-1334                     [64, 64, 1, 1]            --
│    └─Empty: 2-1335                     [64]                      --
│    └─Empty: 2-1336                     [64]                      --
│    └─BatchNorm2d: 2-1337               [16, 64, 2, 2]            --
│    └─Scaler: 2-1338                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1339                      [16, 64, 2, 2]            --
│    └─Empty: 2-1340                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1341                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-101               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1342        --                        --
│    └─One: 2-1343                       [1]                       --
│    └─OutputScale: 2-1344               --                        --
│    └─Empty: 2-1345                     [64, 64, 1, 1]            --
│    └─Empty: 2-1346                     [64, 64, 1, 1]            --
│    └─Empty: 2-1347                     [64]                      --
│    └─Empty: 2-1348                     [64]                      --
│    └─BatchNorm2d: 2-1349               [16, 64, 2, 2]            --
│    └─Scaler: 2-1350                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1351                      [16, 64, 2, 2]            --
│    └─Empty: 2-1352                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1353                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-102        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1354                 [16, 64, 2, 2]            --
│    └─Empty: 2-1355                     [16, 64, 2, 2]            --
│    └─Empty: 2-1356                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1357        --                        --
│    └─One: 2-1358                       [1]                       --
│    └─OutputScale: 2-1359               --                        --
│    └─Empty: 2-1360                     [64, 64, 3, 3]            --
│    └─Empty: 2-1361                     [64, 64, 3, 3]            --
│    └─Empty: 2-1362                     [64]                      --
│    └─Empty: 2-1363                     [64]                      --
│    └─BatchNorm2d: 2-1364               [16, 64, 2, 2]            --
│    └─Scaler: 2-1365                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1366                      [16, 64, 2, 2]            --
│    └─Empty: 2-1367                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1368                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-103               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1369        --                        --
│    └─One: 2-1370                       [1]                       --
│    └─OutputScale: 2-1371               --                        --
│    └─Empty: 2-1372                     [64, 48, 1, 1]            --
│    └─Empty: 2-1373                     [64, 48, 1, 1]            --
│    └─Empty: 2-1374                     [64]                      --
│    └─Empty: 2-1375                     [64]                      --
│    └─BatchNorm2d: 2-1376               [16, 64, 64, 64]          --
│    └─Scaler: 2-1377                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1378                      [16, 64, 64, 64]          --
│    └─Empty: 2-1379                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1380                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-104               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1381        --                        --
│    └─One: 2-1382                       [1]                       --
│    └─OutputScale: 2-1383               --                        --
│    └─Empty: 2-1384                     [64, 64, 3, 3]            --
│    └─Empty: 2-1385                     [64, 64, 3, 3]            --
│    └─Empty: 2-1386                     [64]                      --
│    └─Empty: 2-1387                     [64]                      --
│    └─BatchNorm2d: 2-1388               [16, 64, 64, 64]          --
│    └─Scaler: 2-1389                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1390                      [16, 64, 64, 64]          --
│    └─Empty: 2-1391                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1392                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-105               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1393        --                        --
│    └─One: 2-1394                       [1]                       --
│    └─OutputScale: 2-1395               --                        --
│    └─Empty: 2-1396                     [64, 64, 1, 1]            --
│    └─Empty: 2-1397                     [64, 64, 1, 1]            --
│    └─Empty: 2-1398                     [64]                      --
│    └─Empty: 2-1399                     [64]                      --
│    └─BatchNorm2d: 2-1400               [16, 64, 64, 64]          --
│    └─Scaler: 2-1401                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1402                      [16, 64, 64, 64]          --
│    └─Empty: 2-1403                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1404                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-106               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1405        --                        --
│    └─One: 2-1406                       [1]                       --
│    └─OutputScale: 2-1407               --                        --
│    └─Empty: 2-1408                     [64, 64, 3, 3]            --
│    └─Empty: 2-1409                     [64, 64, 3, 3]            --
│    └─Empty: 2-1410                     [64]                      --
│    └─Empty: 2-1411                     [64]                      --
│    └─BatchNorm2d: 2-1412               [16, 64, 64, 64]          --
│    └─Scaler: 2-1413                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1414                      [16, 64, 64, 64]          --
│    └─Empty: 2-1415                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1416                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-107        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1417                 [16, 64, 32, 32]          --
│    └─Empty: 2-1418                     [16, 64, 32, 32]          --
│    └─Empty: 2-1419                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1420        --                        --
│    └─One: 2-1421                       [1]                       --
│    └─OutputScale: 2-1422               --                        --
│    └─Empty: 2-1423                     [64, 64, 3, 3]            --
│    └─Empty: 2-1424                     [64, 64, 3, 3]            --
│    └─Empty: 2-1425                     [64]                      --
│    └─Empty: 2-1426                     [64]                      --
│    └─BatchNorm2d: 2-1427               [16, 64, 32, 32]          --
│    └─Scaler: 2-1428                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1429                      [16, 64, 32, 32]          --
│    └─Empty: 2-1430                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1431                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-108               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1432        --                        --
│    └─One: 2-1433                       [1]                       --
│    └─OutputScale: 2-1434               --                        --
│    └─Empty: 2-1435                     [64, 64, 3, 3]            --
│    └─Empty: 2-1436                     [64, 64, 3, 3]            --
│    └─Empty: 2-1437                     [64]                      --
│    └─Empty: 2-1438                     [64]                      --
│    └─BatchNorm2d: 2-1439               [16, 64, 32, 32]          --
│    └─Scaler: 2-1440                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1441                      [16, 64, 32, 32]          --
│    └─Empty: 2-1442                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1443                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-109        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1444                 [16, 64, 16, 16]          --
│    └─Empty: 2-1445                     [16, 64, 16, 16]          --
│    └─Empty: 2-1446                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1447        --                        --
│    └─One: 2-1448                       [1]                       --
│    └─OutputScale: 2-1449               --                        --
│    └─Empty: 2-1450                     [64, 64, 3, 3]            --
│    └─Empty: 2-1451                     [64, 64, 3, 3]            --
│    └─Empty: 2-1452                     [64]                      --
│    └─Empty: 2-1453                     [64]                      --
│    └─BatchNorm2d: 2-1454               [16, 64, 16, 16]          --
│    └─Scaler: 2-1455                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1456                      [16, 64, 16, 16]          --
│    └─Empty: 2-1457                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1458                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-110               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1459        --                        --
│    └─One: 2-1460                       [1]                       --
│    └─OutputScale: 2-1461               --                        --
│    └─Empty: 2-1462                     [64, 64, 3, 3]            --
│    └─Empty: 2-1463                     [64, 64, 3, 3]            --
│    └─Empty: 2-1464                     [64]                      --
│    └─Empty: 2-1465                     [64]                      --
│    └─BatchNorm2d: 2-1466               [16, 64, 16, 16]          --
│    └─Scaler: 2-1467                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1468                      [16, 64, 16, 16]          --
│    └─Empty: 2-1469                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1470                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-111        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1471                 [16, 64, 8, 8]            --
│    └─Empty: 2-1472                     [16, 64, 8, 8]            --
│    └─Empty: 2-1473                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1474        --                        --
│    └─One: 2-1475                       [1]                       --
│    └─OutputScale: 2-1476               --                        --
│    └─Empty: 2-1477                     [64, 64, 3, 3]            --
│    └─Empty: 2-1478                     [64, 64, 3, 3]            --
│    └─Empty: 2-1479                     [64]                      --
│    └─Empty: 2-1480                     [64]                      --
│    └─BatchNorm2d: 2-1481               [16, 64, 8, 8]            --
│    └─Scaler: 2-1482                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1483                      [16, 64, 8, 8]            --
│    └─Empty: 2-1484                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1485                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-112               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1486        --                        --
│    └─One: 2-1487                       [1]                       --
│    └─OutputScale: 2-1488               --                        --
│    └─Empty: 2-1489                     [64, 64, 1, 1]            --
│    └─Empty: 2-1490                     [64, 64, 1, 1]            --
│    └─Empty: 2-1491                     [64]                      --
│    └─Empty: 2-1492                     [64]                      --
│    └─BatchNorm2d: 2-1493               [16, 64, 8, 8]            --
│    └─Scaler: 2-1494                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1495                      [16, 64, 8, 8]            --
│    └─Empty: 2-1496                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1497                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-113        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1498                 [16, 64, 8, 8]            --
│    └─Empty: 2-1499                     [16, 64, 8, 8]            --
│    └─Empty: 2-1500                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1501        --                        --
│    └─One: 2-1502                       [1]                       --
│    └─OutputScale: 2-1503               --                        --
│    └─Empty: 2-1504                     [64, 64, 3, 3]            --
│    └─Empty: 2-1505                     [64, 64, 3, 3]            --
│    └─Empty: 2-1506                     [64]                      --
│    └─Empty: 2-1507                     [64]                      --
│    └─BatchNorm2d: 2-1508               [16, 64, 8, 8]            --
│    └─Scaler: 2-1509                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1510                      [16, 64, 8, 8]            --
│    └─Empty: 2-1511                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1512                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-114        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1513                 [16, 64, 4, 4]            --
│    └─Empty: 2-1514                     [16, 64, 4, 4]            --
│    └─Empty: 2-1515                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1516        --                        --
│    └─One: 2-1517                       [1]                       --
│    └─OutputScale: 2-1518               --                        --
│    └─Empty: 2-1519                     [64, 64, 3, 3]            --
│    └─Empty: 2-1520                     [64, 64, 3, 3]            --
│    └─Empty: 2-1521                     [64]                      --
│    └─Empty: 2-1522                     [64]                      --
│    └─BatchNorm2d: 2-1523               [16, 64, 4, 4]            --
│    └─Scaler: 2-1524                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1525                      [16, 64, 4, 4]            --
│    └─Empty: 2-1526                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1527                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-115               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1528        --                        --
│    └─One: 2-1529                       [1]                       --
│    └─OutputScale: 2-1530               --                        --
│    └─Empty: 2-1531                     [64, 64, 1, 1]            --
│    └─Empty: 2-1532                     [64, 64, 1, 1]            --
│    └─Empty: 2-1533                     [64]                      --
│    └─Empty: 2-1534                     [64]                      --
│    └─BatchNorm2d: 2-1535               [16, 64, 4, 4]            --
│    └─Scaler: 2-1536                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1537                      [16, 64, 4, 4]            --
│    └─Empty: 2-1538                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1539                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-116        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1540                 [16, 64, 4, 4]            --
│    └─Empty: 2-1541                     [16, 64, 4, 4]            --
│    └─Empty: 2-1542                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1543        --                        --
│    └─One: 2-1544                       [1]                       --
│    └─OutputScale: 2-1545               --                        --
│    └─Empty: 2-1546                     [64, 64, 3, 3]            --
│    └─Empty: 2-1547                     [64, 64, 3, 3]            --
│    └─Empty: 2-1548                     [64]                      --
│    └─Empty: 2-1549                     [64]                      --
│    └─BatchNorm2d: 2-1550               [16, 64, 4, 4]            --
│    └─Scaler: 2-1551                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1552                      [16, 64, 4, 4]            --
│    └─Empty: 2-1553                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1554                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-117        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1555                 [16, 64, 2, 2]            --
│    └─Empty: 2-1556                     [16, 64, 2, 2]            --
│    └─Empty: 2-1557                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1558        --                        --
│    └─One: 2-1559                       [1]                       --
│    └─OutputScale: 2-1560               --                        --
│    └─Empty: 2-1561                     [64, 64, 1, 1]            --
│    └─Empty: 2-1562                     [64, 64, 1, 1]            --
│    └─Empty: 2-1563                     [64]                      --
│    └─Empty: 2-1564                     [64]                      --
│    └─BatchNorm2d: 2-1565               [16, 64, 2, 2]            --
│    └─Scaler: 2-1566                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1567                      [16, 64, 2, 2]            --
│    └─Empty: 2-1568                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1569                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-118               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1570        --                        --
│    └─One: 2-1571                       [1]                       --
│    └─OutputScale: 2-1572               --                        --
│    └─Empty: 2-1573                     [64, 64, 1, 1]            --
│    └─Empty: 2-1574                     [64, 64, 1, 1]            --
│    └─Empty: 2-1575                     [64]                      --
│    └─Empty: 2-1576                     [64]                      --
│    └─BatchNorm2d: 2-1577               [16, 64, 2, 2]            --
│    └─Scaler: 2-1578                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1579                      [16, 64, 2, 2]            --
│    └─Empty: 2-1580                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1581                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-119        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1582                 [16, 64, 2, 2]            --
│    └─Empty: 2-1583                     [16, 64, 2, 2]            --
│    └─Empty: 2-1584                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1585        --                        --
│    └─One: 2-1586                       [1]                       --
│    └─OutputScale: 2-1587               --                        --
│    └─Empty: 2-1588                     [64, 64, 3, 3]            --
│    └─Empty: 2-1589                     [64, 64, 3, 3]            --
│    └─Empty: 2-1590                     [64]                      --
│    └─Empty: 2-1591                     [64]                      --
│    └─BatchNorm2d: 2-1592               [16, 64, 2, 2]            --
│    └─Scaler: 2-1593                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1594                      [16, 64, 2, 2]            --
│    └─Empty: 2-1595                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1596                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-120               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1597        --                        --
│    └─One: 2-1598                       [1]                       --
│    └─OutputScale: 2-1599               --                        --
│    └─Empty: 2-1600                     [64, 48, 1, 1]            --
│    └─Empty: 2-1601                     [64, 48, 1, 1]            --
│    └─Empty: 2-1602                     [64]                      --
│    └─Empty: 2-1603                     [64]                      --
│    └─BatchNorm2d: 2-1604               [16, 64, 64, 64]          --
│    └─Scaler: 2-1605                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1606                      [16, 64, 64, 64]          --
│    └─Empty: 2-1607                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1608                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-121               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1609        --                        --
│    └─One: 2-1610                       [1]                       --
│    └─OutputScale: 2-1611               --                        --
│    └─Empty: 2-1612                     [64, 64, 3, 3]            --
│    └─Empty: 2-1613                     [64, 64, 3, 3]            --
│    └─Empty: 2-1614                     [64]                      --
│    └─Empty: 2-1615                     [64]                      --
│    └─BatchNorm2d: 2-1616               [16, 64, 64, 64]          --
│    └─Scaler: 2-1617                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1618                      [16, 64, 64, 64]          --
│    └─Empty: 2-1619                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1620                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-122               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1621        --                        --
│    └─One: 2-1622                       [1]                       --
│    └─OutputScale: 2-1623               --                        --
│    └─Empty: 2-1624                     [64, 64, 1, 1]            --
│    └─Empty: 2-1625                     [64, 64, 1, 1]            --
│    └─Empty: 2-1626                     [64]                      --
│    └─Empty: 2-1627                     [64]                      --
│    └─BatchNorm2d: 2-1628               [16, 64, 64, 64]          --
│    └─Scaler: 2-1629                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1630                      [16, 64, 64, 64]          --
│    └─Empty: 2-1631                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1632                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-123               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1633        --                        --
│    └─One: 2-1634                       [1]                       --
│    └─OutputScale: 2-1635               --                        --
│    └─Empty: 2-1636                     [64, 64, 3, 3]            --
│    └─Empty: 2-1637                     [64, 64, 3, 3]            --
│    └─Empty: 2-1638                     [64]                      --
│    └─Empty: 2-1639                     [64]                      --
│    └─BatchNorm2d: 2-1640               [16, 64, 64, 64]          --
│    └─Scaler: 2-1641                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1642                      [16, 64, 64, 64]          --
│    └─Empty: 2-1643                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1644                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-124        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1645                 [16, 64, 32, 32]          --
│    └─Empty: 2-1646                     [16, 64, 32, 32]          --
│    └─Empty: 2-1647                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1648        --                        --
│    └─One: 2-1649                       [1]                       --
│    └─OutputScale: 2-1650               --                        --
│    └─Empty: 2-1651                     [64, 64, 3, 3]            --
│    └─Empty: 2-1652                     [64, 64, 3, 3]            --
│    └─Empty: 2-1653                     [64]                      --
│    └─Empty: 2-1654                     [64]                      --
│    └─BatchNorm2d: 2-1655               [16, 64, 32, 32]          --
│    └─Scaler: 2-1656                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1657                      [16, 64, 32, 32]          --
│    └─Empty: 2-1658                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1659                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-125               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1660        --                        --
│    └─One: 2-1661                       [1]                       --
│    └─OutputScale: 2-1662               --                        --
│    └─Empty: 2-1663                     [64, 64, 3, 3]            --
│    └─Empty: 2-1664                     [64, 64, 3, 3]            --
│    └─Empty: 2-1665                     [64]                      --
│    └─Empty: 2-1666                     [64]                      --
│    └─BatchNorm2d: 2-1667               [16, 64, 32, 32]          --
│    └─Scaler: 2-1668                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1669                      [16, 64, 32, 32]          --
│    └─Empty: 2-1670                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1671                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-126        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1672                 [16, 64, 16, 16]          --
│    └─Empty: 2-1673                     [16, 64, 16, 16]          --
│    └─Empty: 2-1674                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1675        --                        --
│    └─One: 2-1676                       [1]                       --
│    └─OutputScale: 2-1677               --                        --
│    └─Empty: 2-1678                     [64, 64, 3, 3]            --
│    └─Empty: 2-1679                     [64, 64, 3, 3]            --
│    └─Empty: 2-1680                     [64]                      --
│    └─Empty: 2-1681                     [64]                      --
│    └─BatchNorm2d: 2-1682               [16, 64, 16, 16]          --
│    └─Scaler: 2-1683                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1684                      [16, 64, 16, 16]          --
│    └─Empty: 2-1685                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1686                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-127               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1687        --                        --
│    └─One: 2-1688                       [1]                       --
│    └─OutputScale: 2-1689               --                        --
│    └─Empty: 2-1690                     [64, 64, 3, 3]            --
│    └─Empty: 2-1691                     [64, 64, 3, 3]            --
│    └─Empty: 2-1692                     [64]                      --
│    └─Empty: 2-1693                     [64]                      --
│    └─BatchNorm2d: 2-1694               [16, 64, 16, 16]          --
│    └─Scaler: 2-1695                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1696                      [16, 64, 16, 16]          --
│    └─Empty: 2-1697                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1698                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-128        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1699                 [16, 64, 8, 8]            --
│    └─Empty: 2-1700                     [16, 64, 8, 8]            --
│    └─Empty: 2-1701                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1702        --                        --
│    └─One: 2-1703                       [1]                       --
│    └─OutputScale: 2-1704               --                        --
│    └─Empty: 2-1705                     [64, 64, 3, 3]            --
│    └─Empty: 2-1706                     [64, 64, 3, 3]            --
│    └─Empty: 2-1707                     [64]                      --
│    └─Empty: 2-1708                     [64]                      --
│    └─BatchNorm2d: 2-1709               [16, 64, 8, 8]            --
│    └─Scaler: 2-1710                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1711                      [16, 64, 8, 8]            --
│    └─Empty: 2-1712                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1713                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-129               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1714        --                        --
│    └─One: 2-1715                       [1]                       --
│    └─OutputScale: 2-1716               --                        --
│    └─Empty: 2-1717                     [64, 64, 1, 1]            --
│    └─Empty: 2-1718                     [64, 64, 1, 1]            --
│    └─Empty: 2-1719                     [64]                      --
│    └─Empty: 2-1720                     [64]                      --
│    └─BatchNorm2d: 2-1721               [16, 64, 8, 8]            --
│    └─Scaler: 2-1722                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1723                      [16, 64, 8, 8]            --
│    └─Empty: 2-1724                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1725                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-130        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1726                 [16, 64, 8, 8]            --
│    └─Empty: 2-1727                     [16, 64, 8, 8]            --
│    └─Empty: 2-1728                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1729        --                        --
│    └─One: 2-1730                       [1]                       --
│    └─OutputScale: 2-1731               --                        --
│    └─Empty: 2-1732                     [64, 64, 3, 3]            --
│    └─Empty: 2-1733                     [64, 64, 3, 3]            --
│    └─Empty: 2-1734                     [64]                      --
│    └─Empty: 2-1735                     [64]                      --
│    └─BatchNorm2d: 2-1736               [16, 64, 8, 8]            --
│    └─Scaler: 2-1737                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1738                      [16, 64, 8, 8]            --
│    └─Empty: 2-1739                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1740                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-131        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1741                 [16, 64, 4, 4]            --
│    └─Empty: 2-1742                     [16, 64, 4, 4]            --
│    └─Empty: 2-1743                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1744        --                        --
│    └─One: 2-1745                       [1]                       --
│    └─OutputScale: 2-1746               --                        --
│    └─Empty: 2-1747                     [64, 64, 3, 3]            --
│    └─Empty: 2-1748                     [64, 64, 3, 3]            --
│    └─Empty: 2-1749                     [64]                      --
│    └─Empty: 2-1750                     [64]                      --
│    └─BatchNorm2d: 2-1751               [16, 64, 4, 4]            --
│    └─Scaler: 2-1752                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1753                      [16, 64, 4, 4]            --
│    └─Empty: 2-1754                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1755                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-132               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1756        --                        --
│    └─One: 2-1757                       [1]                       --
│    └─OutputScale: 2-1758               --                        --
│    └─Empty: 2-1759                     [64, 64, 1, 1]            --
│    └─Empty: 2-1760                     [64, 64, 1, 1]            --
│    └─Empty: 2-1761                     [64]                      --
│    └─Empty: 2-1762                     [64]                      --
│    └─BatchNorm2d: 2-1763               [16, 64, 4, 4]            --
│    └─Scaler: 2-1764                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1765                      [16, 64, 4, 4]            --
│    └─Empty: 2-1766                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1767                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-133        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1768                 [16, 64, 4, 4]            --
│    └─Empty: 2-1769                     [16, 64, 4, 4]            --
│    └─Empty: 2-1770                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1771        --                        --
│    └─One: 2-1772                       [1]                       --
│    └─OutputScale: 2-1773               --                        --
│    └─Empty: 2-1774                     [64, 64, 3, 3]            --
│    └─Empty: 2-1775                     [64, 64, 3, 3]            --
│    └─Empty: 2-1776                     [64]                      --
│    └─Empty: 2-1777                     [64]                      --
│    └─BatchNorm2d: 2-1778               [16, 64, 4, 4]            --
│    └─Scaler: 2-1779                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1780                      [16, 64, 4, 4]            --
│    └─Empty: 2-1781                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1782                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-134        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1783                 [16, 64, 2, 2]            --
│    └─Empty: 2-1784                     [16, 64, 2, 2]            --
│    └─Empty: 2-1785                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1786        --                        --
│    └─One: 2-1787                       [1]                       --
│    └─OutputScale: 2-1788               --                        --
│    └─Empty: 2-1789                     [64, 64, 1, 1]            --
│    └─Empty: 2-1790                     [64, 64, 1, 1]            --
│    └─Empty: 2-1791                     [64]                      --
│    └─Empty: 2-1792                     [64]                      --
│    └─BatchNorm2d: 2-1793               [16, 64, 2, 2]            --
│    └─Scaler: 2-1794                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1795                      [16, 64, 2, 2]            --
│    └─Empty: 2-1796                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1797                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-135               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-1798        --                        --
│    └─One: 2-1799                       [1]                       --
│    └─OutputScale: 2-1800               --                        --
│    └─Empty: 2-1801                     [64, 64, 1, 1]            --
│    └─Empty: 2-1802                     [64, 64, 1, 1]            --
│    └─Empty: 2-1803                     [64]                      --
│    └─Empty: 2-1804                     [64]                      --
│    └─BatchNorm2d: 2-1805               [16, 64, 2, 2]            --
│    └─Scaler: 2-1806                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1807                      [16, 64, 2, 2]            --
│    └─Empty: 2-1808                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1809                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-136        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-1810                 [16, 64, 2, 2]            --
│    └─Empty: 2-1811                     [16, 64, 2, 2]            --
│    └─Empty: 2-1812                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-1813        --                        --
│    └─One: 2-1814                       [1]                       --
│    └─OutputScale: 2-1815               --                        --
│    └─Empty: 2-1816                     [64, 64, 3, 3]            --
│    └─Empty: 2-1817                     [64, 64, 3, 3]            --
│    └─Empty: 2-1818                     [64]                      --
│    └─Empty: 2-1819                     [64]                      --
│    └─BatchNorm2d: 2-1820               [16, 64, 2, 2]            --
│    └─Scaler: 2-1821                    [16, 64, 2, 2]            --
│    └─ReLU: 2-1822                      [16, 64, 2, 2]            --
│    └─Empty: 2-1823                     [16, 64, 2, 2]            --
│    └─Clamp: 2-1824                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-137               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1825        --                        --
│    └─One: 2-1826                       [1]                       --
│    └─OutputScale: 2-1827               --                        --
│    └─Empty: 2-1828                     [64, 48, 1, 1]            --
│    └─Empty: 2-1829                     [64, 48, 1, 1]            --
│    └─Empty: 2-1830                     [64]                      --
│    └─Empty: 2-1831                     [64]                      --
│    └─BatchNorm2d: 2-1832               [16, 64, 64, 64]          --
│    └─Scaler: 2-1833                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1834                      [16, 64, 64, 64]          --
│    └─Empty: 2-1835                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1836                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-138               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1837        --                        --
│    └─One: 2-1838                       [1]                       --
│    └─OutputScale: 2-1839               --                        --
│    └─Empty: 2-1840                     [64, 64, 3, 3]            --
│    └─Empty: 2-1841                     [64, 64, 3, 3]            --
│    └─Empty: 2-1842                     [64]                      --
│    └─Empty: 2-1843                     [64]                      --
│    └─BatchNorm2d: 2-1844               [16, 64, 64, 64]          --
│    └─Scaler: 2-1845                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1846                      [16, 64, 64, 64]          --
│    └─Empty: 2-1847                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1848                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-139               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1849        --                        --
│    └─One: 2-1850                       [1]                       --
│    └─OutputScale: 2-1851               --                        --
│    └─Empty: 2-1852                     [64, 64, 1, 1]            --
│    └─Empty: 2-1853                     [64, 64, 1, 1]            --
│    └─Empty: 2-1854                     [64]                      --
│    └─Empty: 2-1855                     [64]                      --
│    └─BatchNorm2d: 2-1856               [16, 64, 64, 64]          --
│    └─Scaler: 2-1857                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1858                      [16, 64, 64, 64]          --
│    └─Empty: 2-1859                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1860                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-140               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-1861        --                        --
│    └─One: 2-1862                       [1]                       --
│    └─OutputScale: 2-1863               --                        --
│    └─Empty: 2-1864                     [64, 64, 3, 3]            --
│    └─Empty: 2-1865                     [64, 64, 3, 3]            --
│    └─Empty: 2-1866                     [64]                      --
│    └─Empty: 2-1867                     [64]                      --
│    └─BatchNorm2d: 2-1868               [16, 64, 64, 64]          --
│    └─Scaler: 2-1869                    [16, 64, 64, 64]          --
│    └─ReLU: 2-1870                      [16, 64, 64, 64]          --
│    └─Empty: 2-1871                     [16, 64, 64, 64]          --
│    └─Clamp: 2-1872                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-141        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-1873                 [16, 64, 32, 32]          --
│    └─Empty: 2-1874                     [16, 64, 32, 32]          --
│    └─Empty: 2-1875                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-1876        --                        --
│    └─One: 2-1877                       [1]                       --
│    └─OutputScale: 2-1878               --                        --
│    └─Empty: 2-1879                     [64, 64, 3, 3]            --
│    └─Empty: 2-1880                     [64, 64, 3, 3]            --
│    └─Empty: 2-1881                     [64]                      --
│    └─Empty: 2-1882                     [64]                      --
│    └─BatchNorm2d: 2-1883               [16, 64, 32, 32]          --
│    └─Scaler: 2-1884                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1885                      [16, 64, 32, 32]          --
│    └─Empty: 2-1886                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1887                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-142               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-1888        --                        --
│    └─One: 2-1889                       [1]                       --
│    └─OutputScale: 2-1890               --                        --
│    └─Empty: 2-1891                     [64, 64, 3, 3]            --
│    └─Empty: 2-1892                     [64, 64, 3, 3]            --
│    └─Empty: 2-1893                     [64]                      --
│    └─Empty: 2-1894                     [64]                      --
│    └─BatchNorm2d: 2-1895               [16, 64, 32, 32]          --
│    └─Scaler: 2-1896                    [16, 64, 32, 32]          --
│    └─ReLU: 2-1897                      [16, 64, 32, 32]          --
│    └─Empty: 2-1898                     [16, 64, 32, 32]          --
│    └─Clamp: 2-1899                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-143        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-1900                 [16, 64, 16, 16]          --
│    └─Empty: 2-1901                     [16, 64, 16, 16]          --
│    └─Empty: 2-1902                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-1903        --                        --
│    └─One: 2-1904                       [1]                       --
│    └─OutputScale: 2-1905               --                        --
│    └─Empty: 2-1906                     [64, 64, 3, 3]            --
│    └─Empty: 2-1907                     [64, 64, 3, 3]            --
│    └─Empty: 2-1908                     [64]                      --
│    └─Empty: 2-1909                     [64]                      --
│    └─BatchNorm2d: 2-1910               [16, 64, 16, 16]          --
│    └─Scaler: 2-1911                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1912                      [16, 64, 16, 16]          --
│    └─Empty: 2-1913                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1914                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-144               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-1915        --                        --
│    └─One: 2-1916                       [1]                       --
│    └─OutputScale: 2-1917               --                        --
│    └─Empty: 2-1918                     [64, 64, 3, 3]            --
│    └─Empty: 2-1919                     [64, 64, 3, 3]            --
│    └─Empty: 2-1920                     [64]                      --
│    └─Empty: 2-1921                     [64]                      --
│    └─BatchNorm2d: 2-1922               [16, 64, 16, 16]          --
│    └─Scaler: 2-1923                    [16, 64, 16, 16]          --
│    └─ReLU: 2-1924                      [16, 64, 16, 16]          --
│    └─Empty: 2-1925                     [16, 64, 16, 16]          --
│    └─Clamp: 2-1926                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-145        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1927                 [16, 64, 8, 8]            --
│    └─Empty: 2-1928                     [16, 64, 8, 8]            --
│    └─Empty: 2-1929                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1930        --                        --
│    └─One: 2-1931                       [1]                       --
│    └─OutputScale: 2-1932               --                        --
│    └─Empty: 2-1933                     [64, 64, 3, 3]            --
│    └─Empty: 2-1934                     [64, 64, 3, 3]            --
│    └─Empty: 2-1935                     [64]                      --
│    └─Empty: 2-1936                     [64]                      --
│    └─BatchNorm2d: 2-1937               [16, 64, 8, 8]            --
│    └─Scaler: 2-1938                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1939                      [16, 64, 8, 8]            --
│    └─Empty: 2-1940                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1941                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-146               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-1942        --                        --
│    └─One: 2-1943                       [1]                       --
│    └─OutputScale: 2-1944               --                        --
│    └─Empty: 2-1945                     [64, 64, 1, 1]            --
│    └─Empty: 2-1946                     [64, 64, 1, 1]            --
│    └─Empty: 2-1947                     [64]                      --
│    └─Empty: 2-1948                     [64]                      --
│    └─BatchNorm2d: 2-1949               [16, 64, 8, 8]            --
│    └─Scaler: 2-1950                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1951                      [16, 64, 8, 8]            --
│    └─Empty: 2-1952                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1953                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-147        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-1954                 [16, 64, 8, 8]            --
│    └─Empty: 2-1955                     [16, 64, 8, 8]            --
│    └─Empty: 2-1956                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-1957        --                        --
│    └─One: 2-1958                       [1]                       --
│    └─OutputScale: 2-1959               --                        --
│    └─Empty: 2-1960                     [64, 64, 3, 3]            --
│    └─Empty: 2-1961                     [64, 64, 3, 3]            --
│    └─Empty: 2-1962                     [64]                      --
│    └─Empty: 2-1963                     [64]                      --
│    └─BatchNorm2d: 2-1964               [16, 64, 8, 8]            --
│    └─Scaler: 2-1965                    [16, 64, 8, 8]            --
│    └─ReLU: 2-1966                      [16, 64, 8, 8]            --
│    └─Empty: 2-1967                     [16, 64, 8, 8]            --
│    └─Clamp: 2-1968                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-148        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1969                 [16, 64, 4, 4]            --
│    └─Empty: 2-1970                     [16, 64, 4, 4]            --
│    └─Empty: 2-1971                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1972        --                        --
│    └─One: 2-1973                       [1]                       --
│    └─OutputScale: 2-1974               --                        --
│    └─Empty: 2-1975                     [64, 64, 3, 3]            --
│    └─Empty: 2-1976                     [64, 64, 3, 3]            --
│    └─Empty: 2-1977                     [64]                      --
│    └─Empty: 2-1978                     [64]                      --
│    └─BatchNorm2d: 2-1979               [16, 64, 4, 4]            --
│    └─Scaler: 2-1980                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1981                      [16, 64, 4, 4]            --
│    └─Empty: 2-1982                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1983                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-149               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-1984        --                        --
│    └─One: 2-1985                       [1]                       --
│    └─OutputScale: 2-1986               --                        --
│    └─Empty: 2-1987                     [64, 64, 1, 1]            --
│    └─Empty: 2-1988                     [64, 64, 1, 1]            --
│    └─Empty: 2-1989                     [64]                      --
│    └─Empty: 2-1990                     [64]                      --
│    └─BatchNorm2d: 2-1991               [16, 64, 4, 4]            --
│    └─Scaler: 2-1992                    [16, 64, 4, 4]            --
│    └─ReLU: 2-1993                      [16, 64, 4, 4]            --
│    └─Empty: 2-1994                     [16, 64, 4, 4]            --
│    └─Clamp: 2-1995                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-150        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-1996                 [16, 64, 4, 4]            --
│    └─Empty: 2-1997                     [16, 64, 4, 4]            --
│    └─Empty: 2-1998                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-1999        --                        --
│    └─One: 2-2000                       [1]                       --
│    └─OutputScale: 2-2001               --                        --
│    └─Empty: 2-2002                     [64, 64, 3, 3]            --
│    └─Empty: 2-2003                     [64, 64, 3, 3]            --
│    └─Empty: 2-2004                     [64]                      --
│    └─Empty: 2-2005                     [64]                      --
│    └─BatchNorm2d: 2-2006               [16, 64, 4, 4]            --
│    └─Scaler: 2-2007                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2008                      [16, 64, 4, 4]            --
│    └─Empty: 2-2009                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2010                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-151        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2011                 [16, 64, 2, 2]            --
│    └─Empty: 2-2012                     [16, 64, 2, 2]            --
│    └─Empty: 2-2013                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2014        --                        --
│    └─One: 2-2015                       [1]                       --
│    └─OutputScale: 2-2016               --                        --
│    └─Empty: 2-2017                     [64, 64, 1, 1]            --
│    └─Empty: 2-2018                     [64, 64, 1, 1]            --
│    └─Empty: 2-2019                     [64]                      --
│    └─Empty: 2-2020                     [64]                      --
│    └─BatchNorm2d: 2-2021               [16, 64, 2, 2]            --
│    └─Scaler: 2-2022                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2023                      [16, 64, 2, 2]            --
│    └─Empty: 2-2024                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2025                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-152               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2026        --                        --
│    └─One: 2-2027                       [1]                       --
│    └─OutputScale: 2-2028               --                        --
│    └─Empty: 2-2029                     [64, 64, 1, 1]            --
│    └─Empty: 2-2030                     [64, 64, 1, 1]            --
│    └─Empty: 2-2031                     [64]                      --
│    └─Empty: 2-2032                     [64]                      --
│    └─BatchNorm2d: 2-2033               [16, 64, 2, 2]            --
│    └─Scaler: 2-2034                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2035                      [16, 64, 2, 2]            --
│    └─Empty: 2-2036                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2037                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-153        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2038                 [16, 64, 2, 2]            --
│    └─Empty: 2-2039                     [16, 64, 2, 2]            --
│    └─Empty: 2-2040                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2041        --                        --
│    └─One: 2-2042                       [1]                       --
│    └─OutputScale: 2-2043               --                        --
│    └─Empty: 2-2044                     [64, 64, 3, 3]            --
│    └─Empty: 2-2045                     [64, 64, 3, 3]            --
│    └─Empty: 2-2046                     [64]                      --
│    └─Empty: 2-2047                     [64]                      --
│    └─BatchNorm2d: 2-2048               [16, 64, 2, 2]            --
│    └─Scaler: 2-2049                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2050                      [16, 64, 2, 2]            --
│    └─Empty: 2-2051                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2052                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-154               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2053        --                        --
│    └─One: 2-2054                       [1]                       --
│    └─OutputScale: 2-2055               --                        --
│    └─Empty: 2-2056                     [64, 48, 1, 1]            --
│    └─Empty: 2-2057                     [64, 48, 1, 1]            --
│    └─Empty: 2-2058                     [64]                      --
│    └─Empty: 2-2059                     [64]                      --
│    └─BatchNorm2d: 2-2060               [16, 64, 64, 64]          --
│    └─Scaler: 2-2061                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2062                      [16, 64, 64, 64]          --
│    └─Empty: 2-2063                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2064                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-155               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2065        --                        --
│    └─One: 2-2066                       [1]                       --
│    └─OutputScale: 2-2067               --                        --
│    └─Empty: 2-2068                     [64, 64, 3, 3]            --
│    └─Empty: 2-2069                     [64, 64, 3, 3]            --
│    └─Empty: 2-2070                     [64]                      --
│    └─Empty: 2-2071                     [64]                      --
│    └─BatchNorm2d: 2-2072               [16, 64, 64, 64]          --
│    └─Scaler: 2-2073                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2074                      [16, 64, 64, 64]          --
│    └─Empty: 2-2075                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2076                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-156               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2077        --                        --
│    └─One: 2-2078                       [1]                       --
│    └─OutputScale: 2-2079               --                        --
│    └─Empty: 2-2080                     [64, 64, 1, 1]            --
│    └─Empty: 2-2081                     [64, 64, 1, 1]            --
│    └─Empty: 2-2082                     [64]                      --
│    └─Empty: 2-2083                     [64]                      --
│    └─BatchNorm2d: 2-2084               [16, 64, 64, 64]          --
│    └─Scaler: 2-2085                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2086                      [16, 64, 64, 64]          --
│    └─Empty: 2-2087                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2088                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-157               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2089        --                        --
│    └─One: 2-2090                       [1]                       --
│    └─OutputScale: 2-2091               --                        --
│    └─Empty: 2-2092                     [64, 64, 3, 3]            --
│    └─Empty: 2-2093                     [64, 64, 3, 3]            --
│    └─Empty: 2-2094                     [64]                      --
│    └─Empty: 2-2095                     [64]                      --
│    └─BatchNorm2d: 2-2096               [16, 64, 64, 64]          --
│    └─Scaler: 2-2097                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2098                      [16, 64, 64, 64]          --
│    └─Empty: 2-2099                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2100                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-158        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2101                 [16, 64, 32, 32]          --
│    └─Empty: 2-2102                     [16, 64, 32, 32]          --
│    └─Empty: 2-2103                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2104        --                        --
│    └─One: 2-2105                       [1]                       --
│    └─OutputScale: 2-2106               --                        --
│    └─Empty: 2-2107                     [64, 64, 3, 3]            --
│    └─Empty: 2-2108                     [64, 64, 3, 3]            --
│    └─Empty: 2-2109                     [64]                      --
│    └─Empty: 2-2110                     [64]                      --
│    └─BatchNorm2d: 2-2111               [16, 64, 32, 32]          --
│    └─Scaler: 2-2112                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2113                      [16, 64, 32, 32]          --
│    └─Empty: 2-2114                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2115                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-159               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2116        --                        --
│    └─One: 2-2117                       [1]                       --
│    └─OutputScale: 2-2118               --                        --
│    └─Empty: 2-2119                     [64, 64, 3, 3]            --
│    └─Empty: 2-2120                     [64, 64, 3, 3]            --
│    └─Empty: 2-2121                     [64]                      --
│    └─Empty: 2-2122                     [64]                      --
│    └─BatchNorm2d: 2-2123               [16, 64, 32, 32]          --
│    └─Scaler: 2-2124                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2125                      [16, 64, 32, 32]          --
│    └─Empty: 2-2126                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2127                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-160        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2128                 [16, 64, 16, 16]          --
│    └─Empty: 2-2129                     [16, 64, 16, 16]          --
│    └─Empty: 2-2130                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2131        --                        --
│    └─One: 2-2132                       [1]                       --
│    └─OutputScale: 2-2133               --                        --
│    └─Empty: 2-2134                     [64, 64, 3, 3]            --
│    └─Empty: 2-2135                     [64, 64, 3, 3]            --
│    └─Empty: 2-2136                     [64]                      --
│    └─Empty: 2-2137                     [64]                      --
│    └─BatchNorm2d: 2-2138               [16, 64, 16, 16]          --
│    └─Scaler: 2-2139                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2140                      [16, 64, 16, 16]          --
│    └─Empty: 2-2141                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2142                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-161               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2143        --                        --
│    └─One: 2-2144                       [1]                       --
│    └─OutputScale: 2-2145               --                        --
│    └─Empty: 2-2146                     [64, 64, 3, 3]            --
│    └─Empty: 2-2147                     [64, 64, 3, 3]            --
│    └─Empty: 2-2148                     [64]                      --
│    └─Empty: 2-2149                     [64]                      --
│    └─BatchNorm2d: 2-2150               [16, 64, 16, 16]          --
│    └─Scaler: 2-2151                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2152                      [16, 64, 16, 16]          --
│    └─Empty: 2-2153                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2154                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-162        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2155                 [16, 64, 8, 8]            --
│    └─Empty: 2-2156                     [16, 64, 8, 8]            --
│    └─Empty: 2-2157                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2158        --                        --
│    └─One: 2-2159                       [1]                       --
│    └─OutputScale: 2-2160               --                        --
│    └─Empty: 2-2161                     [64, 64, 3, 3]            --
│    └─Empty: 2-2162                     [64, 64, 3, 3]            --
│    └─Empty: 2-2163                     [64]                      --
│    └─Empty: 2-2164                     [64]                      --
│    └─BatchNorm2d: 2-2165               [16, 64, 8, 8]            --
│    └─Scaler: 2-2166                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2167                      [16, 64, 8, 8]            --
│    └─Empty: 2-2168                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2169                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-163               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2170        --                        --
│    └─One: 2-2171                       [1]                       --
│    └─OutputScale: 2-2172               --                        --
│    └─Empty: 2-2173                     [64, 64, 1, 1]            --
│    └─Empty: 2-2174                     [64, 64, 1, 1]            --
│    └─Empty: 2-2175                     [64]                      --
│    └─Empty: 2-2176                     [64]                      --
│    └─BatchNorm2d: 2-2177               [16, 64, 8, 8]            --
│    └─Scaler: 2-2178                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2179                      [16, 64, 8, 8]            --
│    └─Empty: 2-2180                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2181                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-164        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2182                 [16, 64, 8, 8]            --
│    └─Empty: 2-2183                     [16, 64, 8, 8]            --
│    └─Empty: 2-2184                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2185        --                        --
│    └─One: 2-2186                       [1]                       --
│    └─OutputScale: 2-2187               --                        --
│    └─Empty: 2-2188                     [64, 64, 3, 3]            --
│    └─Empty: 2-2189                     [64, 64, 3, 3]            --
│    └─Empty: 2-2190                     [64]                      --
│    └─Empty: 2-2191                     [64]                      --
│    └─BatchNorm2d: 2-2192               [16, 64, 8, 8]            --
│    └─Scaler: 2-2193                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2194                      [16, 64, 8, 8]            --
│    └─Empty: 2-2195                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2196                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-165        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2197                 [16, 64, 4, 4]            --
│    └─Empty: 2-2198                     [16, 64, 4, 4]            --
│    └─Empty: 2-2199                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2200        --                        --
│    └─One: 2-2201                       [1]                       --
│    └─OutputScale: 2-2202               --                        --
│    └─Empty: 2-2203                     [64, 64, 3, 3]            --
│    └─Empty: 2-2204                     [64, 64, 3, 3]            --
│    └─Empty: 2-2205                     [64]                      --
│    └─Empty: 2-2206                     [64]                      --
│    └─BatchNorm2d: 2-2207               [16, 64, 4, 4]            --
│    └─Scaler: 2-2208                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2209                      [16, 64, 4, 4]            --
│    └─Empty: 2-2210                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2211                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-166               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2212        --                        --
│    └─One: 2-2213                       [1]                       --
│    └─OutputScale: 2-2214               --                        --
│    └─Empty: 2-2215                     [64, 64, 1, 1]            --
│    └─Empty: 2-2216                     [64, 64, 1, 1]            --
│    └─Empty: 2-2217                     [64]                      --
│    └─Empty: 2-2218                     [64]                      --
│    └─BatchNorm2d: 2-2219               [16, 64, 4, 4]            --
│    └─Scaler: 2-2220                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2221                      [16, 64, 4, 4]            --
│    └─Empty: 2-2222                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2223                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-167        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2224                 [16, 64, 4, 4]            --
│    └─Empty: 2-2225                     [16, 64, 4, 4]            --
│    └─Empty: 2-2226                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2227        --                        --
│    └─One: 2-2228                       [1]                       --
│    └─OutputScale: 2-2229               --                        --
│    └─Empty: 2-2230                     [64, 64, 3, 3]            --
│    └─Empty: 2-2231                     [64, 64, 3, 3]            --
│    └─Empty: 2-2232                     [64]                      --
│    └─Empty: 2-2233                     [64]                      --
│    └─BatchNorm2d: 2-2234               [16, 64, 4, 4]            --
│    └─Scaler: 2-2235                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2236                      [16, 64, 4, 4]            --
│    └─Empty: 2-2237                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2238                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-168        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2239                 [16, 64, 2, 2]            --
│    └─Empty: 2-2240                     [16, 64, 2, 2]            --
│    └─Empty: 2-2241                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2242        --                        --
│    └─One: 2-2243                       [1]                       --
│    └─OutputScale: 2-2244               --                        --
│    └─Empty: 2-2245                     [64, 64, 1, 1]            --
│    └─Empty: 2-2246                     [64, 64, 1, 1]            --
│    └─Empty: 2-2247                     [64]                      --
│    └─Empty: 2-2248                     [64]                      --
│    └─BatchNorm2d: 2-2249               [16, 64, 2, 2]            --
│    └─Scaler: 2-2250                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2251                      [16, 64, 2, 2]            --
│    └─Empty: 2-2252                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2253                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-169               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2254        --                        --
│    └─One: 2-2255                       [1]                       --
│    └─OutputScale: 2-2256               --                        --
│    └─Empty: 2-2257                     [64, 64, 1, 1]            --
│    └─Empty: 2-2258                     [64, 64, 1, 1]            --
│    └─Empty: 2-2259                     [64]                      --
│    └─Empty: 2-2260                     [64]                      --
│    └─BatchNorm2d: 2-2261               [16, 64, 2, 2]            --
│    └─Scaler: 2-2262                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2263                      [16, 64, 2, 2]            --
│    └─Empty: 2-2264                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2265                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-170        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2266                 [16, 64, 2, 2]            --
│    └─Empty: 2-2267                     [16, 64, 2, 2]            --
│    └─Empty: 2-2268                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2269        --                        --
│    └─One: 2-2270                       [1]                       --
│    └─OutputScale: 2-2271               --                        --
│    └─Empty: 2-2272                     [64, 64, 3, 3]            --
│    └─Empty: 2-2273                     [64, 64, 3, 3]            --
│    └─Empty: 2-2274                     [64]                      --
│    └─Empty: 2-2275                     [64]                      --
│    └─BatchNorm2d: 2-2276               [16, 64, 2, 2]            --
│    └─Scaler: 2-2277                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2278                      [16, 64, 2, 2]            --
│    └─Empty: 2-2279                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2280                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-171               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2281        --                        --
│    └─One: 2-2282                       [1]                       --
│    └─OutputScale: 2-2283               --                        --
│    └─Empty: 2-2284                     [64, 48, 1, 1]            --
│    └─Empty: 2-2285                     [64, 48, 1, 1]            --
│    └─Empty: 2-2286                     [64]                      --
│    └─Empty: 2-2287                     [64]                      --
│    └─BatchNorm2d: 2-2288               [16, 64, 64, 64]          --
│    └─Scaler: 2-2289                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2290                      [16, 64, 64, 64]          --
│    └─Empty: 2-2291                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2292                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-172               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2293        --                        --
│    └─One: 2-2294                       [1]                       --
│    └─OutputScale: 2-2295               --                        --
│    └─Empty: 2-2296                     [64, 64, 3, 3]            --
│    └─Empty: 2-2297                     [64, 64, 3, 3]            --
│    └─Empty: 2-2298                     [64]                      --
│    └─Empty: 2-2299                     [64]                      --
│    └─BatchNorm2d: 2-2300               [16, 64, 64, 64]          --
│    └─Scaler: 2-2301                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2302                      [16, 64, 64, 64]          --
│    └─Empty: 2-2303                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2304                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-173               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2305        --                        --
│    └─One: 2-2306                       [1]                       --
│    └─OutputScale: 2-2307               --                        --
│    └─Empty: 2-2308                     [64, 64, 1, 1]            --
│    └─Empty: 2-2309                     [64, 64, 1, 1]            --
│    └─Empty: 2-2310                     [64]                      --
│    └─Empty: 2-2311                     [64]                      --
│    └─BatchNorm2d: 2-2312               [16, 64, 64, 64]          --
│    └─Scaler: 2-2313                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2314                      [16, 64, 64, 64]          --
│    └─Empty: 2-2315                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2316                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-174               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2317        --                        --
│    └─One: 2-2318                       [1]                       --
│    └─OutputScale: 2-2319               --                        --
│    └─Empty: 2-2320                     [64, 64, 3, 3]            --
│    └─Empty: 2-2321                     [64, 64, 3, 3]            --
│    └─Empty: 2-2322                     [64]                      --
│    └─Empty: 2-2323                     [64]                      --
│    └─BatchNorm2d: 2-2324               [16, 64, 64, 64]          --
│    └─Scaler: 2-2325                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2326                      [16, 64, 64, 64]          --
│    └─Empty: 2-2327                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2328                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-175        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2329                 [16, 64, 32, 32]          --
│    └─Empty: 2-2330                     [16, 64, 32, 32]          --
│    └─Empty: 2-2331                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2332        --                        --
│    └─One: 2-2333                       [1]                       --
│    └─OutputScale: 2-2334               --                        --
│    └─Empty: 2-2335                     [64, 64, 3, 3]            --
│    └─Empty: 2-2336                     [64, 64, 3, 3]            --
│    └─Empty: 2-2337                     [64]                      --
│    └─Empty: 2-2338                     [64]                      --
│    └─BatchNorm2d: 2-2339               [16, 64, 32, 32]          --
│    └─Scaler: 2-2340                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2341                      [16, 64, 32, 32]          --
│    └─Empty: 2-2342                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2343                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-176               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2344        --                        --
│    └─One: 2-2345                       [1]                       --
│    └─OutputScale: 2-2346               --                        --
│    └─Empty: 2-2347                     [64, 64, 3, 3]            --
│    └─Empty: 2-2348                     [64, 64, 3, 3]            --
│    └─Empty: 2-2349                     [64]                      --
│    └─Empty: 2-2350                     [64]                      --
│    └─BatchNorm2d: 2-2351               [16, 64, 32, 32]          --
│    └─Scaler: 2-2352                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2353                      [16, 64, 32, 32]          --
│    └─Empty: 2-2354                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2355                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-177        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2356                 [16, 64, 16, 16]          --
│    └─Empty: 2-2357                     [16, 64, 16, 16]          --
│    └─Empty: 2-2358                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2359        --                        --
│    └─One: 2-2360                       [1]                       --
│    └─OutputScale: 2-2361               --                        --
│    └─Empty: 2-2362                     [64, 64, 3, 3]            --
│    └─Empty: 2-2363                     [64, 64, 3, 3]            --
│    └─Empty: 2-2364                     [64]                      --
│    └─Empty: 2-2365                     [64]                      --
│    └─BatchNorm2d: 2-2366               [16, 64, 16, 16]          --
│    └─Scaler: 2-2367                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2368                      [16, 64, 16, 16]          --
│    └─Empty: 2-2369                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2370                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-178               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2371        --                        --
│    └─One: 2-2372                       [1]                       --
│    └─OutputScale: 2-2373               --                        --
│    └─Empty: 2-2374                     [64, 64, 3, 3]            --
│    └─Empty: 2-2375                     [64, 64, 3, 3]            --
│    └─Empty: 2-2376                     [64]                      --
│    └─Empty: 2-2377                     [64]                      --
│    └─BatchNorm2d: 2-2378               [16, 64, 16, 16]          --
│    └─Scaler: 2-2379                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2380                      [16, 64, 16, 16]          --
│    └─Empty: 2-2381                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2382                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-179        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2383                 [16, 64, 8, 8]            --
│    └─Empty: 2-2384                     [16, 64, 8, 8]            --
│    └─Empty: 2-2385                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2386        --                        --
│    └─One: 2-2387                       [1]                       --
│    └─OutputScale: 2-2388               --                        --
│    └─Empty: 2-2389                     [64, 64, 3, 3]            --
│    └─Empty: 2-2390                     [64, 64, 3, 3]            --
│    └─Empty: 2-2391                     [64]                      --
│    └─Empty: 2-2392                     [64]                      --
│    └─BatchNorm2d: 2-2393               [16, 64, 8, 8]            --
│    └─Scaler: 2-2394                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2395                      [16, 64, 8, 8]            --
│    └─Empty: 2-2396                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2397                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-180               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2398        --                        --
│    └─One: 2-2399                       [1]                       --
│    └─OutputScale: 2-2400               --                        --
│    └─Empty: 2-2401                     [64, 64, 1, 1]            --
│    └─Empty: 2-2402                     [64, 64, 1, 1]            --
│    └─Empty: 2-2403                     [64]                      --
│    └─Empty: 2-2404                     [64]                      --
│    └─BatchNorm2d: 2-2405               [16, 64, 8, 8]            --
│    └─Scaler: 2-2406                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2407                      [16, 64, 8, 8]            --
│    └─Empty: 2-2408                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2409                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-181        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2410                 [16, 64, 8, 8]            --
│    └─Empty: 2-2411                     [16, 64, 8, 8]            --
│    └─Empty: 2-2412                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2413        --                        --
│    └─One: 2-2414                       [1]                       --
│    └─OutputScale: 2-2415               --                        --
│    └─Empty: 2-2416                     [64, 64, 3, 3]            --
│    └─Empty: 2-2417                     [64, 64, 3, 3]            --
│    └─Empty: 2-2418                     [64]                      --
│    └─Empty: 2-2419                     [64]                      --
│    └─BatchNorm2d: 2-2420               [16, 64, 8, 8]            --
│    └─Scaler: 2-2421                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2422                      [16, 64, 8, 8]            --
│    └─Empty: 2-2423                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2424                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-182        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2425                 [16, 64, 4, 4]            --
│    └─Empty: 2-2426                     [16, 64, 4, 4]            --
│    └─Empty: 2-2427                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2428        --                        --
│    └─One: 2-2429                       [1]                       --
│    └─OutputScale: 2-2430               --                        --
│    └─Empty: 2-2431                     [64, 64, 3, 3]            --
│    └─Empty: 2-2432                     [64, 64, 3, 3]            --
│    └─Empty: 2-2433                     [64]                      --
│    └─Empty: 2-2434                     [64]                      --
│    └─BatchNorm2d: 2-2435               [16, 64, 4, 4]            --
│    └─Scaler: 2-2436                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2437                      [16, 64, 4, 4]            --
│    └─Empty: 2-2438                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2439                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-183               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2440        --                        --
│    └─One: 2-2441                       [1]                       --
│    └─OutputScale: 2-2442               --                        --
│    └─Empty: 2-2443                     [64, 64, 1, 1]            --
│    └─Empty: 2-2444                     [64, 64, 1, 1]            --
│    └─Empty: 2-2445                     [64]                      --
│    └─Empty: 2-2446                     [64]                      --
│    └─BatchNorm2d: 2-2447               [16, 64, 4, 4]            --
│    └─Scaler: 2-2448                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2449                      [16, 64, 4, 4]            --
│    └─Empty: 2-2450                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2451                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-184        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2452                 [16, 64, 4, 4]            --
│    └─Empty: 2-2453                     [16, 64, 4, 4]            --
│    └─Empty: 2-2454                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2455        --                        --
│    └─One: 2-2456                       [1]                       --
│    └─OutputScale: 2-2457               --                        --
│    └─Empty: 2-2458                     [64, 64, 3, 3]            --
│    └─Empty: 2-2459                     [64, 64, 3, 3]            --
│    └─Empty: 2-2460                     [64]                      --
│    └─Empty: 2-2461                     [64]                      --
│    └─BatchNorm2d: 2-2462               [16, 64, 4, 4]            --
│    └─Scaler: 2-2463                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2464                      [16, 64, 4, 4]            --
│    └─Empty: 2-2465                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2466                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-185        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2467                 [16, 64, 2, 2]            --
│    └─Empty: 2-2468                     [16, 64, 2, 2]            --
│    └─Empty: 2-2469                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2470        --                        --
│    └─One: 2-2471                       [1]                       --
│    └─OutputScale: 2-2472               --                        --
│    └─Empty: 2-2473                     [64, 64, 1, 1]            --
│    └─Empty: 2-2474                     [64, 64, 1, 1]            --
│    └─Empty: 2-2475                     [64]                      --
│    └─Empty: 2-2476                     [64]                      --
│    └─BatchNorm2d: 2-2477               [16, 64, 2, 2]            --
│    └─Scaler: 2-2478                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2479                      [16, 64, 2, 2]            --
│    └─Empty: 2-2480                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2481                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-186               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2482        --                        --
│    └─One: 2-2483                       [1]                       --
│    └─OutputScale: 2-2484               --                        --
│    └─Empty: 2-2485                     [64, 64, 1, 1]            --
│    └─Empty: 2-2486                     [64, 64, 1, 1]            --
│    └─Empty: 2-2487                     [64]                      --
│    └─Empty: 2-2488                     [64]                      --
│    └─BatchNorm2d: 2-2489               [16, 64, 2, 2]            --
│    └─Scaler: 2-2490                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2491                      [16, 64, 2, 2]            --
│    └─Empty: 2-2492                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2493                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-187        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2494                 [16, 64, 2, 2]            --
│    └─Empty: 2-2495                     [16, 64, 2, 2]            --
│    └─Empty: 2-2496                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2497        --                        --
│    └─One: 2-2498                       [1]                       --
│    └─OutputScale: 2-2499               --                        --
│    └─Empty: 2-2500                     [64, 64, 3, 3]            --
│    └─Empty: 2-2501                     [64, 64, 3, 3]            --
│    └─Empty: 2-2502                     [64]                      --
│    └─Empty: 2-2503                     [64]                      --
│    └─BatchNorm2d: 2-2504               [16, 64, 2, 2]            --
│    └─Scaler: 2-2505                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2506                      [16, 64, 2, 2]            --
│    └─Empty: 2-2507                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2508                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-188               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2509        --                        --
│    └─One: 2-2510                       [1]                       --
│    └─OutputScale: 2-2511               --                        --
│    └─Empty: 2-2512                     [64, 48, 1, 1]            --
│    └─Empty: 2-2513                     [64, 48, 1, 1]            --
│    └─Empty: 2-2514                     [64]                      --
│    └─Empty: 2-2515                     [64]                      --
│    └─BatchNorm2d: 2-2516               [16, 64, 64, 64]          --
│    └─Scaler: 2-2517                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2518                      [16, 64, 64, 64]          --
│    └─Empty: 2-2519                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2520                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-189               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2521        --                        --
│    └─One: 2-2522                       [1]                       --
│    └─OutputScale: 2-2523               --                        --
│    └─Empty: 2-2524                     [64, 64, 3, 3]            --
│    └─Empty: 2-2525                     [64, 64, 3, 3]            --
│    └─Empty: 2-2526                     [64]                      --
│    └─Empty: 2-2527                     [64]                      --
│    └─BatchNorm2d: 2-2528               [16, 64, 64, 64]          --
│    └─Scaler: 2-2529                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2530                      [16, 64, 64, 64]          --
│    └─Empty: 2-2531                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2532                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-190               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2533        --                        --
│    └─One: 2-2534                       [1]                       --
│    └─OutputScale: 2-2535               --                        --
│    └─Empty: 2-2536                     [64, 64, 1, 1]            --
│    └─Empty: 2-2537                     [64, 64, 1, 1]            --
│    └─Empty: 2-2538                     [64]                      --
│    └─Empty: 2-2539                     [64]                      --
│    └─BatchNorm2d: 2-2540               [16, 64, 64, 64]          --
│    └─Scaler: 2-2541                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2542                      [16, 64, 64, 64]          --
│    └─Empty: 2-2543                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2544                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-191               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2545        --                        --
│    └─One: 2-2546                       [1]                       --
│    └─OutputScale: 2-2547               --                        --
│    └─Empty: 2-2548                     [64, 64, 3, 3]            --
│    └─Empty: 2-2549                     [64, 64, 3, 3]            --
│    └─Empty: 2-2550                     [64]                      --
│    └─Empty: 2-2551                     [64]                      --
│    └─BatchNorm2d: 2-2552               [16, 64, 64, 64]          --
│    └─Scaler: 2-2553                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2554                      [16, 64, 64, 64]          --
│    └─Empty: 2-2555                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2556                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-192        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2557                 [16, 64, 32, 32]          --
│    └─Empty: 2-2558                     [16, 64, 32, 32]          --
│    └─Empty: 2-2559                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2560        --                        --
│    └─One: 2-2561                       [1]                       --
│    └─OutputScale: 2-2562               --                        --
│    └─Empty: 2-2563                     [64, 64, 3, 3]            --
│    └─Empty: 2-2564                     [64, 64, 3, 3]            --
│    └─Empty: 2-2565                     [64]                      --
│    └─Empty: 2-2566                     [64]                      --
│    └─BatchNorm2d: 2-2567               [16, 64, 32, 32]          --
│    └─Scaler: 2-2568                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2569                      [16, 64, 32, 32]          --
│    └─Empty: 2-2570                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2571                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-193               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2572        --                        --
│    └─One: 2-2573                       [1]                       --
│    └─OutputScale: 2-2574               --                        --
│    └─Empty: 2-2575                     [64, 64, 3, 3]            --
│    └─Empty: 2-2576                     [64, 64, 3, 3]            --
│    └─Empty: 2-2577                     [64]                      --
│    └─Empty: 2-2578                     [64]                      --
│    └─BatchNorm2d: 2-2579               [16, 64, 32, 32]          --
│    └─Scaler: 2-2580                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2581                      [16, 64, 32, 32]          --
│    └─Empty: 2-2582                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2583                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-194        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2584                 [16, 64, 16, 16]          --
│    └─Empty: 2-2585                     [16, 64, 16, 16]          --
│    └─Empty: 2-2586                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2587        --                        --
│    └─One: 2-2588                       [1]                       --
│    └─OutputScale: 2-2589               --                        --
│    └─Empty: 2-2590                     [64, 64, 3, 3]            --
│    └─Empty: 2-2591                     [64, 64, 3, 3]            --
│    └─Empty: 2-2592                     [64]                      --
│    └─Empty: 2-2593                     [64]                      --
│    └─BatchNorm2d: 2-2594               [16, 64, 16, 16]          --
│    └─Scaler: 2-2595                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2596                      [16, 64, 16, 16]          --
│    └─Empty: 2-2597                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2598                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-195               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2599        --                        --
│    └─One: 2-2600                       [1]                       --
│    └─OutputScale: 2-2601               --                        --
│    └─Empty: 2-2602                     [64, 64, 3, 3]            --
│    └─Empty: 2-2603                     [64, 64, 3, 3]            --
│    └─Empty: 2-2604                     [64]                      --
│    └─Empty: 2-2605                     [64]                      --
│    └─BatchNorm2d: 2-2606               [16, 64, 16, 16]          --
│    └─Scaler: 2-2607                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2608                      [16, 64, 16, 16]          --
│    └─Empty: 2-2609                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2610                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-196        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2611                 [16, 64, 8, 8]            --
│    └─Empty: 2-2612                     [16, 64, 8, 8]            --
│    └─Empty: 2-2613                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2614        --                        --
│    └─One: 2-2615                       [1]                       --
│    └─OutputScale: 2-2616               --                        --
│    └─Empty: 2-2617                     [64, 64, 3, 3]            --
│    └─Empty: 2-2618                     [64, 64, 3, 3]            --
│    └─Empty: 2-2619                     [64]                      --
│    └─Empty: 2-2620                     [64]                      --
│    └─BatchNorm2d: 2-2621               [16, 64, 8, 8]            --
│    └─Scaler: 2-2622                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2623                      [16, 64, 8, 8]            --
│    └─Empty: 2-2624                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2625                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-197               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2626        --                        --
│    └─One: 2-2627                       [1]                       --
│    └─OutputScale: 2-2628               --                        --
│    └─Empty: 2-2629                     [64, 64, 1, 1]            --
│    └─Empty: 2-2630                     [64, 64, 1, 1]            --
│    └─Empty: 2-2631                     [64]                      --
│    └─Empty: 2-2632                     [64]                      --
│    └─BatchNorm2d: 2-2633               [16, 64, 8, 8]            --
│    └─Scaler: 2-2634                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2635                      [16, 64, 8, 8]            --
│    └─Empty: 2-2636                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2637                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-198        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2638                 [16, 64, 8, 8]            --
│    └─Empty: 2-2639                     [16, 64, 8, 8]            --
│    └─Empty: 2-2640                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2641        --                        --
│    └─One: 2-2642                       [1]                       --
│    └─OutputScale: 2-2643               --                        --
│    └─Empty: 2-2644                     [64, 64, 3, 3]            --
│    └─Empty: 2-2645                     [64, 64, 3, 3]            --
│    └─Empty: 2-2646                     [64]                      --
│    └─Empty: 2-2647                     [64]                      --
│    └─BatchNorm2d: 2-2648               [16, 64, 8, 8]            --
│    └─Scaler: 2-2649                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2650                      [16, 64, 8, 8]            --
│    └─Empty: 2-2651                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2652                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-199        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2653                 [16, 64, 4, 4]            --
│    └─Empty: 2-2654                     [16, 64, 4, 4]            --
│    └─Empty: 2-2655                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2656        --                        --
│    └─One: 2-2657                       [1]                       --
│    └─OutputScale: 2-2658               --                        --
│    └─Empty: 2-2659                     [64, 64, 3, 3]            --
│    └─Empty: 2-2660                     [64, 64, 3, 3]            --
│    └─Empty: 2-2661                     [64]                      --
│    └─Empty: 2-2662                     [64]                      --
│    └─BatchNorm2d: 2-2663               [16, 64, 4, 4]            --
│    └─Scaler: 2-2664                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2665                      [16, 64, 4, 4]            --
│    └─Empty: 2-2666                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2667                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-200               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2668        --                        --
│    └─One: 2-2669                       [1]                       --
│    └─OutputScale: 2-2670               --                        --
│    └─Empty: 2-2671                     [64, 64, 1, 1]            --
│    └─Empty: 2-2672                     [64, 64, 1, 1]            --
│    └─Empty: 2-2673                     [64]                      --
│    └─Empty: 2-2674                     [64]                      --
│    └─BatchNorm2d: 2-2675               [16, 64, 4, 4]            --
│    └─Scaler: 2-2676                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2677                      [16, 64, 4, 4]            --
│    └─Empty: 2-2678                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2679                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-201        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2680                 [16, 64, 4, 4]            --
│    └─Empty: 2-2681                     [16, 64, 4, 4]            --
│    └─Empty: 2-2682                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2683        --                        --
│    └─One: 2-2684                       [1]                       --
│    └─OutputScale: 2-2685               --                        --
│    └─Empty: 2-2686                     [64, 64, 3, 3]            --
│    └─Empty: 2-2687                     [64, 64, 3, 3]            --
│    └─Empty: 2-2688                     [64]                      --
│    └─Empty: 2-2689                     [64]                      --
│    └─BatchNorm2d: 2-2690               [16, 64, 4, 4]            --
│    └─Scaler: 2-2691                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2692                      [16, 64, 4, 4]            --
│    └─Empty: 2-2693                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2694                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-202        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2695                 [16, 64, 2, 2]            --
│    └─Empty: 2-2696                     [16, 64, 2, 2]            --
│    └─Empty: 2-2697                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2698        --                        --
│    └─One: 2-2699                       [1]                       --
│    └─OutputScale: 2-2700               --                        --
│    └─Empty: 2-2701                     [64, 64, 1, 1]            --
│    └─Empty: 2-2702                     [64, 64, 1, 1]            --
│    └─Empty: 2-2703                     [64]                      --
│    └─Empty: 2-2704                     [64]                      --
│    └─BatchNorm2d: 2-2705               [16, 64, 2, 2]            --
│    └─Scaler: 2-2706                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2707                      [16, 64, 2, 2]            --
│    └─Empty: 2-2708                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2709                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-203               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2710        --                        --
│    └─One: 2-2711                       [1]                       --
│    └─OutputScale: 2-2712               --                        --
│    └─Empty: 2-2713                     [64, 64, 1, 1]            --
│    └─Empty: 2-2714                     [64, 64, 1, 1]            --
│    └─Empty: 2-2715                     [64]                      --
│    └─Empty: 2-2716                     [64]                      --
│    └─BatchNorm2d: 2-2717               [16, 64, 2, 2]            --
│    └─Scaler: 2-2718                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2719                      [16, 64, 2, 2]            --
│    └─Empty: 2-2720                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2721                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-204        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2722                 [16, 64, 2, 2]            --
│    └─Empty: 2-2723                     [16, 64, 2, 2]            --
│    └─Empty: 2-2724                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2725        --                        --
│    └─One: 2-2726                       [1]                       --
│    └─OutputScale: 2-2727               --                        --
│    └─Empty: 2-2728                     [64, 64, 3, 3]            --
│    └─Empty: 2-2729                     [64, 64, 3, 3]            --
│    └─Empty: 2-2730                     [64]                      --
│    └─Empty: 2-2731                     [64]                      --
│    └─BatchNorm2d: 2-2732               [16, 64, 2, 2]            --
│    └─Scaler: 2-2733                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2734                      [16, 64, 2, 2]            --
│    └─Empty: 2-2735                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2736                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-205               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2737        --                        --
│    └─One: 2-2738                       [1]                       --
│    └─OutputScale: 2-2739               --                        --
│    └─Empty: 2-2740                     [64, 48, 1, 1]            --
│    └─Empty: 2-2741                     [64, 48, 1, 1]            --
│    └─Empty: 2-2742                     [64]                      --
│    └─Empty: 2-2743                     [64]                      --
│    └─BatchNorm2d: 2-2744               [16, 64, 64, 64]          --
│    └─Scaler: 2-2745                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2746                      [16, 64, 64, 64]          --
│    └─Empty: 2-2747                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2748                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-206               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2749        --                        --
│    └─One: 2-2750                       [1]                       --
│    └─OutputScale: 2-2751               --                        --
│    └─Empty: 2-2752                     [64, 64, 3, 3]            --
│    └─Empty: 2-2753                     [64, 64, 3, 3]            --
│    └─Empty: 2-2754                     [64]                      --
│    └─Empty: 2-2755                     [64]                      --
│    └─BatchNorm2d: 2-2756               [16, 64, 64, 64]          --
│    └─Scaler: 2-2757                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2758                      [16, 64, 64, 64]          --
│    └─Empty: 2-2759                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2760                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-207               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2761        --                        --
│    └─One: 2-2762                       [1]                       --
│    └─OutputScale: 2-2763               --                        --
│    └─Empty: 2-2764                     [64, 64, 1, 1]            --
│    └─Empty: 2-2765                     [64, 64, 1, 1]            --
│    └─Empty: 2-2766                     [64]                      --
│    └─Empty: 2-2767                     [64]                      --
│    └─BatchNorm2d: 2-2768               [16, 64, 64, 64]          --
│    └─Scaler: 2-2769                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2770                      [16, 64, 64, 64]          --
│    └─Empty: 2-2771                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2772                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-208               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2773        --                        --
│    └─One: 2-2774                       [1]                       --
│    └─OutputScale: 2-2775               --                        --
│    └─Empty: 2-2776                     [64, 64, 3, 3]            --
│    └─Empty: 2-2777                     [64, 64, 3, 3]            --
│    └─Empty: 2-2778                     [64]                      --
│    └─Empty: 2-2779                     [64]                      --
│    └─BatchNorm2d: 2-2780               [16, 64, 64, 64]          --
│    └─Scaler: 2-2781                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2782                      [16, 64, 64, 64]          --
│    └─Empty: 2-2783                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2784                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-209        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-2785                 [16, 64, 32, 32]          --
│    └─Empty: 2-2786                     [16, 64, 32, 32]          --
│    └─Empty: 2-2787                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-2788        --                        --
│    └─One: 2-2789                       [1]                       --
│    └─OutputScale: 2-2790               --                        --
│    └─Empty: 2-2791                     [64, 64, 3, 3]            --
│    └─Empty: 2-2792                     [64, 64, 3, 3]            --
│    └─Empty: 2-2793                     [64]                      --
│    └─Empty: 2-2794                     [64]                      --
│    └─BatchNorm2d: 2-2795               [16, 64, 32, 32]          --
│    └─Scaler: 2-2796                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2797                      [16, 64, 32, 32]          --
│    └─Empty: 2-2798                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2799                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-210               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-2800        --                        --
│    └─One: 2-2801                       [1]                       --
│    └─OutputScale: 2-2802               --                        --
│    └─Empty: 2-2803                     [64, 64, 3, 3]            --
│    └─Empty: 2-2804                     [64, 64, 3, 3]            --
│    └─Empty: 2-2805                     [64]                      --
│    └─Empty: 2-2806                     [64]                      --
│    └─BatchNorm2d: 2-2807               [16, 64, 32, 32]          --
│    └─Scaler: 2-2808                    [16, 64, 32, 32]          --
│    └─ReLU: 2-2809                      [16, 64, 32, 32]          --
│    └─Empty: 2-2810                     [16, 64, 32, 32]          --
│    └─Clamp: 2-2811                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-211        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-2812                 [16, 64, 16, 16]          --
│    └─Empty: 2-2813                     [16, 64, 16, 16]          --
│    └─Empty: 2-2814                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-2815        --                        --
│    └─One: 2-2816                       [1]                       --
│    └─OutputScale: 2-2817               --                        --
│    └─Empty: 2-2818                     [64, 64, 3, 3]            --
│    └─Empty: 2-2819                     [64, 64, 3, 3]            --
│    └─Empty: 2-2820                     [64]                      --
│    └─Empty: 2-2821                     [64]                      --
│    └─BatchNorm2d: 2-2822               [16, 64, 16, 16]          --
│    └─Scaler: 2-2823                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2824                      [16, 64, 16, 16]          --
│    └─Empty: 2-2825                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2826                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-212               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-2827        --                        --
│    └─One: 2-2828                       [1]                       --
│    └─OutputScale: 2-2829               --                        --
│    └─Empty: 2-2830                     [64, 64, 3, 3]            --
│    └─Empty: 2-2831                     [64, 64, 3, 3]            --
│    └─Empty: 2-2832                     [64]                      --
│    └─Empty: 2-2833                     [64]                      --
│    └─BatchNorm2d: 2-2834               [16, 64, 16, 16]          --
│    └─Scaler: 2-2835                    [16, 64, 16, 16]          --
│    └─ReLU: 2-2836                      [16, 64, 16, 16]          --
│    └─Empty: 2-2837                     [16, 64, 16, 16]          --
│    └─Clamp: 2-2838                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-213        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2839                 [16, 64, 8, 8]            --
│    └─Empty: 2-2840                     [16, 64, 8, 8]            --
│    └─Empty: 2-2841                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2842        --                        --
│    └─One: 2-2843                       [1]                       --
│    └─OutputScale: 2-2844               --                        --
│    └─Empty: 2-2845                     [64, 64, 3, 3]            --
│    └─Empty: 2-2846                     [64, 64, 3, 3]            --
│    └─Empty: 2-2847                     [64]                      --
│    └─Empty: 2-2848                     [64]                      --
│    └─BatchNorm2d: 2-2849               [16, 64, 8, 8]            --
│    └─Scaler: 2-2850                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2851                      [16, 64, 8, 8]            --
│    └─Empty: 2-2852                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2853                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-214               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-2854        --                        --
│    └─One: 2-2855                       [1]                       --
│    └─OutputScale: 2-2856               --                        --
│    └─Empty: 2-2857                     [64, 64, 1, 1]            --
│    └─Empty: 2-2858                     [64, 64, 1, 1]            --
│    └─Empty: 2-2859                     [64]                      --
│    └─Empty: 2-2860                     [64]                      --
│    └─BatchNorm2d: 2-2861               [16, 64, 8, 8]            --
│    └─Scaler: 2-2862                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2863                      [16, 64, 8, 8]            --
│    └─Empty: 2-2864                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2865                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-215        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-2866                 [16, 64, 8, 8]            --
│    └─Empty: 2-2867                     [16, 64, 8, 8]            --
│    └─Empty: 2-2868                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-2869        --                        --
│    └─One: 2-2870                       [1]                       --
│    └─OutputScale: 2-2871               --                        --
│    └─Empty: 2-2872                     [64, 64, 3, 3]            --
│    └─Empty: 2-2873                     [64, 64, 3, 3]            --
│    └─Empty: 2-2874                     [64]                      --
│    └─Empty: 2-2875                     [64]                      --
│    └─BatchNorm2d: 2-2876               [16, 64, 8, 8]            --
│    └─Scaler: 2-2877                    [16, 64, 8, 8]            --
│    └─ReLU: 2-2878                      [16, 64, 8, 8]            --
│    └─Empty: 2-2879                     [16, 64, 8, 8]            --
│    └─Clamp: 2-2880                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-216        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2881                 [16, 64, 4, 4]            --
│    └─Empty: 2-2882                     [16, 64, 4, 4]            --
│    └─Empty: 2-2883                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2884        --                        --
│    └─One: 2-2885                       [1]                       --
│    └─OutputScale: 2-2886               --                        --
│    └─Empty: 2-2887                     [64, 64, 3, 3]            --
│    └─Empty: 2-2888                     [64, 64, 3, 3]            --
│    └─Empty: 2-2889                     [64]                      --
│    └─Empty: 2-2890                     [64]                      --
│    └─BatchNorm2d: 2-2891               [16, 64, 4, 4]            --
│    └─Scaler: 2-2892                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2893                      [16, 64, 4, 4]            --
│    └─Empty: 2-2894                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2895                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-217               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-2896        --                        --
│    └─One: 2-2897                       [1]                       --
│    └─OutputScale: 2-2898               --                        --
│    └─Empty: 2-2899                     [64, 64, 1, 1]            --
│    └─Empty: 2-2900                     [64, 64, 1, 1]            --
│    └─Empty: 2-2901                     [64]                      --
│    └─Empty: 2-2902                     [64]                      --
│    └─BatchNorm2d: 2-2903               [16, 64, 4, 4]            --
│    └─Scaler: 2-2904                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2905                      [16, 64, 4, 4]            --
│    └─Empty: 2-2906                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2907                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-218        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-2908                 [16, 64, 4, 4]            --
│    └─Empty: 2-2909                     [16, 64, 4, 4]            --
│    └─Empty: 2-2910                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-2911        --                        --
│    └─One: 2-2912                       [1]                       --
│    └─OutputScale: 2-2913               --                        --
│    └─Empty: 2-2914                     [64, 64, 3, 3]            --
│    └─Empty: 2-2915                     [64, 64, 3, 3]            --
│    └─Empty: 2-2916                     [64]                      --
│    └─Empty: 2-2917                     [64]                      --
│    └─BatchNorm2d: 2-2918               [16, 64, 4, 4]            --
│    └─Scaler: 2-2919                    [16, 64, 4, 4]            --
│    └─ReLU: 2-2920                      [16, 64, 4, 4]            --
│    └─Empty: 2-2921                     [16, 64, 4, 4]            --
│    └─Clamp: 2-2922                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-219        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2923                 [16, 64, 2, 2]            --
│    └─Empty: 2-2924                     [16, 64, 2, 2]            --
│    └─Empty: 2-2925                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2926        --                        --
│    └─One: 2-2927                       [1]                       --
│    └─OutputScale: 2-2928               --                        --
│    └─Empty: 2-2929                     [64, 64, 1, 1]            --
│    └─Empty: 2-2930                     [64, 64, 1, 1]            --
│    └─Empty: 2-2931                     [64]                      --
│    └─Empty: 2-2932                     [64]                      --
│    └─BatchNorm2d: 2-2933               [16, 64, 2, 2]            --
│    └─Scaler: 2-2934                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2935                      [16, 64, 2, 2]            --
│    └─Empty: 2-2936                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2937                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-220               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-2938        --                        --
│    └─One: 2-2939                       [1]                       --
│    └─OutputScale: 2-2940               --                        --
│    └─Empty: 2-2941                     [64, 64, 1, 1]            --
│    └─Empty: 2-2942                     [64, 64, 1, 1]            --
│    └─Empty: 2-2943                     [64]                      --
│    └─Empty: 2-2944                     [64]                      --
│    └─BatchNorm2d: 2-2945               [16, 64, 2, 2]            --
│    └─Scaler: 2-2946                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2947                      [16, 64, 2, 2]            --
│    └─Empty: 2-2948                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2949                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-221        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-2950                 [16, 64, 2, 2]            --
│    └─Empty: 2-2951                     [16, 64, 2, 2]            --
│    └─Empty: 2-2952                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-2953        --                        --
│    └─One: 2-2954                       [1]                       --
│    └─OutputScale: 2-2955               --                        --
│    └─Empty: 2-2956                     [64, 64, 3, 3]            --
│    └─Empty: 2-2957                     [64, 64, 3, 3]            --
│    └─Empty: 2-2958                     [64]                      --
│    └─Empty: 2-2959                     [64]                      --
│    └─BatchNorm2d: 2-2960               [16, 64, 2, 2]            --
│    └─Scaler: 2-2961                    [16, 64, 2, 2]            --
│    └─ReLU: 2-2962                      [16, 64, 2, 2]            --
│    └─Empty: 2-2963                     [16, 64, 2, 2]            --
│    └─Clamp: 2-2964                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-222               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2965        --                        --
│    └─One: 2-2966                       [1]                       --
│    └─OutputScale: 2-2967               --                        --
│    └─Empty: 2-2968                     [64, 48, 1, 1]            --
│    └─Empty: 2-2969                     [64, 48, 1, 1]            --
│    └─Empty: 2-2970                     [64]                      --
│    └─Empty: 2-2971                     [64]                      --
│    └─BatchNorm2d: 2-2972               [16, 64, 64, 64]          --
│    └─Scaler: 2-2973                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2974                      [16, 64, 64, 64]          --
│    └─Empty: 2-2975                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2976                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-223               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2977        --                        --
│    └─One: 2-2978                       [1]                       --
│    └─OutputScale: 2-2979               --                        --
│    └─Empty: 2-2980                     [64, 64, 3, 3]            --
│    └─Empty: 2-2981                     [64, 64, 3, 3]            --
│    └─Empty: 2-2982                     [64]                      --
│    └─Empty: 2-2983                     [64]                      --
│    └─BatchNorm2d: 2-2984               [16, 64, 64, 64]          --
│    └─Scaler: 2-2985                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2986                      [16, 64, 64, 64]          --
│    └─Empty: 2-2987                     [16, 64, 64, 64]          --
│    └─Clamp: 2-2988                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-224               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-2989        --                        --
│    └─One: 2-2990                       [1]                       --
│    └─OutputScale: 2-2991               --                        --
│    └─Empty: 2-2992                     [64, 64, 1, 1]            --
│    └─Empty: 2-2993                     [64, 64, 1, 1]            --
│    └─Empty: 2-2994                     [64]                      --
│    └─Empty: 2-2995                     [64]                      --
│    └─BatchNorm2d: 2-2996               [16, 64, 64, 64]          --
│    └─Scaler: 2-2997                    [16, 64, 64, 64]          --
│    └─ReLU: 2-2998                      [16, 64, 64, 64]          --
│    └─Empty: 2-2999                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3000                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-225               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3001        --                        --
│    └─One: 2-3002                       [1]                       --
│    └─OutputScale: 2-3003               --                        --
│    └─Empty: 2-3004                     [64, 64, 3, 3]            --
│    └─Empty: 2-3005                     [64, 64, 3, 3]            --
│    └─Empty: 2-3006                     [64]                      --
│    └─Empty: 2-3007                     [64]                      --
│    └─BatchNorm2d: 2-3008               [16, 64, 64, 64]          --
│    └─Scaler: 2-3009                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3010                      [16, 64, 64, 64]          --
│    └─Empty: 2-3011                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3012                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-226        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3013                 [16, 64, 32, 32]          --
│    └─Empty: 2-3014                     [16, 64, 32, 32]          --
│    └─Empty: 2-3015                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3016        --                        --
│    └─One: 2-3017                       [1]                       --
│    └─OutputScale: 2-3018               --                        --
│    └─Empty: 2-3019                     [64, 64, 3, 3]            --
│    └─Empty: 2-3020                     [64, 64, 3, 3]            --
│    └─Empty: 2-3021                     [64]                      --
│    └─Empty: 2-3022                     [64]                      --
│    └─BatchNorm2d: 2-3023               [16, 64, 32, 32]          --
│    └─Scaler: 2-3024                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3025                      [16, 64, 32, 32]          --
│    └─Empty: 2-3026                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3027                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-227               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3028        --                        --
│    └─One: 2-3029                       [1]                       --
│    └─OutputScale: 2-3030               --                        --
│    └─Empty: 2-3031                     [64, 64, 3, 3]            --
│    └─Empty: 2-3032                     [64, 64, 3, 3]            --
│    └─Empty: 2-3033                     [64]                      --
│    └─Empty: 2-3034                     [64]                      --
│    └─BatchNorm2d: 2-3035               [16, 64, 32, 32]          --
│    └─Scaler: 2-3036                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3037                      [16, 64, 32, 32]          --
│    └─Empty: 2-3038                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3039                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-228        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3040                 [16, 64, 16, 16]          --
│    └─Empty: 2-3041                     [16, 64, 16, 16]          --
│    └─Empty: 2-3042                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3043        --                        --
│    └─One: 2-3044                       [1]                       --
│    └─OutputScale: 2-3045               --                        --
│    └─Empty: 2-3046                     [64, 64, 3, 3]            --
│    └─Empty: 2-3047                     [64, 64, 3, 3]            --
│    └─Empty: 2-3048                     [64]                      --
│    └─Empty: 2-3049                     [64]                      --
│    └─BatchNorm2d: 2-3050               [16, 64, 16, 16]          --
│    └─Scaler: 2-3051                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3052                      [16, 64, 16, 16]          --
│    └─Empty: 2-3053                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3054                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-229               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3055        --                        --
│    └─One: 2-3056                       [1]                       --
│    └─OutputScale: 2-3057               --                        --
│    └─Empty: 2-3058                     [64, 64, 3, 3]            --
│    └─Empty: 2-3059                     [64, 64, 3, 3]            --
│    └─Empty: 2-3060                     [64]                      --
│    └─Empty: 2-3061                     [64]                      --
│    └─BatchNorm2d: 2-3062               [16, 64, 16, 16]          --
│    └─Scaler: 2-3063                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3064                      [16, 64, 16, 16]          --
│    └─Empty: 2-3065                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3066                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-230        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3067                 [16, 64, 8, 8]            --
│    └─Empty: 2-3068                     [16, 64, 8, 8]            --
│    └─Empty: 2-3069                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3070        --                        --
│    └─One: 2-3071                       [1]                       --
│    └─OutputScale: 2-3072               --                        --
│    └─Empty: 2-3073                     [64, 64, 3, 3]            --
│    └─Empty: 2-3074                     [64, 64, 3, 3]            --
│    └─Empty: 2-3075                     [64]                      --
│    └─Empty: 2-3076                     [64]                      --
│    └─BatchNorm2d: 2-3077               [16, 64, 8, 8]            --
│    └─Scaler: 2-3078                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3079                      [16, 64, 8, 8]            --
│    └─Empty: 2-3080                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3081                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-231               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3082        --                        --
│    └─One: 2-3083                       [1]                       --
│    └─OutputScale: 2-3084               --                        --
│    └─Empty: 2-3085                     [64, 64, 1, 1]            --
│    └─Empty: 2-3086                     [64, 64, 1, 1]            --
│    └─Empty: 2-3087                     [64]                      --
│    └─Empty: 2-3088                     [64]                      --
│    └─BatchNorm2d: 2-3089               [16, 64, 8, 8]            --
│    └─Scaler: 2-3090                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3091                      [16, 64, 8, 8]            --
│    └─Empty: 2-3092                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3093                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-232        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3094                 [16, 64, 8, 8]            --
│    └─Empty: 2-3095                     [16, 64, 8, 8]            --
│    └─Empty: 2-3096                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3097        --                        --
│    └─One: 2-3098                       [1]                       --
│    └─OutputScale: 2-3099               --                        --
│    └─Empty: 2-3100                     [64, 64, 3, 3]            --
│    └─Empty: 2-3101                     [64, 64, 3, 3]            --
│    └─Empty: 2-3102                     [64]                      --
│    └─Empty: 2-3103                     [64]                      --
│    └─BatchNorm2d: 2-3104               [16, 64, 8, 8]            --
│    └─Scaler: 2-3105                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3106                      [16, 64, 8, 8]            --
│    └─Empty: 2-3107                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3108                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-233        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3109                 [16, 64, 4, 4]            --
│    └─Empty: 2-3110                     [16, 64, 4, 4]            --
│    └─Empty: 2-3111                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3112        --                        --
│    └─One: 2-3113                       [1]                       --
│    └─OutputScale: 2-3114               --                        --
│    └─Empty: 2-3115                     [64, 64, 3, 3]            --
│    └─Empty: 2-3116                     [64, 64, 3, 3]            --
│    └─Empty: 2-3117                     [64]                      --
│    └─Empty: 2-3118                     [64]                      --
│    └─BatchNorm2d: 2-3119               [16, 64, 4, 4]            --
│    └─Scaler: 2-3120                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3121                      [16, 64, 4, 4]            --
│    └─Empty: 2-3122                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3123                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-234               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3124        --                        --
│    └─One: 2-3125                       [1]                       --
│    └─OutputScale: 2-3126               --                        --
│    └─Empty: 2-3127                     [64, 64, 1, 1]            --
│    └─Empty: 2-3128                     [64, 64, 1, 1]            --
│    └─Empty: 2-3129                     [64]                      --
│    └─Empty: 2-3130                     [64]                      --
│    └─BatchNorm2d: 2-3131               [16, 64, 4, 4]            --
│    └─Scaler: 2-3132                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3133                      [16, 64, 4, 4]            --
│    └─Empty: 2-3134                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3135                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-235        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3136                 [16, 64, 4, 4]            --
│    └─Empty: 2-3137                     [16, 64, 4, 4]            --
│    └─Empty: 2-3138                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3139        --                        --
│    └─One: 2-3140                       [1]                       --
│    └─OutputScale: 2-3141               --                        --
│    └─Empty: 2-3142                     [64, 64, 3, 3]            --
│    └─Empty: 2-3143                     [64, 64, 3, 3]            --
│    └─Empty: 2-3144                     [64]                      --
│    └─Empty: 2-3145                     [64]                      --
│    └─BatchNorm2d: 2-3146               [16, 64, 4, 4]            --
│    └─Scaler: 2-3147                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3148                      [16, 64, 4, 4]            --
│    └─Empty: 2-3149                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3150                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-236        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3151                 [16, 64, 2, 2]            --
│    └─Empty: 2-3152                     [16, 64, 2, 2]            --
│    └─Empty: 2-3153                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3154        --                        --
│    └─One: 2-3155                       [1]                       --
│    └─OutputScale: 2-3156               --                        --
│    └─Empty: 2-3157                     [64, 64, 1, 1]            --
│    └─Empty: 2-3158                     [64, 64, 1, 1]            --
│    └─Empty: 2-3159                     [64]                      --
│    └─Empty: 2-3160                     [64]                      --
│    └─BatchNorm2d: 2-3161               [16, 64, 2, 2]            --
│    └─Scaler: 2-3162                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3163                      [16, 64, 2, 2]            --
│    └─Empty: 2-3164                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3165                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-237               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3166        --                        --
│    └─One: 2-3167                       [1]                       --
│    └─OutputScale: 2-3168               --                        --
│    └─Empty: 2-3169                     [64, 64, 1, 1]            --
│    └─Empty: 2-3170                     [64, 64, 1, 1]            --
│    └─Empty: 2-3171                     [64]                      --
│    └─Empty: 2-3172                     [64]                      --
│    └─BatchNorm2d: 2-3173               [16, 64, 2, 2]            --
│    └─Scaler: 2-3174                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3175                      [16, 64, 2, 2]            --
│    └─Empty: 2-3176                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3177                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-238        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3178                 [16, 64, 2, 2]            --
│    └─Empty: 2-3179                     [16, 64, 2, 2]            --
│    └─Empty: 2-3180                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3181        --                        --
│    └─One: 2-3182                       [1]                       --
│    └─OutputScale: 2-3183               --                        --
│    └─Empty: 2-3184                     [64, 64, 3, 3]            --
│    └─Empty: 2-3185                     [64, 64, 3, 3]            --
│    └─Empty: 2-3186                     [64]                      --
│    └─Empty: 2-3187                     [64]                      --
│    └─BatchNorm2d: 2-3188               [16, 64, 2, 2]            --
│    └─Scaler: 2-3189                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3190                      [16, 64, 2, 2]            --
│    └─Empty: 2-3191                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3192                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-239               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3193        --                        --
│    └─One: 2-3194                       [1]                       --
│    └─OutputScale: 2-3195               --                        --
│    └─Empty: 2-3196                     [64, 48, 1, 1]            --
│    └─Empty: 2-3197                     [64, 48, 1, 1]            --
│    └─Empty: 2-3198                     [64]                      --
│    └─Empty: 2-3199                     [64]                      --
│    └─BatchNorm2d: 2-3200               [16, 64, 64, 64]          --
│    └─Scaler: 2-3201                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3202                      [16, 64, 64, 64]          --
│    └─Empty: 2-3203                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3204                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-240               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3205        --                        --
│    └─One: 2-3206                       [1]                       --
│    └─OutputScale: 2-3207               --                        --
│    └─Empty: 2-3208                     [64, 64, 3, 3]            --
│    └─Empty: 2-3209                     [64, 64, 3, 3]            --
│    └─Empty: 2-3210                     [64]                      --
│    └─Empty: 2-3211                     [64]                      --
│    └─BatchNorm2d: 2-3212               [16, 64, 64, 64]          --
│    └─Scaler: 2-3213                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3214                      [16, 64, 64, 64]          --
│    └─Empty: 2-3215                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3216                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-241               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3217        --                        --
│    └─One: 2-3218                       [1]                       --
│    └─OutputScale: 2-3219               --                        --
│    └─Empty: 2-3220                     [64, 64, 1, 1]            --
│    └─Empty: 2-3221                     [64, 64, 1, 1]            --
│    └─Empty: 2-3222                     [64]                      --
│    └─Empty: 2-3223                     [64]                      --
│    └─BatchNorm2d: 2-3224               [16, 64, 64, 64]          --
│    └─Scaler: 2-3225                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3226                      [16, 64, 64, 64]          --
│    └─Empty: 2-3227                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3228                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-242               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3229        --                        --
│    └─One: 2-3230                       [1]                       --
│    └─OutputScale: 2-3231               --                        --
│    └─Empty: 2-3232                     [64, 64, 3, 3]            --
│    └─Empty: 2-3233                     [64, 64, 3, 3]            --
│    └─Empty: 2-3234                     [64]                      --
│    └─Empty: 2-3235                     [64]                      --
│    └─BatchNorm2d: 2-3236               [16, 64, 64, 64]          --
│    └─Scaler: 2-3237                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3238                      [16, 64, 64, 64]          --
│    └─Empty: 2-3239                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3240                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-243        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3241                 [16, 64, 32, 32]          --
│    └─Empty: 2-3242                     [16, 64, 32, 32]          --
│    └─Empty: 2-3243                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3244        --                        --
│    └─One: 2-3245                       [1]                       --
│    └─OutputScale: 2-3246               --                        --
│    └─Empty: 2-3247                     [64, 64, 3, 3]            --
│    └─Empty: 2-3248                     [64, 64, 3, 3]            --
│    └─Empty: 2-3249                     [64]                      --
│    └─Empty: 2-3250                     [64]                      --
│    └─BatchNorm2d: 2-3251               [16, 64, 32, 32]          --
│    └─Scaler: 2-3252                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3253                      [16, 64, 32, 32]          --
│    └─Empty: 2-3254                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3255                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-244               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3256        --                        --
│    └─One: 2-3257                       [1]                       --
│    └─OutputScale: 2-3258               --                        --
│    └─Empty: 2-3259                     [64, 64, 3, 3]            --
│    └─Empty: 2-3260                     [64, 64, 3, 3]            --
│    └─Empty: 2-3261                     [64]                      --
│    └─Empty: 2-3262                     [64]                      --
│    └─BatchNorm2d: 2-3263               [16, 64, 32, 32]          --
│    └─Scaler: 2-3264                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3265                      [16, 64, 32, 32]          --
│    └─Empty: 2-3266                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3267                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-245        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3268                 [16, 64, 16, 16]          --
│    └─Empty: 2-3269                     [16, 64, 16, 16]          --
│    └─Empty: 2-3270                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3271        --                        --
│    └─One: 2-3272                       [1]                       --
│    └─OutputScale: 2-3273               --                        --
│    └─Empty: 2-3274                     [64, 64, 3, 3]            --
│    └─Empty: 2-3275                     [64, 64, 3, 3]            --
│    └─Empty: 2-3276                     [64]                      --
│    └─Empty: 2-3277                     [64]                      --
│    └─BatchNorm2d: 2-3278               [16, 64, 16, 16]          --
│    └─Scaler: 2-3279                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3280                      [16, 64, 16, 16]          --
│    └─Empty: 2-3281                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3282                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-246               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3283        --                        --
│    └─One: 2-3284                       [1]                       --
│    └─OutputScale: 2-3285               --                        --
│    └─Empty: 2-3286                     [64, 64, 3, 3]            --
│    └─Empty: 2-3287                     [64, 64, 3, 3]            --
│    └─Empty: 2-3288                     [64]                      --
│    └─Empty: 2-3289                     [64]                      --
│    └─BatchNorm2d: 2-3290               [16, 64, 16, 16]          --
│    └─Scaler: 2-3291                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3292                      [16, 64, 16, 16]          --
│    └─Empty: 2-3293                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3294                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-247        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3295                 [16, 64, 8, 8]            --
│    └─Empty: 2-3296                     [16, 64, 8, 8]            --
│    └─Empty: 2-3297                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3298        --                        --
│    └─One: 2-3299                       [1]                       --
│    └─OutputScale: 2-3300               --                        --
│    └─Empty: 2-3301                     [64, 64, 3, 3]            --
│    └─Empty: 2-3302                     [64, 64, 3, 3]            --
│    └─Empty: 2-3303                     [64]                      --
│    └─Empty: 2-3304                     [64]                      --
│    └─BatchNorm2d: 2-3305               [16, 64, 8, 8]            --
│    └─Scaler: 2-3306                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3307                      [16, 64, 8, 8]            --
│    └─Empty: 2-3308                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3309                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-248               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3310        --                        --
│    └─One: 2-3311                       [1]                       --
│    └─OutputScale: 2-3312               --                        --
│    └─Empty: 2-3313                     [64, 64, 1, 1]            --
│    └─Empty: 2-3314                     [64, 64, 1, 1]            --
│    └─Empty: 2-3315                     [64]                      --
│    └─Empty: 2-3316                     [64]                      --
│    └─BatchNorm2d: 2-3317               [16, 64, 8, 8]            --
│    └─Scaler: 2-3318                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3319                      [16, 64, 8, 8]            --
│    └─Empty: 2-3320                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3321                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-249        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3322                 [16, 64, 8, 8]            --
│    └─Empty: 2-3323                     [16, 64, 8, 8]            --
│    └─Empty: 2-3324                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3325        --                        --
│    └─One: 2-3326                       [1]                       --
│    └─OutputScale: 2-3327               --                        --
│    └─Empty: 2-3328                     [64, 64, 3, 3]            --
│    └─Empty: 2-3329                     [64, 64, 3, 3]            --
│    └─Empty: 2-3330                     [64]                      --
│    └─Empty: 2-3331                     [64]                      --
│    └─BatchNorm2d: 2-3332               [16, 64, 8, 8]            --
│    └─Scaler: 2-3333                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3334                      [16, 64, 8, 8]            --
│    └─Empty: 2-3335                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3336                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-250        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3337                 [16, 64, 4, 4]            --
│    └─Empty: 2-3338                     [16, 64, 4, 4]            --
│    └─Empty: 2-3339                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3340        --                        --
│    └─One: 2-3341                       [1]                       --
│    └─OutputScale: 2-3342               --                        --
│    └─Empty: 2-3343                     [64, 64, 3, 3]            --
│    └─Empty: 2-3344                     [64, 64, 3, 3]            --
│    └─Empty: 2-3345                     [64]                      --
│    └─Empty: 2-3346                     [64]                      --
│    └─BatchNorm2d: 2-3347               [16, 64, 4, 4]            --
│    └─Scaler: 2-3348                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3349                      [16, 64, 4, 4]            --
│    └─Empty: 2-3350                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3351                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-251               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3352        --                        --
│    └─One: 2-3353                       [1]                       --
│    └─OutputScale: 2-3354               --                        --
│    └─Empty: 2-3355                     [64, 64, 1, 1]            --
│    └─Empty: 2-3356                     [64, 64, 1, 1]            --
│    └─Empty: 2-3357                     [64]                      --
│    └─Empty: 2-3358                     [64]                      --
│    └─BatchNorm2d: 2-3359               [16, 64, 4, 4]            --
│    └─Scaler: 2-3360                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3361                      [16, 64, 4, 4]            --
│    └─Empty: 2-3362                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3363                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-252        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3364                 [16, 64, 4, 4]            --
│    └─Empty: 2-3365                     [16, 64, 4, 4]            --
│    └─Empty: 2-3366                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3367        --                        --
│    └─One: 2-3368                       [1]                       --
│    └─OutputScale: 2-3369               --                        --
│    └─Empty: 2-3370                     [64, 64, 3, 3]            --
│    └─Empty: 2-3371                     [64, 64, 3, 3]            --
│    └─Empty: 2-3372                     [64]                      --
│    └─Empty: 2-3373                     [64]                      --
│    └─BatchNorm2d: 2-3374               [16, 64, 4, 4]            --
│    └─Scaler: 2-3375                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3376                      [16, 64, 4, 4]            --
│    └─Empty: 2-3377                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3378                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-253        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3379                 [16, 64, 2, 2]            --
│    └─Empty: 2-3380                     [16, 64, 2, 2]            --
│    └─Empty: 2-3381                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3382        --                        --
│    └─One: 2-3383                       [1]                       --
│    └─OutputScale: 2-3384               --                        --
│    └─Empty: 2-3385                     [64, 64, 1, 1]            --
│    └─Empty: 2-3386                     [64, 64, 1, 1]            --
│    └─Empty: 2-3387                     [64]                      --
│    └─Empty: 2-3388                     [64]                      --
│    └─BatchNorm2d: 2-3389               [16, 64, 2, 2]            --
│    └─Scaler: 2-3390                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3391                      [16, 64, 2, 2]            --
│    └─Empty: 2-3392                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3393                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-254               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3394        --                        --
│    └─One: 2-3395                       [1]                       --
│    └─OutputScale: 2-3396               --                        --
│    └─Empty: 2-3397                     [64, 64, 1, 1]            --
│    └─Empty: 2-3398                     [64, 64, 1, 1]            --
│    └─Empty: 2-3399                     [64]                      --
│    └─Empty: 2-3400                     [64]                      --
│    └─BatchNorm2d: 2-3401               [16, 64, 2, 2]            --
│    └─Scaler: 2-3402                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3403                      [16, 64, 2, 2]            --
│    └─Empty: 2-3404                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3405                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-255        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3406                 [16, 64, 2, 2]            --
│    └─Empty: 2-3407                     [16, 64, 2, 2]            --
│    └─Empty: 2-3408                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3409        --                        --
│    └─One: 2-3410                       [1]                       --
│    └─OutputScale: 2-3411               --                        --
│    └─Empty: 2-3412                     [64, 64, 3, 3]            --
│    └─Empty: 2-3413                     [64, 64, 3, 3]            --
│    └─Empty: 2-3414                     [64]                      --
│    └─Empty: 2-3415                     [64]                      --
│    └─BatchNorm2d: 2-3416               [16, 64, 2, 2]            --
│    └─Scaler: 2-3417                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3418                      [16, 64, 2, 2]            --
│    └─Empty: 2-3419                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3420                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-256               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3421        --                        --
│    └─One: 2-3422                       [1]                       --
│    └─OutputScale: 2-3423               --                        --
│    └─Empty: 2-3424                     [64, 48, 1, 1]            --
│    └─Empty: 2-3425                     [64, 48, 1, 1]            --
│    └─Empty: 2-3426                     [64]                      --
│    └─Empty: 2-3427                     [64]                      --
│    └─BatchNorm2d: 2-3428               [16, 64, 64, 64]          --
│    └─Scaler: 2-3429                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3430                      [16, 64, 64, 64]          --
│    └─Empty: 2-3431                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3432                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-257               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3433        --                        --
│    └─One: 2-3434                       [1]                       --
│    └─OutputScale: 2-3435               --                        --
│    └─Empty: 2-3436                     [64, 64, 3, 3]            --
│    └─Empty: 2-3437                     [64, 64, 3, 3]            --
│    └─Empty: 2-3438                     [64]                      --
│    └─Empty: 2-3439                     [64]                      --
│    └─BatchNorm2d: 2-3440               [16, 64, 64, 64]          --
│    └─Scaler: 2-3441                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3442                      [16, 64, 64, 64]          --
│    └─Empty: 2-3443                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3444                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-258               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3445        --                        --
│    └─One: 2-3446                       [1]                       --
│    └─OutputScale: 2-3447               --                        --
│    └─Empty: 2-3448                     [64, 64, 1, 1]            --
│    └─Empty: 2-3449                     [64, 64, 1, 1]            --
│    └─Empty: 2-3450                     [64]                      --
│    └─Empty: 2-3451                     [64]                      --
│    └─BatchNorm2d: 2-3452               [16, 64, 64, 64]          --
│    └─Scaler: 2-3453                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3454                      [16, 64, 64, 64]          --
│    └─Empty: 2-3455                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3456                     [16, 64, 64, 64]          --
├─FusedConv2dBNReLU: 1-259               [16, 64, 64, 64]          (recursive)
│    └─OutputShiftSqueeze: 2-3457        --                        --
│    └─One: 2-3458                       [1]                       --
│    └─OutputScale: 2-3459               --                        --
│    └─Empty: 2-3460                     [64, 64, 3, 3]            --
│    └─Empty: 2-3461                     [64, 64, 3, 3]            --
│    └─Empty: 2-3462                     [64]                      --
│    └─Empty: 2-3463                     [64]                      --
│    └─BatchNorm2d: 2-3464               [16, 64, 64, 64]          --
│    └─Scaler: 2-3465                    [16, 64, 64, 64]          --
│    └─ReLU: 2-3466                      [16, 64, 64, 64]          --
│    └─Empty: 2-3467                     [16, 64, 64, 64]          --
│    └─Clamp: 2-3468                     [16, 64, 64, 64]          --
├─FusedMaxPoolConv2dBNReLU: 1-260        [16, 64, 32, 32]          (recursive)
│    └─MaxPool2d: 2-3469                 [16, 64, 32, 32]          --
│    └─Empty: 2-3470                     [16, 64, 32, 32]          --
│    └─Empty: 2-3471                     [16, 64, 32, 32]          --
│    └─OutputShiftSqueeze: 2-3472        --                        --
│    └─One: 2-3473                       [1]                       --
│    └─OutputScale: 2-3474               --                        --
│    └─Empty: 2-3475                     [64, 64, 3, 3]            --
│    └─Empty: 2-3476                     [64, 64, 3, 3]            --
│    └─Empty: 2-3477                     [64]                      --
│    └─Empty: 2-3478                     [64]                      --
│    └─BatchNorm2d: 2-3479               [16, 64, 32, 32]          --
│    └─Scaler: 2-3480                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3481                      [16, 64, 32, 32]          --
│    └─Empty: 2-3482                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3483                     [16, 64, 32, 32]          --
├─FusedConv2dBNReLU: 1-261               [16, 64, 32, 32]          (recursive)
│    └─OutputShiftSqueeze: 2-3484        --                        --
│    └─One: 2-3485                       [1]                       --
│    └─OutputScale: 2-3486               --                        --
│    └─Empty: 2-3487                     [64, 64, 3, 3]            --
│    └─Empty: 2-3488                     [64, 64, 3, 3]            --
│    └─Empty: 2-3489                     [64]                      --
│    └─Empty: 2-3490                     [64]                      --
│    └─BatchNorm2d: 2-3491               [16, 64, 32, 32]          --
│    └─Scaler: 2-3492                    [16, 64, 32, 32]          --
│    └─ReLU: 2-3493                      [16, 64, 32, 32]          --
│    └─Empty: 2-3494                     [16, 64, 32, 32]          --
│    └─Clamp: 2-3495                     [16, 64, 32, 32]          --
├─FusedMaxPoolConv2dBNReLU: 1-262        [16, 64, 16, 16]          (recursive)
│    └─MaxPool2d: 2-3496                 [16, 64, 16, 16]          --
│    └─Empty: 2-3497                     [16, 64, 16, 16]          --
│    └─Empty: 2-3498                     [16, 64, 16, 16]          --
│    └─OutputShiftSqueeze: 2-3499        --                        --
│    └─One: 2-3500                       [1]                       --
│    └─OutputScale: 2-3501               --                        --
│    └─Empty: 2-3502                     [64, 64, 3, 3]            --
│    └─Empty: 2-3503                     [64, 64, 3, 3]            --
│    └─Empty: 2-3504                     [64]                      --
│    └─Empty: 2-3505                     [64]                      --
│    └─BatchNorm2d: 2-3506               [16, 64, 16, 16]          --
│    └─Scaler: 2-3507                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3508                      [16, 64, 16, 16]          --
│    └─Empty: 2-3509                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3510                     [16, 64, 16, 16]          --
├─FusedConv2dBNReLU: 1-263               [16, 64, 16, 16]          (recursive)
│    └─OutputShiftSqueeze: 2-3511        --                        --
│    └─One: 2-3512                       [1]                       --
│    └─OutputScale: 2-3513               --                        --
│    └─Empty: 2-3514                     [64, 64, 3, 3]            --
│    └─Empty: 2-3515                     [64, 64, 3, 3]            --
│    └─Empty: 2-3516                     [64]                      --
│    └─Empty: 2-3517                     [64]                      --
│    └─BatchNorm2d: 2-3518               [16, 64, 16, 16]          --
│    └─Scaler: 2-3519                    [16, 64, 16, 16]          --
│    └─ReLU: 2-3520                      [16, 64, 16, 16]          --
│    └─Empty: 2-3521                     [16, 64, 16, 16]          --
│    └─Clamp: 2-3522                     [16, 64, 16, 16]          --
├─FusedMaxPoolConv2dBNReLU: 1-264        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3523                 [16, 64, 8, 8]            --
│    └─Empty: 2-3524                     [16, 64, 8, 8]            --
│    └─Empty: 2-3525                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3526        --                        --
│    └─One: 2-3527                       [1]                       --
│    └─OutputScale: 2-3528               --                        --
│    └─Empty: 2-3529                     [64, 64, 3, 3]            --
│    └─Empty: 2-3530                     [64, 64, 3, 3]            --
│    └─Empty: 2-3531                     [64]                      --
│    └─Empty: 2-3532                     [64]                      --
│    └─BatchNorm2d: 2-3533               [16, 64, 8, 8]            --
│    └─Scaler: 2-3534                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3535                      [16, 64, 8, 8]            --
│    └─Empty: 2-3536                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3537                     [16, 64, 8, 8]            --
├─FusedConv2dBNReLU: 1-265               [16, 64, 8, 8]            (recursive)
│    └─OutputShiftSqueeze: 2-3538        --                        --
│    └─One: 2-3539                       [1]                       --
│    └─OutputScale: 2-3540               --                        --
│    └─Empty: 2-3541                     [64, 64, 1, 1]            --
│    └─Empty: 2-3542                     [64, 64, 1, 1]            --
│    └─Empty: 2-3543                     [64]                      --
│    └─Empty: 2-3544                     [64]                      --
│    └─BatchNorm2d: 2-3545               [16, 64, 8, 8]            --
│    └─Scaler: 2-3546                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3547                      [16, 64, 8, 8]            --
│    └─Empty: 2-3548                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3549                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-266        [16, 64, 8, 8]            (recursive)
│    └─MaxPool2d: 2-3550                 [16, 64, 8, 8]            --
│    └─Empty: 2-3551                     [16, 64, 8, 8]            --
│    └─Empty: 2-3552                     [16, 64, 8, 8]            --
│    └─OutputShiftSqueeze: 2-3553        --                        --
│    └─One: 2-3554                       [1]                       --
│    └─OutputScale: 2-3555               --                        --
│    └─Empty: 2-3556                     [64, 64, 3, 3]            --
│    └─Empty: 2-3557                     [64, 64, 3, 3]            --
│    └─Empty: 2-3558                     [64]                      --
│    └─Empty: 2-3559                     [64]                      --
│    └─BatchNorm2d: 2-3560               [16, 64, 8, 8]            --
│    └─Scaler: 2-3561                    [16, 64, 8, 8]            --
│    └─ReLU: 2-3562                      [16, 64, 8, 8]            --
│    └─Empty: 2-3563                     [16, 64, 8, 8]            --
│    └─Clamp: 2-3564                     [16, 64, 8, 8]            --
├─FusedMaxPoolConv2dBNReLU: 1-267        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3565                 [16, 64, 4, 4]            --
│    └─Empty: 2-3566                     [16, 64, 4, 4]            --
│    └─Empty: 2-3567                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3568        --                        --
│    └─One: 2-3569                       [1]                       --
│    └─OutputScale: 2-3570               --                        --
│    └─Empty: 2-3571                     [64, 64, 3, 3]            --
│    └─Empty: 2-3572                     [64, 64, 3, 3]            --
│    └─Empty: 2-3573                     [64]                      --
│    └─Empty: 2-3574                     [64]                      --
│    └─BatchNorm2d: 2-3575               [16, 64, 4, 4]            --
│    └─Scaler: 2-3576                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3577                      [16, 64, 4, 4]            --
│    └─Empty: 2-3578                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3579                     [16, 64, 4, 4]            --
├─FusedConv2dBNReLU: 1-268               [16, 64, 4, 4]            (recursive)
│    └─OutputShiftSqueeze: 2-3580        --                        --
│    └─One: 2-3581                       [1]                       --
│    └─OutputScale: 2-3582               --                        --
│    └─Empty: 2-3583                     [64, 64, 1, 1]            --
│    └─Empty: 2-3584                     [64, 64, 1, 1]            --
│    └─Empty: 2-3585                     [64]                      --
│    └─Empty: 2-3586                     [64]                      --
│    └─BatchNorm2d: 2-3587               [16, 64, 4, 4]            --
│    └─Scaler: 2-3588                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3589                      [16, 64, 4, 4]            --
│    └─Empty: 2-3590                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3591                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-269        [16, 64, 4, 4]            (recursive)
│    └─MaxPool2d: 2-3592                 [16, 64, 4, 4]            --
│    └─Empty: 2-3593                     [16, 64, 4, 4]            --
│    └─Empty: 2-3594                     [16, 64, 4, 4]            --
│    └─OutputShiftSqueeze: 2-3595        --                        --
│    └─One: 2-3596                       [1]                       --
│    └─OutputScale: 2-3597               --                        --
│    └─Empty: 2-3598                     [64, 64, 3, 3]            --
│    └─Empty: 2-3599                     [64, 64, 3, 3]            --
│    └─Empty: 2-3600                     [64]                      --
│    └─Empty: 2-3601                     [64]                      --
│    └─BatchNorm2d: 2-3602               [16, 64, 4, 4]            --
│    └─Scaler: 2-3603                    [16, 64, 4, 4]            --
│    └─ReLU: 2-3604                      [16, 64, 4, 4]            --
│    └─Empty: 2-3605                     [16, 64, 4, 4]            --
│    └─Clamp: 2-3606                     [16, 64, 4, 4]            --
├─FusedMaxPoolConv2dBNReLU: 1-270        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3607                 [16, 64, 2, 2]            --
│    └─Empty: 2-3608                     [16, 64, 2, 2]            --
│    └─Empty: 2-3609                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3610        --                        --
│    └─One: 2-3611                       [1]                       --
│    └─OutputScale: 2-3612               --                        --
│    └─Empty: 2-3613                     [64, 64, 1, 1]            --
│    └─Empty: 2-3614                     [64, 64, 1, 1]            --
│    └─Empty: 2-3615                     [64]                      --
│    └─Empty: 2-3616                     [64]                      --
│    └─BatchNorm2d: 2-3617               [16, 64, 2, 2]            --
│    └─Scaler: 2-3618                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3619                      [16, 64, 2, 2]            --
│    └─Empty: 2-3620                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3621                     [16, 64, 2, 2]            --
├─FusedConv2dBNReLU: 1-271               [16, 64, 2, 2]            (recursive)
│    └─OutputShiftSqueeze: 2-3622        --                        --
│    └─One: 2-3623                       [1]                       --
│    └─OutputScale: 2-3624               --                        --
│    └─Empty: 2-3625                     [64, 64, 1, 1]            --
│    └─Empty: 2-3626                     [64, 64, 1, 1]            --
│    └─Empty: 2-3627                     [64]                      --
│    └─Empty: 2-3628                     [64]                      --
│    └─BatchNorm2d: 2-3629               [16, 64, 2, 2]            --
│    └─Scaler: 2-3630                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3631                      [16, 64, 2, 2]            --
│    └─Empty: 2-3632                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3633                     [16, 64, 2, 2]            --
├─FusedMaxPoolConv2dBNReLU: 1-272        [16, 64, 2, 2]            (recursive)
│    └─MaxPool2d: 2-3634                 [16, 64, 2, 2]            --
│    └─Empty: 2-3635                     [16, 64, 2, 2]            --
│    └─Empty: 2-3636                     [16, 64, 2, 2]            --
│    └─OutputShiftSqueeze: 2-3637        --                        --
│    └─One: 2-3638                       [1]                       --
│    └─OutputScale: 2-3639               --                        --
│    └─Empty: 2-3640                     [64, 64, 3, 3]            --
│    └─Empty: 2-3641                     [64, 64, 3, 3]            --
│    └─Empty: 2-3642                     [64]                      --
│    └─Empty: 2-3643                     [64]                      --
│    └─BatchNorm2d: 2-3644               [16, 64, 2, 2]            --
│    └─Scaler: 2-3645                    [16, 64, 2, 2]            --
│    └─ReLU: 2-3646                      [16, 64, 2, 2]            --
│    └─Empty: 2-3647                     [16, 64, 2, 2]            --
│    └─Clamp: 2-3648                     [16, 64, 2, 2]            --
├─Conv1d: 1-273                          [16, 64, 16]              16,454
│    └─OutputShiftSqueeze: 2-3649        --                        --
│    └─One: 2-3650                       [1]                       --
│    └─OutputScale: 2-3651               --                        --
│    └─Empty: 2-3652                     [64, 256, 1]              --
│    └─Empty: 2-3653                     [64, 256, 1]              --
│    └─Empty: 2-3654                     [64]                      --
│    └─Empty: 2-3655                     [64]                      --
│    └─Scaler: 2-3656                    [16, 64, 16]              --
│    └─Empty: 2-3657                     [16, 64, 16]              --
│    └─Empty: 2-3658                     [16, 64, 16]              --
│    └─Clamp: 2-3659                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-274               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3660        --                        --
│    └─One: 2-3661                       [1]                       --
│    └─OutputScale: 2-3662               --                        --
│    └─Empty: 2-3663                     [64, 64, 3]               --
│    └─Empty: 2-3664                     [64, 64, 3]               --
│    └─Empty: 2-3665                     [64]                      --
│    └─Empty: 2-3666                     [64]                      --
│    └─BatchNorm1d: 2-3667               [16, 64, 16]              --
│    └─Scaler: 2-3668                    [16, 64, 16]              --
│    └─ReLU: 2-3669                      [16, 64, 16]              --
│    └─Empty: 2-3670                     [16, 64, 16]              --
│    └─Clamp: 2-3671                     [16, 64, 16]              --
├─Conv1d: 1-275                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3672        --                        --
│    └─One: 2-3673                       [1]                       --
│    └─OutputScale: 2-3674               --                        --
│    └─Empty: 2-3675                     [64, 64, 1]               --
│    └─Empty: 2-3676                     [64, 64, 1]               --
│    └─Empty: 2-3677                     [64]                      --
│    └─Empty: 2-3678                     [64]                      --
│    └─Scaler: 2-3679                    [16, 64, 16]              --
│    └─Empty: 2-3680                     [16, 64, 16]              --
│    └─Empty: 2-3681                     [16, 64, 16]              --
│    └─Clamp: 2-3682                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-276               [16, 64, 16]              12,358
│    └─OutputShiftSqueeze: 2-3683        --                        --
│    └─One: 2-3684                       [1]                       --
│    └─OutputScale: 2-3685               --                        --
│    └─Empty: 2-3686                     [64, 64, 3]               --
│    └─Empty: 2-3687                     [64, 64, 3]               --
│    └─Empty: 2-3688                     [64]                      --
│    └─Empty: 2-3689                     [64]                      --
│    └─BatchNorm1d: 2-3690               [16, 64, 16]              --
│    └─Scaler: 2-3691                    [16, 64, 16]              --
│    └─ReLU: 2-3692                      [16, 64, 16]              --
│    └─Empty: 2-3693                     [16, 64, 16]              --
│    └─Clamp: 2-3694                     [16, 64, 16]              --
├─Conv1d: 1-277                          [16, 64, 16]              4,166
│    └─OutputShiftSqueeze: 2-3695        --                        --
│    └─One: 2-3696                       [1]                       --
│    └─OutputScale: 2-3697               --                        --
│    └─Empty: 2-3698                     [64, 64, 1]               --
│    └─Empty: 2-3699                     [64, 64, 1]               --
│    └─Empty: 2-3700                     [64]                      --
│    └─Empty: 2-3701                     [64]                      --
│    └─Scaler: 2-3702                    [16, 64, 16]              --
│    └─Empty: 2-3703                     [16, 64, 16]              --
│    └─Empty: 2-3704                     [16, 64, 16]              --
│    └─Clamp: 2-3705                     [16, 64, 16]              --
├─FusedConv1dBNReLU: 1-278               [16, 64, 12]              12,358
│    └─OutputShiftSqueeze: 2-3706        --                        --
│    └─One: 2-3707                       [1]                       --
│    └─OutputScale: 2-3708               --                        --
│    └─Empty: 2-3709                     [64, 64, 3]               --
│    └─Empty: 2-3710                     [64, 64, 3]               --
│    └─Empty: 2-3711                     [64]                      --
│    └─Empty: 2-3712                     [64]                      --
│    └─BatchNorm1d: 2-3713               [16, 64, 12]              --
│    └─Scaler: 2-3714                    [16, 64, 12]              --
│    └─ReLU: 2-3715                      [16, 64, 12]              --
│    └─Empty: 2-3716                     [16, 64, 12]              --
│    └─Clamp: 2-3717                     [16, 64, 12]              --
├─Conv1d: 1-279                          [16, 64, 12]              4,166
│    └─OutputShiftSqueeze: 2-3718        --                        --
│    └─One: 2-3719                       [1]                       --
│    └─OutputScale: 2-3720               --                        --
│    └─Empty: 2-3721                     [64, 64, 1]               --
│    └─Empty: 2-3722                     [64, 64, 1]               --
│    └─Empty: 2-3723                     [64]                      --
│    └─Empty: 2-3724                     [64]                      --
│    └─Scaler: 2-3725                    [16, 64, 12]              --
│    └─Empty: 2-3726                     [16, 64, 12]              --
│    └─Empty: 2-3727                     [16, 64, 12]              --
│    └─Clamp: 2-3728                     [16, 64, 12]              --
├─FusedConv1dBNReLU: 1-280               [16, 64, 8]               12,358
│    └─OutputShiftSqueeze: 2-3729        --                        --
│    └─One: 2-3730                       [1]                       --
│    └─OutputScale: 2-3731               --                        --
│    └─Empty: 2-3732                     [64, 64, 3]               --
│    └─Empty: 2-3733                     [64, 64, 3]               --
│    └─Empty: 2-3734                     [64]                      --
│    └─Empty: 2-3735                     [64]                      --
│    └─BatchNorm1d: 2-3736               [16, 64, 8]               --
│    └─Scaler: 2-3737                    [16, 64, 8]               --
│    └─ReLU: 2-3738                      [16, 64, 8]               --
│    └─Empty: 2-3739                     [16, 64, 8]               --
│    └─Clamp: 2-3740                     [16, 64, 8]               --
├─Conv1d: 1-281                          [16, 64, 8]               4,166
│    └─OutputShiftSqueeze: 2-3741        --                        --
│    └─One: 2-3742                       [1]                       --
│    └─OutputScale: 2-3743               --                        --
│    └─Empty: 2-3744                     [64, 64, 1]               --
│    └─Empty: 2-3745                     [64, 64, 1]               --
│    └─Empty: 2-3746                     [64]                      --
│    └─Empty: 2-3747                     [64]                      --
│    └─Scaler: 2-3748                    [16, 64, 8]               --
│    └─Empty: 2-3749                     [16, 64, 8]               --
│    └─Empty: 2-3750                     [16, 64, 8]               --
│    └─Clamp: 2-3751                     [16, 64, 8]               --
├─FusedLinearReLU: 1-282                 [16, 32]                  16,422
│    └─OutputShiftSqueeze: 2-3752        --                        --
│    └─One: 2-3753                       [1]                       --
│    └─OutputScale: 2-3754               --                        --
│    └─Empty: 2-3755                     [32, 512]                 --
│    └─Empty: 2-3756                     [32, 512]                 --
│    └─Empty: 2-3757                     [32]                      --
│    └─Empty: 2-3758                     [32]                      --
│    └─Scaler: 2-3759                    [16, 32]                  --
│    └─ReLU: 2-3760                      [16, 32]                  --
│    └─Empty: 2-3761                     [16, 32]                  --
│    └─Clamp: 2-3762                     [16, 32]                  --
├─Linear: 1-283                          [16, 5]                   166
│    └─OutputShiftSqueeze: 2-3763        --                        --
│    └─One: 2-3764                       [1]                       --
│    └─OutputScale: 2-3765               --                        --
│    └─Empty: 2-3766                     [5, 32]                   --
│    └─Empty: 2-3767                     [5, 32]                   --
│    └─Empty: 2-3768                     [16, 5]                   --
│    └─Empty: 2-3769                     [16, 5]                   --
│    └─Clamp: 2-3770                     [16, 5]                   --
==========================================================================================
Total params: 529,384
Trainable params: 529,216
Non-trainable params: 168
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 201.33
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 201.33
==========================================================================================
I - Epoch: 0
I - Training: 
	I - Batch: 50 | Loss: 1.529 | Acc: 47.500% | Wgt Acc: 32.961%
	I - Batch: 100 | Loss: 1.534 | Acc: 43.188% | Wgt Acc: 31.441%
	I - Batch: 150 | Loss: 1.510 | Acc: 47.000% | Wgt Acc: 33.356%
	I - Batch: 200 | Loss: 1.504 | Acc: 47.438% | Wgt Acc: 33.986%
	I - Batch: 250 | Loss: 1.490 | Acc: 49.150% | Wgt Acc: 34.812%
	I - Batch: 300 | Loss: 1.474 | Acc: 50.042% | Wgt Acc: 35.542%
I - num batch: 313
I - Train -- Loss: 1.469 | Acc: 50.300% | Wgt Acc: 35.882% | LR: 1.000000e-03 | Dur: 245.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 319.   46.   89.  282.  431.]
 [   3.    1.    0.    0.    1.]
 [   0.    0.    0.    0.    0.]
 [ 121.   33.   50.  124.  263.]
 [ 251.  254.  348.  313. 2071.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.498 | Acc: 40.500% | Wgt Acc: 29.366%
I - num batch: 70
I - Val -- Loss: 1.465 | Acc: 44.434% | Wgt Acc: 31.615% | Dur: 44.31s
I - Confusion Matrix: [row->prediction - col->label]
[[154.  30.  22. 139.  90.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   1.   1.]
 [ 45. 104. 124.  64. 340.]]

I - Local maximum validation set accuracy:  44.43

I - Epoch: 1
I - Training: 
	I - Batch: 50 | Loss: 1.426 | Acc: 51.000% | Wgt Acc: 36.671%
	I - Batch: 100 | Loss: 1.397 | Acc: 53.312% | Wgt Acc: 38.087%
	I - Batch: 150 | Loss: 1.407 | Acc: 52.750% | Wgt Acc: 37.671%
	I - Batch: 200 | Loss: 1.411 | Acc: 53.031% | Wgt Acc: 38.194%
	I - Batch: 250 | Loss: 1.412 | Acc: 53.600% | Wgt Acc: 38.269%
	I - Batch: 300 | Loss: 1.408 | Acc: 53.771% | Wgt Acc: 38.659%
I - num batch: 313
I - Train -- Loss: 1.407 | Acc: 53.740% | Wgt Acc: 38.622% | LR: 1.000000e-03 | Dur: 244.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 333.   32.   46.  323.  339.]
 [   1.    2.    3.    0.    1.]
 [   1.    0.    4.    1.    4.]
 [ 161.   19.   37.  150.  224.]
 [ 198.  281.  397.  245. 2198.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.507 | Acc: 40.250% | Wgt Acc: 25.894%
I - num batch: 70
I - Val -- Loss: 1.474 | Acc: 45.063% | Wgt Acc: 29.160% | Dur: 43.69s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   8.  13. 116.  37.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  4.   3.   2.   8.   7.]
 [ 88. 123. 131.  80. 387.]]

I - Local maximum validation set accuracy:  45.06

I - Epoch: 2
I - Training: 
	I - Batch: 50 | Loss: 1.366 | Acc: 56.125% | Wgt Acc: 40.731%
	I - Batch: 100 | Loss: 1.385 | Acc: 54.062% | Wgt Acc: 38.423%
	I - Batch: 150 | Loss: 1.392 | Acc: 53.833% | Wgt Acc: 38.209%
	I - Batch: 200 | Loss: 1.399 | Acc: 53.844% | Wgt Acc: 38.919%
	I - Batch: 250 | Loss: 1.388 | Acc: 54.450% | Wgt Acc: 39.365%
	I - Batch: 300 | Loss: 1.386 | Acc: 54.312% | Wgt Acc: 39.499%
I - num batch: 313
I - Train -- Loss: 1.387 | Acc: 54.440% | Wgt Acc: 39.802% | LR: 1.000000e-03 | Dur: 241.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 351.   34.   33.  306.  352.]
 [   4.    0.    2.    2.    4.]
 [   9.    2.    7.    6.   11.]
 [ 153.   23.   43.  175.  210.]
 [ 177.  275.  402.  230. 2189.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.464 | Acc: 42.750% | Wgt Acc: 31.098%
I - num batch: 70
I - Val -- Loss: 1.425 | Acc: 46.768% | Wgt Acc: 33.817% | Dur: 41.35s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   7.  12. 101.  44.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 25.  21.   8.  35.  37.]
 [ 38. 106. 126.  68. 350.]]

I - Local maximum validation set accuracy:  46.77

I - Epoch: 3
I - Training: 
	I - Batch: 50 | Loss: 1.396 | Acc: 55.375% | Wgt Acc: 38.454%
	I - Batch: 100 | Loss: 1.383 | Acc: 56.062% | Wgt Acc: 39.651%
	I - Batch: 150 | Loss: 1.396 | Acc: 55.083% | Wgt Acc: 39.696%
	I - Batch: 200 | Loss: 1.399 | Acc: 55.344% | Wgt Acc: 39.923%
	I - Batch: 250 | Loss: 1.400 | Acc: 54.925% | Wgt Acc: 39.791%
	I - Batch: 300 | Loss: 1.402 | Acc: 54.625% | Wgt Acc: 39.512%
I - num batch: 313
I - Train -- Loss: 1.406 | Acc: 54.360% | Wgt Acc: 39.296% | LR: 1.000000e-03 | Dur: 249.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 431.   41.   55.  370.  436.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  74.   25.   20.   78.  121.]
 [ 189.  268.  412.  271. 2209.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.513 | Acc: 39.250% | Wgt Acc: 27.990%
I - num batch: 70
I - Val -- Loss: 1.486 | Acc: 43.537% | Wgt Acc: 30.848% | Dur: 43.67s
I - Confusion Matrix: [row->prediction - col->label]
[[140.  20.  20. 115.  87.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  7.   3.   4.  10.   9.]
 [ 52. 111. 122.  79. 335.]]

I - Epoch: 4
I - Training: 
	I - Batch: 50 | Loss: 1.384 | Acc: 53.500% | Wgt Acc: 40.105%
	I - Batch: 100 | Loss: 1.371 | Acc: 55.125% | Wgt Acc: 41.296%
	I - Batch: 150 | Loss: 1.372 | Acc: 54.667% | Wgt Acc: 40.689%
	I - Batch: 200 | Loss: 1.393 | Acc: 53.250% | Wgt Acc: 39.530%
	I - Batch: 250 | Loss: 1.400 | Acc: 53.275% | Wgt Acc: 39.108%
	I - Batch: 300 | Loss: 1.393 | Acc: 53.958% | Wgt Acc: 39.838%
I - num batch: 313
I - Train -- Loss: 1.401 | Acc: 53.760% | Wgt Acc: 39.360% | LR: 1.000000e-03 | Dur: 228.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 396.   24.   40.  326.  376.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    1.]
 [ 111.   32.   50.  135.  232.]
 [ 187.  278.  397.  258. 2157.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.539 | Acc: 38.500% | Wgt Acc: 24.658%
I - num batch: 70
I - Val -- Loss: 1.509 | Acc: 43.178% | Wgt Acc: 27.240% | Dur: 40.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 56.   2.   6.  41.  22.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 55.   8.   5.  44.  28.]
 [ 88. 124. 135. 119. 381.]]

I - Epoch: 5
I - Training: 
	I - Batch: 50 | Loss: 1.380 | Acc: 55.750% | Wgt Acc: 39.412%
	I - Batch: 100 | Loss: 1.387 | Acc: 54.438% | Wgt Acc: 40.625%
	I - Batch: 150 | Loss: 1.408 | Acc: 51.792% | Wgt Acc: 39.504%
	I - Batch: 200 | Loss: 1.412 | Acc: 52.812% | Wgt Acc: 39.271%
	I - Batch: 250 | Loss: 1.412 | Acc: 52.800% | Wgt Acc: 39.126%
	I - Batch: 300 | Loss: 1.415 | Acc: 51.812% | Wgt Acc: 38.560%
I - num batch: 313
I - Train -- Loss: 1.415 | Acc: 51.740% | Wgt Acc: 38.528% | LR: 1.000000e-03 | Dur: 233.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 256.   25.   27.  196.  310.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 269.   51.   68.  291.  416.]
 [ 169.  258.  392.  232. 2040.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.459 | Acc: 35.875% | Wgt Acc: 26.753%
I - num batch: 70
I - Val -- Loss: 1.432 | Acc: 39.497% | Wgt Acc: 30.181% | Dur: 40.45s
I - Confusion Matrix: [row->prediction - col->label]
[[  2.   2.   1.   6.  13.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [171.  27.  33. 166. 146.]
 [ 26. 105. 112.  32. 272.]]

I - Epoch: 6
I - Training: 
	I - Batch: 50 | Loss: 1.386 | Acc: 51.625% | Wgt Acc: 37.809%
	I - Batch: 100 | Loss: 1.391 | Acc: 53.312% | Wgt Acc: 38.593%
	I - Batch: 150 | Loss: 1.394 | Acc: 54.083% | Wgt Acc: 38.928%
	I - Batch: 200 | Loss: 1.392 | Acc: 54.406% | Wgt Acc: 39.335%
	I - Batch: 250 | Loss: 1.391 | Acc: 54.000% | Wgt Acc: 39.509%
	I - Batch: 300 | Loss: 1.395 | Acc: 53.646% | Wgt Acc: 39.272%
I - num batch: 313
I - Train -- Loss: 1.393 | Acc: 53.520% | Wgt Acc: 39.082% | LR: 1.000000e-03 | Dur: 241.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 319.   23.   42.  287.  334.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 208.   26.   45.  204.  279.]
 [ 167.  285.  400.  228. 2153.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.441 | Acc: 41.875% | Wgt Acc: 30.344%
I - num batch: 70
I - Val -- Loss: 1.409 | Acc: 45.153% | Wgt Acc: 32.780% | Dur: 44.66s
I - Confusion Matrix: [row->prediction - col->label]
[[135.  17.  21. 123.  84.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 12.   8.   6.  32.  11.]
 [ 52. 109. 119.  49. 336.]]

I - Epoch: 7
I - Training: 
	I - Batch: 50 | Loss: 1.390 | Acc: 55.500% | Wgt Acc: 40.812%
	I - Batch: 100 | Loss: 1.390 | Acc: 55.188% | Wgt Acc: 40.543%
	I - Batch: 150 | Loss: 1.394 | Acc: 55.042% | Wgt Acc: 39.920%
	I - Batch: 200 | Loss: 1.383 | Acc: 55.844% | Wgt Acc: 40.596%
	I - Batch: 250 | Loss: 1.384 | Acc: 55.475% | Wgt Acc: 40.102%
	I - Batch: 300 | Loss: 1.386 | Acc: 55.354% | Wgt Acc: 40.130%
I - num batch: 313
I - Train -- Loss: 1.387 | Acc: 55.380% | Wgt Acc: 40.149% | LR: 1.000000e-03 | Dur: 248.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 446.   28.   40.  390.  395.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  65.   21.   27.   79.  127.]
 [ 183.  285.  420.  250. 2244.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.501 | Acc: 38.875% | Wgt Acc: 25.189%
I - num batch: 70
I - Val -- Loss: 1.471 | Acc: 43.088% | Wgt Acc: 28.367% | Dur: 44.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 25.   4.   2.  13.  16.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [115.  13.  15.  92.  52.]
 [ 59. 117. 129.  99. 363.]]

I - Epoch: 8
I - Training: 
	I - Batch: 50 | Loss: 1.376 | Acc: 55.125% | Wgt Acc: 39.527%
	I - Batch: 100 | Loss: 1.371 | Acc: 56.125% | Wgt Acc: 41.415%
	I - Batch: 150 | Loss: 1.370 | Acc: 55.583% | Wgt Acc: 40.649%
	I - Batch: 200 | Loss: 1.374 | Acc: 56.156% | Wgt Acc: 40.825%
	I - Batch: 250 | Loss: 1.377 | Acc: 55.875% | Wgt Acc: 40.035%
	I - Batch: 300 | Loss: 1.379 | Acc: 55.896% | Wgt Acc: 40.283%
I - num batch: 313
I - Train -- Loss: 1.377 | Acc: 55.900% | Wgt Acc: 40.347% | LR: 1.000000e-03 | Dur: 248.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 410.   18.   29.  324.  321.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  85.   19.   26.  110.  170.]
 [ 199.  297.  432.  285. 2275.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.429 | Acc: 42.125% | Wgt Acc: 30.819%
I - num batch: 70
I - Val -- Loss: 1.403 | Acc: 45.512% | Wgt Acc: 33.018% | Dur: 45.74s
I - Confusion Matrix: [row->prediction - col->label]
[[147.  14.  15. 132.  59.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 16.  10.  10.  21.  33.]
 [ 36. 110. 121.  51. 339.]]

I - Epoch: 9
I - Training: 
	I - Batch: 50 | Loss: 1.360 | Acc: 56.750% | Wgt Acc: 41.338%
	I - Batch: 100 | Loss: 1.373 | Acc: 55.688% | Wgt Acc: 40.342%
	I - Batch: 150 | Loss: 1.369 | Acc: 56.583% | Wgt Acc: 40.978%
	I - Batch: 200 | Loss: 1.365 | Acc: 56.188% | Wgt Acc: 40.924%
	I - Batch: 250 | Loss: 1.368 | Acc: 56.275% | Wgt Acc: 41.170%
	I - Batch: 300 | Loss: 1.363 | Acc: 56.021% | Wgt Acc: 40.815%
I - num batch: 313
I - Train -- Loss: 1.366 | Acc: 55.800% | Wgt Acc: 40.562% | LR: 1.000000e-03 | Dur: 246.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 432.   25.   36.  348.  354.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [  67.   17.   34.  103.  157.]
 [ 195.  292.  417.  268. 2255.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.456 | Acc: 42.375% | Wgt Acc: 27.117%
I - num batch: 70
I - Val -- Loss: 1.435 | Acc: 47.038% | Wgt Acc: 30.229% | Dur: 44.73s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   2.   9.  70.  22.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 11.   1.   1.  11.   2.]
 [ 82. 131. 136. 123. 407.]]

I - Local maximum validation set accuracy:  47.04

I - Epoch: 10
I - Training: 
	I - Batch: 50 | Loss: 1.353 | Acc: 57.625% | Wgt Acc: 41.184%
	I - Batch: 100 | Loss: 1.344 | Acc: 57.875% | Wgt Acc: 41.463%
	I - Batch: 150 | Loss: 1.359 | Acc: 57.500% | Wgt Acc: 40.864%
	I - Batch: 200 | Loss: 1.355 | Acc: 57.625% | Wgt Acc: 41.274%
	I - Batch: 250 | Loss: 1.353 | Acc: 57.375% | Wgt Acc: 41.507%
	I - Batch: 300 | Loss: 1.352 | Acc: 57.083% | Wgt Acc: 41.292%
I - num batch: 313
I - Train -- Loss: 1.349 | Acc: 57.220% | Wgt Acc: 41.349% | LR: 5.000000e-04 | Dur: 242.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 391.   19.   16.  283.  274.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 105.   18.   29.  144.  166.]
 [ 198.  297.  442.  292. 2326.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.410 | Acc: 43.125% | Wgt Acc: 27.724%
I - num batch: 70
I - Val -- Loss: 1.394 | Acc: 48.115% | Wgt Acc: 31.219% | Dur: 41.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 80.   0.   2.  44.   9.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 38.   4.   4.  44.  10.]
 [ 81. 130. 140. 116. 412.]]

I - Local maximum validation set accuracy:  48.11

I - Epoch: 11
I - Training: 
	I - Batch: 50 | Loss: 1.386 | Acc: 54.875% | Wgt Acc: 37.955%
	I - Batch: 100 | Loss: 1.371 | Acc: 55.938% | Wgt Acc: 39.979%
	I - Batch: 150 | Loss: 1.351 | Acc: 57.708% | Wgt Acc: 41.111%
	I - Batch: 200 | Loss: 1.341 | Acc: 58.500% | Wgt Acc: 41.925%
	I - Batch: 250 | Loss: 1.344 | Acc: 58.050% | Wgt Acc: 41.525%
	I - Batch: 300 | Loss: 1.343 | Acc: 57.708% | Wgt Acc: 41.702%
I - num batch: 313
I - Train -- Loss: 1.339 | Acc: 57.740% | Wgt Acc: 41.836% | LR: 5.000000e-04 | Dur: 238.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 372.   14.   20.  273.  232.]
 [   0.    0.    0.    0.    0.]
 [   0.    1.    0.    0.    0.]
 [ 120.   33.   36.  174.  193.]
 [ 202.  286.  431.  272. 2341.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.392 | Acc: 44.500% | Wgt Acc: 31.699%
I - num batch: 70
I - Val -- Loss: 1.374 | Acc: 48.474% | Wgt Acc: 34.277% | Dur: 41.61s
I - Confusion Matrix: [row->prediction - col->label]
[[132.   5.  11.  99.  36.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 16.  13.   7.  34.  21.]
 [ 51. 116. 128.  71. 374.]]

I - Local maximum validation set accuracy:  48.47

I - Epoch: 12
I - Training: 
	I - Batch: 50 | Loss: 1.338 | Acc: 56.000% | Wgt Acc: 41.566%
	I - Batch: 100 | Loss: 1.318 | Acc: 58.250% | Wgt Acc: 42.839%
	I - Batch: 150 | Loss: 1.331 | Acc: 57.917% | Wgt Acc: 42.416%
	I - Batch: 200 | Loss: 1.337 | Acc: 57.406% | Wgt Acc: 41.952%
	I - Batch: 250 | Loss: 1.337 | Acc: 56.975% | Wgt Acc: 41.956%
	I - Batch: 300 | Loss: 1.334 | Acc: 56.667% | Wgt Acc: 42.084%
I - num batch: 313
I - Train -- Loss: 1.331 | Acc: 56.760% | Wgt Acc: 42.276% | LR: 5.000000e-04 | Dur: 239.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 399.   13.   21.  298.  233.]
 [   0.    2.    2.    2.    7.]
 [   1.    8.    8.    3.   17.]
 [ 113.   38.   46.  189.  269.]
 [ 181.  273.  410.  227. 2240.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.421 | Acc: 43.375% | Wgt Acc: 29.149%
I - num batch: 70
I - Val -- Loss: 1.405 | Acc: 48.115% | Wgt Acc: 32.695% | Dur: 42.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 31.   0.   0.  20.   2.]
 [  0.   0.   0.   0.   0.]
 [  0.   2.   2.   0.   0.]
 [103.  14.  12. 112.  38.]
 [ 65. 118. 132.  72. 391.]]

I - Epoch: 13
I - Training: 
	I - Batch: 50 | Loss: 1.298 | Acc: 57.250% | Wgt Acc: 42.153%
	I - Batch: 100 | Loss: 1.280 | Acc: 58.500% | Wgt Acc: 43.143%
	I - Batch: 150 | Loss: 1.301 | Acc: 57.250% | Wgt Acc: 42.889%
	I - Batch: 200 | Loss: 1.307 | Acc: 57.281% | Wgt Acc: 42.600%
	I - Batch: 250 | Loss: 1.310 | Acc: 57.325% | Wgt Acc: 42.555%
	I - Batch: 300 | Loss: 1.314 | Acc: 57.854% | Wgt Acc: 42.707%
I - num batch: 313
I - Train -- Loss: 1.312 | Acc: 58.040% | Wgt Acc: 42.812% | LR: 5.000000e-04 | Dur: 240.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 390.   13.   12.  274.  198.]
 [   0.    0.    0.    0.    0.]
 [   0.    1.    0.    0.    2.]
 [ 111.   35.   47.  201.  255.]
 [ 193.  285.  428.  244. 2311.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.431 | Acc: 44.125% | Wgt Acc: 28.898%
I - num batch: 70
I - Val -- Loss: 1.400 | Acc: 48.923% | Wgt Acc: 32.287% | Dur: 40.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   3.  61.  12.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 17.   7.   4.  35.   8.]
 [ 83. 126. 139. 108. 411.]]

I - Local maximum validation set accuracy:  48.92

I - Epoch: 14
I - Training: 
	I - Batch: 50 | Loss: 1.319 | Acc: 58.250% | Wgt Acc: 41.093%
	I - Batch: 100 | Loss: 1.319 | Acc: 58.188% | Wgt Acc: 41.505%
	I - Batch: 150 | Loss: 1.313 | Acc: 57.917% | Wgt Acc: 41.859%
	I - Batch: 200 | Loss: 1.307 | Acc: 58.188% | Wgt Acc: 42.232%
	I - Batch: 250 | Loss: 1.309 | Acc: 57.725% | Wgt Acc: 41.987%
	I - Batch: 300 | Loss: 1.309 | Acc: 58.312% | Wgt Acc: 42.631%
I - num batch: 313
I - Train -- Loss: 1.312 | Acc: 58.460% | Wgt Acc: 42.685% | LR: 5.000000e-04 | Dur: 195.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 401.   10.   14.  309.  183.]
 [   0.    0.    0.    0.    0.]
 [   0.    2.    0.    0.    2.]
 [  92.   30.   43.  170.  229.]
 [ 201.  292.  430.  240. 2352.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.449 | Acc: 43.625% | Wgt Acc: 28.493%
I - num batch: 70
I - Val -- Loss: 1.410 | Acc: 48.205% | Wgt Acc: 31.742% | Dur: 34.50s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   4.   4.  76.  13.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  8.  11.  12.  23.  12.]
 [ 83. 119. 130. 105. 406.]]

I - Epoch: 15
I - Training: 
	I - Batch: 50 | Loss: 1.358 | Acc: 55.500% | Wgt Acc: 38.274%
	I - Batch: 100 | Loss: 1.347 | Acc: 55.562% | Wgt Acc: 39.159%
	I - Batch: 150 | Loss: 1.352 | Acc: 55.625% | Wgt Acc: 39.938%
	I - Batch: 200 | Loss: 1.335 | Acc: 57.062% | Wgt Acc: 41.439%
	I - Batch: 250 | Loss: 1.324 | Acc: 57.475% | Wgt Acc: 42.073%
	I - Batch: 300 | Loss: 1.319 | Acc: 57.646% | Wgt Acc: 42.139%
I - num batch: 313
I - Train -- Loss: 1.318 | Acc: 57.700% | Wgt Acc: 42.165% | LR: 5.000000e-04 | Dur: 195.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 402.   10.   18.  313.  211.]
 [   0.    0.    0.    0.    0.]
 [   2.    6.   11.    3.   28.]
 [  82.   38.   57.  150.  205.]
 [ 208.  280.  401.  253. 2322.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.431 | Acc: 42.375% | Wgt Acc: 30.770%
I - num batch: 70
I - Val -- Loss: 1.391 | Acc: 45.512% | Wgt Acc: 32.827% | Dur: 33.33s
I - Confusion Matrix: [row->prediction - col->label]
[[151.  16.  17. 139.  63.]
 [  0.   0.   0.   0.   0.]
 [  0.   3.   1.   1.   2.]
 [  7.  13.  17.  13.  24.]
 [ 41. 102. 111.  51. 342.]]

I - Epoch: 16
I - Training: 
	I - Batch: 50 | Loss: 1.278 | Acc: 59.000% | Wgt Acc: 44.026%
	I - Batch: 100 | Loss: 1.293 | Acc: 58.000% | Wgt Acc: 44.321%
	I - Batch: 150 | Loss: 1.305 | Acc: 57.125% | Wgt Acc: 43.269%
	I - Batch: 200 | Loss: 1.304 | Acc: 58.000% | Wgt Acc: 43.794%
	I - Batch: 250 | Loss: 1.307 | Acc: 57.375% | Wgt Acc: 43.173%
	I - Batch: 300 | Loss: 1.316 | Acc: 56.646% | Wgt Acc: 42.702%
I - num batch: 313
I - Train -- Loss: 1.317 | Acc: 56.460% | Wgt Acc: 42.452% | LR: 5.000000e-04 | Dur: 192.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 382.   10.   19.  258.  229.]
 [   0.    0.    0.    0.    0.]
 [   2.    9.    7.    4.   17.]
 [ 152.   54.   69.  229.  315.]
 [ 158.  261.  392.  228. 2205.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.406 | Acc: 44.375% | Wgt Acc: 31.280%
I - num batch: 70
I - Val -- Loss: 1.374 | Acc: 48.743% | Wgt Acc: 34.610% | Dur: 33.50s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   2.   4.  61.  20.]
 [  0.   0.   0.   0.   0.]
 [  1.   1.   0.   0.   6.]
 [ 31.  12.   8.  68.  31.]
 [ 66. 119. 134.  75. 374.]]

I - Epoch: 17
I - Training: 
	I - Batch: 50 | Loss: 1.295 | Acc: 58.875% | Wgt Acc: 43.928%
	I - Batch: 100 | Loss: 1.313 | Acc: 58.000% | Wgt Acc: 43.569%
	I - Batch: 150 | Loss: 1.313 | Acc: 56.250% | Wgt Acc: 42.980%
	I - Batch: 200 | Loss: 1.308 | Acc: 57.344% | Wgt Acc: 43.669%
	I - Batch: 250 | Loss: 1.312 | Acc: 57.225% | Wgt Acc: 43.173%
	I - Batch: 300 | Loss: 1.315 | Acc: 57.375% | Wgt Acc: 43.037%
I - num batch: 313
I - Train -- Loss: 1.319 | Acc: 57.160% | Wgt Acc: 42.765% | LR: 5.000000e-04 | Dur: 189.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 400.   13.   21.  288.  285.]
 [   0.    0.    0.    0.    0.]
 [   5.   13.   15.   13.   33.]
 [ 135.   42.   45.  197.  202.]
 [ 154.  266.  406.  221. 2246.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.440 | Acc: 44.000% | Wgt Acc: 29.568%
I - num batch: 70
I - Val -- Loss: 1.413 | Acc: 48.474% | Wgt Acc: 32.626% | Dur: 32.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 53.   0.   1.  27.   9.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 71.   9.   9.  89.  24.]
 [ 75. 125. 136.  88. 398.]]

I - Epoch: 18
I - Training: 
	I - Batch: 50 | Loss: 1.259 | Acc: 60.000% | Wgt Acc: 45.951%
	I - Batch: 100 | Loss: 1.305 | Acc: 58.312% | Wgt Acc: 43.475%
	I - Batch: 150 | Loss: 1.324 | Acc: 56.583% | Wgt Acc: 41.971%
	I - Batch: 200 | Loss: 1.324 | Acc: 56.281% | Wgt Acc: 41.512%
	I - Batch: 250 | Loss: 1.318 | Acc: 56.925% | Wgt Acc: 42.083%
	I - Batch: 300 | Loss: 1.315 | Acc: 57.271% | Wgt Acc: 42.373%
I - num batch: 313
I - Train -- Loss: 1.312 | Acc: 57.360% | Wgt Acc: 42.472% | LR: 5.000000e-04 | Dur: 190.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 419.    7.   16.  290.  258.]
 [   0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.]
 [ 117.   28.   35.  174.  233.]
 [ 158.  299.  436.  255. 2275.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.371 | Acc: 44.375% | Wgt Acc: 32.823%
I - num batch: 70
I - Val -- Loss: 1.333 | Acc: 48.923% | Wgt Acc: 36.346% | Dur: 33.55s
I - Confusion Matrix: [row->prediction - col->label]
[[137.   5.   9.  97.  35.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [ 20.  20.  18.  56.  44.]
 [ 42. 109. 119.  51. 352.]]

I - Epoch: 19
I - Training: 
	I - Batch: 50 | Loss: 1.282 | Acc: 59.500% | Wgt Acc: 45.236%
	I - Batch: 100 | Loss: 1.293 | Acc: 59.250% | Wgt Acc: 44.272%
	I - Batch: 150 | Loss: 1.287 | Acc: 59.333% | Wgt Acc: 43.956%
	I - Batch: 200 | Loss: 1.299 | Acc: 59.125% | Wgt Acc: 43.445%
	I - Batch: 250 | Loss: 1.311 | Acc: 58.550% | Wgt Acc: 43.035%
	I - Batch: 300 | Loss: 1.307 | Acc: 58.167% | Wgt Acc: 43.192%
I - num batch: 313
I - Train -- Loss: 1.306 | Acc: 58.000% | Wgt Acc: 43.164% | LR: 5.000000e-04 | Dur: 193.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 404.   11.   17.  294.  222.]
 [   0.    0.    0.    0.    0.]
 [   7.   36.   25.   13.   56.]
 [ 107.   30.   49.  177.  194.]
 [ 176.  257.  396.  235. 2294.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.376 | Acc: 40.625% | Wgt Acc: 33.159%
I - num batch: 70
I - Val -- Loss: 1.346 | Acc: 42.190% | Wgt Acc: 34.573% | Dur: 33.61s
I - Confusion Matrix: [row->prediction - col->label]
[[158.  14.  14. 138.  77.]
 [  0.   0.   0.   0.   0.]
 [  2.  31.  19.   3.  42.]
 [ 15.  21.  19.  32.  51.]
 [ 24.  68.  94.  31. 261.]]

I - Epoch: 20
I - Training: 
	I - Batch: 50 | Loss: 1.245 | Acc: 60.000% | Wgt Acc: 45.790%
	I - Batch: 100 | Loss: 1.285 | Acc: 58.125% | Wgt Acc: 44.202%
	I - Batch: 150 | Loss: 1.295 | Acc: 57.542% | Wgt Acc: 43.756%
	I - Batch: 200 | Loss: 1.292 | Acc: 57.594% | Wgt Acc: 43.541%
	I - Batch: 250 | Loss: 1.291 | Acc: 57.575% | Wgt Acc: 43.516%
	I - Batch: 300 | Loss: 1.289 | Acc: 57.812% | Wgt Acc: 43.702%
I - num batch: 313
I - Train -- Loss: 1.290 | Acc: 57.820% | Wgt Acc: 43.663% | LR: 2.500000e-04 | Dur: 193.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.   12.   20.  357.  261.]
 [   0.    0.    0.    0.    0.]
 [   6.   38.   39.   17.   87.]
 [  60.   30.   43.  134.  163.]
 [ 165.  254.  385.  211. 2255.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.391 | Acc: 42.375% | Wgt Acc: 32.327%
I - num batch: 70
I - Val -- Loss: 1.350 | Acc: 45.601% | Wgt Acc: 34.616% | Dur: 33.59s
I - Confusion Matrix: [row->prediction - col->label]
[[160.  12.  15. 138.  77.]
 [  0.   0.   0.   0.   0.]
 [  0.  11.   7.   1.   6.]
 [  9.  16.  16.  22.  29.]
 [ 30.  95. 108.  43. 319.]]

I - Epoch: 21
I - Training: 
	I - Batch: 50 | Loss: 1.310 | Acc: 57.250% | Wgt Acc: 41.929%
	I - Batch: 100 | Loss: 1.295 | Acc: 57.938% | Wgt Acc: 44.768%
	I - Batch: 150 | Loss: 1.291 | Acc: 57.750% | Wgt Acc: 44.595%
	I - Batch: 200 | Loss: 1.274 | Acc: 58.250% | Wgt Acc: 45.275%
	I - Batch: 250 | Loss: 1.283 | Acc: 57.575% | Wgt Acc: 44.340%
	I - Batch: 300 | Loss: 1.280 | Acc: 57.729% | Wgt Acc: 44.687%
I - num batch: 313
I - Train -- Loss: 1.282 | Acc: 57.580% | Wgt Acc: 44.572% | LR: 2.500000e-04 | Dur: 193.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 411.    6.   14.  258.  233.]
 [   0.    1.    0.    2.    2.]
 [   7.   59.   54.   27.  105.]
 [ 130.   42.   44.  224.  237.]
 [ 146.  226.  375.  208. 2189.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.390 | Acc: 45.125% | Wgt Acc: 31.894%
I - num batch: 70
I - Val -- Loss: 1.358 | Acc: 49.192% | Wgt Acc: 34.859% | Dur: 33.69s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   2.  74.  22.]
 [  0.   0.   0.   0.   0.]
 [  2.  10.  11.   8.   8.]
 [ 11.  13.  10.  39.  20.]
 [ 69. 109. 123.  83. 381.]]

I - Local maximum validation set accuracy:  49.19

I - Epoch: 22
I - Training: 
	I - Batch: 50 | Loss: 1.284 | Acc: 58.625% | Wgt Acc: 44.320%
	I - Batch: 100 | Loss: 1.271 | Acc: 59.250% | Wgt Acc: 44.270%
	I - Batch: 150 | Loss: 1.274 | Acc: 59.375% | Wgt Acc: 44.648%
	I - Batch: 200 | Loss: 1.290 | Acc: 58.688% | Wgt Acc: 43.758%
	I - Batch: 250 | Loss: 1.279 | Acc: 58.725% | Wgt Acc: 44.360%
	I - Batch: 300 | Loss: 1.278 | Acc: 58.479% | Wgt Acc: 44.744%
I - num batch: 313
I - Train -- Loss: 1.279 | Acc: 58.400% | Wgt Acc: 44.659% | LR: 2.500000e-04 | Dur: 193.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 452.   15.   20.  291.  272.]
 [   0.    0.    1.    0.    0.]
 [   4.   25.   28.    8.   42.]
 [  84.   34.   49.  196.  208.]
 [ 154.  260.  389.  224. 2244.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.389 | Acc: 47.000% | Wgt Acc: 33.766%
I - num batch: 70
I - Val -- Loss: 1.355 | Acc: 51.436% | Wgt Acc: 36.944% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   3.   6.  73.  25.]
 [  0.   0.   0.   0.   0.]
 [  1.   2.   2.   0.   3.]
 [ 24.   8.   7.  58.  14.]
 [ 50. 121. 131.  73. 389.]]

I - Local maximum validation set accuracy:  51.44

I - Epoch: 23
I - Training: 
	I - Batch: 50 | Loss: 1.215 | Acc: 61.375% | Wgt Acc: 47.768%
	I - Batch: 100 | Loss: 1.256 | Acc: 59.688% | Wgt Acc: 45.642%
	I - Batch: 150 | Loss: 1.264 | Acc: 59.083% | Wgt Acc: 45.230%
	I - Batch: 200 | Loss: 1.260 | Acc: 59.156% | Wgt Acc: 45.306%
	I - Batch: 250 | Loss: 1.267 | Acc: 59.225% | Wgt Acc: 45.667%
	I - Batch: 300 | Loss: 1.262 | Acc: 59.000% | Wgt Acc: 45.890%
I - num batch: 313
I - Train -- Loss: 1.267 | Acc: 58.820% | Wgt Acc: 45.638% | LR: 2.500000e-04 | Dur: 193.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 339.    4.   12.  172.  185.]
 [   0.    0.    0.    0.    0.]
 [  10.   47.   47.   23.   91.]
 [ 199.   44.   56.  327.  262.]
 [ 146.  239.  372.  197. 2228.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.374 | Acc: 45.250% | Wgt Acc: 35.247%
I - num batch: 70
I - Val -- Loss: 1.335 | Acc: 48.294% | Wgt Acc: 37.658% | Dur: 33.67s
I - Confusion Matrix: [row->prediction - col->label]
[[143.   4.   7.  97.  42.]
 [  0.   0.   0.   0.   0.]
 [  0.   8.   6.   0.   5.]
 [ 23.  39.  30.  66.  61.]
 [ 33.  83. 103.  41. 323.]]

I - Epoch: 24
I - Training: 
	I - Batch: 50 | Loss: 1.218 | Acc: 60.500% | Wgt Acc: 47.911%
	I - Batch: 100 | Loss: 1.257 | Acc: 58.875% | Wgt Acc: 46.391%
	I - Batch: 150 | Loss: 1.251 | Acc: 59.083% | Wgt Acc: 46.511%
	I - Batch: 200 | Loss: 1.265 | Acc: 57.938% | Wgt Acc: 45.535%
	I - Batch: 250 | Loss: 1.263 | Acc: 58.225% | Wgt Acc: 45.680%
	I - Batch: 300 | Loss: 1.262 | Acc: 58.667% | Wgt Acc: 45.818%
I - num batch: 313
I - Train -- Loss: 1.264 | Acc: 58.720% | Wgt Acc: 45.870% | LR: 2.500000e-04 | Dur: 193.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 401.   12.   16.  201.  204.]
 [   1.    1.    3.    1.    4.]
 [   7.   42.   54.   14.  103.]
 [ 123.   36.   48.  271.  246.]
 [ 162.  243.  366.  232. 2209.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.344 | Acc: 46.500% | Wgt Acc: 35.555%
I - num batch: 70
I - Val -- Loss: 1.314 | Acc: 49.910% | Wgt Acc: 38.431% | Dur: 33.59s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   3.   5.  67.  16.]
 [  0.   1.   0.   2.   0.]
 [  2.  19.  18.   2.  33.]
 [ 34.  19.  20.  76.  38.]
 [ 46.  92. 103.  57. 344.]]

I - Epoch: 25
I - Training: 
	I - Batch: 50 | Loss: 1.230 | Acc: 60.250% | Wgt Acc: 46.618%
	I - Batch: 100 | Loss: 1.240 | Acc: 59.812% | Wgt Acc: 46.698%
	I - Batch: 150 | Loss: 1.239 | Acc: 59.917% | Wgt Acc: 46.747%
	I - Batch: 200 | Loss: 1.244 | Acc: 59.531% | Wgt Acc: 46.056%
	I - Batch: 250 | Loss: 1.239 | Acc: 60.025% | Wgt Acc: 46.534%
	I - Batch: 300 | Loss: 1.241 | Acc: 59.542% | Wgt Acc: 46.483%
I - num batch: 313
I - Train -- Loss: 1.246 | Acc: 59.280% | Wgt Acc: 46.161% | LR: 1.250000e-04 | Dur: 193.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 376.    6.   10.  198.  163.]
 [   0.    1.    0.    2.    3.]
 [   6.   45.   58.   18.  106.]
 [ 152.   36.   58.  290.  255.]
 [ 160.  246.  361.  211. 2239.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.315 | Acc: 47.875% | Wgt Acc: 37.762%
I - num batch: 70
I - Val -- Loss: 1.280 | Acc: 51.526% | Wgt Acc: 40.976% | Dur: 33.59s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   6.  63.  25.]
 [  0.   1.   0.   0.   0.]
 [  0.  25.  22.   2.  23.]
 [ 34.  19.  21.  93.  46.]
 [ 44.  87.  97.  46. 337.]]

I - Local maximum validation set accuracy:  51.53

I - Epoch: 26
I - Training: 
	I - Batch: 50 | Loss: 1.230 | Acc: 59.750% | Wgt Acc: 49.434%
	I - Batch: 100 | Loss: 1.245 | Acc: 57.750% | Wgt Acc: 47.182%
	I - Batch: 150 | Loss: 1.242 | Acc: 57.083% | Wgt Acc: 46.596%
	I - Batch: 200 | Loss: 1.246 | Acc: 57.656% | Wgt Acc: 46.886%
	I - Batch: 250 | Loss: 1.239 | Acc: 58.350% | Wgt Acc: 47.390%
	I - Batch: 300 | Loss: 1.232 | Acc: 58.729% | Wgt Acc: 47.809%
I - num batch: 313
I - Train -- Loss: 1.231 | Acc: 58.860% | Wgt Acc: 47.947% | LR: 1.250000e-04 | Dur: 193.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 391.    5.   10.  161.  182.]
 [   0.    1.    2.    0.    1.]
 [  16.   88.  106.   46.  202.]
 [ 151.   45.   56.  328.  264.]
 [ 136.  195.  313.  184. 2117.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.337 | Acc: 47.625% | Wgt Acc: 35.995%
I - num batch: 70
I - Val -- Loss: 1.295 | Acc: 51.795% | Wgt Acc: 39.203% | Dur: 33.57s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   2.   6.  83.  29.]
 [  0.   0.   0.   1.   0.]
 [  3.  21.  21.   7.  12.]
 [ 16.  11.  11.  53.  23.]
 [ 44. 100. 108.  60. 367.]]

I - Local maximum validation set accuracy:  51.80

I - Epoch: 27
I - Training: 
	I - Batch: 50 | Loss: 1.213 | Acc: 57.125% | Wgt Acc: 47.750%
	I - Batch: 100 | Loss: 1.218 | Acc: 58.875% | Wgt Acc: 48.983%
	I - Batch: 150 | Loss: 1.202 | Acc: 59.583% | Wgt Acc: 49.670%
	I - Batch: 200 | Loss: 1.208 | Acc: 59.156% | Wgt Acc: 49.241%
	I - Batch: 250 | Loss: 1.212 | Acc: 58.850% | Wgt Acc: 48.719%
	I - Batch: 300 | Loss: 1.209 | Acc: 59.333% | Wgt Acc: 48.879%
I - num batch: 313
I - Train -- Loss: 1.212 | Acc: 59.380% | Wgt Acc: 48.806% | LR: 1.250000e-04 | Dur: 193.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 413.    4.   10.  207.  203.]
 [   0.    1.    0.    0.    0.]
 [   9.  114.  135.   36.  216.]
 [ 136.   38.   58.  302.  229.]
 [ 136.  177.  284.  174. 2118.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.311 | Acc: 48.250% | Wgt Acc: 39.138%
I - num batch: 70
I - Val -- Loss: 1.279 | Acc: 51.257% | Wgt Acc: 41.071% | Dur: 33.78s
I - Confusion Matrix: [row->prediction - col->label]
[[141.   3.   7.  81.  35.]
 [  0.   1.   1.   1.   0.]
 [  3.  29.  23.   3.  12.]
 [ 23.  21.  24.  75.  53.]
 [ 32.  80.  91.  44. 331.]]

I - Epoch: 28
I - Training: 
	I - Batch: 50 | Loss: 1.253 | Acc: 58.250% | Wgt Acc: 47.050%
	I - Batch: 100 | Loss: 1.214 | Acc: 57.438% | Wgt Acc: 47.769%
	I - Batch: 150 | Loss: 1.197 | Acc: 57.333% | Wgt Acc: 48.587%
	I - Batch: 200 | Loss: 1.195 | Acc: 57.844% | Wgt Acc: 49.016%
	I - Batch: 250 | Loss: 1.208 | Acc: 57.550% | Wgt Acc: 48.148%
	I - Batch: 300 | Loss: 1.210 | Acc: 57.854% | Wgt Acc: 48.448%
I - num batch: 313
I - Train -- Loss: 1.212 | Acc: 57.880% | Wgt Acc: 48.339% | LR: 1.250000e-04 | Dur: 194.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 403.    6.   11.  191.  193.]
 [   1.    2.    5.    2.    0.]
 [   9.  135.  156.   28.  278.]
 [ 143.   33.   61.  305.  267.]
 [ 138.  158.  254.  193. 2028.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.329 | Acc: 48.000% | Wgt Acc: 38.167%
I - num batch: 70
I - Val -- Loss: 1.280 | Acc: 51.795% | Wgt Acc: 41.023% | Dur: 33.79s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   4.  11.  83.  37.]
 [  0.   1.   0.   0.   0.]
 [  1.  32.  30.   2.  18.]
 [ 31.  21.  19.  73.  33.]
 [ 37.  76.  86.  46. 343.]]

I - Epoch: 29
I - Training: 
	I - Batch: 50 | Loss: 1.164 | Acc: 60.750% | Wgt Acc: 48.996%
	I - Batch: 100 | Loss: 1.196 | Acc: 60.500% | Wgt Acc: 50.106%
	I - Batch: 150 | Loss: 1.190 | Acc: 59.792% | Wgt Acc: 49.450%
	I - Batch: 200 | Loss: 1.196 | Acc: 59.969% | Wgt Acc: 49.333%
	I - Batch: 250 | Loss: 1.203 | Acc: 59.625% | Wgt Acc: 49.257%
	I - Batch: 300 | Loss: 1.208 | Acc: 59.000% | Wgt Acc: 48.528%
I - num batch: 313
I - Train -- Loss: 1.206 | Acc: 58.920% | Wgt Acc: 48.614% | LR: 1.250000e-04 | Dur: 194.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 388.    3.    5.  178.  156.]
 [   1.    6.    8.    9.   12.]
 [  15.  124.  146.   38.  245.]
 [ 149.   48.   55.  310.  257.]
 [ 141.  153.  273.  184. 2096.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.274 | Acc: 47.375% | Wgt Acc: 39.858%
I - num batch: 70
I - Val -- Loss: 1.241 | Acc: 50.539% | Wgt Acc: 42.531% | Dur: 34.17s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   3.   8.  71.  38.]
 [  1.   8.  10.   0.   9.]
 [  0.  46.  38.   2.  35.]
 [ 31.  24.  21.  83.  46.]
 [ 36.  53.  69.  48. 303.]]

I - Epoch: 30
I - Training: 
	I - Batch: 50 | Loss: 1.145 | Acc: 60.625% | Wgt Acc: 53.974%
	I - Batch: 100 | Loss: 1.176 | Acc: 60.312% | Wgt Acc: 51.941%
	I - Batch: 150 | Loss: 1.180 | Acc: 61.167% | Wgt Acc: 51.537%
	I - Batch: 200 | Loss: 1.188 | Acc: 60.438% | Wgt Acc: 50.865%
	I - Batch: 250 | Loss: 1.193 | Acc: 60.025% | Wgt Acc: 50.063%
	I - Batch: 300 | Loss: 1.185 | Acc: 60.021% | Wgt Acc: 50.183%
I - num batch: 313
I - Train -- Loss: 1.182 | Acc: 60.060% | Wgt Acc: 50.304% | LR: 1.250000e-04 | Dur: 195.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 392.    6.    8.  186.  170.]
 [   4.   13.   20.   13.   25.]
 [   9.  123.  168.   24.  226.]
 [ 142.   44.   56.  328.  243.]
 [ 147.  148.  235.  168. 2102.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.272 | Acc: 51.000% | Wgt Acc: 42.379%
I - num batch: 70
I - Val -- Loss: 1.241 | Acc: 52.962% | Wgt Acc: 44.013% | Dur: 34.00s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   1.   5.  51.  24.]
 [  1.   8.   3.   4.   5.]
 [  0.  46.  42.   4.  28.]
 [ 42.  14.  20.  96.  48.]
 [ 38.  65.  76.  49. 326.]]

I - Local maximum validation set accuracy:  52.96

I - Epoch: 31
I - Training: 
	I - Batch: 50 | Loss: 1.183 | Acc: 57.000% | Wgt Acc: 49.665%
	I - Batch: 100 | Loss: 1.192 | Acc: 56.938% | Wgt Acc: 49.254%
	I - Batch: 150 | Loss: 1.183 | Acc: 57.750% | Wgt Acc: 49.951%
	I - Batch: 200 | Loss: 1.192 | Acc: 57.781% | Wgt Acc: 49.699%
	I - Batch: 250 | Loss: 1.173 | Acc: 59.025% | Wgt Acc: 50.834%
	I - Batch: 300 | Loss: 1.176 | Acc: 59.292% | Wgt Acc: 51.009%
I - num batch: 313
I - Train -- Loss: 1.181 | Acc: 59.200% | Wgt Acc: 50.831% | LR: 1.250000e-04 | Dur: 195.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 429.    6.   10.  179.  225.]
 [   6.   30.   23.   21.   45.]
 [   5.  124.  160.   22.  228.]
 [ 124.   32.   62.  333.  260.]
 [ 130.  142.  232.  164. 2008.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.323 | Acc: 49.125% | Wgt Acc: 42.875%
I - num batch: 70
I - Val -- Loss: 1.280 | Acc: 50.718% | Wgt Acc: 44.457% | Dur: 33.97s
I - Confusion Matrix: [row->prediction - col->label]
[[161.   7.  10.  98.  64.]
 [  0.   9.   6.   1.   9.]
 [  0.  43.  44.   0.  31.]
 [ 16.  28.  24.  71.  47.]
 [ 22.  47.  62.  34. 280.]]

I - Epoch: 32
I - Training: 
	I - Batch: 50 | Loss: 1.139 | Acc: 59.375% | Wgt Acc: 52.384%
	I - Batch: 100 | Loss: 1.163 | Acc: 57.750% | Wgt Acc: 49.930%
	I - Batch: 150 | Loss: 1.160 | Acc: 58.292% | Wgt Acc: 50.300%
	I - Batch: 200 | Loss: 1.165 | Acc: 58.781% | Wgt Acc: 50.462%
	I - Batch: 250 | Loss: 1.168 | Acc: 58.875% | Wgt Acc: 50.089%
	I - Batch: 300 | Loss: 1.160 | Acc: 59.208% | Wgt Acc: 50.896%
I - num batch: 313
I - Train -- Loss: 1.162 | Acc: 59.060% | Wgt Acc: 50.743% | LR: 1.250000e-04 | Dur: 195.98s
I - Confusion Matrix: [row->prediction - col->label]
[[ 402.    2.    6.  152.  172.]
 [   7.   23.   22.    8.   54.]
 [   6.  152.  165.   31.  262.]
 [ 148.   40.   61.  363.  278.]
 [ 131.  117.  233.  165. 2000.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.272 | Acc: 50.625% | Wgt Acc: 41.422%
I - num batch: 70
I - Val -- Loss: 1.262 | Acc: 52.334% | Wgt Acc: 42.388% | Dur: 34.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 82.   0.   0.  28.   8.]
 [  0.  11.   5.   9.   7.]
 [  5.  55.  53.   7.  44.]
 [ 64.   5.  16.  95.  30.]
 [ 48.  63.  72.  65. 342.]]

I - Epoch: 33
I - Training: 
	I - Batch: 50 | Loss: 1.164 | Acc: 60.750% | Wgt Acc: 51.008%
	I - Batch: 100 | Loss: 1.158 | Acc: 59.875% | Wgt Acc: 49.728%
	I - Batch: 150 | Loss: 1.158 | Acc: 61.125% | Wgt Acc: 51.003%
	I - Batch: 200 | Loss: 1.142 | Acc: 61.531% | Wgt Acc: 51.659%
	I - Batch: 250 | Loss: 1.150 | Acc: 60.700% | Wgt Acc: 51.430%
	I - Batch: 300 | Loss: 1.153 | Acc: 60.646% | Wgt Acc: 51.773%
I - num batch: 313
I - Train -- Loss: 1.155 | Acc: 60.640% | Wgt Acc: 51.798% | LR: 1.250000e-04 | Dur: 195.93s
I - Confusion Matrix: [row->prediction - col->label]
[[ 382.    4.    6.  140.  147.]
 [   5.   28.   26.   19.   43.]
 [   8.  140.  178.   25.  244.]
 [ 165.   27.   54.  370.  258.]
 [ 134.  135.  223.  165. 2074.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.258 | Acc: 51.000% | Wgt Acc: 42.721%
I - num batch: 70
I - Val -- Loss: 1.236 | Acc: 53.232% | Wgt Acc: 44.256% | Dur: 34.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   1.   1.  36.  14.]
 [  2.   7.   5.   2.   6.]
 [  2.  63.  51.   3.  38.]
 [ 58.  14.  20. 112.  44.]
 [ 43.  49.  69.  51. 329.]]

I - Local maximum validation set accuracy:  53.23

I - Epoch: 34
I - Training: 
	I - Batch: 50 | Loss: 1.182 | Acc: 57.625% | Wgt Acc: 48.903%
	I - Batch: 100 | Loss: 1.173 | Acc: 59.375% | Wgt Acc: 50.601%
	I - Batch: 150 | Loss: 1.167 | Acc: 60.250% | Wgt Acc: 51.355%
	I - Batch: 200 | Loss: 1.166 | Acc: 59.812% | Wgt Acc: 50.805%
	I - Batch: 250 | Loss: 1.155 | Acc: 60.675% | Wgt Acc: 51.717%
	I - Batch: 300 | Loss: 1.147 | Acc: 60.896% | Wgt Acc: 52.082%
I - num batch: 313
I - Train -- Loss: 1.147 | Acc: 60.840% | Wgt Acc: 52.043% | LR: 1.250000e-04 | Dur: 195.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 392.    1.    6.  144.  161.]
 [   2.   30.   36.   24.   50.]
 [   5.  145.  181.   20.  211.]
 [ 159.   34.   53.  361.  266.]
 [ 136.  124.  211.  170. 2078.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.270 | Acc: 50.500% | Wgt Acc: 42.638%
I - num batch: 70
I - Val -- Loss: 1.255 | Acc: 52.334% | Wgt Acc: 43.706% | Dur: 33.69s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   0.   1.  42.  10.]
 [  0.   5.   3.   7.   1.]
 [  4.  71.  68.  12.  68.]
 [ 47.   8.  10.  84.  28.]
 [ 46.  50.  64.  59. 324.]]

I - Epoch: 35
I - Training: 
	I - Batch: 50 | Loss: 1.173 | Acc: 57.625% | Wgt Acc: 50.224%
	I - Batch: 100 | Loss: 1.146 | Acc: 59.375% | Wgt Acc: 52.611%
	I - Batch: 150 | Loss: 1.131 | Acc: 60.917% | Wgt Acc: 54.182%
	I - Batch: 200 | Loss: 1.142 | Acc: 60.156% | Wgt Acc: 52.771%
	I - Batch: 250 | Loss: 1.135 | Acc: 60.575% | Wgt Acc: 53.166%
	I - Batch: 300 | Loss: 1.135 | Acc: 60.458% | Wgt Acc: 53.127%
I - num batch: 313
I - Train -- Loss: 1.134 | Acc: 60.540% | Wgt Acc: 53.224% | LR: 1.250000e-04 | Dur: 194.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 411.    1.    6.  140.  165.]
 [   2.   23.   11.   19.   48.]
 [  12.  165.  222.   25.  275.]
 [ 156.   33.   61.  376.  283.]
 [ 113.  112.  187.  159. 1995.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.265 | Acc: 50.375% | Wgt Acc: 42.868%
I - num batch: 70
I - Val -- Loss: 1.244 | Acc: 52.154% | Wgt Acc: 44.045% | Dur: 33.80s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   2.   5.  61.  19.]
 [  1.   5.   4.   3.   1.]
 [  2.  66.  60.   6.  74.]
 [ 19.  10.  10.  71.  23.]
 [ 46.  51.  67.  63. 314.]]

I - Epoch: 36
I - Training: 
	I - Batch: 50 | Loss: 1.102 | Acc: 63.250% | Wgt Acc: 54.889%
	I - Batch: 100 | Loss: 1.125 | Acc: 61.750% | Wgt Acc: 53.472%
	I - Batch: 150 | Loss: 1.108 | Acc: 62.625% | Wgt Acc: 54.160%
	I - Batch: 200 | Loss: 1.108 | Acc: 62.500% | Wgt Acc: 54.072%
	I - Batch: 250 | Loss: 1.110 | Acc: 61.875% | Wgt Acc: 53.692%
	I - Batch: 300 | Loss: 1.123 | Acc: 60.938% | Wgt Acc: 53.076%
I - num batch: 313
I - Train -- Loss: 1.124 | Acc: 60.740% | Wgt Acc: 52.948% | LR: 1.250000e-04 | Dur: 194.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 414.    4.    6.  148.  186.]
 [   1.   21.   21.   19.   39.]
 [   8.  165.  206.   27.  241.]
 [ 145.   36.   53.  374.  278.]
 [ 126.  108.  201.  151. 2022.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.235 | Acc: 51.000% | Wgt Acc: 47.786%
I - num batch: 70
I - Val -- Loss: 1.212 | Acc: 52.244% | Wgt Acc: 48.574% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   1.   4.  49.  36.]
 [  5.  11.   5.   5.   7.]
 [  2.  63.  64.   8.  58.]
 [ 40.  24.  27. 120.  77.]
 [ 18.  35.  46.  22. 253.]]

I - Epoch: 37
I - Training: 
	I - Batch: 50 | Loss: 1.082 | Acc: 58.875% | Wgt Acc: 52.811%
	I - Batch: 100 | Loss: 1.094 | Acc: 60.625% | Wgt Acc: 53.278%
	I - Batch: 150 | Loss: 1.129 | Acc: 59.750% | Wgt Acc: 51.811%
	I - Batch: 200 | Loss: 1.127 | Acc: 60.594% | Wgt Acc: 52.177%
	I - Batch: 250 | Loss: 1.130 | Acc: 60.525% | Wgt Acc: 52.351%
	I - Batch: 300 | Loss: 1.131 | Acc: 60.188% | Wgt Acc: 52.353%
I - num batch: 313
I - Train -- Loss: 1.132 | Acc: 60.180% | Wgt Acc: 52.470% | LR: 1.250000e-04 | Dur: 192.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 411.    3.    7.  162.  190.]
 [   5.   20.   25.   20.   50.]
 [   7.  169.  215.   25.  274.]
 [ 137.   35.   54.  358.  247.]
 [ 134.  107.  186.  154. 2005.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.309 | Acc: 48.875% | Wgt Acc: 43.280%
I - num batch: 70
I - Val -- Loss: 1.266 | Acc: 51.167% | Wgt Acc: 44.759% | Dur: 32.83s
I - Confusion Matrix: [row->prediction - col->label]
[[148.   3.   6.  70.  47.]
 [  3.   5.  14.   2.  14.]
 [  0.  46.  39.   0.  28.]
 [ 25.  32.  29.  97.  61.]
 [ 23.  48.  58.  35. 281.]]

I - Epoch: 38
I - Training: 
	I - Batch: 50 | Loss: 1.079 | Acc: 63.500% | Wgt Acc: 57.937%
	I - Batch: 100 | Loss: 1.083 | Acc: 62.125% | Wgt Acc: 55.447%
	I - Batch: 150 | Loss: 1.087 | Acc: 61.750% | Wgt Acc: 54.980%
	I - Batch: 200 | Loss: 1.102 | Acc: 61.000% | Wgt Acc: 53.916%
	I - Batch: 250 | Loss: 1.111 | Acc: 60.825% | Wgt Acc: 53.540%
	I - Batch: 300 | Loss: 1.117 | Acc: 60.750% | Wgt Acc: 53.262%
I - num batch: 313
I - Train -- Loss: 1.117 | Acc: 60.800% | Wgt Acc: 53.394% | LR: 1.250000e-04 | Dur: 191.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 412.    1.    9.  134.  188.]
 [   4.   18.   13.   20.   28.]
 [   7.  177.  228.   38.  296.]
 [ 135.   31.   49.  376.  248.]
 [ 136.  107.  188.  151. 2006.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.235 | Acc: 50.750% | Wgt Acc: 44.132%
I - num batch: 70
I - Val -- Loss: 1.210 | Acc: 52.693% | Wgt Acc: 45.595% | Dur: 33.75s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   1.   1.  37.  18.]
 [  1.   5.   5.   2.   4.]
 [  2.  58.  55.   6.  35.]
 [ 62.  21.  27. 122.  74.]
 [ 29.  49.  58.  37. 300.]]

I - Epoch: 39
I - Training: 
	I - Batch: 50 | Loss: 1.096 | Acc: 63.000% | Wgt Acc: 56.426%
	I - Batch: 100 | Loss: 1.082 | Acc: 62.812% | Wgt Acc: 56.601%
	I - Batch: 150 | Loss: 1.097 | Acc: 61.708% | Wgt Acc: 54.625%
	I - Batch: 200 | Loss: 1.105 | Acc: 60.875% | Wgt Acc: 53.855%
	I - Batch: 250 | Loss: 1.102 | Acc: 61.350% | Wgt Acc: 53.921%
	I - Batch: 300 | Loss: 1.099 | Acc: 61.146% | Wgt Acc: 54.128%
I - num batch: 313
I - Train -- Loss: 1.100 | Acc: 61.020% | Wgt Acc: 54.053% | LR: 1.250000e-04 | Dur: 194.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 429.    1.    6.  149.  186.]
 [   1.    7.    5.    3.   10.]
 [  10.  205.  250.   44.  325.]
 [ 132.   26.   64.  377.  257.]
 [ 122.   95.  162.  146. 1988.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.247 | Acc: 51.375% | Wgt Acc: 46.417%
I - num batch: 70
I - Val -- Loss: 1.214 | Acc: 53.142% | Wgt Acc: 47.616% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   1.  45.  29.]
 [  2.   7.   1.   2.   2.]
 [  2.  61.  66.   7.  55.]
 [ 42.  23.  30. 117.  63.]
 [ 33.  41.  48.  33. 282.]]

I - Epoch: 40
I - Training: 
	I - Batch: 50 | Loss: 1.050 | Acc: 62.625% | Wgt Acc: 57.054%
	I - Batch: 100 | Loss: 1.036 | Acc: 64.188% | Wgt Acc: 58.102%
	I - Batch: 150 | Loss: 1.061 | Acc: 63.958% | Wgt Acc: 57.425%
	I - Batch: 200 | Loss: 1.080 | Acc: 62.875% | Wgt Acc: 56.585%
	I - Batch: 250 | Loss: 1.079 | Acc: 62.425% | Wgt Acc: 56.174%
	I - Batch: 300 | Loss: 1.087 | Acc: 62.104% | Wgt Acc: 55.767%
I - num batch: 313
I - Train -- Loss: 1.092 | Acc: 61.820% | Wgt Acc: 55.479% | LR: 1.250000e-04 | Dur: 194.85s
I - Confusion Matrix: [row->prediction - col->label]
[[ 416.    1.    5.  106.  160.]
 [   2.    7.   10.    8.   20.]
 [   7.  199.  274.   43.  350.]
 [ 135.   36.   54.  415.  257.]
 [ 134.   91.  144.  147. 1979.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.243 | Acc: 50.750% | Wgt Acc: 44.670%
I - num batch: 70
I - Val -- Loss: 1.218 | Acc: 52.962% | Wgt Acc: 46.177% | Dur: 33.68s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   1.   3.  50.  20.]
 [  2.   5.   2.   1.   1.]
 [  6.  73.  75.  20.  77.]
 [ 20.   8.  17.  80.  32.]
 [ 42.  47.  49.  53. 301.]]

I - Epoch: 41
I - Training: 
	I - Batch: 50 | Loss: 1.109 | Acc: 61.500% | Wgt Acc: 54.495%
	I - Batch: 100 | Loss: 1.109 | Acc: 62.000% | Wgt Acc: 54.750%
	I - Batch: 150 | Loss: 1.100 | Acc: 61.792% | Wgt Acc: 55.119%
	I - Batch: 200 | Loss: 1.086 | Acc: 62.125% | Wgt Acc: 55.697%
	I - Batch: 250 | Loss: 1.082 | Acc: 62.775% | Wgt Acc: 56.467%
	I - Batch: 300 | Loss: 1.085 | Acc: 62.042% | Wgt Acc: 55.785%
I - num batch: 313
I - Train -- Loss: 1.088 | Acc: 61.980% | Wgt Acc: 55.670% | LR: 1.250000e-04 | Dur: 193.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 422.    2.    7.  115.  195.]
 [   5.   19.   16.    9.   31.]
 [  11.  184.  257.   41.  301.]
 [ 133.   31.   47.  419.  257.]
 [ 123.   98.  160.  135. 1982.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.243 | Acc: 48.875% | Wgt Acc: 44.202%
I - num batch: 70
I - Val -- Loss: 1.217 | Acc: 50.449% | Wgt Acc: 45.415% | Dur: 33.27s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   1.   3.  34.  30.]
 [  1.   4.   3.   2.   8.]
 [  2.  70.  60.  13.  60.]
 [ 70.  23.  26. 130.  70.]
 [ 21.  36.  54.  25. 263.]]

I - Epoch: 42
I - Training: 
	I - Batch: 50 | Loss: 1.074 | Acc: 63.250% | Wgt Acc: 56.231%
	I - Batch: 100 | Loss: 1.062 | Acc: 63.625% | Wgt Acc: 56.926%
	I - Batch: 150 | Loss: 1.057 | Acc: 63.708% | Wgt Acc: 56.790%
	I - Batch: 200 | Loss: 1.060 | Acc: 63.312% | Wgt Acc: 56.592%
	I - Batch: 250 | Loss: 1.057 | Acc: 63.725% | Wgt Acc: 56.998%
	I - Batch: 300 | Loss: 1.054 | Acc: 63.792% | Wgt Acc: 57.081%
I - num batch: 313
I - Train -- Loss: 1.053 | Acc: 63.780% | Wgt Acc: 57.039% | LR: 1.250000e-04 | Dur: 192.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 439.    2.    4.  107.  191.]
 [   2.   27.   16.   10.   36.]
 [   8.  189.  242.   37.  232.]
 [ 132.   40.   59.  430.  256.]
 [ 113.   76.  166.  135. 2051.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.310 | Acc: 50.875% | Wgt Acc: 44.579%
I - num batch: 70
I - Val -- Loss: 1.275 | Acc: 52.873% | Wgt Acc: 45.997% | Dur: 33.32s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   0.   5.  44.  44.]
 [  0.   4.   3.   1.   2.]
 [  0.  44.  42.   3.  28.]
 [ 50.  30.  34. 122.  63.]
 [ 22.  56.  62.  34. 294.]]

I - Epoch: 43
I - Training: 
	I - Batch: 50 | Loss: 1.065 | Acc: 63.125% | Wgt Acc: 55.827%
	I - Batch: 100 | Loss: 1.064 | Acc: 62.938% | Wgt Acc: 55.357%
	I - Batch: 150 | Loss: 1.061 | Acc: 62.417% | Wgt Acc: 55.916%
	I - Batch: 200 | Loss: 1.051 | Acc: 62.281% | Wgt Acc: 56.426%
	I - Batch: 250 | Loss: 1.057 | Acc: 62.450% | Wgt Acc: 56.346%
	I - Batch: 300 | Loss: 1.063 | Acc: 62.312% | Wgt Acc: 56.317%
I - num batch: 313
I - Train -- Loss: 1.062 | Acc: 62.320% | Wgt Acc: 56.390% | LR: 1.250000e-04 | Dur: 192.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 448.    2.    7.  117.  182.]
 [   1.   14.    5.    5.   13.]
 [  10.  210.  263.   42.  330.]
 [ 120.   34.   59.  422.  272.]
 [ 115.   74.  153.  133. 1969.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.330 | Acc: 51.750% | Wgt Acc: 42.589%
I - num batch: 70
I - Val -- Loss: 1.299 | Acc: 53.591% | Wgt Acc: 43.537% | Dur: 33.49s
I - Confusion Matrix: [row->prediction - col->label]
[[145.   2.   8.  84.  31.]
 [  0.   2.   2.   0.   1.]
 [  3.  61.  64.  10.  41.]
 [  6.  10.   8.  39.  11.]
 [ 45.  59.  64.  71. 347.]]

I - Local maximum validation set accuracy:  53.59

I - Epoch: 44
I - Training: 
	I - Batch: 50 | Loss: 1.028 | Acc: 65.500% | Wgt Acc: 57.353%
	I - Batch: 100 | Loss: 0.993 | Acc: 65.688% | Wgt Acc: 58.662%
	I - Batch: 150 | Loss: 1.029 | Acc: 64.000% | Wgt Acc: 57.758%
	I - Batch: 200 | Loss: 1.041 | Acc: 63.344% | Wgt Acc: 57.193%
	I - Batch: 250 | Loss: 1.046 | Acc: 63.175% | Wgt Acc: 57.331%
	I - Batch: 300 | Loss: 1.035 | Acc: 64.000% | Wgt Acc: 58.117%
I - num batch: 313
I - Train -- Loss: 1.032 | Acc: 63.980% | Wgt Acc: 58.119% | LR: 1.250000e-04 | Dur: 194.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.    1.    3.  105.  191.]
 [   2.   29.   30.   18.   42.]
 [   6.  184.  268.   25.  258.]
 [ 104.   40.   48.  425.  261.]
 [ 119.   80.  138.  146. 2014.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.274 | Acc: 53.625% | Wgt Acc: 43.671%
I - num batch: 70
I - Val -- Loss: 1.237 | Acc: 56.373% | Wgt Acc: 45.590% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[135.   1.   5.  63.  21.]
 [  0.   3.   2.   0.   1.]
 [  0.  56.  57.   7.  26.]
 [ 16.   9.  17.  67.  17.]
 [ 48.  65.  65.  67. 366.]]

I - Local maximum validation set accuracy:  56.37

I - Epoch: 45
I - Training: 
	I - Batch: 50 | Loss: 1.018 | Acc: 65.875% | Wgt Acc: 59.868%
	I - Batch: 100 | Loss: 1.009 | Acc: 65.750% | Wgt Acc: 60.173%
	I - Batch: 150 | Loss: 1.011 | Acc: 66.375% | Wgt Acc: 60.440%
	I - Batch: 200 | Loss: 1.025 | Acc: 65.281% | Wgt Acc: 59.251%
	I - Batch: 250 | Loss: 1.021 | Acc: 64.875% | Wgt Acc: 59.159%
	I - Batch: 300 | Loss: 1.022 | Acc: 64.771% | Wgt Acc: 59.188%
I - num batch: 313
I - Train -- Loss: 1.025 | Acc: 64.660% | Wgt Acc: 58.992% | LR: 1.250000e-04 | Dur: 192.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 466.    1.    4.   80.  179.]
 [   1.    3.    2.    2.    4.]
 [   9.  224.  292.   43.  320.]
 [ 116.   35.   52.  456.  247.]
 [ 102.   71.  137.  138. 2016.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.245 | Acc: 50.500% | Wgt Acc: 45.956%
I - num batch: 70
I - Val -- Loss: 1.212 | Acc: 52.334% | Wgt Acc: 47.585% | Dur: 33.19s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   0.   5.  48.  36.]
 [  2.   3.   3.   2.   6.]
 [  1.  69.  73.   9.  50.]
 [ 52.  23.  24. 118.  71.]
 [ 23.  39.  41.  27. 268.]]

I - Epoch: 46
I - Training: 
	I - Batch: 50 | Loss: 1.051 | Acc: 64.875% | Wgt Acc: 57.345%
	I - Batch: 100 | Loss: 1.037 | Acc: 64.750% | Wgt Acc: 58.205%
	I - Batch: 150 | Loss: 1.014 | Acc: 65.625% | Wgt Acc: 59.344%
	I - Batch: 200 | Loss: 1.014 | Acc: 65.375% | Wgt Acc: 59.171%
	I - Batch: 250 | Loss: 1.010 | Acc: 64.875% | Wgt Acc: 58.844%
	I - Batch: 300 | Loss: 1.008 | Acc: 65.271% | Wgt Acc: 59.264%
I - num batch: 313
I - Train -- Loss: 1.014 | Acc: 65.240% | Wgt Acc: 59.209% | LR: 1.250000e-04 | Dur: 193.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 463.    0.    3.   93.  180.]
 [   2.   29.   18.    5.   39.]
 [   5.  196.  267.   30.  255.]
 [ 105.   38.   53.  448.  237.]
 [ 119.   71.  146.  143. 2055.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.455 | Acc: 46.000% | Wgt Acc: 39.515%
I - num batch: 70
I - Val -- Loss: 1.383 | Acc: 49.641% | Wgt Acc: 42.616% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[154.   8.  11. 102.  84.]
 [  1.   9.   9.   1.   2.]
 [  0.  37.  38.   2.  21.]
 [ 17.  20.  23.  66.  38.]
 [ 27.  60.  65.  33. 286.]]

I - Epoch: 47
I - Training: 
	I - Batch: 50 | Loss: 0.995 | Acc: 64.250% | Wgt Acc: 57.742%
	I - Batch: 100 | Loss: 0.995 | Acc: 64.750% | Wgt Acc: 58.669%
	I - Batch: 150 | Loss: 0.994 | Acc: 65.708% | Wgt Acc: 59.599%
	I - Batch: 200 | Loss: 0.985 | Acc: 66.188% | Wgt Acc: 59.912%
	I - Batch: 250 | Loss: 0.989 | Acc: 66.125% | Wgt Acc: 59.734%
	I - Batch: 300 | Loss: 0.996 | Acc: 65.625% | Wgt Acc: 59.360%
I - num batch: 313
I - Train -- Loss: 0.995 | Acc: 65.740% | Wgt Acc: 59.417% | LR: 1.250000e-04 | Dur: 194.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 471.    1.    5.   85.  179.]
 [   2.   27.   19.   15.   22.]
 [   7.  209.  271.   42.  253.]
 [  94.   28.   40.  434.  228.]
 [ 120.   69.  152.  143. 2084.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.279 | Acc: 52.375% | Wgt Acc: 43.979%
I - num batch: 70
I - Val -- Loss: 1.242 | Acc: 54.758% | Wgt Acc: 45.373% | Dur: 33.74s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   2.   5.  48.  31.]
 [  0.   7.   4.   3.   1.]
 [  3.  52.  50.   8.  39.]
 [ 31.  13.  16.  91.  20.]
 [ 43.  60.  71.  54. 340.]]

I - Epoch: 48
I - Training: 
	I - Batch: 50 | Loss: 1.021 | Acc: 62.875% | Wgt Acc: 57.630%
	I - Batch: 100 | Loss: 0.997 | Acc: 65.062% | Wgt Acc: 59.514%
	I - Batch: 150 | Loss: 0.991 | Acc: 65.417% | Wgt Acc: 59.661%
	I - Batch: 200 | Loss: 0.985 | Acc: 65.688% | Wgt Acc: 59.833%
	I - Batch: 250 | Loss: 0.979 | Acc: 65.800% | Wgt Acc: 60.118%
	I - Batch: 300 | Loss: 0.976 | Acc: 65.875% | Wgt Acc: 60.775%
I - num batch: 313
I - Train -- Loss: 0.977 | Acc: 65.820% | Wgt Acc: 60.602% | LR: 1.250000e-04 | Dur: 195.01s
I - Confusion Matrix: [row->prediction - col->label]
[[ 496.    0.    5.   93.  201.]
 [   1.   21.   26.   14.   19.]
 [   8.  224.  291.   32.  289.]
 [  85.   32.   42.  456.  230.]
 [ 104.   57.  123.  124. 2027.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.292 | Acc: 51.875% | Wgt Acc: 45.047%
I - num batch: 70
I - Val -- Loss: 1.258 | Acc: 53.950% | Wgt Acc: 46.860% | Dur: 34.07s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   3.   2.  39.  29.]
 [  0.   4.   3.   5.   1.]
 [  3.  66.  73.  14.  56.]
 [ 52.  13.  19. 114.  37.]
 [ 42.  48.  49.  32. 308.]]

I - Epoch: 49
I - Training: 
	I - Batch: 50 | Loss: 0.896 | Acc: 68.250% | Wgt Acc: 64.055%
	I - Batch: 100 | Loss: 0.932 | Acc: 67.688% | Wgt Acc: 62.426%
	I - Batch: 150 | Loss: 0.945 | Acc: 67.042% | Wgt Acc: 61.632%
	I - Batch: 200 | Loss: 0.941 | Acc: 67.531% | Wgt Acc: 61.962%
	I - Batch: 250 | Loss: 0.958 | Acc: 66.800% | Wgt Acc: 61.095%
	I - Batch: 300 | Loss: 0.966 | Acc: 67.021% | Wgt Acc: 60.815%
I - num batch: 313
I - Train -- Loss: 0.967 | Acc: 66.820% | Wgt Acc: 60.618% | LR: 1.250000e-04 | Dur: 194.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 475.    2.    4.   70.  187.]
 [   0.   21.   17.   17.   20.]
 [   5.  219.  283.   38.  263.]
 [  94.   31.   47.  457.  191.]
 [ 120.   61.  136.  137. 2105.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.290 | Acc: 51.000% | Wgt Acc: 45.844%
I - num batch: 70
I - Val -- Loss: 1.247 | Acc: 53.411% | Wgt Acc: 47.833% | Dur: 33.98s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   1.   6.  51.  41.]
 [  1.  11.   5.   5.   2.]
 [  2.  53.  65.   9.  51.]
 [ 46.  22.  25. 109.  52.]
 [ 25.  47.  45.  30. 285.]]

I - Epoch: 50
I - Training: 
	I - Batch: 50 | Loss: 0.928 | Acc: 66.875% | Wgt Acc: 62.814%
	I - Batch: 100 | Loss: 0.953 | Acc: 66.812% | Wgt Acc: 61.276%
	I - Batch: 150 | Loss: 0.943 | Acc: 66.417% | Wgt Acc: 61.331%
	I - Batch: 200 | Loss: 0.934 | Acc: 66.906% | Wgt Acc: 61.786%
	I - Batch: 250 | Loss: 0.936 | Acc: 67.275% | Wgt Acc: 62.011%
	I - Batch: 300 | Loss: 0.946 | Acc: 66.542% | Wgt Acc: 61.415%
I - num batch: 313
I - Train -- Loss: 0.947 | Acc: 66.540% | Wgt Acc: 61.365% | LR: 1.250000e-04 | Dur: 195.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 489.    0.    3.   76.  192.]
 [   0.   27.   29.    9.   15.]
 [   4.  228.  295.   38.  270.]
 [  87.   21.   50.  470.  243.]
 [ 114.   58.  110.  126. 2046.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.246 | Acc: 52.000% | Wgt Acc: 45.711%
I - num batch: 70
I - Val -- Loss: 1.217 | Acc: 55.206% | Wgt Acc: 48.473% | Dur: 33.92s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   1.   0.  29.  29.]
 [  1.  16.   7.   9.   7.]
 [  3.  56.  61.   8.  44.]
 [ 53.  15.  24. 125.  42.]
 [ 38.  46.  54.  33. 309.]]

I - Epoch: 51
I - Training: 
	I - Batch: 50 | Loss: 0.903 | Acc: 68.750% | Wgt Acc: 62.644%
	I - Batch: 100 | Loss: 0.898 | Acc: 69.500% | Wgt Acc: 63.713%
	I - Batch: 150 | Loss: 0.915 | Acc: 68.625% | Wgt Acc: 63.679%
	I - Batch: 200 | Loss: 0.936 | Acc: 67.594% | Wgt Acc: 62.569%
	I - Batch: 250 | Loss: 0.928 | Acc: 67.700% | Wgt Acc: 62.598%
	I - Batch: 300 | Loss: 0.925 | Acc: 67.979% | Wgt Acc: 62.739%
I - num batch: 313
I - Train -- Loss: 0.929 | Acc: 67.780% | Wgt Acc: 62.508% | LR: 1.250000e-04 | Dur: 194.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 496.    0.    4.   57.  195.]
 [   1.   48.   36.   21.   35.]
 [   2.  208.  270.   36.  222.]
 [  87.   29.   53.  490.  229.]
 [ 108.   49.  124.  115. 2085.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.231 | Acc: 51.625% | Wgt Acc: 46.500%
I - num batch: 70
I - Val -- Loss: 1.216 | Acc: 53.411% | Wgt Acc: 48.024% | Dur: 33.56s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   0.   3.  54.  26.]
 [  2.  19.  16.   8.   9.]
 [  1.  63.  68.   8.  64.]
 [ 38.  21.  20. 102.  46.]
 [ 38.  31.  39.  32. 286.]]

I - Epoch: 52
I - Training: 
	I - Batch: 50 | Loss: 0.888 | Acc: 69.125% | Wgt Acc: 63.146%
	I - Batch: 100 | Loss: 0.873 | Acc: 70.000% | Wgt Acc: 64.462%
	I - Batch: 150 | Loss: 0.888 | Acc: 68.583% | Wgt Acc: 63.848%
	I - Batch: 200 | Loss: 0.881 | Acc: 69.312% | Wgt Acc: 64.053%
	I - Batch: 250 | Loss: 0.896 | Acc: 69.000% | Wgt Acc: 63.673%
	I - Batch: 300 | Loss: 0.898 | Acc: 68.979% | Wgt Acc: 63.757%
I - num batch: 313
I - Train -- Loss: 0.903 | Acc: 68.800% | Wgt Acc: 63.503% | LR: 1.250000e-04 | Dur: 194.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 520.    0.    5.   69.  189.]
 [   1.   37.   42.   14.   37.]
 [   4.  230.  292.   28.  207.]
 [  64.   27.   35.  478.  220.]
 [ 105.   40.  113.  130. 2113.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.274 | Acc: 51.875% | Wgt Acc: 44.356%
I - num batch: 70
I - Val -- Loss: 1.264 | Acc: 53.770% | Wgt Acc: 45.399% | Dur: 33.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 90.   0.   1.  20.  20.]
 [  0.   4.   4.   7.   1.]
 [  5.  73.  73.  21.  55.]
 [ 53.   7.  17. 106.  29.]
 [ 51.  50.  51.  50. 326.]]

I - Epoch: 53
I - Training: 
	I - Batch: 50 | Loss: 0.802 | Acc: 72.500% | Wgt Acc: 66.455%
	I - Batch: 100 | Loss: 0.838 | Acc: 71.188% | Wgt Acc: 65.453%
	I - Batch: 150 | Loss: 0.864 | Acc: 70.125% | Wgt Acc: 64.908%
	I - Batch: 200 | Loss: 0.866 | Acc: 70.219% | Wgt Acc: 64.778%
	I - Batch: 250 | Loss: 0.881 | Acc: 69.375% | Wgt Acc: 64.191%
	I - Batch: 300 | Loss: 0.879 | Acc: 69.250% | Wgt Acc: 64.205%
I - num batch: 313
I - Train -- Loss: 0.879 | Acc: 69.420% | Wgt Acc: 64.356% | LR: 1.250000e-04 | Dur: 193.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 515.    0.    1.   53.  204.]
 [   0.   37.   30.   21.   32.]
 [   1.  226.  289.   22.  220.]
 [  71.   26.   55.  515.  195.]
 [ 107.   45.  112.  108. 2115.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.419 | Acc: 51.125% | Wgt Acc: 39.117%
I - num batch: 70
I - Val -- Loss: 1.387 | Acc: 53.321% | Wgt Acc: 39.796% | Dur: 33.63s
I - Confusion Matrix: [row->prediction - col->label]
[[ 82.   0.   1.  29.   8.]
 [  0.   6.   5.   5.   2.]
 [  0.  46.  42.   5.  12.]
 [ 33.   9.  12.  71.  16.]
 [ 84.  73.  86.  94. 393.]]

I - Epoch: 54
I - Training: 
	I - Batch: 50 | Loss: 0.859 | Acc: 71.500% | Wgt Acc: 64.882%
	I - Batch: 100 | Loss: 0.858 | Acc: 70.438% | Wgt Acc: 65.926%
	I - Batch: 150 | Loss: 0.860 | Acc: 70.375% | Wgt Acc: 65.513%
	I - Batch: 200 | Loss: 0.855 | Acc: 70.906% | Wgt Acc: 65.953%
	I - Batch: 250 | Loss: 0.851 | Acc: 71.300% | Wgt Acc: 66.214%
	I - Batch: 300 | Loss: 0.856 | Acc: 70.625% | Wgt Acc: 65.620%
I - num batch: 313
I - Train -- Loss: 0.856 | Acc: 70.520% | Wgt Acc: 65.477% | LR: 1.250000e-04 | Dur: 193.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 515.    0.    4.   42.  158.]
 [   1.   29.   32.    9.   13.]
 [   5.  230.  304.   26.  233.]
 [  52.   27.   34.  536.  220.]
 [ 121.   48.  113.  106. 2142.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.291 | Acc: 52.375% | Wgt Acc: 45.334%
I - num batch: 70
I - Val -- Loss: 1.259 | Acc: 54.758% | Wgt Acc: 47.241% | Dur: 33.58s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   1.   2.  59.  33.]
 [  0.   1.   1.   5.   1.]
 [  5.  68.  78.  14.  45.]
 [ 21.  15.  18.  81.  35.]
 [ 40.  49.  47.  45. 317.]]

I - Epoch: 55
I - Training: 
	I - Batch: 50 | Loss: 0.831 | Acc: 70.875% | Wgt Acc: 65.447%
	I - Batch: 100 | Loss: 0.823 | Acc: 71.562% | Wgt Acc: 66.499%
	I - Batch: 150 | Loss: 0.817 | Acc: 71.958% | Wgt Acc: 66.503%
	I - Batch: 200 | Loss: 0.822 | Acc: 71.531% | Wgt Acc: 66.082%
	I - Batch: 250 | Loss: 0.823 | Acc: 71.875% | Wgt Acc: 66.612%
	I - Batch: 300 | Loss: 0.828 | Acc: 71.229% | Wgt Acc: 66.162%
I - num batch: 313
I - Train -- Loss: 0.833 | Acc: 71.060% | Wgt Acc: 65.932% | LR: 1.250000e-04 | Dur: 194.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 534.    0.    2.   57.  169.]
 [   0.   10.   13.   16.   15.]
 [   2.  265.  321.   23.  209.]
 [  55.   25.   41.  531.  216.]
 [ 103.   34.  110.   92. 2157.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.272 | Acc: 52.250% | Wgt Acc: 45.550%
I - num batch: 70
I - Val -- Loss: 1.241 | Acc: 54.399% | Wgt Acc: 47.246% | Dur: 33.61s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   2.   3.  56.  37.]
 [  0.   2.   2.   6.   1.]
 [  2.  69.  70.   6.  46.]
 [ 38.  22.  20.  97.  38.]
 [ 31.  39.  51.  39. 309.]]

I - Epoch: 56
I - Training: 
	I - Batch: 50 | Loss: 0.796 | Acc: 73.000% | Wgt Acc: 68.707%
	I - Batch: 100 | Loss: 0.802 | Acc: 72.500% | Wgt Acc: 68.394%
	I - Batch: 150 | Loss: 0.801 | Acc: 71.500% | Wgt Acc: 67.504%
	I - Batch: 200 | Loss: 0.817 | Acc: 70.562% | Wgt Acc: 66.731%
	I - Batch: 250 | Loss: 0.814 | Acc: 70.525% | Wgt Acc: 66.737%
	I - Batch: 300 | Loss: 0.817 | Acc: 70.812% | Wgt Acc: 66.719%
I - num batch: 313
I - Train -- Loss: 0.816 | Acc: 70.840% | Wgt Acc: 66.747% | LR: 1.250000e-04 | Dur: 193.16s
I - Confusion Matrix: [row->prediction - col->label]
[[ 531.    2.    2.   44.  191.]
 [   0.   26.   25.   11.   11.]
 [   5.  265.  329.   28.  244.]
 [  49.   15.   33.  554.  218.]
 [ 109.   26.   98.   82. 2102.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.372 | Acc: 50.375% | Wgt Acc: 44.915%
I - num batch: 70
I - Val -- Loss: 1.326 | Acc: 52.603% | Wgt Acc: 46.913% | Dur: 33.09s
I - Confusion Matrix: [row->prediction - col->label]
[[149.   4.   9.  73.  55.]
 [  0.   1.   2.   2.   0.]
 [  2.  66.  65.   8.  58.]
 [ 22.  18.  20.  91.  38.]
 [ 26.  45.  50.  30. 280.]]

I - Epoch: 57
I - Training: 
	I - Batch: 50 | Loss: 0.818 | Acc: 71.375% | Wgt Acc: 67.041%
	I - Batch: 100 | Loss: 0.797 | Acc: 71.312% | Wgt Acc: 67.251%
	I - Batch: 150 | Loss: 0.803 | Acc: 71.375% | Wgt Acc: 66.605%
	I - Batch: 200 | Loss: 0.813 | Acc: 71.219% | Wgt Acc: 66.632%
	I - Batch: 250 | Loss: 0.818 | Acc: 71.000% | Wgt Acc: 66.715%
	I - Batch: 300 | Loss: 0.824 | Acc: 70.729% | Wgt Acc: 66.392%
I - num batch: 313
I - Train -- Loss: 0.822 | Acc: 70.940% | Wgt Acc: 66.535% | LR: 1.250000e-04 | Dur: 192.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 540.    0.    2.   39.  187.]
 [   0.   16.   21.   20.   11.]
 [   2.  257.  329.   24.  212.]
 [  48.   30.   40.  544.  238.]
 [ 104.   31.   95.   92. 2118.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.285 | Acc: 52.250% | Wgt Acc: 45.753%
I - num batch: 70
I - Val -- Loss: 1.256 | Acc: 53.770% | Wgt Acc: 46.786% | Dur: 33.20s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   1.   4.  43.  25.]
 [  0.   3.   6.   7.   7.]
 [  1.  68.  71.  10.  53.]
 [ 45.  19.  21. 106.  41.]
 [ 39.  43.  44.  38. 305.]]

I - Epoch: 58
I - Training: 
	I - Batch: 50 | Loss: 0.771 | Acc: 73.625% | Wgt Acc: 70.139%
	I - Batch: 100 | Loss: 0.762 | Acc: 74.562% | Wgt Acc: 70.035%
	I - Batch: 150 | Loss: 0.773 | Acc: 74.333% | Wgt Acc: 69.904%
	I - Batch: 200 | Loss: 0.775 | Acc: 73.906% | Wgt Acc: 69.480%
	I - Batch: 250 | Loss: 0.773 | Acc: 73.750% | Wgt Acc: 69.546%
	I - Batch: 300 | Loss: 0.778 | Acc: 73.667% | Wgt Acc: 69.237%
I - num batch: 313
I - Train -- Loss: 0.780 | Acc: 73.480% | Wgt Acc: 68.963% | LR: 1.250000e-04 | Dur: 192.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 546.    0.    4.   41.  159.]
 [   0.   31.   24.   13.   22.]
 [   3.  253.  333.   15.  192.]
 [  41.   21.   23.  569.  198.]
 [ 104.   29.  103.   81. 2195.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.368 | Acc: 52.250% | Wgt Acc: 43.783%
I - num batch: 70
I - Val -- Loss: 1.353 | Acc: 53.950% | Wgt Acc: 44.939% | Dur: 33.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   2.  33.  20.]
 [  0.   2.   3.   5.   1.]
 [  5.  68.  68.  17.  48.]
 [ 48.  13.  13.  98.  28.]
 [ 47.  50.  60.  51. 334.]]

I - Epoch: 59
I - Training: 
	I - Batch: 50 | Loss: 0.738 | Acc: 74.250% | Wgt Acc: 70.856%
	I - Batch: 100 | Loss: 0.717 | Acc: 75.125% | Wgt Acc: 71.683%
	I - Batch: 150 | Loss: 0.729 | Acc: 74.583% | Wgt Acc: 70.646%
	I - Batch: 200 | Loss: 0.730 | Acc: 74.938% | Wgt Acc: 70.953%
	I - Batch: 250 | Loss: 0.747 | Acc: 73.575% | Wgt Acc: 69.774%
	I - Batch: 300 | Loss: 0.738 | Acc: 74.000% | Wgt Acc: 70.075%
I - num batch: 313
I - Train -- Loss: 0.740 | Acc: 73.900% | Wgt Acc: 69.953% | LR: 1.250000e-04 | Dur: 192.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 567.    0.    1.   23.  174.]
 [   1.   11.   13.    4.    7.]
 [   2.  281.  349.   21.  212.]
 [  24.   17.   34.  598.  203.]
 [ 100.   25.   90.   73. 2170.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.351 | Acc: 53.000% | Wgt Acc: 46.878%
I - num batch: 70
I - Val -- Loss: 1.341 | Acc: 54.758% | Wgt Acc: 48.421% | Dur: 33.09s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   3.   5.  49.  37.]
 [  0.   2.   0.   3.   0.]
 [  5.  68.  77.  13.  50.]
 [ 35.  18.  19. 106.  44.]
 [ 34.  43.  45.  33. 300.]]

I - Epoch: 60
I - Training: 
	I - Batch: 50 | Loss: 0.734 | Acc: 75.125% | Wgt Acc: 69.621%
	I - Batch: 100 | Loss: 0.716 | Acc: 74.250% | Wgt Acc: 69.632%
	I - Batch: 150 | Loss: 0.709 | Acc: 74.875% | Wgt Acc: 70.328%
	I - Batch: 200 | Loss: 0.722 | Acc: 74.500% | Wgt Acc: 70.106%
	I - Batch: 250 | Loss: 0.730 | Acc: 74.600% | Wgt Acc: 69.962%
	I - Batch: 300 | Loss: 0.726 | Acc: 74.896% | Wgt Acc: 70.396%
I - num batch: 313
I - Train -- Loss: 0.731 | Acc: 74.860% | Wgt Acc: 70.385% | LR: 1.250000e-04 | Dur: 191.37s
I - Confusion Matrix: [row->prediction - col->label]
[[ 558.    0.    3.   27.  158.]
 [   0.   17.   11.    5.   10.]
 [   1.  282.  354.   28.  208.]
 [  35.   14.   26.  587.  163.]
 [ 100.   21.   93.   72. 2227.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.535 | Acc: 52.875% | Wgt Acc: 44.705%
I - num batch: 70
I - Val -- Loss: 1.473 | Acc: 55.566% | Wgt Acc: 46.674% | Dur: 33.00s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.   7.  52.  41.]
 [  0.   0.   2.   1.   0.]
 [  1.  34.  46.   1.  18.]
 [ 34.  31.  28. 112.  40.]
 [ 35.  66.  63.  38. 332.]]

I - Epoch: 61
I - Training: 
	I - Batch: 50 | Loss: 0.697 | Acc: 74.000% | Wgt Acc: 70.752%
	I - Batch: 100 | Loss: 0.716 | Acc: 73.250% | Wgt Acc: 69.398%
	I - Batch: 150 | Loss: 0.712 | Acc: 73.875% | Wgt Acc: 70.132%
	I - Batch: 200 | Loss: 0.707 | Acc: 74.250% | Wgt Acc: 70.391%
	I - Batch: 250 | Loss: 0.712 | Acc: 74.250% | Wgt Acc: 70.558%
	I - Batch: 300 | Loss: 0.712 | Acc: 74.583% | Wgt Acc: 70.850%
I - num batch: 313
I - Train -- Loss: 0.708 | Acc: 74.720% | Wgt Acc: 70.938% | LR: 1.250000e-04 | Dur: 191.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 590.    0.    2.   25.  156.]
 [   0.    8.   11.    7.    3.]
 [   2.  291.  356.   18.  208.]
 [  31.   16.   28.  600.  217.]
 [  71.   19.   90.   69. 2182.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.395 | Acc: 51.250% | Wgt Acc: 44.188%
I - num batch: 70
I - Val -- Loss: 1.355 | Acc: 53.860% | Wgt Acc: 46.145% | Dur: 32.99s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   2.   3.  45.  29.]
 [  0.   1.   3.   1.   0.]
 [  3.  62.  66.  12.  47.]
 [ 40.  23.  19. 107.  41.]
 [ 44.  46.  55.  39. 314.]]

I - Epoch: 62
I - Training: 
	I - Batch: 50 | Loss: 0.611 | Acc: 80.625% | Wgt Acc: 77.135%
	I - Batch: 100 | Loss: 0.655 | Acc: 78.750% | Wgt Acc: 75.041%
	I - Batch: 150 | Loss: 0.677 | Acc: 76.833% | Wgt Acc: 72.839%
	I - Batch: 200 | Loss: 0.691 | Acc: 76.281% | Wgt Acc: 72.381%
	I - Batch: 250 | Loss: 0.702 | Acc: 75.350% | Wgt Acc: 71.472%
	I - Batch: 300 | Loss: 0.707 | Acc: 75.146% | Wgt Acc: 71.143%
I - num batch: 313
I - Train -- Loss: 0.710 | Acc: 75.100% | Wgt Acc: 71.173% | LR: 1.250000e-04 | Dur: 191.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 568.    0.    3.   28.  185.]
 [   0.    4.    5.    3.    7.]
 [   2.  293.  373.   25.  187.]
 [  35.   17.   25.  608.  185.]
 [  89.   20.   81.   55. 2202.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.348 | Acc: 49.625% | Wgt Acc: 44.070%
I - num batch: 70
I - Val -- Loss: 1.337 | Acc: 50.987% | Wgt Acc: 45.198% | Dur: 32.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   0.   2.  23.  16.]
 [  4.   5.   5.   3.   0.]
 [  1.  66.  72.  11.  63.]
 [ 86.  30.  30. 138.  73.]
 [ 34.  33.  37.  29. 279.]]

I - Epoch: 63
I - Training: 
	I - Batch: 50 | Loss: 0.677 | Acc: 76.375% | Wgt Acc: 71.965%
	I - Batch: 100 | Loss: 0.661 | Acc: 77.562% | Wgt Acc: 73.091%
	I - Batch: 150 | Loss: 0.665 | Acc: 76.792% | Wgt Acc: 72.178%
	I - Batch: 200 | Loss: 0.669 | Acc: 76.688% | Wgt Acc: 72.579%
	I - Batch: 250 | Loss: 0.667 | Acc: 76.850% | Wgt Acc: 72.874%
	I - Batch: 300 | Loss: 0.678 | Acc: 76.250% | Wgt Acc: 72.417%
I - num batch: 313
I - Train -- Loss: 0.682 | Acc: 76.140% | Wgt Acc: 72.307% | LR: 1.250000e-04 | Dur: 189.60s
I - Confusion Matrix: [row->prediction - col->label]
[[ 593.    0.    2.   15.  174.]
 [   0.    8.    5.   10.    5.]
 [   2.  292.  366.   19.  185.]
 [  30.   19.   26.  617.  179.]
 [  69.   15.   88.   58. 2223.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.404 | Acc: 51.000% | Wgt Acc: 45.557%
I - num batch: 70
I - Val -- Loss: 1.371 | Acc: 52.962% | Wgt Acc: 47.167% | Dur: 32.60s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   2.   5.  50.  48.]
 [  0.   0.   0.   0.   0.]
 [  4.  69.  72.  18.  57.]
 [ 35.  24.  25. 104.  42.]
 [ 30.  39.  44.  32. 284.]]

I - Epoch: 64
I - Training: 
	I - Batch: 50 | Loss: 0.612 | Acc: 80.000% | Wgt Acc: 76.350%
	I - Batch: 100 | Loss: 0.625 | Acc: 78.688% | Wgt Acc: 74.589%
	I - Batch: 150 | Loss: 0.646 | Acc: 77.958% | Wgt Acc: 73.764%
	I - Batch: 200 | Loss: 0.643 | Acc: 77.531% | Wgt Acc: 73.436%
	I - Batch: 250 | Loss: 0.639 | Acc: 78.225% | Wgt Acc: 74.018%
	I - Batch: 300 | Loss: 0.655 | Acc: 77.438% | Wgt Acc: 73.130%
I - num batch: 313
I - Train -- Loss: 0.656 | Acc: 77.400% | Wgt Acc: 73.076% | LR: 1.250000e-04 | Dur: 189.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 588.    0.    1.   32.  154.]
 [   0.    5.    3.    3.    0.]
 [   3.  304.  375.   19.  170.]
 [  25.    5.   23.  619.  159.]
 [  78.   20.   85.   46. 2283.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.538 | Acc: 52.500% | Wgt Acc: 43.245%
I - num batch: 70
I - Val -- Loss: 1.499 | Acc: 55.117% | Wgt Acc: 45.119% | Dur: 32.63s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   1.   3.  35.  19.]
 [  0.   0.   0.   1.   1.]
 [  3.  56.  61.  11.  37.]
 [ 37.  13.  21.  97.  24.]
 [ 53.  64.  61.  60. 350.]]

I - Epoch: 65
I - Training: 
	I - Batch: 50 | Loss: 0.642 | Acc: 78.625% | Wgt Acc: 75.080%
	I - Batch: 100 | Loss: 0.661 | Acc: 76.812% | Wgt Acc: 73.524%
	I - Batch: 150 | Loss: 0.651 | Acc: 77.208% | Wgt Acc: 73.315%
	I - Batch: 200 | Loss: 0.640 | Acc: 77.375% | Wgt Acc: 73.494%
	I - Batch: 250 | Loss: 0.650 | Acc: 77.550% | Wgt Acc: 73.487%
	I - Batch: 300 | Loss: 0.657 | Acc: 77.125% | Wgt Acc: 73.275%
I - num batch: 313
I - Train -- Loss: 0.657 | Acc: 76.900% | Wgt Acc: 73.047% | LR: 1.250000e-04 | Dur: 190.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 593.    0.    1.   25.  152.]
 [   0.    4.    2.    3.    5.]
 [   1.  301.  380.   22.  203.]
 [  30.   14.   17.  623.  161.]
 [  70.   15.   87.   46. 2245.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.451 | Acc: 51.750% | Wgt Acc: 44.754%
I - num batch: 70
I - Val -- Loss: 1.423 | Acc: 53.232% | Wgt Acc: 46.209% | Dur: 33.30s
I - Confusion Matrix: [row->prediction - col->label]
[[119.   3.   4.  45.  36.]
 [  0.   1.   0.   0.   0.]
 [  2.  57.  67.  13.  44.]
 [ 43.  21.  21. 104.  49.]
 [ 35.  52.  54.  42. 302.]]

I - Epoch: 66
I - Training: 
	I - Batch: 50 | Loss: 0.633 | Acc: 79.375% | Wgt Acc: 76.141%
	I - Batch: 100 | Loss: 0.598 | Acc: 80.688% | Wgt Acc: 77.629%
	I - Batch: 150 | Loss: 0.594 | Acc: 80.000% | Wgt Acc: 76.802%
	I - Batch: 200 | Loss: 0.603 | Acc: 79.500% | Wgt Acc: 75.984%
	I - Batch: 250 | Loss: 0.611 | Acc: 79.425% | Wgt Acc: 75.865%
	I - Batch: 300 | Loss: 0.619 | Acc: 78.646% | Wgt Acc: 74.723%
I - num batch: 313
I - Train -- Loss: 0.619 | Acc: 78.560% | Wgt Acc: 74.719% | LR: 1.250000e-04 | Dur: 193.32s
I - Confusion Matrix: [row->prediction - col->label]
[[ 607.    0.    0.   22.  146.]
 [   0.    3.    1.    1.    2.]
 [   2.  303.  398.   18.  171.]
 [  20.    9.   17.  630.  157.]
 [  65.   19.   71.   48. 2290.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.440 | Acc: 49.125% | Wgt Acc: 43.846%
I - num batch: 70
I - Val -- Loss: 1.432 | Acc: 51.346% | Wgt Acc: 45.161% | Dur: 33.53s
I - Confusion Matrix: [row->prediction - col->label]
[[ 95.   2.   3.  26.  12.]
 [  0.   3.   1.   1.   2.]
 [  7.  91.  97.  46. 101.]
 [ 55.  13.   8.  86.  25.]
 [ 42.  25.  37.  45. 291.]]

I - Epoch: 67
I - Training: 
	I - Batch: 50 | Loss: 0.644 | Acc: 77.500% | Wgt Acc: 72.116%
	I - Batch: 100 | Loss: 0.608 | Acc: 78.812% | Wgt Acc: 74.834%
	I - Batch: 150 | Loss: 0.594 | Acc: 80.000% | Wgt Acc: 76.382%
	I - Batch: 200 | Loss: 0.597 | Acc: 80.125% | Wgt Acc: 76.212%
	I - Batch: 250 | Loss: 0.618 | Acc: 79.125% | Wgt Acc: 75.044%
	I - Batch: 300 | Loss: 0.624 | Acc: 78.396% | Wgt Acc: 74.123%
I - num batch: 313
I - Train -- Loss: 0.626 | Acc: 78.320% | Wgt Acc: 74.069% | LR: 1.250000e-04 | Dur: 193.45s
I - Confusion Matrix: [row->prediction - col->label]
[[ 596.    0.    0.   20.  132.]
 [   0.    8.    3.    1.    2.]
 [   1.  307.  378.   21.  153.]
 [  22.    8.   21.  630.  175.]
 [  75.   11.   85.   47. 2304.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.522 | Acc: 49.375% | Wgt Acc: 43.993%
I - num batch: 70
I - Val -- Loss: 1.471 | Acc: 51.167% | Wgt Acc: 45.669% | Dur: 33.50s
I - Confusion Matrix: [row->prediction - col->label]
[[147.   5.   9.  76.  58.]
 [  0.   1.   1.   2.   3.]
 [  1.  58.  64.   7.  43.]
 [ 24.  29.  29.  86.  55.]
 [ 27.  41.  43.  33. 272.]]

I - Epoch: 68
I - Training: 
	I - Batch: 50 | Loss: 0.627 | Acc: 77.500% | Wgt Acc: 72.901%
	I - Batch: 100 | Loss: 0.595 | Acc: 78.750% | Wgt Acc: 75.453%
	I - Batch: 150 | Loss: 0.594 | Acc: 79.083% | Wgt Acc: 75.316%
	I - Batch: 200 | Loss: 0.592 | Acc: 79.156% | Wgt Acc: 75.128%
	I - Batch: 250 | Loss: 0.596 | Acc: 79.375% | Wgt Acc: 75.199%
	I - Batch: 300 | Loss: 0.592 | Acc: 79.750% | Wgt Acc: 75.570%
I - num batch: 313
I - Train -- Loss: 0.595 | Acc: 79.520% | Wgt Acc: 75.356% | LR: 1.250000e-04 | Dur: 193.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 607.    0.    0.   24.  143.]
 [   0.   13.    6.    5.    1.]
 [   3.  294.  385.   14.  154.]
 [  17.    8.   19.  638.  135.]
 [  67.   19.   77.   38. 2333.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.442 | Acc: 53.125% | Wgt Acc: 46.766%
I - num batch: 70
I - Val -- Loss: 1.412 | Acc: 54.847% | Wgt Acc: 48.230% | Dur: 33.51s
I - Confusion Matrix: [row->prediction - col->label]
[[136.   3.   3.  48.  31.]
 [  0.   2.   2.   0.   2.]
 [  3.  65.  71.  14.  53.]
 [ 28.  15.  16.  99.  42.]
 [ 32.  49.  54.  43. 303.]]

I - Epoch: 69
I - Training: 
	I - Batch: 50 | Loss: 0.609 | Acc: 80.875% | Wgt Acc: 76.385%
	I - Batch: 100 | Loss: 0.567 | Acc: 81.625% | Wgt Acc: 77.741%
	I - Batch: 150 | Loss: 0.571 | Acc: 80.542% | Wgt Acc: 76.659%
	I - Batch: 200 | Loss: 0.560 | Acc: 80.844% | Wgt Acc: 76.899%
	I - Batch: 250 | Loss: 0.576 | Acc: 79.600% | Wgt Acc: 75.392%
	I - Batch: 300 | Loss: 0.583 | Acc: 79.396% | Wgt Acc: 75.397%
I - num batch: 313
I - Train -- Loss: 0.582 | Acc: 79.440% | Wgt Acc: 75.458% | LR: 1.250000e-04 | Dur: 193.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 612.    0.    0.   17.  155.]
 [   0.    6.    6.    1.    2.]
 [   1.  305.  397.   16.  166.]
 [  19.   15.   16.  636.  122.]
 [  62.    8.   68.   49. 2321.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.580 | Acc: 50.000% | Wgt Acc: 41.513%
I - num batch: 70
I - Val -- Loss: 1.560 | Acc: 53.052% | Wgt Acc: 43.611% | Dur: 33.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   3.  31.  16.]
 [  0.   0.   2.   2.   2.]
 [  3.  63.  62.  21.  41.]
 [ 38.  18.  18.  95.  37.]
 [ 59.  52.  61.  55. 335.]]

I - Epoch: 70
I - Training: 
	I - Batch: 50 | Loss: 0.581 | Acc: 81.375% | Wgt Acc: 78.222%
	I - Batch: 100 | Loss: 0.537 | Acc: 82.125% | Wgt Acc: 78.866%
	I - Batch: 150 | Loss: 0.538 | Acc: 82.375% | Wgt Acc: 78.371%
	I - Batch: 200 | Loss: 0.549 | Acc: 81.562% | Wgt Acc: 77.945%
	I - Batch: 250 | Loss: 0.556 | Acc: 81.500% | Wgt Acc: 77.933%
	I - Batch: 300 | Loss: 0.563 | Acc: 81.167% | Wgt Acc: 77.334%
I - num batch: 313
I - Train -- Loss: 0.566 | Acc: 81.060% | Wgt Acc: 77.116% | LR: 1.250000e-04 | Dur: 193.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 625.    0.    0.   12.  122.]
 [   0.    7.    8.    1.    0.]
 [   1.  298.  405.   15.  163.]
 [  13.   13.   14.  654.  119.]
 [  55.   16.   60.   37. 2362.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.472 | Acc: 52.125% | Wgt Acc: 45.879%
I - num batch: 70
I - Val -- Loss: 1.428 | Acc: 55.027% | Wgt Acc: 48.346% | Dur: 33.61s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   1.   4.  26.  27.]
 [  1.   2.   1.   0.   1.]
 [  2.  67.  73.  13.  54.]
 [ 63.  23.  21. 132.  44.]
 [ 32.  41.  47.  33. 305.]]

I - Epoch: 71
I - Training: 
	I - Batch: 50 | Loss: 0.547 | Acc: 82.125% | Wgt Acc: 78.046%
	I - Batch: 100 | Loss: 0.546 | Acc: 82.688% | Wgt Acc: 78.305%
	I - Batch: 150 | Loss: 0.556 | Acc: 81.542% | Wgt Acc: 76.905%
	I - Batch: 200 | Loss: 0.545 | Acc: 81.969% | Wgt Acc: 77.700%
	I - Batch: 250 | Loss: 0.541 | Acc: 81.950% | Wgt Acc: 77.669%
	I - Batch: 300 | Loss: 0.542 | Acc: 81.979% | Wgt Acc: 77.833%
I - num batch: 313
I - Train -- Loss: 0.543 | Acc: 81.980% | Wgt Acc: 77.827% | LR: 1.250000e-04 | Dur: 193.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 626.    0.    0.   15.  103.]
 [   0.   12.    2.    2.    3.]
 [   1.  303.  406.   16.  156.]
 [  16.   11.   13.  656.  105.]
 [  51.    8.   66.   30. 2399.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.541 | Acc: 51.625% | Wgt Acc: 42.917%
I - num batch: 70
I - Val -- Loss: 1.491 | Acc: 54.399% | Wgt Acc: 45.304% | Dur: 33.50s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   3.   0.  36.  25.]
 [  0.   0.   0.   2.   1.]
 [  3.  66.  68.  13.  37.]
 [ 45.  12.  17. 101.  32.]
 [ 50.  53.  61.  52. 336.]]

I - Epoch: 72
I - Training: 
	I - Batch: 50 | Loss: 0.494 | Acc: 82.750% | Wgt Acc: 78.674%
	I - Batch: 100 | Loss: 0.488 | Acc: 83.438% | Wgt Acc: 79.478%
	I - Batch: 150 | Loss: 0.520 | Acc: 82.000% | Wgt Acc: 78.046%
	I - Batch: 200 | Loss: 0.528 | Acc: 82.188% | Wgt Acc: 78.052%
	I - Batch: 250 | Loss: 0.523 | Acc: 82.450% | Wgt Acc: 78.491%
	I - Batch: 300 | Loss: 0.519 | Acc: 82.438% | Wgt Acc: 78.357%
I - num batch: 313
I - Train -- Loss: 0.521 | Acc: 82.320% | Wgt Acc: 78.262% | LR: 1.250000e-04 | Dur: 193.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 638.    0.    0.   12.  129.]
 [   0.   24.   19.    7.    4.]
 [   1.  291.  402.   19.  123.]
 [  10.    8.   14.  646.  104.]
 [  45.   11.   52.   35. 2406.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.517 | Acc: 50.125% | Wgt Acc: 43.462%
I - num batch: 70
I - Val -- Loss: 1.514 | Acc: 51.346% | Wgt Acc: 44.288% | Dur: 33.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 86.   0.   1.  22.  14.]
 [  0.   1.   4.   3.   2.]
 [  6.  80.  80.  33.  77.]
 [ 58.  17.  16. 106.  39.]
 [ 49.  36.  45.  40. 299.]]

I - Epoch: 73
I - Training: 
	I - Batch: 50 | Loss: 0.523 | Acc: 83.625% | Wgt Acc: 79.085%
	I - Batch: 100 | Loss: 0.522 | Acc: 82.938% | Wgt Acc: 78.832%
	I - Batch: 150 | Loss: 0.532 | Acc: 82.708% | Wgt Acc: 78.000%
	I - Batch: 200 | Loss: 0.528 | Acc: 82.438% | Wgt Acc: 77.870%
	I - Batch: 250 | Loss: 0.521 | Acc: 82.500% | Wgt Acc: 78.130%
	I - Batch: 300 | Loss: 0.513 | Acc: 82.875% | Wgt Acc: 78.594%
I - num batch: 313
I - Train -- Loss: 0.513 | Acc: 83.020% | Wgt Acc: 78.678% | LR: 1.250000e-04 | Dur: 193.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 637.    0.    0.   14.   98.]
 [   0.    9.    6.    5.    5.]
 [   0.  306.  412.    7.  125.]
 [  13.    9.   14.  657.  102.]
 [  44.   10.   55.   36. 2436.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.504 | Acc: 50.875% | Wgt Acc: 45.837%
I - num batch: 70
I - Val -- Loss: 1.481 | Acc: 52.244% | Wgt Acc: 46.997% | Dur: 33.11s
I - Confusion Matrix: [row->prediction - col->label]
[[107.   0.   3.  35.  31.]
 [  0.   3.   1.   1.   3.]
 [  2.  57.  69.  10.  50.]
 [ 62.  27.  27. 129.  73.]
 [ 28.  47.  46.  29. 274.]]

I - Epoch: 74
I - Training: 
	I - Batch: 50 | Loss: 0.480 | Acc: 83.250% | Wgt Acc: 78.549%
	I - Batch: 100 | Loss: 0.498 | Acc: 83.125% | Wgt Acc: 78.205%
	I - Batch: 150 | Loss: 0.493 | Acc: 83.458% | Wgt Acc: 78.761%
	I - Batch: 200 | Loss: 0.490 | Acc: 83.875% | Wgt Acc: 79.218%
	I - Batch: 250 | Loss: 0.491 | Acc: 84.100% | Wgt Acc: 79.547%
	I - Batch: 300 | Loss: 0.491 | Acc: 84.000% | Wgt Acc: 79.498%
I - num batch: 313
I - Train -- Loss: 0.494 | Acc: 83.720% | Wgt Acc: 79.124% | LR: 1.250000e-04 | Dur: 191.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 636.    0.    0.   12.   79.]
 [   0.   18.   16.    2.    4.]
 [   0.  297.  398.   11.  121.]
 [  13.    8.   12.  666.   94.]
 [  45.   11.   61.   28. 2468.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.459 | Acc: 51.375% | Wgt Acc: 45.662%
I - num batch: 70
I - Val -- Loss: 1.462 | Acc: 52.873% | Wgt Acc: 46.648% | Dur: 33.11s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   1.   4.  33.  28.]
 [  0.   1.   3.   3.   0.]
 [  6.  71.  75.  22.  62.]
 [ 57.  17.  21. 113.  50.]
 [ 27.  44.  43.  33. 291.]]

I - Epoch: 75
I - Training: 
	I - Batch: 50 | Loss: 0.447 | Acc: 84.500% | Wgt Acc: 80.869%
	I - Batch: 100 | Loss: 0.462 | Acc: 84.188% | Wgt Acc: 80.295%
	I - Batch: 150 | Loss: 0.462 | Acc: 84.208% | Wgt Acc: 80.445%
	I - Batch: 200 | Loss: 0.464 | Acc: 84.500% | Wgt Acc: 80.716%
	I - Batch: 250 | Loss: 0.466 | Acc: 84.250% | Wgt Acc: 80.578%
	I - Batch: 300 | Loss: 0.476 | Acc: 83.958% | Wgt Acc: 80.141%
I - num batch: 313
I - Train -- Loss: 0.479 | Acc: 83.880% | Wgt Acc: 80.022% | LR: 1.250000e-04 | Dur: 191.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 650.    0.    0.    9.   91.]
 [   0.   27.   13.    3.    6.]
 [   1.  292.  413.    8.  150.]
 [  10.    7.   10.  666.   81.]
 [  33.    8.   51.   33. 2438.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.705 | Acc: 48.500% | Wgt Acc: 39.403%
I - num batch: 70
I - Val -- Loss: 1.722 | Acc: 50.987% | Wgt Acc: 40.632% | Dur: 33.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 74.   1.   1.  21.  10.]
 [  1.   0.   0.   1.   0.]
 [  5.  75.  70.  31.  59.]
 [ 45.   9.  11.  81.  19.]
 [ 74.  49.  64.  70. 343.]]

I - Epoch: 76
I - Training: 
	I - Batch: 50 | Loss: 0.498 | Acc: 83.375% | Wgt Acc: 80.031%
	I - Batch: 100 | Loss: 0.465 | Acc: 84.812% | Wgt Acc: 81.018%
	I - Batch: 150 | Loss: 0.461 | Acc: 85.125% | Wgt Acc: 81.241%
	I - Batch: 200 | Loss: 0.463 | Acc: 85.000% | Wgt Acc: 81.202%
	I - Batch: 250 | Loss: 0.468 | Acc: 84.825% | Wgt Acc: 81.040%
	I - Batch: 300 | Loss: 0.480 | Acc: 84.271% | Wgt Acc: 80.389%
I - num batch: 313
I - Train -- Loss: 0.481 | Acc: 84.080% | Wgt Acc: 80.239% | LR: 1.250000e-04 | Dur: 191.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 642.    0.    0.   11.  100.]
 [   0.   61.   36.    5.   16.]
 [   0.  255.  382.    6.  111.]
 [  11.    8.   11.  671.   91.]
 [  41.   10.   58.   26. 2448.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.518 | Acc: 51.250% | Wgt Acc: 44.964%
I - num batch: 70
I - Val -- Loss: 1.497 | Acc: 53.232% | Wgt Acc: 46.563% | Dur: 33.02s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   2.   2.  34.  23.]
 [  0.   5.   4.   2.   1.]
 [  2.  69.  74.  14.  58.]
 [ 41.  21.  25. 110.  49.]
 [ 52.  37.  41.  44. 300.]]

I - Epoch: 77
I - Training: 
	I - Batch: 50 | Loss: 0.435 | Acc: 85.000% | Wgt Acc: 79.119%
	I - Batch: 100 | Loss: 0.452 | Acc: 85.250% | Wgt Acc: 80.757%
	I - Batch: 150 | Loss: 0.475 | Acc: 84.375% | Wgt Acc: 79.971%
	I - Batch: 200 | Loss: 0.468 | Acc: 84.625% | Wgt Acc: 80.275%
	I - Batch: 250 | Loss: 0.461 | Acc: 85.025% | Wgt Acc: 80.802%
	I - Batch: 300 | Loss: 0.462 | Acc: 85.042% | Wgt Acc: 80.982%
I - num batch: 313
I - Train -- Loss: 0.467 | Acc: 84.800% | Wgt Acc: 80.685% | LR: 1.250000e-04 | Dur: 191.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 636.    0.    0.   14.   90.]
 [   0.   51.   30.    4.   10.]
 [   1.  270.  397.    8.  108.]
 [  16.    7.   13.  675.   77.]
 [  41.    6.   47.   18. 2481.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.561 | Acc: 51.000% | Wgt Acc: 44.775%
I - num batch: 70
I - Val -- Loss: 1.541 | Acc: 53.591% | Wgt Acc: 46.569% | Dur: 33.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   1.   2.  24.  23.]
 [  1.   6.   7.   3.   5.]
 [  3.  68.  75.  10.  63.]
 [ 48.  12.  20. 112.  33.]
 [ 50.  47.  42.  55. 307.]]

I - Epoch: 78
I - Training: 
	I - Batch: 50 | Loss: 0.492 | Acc: 82.625% | Wgt Acc: 79.463%
	I - Batch: 100 | Loss: 0.493 | Acc: 83.250% | Wgt Acc: 79.440%
	I - Batch: 150 | Loss: 0.487 | Acc: 83.625% | Wgt Acc: 79.777%
	I - Batch: 200 | Loss: 0.480 | Acc: 84.156% | Wgt Acc: 80.150%
	I - Batch: 250 | Loss: 0.475 | Acc: 84.250% | Wgt Acc: 80.196%
	I - Batch: 300 | Loss: 0.473 | Acc: 84.208% | Wgt Acc: 80.192%
I - num batch: 313
I - Train -- Loss: 0.471 | Acc: 84.300% | Wgt Acc: 80.289% | LR: 1.250000e-04 | Dur: 191.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 636.    0.    0.   12.  111.]
 [   0.   44.   25.    4.    7.]
 [   2.  276.  406.   10.  104.]
 [  16.    7.    8.  667.   82.]
 [  40.    7.   48.   26. 2462.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.864 | Acc: 49.000% | Wgt Acc: 38.984%
I - num batch: 70
I - Val -- Loss: 1.829 | Acc: 51.257% | Wgt Acc: 39.902% | Dur: 33.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 93.   2.   2.  34.  21.]
 [  0.   4.   7.   4.   0.]
 [  3.  48.  44.   9.  31.]
 [ 29.  12.  14.  76.  25.]
 [ 74.  68.  79.  81. 354.]]

I - Epoch: 79
I - Training: 
	I - Batch: 50 | Loss: 0.395 | Acc: 86.250% | Wgt Acc: 82.133%
	I - Batch: 100 | Loss: 0.399 | Acc: 87.375% | Wgt Acc: 83.844%
	I - Batch: 150 | Loss: 0.429 | Acc: 86.667% | Wgt Acc: 82.927%
	I - Batch: 200 | Loss: 0.448 | Acc: 85.562% | Wgt Acc: 81.948%
	I - Batch: 250 | Loss: 0.451 | Acc: 85.525% | Wgt Acc: 81.912%
	I - Batch: 300 | Loss: 0.456 | Acc: 85.375% | Wgt Acc: 81.694%
I - num batch: 313
I - Train -- Loss: 0.458 | Acc: 85.380% | Wgt Acc: 81.759% | LR: 1.250000e-04 | Dur: 192.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 646.    0.    0.   11.   94.]
 [   0.   77.   35.    8.   10.]
 [   1.  242.  396.    9.  115.]
 [  10.    6.    8.  672.   69.]
 [  37.    9.   48.   19. 2478.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.718 | Acc: 49.875% | Wgt Acc: 41.164%
I - num batch: 70
I - Val -- Loss: 1.690 | Acc: 53.142% | Wgt Acc: 43.516% | Dur: 33.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   1.   2.  29.  16.]
 [  1.   8.   4.   3.   8.]
 [  4.  59.  66.  20.  42.]
 [ 31.  13.  14.  80.  23.]
 [ 67.  53.  60.  72. 342.]]

I - Epoch: 80
I - Training: 
	I - Batch: 50 | Loss: 0.472 | Acc: 84.875% | Wgt Acc: 81.221%
	I - Batch: 100 | Loss: 0.469 | Acc: 84.625% | Wgt Acc: 81.007%
	I - Batch: 150 | Loss: 0.464 | Acc: 84.625% | Wgt Acc: 81.043%
	I - Batch: 200 | Loss: 0.449 | Acc: 85.625% | Wgt Acc: 82.206%
	I - Batch: 250 | Loss: 0.441 | Acc: 85.875% | Wgt Acc: 82.390%
	I - Batch: 300 | Loss: 0.447 | Acc: 85.792% | Wgt Acc: 82.330%
I - num batch: 313
I - Train -- Loss: 0.449 | Acc: 85.860% | Wgt Acc: 82.395% | LR: 1.250000e-04 | Dur: 192.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 653.    0.    0.    7.   84.]
 [   1.  114.   68.    6.   13.]
 [   0.  201.  367.    7.  101.]
 [  10.   11.    7.  670.   79.]
 [  30.    8.   45.   29. 2489.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.767 | Acc: 52.375% | Wgt Acc: 43.155%
I - num batch: 70
I - Val -- Loss: 1.743 | Acc: 54.847% | Wgt Acc: 44.574% | Dur: 33.89s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   2.  41.  21.]
 [  0.   9.  10.   2.   8.]
 [  4.  51.  50.   9.  28.]
 [ 19.   6.  17.  77.  20.]
 [ 55.  66.  67.  75. 354.]]

I - Epoch: 81
I - Training: 
	I - Batch: 50 | Loss: 0.401 | Acc: 88.625% | Wgt Acc: 85.745%
	I - Batch: 100 | Loss: 0.432 | Acc: 86.500% | Wgt Acc: 82.970%
	I - Batch: 150 | Loss: 0.433 | Acc: 86.833% | Wgt Acc: 83.014%
	I - Batch: 200 | Loss: 0.430 | Acc: 86.875% | Wgt Acc: 83.297%
	I - Batch: 250 | Loss: 0.435 | Acc: 86.500% | Wgt Acc: 83.084%
	I - Batch: 300 | Loss: 0.433 | Acc: 86.458% | Wgt Acc: 82.903%
I - num batch: 313
I - Train -- Loss: 0.434 | Acc: 86.420% | Wgt Acc: 82.854% | LR: 1.250000e-04 | Dur: 192.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 651.    0.    0.   11.   64.]
 [   0.  147.   92.    8.   15.]
 [   0.  178.  339.    6.   93.]
 [   5.    7.   13.  669.   79.]
 [  38.    2.   43.   25. 2515.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.692 | Acc: 53.250% | Wgt Acc: 44.992%
I - num batch: 70
I - Val -- Loss: 1.643 | Acc: 55.566% | Wgt Acc: 46.685% | Dur: 33.21s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   2.  44.  25.]
 [  0.  19.  15.   3.   6.]
 [  2.  37.  54.   9.  30.]
 [ 29.  13.  17.  84.  29.]
 [ 47.  63.  58.  64. 341.]]

I - Epoch: 82
I - Training: 
	I - Batch: 50 | Loss: 0.359 | Acc: 90.500% | Wgt Acc: 88.885%
	I - Batch: 100 | Loss: 0.371 | Acc: 90.062% | Wgt Acc: 87.928%
	I - Batch: 150 | Loss: 0.366 | Acc: 89.792% | Wgt Acc: 87.205%
	I - Batch: 200 | Loss: 0.377 | Acc: 89.031% | Wgt Acc: 86.286%
	I - Batch: 250 | Loss: 0.388 | Acc: 88.675% | Wgt Acc: 85.812%
	I - Batch: 300 | Loss: 0.393 | Acc: 88.562% | Wgt Acc: 85.575%
I - num batch: 313
I - Train -- Loss: 0.395 | Acc: 88.480% | Wgt Acc: 85.439% | LR: 1.250000e-04 | Dur: 192.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 659.    0.    0.    7.   57.]
 [   0.  170.   83.    4.   13.]
 [   0.  157.  362.    4.   78.]
 [   6.    0.    5.  681.   66.]
 [  29.    7.   37.   23. 2552.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.677 | Acc: 50.500% | Wgt Acc: 44.600%
I - num batch: 70
I - Val -- Loss: 1.655 | Acc: 50.987% | Wgt Acc: 44.595% | Dur: 33.14s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   3.   2.  34.  29.]
 [  0.  25.  21.  14.  22.]
 [  4.  47.  57.  16.  60.]
 [ 43.  11.  16.  89.  28.]
 [ 47.  48.  50.  51. 292.]]

I - Epoch: 83
I - Training: 
	I - Batch: 50 | Loss: 0.386 | Acc: 88.500% | Wgt Acc: 86.228%
	I - Batch: 100 | Loss: 0.410 | Acc: 87.562% | Wgt Acc: 84.670%
	I - Batch: 150 | Loss: 0.401 | Acc: 87.667% | Wgt Acc: 84.518%
	I - Batch: 200 | Loss: 0.396 | Acc: 88.094% | Wgt Acc: 84.741%
	I - Batch: 250 | Loss: 0.398 | Acc: 88.025% | Wgt Acc: 84.784%
	I - Batch: 300 | Loss: 0.407 | Acc: 87.750% | Wgt Acc: 84.409%
I - num batch: 313
I - Train -- Loss: 0.405 | Acc: 87.860% | Wgt Acc: 84.597% | LR: 1.250000e-04 | Dur: 192.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 657.    0.    0.   12.   67.]
 [   0.  168.   91.    2.   18.]
 [   0.  157.  345.    6.   77.]
 [   7.    5.    7.  679.   60.]
 [  30.    4.   44.   20. 2544.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.781 | Acc: 51.500% | Wgt Acc: 43.099%
I - num batch: 70
I - Val -- Loss: 1.699 | Acc: 54.578% | Wgt Acc: 45.669% | Dur: 33.44s
I - Confusion Matrix: [row->prediction - col->label]
[[127.   5.   2.  46.  34.]
 [  0.  13.  11.   2.   3.]
 [  1.  34.  38.   4.  19.]
 [ 30.  24.  28.  98.  43.]
 [ 41.  58.  67.  54. 332.]]

I - Epoch: 84
I - Training: 
	I - Batch: 50 | Loss: 0.399 | Acc: 87.250% | Wgt Acc: 84.358%
	I - Batch: 100 | Loss: 0.384 | Acc: 88.500% | Wgt Acc: 85.629%
	I - Batch: 150 | Loss: 0.375 | Acc: 88.792% | Wgt Acc: 86.081%
	I - Batch: 200 | Loss: 0.386 | Acc: 88.469% | Wgt Acc: 85.682%
	I - Batch: 250 | Loss: 0.387 | Acc: 88.550% | Wgt Acc: 85.767%
	I - Batch: 300 | Loss: 0.393 | Acc: 88.083% | Wgt Acc: 85.340%
I - num batch: 313
I - Train -- Loss: 0.393 | Acc: 88.100% | Wgt Acc: 85.417% | LR: 1.250000e-04 | Dur: 194.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 664.    0.    0.    8.   69.]
 [   0.  183.   85.    4.   15.]
 [   0.  142.  351.    2.   97.]
 [   7.    5.    6.  682.   60.]
 [  23.    4.   45.   23. 2525.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.587 | Acc: 53.500% | Wgt Acc: 49.043%
I - num batch: 70
I - Val -- Loss: 1.571 | Acc: 54.309% | Wgt Acc: 49.246% | Dur: 33.48s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   0.  42.  26.]
 [  0.  41.  35.   9.  22.]
 [  2.  33.  47.   8.  40.]
 [ 45.  21.  22. 109.  55.]
 [ 32.  37.  42.  36. 288.]]

I - Epoch: 85
I - Training: 
	I - Batch: 50 | Loss: 0.334 | Acc: 90.375% | Wgt Acc: 87.604%
	I - Batch: 100 | Loss: 0.368 | Acc: 89.125% | Wgt Acc: 86.445%
	I - Batch: 150 | Loss: 0.382 | Acc: 88.333% | Wgt Acc: 85.434%
	I - Batch: 200 | Loss: 0.406 | Acc: 87.781% | Wgt Acc: 84.946%
	I - Batch: 250 | Loss: 0.408 | Acc: 87.525% | Wgt Acc: 84.752%
	I - Batch: 300 | Loss: 0.405 | Acc: 87.625% | Wgt Acc: 84.942%
I - num batch: 313
I - Train -- Loss: 0.402 | Acc: 87.800% | Wgt Acc: 85.183% | LR: 1.250000e-04 | Dur: 193.43s
I - Confusion Matrix: [row->prediction - col->label]
[[ 649.    0.    1.   15.   69.]
 [   0.  202.   93.    6.   22.]
 [   0.  123.  342.    1.  105.]
 [  16.    4.    8.  678.   51.]
 [  29.    5.   43.   19. 2519.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.720 | Acc: 53.375% | Wgt Acc: 46.235%
I - num batch: 70
I - Val -- Loss: 1.660 | Acc: 55.296% | Wgt Acc: 47.251% | Dur: 33.54s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   3.   3.  54.  30.]
 [  0.  28.  22.   3.   7.]
 [  2.  39.  48.  11.  45.]
 [ 27.  11.  16.  84.  19.]
 [ 44.  53.  57.  52. 330.]]

I - Epoch: 86
I - Training: 
	I - Batch: 50 | Loss: 0.378 | Acc: 89.875% | Wgt Acc: 86.859%
	I - Batch: 100 | Loss: 0.383 | Acc: 89.750% | Wgt Acc: 86.489%
	I - Batch: 150 | Loss: 0.369 | Acc: 89.792% | Wgt Acc: 86.736%
	I - Batch: 200 | Loss: 0.363 | Acc: 90.000% | Wgt Acc: 87.179%
	I - Batch: 250 | Loss: 0.364 | Acc: 90.000% | Wgt Acc: 87.359%
	I - Batch: 300 | Loss: 0.366 | Acc: 89.562% | Wgt Acc: 86.818%
I - num batch: 313
I - Train -- Loss: 0.366 | Acc: 89.480% | Wgt Acc: 86.739% | LR: 1.250000e-04 | Dur: 193.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    0.    0.    5.   62.]
 [   0.  215.  104.    5.   19.]
 [   1.  110.  332.    2.   68.]
 [   4.    4.    7.  689.   46.]
 [  22.    5.   44.   18. 2571.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.628 | Acc: 50.000% | Wgt Acc: 45.020%
I - num batch: 70
I - Val -- Loss: 1.616 | Acc: 52.334% | Wgt Acc: 46.214% | Dur: 33.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   3.   1.  37.  20.]
 [  1.  32.  25.   4.  17.]
 [  3.  46.  64.  14.  63.]
 [ 45.  14.  20.  96.  34.]
 [ 56.  39.  36.  53. 297.]]

I - Epoch: 87
I - Training: 
	I - Batch: 50 | Loss: 0.367 | Acc: 89.875% | Wgt Acc: 87.621%
	I - Batch: 100 | Loss: 0.358 | Acc: 90.062% | Wgt Acc: 88.286%
	I - Batch: 150 | Loss: 0.354 | Acc: 90.750% | Wgt Acc: 88.973%
	I - Batch: 200 | Loss: 0.362 | Acc: 90.344% | Wgt Acc: 88.138%
	I - Batch: 250 | Loss: 0.357 | Acc: 90.475% | Wgt Acc: 88.214%
	I - Batch: 300 | Loss: 0.361 | Acc: 90.229% | Wgt Acc: 88.036%
I - num batch: 313
I - Train -- Loss: 0.361 | Acc: 90.260% | Wgt Acc: 88.086% | LR: 1.250000e-04 | Dur: 194.06s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    1.    0.    7.   56.]
 [   0.  228.   88.    3.   18.]
 [   1.   99.  357.    5.   74.]
 [   4.    3.    4.  691.   48.]
 [  22.    3.   38.   13. 2570.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.653 | Acc: 50.250% | Wgt Acc: 44.621%
I - num batch: 70
I - Val -- Loss: 1.624 | Acc: 52.603% | Wgt Acc: 45.770% | Dur: 33.56s
I - Confusion Matrix: [row->prediction - col->label]
[[ 84.   2.   2.  34.  15.]
 [  2.  40.  35.  11.  19.]
 [  5.  47.  58.  20.  63.]
 [ 43.   9.  10.  94.  24.]
 [ 65.  36.  41.  45. 310.]]

I - Epoch: 88
I - Training: 
	I - Batch: 50 | Loss: 0.363 | Acc: 90.875% | Wgt Acc: 88.384%
	I - Batch: 100 | Loss: 0.368 | Acc: 91.125% | Wgt Acc: 88.440%
	I - Batch: 150 | Loss: 0.353 | Acc: 90.792% | Wgt Acc: 87.999%
	I - Batch: 200 | Loss: 0.352 | Acc: 90.781% | Wgt Acc: 88.314%
	I - Batch: 250 | Loss: 0.351 | Acc: 90.500% | Wgt Acc: 88.137%
	I - Batch: 300 | Loss: 0.353 | Acc: 90.333% | Wgt Acc: 88.105%
I - num batch: 313
I - Train -- Loss: 0.355 | Acc: 90.240% | Wgt Acc: 87.965% | LR: 1.250000e-04 | Dur: 194.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 661.    0.    0.    6.   60.]
 [   0.  233.   99.    3.   16.]
 [   0.   93.  344.    5.   74.]
 [   7.    3.    9.  700.   42.]
 [  26.    5.   35.    5. 2574.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.907 | Acc: 52.625% | Wgt Acc: 43.252%
I - num batch: 70
I - Val -- Loss: 1.854 | Acc: 55.027% | Wgt Acc: 44.785% | Dur: 33.72s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.   3.  45.  31.]
 [  0.  17.  12.   3.   3.]
 [  0.  30.  36.   4.  22.]
 [ 19.  15.  14.  77.  21.]
 [ 51.  69.  81.  75. 354.]]

I - Epoch: 89
I - Training: 
	I - Batch: 50 | Loss: 0.367 | Acc: 90.000% | Wgt Acc: 87.906%
	I - Batch: 100 | Loss: 0.370 | Acc: 89.500% | Wgt Acc: 86.896%
	I - Batch: 150 | Loss: 0.358 | Acc: 89.917% | Wgt Acc: 87.535%
	I - Batch: 200 | Loss: 0.352 | Acc: 89.906% | Wgt Acc: 87.510%
	I - Batch: 250 | Loss: 0.360 | Acc: 89.600% | Wgt Acc: 87.397%
	I - Batch: 300 | Loss: 0.362 | Acc: 89.625% | Wgt Acc: 87.370%
I - num batch: 313
I - Train -- Loss: 0.362 | Acc: 89.640% | Wgt Acc: 87.362% | LR: 1.250000e-04 | Dur: 194.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 660.    0.    0.    8.   62.]
 [   1.  217.   79.    6.   12.]
 [   0.  106.  362.    3.   90.]
 [   5.    8.    9.  686.   45.]
 [  28.    3.   37.   16. 2557.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.771 | Acc: 52.250% | Wgt Acc: 43.727%
I - num batch: 70
I - Val -- Loss: 1.699 | Acc: 54.847% | Wgt Acc: 45.659% | Dur: 33.65s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   3.   1.  45.  22.]
 [  0.  25.  19.   2.  11.]
 [  0.  42.  44.   3.  29.]
 [ 27.  13.  22.  83.  26.]
 [ 56.  51.  60.  71. 343.]]

I - Epoch: 90
I - Training: 
	I - Batch: 50 | Loss: 0.343 | Acc: 91.500% | Wgt Acc: 88.690%
	I - Batch: 100 | Loss: 0.341 | Acc: 91.438% | Wgt Acc: 89.186%
	I - Batch: 150 | Loss: 0.325 | Acc: 91.625% | Wgt Acc: 89.478%
	I - Batch: 200 | Loss: 0.328 | Acc: 91.625% | Wgt Acc: 89.438%
	I - Batch: 250 | Loss: 0.341 | Acc: 91.050% | Wgt Acc: 88.643%
	I - Batch: 300 | Loss: 0.340 | Acc: 90.729% | Wgt Acc: 88.372%
I - num batch: 313
I - Train -- Loss: 0.335 | Acc: 90.880% | Wgt Acc: 88.612% | LR: 1.250000e-04 | Dur: 194.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 667.    0.    0.    9.   56.]
 [   0.  243.   98.    5.   12.]
 [   0.   84.  350.    2.   66.]
 [   6.    5.    5.  689.   37.]
 [  21.    2.   34.   14. 2595.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.941 | Acc: 50.250% | Wgt Acc: 40.710%
I - num batch: 70
I - Val -- Loss: 1.877 | Acc: 52.693% | Wgt Acc: 42.383% | Dur: 33.73s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   2.   4.  37.  21.]
 [  0.  15.  10.   3.   4.]
 [  0.  35.  31.   5.  28.]
 [ 39.  14.  21.  90.  33.]
 [ 54.  68.  80.  69. 345.]]

I - Epoch: 91
I - Training: 
	I - Batch: 50 | Loss: 0.320 | Acc: 91.875% | Wgt Acc: 90.059%
	I - Batch: 100 | Loss: 0.309 | Acc: 92.125% | Wgt Acc: 90.042%
	I - Batch: 150 | Loss: 0.299 | Acc: 92.458% | Wgt Acc: 90.392%
	I - Batch: 200 | Loss: 0.302 | Acc: 92.312% | Wgt Acc: 90.352%
	I - Batch: 250 | Loss: 0.302 | Acc: 92.325% | Wgt Acc: 90.412%
	I - Batch: 300 | Loss: 0.303 | Acc: 92.333% | Wgt Acc: 90.518%
I - num batch: 313
I - Train -- Loss: 0.301 | Acc: 92.320% | Wgt Acc: 90.560% | LR: 1.250000e-04 | Dur: 193.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 670.    0.    0.    6.   42.]
 [   0.  260.   81.    7.   17.]
 [   0.   72.  373.    1.   56.]
 [   3.    0.    1.  698.   36.]
 [  21.    2.   32.    7. 2615.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.899 | Acc: 52.375% | Wgt Acc: 42.680%
I - num batch: 70
I - Val -- Loss: 1.828 | Acc: 55.386% | Wgt Acc: 44.891% | Dur: 33.65s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   3.   5.  43.  22.]
 [  1.  10.  11.   0.   3.]
 [  1.  39.  48.   6.  19.]
 [ 34.  18.  18.  91.  28.]
 [ 54.  64.  64.  64. 359.]]

I - Epoch: 92
I - Training: 
	I - Batch: 50 | Loss: 0.305 | Acc: 92.500% | Wgt Acc: 90.145%
	I - Batch: 100 | Loss: 0.292 | Acc: 92.562% | Wgt Acc: 90.988%
	I - Batch: 150 | Loss: 0.288 | Acc: 93.000% | Wgt Acc: 91.564%
	I - Batch: 200 | Loss: 0.289 | Acc: 92.719% | Wgt Acc: 91.291%
	I - Batch: 250 | Loss: 0.303 | Acc: 92.250% | Wgt Acc: 90.633%
	I - Batch: 300 | Loss: 0.307 | Acc: 91.875% | Wgt Acc: 90.324%
I - num batch: 313
I - Train -- Loss: 0.308 | Acc: 91.940% | Wgt Acc: 90.334% | LR: 1.250000e-04 | Dur: 194.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 669.    0.    0.    6.   41.]
 [   0.  263.   73.    8.   12.]
 [   0.   63.  373.    0.   72.]
 [   6.    5.    6.  694.   43.]
 [  19.    3.   35.   11. 2598.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.882 | Acc: 50.750% | Wgt Acc: 41.345%
I - num batch: 70
I - Val -- Loss: 1.859 | Acc: 52.783% | Wgt Acc: 42.346% | Dur: 33.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 89.   1.   1.  32.  15.]
 [  1.  16.  13.   4.   6.]
 [  2.  52.  59.  13.  39.]
 [ 34.   7.  13.  70.  17.]
 [ 73.  58.  60.  85. 354.]]

I - Epoch: 93
I - Training: 
	I - Batch: 50 | Loss: 0.318 | Acc: 90.875% | Wgt Acc: 88.607%
	I - Batch: 100 | Loss: 0.309 | Acc: 91.375% | Wgt Acc: 89.495%
	I - Batch: 150 | Loss: 0.304 | Acc: 91.542% | Wgt Acc: 89.558%
	I - Batch: 200 | Loss: 0.312 | Acc: 91.281% | Wgt Acc: 89.119%
	I - Batch: 250 | Loss: 0.327 | Acc: 90.425% | Wgt Acc: 88.282%
	I - Batch: 300 | Loss: 0.342 | Acc: 90.083% | Wgt Acc: 87.934%
I - num batch: 313
I - Train -- Loss: 0.345 | Acc: 89.840% | Wgt Acc: 87.883% | LR: 1.250000e-04 | Dur: 194.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 658.    0.    0.    9.   67.]
 [   0.  241.   80.   11.   13.]
 [   0.   82.  360.    3.   93.]
 [  11.    8.    8.  680.   40.]
 [  25.    3.   39.   16. 2553.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.855 | Acc: 53.500% | Wgt Acc: 45.013%
I - num batch: 70
I - Val -- Loss: 1.812 | Acc: 55.925% | Wgt Acc: 46.600% | Dur: 33.65s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   2.   4.  46.  26.]
 [  0.  12.   7.   4.   3.]
 [  1.  45.  54.  15.  35.]
 [ 32.  10.  13.  83.  21.]
 [ 38.  65.  68.  56. 346.]]

I - Epoch: 94
I - Training: 
	I - Batch: 50 | Loss: 0.319 | Acc: 91.125% | Wgt Acc: 89.016%
	I - Batch: 100 | Loss: 0.291 | Acc: 92.562% | Wgt Acc: 90.712%
	I - Batch: 150 | Loss: 0.294 | Acc: 92.625% | Wgt Acc: 90.732%
	I - Batch: 200 | Loss: 0.294 | Acc: 92.938% | Wgt Acc: 91.047%
	I - Batch: 250 | Loss: 0.302 | Acc: 92.475% | Wgt Acc: 90.574%
	I - Batch: 300 | Loss: 0.303 | Acc: 92.229% | Wgt Acc: 90.387%
I - num batch: 313
I - Train -- Loss: 0.305 | Acc: 92.160% | Wgt Acc: 90.412% | LR: 1.250000e-04 | Dur: 194.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 674.    0.    0.    7.   40.]
 [   0.  266.   83.    3.   10.]
 [   0.   63.  366.    2.   67.]
 [   3.    3.    5.  691.   38.]
 [  17.    2.   33.   16. 2611.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.853 | Acc: 51.375% | Wgt Acc: 44.153%
I - num batch: 70
I - Val -- Loss: 1.789 | Acc: 53.770% | Wgt Acc: 46.008% | Dur: 33.63s
I - Confusion Matrix: [row->prediction - col->label]
[[128.   4.   4.  54.  40.]
 [  0.  12.  15.   3.   4.]
 [  0.  53.  59.  10.  45.]
 [ 37.  14.  15.  83.  25.]
 [ 34.  51.  53.  54. 317.]]

I - Epoch: 95
I - Training: 
	I - Batch: 50 | Loss: 0.276 | Acc: 93.375% | Wgt Acc: 92.364%
	I - Batch: 100 | Loss: 0.253 | Acc: 94.438% | Wgt Acc: 93.242%
	I - Batch: 150 | Loss: 0.245 | Acc: 95.083% | Wgt Acc: 93.959%
	I - Batch: 200 | Loss: 0.250 | Acc: 94.656% | Wgt Acc: 93.491%
	I - Batch: 250 | Loss: 0.254 | Acc: 94.225% | Wgt Acc: 93.026%
	I - Batch: 300 | Loss: 0.264 | Acc: 93.771% | Wgt Acc: 92.554%
I - num batch: 313
I - Train -- Loss: 0.267 | Acc: 93.560% | Wgt Acc: 92.296% | LR: 1.250000e-04 | Dur: 194.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    5.   42.]
 [   0.  277.   68.    0.    8.]
 [   0.   51.  389.    2.   53.]
 [   4.    3.    2.  701.   34.]
 [   8.    3.   28.   11. 2629.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.831 | Acc: 51.250% | Wgt Acc: 44.831%
I - num batch: 70
I - Val -- Loss: 1.801 | Acc: 53.142% | Wgt Acc: 46.315% | Dur: 33.58s
I - Confusion Matrix: [row->prediction - col->label]
[[116.   2.   2.  47.  18.]
 [  0.  24.  17.   4.  14.]
 [  3.  57.  77.  17.  67.]
 [ 21.   8.   9.  65.  22.]
 [ 59.  43.  41.  71. 310.]]

I - Epoch: 96
I - Training: 
	I - Batch: 50 | Loss: 0.255 | Acc: 92.875% | Wgt Acc: 92.171%
	I - Batch: 100 | Loss: 0.270 | Acc: 93.000% | Wgt Acc: 92.205%
	I - Batch: 150 | Loss: 0.277 | Acc: 92.458% | Wgt Acc: 91.547%
	I - Batch: 200 | Loss: 0.291 | Acc: 92.000% | Wgt Acc: 90.746%
	I - Batch: 250 | Loss: 0.297 | Acc: 92.075% | Wgt Acc: 90.706%
	I - Batch: 300 | Loss: 0.308 | Acc: 91.771% | Wgt Acc: 90.476%
I - num batch: 313
I - Train -- Loss: 0.313 | Acc: 91.640% | Wgt Acc: 90.318% | LR: 1.250000e-04 | Dur: 194.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 665.    0.    0.   15.   52.]
 [   0.  271.   64.    6.   11.]
 [   0.   59.  387.    1.   76.]
 [  11.    3.    6.  678.   46.]
 [  18.    1.   30.   19. 2581.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.100 | Acc: 50.125% | Wgt Acc: 39.571%
I - num batch: 70
I - Val -- Loss: 2.061 | Acc: 52.962% | Wgt Acc: 41.595% | Dur: 33.53s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   4.   2.  59.  27.]
 [  1.  13.  12.   3.   3.]
 [  0.  43.  33.   8.  26.]
 [ 21.   2.   7.  62.  14.]
 [ 56.  72.  92.  72. 361.]]

I - Epoch: 97
I - Training: 
	I - Batch: 50 | Loss: 0.311 | Acc: 91.125% | Wgt Acc: 89.104%
	I - Batch: 100 | Loss: 0.289 | Acc: 92.375% | Wgt Acc: 90.835%
	I - Batch: 150 | Loss: 0.277 | Acc: 93.083% | Wgt Acc: 91.835%
	I - Batch: 200 | Loss: 0.277 | Acc: 92.844% | Wgt Acc: 91.771%
	I - Batch: 250 | Loss: 0.279 | Acc: 92.650% | Wgt Acc: 91.437%
	I - Batch: 300 | Loss: 0.278 | Acc: 92.729% | Wgt Acc: 91.616%
I - num batch: 313
I - Train -- Loss: 0.276 | Acc: 92.840% | Wgt Acc: 91.737% | LR: 1.250000e-04 | Dur: 193.64s
I - Confusion Matrix: [row->prediction - col->label]
[[ 672.    0.    0.    3.   46.]
 [   0.  276.   67.    4.   15.]
 [   1.   51.  391.    1.   67.]
 [   4.    6.    1.  701.   36.]
 [  17.    1.   28.   10. 2602.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.078 | Acc: 47.250% | Wgt Acc: 37.713%
I - num batch: 70
I - Val -- Loss: 2.064 | Acc: 49.372% | Wgt Acc: 38.685% | Dur: 33.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 69.   1.   3.  22.  11.]
 [  0.  15.  15.  25.  11.]
 [  2.  56.  57.  18.  53.]
 [ 53.   5.   7.  64.  11.]
 [ 75.  57.  64.  75. 345.]]

I - Epoch: 98
I - Training: 
	I - Batch: 50 | Loss: 0.231 | Acc: 95.375% | Wgt Acc: 94.979%
	I - Batch: 100 | Loss: 0.239 | Acc: 94.562% | Wgt Acc: 93.918%
	I - Batch: 150 | Loss: 0.251 | Acc: 94.083% | Wgt Acc: 93.046%
	I - Batch: 200 | Loss: 0.259 | Acc: 93.625% | Wgt Acc: 92.697%
	I - Batch: 250 | Loss: 0.256 | Acc: 93.825% | Wgt Acc: 92.903%
	I - Batch: 300 | Loss: 0.256 | Acc: 93.708% | Wgt Acc: 92.773%
I - num batch: 313
I - Train -- Loss: 0.256 | Acc: 93.700% | Wgt Acc: 92.740% | LR: 1.250000e-04 | Dur: 193.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    0.    0.    8.   42.]
 [   0.  293.   63.    6.   11.]
 [   0.   36.  394.    1.   62.]
 [   3.    3.    1.  699.   28.]
 [  15.    2.   29.    5. 2623.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.918 | Acc: 47.125% | Wgt Acc: 40.787%
I - num batch: 70
I - Val -- Loss: 1.888 | Acc: 49.820% | Wgt Acc: 42.452% | Dur: 33.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   2.   1.  31.  24.]
 [  1.  34.  28.  10.  15.]
 [  3.  39.  50.  16.  59.]
 [ 44.  14.  10.  75.  29.]
 [ 59.  45.  57.  72. 304.]]

I - Epoch: 99
I - Training: 
	I - Batch: 50 | Loss: 0.243 | Acc: 94.500% | Wgt Acc: 94.755%
	I - Batch: 100 | Loss: 0.234 | Acc: 95.250% | Wgt Acc: 94.742%
	I - Batch: 150 | Loss: 0.233 | Acc: 95.333% | Wgt Acc: 94.605%
	I - Batch: 200 | Loss: 0.236 | Acc: 95.031% | Wgt Acc: 94.222%
	I - Batch: 250 | Loss: 0.244 | Acc: 94.475% | Wgt Acc: 93.654%
	I - Batch: 300 | Loss: 0.246 | Acc: 94.229% | Wgt Acc: 93.350%
I - num batch: 313
I - Train -- Loss: 0.247 | Acc: 94.160% | Wgt Acc: 93.205% | LR: 1.250000e-04 | Dur: 193.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    0.    0.    8.   34.]
 [   0.  291.   47.    4.    7.]
 [   0.   38.  409.    1.   63.]
 [   6.    4.    2.  695.   25.]
 [  12.    1.   29.   11. 2637.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.011 | Acc: 48.375% | Wgt Acc: 40.312%
I - num batch: 70
I - Val -- Loss: 1.964 | Acc: 50.718% | Wgt Acc: 42.172% | Dur: 33.52s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   4.  48.  35.]
 [  1.  29.  29.  10.  18.]
 [  1.  36.  27.  15.  25.]
 [ 24.  13.  16.  72.  36.]
 [ 53.  54.  70.  59. 317.]]

I - Epoch: 100
I - Training: 
	I - Batch: 50 | Loss: 0.230 | Acc: 94.375% | Wgt Acc: 94.053%
	I - Batch: 100 | Loss: 0.253 | Acc: 93.875% | Wgt Acc: 92.949%
	I - Batch: 150 | Loss: 0.256 | Acc: 93.750% | Wgt Acc: 92.935%
	I - Batch: 200 | Loss: 0.260 | Acc: 93.594% | Wgt Acc: 92.815%
	I - Batch: 250 | Loss: 0.258 | Acc: 93.550% | Wgt Acc: 92.777%
	I - Batch: 300 | Loss: 0.262 | Acc: 93.521% | Wgt Acc: 92.774%
I - num batch: 313
I - Train -- Loss: 0.261 | Acc: 93.500% | Wgt Acc: 92.759% | LR: 1.250000e-04 | Dur: 192.61s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    0.    0.    7.   41.]
 [   0.  289.   45.    9.   14.]
 [   0.   34.  406.    3.   65.]
 [   2.    8.    3.  692.   39.]
 [  11.    3.   33.    8. 2607.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.967 | Acc: 49.625% | Wgt Acc: 40.905%
I - num batch: 70
I - Val -- Loss: 1.907 | Acc: 53.142% | Wgt Acc: 43.611% | Dur: 33.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 83.   2.   0.  23.  11.]
 [  0.  16.  12.   4.   4.]
 [  3.  42.  50.   9.  47.]
 [ 54.  13.  14. 103.  29.]
 [ 59.  61.  70.  65. 340.]]

I - Epoch: 101
I - Training: 
	I - Batch: 50 | Loss: 0.257 | Acc: 93.125% | Wgt Acc: 92.222%
	I - Batch: 100 | Loss: 0.229 | Acc: 94.250% | Wgt Acc: 93.373%
	I - Batch: 150 | Loss: 0.245 | Acc: 93.792% | Wgt Acc: 93.050%
	I - Batch: 200 | Loss: 0.243 | Acc: 93.906% | Wgt Acc: 93.147%
	I - Batch: 250 | Loss: 0.249 | Acc: 93.550% | Wgt Acc: 92.744%
	I - Batch: 300 | Loss: 0.255 | Acc: 93.396% | Wgt Acc: 92.546%
I - num batch: 313
I - Train -- Loss: 0.257 | Acc: 93.380% | Wgt Acc: 92.578% | LR: 1.250000e-04 | Dur: 191.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 671.    0.    0.    7.   47.]
 [   0.  290.   56.    9.   14.]
 [   0.   33.  407.    2.   62.]
 [   4.    7.    2.  693.   35.]
 [  19.    4.   22.    8. 2608.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.099 | Acc: 49.375% | Wgt Acc: 40.626%
I - num batch: 70
I - Val -- Loss: 2.002 | Acc: 53.411% | Wgt Acc: 43.838% | Dur: 33.02s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   3.   5.  38.  30.]
 [  1.  17.  13.   4.   6.]
 [  1.  28.  33.   6.  18.]
 [ 52.  23.  22. 105.  39.]
 [ 43.  63.  73.  51. 338.]]

I - Epoch: 102
I - Training: 
	I - Batch: 50 | Loss: 0.219 | Acc: 95.625% | Wgt Acc: 94.260%
	I - Batch: 100 | Loss: 0.222 | Acc: 95.125% | Wgt Acc: 94.181%
	I - Batch: 150 | Loss: 0.218 | Acc: 94.958% | Wgt Acc: 94.308%
	I - Batch: 200 | Loss: 0.223 | Acc: 94.656% | Wgt Acc: 93.921%
	I - Batch: 250 | Loss: 0.219 | Acc: 94.825% | Wgt Acc: 94.042%
	I - Batch: 300 | Loss: 0.215 | Acc: 95.021% | Wgt Acc: 94.293%
I - num batch: 313
I - Train -- Loss: 0.217 | Acc: 94.960% | Wgt Acc: 94.192% | LR: 1.250000e-04 | Dur: 191.66s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    0.    0.    3.   39.]
 [   1.  299.   43.    4.    8.]
 [   0.   29.  418.    1.   48.]
 [   1.    5.    1.  702.   19.]
 [  15.    1.   25.    9. 2652.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.073 | Acc: 48.375% | Wgt Acc: 40.710%
I - num batch: 70
I - Val -- Loss: 1.945 | Acc: 52.424% | Wgt Acc: 43.833% | Dur: 33.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 81.   3.   3.  24.  19.]
 [  1.  17.  12.   5.   6.]
 [  1.  36.  49.   7.  38.]
 [ 68.  20.  21. 113.  44.]
 [ 48.  58.  61.  55. 324.]]

I - Epoch: 103
I - Training: 
	I - Batch: 50 | Loss: 0.212 | Acc: 95.500% | Wgt Acc: 94.377%
	I - Batch: 100 | Loss: 0.197 | Acc: 96.312% | Wgt Acc: 95.515%
	I - Batch: 150 | Loss: 0.184 | Acc: 96.625% | Wgt Acc: 96.094%
	I - Batch: 200 | Loss: 0.182 | Acc: 96.719% | Wgt Acc: 96.150%
	I - Batch: 250 | Loss: 0.192 | Acc: 96.325% | Wgt Acc: 95.815%
	I - Batch: 300 | Loss: 0.192 | Acc: 96.312% | Wgt Acc: 95.835%
I - num batch: 313
I - Train -- Loss: 0.193 | Acc: 96.240% | Wgt Acc: 95.809% | LR: 1.250000e-04 | Dur: 191.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    0.    2.   26.]
 [   0.  312.   27.    3.    8.]
 [   0.   19.  437.    0.   40.]
 [   3.    2.    1.  708.   17.]
 [  11.    1.   22.    6. 2675.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.853 | Acc: 48.875% | Wgt Acc: 44.398%
I - num batch: 70
I - Val -- Loss: 1.853 | Acc: 49.910% | Wgt Acc: 44.701% | Dur: 33.13s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   2.   1.  33.  26.]
 [  4.  33.  24.  22.  25.]
 [  4.  55.  65.  18.  77.]
 [ 30.   8.  11.  73.  27.]
 [ 52.  36.  45.  58. 276.]]

I - Epoch: 104
I - Training: 
	I - Batch: 50 | Loss: 0.203 | Acc: 96.250% | Wgt Acc: 95.520%
	I - Batch: 100 | Loss: 0.204 | Acc: 95.750% | Wgt Acc: 94.732%
	I - Batch: 150 | Loss: 0.196 | Acc: 95.833% | Wgt Acc: 94.847%
	I - Batch: 200 | Loss: 0.191 | Acc: 96.000% | Wgt Acc: 95.132%
	I - Batch: 250 | Loss: 0.193 | Acc: 95.825% | Wgt Acc: 95.078%
	I - Batch: 300 | Loss: 0.200 | Acc: 95.688% | Wgt Acc: 94.794%
I - num batch: 313
I - Train -- Loss: 0.203 | Acc: 95.540% | Wgt Acc: 94.599% | LR: 1.250000e-04 | Dur: 191.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    0.    0.    6.   20.]
 [   0.  297.   37.    4.    6.]
 [   0.   33.  429.    0.   44.]
 [   6.    3.    3.  697.   18.]
 [  12.    1.   18.   12. 2678.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.968 | Acc: 49.250% | Wgt Acc: 43.532%
I - num batch: 70
I - Val -- Loss: 1.948 | Acc: 51.167% | Wgt Acc: 44.526% | Dur: 33.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   2.   1.  36.  17.]
 [  2.  37.  33.   8.  23.]
 [  3.  45.  62.  25.  61.]
 [ 27.   8.  13.  73.  28.]
 [ 71.  42.  37.  62. 302.]]

I - Epoch: 105
I - Training: 
	I - Batch: 50 | Loss: 0.230 | Acc: 93.000% | Wgt Acc: 92.299%
	I - Batch: 100 | Loss: 0.219 | Acc: 94.188% | Wgt Acc: 93.498%
	I - Batch: 150 | Loss: 0.215 | Acc: 94.708% | Wgt Acc: 94.186%
	I - Batch: 200 | Loss: 0.215 | Acc: 94.969% | Wgt Acc: 94.332%
	I - Batch: 250 | Loss: 0.207 | Acc: 95.250% | Wgt Acc: 94.731%
	I - Batch: 300 | Loss: 0.210 | Acc: 94.958% | Wgt Acc: 94.480%
I - num batch: 313
I - Train -- Loss: 0.211 | Acc: 94.860% | Wgt Acc: 94.383% | LR: 1.250000e-04 | Dur: 191.74s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    0.    0.    6.   30.]
 [   0.  305.   32.    6.    8.]
 [   0.   22.  424.    0.   67.]
 [   2.    6.    2.  698.   24.]
 [  13.    1.   29.    9. 2637.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.895 | Acc: 50.375% | Wgt Acc: 46.284%
I - num batch: 70
I - Val -- Loss: 1.828 | Acc: 50.987% | Wgt Acc: 46.891% | Dur: 33.09s
I - Confusion Matrix: [row->prediction - col->label]
[[123.   3.   6.  39.  42.]
 [  2.  22.  15.   5.  16.]
 [  0.  40.  55.   7.  43.]
 [ 45.  24.  26. 111.  73.]
 [ 29.  45.  44.  42. 257.]]

I - Epoch: 106
I - Training: 
	I - Batch: 50 | Loss: 0.207 | Acc: 94.375% | Wgt Acc: 94.110%
	I - Batch: 100 | Loss: 0.213 | Acc: 94.562% | Wgt Acc: 94.186%
	I - Batch: 150 | Loss: 0.202 | Acc: 95.208% | Wgt Acc: 94.765%
	I - Batch: 200 | Loss: 0.205 | Acc: 95.156% | Wgt Acc: 94.589%
	I - Batch: 250 | Loss: 0.205 | Acc: 95.150% | Wgt Acc: 94.556%
	I - Batch: 300 | Loss: 0.202 | Acc: 95.188% | Wgt Acc: 94.671%
I - num batch: 313
I - Train -- Loss: 0.201 | Acc: 95.200% | Wgt Acc: 94.660% | LR: 1.250000e-04 | Dur: 191.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    0.    0.    7.   33.]
 [   0.  310.   29.    2.   10.]
 [   0.   18.  424.    1.   49.]
 [   4.    5.    3.  700.   23.]
 [  15.    1.   31.    9. 2651.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.057 | Acc: 50.000% | Wgt Acc: 42.700%
I - num batch: 70
I - Val -- Loss: 1.968 | Acc: 53.142% | Wgt Acc: 45.293% | Dur: 33.09s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   4.   4.  45.  29.]
 [  0.  16.  13.   2.   4.]
 [  0.  45.  52.  12.  47.]
 [ 34.  11.  17.  86.  35.]
 [ 43.  58.  60.  59. 316.]]

I - Epoch: 107
I - Training: 
	I - Batch: 50 | Loss: 0.172 | Acc: 96.375% | Wgt Acc: 96.672%
	I - Batch: 100 | Loss: 0.201 | Acc: 94.875% | Wgt Acc: 94.976%
	I - Batch: 150 | Loss: 0.210 | Acc: 94.625% | Wgt Acc: 94.509%
	I - Batch: 200 | Loss: 0.206 | Acc: 94.688% | Wgt Acc: 94.484%
	I - Batch: 250 | Loss: 0.197 | Acc: 95.125% | Wgt Acc: 94.866%
	I - Batch: 300 | Loss: 0.194 | Acc: 95.271% | Wgt Acc: 95.026%
I - num batch: 313
I - Train -- Loss: 0.194 | Acc: 95.300% | Wgt Acc: 94.997% | LR: 1.250000e-04 | Dur: 191.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 677.    0.    0.    4.   40.]
 [   0.  312.   28.    0.    7.]
 [   0.   17.  432.    1.   53.]
 [   4.    2.    1.  701.   23.]
 [  13.    3.   26.   13. 2643.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.002 | Acc: 52.625% | Wgt Acc: 45.977%
I - num batch: 70
I - Val -- Loss: 1.907 | Acc: 54.847% | Wgt Acc: 47.495% | Dur: 33.03s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.   2.  47.  28.]
 [  0.  32.  22.   5.  10.]
 [  1.  26.  44.   5.  29.]
 [ 28.  21.  27.  87.  45.]
 [ 41.  52.  51.  60. 319.]]

I - Epoch: 108
I - Training: 
	I - Batch: 50 | Loss: 0.144 | Acc: 98.000% | Wgt Acc: 97.649%
	I - Batch: 100 | Loss: 0.154 | Acc: 97.500% | Wgt Acc: 97.328%
	I - Batch: 150 | Loss: 0.155 | Acc: 97.375% | Wgt Acc: 97.102%
	I - Batch: 200 | Loss: 0.156 | Acc: 97.125% | Wgt Acc: 96.921%
	I - Batch: 250 | Loss: 0.167 | Acc: 96.550% | Wgt Acc: 96.298%
	I - Batch: 300 | Loss: 0.165 | Acc: 96.708% | Wgt Acc: 96.395%
I - num batch: 313
I - Train -- Loss: 0.169 | Acc: 96.460% | Wgt Acc: 96.181% | LR: 1.250000e-04 | Dur: 193.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 687.    0.    0.    2.   21.]
 [   0.  317.   25.    1.    8.]
 [   0.   14.  437.    1.   53.]
 [   2.    2.    2.  708.   10.]
 [   5.    1.   23.    7. 2674.]]

I - Validation: 
	I - Batch: 50 | Loss: 1.995 | Acc: 48.000% | Wgt Acc: 41.932%
I - num batch: 70
I - Val -- Loss: 1.985 | Acc: 50.000% | Wgt Acc: 43.002% | Dur: 33.83s
I - Confusion Matrix: [row->prediction - col->label]
[[ 71.   1.   1.  17.  15.]
 [  2.  17.  16.   6.  11.]
 [  3.  65.  73.  25.  78.]
 [ 66.  11.  15.  98.  29.]
 [ 57.  40.  41.  58. 298.]]

I - Epoch: 109
I - Training: 
	I - Batch: 50 | Loss: 0.182 | Acc: 96.125% | Wgt Acc: 95.604%
	I - Batch: 100 | Loss: 0.161 | Acc: 96.875% | Wgt Acc: 96.796%
	I - Batch: 150 | Loss: 0.166 | Acc: 96.625% | Wgt Acc: 96.256%
	I - Batch: 200 | Loss: 0.162 | Acc: 96.531% | Wgt Acc: 96.099%
	I - Batch: 250 | Loss: 0.168 | Acc: 96.425% | Wgt Acc: 95.963%
	I - Batch: 300 | Loss: 0.169 | Acc: 96.396% | Wgt Acc: 95.978%
I - num batch: 313
I - Train -- Loss: 0.168 | Acc: 96.460% | Wgt Acc: 96.032% | LR: 1.250000e-04 | Dur: 195.14s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    5.   21.]
 [   0.  312.   24.    3.    6.]
 [   0.   16.  444.    2.   45.]
 [   5.    5.    0.  703.   12.]
 [   7.    1.   19.    6. 2682.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.071 | Acc: 48.875% | Wgt Acc: 42.882%
I - num batch: 70
I - Val -- Loss: 1.972 | Acc: 51.795% | Wgt Acc: 45.050% | Dur: 33.99s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   1.   3.  46.  21.]
 [  1.  31.  18.  10.  13.]
 [  4.  41.  56.  13.  61.]
 [ 42.  15.  19.  83.  34.]
 [ 47.  46.  50.  52. 302.]]

I - Epoch: 110
I - Training: 
	I - Batch: 50 | Loss: 0.137 | Acc: 97.750% | Wgt Acc: 97.829%
	I - Batch: 100 | Loss: 0.163 | Acc: 96.750% | Wgt Acc: 96.500%
	I - Batch: 150 | Loss: 0.161 | Acc: 96.750% | Wgt Acc: 96.529%
	I - Batch: 200 | Loss: 0.171 | Acc: 96.250% | Wgt Acc: 96.014%
	I - Batch: 250 | Loss: 0.170 | Acc: 96.175% | Wgt Acc: 95.946%
	I - Batch: 300 | Loss: 0.164 | Acc: 96.354% | Wgt Acc: 96.094%
I - num batch: 313
I - Train -- Loss: 0.164 | Acc: 96.400% | Wgt Acc: 96.127% | LR: 1.250000e-04 | Dur: 194.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    3.   24.]
 [   0.  312.   21.    3.    8.]
 [   1.   13.  449.    2.   49.]
 [   3.    7.    1.  704.   12.]
 [   8.    2.   16.    7. 2673.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.036 | Acc: 48.750% | Wgt Acc: 42.700%
I - num batch: 70
I - Val -- Loss: 1.972 | Acc: 50.898% | Wgt Acc: 44.336% | Dur: 33.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   2.   1.  41.  25.]
 [  0.  19.  13.   8.  13.]
 [  7.  60.  75.  24.  68.]
 [ 41.  12.  15.  80.  29.]
 [ 54.  41.  42.  51. 296.]]

I - Epoch: 111
I - Training: 
	I - Batch: 50 | Loss: 0.162 | Acc: 97.625% | Wgt Acc: 97.168%
	I - Batch: 100 | Loss: 0.141 | Acc: 97.875% | Wgt Acc: 97.639%
	I - Batch: 150 | Loss: 0.136 | Acc: 97.792% | Wgt Acc: 97.708%
	I - Batch: 200 | Loss: 0.137 | Acc: 97.531% | Wgt Acc: 97.419%
	I - Batch: 250 | Loss: 0.141 | Acc: 97.400% | Wgt Acc: 97.326%
	I - Batch: 300 | Loss: 0.143 | Acc: 97.333% | Wgt Acc: 97.202%
I - num batch: 313
I - Train -- Loss: 0.144 | Acc: 97.180% | Wgt Acc: 97.089% | LR: 1.250000e-04 | Dur: 194.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    7.   22.]
 [   0.  322.   16.    3.    5.]
 [   0.    8.  460.    0.   34.]
 [   3.    3.    0.  703.   16.]
 [   6.    1.   11.    6. 2689.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.186 | Acc: 49.625% | Wgt Acc: 41.115%
I - num batch: 70
I - Val -- Loss: 2.092 | Acc: 53.321% | Wgt Acc: 43.701% | Dur: 33.91s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   2.   2.  34.   9.]
 [  2.  28.  21.  13.  14.]
 [  2.  48.  52.  17.  40.]
 [ 29.   3.  11.  68.  21.]
 [ 67.  53.  60.  72. 347.]]

I - Epoch: 112
I - Training: 
	I - Batch: 50 | Loss: 0.191 | Acc: 94.750% | Wgt Acc: 94.804%
	I - Batch: 100 | Loss: 0.192 | Acc: 94.812% | Wgt Acc: 94.607%
	I - Batch: 150 | Loss: 0.194 | Acc: 94.625% | Wgt Acc: 94.365%
	I - Batch: 200 | Loss: 0.182 | Acc: 95.219% | Wgt Acc: 94.995%
	I - Batch: 250 | Loss: 0.181 | Acc: 95.275% | Wgt Acc: 95.148%
	I - Batch: 300 | Loss: 0.183 | Acc: 95.271% | Wgt Acc: 95.119%
I - num batch: 313
I - Train -- Loss: 0.182 | Acc: 95.320% | Wgt Acc: 95.167% | LR: 1.250000e-04 | Dur: 195.11s
I - Confusion Matrix: [row->prediction - col->label]
[[ 680.    0.    0.    4.   33.]
 [   0.  307.   18.    4.    8.]
 [   0.   23.  444.    1.   55.]
 [   3.    3.    2.  699.   34.]
 [  11.    1.   23.   11. 2636.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.089 | Acc: 51.125% | Wgt Acc: 43.287%
I - num batch: 70
I - Val -- Loss: 2.015 | Acc: 53.232% | Wgt Acc: 44.637% | Dur: 33.83s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   3.   1.  38.  14.]
 [  0.  22.  17.  10.  12.]
 [  2.  53.  63.  14.  52.]
 [ 36.   7.  14.  74.  21.]
 [ 59.  49.  51.  68. 332.]]

I - Epoch: 113
I - Training: 
	I - Batch: 50 | Loss: 0.165 | Acc: 96.625% | Wgt Acc: 96.447%
	I - Batch: 100 | Loss: 0.161 | Acc: 96.250% | Wgt Acc: 96.338%
	I - Batch: 150 | Loss: 0.157 | Acc: 96.583% | Wgt Acc: 96.550%
	I - Batch: 200 | Loss: 0.158 | Acc: 96.531% | Wgt Acc: 96.485%
	I - Batch: 250 | Loss: 0.167 | Acc: 96.150% | Wgt Acc: 96.014%
	I - Batch: 300 | Loss: 0.167 | Acc: 96.104% | Wgt Acc: 95.932%
I - num batch: 313
I - Train -- Loss: 0.167 | Acc: 96.020% | Wgt Acc: 95.885% | LR: 1.250000e-04 | Dur: 195.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 675.    0.    0.    3.   33.]
 [   0.  317.   17.    2.    5.]
 [   0.   13.  446.    2.   55.]
 [   6.    3.    0.  706.   16.]
 [  13.    1.   24.    6. 2657.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.232 | Acc: 48.375% | Wgt Acc: 40.004%
I - num batch: 70
I - Val -- Loss: 2.176 | Acc: 51.526% | Wgt Acc: 41.748% | Dur: 34.00s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   2.   2.  34.  11.]
 [  2.  21.  14.  13.  14.]
 [  3.  51.  59.  16.  43.]
 [ 26.   5.  11.  58.  21.]
 [ 74.  55.  60.  83. 342.]]

I - Epoch: 114
I - Training: 
	I - Batch: 50 | Loss: 0.140 | Acc: 96.625% | Wgt Acc: 96.956%
	I - Batch: 100 | Loss: 0.151 | Acc: 96.438% | Wgt Acc: 96.445%
	I - Batch: 150 | Loss: 0.164 | Acc: 96.000% | Wgt Acc: 95.798%
	I - Batch: 200 | Loss: 0.166 | Acc: 96.000% | Wgt Acc: 95.858%
	I - Batch: 250 | Loss: 0.159 | Acc: 96.250% | Wgt Acc: 96.113%
	I - Batch: 300 | Loss: 0.156 | Acc: 96.458% | Wgt Acc: 96.280%
I - num batch: 313
I - Train -- Loss: 0.155 | Acc: 96.500% | Wgt Acc: 96.312% | LR: 1.250000e-04 | Dur: 195.09s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    4.   25.]
 [   0.  314.   16.    5.    4.]
 [   0.   15.  455.    0.   47.]
 [   4.    4.    0.  701.   17.]
 [   8.    1.   16.    9. 2673.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.039 | Acc: 51.500% | Wgt Acc: 44.328%
I - num batch: 70
I - Val -- Loss: 1.976 | Acc: 53.770% | Wgt Acc: 46.013% | Dur: 33.86s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   3.   3.  53.  27.]
 [  0.  18.  15.   6.  11.]
 [  0.  42.  58.  10.  38.]
 [ 34.  18.  19.  82.  36.]
 [ 43.  53.  51.  53. 319.]]

I - Epoch: 115
I - Training: 
	I - Batch: 50 | Loss: 0.139 | Acc: 97.250% | Wgt Acc: 96.238%
	I - Batch: 100 | Loss: 0.164 | Acc: 96.500% | Wgt Acc: 95.506%
	I - Batch: 150 | Loss: 0.155 | Acc: 96.708% | Wgt Acc: 96.054%
	I - Batch: 200 | Loss: 0.152 | Acc: 96.875% | Wgt Acc: 96.352%
	I - Batch: 250 | Loss: 0.157 | Acc: 96.550% | Wgt Acc: 96.100%
	I - Batch: 300 | Loss: 0.158 | Acc: 96.625% | Wgt Acc: 96.190%
I - num batch: 313
I - Train -- Loss: 0.158 | Acc: 96.640% | Wgt Acc: 96.222% | LR: 1.250000e-04 | Dur: 194.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    4.   28.]
 [   0.  311.   21.    7.    6.]
 [   0.   15.  450.    1.   32.]
 [   3.    7.    0.  702.   13.]
 [   9.    1.   16.    5. 2687.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.203 | Acc: 47.500% | Wgt Acc: 40.381%
I - num batch: 70
I - Val -- Loss: 2.109 | Acc: 51.077% | Wgt Acc: 42.875% | Dur: 33.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   2.   2.  45.  15.]
 [  1.  19.  13.   4.  15.]
 [  2.  34.  47.   9.  40.]
 [ 50.  25.  24.  95.  47.]
 [ 52.  54.  60.  51. 314.]]

I - Epoch: 116
I - Training: 
	I - Batch: 50 | Loss: 0.180 | Acc: 94.875% | Wgt Acc: 94.989%
	I - Batch: 100 | Loss: 0.158 | Acc: 96.062% | Wgt Acc: 96.501%
	I - Batch: 150 | Loss: 0.162 | Acc: 95.958% | Wgt Acc: 96.305%
	I - Batch: 200 | Loss: 0.160 | Acc: 96.062% | Wgt Acc: 96.251%
	I - Batch: 250 | Loss: 0.161 | Acc: 96.100% | Wgt Acc: 96.226%
	I - Batch: 300 | Loss: 0.168 | Acc: 95.792% | Wgt Acc: 95.729%
I - num batch: 313
I - Train -- Loss: 0.168 | Acc: 95.740% | Wgt Acc: 95.648% | LR: 1.250000e-04 | Dur: 194.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    4.   26.]
 [   0.  315.   25.    7.    6.]
 [   0.   14.  447.    1.   56.]
 [   3.    3.    1.  696.   31.]
 [   9.    2.   14.   11. 2647.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.258 | Acc: 48.625% | Wgt Acc: 39.976%
I - num batch: 70
I - Val -- Loss: 2.133 | Acc: 52.693% | Wgt Acc: 42.680% | Dur: 33.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 81.   2.   2.  33.  14.]
 [  1.  17.   7.   2.   8.]
 [  3.  46.  55.  11.  33.]
 [ 54.  10.  13.  87.  29.]
 [ 60.  59.  69.  71. 347.]]

I - Epoch: 117
I - Training: 
	I - Batch: 50 | Loss: 0.186 | Acc: 95.625% | Wgt Acc: 94.613%
	I - Batch: 100 | Loss: 0.180 | Acc: 95.375% | Wgt Acc: 94.742%
	I - Batch: 150 | Loss: 0.178 | Acc: 95.375% | Wgt Acc: 94.930%
	I - Batch: 200 | Loss: 0.174 | Acc: 95.688% | Wgt Acc: 95.292%
	I - Batch: 250 | Loss: 0.186 | Acc: 95.125% | Wgt Acc: 94.744%
	I - Batch: 300 | Loss: 0.197 | Acc: 94.646% | Wgt Acc: 94.329%
I - num batch: 313
I - Train -- Loss: 0.194 | Acc: 94.780% | Wgt Acc: 94.477% | LR: 1.250000e-04 | Dur: 193.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 663.    0.    0.    5.   45.]
 [   0.  304.   19.    9.   12.]
 [   0.   23.  446.    0.   55.]
 [  10.    5.    3.  696.   24.]
 [  21.    2.   19.    9. 2630.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.278 | Acc: 50.625% | Wgt Acc: 42.205%
I - num batch: 70
I - Val -- Loss: 2.182 | Acc: 52.424% | Wgt Acc: 43.357% | Dur: 33.73s
I - Confusion Matrix: [row->prediction - col->label]
[[130.   2.   6.  64.  40.]
 [  0.  12.   8.   1.   6.]
 [  1.  54.  62.  13.  34.]
 [ 18.   5.  13.  48.  19.]
 [ 50.  61.  57.  78. 332.]]

I - Epoch: 118
I - Training: 
	I - Batch: 50 | Loss: 0.181 | Acc: 95.375% | Wgt Acc: 95.119%
	I - Batch: 100 | Loss: 0.163 | Acc: 95.750% | Wgt Acc: 95.758%
	I - Batch: 150 | Loss: 0.152 | Acc: 96.292% | Wgt Acc: 96.233%
	I - Batch: 200 | Loss: 0.149 | Acc: 96.312% | Wgt Acc: 96.285%
	I - Batch: 250 | Loss: 0.149 | Acc: 96.325% | Wgt Acc: 96.254%
	I - Batch: 300 | Loss: 0.147 | Acc: 96.396% | Wgt Acc: 96.397%
I - num batch: 313
I - Train -- Loss: 0.147 | Acc: 96.440% | Wgt Acc: 96.447% | LR: 1.250000e-04 | Dur: 194.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    0.    0.    5.   30.]
 [   0.  317.   14.    1.    9.]
 [   0.   12.  456.    0.   45.]
 [   4.    4.    1.  704.   20.]
 [   7.    1.   16.    9. 2662.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.192 | Acc: 51.250% | Wgt Acc: 42.463%
I - num batch: 70
I - Val -- Loss: 2.133 | Acc: 53.052% | Wgt Acc: 43.426% | Dur: 33.67s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   3.   3.  54.  21.]
 [  0.  25.  14.   4.  10.]
 [  0.  45.  52.  10.  35.]
 [ 31.   8.  11.  59.  20.]
 [ 58.  53.  66.  77. 345.]]

I - Epoch: 119
I - Training: 
	I - Batch: 50 | Loss: 0.117 | Acc: 98.125% | Wgt Acc: 97.622%
	I - Batch: 100 | Loss: 0.134 | Acc: 97.375% | Wgt Acc: 97.152%
	I - Batch: 150 | Loss: 0.135 | Acc: 97.125% | Wgt Acc: 96.897%
	I - Batch: 200 | Loss: 0.129 | Acc: 97.312% | Wgt Acc: 97.185%
	I - Batch: 250 | Loss: 0.130 | Acc: 97.350% | Wgt Acc: 97.175%
	I - Batch: 300 | Loss: 0.127 | Acc: 97.312% | Wgt Acc: 97.227%
I - num batch: 313
I - Train -- Loss: 0.126 | Acc: 97.360% | Wgt Acc: 97.279% | LR: 1.250000e-04 | Dur: 194.08s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    3.   21.]
 [   0.  320.   14.    1.    6.]
 [   0.   10.  459.    1.   35.]
 [   2.    3.    1.  709.   12.]
 [   4.    1.   13.    5. 2692.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.335 | Acc: 51.375% | Wgt Acc: 42.330%
I - num batch: 70
I - Val -- Loss: 2.249 | Acc: 53.501% | Wgt Acc: 43.219% | Dur: 33.67s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   3.   5.  53.  31.]
 [  0.  18.  18.   3.   5.]
 [  1.  44.  46.  12.  22.]
 [ 16.   6.   7.  59.  21.]
 [ 61.  63.  70.  77. 352.]]

I - Epoch: 120
I - Training: 
	I - Batch: 50 | Loss: 0.122 | Acc: 98.625% | Wgt Acc: 98.299%
	I - Batch: 100 | Loss: 0.135 | Acc: 98.062% | Wgt Acc: 97.818%
	I - Batch: 150 | Loss: 0.134 | Acc: 97.792% | Wgt Acc: 97.687%
	I - Batch: 200 | Loss: 0.125 | Acc: 97.938% | Wgt Acc: 97.830%
	I - Batch: 250 | Loss: 0.119 | Acc: 98.050% | Wgt Acc: 97.937%
	I - Batch: 300 | Loss: 0.115 | Acc: 98.188% | Wgt Acc: 98.104%
I - num batch: 313
I - Train -- Loss: 0.114 | Acc: 98.180% | Wgt Acc: 98.135% | LR: 1.250000e-04 | Dur: 194.29s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    1.    0.    2.   15.]
 [   0.  327.    8.    2.    7.]
 [   0.    4.  466.    0.   26.]
 [   2.    2.    0.  713.    3.]
 [   4.    0.   13.    2. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.207 | Acc: 48.875% | Wgt Acc: 40.682%
I - num batch: 70
I - Val -- Loss: 2.104 | Acc: 51.885% | Wgt Acc: 42.912% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   3.   3.  44.  37.]
 [  1.  14.  13.   8.   8.]
 [  0.  51.  51.   7.  32.]
 [ 31.   7.  12.  74.  27.]
 [ 55.  59.  67.  71. 327.]]

I - Epoch: 121
I - Training: 
	I - Batch: 50 | Loss: 0.106 | Acc: 98.375% | Wgt Acc: 98.252%
	I - Batch: 100 | Loss: 0.109 | Acc: 98.188% | Wgt Acc: 98.205%
	I - Batch: 150 | Loss: 0.115 | Acc: 97.958% | Wgt Acc: 97.801%
	I - Batch: 200 | Loss: 0.116 | Acc: 97.875% | Wgt Acc: 97.606%
	I - Batch: 250 | Loss: 0.117 | Acc: 97.750% | Wgt Acc: 97.524%
	I - Batch: 300 | Loss: 0.114 | Acc: 97.833% | Wgt Acc: 97.624%
I - num batch: 313
I - Train -- Loss: 0.113 | Acc: 97.860% | Wgt Acc: 97.661% | LR: 1.250000e-04 | Dur: 194.18s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    3.   12.]
 [   0.  323.   13.    2.    3.]
 [   0.    9.  462.    0.   29.]
 [   4.    2.    0.  710.    9.]
 [   5.    0.   12.    4. 2713.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.242 | Acc: 51.875% | Wgt Acc: 43.741%
I - num batch: 70
I - Val -- Loss: 2.157 | Acc: 53.950% | Wgt Acc: 44.669% | Dur: 33.71s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   2.   3.  61.  25.]
 [  0.  27.  23.   8.  19.]
 [  1.  35.  44.   3.  26.]
 [ 16.  12.  13.  62.  19.]
 [ 56.  58.  63.  70. 342.]]

I - Epoch: 122
I - Training: 
	I - Batch: 50 | Loss: 0.127 | Acc: 97.250% | Wgt Acc: 97.482%
	I - Batch: 100 | Loss: 0.122 | Acc: 97.562% | Wgt Acc: 97.607%
	I - Batch: 150 | Loss: 0.123 | Acc: 97.208% | Wgt Acc: 97.221%
	I - Batch: 200 | Loss: 0.124 | Acc: 97.125% | Wgt Acc: 97.065%
	I - Batch: 250 | Loss: 0.130 | Acc: 96.875% | Wgt Acc: 96.781%
	I - Batch: 300 | Loss: 0.129 | Acc: 96.917% | Wgt Acc: 96.814%
I - num batch: 313
I - Train -- Loss: 0.131 | Acc: 96.820% | Wgt Acc: 96.762% | LR: 1.250000e-04 | Dur: 194.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    0.    6.   22.]
 [   1.  321.   11.    5.    6.]
 [   0.    7.  457.    1.   42.]
 [   5.    5.    0.  702.   19.]
 [   4.    1.   19.    5. 2677.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.429 | Acc: 48.250% | Wgt Acc: 38.698%
I - num batch: 70
I - Val -- Loss: 2.357 | Acc: 51.526% | Wgt Acc: 40.568% | Dur: 33.70s
I - Confusion Matrix: [row->prediction - col->label]
[[ 93.   3.   4.  49.  18.]
 [  0.  22.  18.   6.   9.]
 [  1.  46.  48.  13.  33.]
 [ 22.   9.   5.  54.  14.]
 [ 83.  54.  71.  82. 357.]]

I - Epoch: 123
I - Training: 
	I - Batch: 50 | Loss: 0.172 | Acc: 96.125% | Wgt Acc: 96.184%
	I - Batch: 100 | Loss: 0.182 | Acc: 95.375% | Wgt Acc: 94.955%
	I - Batch: 150 | Loss: 0.181 | Acc: 95.458% | Wgt Acc: 95.024%
	I - Batch: 200 | Loss: 0.175 | Acc: 95.688% | Wgt Acc: 95.381%
	I - Batch: 250 | Loss: 0.163 | Acc: 96.050% | Wgt Acc: 95.773%
	I - Batch: 300 | Loss: 0.152 | Acc: 96.438% | Wgt Acc: 96.243%
I - num batch: 313
I - Train -- Loss: 0.149 | Acc: 96.540% | Wgt Acc: 96.348% | LR: 1.250000e-04 | Dur: 194.24s
I - Confusion Matrix: [row->prediction - col->label]
[[ 682.    0.    0.    8.   26.]
 [   0.  316.   12.    6.    5.]
 [   0.   11.  455.    1.   42.]
 [   4.    6.    5.  699.   18.]
 [   8.    1.   15.    5. 2675.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.298 | Acc: 50.750% | Wgt Acc: 41.960%
I - num batch: 70
I - Val -- Loss: 2.243 | Acc: 53.142% | Wgt Acc: 43.193% | Dur: 33.64s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   3.   3.  37.  16.]
 [  0.  18.  14.   6.   8.]
 [  3.  50.  55.  15.  41.]
 [ 24.   2.   3.  70.  18.]
 [ 71.  61.  71.  76. 348.]]

I - Epoch: 124
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 98.375% | Wgt Acc: 98.528%
	I - Batch: 100 | Loss: 0.106 | Acc: 97.812% | Wgt Acc: 97.745%
	I - Batch: 150 | Loss: 0.105 | Acc: 97.917% | Wgt Acc: 97.917%
	I - Batch: 200 | Loss: 0.104 | Acc: 97.938% | Wgt Acc: 97.923%
	I - Batch: 250 | Loss: 0.102 | Acc: 98.175% | Wgt Acc: 98.076%
	I - Batch: 300 | Loss: 0.104 | Acc: 98.083% | Wgt Acc: 98.021%
I - num batch: 313
I - Train -- Loss: 0.105 | Acc: 98.040% | Wgt Acc: 98.012% | LR: 1.250000e-04 | Dur: 193.19s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    3.   17.]
 [   0.  324.    6.    2.    2.]
 [   0.   10.  473.    0.   26.]
 [   5.    0.    0.  708.   10.]
 [   3.    0.    8.    6. 2711.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.210 | Acc: 51.125% | Wgt Acc: 43.350%
I - num batch: 70
I - Val -- Loss: 2.141 | Acc: 53.591% | Wgt Acc: 45.161% | Dur: 33.08s
I - Confusion Matrix: [row->prediction - col->label]
[[125.   3.   4.  50.  31.]
 [  0.  22.  16.   5.  14.]
 [  1.  34.  42.   8.  16.]
 [ 26.  22.  22.  82.  44.]
 [ 47.  53.  62.  59. 326.]]

I - Epoch: 125
I - Training: 
	I - Batch: 50 | Loss: 0.128 | Acc: 97.375% | Wgt Acc: 97.050%
	I - Batch: 100 | Loss: 0.139 | Acc: 96.562% | Wgt Acc: 96.209%
	I - Batch: 150 | Loss: 0.133 | Acc: 96.750% | Wgt Acc: 96.548%
	I - Batch: 200 | Loss: 0.126 | Acc: 97.062% | Wgt Acc: 96.907%
	I - Batch: 250 | Loss: 0.117 | Acc: 97.450% | Wgt Acc: 97.334%
	I - Batch: 300 | Loss: 0.117 | Acc: 97.417% | Wgt Acc: 97.293%
I - num batch: 313
I - Train -- Loss: 0.117 | Acc: 97.420% | Wgt Acc: 97.313% | LR: 1.250000e-04 | Dur: 191.48s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    0.    2.   22.]
 [   0.  320.   11.    3.    6.]
 [   0.    9.  468.    2.   22.]
 [   2.    5.    0.  702.   19.]
 [   8.    0.    8.   10. 2697.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.312 | Acc: 49.000% | Wgt Acc: 41.241%
I - num batch: 70
I - Val -- Loss: 2.213 | Acc: 51.706% | Wgt Acc: 43.367% | Dur: 33.04s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   3.   2.  52.  38.]
 [  1.  24.  17.   7.  11.]
 [  0.  32.  38.   2.  27.]
 [ 41.  19.  21.  84.  37.]
 [ 45.  56.  68.  59. 318.]]

I - Epoch: 126
I - Training: 
	I - Batch: 50 | Loss: 0.110 | Acc: 97.500% | Wgt Acc: 97.814%
	I - Batch: 100 | Loss: 0.113 | Acc: 97.625% | Wgt Acc: 97.685%
	I - Batch: 150 | Loss: 0.112 | Acc: 97.625% | Wgt Acc: 97.657%
	I - Batch: 200 | Loss: 0.103 | Acc: 97.969% | Wgt Acc: 98.014%
	I - Batch: 250 | Loss: 0.100 | Acc: 98.075% | Wgt Acc: 98.008%
	I - Batch: 300 | Loss: 0.103 | Acc: 97.833% | Wgt Acc: 97.750%
I - num batch: 313
I - Train -- Loss: 0.101 | Acc: 97.880% | Wgt Acc: 97.816% | LR: 1.250000e-04 | Dur: 191.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    2.   12.]
 [   0.  322.   10.    3.    5.]
 [   0.    9.  468.    0.   28.]
 [   1.    2.    0.  708.   14.]
 [   4.    1.    9.    6. 2707.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.360 | Acc: 48.625% | Wgt Acc: 40.312%
I - num batch: 70
I - Val -- Loss: 2.277 | Acc: 51.526% | Wgt Acc: 42.283% | Dur: 33.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 81.   1.   2.  24.   5.]
 [  1.  31.  25.  16.  17.]
 [  3.  46.  50.  13.  45.]
 [ 39.   5.  11.  76.  28.]
 [ 75.  51.  58.  75. 336.]]

I - Epoch: 127
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 98.750% | Wgt Acc: 98.990%
	I - Batch: 100 | Loss: 0.091 | Acc: 98.500% | Wgt Acc: 98.561%
	I - Batch: 150 | Loss: 0.089 | Acc: 98.333% | Wgt Acc: 98.582%
	I - Batch: 200 | Loss: 0.092 | Acc: 98.281% | Wgt Acc: 98.431%
	I - Batch: 250 | Loss: 0.094 | Acc: 98.250% | Wgt Acc: 98.387%
	I - Batch: 300 | Loss: 0.094 | Acc: 98.125% | Wgt Acc: 98.282%
I - num batch: 313
I - Train -- Loss: 0.094 | Acc: 98.100% | Wgt Acc: 98.274% | LR: 1.250000e-04 | Dur: 191.36s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    0.    3.   21.]
 [   0.  331.    5.    1.    3.]
 [   0.    2.  473.    0.   31.]
 [   3.    1.    0.  713.    7.]
 [   7.    0.    9.    2. 2704.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.279 | Acc: 50.500% | Wgt Acc: 42.239%
I - num batch: 70
I - Val -- Loss: 2.194 | Acc: 53.142% | Wgt Acc: 44.198% | Dur: 32.96s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   4.   2.  63.  40.]
 [  0.  19.  15.   5.   7.]
 [  0.  41.  43.  11.  27.]
 [ 25.  17.  20.  68.  26.]
 [ 43.  53.  66.  57. 331.]]

I - Epoch: 128
I - Training: 
	I - Batch: 50 | Loss: 0.108 | Acc: 98.250% | Wgt Acc: 98.362%
	I - Batch: 100 | Loss: 0.107 | Acc: 97.812% | Wgt Acc: 97.930%
	I - Batch: 150 | Loss: 0.097 | Acc: 98.000% | Wgt Acc: 98.122%
	I - Batch: 200 | Loss: 0.091 | Acc: 98.281% | Wgt Acc: 98.406%
	I - Batch: 250 | Loss: 0.090 | Acc: 98.300% | Wgt Acc: 98.370%
	I - Batch: 300 | Loss: 0.088 | Acc: 98.458% | Wgt Acc: 98.495%
I - num batch: 313
I - Train -- Loss: 0.087 | Acc: 98.500% | Wgt Acc: 98.544% | LR: 1.250000e-04 | Dur: 191.35s
I - Confusion Matrix: [row->prediction - col->label]
[[ 687.    0.    0.    3.   12.]
 [   0.  329.    3.    2.    3.]
 [   0.    3.  475.    0.   25.]
 [   1.    2.    0.  713.    5.]
 [   6.    0.    9.    1. 2721.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.292 | Acc: 48.875% | Wgt Acc: 41.199%
I - num batch: 70
I - Val -- Loss: 2.226 | Acc: 51.346% | Wgt Acc: 42.738% | Dur: 33.10s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   2.   3.  37.  23.]
 [  1.  20.  15.  10.  10.]
 [  2.  48.  46.  10.  36.]
 [ 35.  17.  15.  85.  41.]
 [ 61.  47.  67.  62. 321.]]

I - Epoch: 129
I - Training: 
	I - Batch: 50 | Loss: 0.067 | Acc: 99.250% | Wgt Acc: 99.336%
	I - Batch: 100 | Loss: 0.084 | Acc: 98.750% | Wgt Acc: 98.651%
	I - Batch: 150 | Loss: 0.083 | Acc: 98.792% | Wgt Acc: 98.803%
	I - Batch: 200 | Loss: 0.085 | Acc: 98.625% | Wgt Acc: 98.586%
	I - Batch: 250 | Loss: 0.087 | Acc: 98.600% | Wgt Acc: 98.533%
	I - Batch: 300 | Loss: 0.087 | Acc: 98.604% | Wgt Acc: 98.600%
I - num batch: 313
I - Train -- Loss: 0.087 | Acc: 98.620% | Wgt Acc: 98.612% | LR: 1.250000e-04 | Dur: 191.27s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    4.    8.]
 [   0.  326.    5.    1.    2.]
 [   0.    7.  476.    0.   19.]
 [   1.    1.    0.  712.   11.]
 [   2.    0.    6.    2. 2726.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.501 | Acc: 47.125% | Wgt Acc: 37.566%
I - num batch: 70
I - Val -- Loss: 2.382 | Acc: 50.898% | Wgt Acc: 40.066% | Dur: 33.02s
I - Confusion Matrix: [row->prediction - col->label]
[[ 81.   2.   1.  31.  11.]
 [  1.  25.  21.  13.  10.]
 [  1.  37.  43.  13.  38.]
 [ 22.  11.  10.  65.  19.]
 [ 94.  59.  71.  82. 353.]]

I - Epoch: 130
I - Training: 
	I - Batch: 50 | Loss: 0.090 | Acc: 98.375% | Wgt Acc: 98.470%
	I - Batch: 100 | Loss: 0.091 | Acc: 98.438% | Wgt Acc: 98.567%
	I - Batch: 150 | Loss: 0.089 | Acc: 98.333% | Wgt Acc: 98.433%
	I - Batch: 200 | Loss: 0.088 | Acc: 98.281% | Wgt Acc: 98.436%
	I - Batch: 250 | Loss: 0.085 | Acc: 98.475% | Wgt Acc: 98.617%
	I - Batch: 300 | Loss: 0.085 | Acc: 98.500% | Wgt Acc: 98.603%
I - num batch: 313
I - Train -- Loss: 0.086 | Acc: 98.460% | Wgt Acc: 98.563% | LR: 1.250000e-04 | Dur: 191.20s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    2.   12.]
 [   0.  333.    6.    2.    4.]
 [   0.    1.  474.    0.   26.]
 [   2.    0.    1.  710.    6.]
 [   4.    0.    6.    5. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.341 | Acc: 50.875% | Wgt Acc: 42.365%
I - num batch: 70
I - Val -- Loss: 2.258 | Acc: 53.321% | Wgt Acc: 43.775% | Dur: 33.01s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   1.   2.  48.  24.]
 [  0.  14.  16.   8.   7.]
 [  1.  47.  54.  14.  35.]
 [ 23.  10.  10.  64.  24.]
 [ 54.  62.  64.  70. 341.]]

I - Epoch: 131
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 98.375% | Wgt Acc: 98.624%
	I - Batch: 100 | Loss: 0.084 | Acc: 98.438% | Wgt Acc: 98.608%
	I - Batch: 150 | Loss: 0.084 | Acc: 98.542% | Wgt Acc: 98.675%
	I - Batch: 200 | Loss: 0.093 | Acc: 98.281% | Wgt Acc: 98.247%
	I - Batch: 250 | Loss: 0.090 | Acc: 98.400% | Wgt Acc: 98.444%
	I - Batch: 300 | Loss: 0.088 | Acc: 98.479% | Wgt Acc: 98.499%
I - num batch: 313
I - Train -- Loss: 0.087 | Acc: 98.500% | Wgt Acc: 98.513% | LR: 1.250000e-04 | Dur: 191.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.   18.]
 [   1.  331.    5.    2.    5.]
 [   0.    2.  473.    0.   12.]
 [   1.    1.    0.  712.    8.]
 [   6.    0.    9.    3. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.385 | Acc: 50.125% | Wgt Acc: 41.464%
I - num batch: 70
I - Val -- Loss: 2.301 | Acc: 52.513% | Wgt Acc: 43.029% | Dur: 33.07s
I - Confusion Matrix: [row->prediction - col->label]
[[120.   2.   3.  50.  29.]
 [  0.  13.  15.   4.   7.]
 [  1.  48.  50.   9.  39.]
 [ 20.  12.  12.  66.  20.]
 [ 58.  59.  66.  75. 336.]]

I - Epoch: 132
I - Training: 
	I - Batch: 50 | Loss: 0.074 | Acc: 98.875% | Wgt Acc: 98.954%
	I - Batch: 100 | Loss: 0.077 | Acc: 98.562% | Wgt Acc: 98.596%
	I - Batch: 150 | Loss: 0.091 | Acc: 98.042% | Wgt Acc: 98.081%
	I - Batch: 200 | Loss: 0.086 | Acc: 98.312% | Wgt Acc: 98.383%
	I - Batch: 250 | Loss: 0.085 | Acc: 98.300% | Wgt Acc: 98.336%
	I - Batch: 300 | Loss: 0.087 | Acc: 98.312% | Wgt Acc: 98.322%
I - num batch: 313
I - Train -- Loss: 0.086 | Acc: 98.380% | Wgt Acc: 98.389% | LR: 1.250000e-04 | Dur: 191.25s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    3.   11.]
 [   0.  326.    6.    1.    3.]
 [   0.    4.  476.    0.   26.]
 [   1.    4.    0.  710.    7.]
 [   5.    0.    5.    5. 2719.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.328 | Acc: 49.125% | Wgt Acc: 41.604%
I - num batch: 70
I - Val -- Loss: 2.268 | Acc: 51.436% | Wgt Acc: 42.949% | Dur: 33.03s
I - Confusion Matrix: [row->prediction - col->label]
[[102.   2.   2.  36.  22.]
 [  1.  26.  20.  13.  16.]
 [  1.  48.  51.  19.  38.]
 [ 27.  14.  15.  71.  32.]
 [ 68.  44.  58.  65. 323.]]

I - Epoch: 133
I - Training: 
	I - Batch: 50 | Loss: 0.084 | Acc: 98.375% | Wgt Acc: 98.509%
	I - Batch: 100 | Loss: 0.086 | Acc: 98.250% | Wgt Acc: 98.134%
	I - Batch: 150 | Loss: 0.100 | Acc: 97.792% | Wgt Acc: 97.717%
	I - Batch: 200 | Loss: 0.103 | Acc: 97.625% | Wgt Acc: 97.585%
	I - Batch: 250 | Loss: 0.104 | Acc: 97.550% | Wgt Acc: 97.484%
	I - Batch: 300 | Loss: 0.108 | Acc: 97.396% | Wgt Acc: 97.390%
I - num batch: 313
I - Train -- Loss: 0.108 | Acc: 97.420% | Wgt Acc: 97.424% | LR: 1.250000e-04 | Dur: 193.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 678.    0.    0.    9.   28.]
 [   0.  324.    8.    4.    3.]
 [   0.    4.  475.    0.   25.]
 [   7.    5.    0.  700.   16.]
 [   9.    1.    4.    6. 2694.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.357 | Acc: 50.875% | Wgt Acc: 43.769%
I - num batch: 70
I - Val -- Loss: 2.253 | Acc: 53.411% | Wgt Acc: 45.304% | Dur: 34.03s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   1.   3.  34.  27.]
 [  0.  24.  14.   9.  13.]
 [  1.  37.  53.   8.  33.]
 [ 33.  14.  15.  82.  34.]
 [ 53.  58.  61.  71. 324.]]

I - Epoch: 134
I - Training: 
	I - Batch: 50 | Loss: 0.101 | Acc: 97.375% | Wgt Acc: 97.385%
	I - Batch: 100 | Loss: 0.106 | Acc: 97.625% | Wgt Acc: 97.553%
	I - Batch: 150 | Loss: 0.107 | Acc: 97.333% | Wgt Acc: 97.421%
	I - Batch: 200 | Loss: 0.103 | Acc: 97.469% | Wgt Acc: 97.542%
	I - Batch: 250 | Loss: 0.108 | Acc: 97.375% | Wgt Acc: 97.338%
	I - Batch: 300 | Loss: 0.110 | Acc: 97.250% | Wgt Acc: 97.242%
I - num batch: 313
I - Train -- Loss: 0.110 | Acc: 97.240% | Wgt Acc: 97.215% | LR: 1.250000e-04 | Dur: 195.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    0.    0.   10.   14.]
 [   0.  326.   11.    3.    3.]
 [   0.    7.  467.    0.   41.]
 [   8.    1.    0.  696.   18.]
 [   3.    0.    9.   10. 2690.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.525 | Acc: 49.125% | Wgt Acc: 41.373%
I - num batch: 70
I - Val -- Loss: 2.413 | Acc: 52.065% | Wgt Acc: 43.087% | Dur: 33.86s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   2.   6.  47.  24.]
 [  0.  20.  12.   4.  10.]
 [  3.  40.  51.  13.  40.]
 [ 25.  10.  13.  66.  27.]
 [ 58.  62.  64.  74. 330.]]

I - Epoch: 135
I - Training: 
	I - Batch: 50 | Loss: 0.124 | Acc: 96.750% | Wgt Acc: 96.296%
	I - Batch: 100 | Loss: 0.114 | Acc: 97.062% | Wgt Acc: 96.871%
	I - Batch: 150 | Loss: 0.118 | Acc: 97.042% | Wgt Acc: 96.785%
	I - Batch: 200 | Loss: 0.113 | Acc: 97.438% | Wgt Acc: 97.199%
	I - Batch: 250 | Loss: 0.113 | Acc: 97.325% | Wgt Acc: 97.093%
	I - Batch: 300 | Loss: 0.118 | Acc: 96.979% | Wgt Acc: 96.908%
I - num batch: 313
I - Train -- Loss: 0.119 | Acc: 96.960% | Wgt Acc: 96.858% | LR: 1.250000e-04 | Dur: 195.21s
I - Confusion Matrix: [row->prediction - col->label]
[[ 676.    0.    0.    6.   28.]
 [   0.  320.   12.    3.    6.]
 [   0.    9.  463.    0.   34.]
 [   2.    5.    0.  705.   14.]
 [  16.    0.   12.    5. 2684.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.575 | Acc: 50.000% | Wgt Acc: 41.115%
I - num batch: 70
I - Val -- Loss: 2.455 | Acc: 52.693% | Wgt Acc: 42.764% | Dur: 33.64s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   3.   7.  50.  34.]
 [  1.  22.  15.   5.  10.]
 [  0.  34.  39.   7.  26.]
 [ 30.   6.  12.  64.  17.]
 [ 50.  69.  73.  78. 344.]]

I - Epoch: 136
I - Training: 
	I - Batch: 50 | Loss: 0.108 | Acc: 98.000% | Wgt Acc: 97.632%
	I - Batch: 100 | Loss: 0.118 | Acc: 97.562% | Wgt Acc: 97.301%
	I - Batch: 150 | Loss: 0.127 | Acc: 97.125% | Wgt Acc: 97.023%
	I - Batch: 200 | Loss: 0.127 | Acc: 97.000% | Wgt Acc: 96.920%
	I - Batch: 250 | Loss: 0.130 | Acc: 96.925% | Wgt Acc: 96.849%
	I - Batch: 300 | Loss: 0.136 | Acc: 96.583% | Wgt Acc: 96.387%
I - num batch: 313
I - Train -- Loss: 0.138 | Acc: 96.360% | Wgt Acc: 96.224% | LR: 1.250000e-04 | Dur: 192.05s
I - Confusion Matrix: [row->prediction - col->label]
[[ 681.    0.    0.    7.   23.]
 [   0.  316.   13.    7.    6.]
 [   0.   10.  458.    0.   45.]
 [   5.    8.    1.  695.   24.]
 [   8.    0.   15.   10. 2668.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.344 | Acc: 49.500% | Wgt Acc: 42.589%
I - num batch: 70
I - Val -- Loss: 2.245 | Acc: 52.424% | Wgt Acc: 44.547% | Dur: 33.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 86.   1.   4.  25.  15.]
 [  0.  30.  23.  11.  17.]
 [  0.  36.  55.   9.  39.]
 [ 55.   7.  16.  93.  40.]
 [ 58.  60.  48.  66. 320.]]

I - Epoch: 137
I - Training: 
	I - Batch: 50 | Loss: 0.134 | Acc: 96.500% | Wgt Acc: 96.098%
	I - Batch: 100 | Loss: 0.133 | Acc: 96.375% | Wgt Acc: 96.147%
	I - Batch: 150 | Loss: 0.123 | Acc: 96.917% | Wgt Acc: 96.763%
	I - Batch: 200 | Loss: 0.118 | Acc: 97.062% | Wgt Acc: 96.841%
	I - Batch: 250 | Loss: 0.117 | Acc: 96.975% | Wgt Acc: 96.820%
	I - Batch: 300 | Loss: 0.111 | Acc: 97.271% | Wgt Acc: 97.146%
I - num batch: 313
I - Train -- Loss: 0.110 | Acc: 97.340% | Wgt Acc: 97.201% | LR: 1.250000e-04 | Dur: 192.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    6.   17.]
 [   0.  323.    6.    6.    4.]
 [   0.   10.  464.    1.   28.]
 [   3.    1.    0.  698.   20.]
 [   6.    0.   17.    8. 2697.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.347 | Acc: 51.250% | Wgt Acc: 44.412%
I - num batch: 70
I - Val -- Loss: 2.264 | Acc: 53.142% | Wgt Acc: 46.082% | Dur: 33.16s
I - Confusion Matrix: [row->prediction - col->label]
[[133.   5.   7.  54.  52.]
 [  0.  14.  15.   3.   4.]
 [  0.  32.  40.   4.  20.]
 [ 36.  30.  30. 104.  54.]
 [ 30.  53.  54.  39. 301.]]

I - Epoch: 138
I - Training: 
	I - Batch: 50 | Loss: 0.086 | Acc: 98.250% | Wgt Acc: 98.306%
	I - Batch: 100 | Loss: 0.090 | Acc: 98.188% | Wgt Acc: 98.190%
	I - Batch: 150 | Loss: 0.091 | Acc: 98.125% | Wgt Acc: 98.191%
	I - Batch: 200 | Loss: 0.089 | Acc: 98.156% | Wgt Acc: 98.204%
	I - Batch: 250 | Loss: 0.094 | Acc: 98.100% | Wgt Acc: 98.074%
	I - Batch: 300 | Loss: 0.093 | Acc: 98.146% | Wgt Acc: 98.125%
I - num batch: 313
I - Train -- Loss: 0.092 | Acc: 98.200% | Wgt Acc: 98.168% | LR: 1.250000e-04 | Dur: 192.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    1.   12.]
 [   0.  324.    4.    3.    3.]
 [   0.    6.  472.    0.   27.]
 [   2.    3.    1.  710.    9.]
 [   3.    1.   10.    5. 2715.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.329 | Acc: 51.250% | Wgt Acc: 43.462%
I - num batch: 70
I - Val -- Loss: 2.256 | Acc: 53.680% | Wgt Acc: 45.188% | Dur: 33.14s
I - Confusion Matrix: [row->prediction - col->label]
[[112.   1.   3.  38.  21.]
 [  0.  19.   9.   5.  10.]
 [  1.  50.  59.   9.  42.]
 [ 26.   8.  11.  78.  28.]
 [ 60.  56.  64.  74. 330.]]

I - Epoch: 139
I - Training: 
	I - Batch: 50 | Loss: 0.067 | Acc: 98.875% | Wgt Acc: 99.104%
	I - Batch: 100 | Loss: 0.078 | Acc: 98.500% | Wgt Acc: 98.721%
	I - Batch: 150 | Loss: 0.083 | Acc: 98.458% | Wgt Acc: 98.596%
	I - Batch: 200 | Loss: 0.085 | Acc: 98.312% | Wgt Acc: 98.333%
	I - Batch: 250 | Loss: 0.084 | Acc: 98.350% | Wgt Acc: 98.416%
	I - Batch: 300 | Loss: 0.087 | Acc: 98.188% | Wgt Acc: 98.257%
I - num batch: 313
I - Train -- Loss: 0.087 | Acc: 98.120% | Wgt Acc: 98.226% | LR: 1.250000e-04 | Dur: 193.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    2.   16.]
 [   0.  331.    4.    0.    2.]
 [   0.    3.  472.    2.   24.]
 [   4.    0.    1.  710.   16.]
 [   5.    0.   10.    5. 2708.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.424 | Acc: 52.000% | Wgt Acc: 43.413%
I - num batch: 70
I - Val -- Loss: 2.347 | Acc: 54.937% | Wgt Acc: 45.521% | Dur: 33.51s
I - Confusion Matrix: [row->prediction - col->label]
[[ 93.   2.   4.  34.  11.]
 [  0.  20.  14.   4.   9.]
 [  2.  54.  67.  10.  34.]
 [ 25.   5.   9.  82.  27.]
 [ 79.  53.  52.  74. 350.]]

I - Epoch: 140
I - Training: 
	I - Batch: 50 | Loss: 0.087 | Acc: 97.875% | Wgt Acc: 97.670%
	I - Batch: 100 | Loss: 0.087 | Acc: 98.000% | Wgt Acc: 97.988%
	I - Batch: 150 | Loss: 0.083 | Acc: 98.333% | Wgt Acc: 98.314%
	I - Batch: 200 | Loss: 0.081 | Acc: 98.469% | Wgt Acc: 98.454%
	I - Batch: 250 | Loss: 0.076 | Acc: 98.600% | Wgt Acc: 98.632%
	I - Batch: 300 | Loss: 0.073 | Acc: 98.708% | Wgt Acc: 98.730%
I - num batch: 313
I - Train -- Loss: 0.072 | Acc: 98.740% | Wgt Acc: 98.768% | LR: 1.250000e-04 | Dur: 193.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    2.   12.]
 [   1.  330.    4.    4.    1.]
 [   0.    1.  478.    0.   14.]
 [   0.    3.    1.  710.   10.]
 [   3.    0.    4.    3. 2729.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.399 | Acc: 51.125% | Wgt Acc: 44.293%
I - num batch: 70
I - Val -- Loss: 2.296 | Acc: 53.411% | Wgt Acc: 45.791% | Dur: 33.50s
I - Confusion Matrix: [row->prediction - col->label]
[[129.   3.   4.  54.  37.]
 [  0.  13.  14.   2.   6.]
 [  0.  39.  50.   7.  34.]
 [ 31.  14.  18.  91.  42.]
 [ 39.  65.  60.  50. 312.]]

I - Epoch: 141
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 98.625% | Wgt Acc: 98.890%
	I - Batch: 100 | Loss: 0.060 | Acc: 98.875% | Wgt Acc: 99.060%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.083% | Wgt Acc: 99.186%
	I - Batch: 200 | Loss: 0.057 | Acc: 99.094% | Wgt Acc: 99.214%
	I - Batch: 250 | Loss: 0.061 | Acc: 99.025% | Wgt Acc: 99.161%
	I - Batch: 300 | Loss: 0.058 | Acc: 99.104% | Wgt Acc: 99.209%
I - num batch: 313
I - Train -- Loss: 0.059 | Acc: 99.100% | Wgt Acc: 99.219% | LR: 1.250000e-04 | Dur: 193.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    8.]
 [   0.  332.    1.    0.    1.]
 [   0.    2.  483.    0.   13.]
 [   1.    0.    0.  714.    9.]
 [   2.    0.    3.    3. 2735.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.295 | Acc: 50.125% | Wgt Acc: 43.455%
I - num batch: 70
I - Val -- Loss: 2.187 | Acc: 52.513% | Wgt Acc: 45.410% | Dur: 33.55s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   1.   4.  31.  33.]
 [  0.  30.  24.   8.  14.]
 [  0.  25.  33.   4.  20.]
 [ 56.  24.  29. 112.  60.]
 [ 37.  54.  56.  49. 304.]]

I - Epoch: 142
I - Training: 
	I - Batch: 50 | Loss: 0.066 | Acc: 99.125% | Wgt Acc: 98.985%
	I - Batch: 100 | Loss: 0.060 | Acc: 99.062% | Wgt Acc: 99.092%
	I - Batch: 150 | Loss: 0.063 | Acc: 99.000% | Wgt Acc: 99.023%
	I - Batch: 200 | Loss: 0.064 | Acc: 99.000% | Wgt Acc: 99.071%
	I - Batch: 250 | Loss: 0.067 | Acc: 99.025% | Wgt Acc: 99.091%
	I - Batch: 300 | Loss: 0.066 | Acc: 99.021% | Wgt Acc: 99.129%
I - num batch: 313
I - Train -- Loss: 0.067 | Acc: 99.000% | Wgt Acc: 99.109% | LR: 1.250000e-04 | Dur: 193.75s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    9.]
 [   0.  332.    2.    0.    2.]
 [   0.    1.  483.    1.   15.]
 [   1.    1.    0.  711.    7.]
 [   2.    0.    2.    5. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.386 | Acc: 50.000% | Wgt Acc: 41.415%
I - num batch: 70
I - Val -- Loss: 2.316 | Acc: 53.321% | Wgt Acc: 43.748% | Dur: 33.53s
I - Confusion Matrix: [row->prediction - col->label]
[[101.   1.   2.  32.  15.]
 [  0.  20.  15.   5.   9.]
 [  0.  52.  51.   9.  32.]
 [ 34.   9.  13.  79.  32.]
 [ 64.  52.  65.  79. 343.]]

I - Epoch: 143
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.375% | Wgt Acc: 99.479%
	I - Batch: 100 | Loss: 0.049 | Acc: 99.562% | Wgt Acc: 99.612%
	I - Batch: 150 | Loss: 0.056 | Acc: 99.375% | Wgt Acc: 99.425%
	I - Batch: 200 | Loss: 0.060 | Acc: 99.219% | Wgt Acc: 99.330%
	I - Batch: 250 | Loss: 0.056 | Acc: 99.325% | Wgt Acc: 99.438%
	I - Batch: 300 | Loss: 0.058 | Acc: 99.250% | Wgt Acc: 99.290%
I - num batch: 313
I - Train -- Loss: 0.058 | Acc: 99.200% | Wgt Acc: 99.205% | LR: 1.250000e-04 | Dur: 193.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    6.]
 [   0.  331.    1.    2.    1.]
 [   0.    2.  481.    0.   13.]
 [   1.    1.    0.  714.    3.]
 [   2.    0.    5.    2. 2743.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.307 | Acc: 49.500% | Wgt Acc: 43.085%
I - num batch: 70
I - Val -- Loss: 2.226 | Acc: 52.154% | Wgt Acc: 44.664% | Dur: 33.55s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   1.   4.  39.  21.]
 [  1.  22.  17.  14.  12.]
 [  1.  55.  62.  16.  58.]
 [ 32.  13.  14.  72.  28.]
 [ 52.  43.  49.  63. 312.]]

I - Epoch: 144
I - Training: 
	I - Batch: 50 | Loss: 0.069 | Acc: 99.250% | Wgt Acc: 99.101%
	I - Batch: 100 | Loss: 0.055 | Acc: 99.438% | Wgt Acc: 99.446%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.208% | Wgt Acc: 99.212%
	I - Batch: 200 | Loss: 0.063 | Acc: 98.969% | Wgt Acc: 98.975%
	I - Batch: 250 | Loss: 0.060 | Acc: 99.100% | Wgt Acc: 99.111%
	I - Batch: 300 | Loss: 0.063 | Acc: 99.021% | Wgt Acc: 98.971%
I - num batch: 313
I - Train -- Loss: 0.064 | Acc: 99.020% | Wgt Acc: 98.966% | LR: 1.250000e-04 | Dur: 195.28s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    5.]
 [   0.  329.    5.    1.    1.]
 [   0.    4.  477.    0.   13.]
 [   1.    1.    0.  714.    7.]
 [   2.    0.    5.    3. 2740.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.522 | Acc: 49.625% | Wgt Acc: 40.493%
I - num batch: 70
I - Val -- Loss: 2.425 | Acc: 53.142% | Wgt Acc: 42.976% | Dur: 33.84s
I - Confusion Matrix: [row->prediction - col->label]
[[ 89.   1.   2.  35.   8.]
 [  2.  17.  10.   6.   6.]
 [  2.  57.  69.  19.  44.]
 [ 28.   5.   7.  63.  19.]
 [ 78.  54.  58.  81. 354.]]

I - Epoch: 145
I - Training: 
	I - Batch: 50 | Loss: 0.089 | Acc: 97.625% | Wgt Acc: 97.729%
	I - Batch: 100 | Loss: 0.090 | Acc: 97.750% | Wgt Acc: 97.932%
	I - Batch: 150 | Loss: 0.083 | Acc: 98.250% | Wgt Acc: 98.325%
	I - Batch: 200 | Loss: 0.087 | Acc: 98.031% | Wgt Acc: 98.118%
	I - Batch: 250 | Loss: 0.089 | Acc: 97.975% | Wgt Acc: 97.995%
	I - Batch: 300 | Loss: 0.085 | Acc: 98.062% | Wgt Acc: 98.088%
I - num batch: 313
I - Train -- Loss: 0.084 | Acc: 98.100% | Wgt Acc: 98.145% | LR: 1.250000e-04 | Dur: 195.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    3.   15.]
 [   0.  328.    4.    2.    3.]
 [   0.    4.  473.    0.   29.]
 [   2.    2.    0.  709.    9.]
 [   7.    0.   10.    5. 2710.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.257 | Acc: 51.125% | Wgt Acc: 44.545%
I - num batch: 70
I - Val -- Loss: 2.184 | Acc: 53.501% | Wgt Acc: 45.912% | Dur: 33.92s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   1.   2.  36.  21.]
 [  1.  24.  25.   7.  21.]
 [  2.  42.  54.  10.  27.]
 [ 41.  15.  19.  93.  45.]
 [ 47.  52.  46.  58. 317.]]

I - Epoch: 146
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 99.000% | Wgt Acc: 99.042%
	I - Batch: 100 | Loss: 0.059 | Acc: 99.250% | Wgt Acc: 99.254%
	I - Batch: 150 | Loss: 0.055 | Acc: 99.375% | Wgt Acc: 99.397%
	I - Batch: 200 | Loss: 0.056 | Acc: 99.344% | Wgt Acc: 99.308%
	I - Batch: 250 | Loss: 0.056 | Acc: 99.300% | Wgt Acc: 99.305%
	I - Batch: 300 | Loss: 0.057 | Acc: 99.208% | Wgt Acc: 99.244%
I - num batch: 313
I - Train -- Loss: 0.056 | Acc: 99.220% | Wgt Acc: 99.263% | LR: 1.250000e-04 | Dur: 195.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    3.    6.]
 [   0.  332.    1.    1.    1.]
 [   0.    2.  482.    0.   13.]
 [   2.    0.    0.  714.    4.]
 [   1.    0.    4.    1. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.420 | Acc: 52.500% | Wgt Acc: 43.413%
I - num batch: 70
I - Val -- Loss: 2.311 | Acc: 55.835% | Wgt Acc: 45.770% | Dur: 34.03s
I - Confusion Matrix: [row->prediction - col->label]
[[122.   3.   3.  44.  16.]
 [  0.  12.  11.   3.   5.]
 [  0.  47.  52.   6.  24.]
 [ 28.  14.  17.  80.  30.]
 [ 49.  58.  63.  71. 356.]]

I - Epoch: 147
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 99.250% | Wgt Acc: 99.061%
	I - Batch: 100 | Loss: 0.067 | Acc: 99.000% | Wgt Acc: 98.825%
	I - Batch: 150 | Loss: 0.065 | Acc: 98.958% | Wgt Acc: 98.927%
	I - Batch: 200 | Loss: 0.063 | Acc: 99.188% | Wgt Acc: 99.154%
	I - Batch: 250 | Loss: 0.059 | Acc: 99.275% | Wgt Acc: 99.222%
	I - Batch: 300 | Loss: 0.060 | Acc: 99.125% | Wgt Acc: 99.077%
I - num batch: 313
I - Train -- Loss: 0.059 | Acc: 99.100% | Wgt Acc: 99.077% | LR: 1.250000e-04 | Dur: 195.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    3.    7.]
 [   0.  331.    3.    3.    1.]
 [   0.    1.  481.    0.   13.]
 [   1.    2.    0.  711.    3.]
 [   3.    0.    3.    2. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.668 | Acc: 49.250% | Wgt Acc: 38.803%
I - num batch: 70
I - Val -- Loss: 2.527 | Acc: 53.591% | Wgt Acc: 42.045% | Dur: 33.95s
I - Confusion Matrix: [row->prediction - col->label]
[[ 88.   1.   4.  27.  15.]
 [  0.  10.   8.   1.   4.]
 [  0.  36.  39.   6.  16.]
 [ 46.  13.  14.  94.  30.]
 [ 65.  74.  81.  76. 366.]]

I - Epoch: 148
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 98.875% | Wgt Acc: 98.808%
	I - Batch: 100 | Loss: 0.061 | Acc: 99.000% | Wgt Acc: 98.987%
	I - Batch: 150 | Loss: 0.058 | Acc: 99.042% | Wgt Acc: 99.115%
	I - Batch: 200 | Loss: 0.057 | Acc: 99.062% | Wgt Acc: 99.161%
	I - Batch: 250 | Loss: 0.056 | Acc: 99.200% | Wgt Acc: 99.279%
	I - Batch: 300 | Loss: 0.055 | Acc: 99.229% | Wgt Acc: 99.304%
I - num batch: 313
I - Train -- Loss: 0.055 | Acc: 99.240% | Wgt Acc: 99.303% | LR: 1.250000e-04 | Dur: 195.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 692.    0.    0.    3.    6.]
 [   0.  333.    0.    1.    2.]
 [   0.    1.  483.    1.   10.]
 [   1.    0.    0.  712.    6.]
 [   1.    0.    4.    2. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.519 | Acc: 50.125% | Wgt Acc: 41.855%
I - num batch: 70
I - Val -- Loss: 2.427 | Acc: 53.232% | Wgt Acc: 43.605% | Dur: 33.89s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   2.   3.  30.  15.]
 [  0.  14.  14.   3.   6.]
 [  0.  45.  46.   8.  34.]
 [ 32.  14.  19.  87.  36.]
 [ 61.  59.  64.  76. 340.]]

I - Epoch: 149
I - Training: 
	I - Batch: 50 | Loss: 0.050 | Acc: 99.375% | Wgt Acc: 99.434%
	I - Batch: 100 | Loss: 0.052 | Acc: 99.250% | Wgt Acc: 99.251%
	I - Batch: 150 | Loss: 0.059 | Acc: 98.958% | Wgt Acc: 98.878%
	I - Batch: 200 | Loss: 0.063 | Acc: 98.906% | Wgt Acc: 98.821%
	I - Batch: 250 | Loss: 0.061 | Acc: 99.000% | Wgt Acc: 98.943%
	I - Batch: 300 | Loss: 0.065 | Acc: 98.833% | Wgt Acc: 98.714%
I - num batch: 313
I - Train -- Loss: 0.064 | Acc: 98.860% | Wgt Acc: 98.754% | LR: 1.250000e-04 | Dur: 195.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    3.    7.]
 [   0.  327.    0.    4.    2.]
 [   0.    4.  481.    0.   10.]
 [   2.    3.    0.  707.    8.]
 [   3.    0.    6.    5. 2739.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.358 | Acc: 51.750% | Wgt Acc: 44.663%
I - num batch: 70
I - Val -- Loss: 2.264 | Acc: 54.129% | Wgt Acc: 45.902% | Dur: 33.98s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   2.   4.  46.  26.]
 [  0.  17.  10.   3.  10.]
 [  1.  53.  68.  10.  43.]
 [ 29.  12.  14.  72.  23.]
 [ 52.  50.  50.  73. 329.]]

I - Epoch: 150
I - Training: 
	I - Batch: 50 | Loss: 0.050 | Acc: 99.500% | Wgt Acc: 99.328%
	I - Batch: 100 | Loss: 0.049 | Acc: 99.625% | Wgt Acc: 99.466%
	I - Batch: 150 | Loss: 0.057 | Acc: 99.208% | Wgt Acc: 99.122%
	I - Batch: 200 | Loss: 0.055 | Acc: 99.281% | Wgt Acc: 99.246%
	I - Batch: 250 | Loss: 0.054 | Acc: 99.275% | Wgt Acc: 99.266%
	I - Batch: 300 | Loss: 0.058 | Acc: 99.125% | Wgt Acc: 99.074%
I - num batch: 313
I - Train -- Loss: 0.060 | Acc: 99.060% | Wgt Acc: 99.020% | LR: 1.250000e-04 | Dur: 195.73s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    3.    7.]
 [   0.  333.    3.    1.    1.]
 [   0.    0.  478.    0.   12.]
 [   4.    1.    0.  714.    4.]
 [   4.    0.    6.    1. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.547 | Acc: 49.875% | Wgt Acc: 42.854%
I - num batch: 70
I - Val -- Loss: 2.417 | Acc: 52.424% | Wgt Acc: 44.071% | Dur: 34.03s
I - Confusion Matrix: [row->prediction - col->label]
[[124.   3.   5.  55.  33.]
 [  0.  16.  15.   4.   9.]
 [  3.  43.  57.  11.  39.]
 [ 20.  14.  13.  65.  28.]
 [ 52.  58.  56.  69. 322.]]

I - Epoch: 151
I - Training: 
	I - Batch: 50 | Loss: 0.095 | Acc: 97.875% | Wgt Acc: 97.585%
	I - Batch: 100 | Loss: 0.103 | Acc: 97.188% | Wgt Acc: 97.293%
	I - Batch: 150 | Loss: 0.101 | Acc: 97.250% | Wgt Acc: 97.340%
	I - Batch: 200 | Loss: 0.094 | Acc: 97.531% | Wgt Acc: 97.578%
	I - Batch: 250 | Loss: 0.093 | Acc: 97.625% | Wgt Acc: 97.659%
	I - Batch: 300 | Loss: 0.090 | Acc: 97.750% | Wgt Acc: 97.808%
I - num batch: 313
I - Train -- Loss: 0.089 | Acc: 97.840% | Wgt Acc: 97.901% | LR: 1.250000e-04 | Dur: 195.90s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    1.   13.]
 [   0.  326.    5.    4.    5.]
 [   0.    4.  474.    0.   27.]
 [   2.    4.    1.  705.   19.]
 [   7.    0.    7.    9. 2702.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.638 | Acc: 50.750% | Wgt Acc: 40.738%
I - num batch: 70
I - Val -- Loss: 2.518 | Acc: 53.770% | Wgt Acc: 42.817% | Dur: 34.09s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   2.   2.  33.  14.]
 [  0.  12.  14.   2.   8.]
 [  0.  35.  40.   6.  19.]
 [ 37.  14.  16.  88.  31.]
 [ 62.  71.  74.  75. 359.]]

I - Epoch: 152
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.375% | Wgt Acc: 99.498%
	I - Batch: 100 | Loss: 0.052 | Acc: 99.250% | Wgt Acc: 99.216%
	I - Batch: 150 | Loss: 0.054 | Acc: 99.125% | Wgt Acc: 99.148%
	I - Batch: 200 | Loss: 0.053 | Acc: 99.031% | Wgt Acc: 99.089%
	I - Batch: 250 | Loss: 0.054 | Acc: 99.050% | Wgt Acc: 99.063%
	I - Batch: 300 | Loss: 0.060 | Acc: 98.938% | Wgt Acc: 98.971%
I - num batch: 313
I - Train -- Loss: 0.059 | Acc: 98.940% | Wgt Acc: 98.975% | LR: 1.250000e-04 | Dur: 196.12s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    1.    7.]
 [   0.  332.    3.    0.    2.]
 [   0.    2.  476.    0.   18.]
 [   1.    0.    0.  715.    5.]
 [   3.    0.    8.    3. 2734.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.476 | Acc: 52.125% | Wgt Acc: 43.706%
I - num batch: 70
I - Val -- Loss: 2.392 | Acc: 55.386% | Wgt Acc: 46.272% | Dur: 34.15s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   2.  40.  19.]
 [  0.  21.  18.   6.  15.]
 [  1.  31.  43.   5.  15.]
 [ 36.  15.  24.  90.  40.]
 [ 41.  65.  59.  63. 342.]]

I - Epoch: 153
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 98.625% | Wgt Acc: 98.650%
	I - Batch: 100 | Loss: 0.064 | Acc: 98.500% | Wgt Acc: 98.475%
	I - Batch: 150 | Loss: 0.064 | Acc: 98.667% | Wgt Acc: 98.647%
	I - Batch: 200 | Loss: 0.063 | Acc: 98.719% | Wgt Acc: 98.694%
	I - Batch: 250 | Loss: 0.065 | Acc: 98.700% | Wgt Acc: 98.663%
	I - Batch: 300 | Loss: 0.064 | Acc: 98.812% | Wgt Acc: 98.794%
I - num batch: 313
I - Train -- Loss: 0.064 | Acc: 98.780% | Wgt Acc: 98.781% | LR: 1.250000e-04 | Dur: 194.86s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.    8.]
 [   0.  328.    3.    0.    1.]
 [   0.    3.  479.    0.   17.]
 [   3.    2.    0.  715.    9.]
 [   5.    1.    5.    2. 2731.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.387 | Acc: 50.750% | Wgt Acc: 43.965%
I - num batch: 70
I - Val -- Loss: 2.290 | Acc: 54.309% | Wgt Acc: 46.579% | Dur: 33.07s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   2.   1.  32.  20.]
 [  0.  27.  13.   6.  14.]
 [  0.  35.  54.   8.  26.]
 [ 63.  16.  22. 103.  48.]
 [ 38.  54.  56.  55. 323.]]

I - Epoch: 154
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 99.625% | Wgt Acc: 99.790%
	I - Batch: 100 | Loss: 0.046 | Acc: 99.562% | Wgt Acc: 99.565%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.458% | Wgt Acc: 99.492%
	I - Batch: 200 | Loss: 0.050 | Acc: 99.344% | Wgt Acc: 99.347%
	I - Batch: 250 | Loss: 0.049 | Acc: 99.375% | Wgt Acc: 99.396%
	I - Batch: 300 | Loss: 0.053 | Acc: 99.208% | Wgt Acc: 99.299%
I - num batch: 313
I - Train -- Loss: 0.053 | Acc: 99.180% | Wgt Acc: 99.259% | LR: 1.250000e-04 | Dur: 191.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    1.    4.]
 [   0.  332.    1.    1.    1.]
 [   0.    1.  482.    0.   17.]
 [   1.    1.    0.  716.    5.]
 [   3.    0.    4.    1. 2739.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.611 | Acc: 50.625% | Wgt Acc: 41.827%
I - num batch: 70
I - Val -- Loss: 2.500 | Acc: 53.770% | Wgt Acc: 43.822% | Dur: 33.16s
I - Confusion Matrix: [row->prediction - col->label]
[[114.   2.   5.  41.  21.]
 [  1.  21.  11.   6.   6.]
 [  0.  37.  45.   8.  24.]
 [ 26.  13.  17.  70.  31.]
 [ 58.  61.  68.  79. 349.]]

I - Epoch: 155
I - Training: 
	I - Batch: 50 | Loss: 0.062 | Acc: 98.625% | Wgt Acc: 98.640%
	I - Batch: 100 | Loss: 0.067 | Acc: 98.812% | Wgt Acc: 98.766%
	I - Batch: 150 | Loss: 0.065 | Acc: 98.917% | Wgt Acc: 98.889%
	I - Batch: 200 | Loss: 0.061 | Acc: 99.000% | Wgt Acc: 98.944%
	I - Batch: 250 | Loss: 0.056 | Acc: 99.125% | Wgt Acc: 99.114%
	I - Batch: 300 | Loss: 0.056 | Acc: 99.083% | Wgt Acc: 99.109%
I - num batch: 313
I - Train -- Loss: 0.057 | Acc: 99.080% | Wgt Acc: 99.086% | LR: 1.250000e-04 | Dur: 191.62s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    1.    5.]
 [   0.  328.    2.    2.    2.]
 [   0.    2.  482.    0.   15.]
 [   3.    4.    0.  715.    5.]
 [   1.    0.    3.    1. 2739.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.669 | Acc: 50.750% | Wgt Acc: 42.225%
I - num batch: 70
I - Val -- Loss: 2.525 | Acc: 53.950% | Wgt Acc: 44.320% | Dur: 33.07s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   2.   3.  44.  26.]
 [  0.  19.  13.   3.  12.]
 [  1.  35.  44.  10.  17.]
 [ 20.  11.  17.  73.  32.]
 [ 57.  67.  69.  74. 344.]]

I - Epoch: 156
I - Training: 
	I - Batch: 50 | Loss: 0.069 | Acc: 99.125% | Wgt Acc: 98.917%
	I - Batch: 100 | Loss: 0.062 | Acc: 99.312% | Wgt Acc: 99.190%
	I - Batch: 150 | Loss: 0.062 | Acc: 99.125% | Wgt Acc: 99.020%
	I - Batch: 200 | Loss: 0.057 | Acc: 99.188% | Wgt Acc: 99.105%
	I - Batch: 250 | Loss: 0.055 | Acc: 99.200% | Wgt Acc: 99.118%
	I - Batch: 300 | Loss: 0.054 | Acc: 99.208% | Wgt Acc: 99.141%
I - num batch: 313
I - Train -- Loss: 0.056 | Acc: 99.080% | Wgt Acc: 99.001% | LR: 1.250000e-04 | Dur: 191.57s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    5.    7.]
 [   0.  330.    3.    1.    1.]
 [   0.    3.  480.    0.    7.]
 [   2.    1.    0.  712.    7.]
 [   4.    0.    4.    1. 2744.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.365 | Acc: 49.125% | Wgt Acc: 43.413%
I - num batch: 70
I - Val -- Loss: 2.276 | Acc: 51.975% | Wgt Acc: 45.320% | Dur: 33.13s
I - Confusion Matrix: [row->prediction - col->label]
[[105.   1.   2.  37.  23.]
 [  0.  31.  20.  12.  24.]
 [  2.  44.  59.  14.  43.]
 [ 39.  11.  18.  82.  39.]
 [ 53.  47.  47.  59. 302.]]

I - Epoch: 157
I - Training: 
	I - Batch: 50 | Loss: 0.066 | Acc: 99.000% | Wgt Acc: 99.002%
	I - Batch: 100 | Loss: 0.065 | Acc: 98.812% | Wgt Acc: 98.757%
	I - Batch: 150 | Loss: 0.068 | Acc: 98.500% | Wgt Acc: 98.518%
	I - Batch: 200 | Loss: 0.065 | Acc: 98.531% | Wgt Acc: 98.508%
	I - Batch: 250 | Loss: 0.065 | Acc: 98.600% | Wgt Acc: 98.508%
	I - Batch: 300 | Loss: 0.062 | Acc: 98.688% | Wgt Acc: 98.623%
I - num batch: 313
I - Train -- Loss: 0.061 | Acc: 98.740% | Wgt Acc: 98.677% | LR: 1.250000e-04 | Dur: 191.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    2.    7.]
 [   0.  329.    4.    3.    2.]
 [   0.    2.  475.    0.   16.]
 [   3.    3.    0.  711.    8.]
 [   2.    0.    8.    3. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.410 | Acc: 50.500% | Wgt Acc: 43.189%
I - num batch: 70
I - Val -- Loss: 2.329 | Acc: 53.142% | Wgt Acc: 45.283% | Dur: 33.12s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   2.   3.  39.  21.]
 [  0.  19.  13.   7.  13.]
 [  1.  48.  55.   8.  35.]
 [ 43.  11.  14.  91.  44.]
 [ 46.  54.  61.  59. 318.]]

I - Epoch: 158
I - Training: 
	I - Batch: 50 | Loss: 0.081 | Acc: 98.000% | Wgt Acc: 97.912%
	I - Batch: 100 | Loss: 0.078 | Acc: 98.312% | Wgt Acc: 98.163%
	I - Batch: 150 | Loss: 0.074 | Acc: 98.458% | Wgt Acc: 98.383%
	I - Batch: 200 | Loss: 0.071 | Acc: 98.625% | Wgt Acc: 98.578%
	I - Batch: 250 | Loss: 0.073 | Acc: 98.600% | Wgt Acc: 98.519%
	I - Batch: 300 | Loss: 0.080 | Acc: 98.250% | Wgt Acc: 98.061%
I - num batch: 313
I - Train -- Loss: 0.084 | Acc: 98.220% | Wgt Acc: 98.012% | LR: 1.250000e-04 | Dur: 191.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    3.   10.]
 [   0.  318.    8.    3.    2.]
 [   0.   12.  472.    1.   16.]
 [   3.    2.    1.  709.   15.]
 [   2.    2.    6.    3. 2723.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.626 | Acc: 48.125% | Wgt Acc: 38.712%
I - num batch: 70
I - Val -- Loss: 2.495 | Acc: 51.706% | Wgt Acc: 41.727% | Dur: 33.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 91.   1.   7.  33.  11.]
 [  1.   9.  11.   2.   9.]
 [  1.  46.  55.   8.  46.]
 [ 42.  13.  12.  81.  25.]
 [ 64.  65.  61.  80. 340.]]

I - Epoch: 159
I - Training: 
	I - Batch: 50 | Loss: 0.086 | Acc: 98.125% | Wgt Acc: 98.350%
	I - Batch: 100 | Loss: 0.078 | Acc: 98.438% | Wgt Acc: 98.583%
	I - Batch: 150 | Loss: 0.075 | Acc: 98.583% | Wgt Acc: 98.638%
	I - Batch: 200 | Loss: 0.073 | Acc: 98.594% | Wgt Acc: 98.632%
	I - Batch: 250 | Loss: 0.073 | Acc: 98.475% | Wgt Acc: 98.529%
	I - Batch: 300 | Loss: 0.072 | Acc: 98.458% | Wgt Acc: 98.487%
I - num batch: 313
I - Train -- Loss: 0.072 | Acc: 98.500% | Wgt Acc: 98.519% | LR: 1.250000e-04 | Dur: 191.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    3.   14.]
 [   0.  332.    5.    4.    2.]
 [   0.    1.  477.    0.   17.]
 [   3.    1.    0.  707.    9.]
 [   6.    0.    5.    5. 2724.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.518 | Acc: 49.750% | Wgt Acc: 41.764%
I - num batch: 70
I - Val -- Loss: 2.391 | Acc: 53.142% | Wgt Acc: 44.452% | Dur: 33.11s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   2.   5.  40.  26.]
 [  1.  25.  15.   6.  11.]
 [  3.  42.  49.  11.  30.]
 [ 26.  11.  17.  79.  33.]
 [ 61.  54.  60.  68. 331.]]

I - Epoch: 160
I - Training: 
	I - Batch: 50 | Loss: 0.046 | Acc: 99.375% | Wgt Acc: 99.366%
	I - Batch: 100 | Loss: 0.057 | Acc: 99.125% | Wgt Acc: 99.046%
	I - Batch: 150 | Loss: 0.059 | Acc: 99.167% | Wgt Acc: 99.104%
	I - Batch: 200 | Loss: 0.056 | Acc: 99.031% | Wgt Acc: 99.081%
	I - Batch: 250 | Loss: 0.053 | Acc: 99.100% | Wgt Acc: 99.190%
	I - Batch: 300 | Loss: 0.054 | Acc: 99.062% | Wgt Acc: 99.140%
I - num batch: 313
I - Train -- Loss: 0.055 | Acc: 99.040% | Wgt Acc: 99.098% | LR: 1.250000e-04 | Dur: 191.55s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    6.]
 [   0.  331.    2.    3.    1.]
 [   0.    1.  481.    0.   12.]
 [   1.    2.    1.  713.   11.]
 [   2.    0.    3.    2. 2736.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.401 | Acc: 49.625% | Wgt Acc: 43.518%
I - num batch: 70
I - Val -- Loss: 2.305 | Acc: 52.154% | Wgt Acc: 45.367% | Dur: 33.13s
I - Confusion Matrix: [row->prediction - col->label]
[[110.   1.   4.  38.  29.]
 [  1.  20.  10.   1.  12.]
 [  3.  52.  62.  16.  47.]
 [ 41.  15.  16.  88.  42.]
 [ 44.  46.  54.  61. 301.]]

I - Epoch: 161
I - Training: 
	I - Batch: 50 | Loss: 0.078 | Acc: 97.875% | Wgt Acc: 97.488%
	I - Batch: 100 | Loss: 0.073 | Acc: 98.188% | Wgt Acc: 98.064%
	I - Batch: 150 | Loss: 0.071 | Acc: 98.333% | Wgt Acc: 98.265%
	I - Batch: 200 | Loss: 0.070 | Acc: 98.375% | Wgt Acc: 98.291%
	I - Batch: 250 | Loss: 0.073 | Acc: 98.400% | Wgt Acc: 98.238%
	I - Batch: 300 | Loss: 0.075 | Acc: 98.208% | Wgt Acc: 98.062%
I - num batch: 313
I - Train -- Loss: 0.075 | Acc: 98.200% | Wgt Acc: 98.075% | LR: 1.250000e-04 | Dur: 191.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    7.   12.]
 [   0.  327.    4.    2.    2.]
 [   0.    5.  475.    1.   16.]
 [   2.    2.    1.  700.   14.]
 [   6.    0.    7.    9. 2722.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.383 | Acc: 51.000% | Wgt Acc: 45.041%
I - num batch: 70
I - Val -- Loss: 2.293 | Acc: 52.513% | Wgt Acc: 46.024% | Dur: 33.08s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   2.   4.  55.  42.]
 [  2.  19.  15.   7.  12.]
 [  0.  41.  51.   5.  29.]
 [ 33.  19.  23.  89.  53.]
 [ 33.  53.  53.  48. 295.]]

I - Epoch: 162
I - Training: 
	I - Batch: 50 | Loss: 0.063 | Acc: 98.750% | Wgt Acc: 98.502%
	I - Batch: 100 | Loss: 0.068 | Acc: 98.625% | Wgt Acc: 98.591%
	I - Batch: 150 | Loss: 0.069 | Acc: 98.458% | Wgt Acc: 98.443%
	I - Batch: 200 | Loss: 0.065 | Acc: 98.625% | Wgt Acc: 98.643%
	I - Batch: 250 | Loss: 0.065 | Acc: 98.600% | Wgt Acc: 98.606%
	I - Batch: 300 | Loss: 0.065 | Acc: 98.625% | Wgt Acc: 98.603%
I - num batch: 313
I - Train -- Loss: 0.066 | Acc: 98.600% | Wgt Acc: 98.578% | LR: 1.250000e-04 | Dur: 191.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 684.    0.    0.    5.   12.]
 [   0.  332.    1.    3.    1.]
 [   0.    2.  478.    0.   13.]
 [   3.    0.    0.  707.   11.]
 [   7.    0.    8.    4. 2729.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.631 | Acc: 50.625% | Wgt Acc: 41.255%
I - num batch: 70
I - Val -- Loss: 2.521 | Acc: 53.411% | Wgt Acc: 43.235% | Dur: 33.13s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   2.   3.  32.  21.]
 [  0.   9.  11.   3.  10.]
 [  3.  49.  56.  13.  27.]
 [ 40.   9.   9.  82.  24.]
 [ 57.  65.  67.  74. 349.]]

I - Epoch: 163
I - Training: 
	I - Batch: 50 | Loss: 0.078 | Acc: 97.875% | Wgt Acc: 98.101%
	I - Batch: 100 | Loss: 0.071 | Acc: 98.250% | Wgt Acc: 98.352%
	I - Batch: 150 | Loss: 0.084 | Acc: 97.958% | Wgt Acc: 97.942%
	I - Batch: 200 | Loss: 0.083 | Acc: 98.031% | Wgt Acc: 98.059%
	I - Batch: 250 | Loss: 0.085 | Acc: 97.950% | Wgt Acc: 97.930%
	I - Batch: 300 | Loss: 0.079 | Acc: 98.167% | Wgt Acc: 98.152%
I - num batch: 313
I - Train -- Loss: 0.079 | Acc: 98.180% | Wgt Acc: 98.134% | LR: 1.250000e-04 | Dur: 191.41s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    0.    0.    3.   16.]
 [   0.  328.    4.    4.    3.]
 [   0.    4.  477.    1.   16.]
 [   7.    2.    0.  703.   13.]
 [   4.    0.    6.    8. 2718.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.692 | Acc: 49.625% | Wgt Acc: 42.135%
I - num batch: 70
I - Val -- Loss: 2.566 | Acc: 51.346% | Wgt Acc: 43.605% | Dur: 33.01s
I - Confusion Matrix: [row->prediction - col->label]
[[138.   3.   9.  65.  59.]
 [  0.   9.  11.   4.   5.]
 [  0.  29.  41.   3.  13.]
 [ 29.  23.  25.  81.  51.]
 [ 32.  70.  60.  51. 303.]]

I - Epoch: 164
I - Training: 
	I - Batch: 50 | Loss: 0.069 | Acc: 98.000% | Wgt Acc: 98.171%
	I - Batch: 100 | Loss: 0.074 | Acc: 97.875% | Wgt Acc: 98.027%
	I - Batch: 150 | Loss: 0.068 | Acc: 98.167% | Wgt Acc: 98.411%
	I - Batch: 200 | Loss: 0.068 | Acc: 98.344% | Wgt Acc: 98.493%
	I - Batch: 250 | Loss: 0.065 | Acc: 98.500% | Wgt Acc: 98.597%
	I - Batch: 300 | Loss: 0.059 | Acc: 98.708% | Wgt Acc: 98.810%
I - num batch: 313
I - Train -- Loss: 0.059 | Acc: 98.740% | Wgt Acc: 98.824% | LR: 1.250000e-04 | Dur: 191.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.   13.]
 [   0.  331.    0.    2.    1.]
 [   0.    2.  481.    0.   16.]
 [   2.    1.    0.  712.    9.]
 [   6.    0.    6.    3. 2727.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.711 | Acc: 49.125% | Wgt Acc: 39.054%
I - num batch: 70
I - Val -- Loss: 2.606 | Acc: 52.065% | Wgt Acc: 41.166% | Dur: 33.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 70.   1.   4.  26.  10.]
 [  0.  19.  14.   6.  11.]
 [  2.  44.  53.  14.  29.]
 [ 41.   8.  12.  80.  23.]
 [ 86.  62.  63.  78. 358.]]

I - Epoch: 165
I - Training: 
	I - Batch: 50 | Loss: 0.032 | Acc: 99.875% | Wgt Acc: 99.796%
	I - Batch: 100 | Loss: 0.037 | Acc: 99.750% | Wgt Acc: 99.739%
	I - Batch: 150 | Loss: 0.043 | Acc: 99.458% | Wgt Acc: 99.422%
	I - Batch: 200 | Loss: 0.042 | Acc: 99.500% | Wgt Acc: 99.456%
	I - Batch: 250 | Loss: 0.044 | Acc: 99.450% | Wgt Acc: 99.400%
	I - Batch: 300 | Loss: 0.048 | Acc: 99.375% | Wgt Acc: 99.321%
I - num batch: 313
I - Train -- Loss: 0.048 | Acc: 99.360% | Wgt Acc: 99.327% | LR: 1.250000e-04 | Dur: 191.69s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    3.]
 [   0.  330.    3.    0.    2.]
 [   0.    3.  482.    0.   10.]
 [   3.    1.    0.  716.    2.]
 [   0.    0.    2.    2. 2749.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.499 | Acc: 51.250% | Wgt Acc: 44.517%
I - num batch: 70
I - Val -- Loss: 2.429 | Acc: 52.424% | Wgt Acc: 45.770% | Dur: 33.03s
I - Confusion Matrix: [row->prediction - col->label]
[[126.   3.   5.  43.  44.]
 [  0.  18.  19.   4.  14.]
 [  1.  36.  48.   7.  24.]
 [ 29.  22.  19.  96.  53.]
 [ 43.  55.  55.  54. 296.]]

I - Epoch: 166
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.500% | Wgt Acc: 99.465%
	I - Batch: 100 | Loss: 0.042 | Acc: 99.500% | Wgt Acc: 99.464%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.417% | Wgt Acc: 99.281%
	I - Batch: 200 | Loss: 0.049 | Acc: 99.312% | Wgt Acc: 99.222%
	I - Batch: 250 | Loss: 0.052 | Acc: 99.175% | Wgt Acc: 99.083%
	I - Batch: 300 | Loss: 0.054 | Acc: 99.021% | Wgt Acc: 99.006%
I - num batch: 313
I - Train -- Loss: 0.053 | Acc: 99.060% | Wgt Acc: 99.047% | LR: 1.250000e-04 | Dur: 191.67s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    3.    6.]
 [   0.  331.    5.    2.    2.]
 [   0.    2.  479.    0.   16.]
 [   2.    1.    0.  713.    2.]
 [   2.    0.    3.    1. 2740.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.721 | Acc: 50.000% | Wgt Acc: 39.711%
I - num batch: 70
I - Val -- Loss: 2.619 | Acc: 53.411% | Wgt Acc: 42.150% | Dur: 33.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 91.   1.   3.  24.   9.]
 [  0.  14.  15.   1.   6.]
 [  0.  36.  40.   8.  21.]
 [ 37.  16.  13.  87.  32.]
 [ 71.  67.  75.  84. 363.]]

I - Epoch: 167
I - Training: 
	I - Batch: 50 | Loss: 0.109 | Acc: 96.875% | Wgt Acc: 96.599%
	I - Batch: 100 | Loss: 0.119 | Acc: 96.562% | Wgt Acc: 96.253%
	I - Batch: 150 | Loss: 0.113 | Acc: 96.875% | Wgt Acc: 96.652%
	I - Batch: 200 | Loss: 0.099 | Acc: 97.344% | Wgt Acc: 97.282%
	I - Batch: 250 | Loss: 0.092 | Acc: 97.575% | Wgt Acc: 97.516%
	I - Batch: 300 | Loss: 0.086 | Acc: 97.812% | Wgt Acc: 97.706%
I - num batch: 313
I - Train -- Loss: 0.086 | Acc: 97.820% | Wgt Acc: 97.711% | LR: 1.250000e-04 | Dur: 192.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 679.    0.    0.    5.   17.]
 [   0.  326.    6.    5.    3.]
 [   0.    6.  470.    1.   26.]
 [   5.    2.    0.  706.   10.]
 [  10.    0.   11.    2. 2710.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.594 | Acc: 51.375% | Wgt Acc: 42.435%
I - num batch: 70
I - Val -- Loss: 2.502 | Acc: 54.578% | Wgt Acc: 44.674% | Dur: 33.54s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   2.  35.  14.]
 [  1.  25.  22.   7.   9.]
 [  0.  42.  55.   9.  34.]
 [ 24.   9.   8.  74.  19.]
 [ 75.  57.  59.  79. 355.]]

I - Epoch: 168
I - Training: 
	I - Batch: 50 | Loss: 0.075 | Acc: 98.500% | Wgt Acc: 98.433%
	I - Batch: 100 | Loss: 0.073 | Acc: 98.625% | Wgt Acc: 98.522%
	I - Batch: 150 | Loss: 0.063 | Acc: 98.875% | Wgt Acc: 98.806%
	I - Batch: 200 | Loss: 0.065 | Acc: 98.812% | Wgt Acc: 98.757%
	I - Batch: 250 | Loss: 0.064 | Acc: 98.700% | Wgt Acc: 98.732%
	I - Batch: 300 | Loss: 0.060 | Acc: 98.875% | Wgt Acc: 98.923%
I - num batch: 313
I - Train -- Loss: 0.060 | Acc: 98.860% | Wgt Acc: 98.907% | LR: 1.250000e-04 | Dur: 193.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    4.   12.]
 [   0.  332.    1.    2.    1.]
 [   0.    1.  479.    0.   13.]
 [   3.    1.    0.  712.    8.]
 [   3.    0.    7.    1. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.481 | Acc: 48.625% | Wgt Acc: 41.709%
I - num batch: 70
I - Val -- Loss: 2.437 | Acc: 51.077% | Wgt Acc: 43.293% | Dur: 33.59s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   1.   1.  33.  14.]
 [  4.  27.  19.  14.  23.]
 [  0.  55.  60.  16.  48.]
 [ 35.   7.  14.  76.  32.]
 [ 68.  44.  52.  65. 314.]]

I - Epoch: 169
I - Training: 
	I - Batch: 50 | Loss: 0.042 | Acc: 99.375% | Wgt Acc: 99.261%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.562% | Wgt Acc: 99.510%
	I - Batch: 150 | Loss: 0.046 | Acc: 99.292% | Wgt Acc: 99.234%
	I - Batch: 200 | Loss: 0.042 | Acc: 99.469% | Wgt Acc: 99.425%
	I - Batch: 250 | Loss: 0.042 | Acc: 99.525% | Wgt Acc: 99.463%
	I - Batch: 300 | Loss: 0.042 | Acc: 99.458% | Wgt Acc: 99.385%
I - num batch: 313
I - Train -- Loss: 0.043 | Acc: 99.460% | Wgt Acc: 99.381% | LR: 1.250000e-04 | Dur: 193.10s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    3.]
 [   0.  333.    1.    2.    1.]
 [   0.    0.  481.    0.    6.]
 [   1.    1.    0.  713.    1.]
 [   2.    0.    5.    2. 2755.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.511 | Acc: 51.375% | Wgt Acc: 43.301%
I - num batch: 70
I - Val -- Loss: 2.410 | Acc: 54.039% | Wgt Acc: 45.283% | Dur: 33.36s
I - Confusion Matrix: [row->prediction - col->label]
[[115.   1.   2.  45.  25.]
 [  0.  17.  14.   6.   9.]
 [  0.  39.  49.   5.  26.]
 [ 41.  18.  16.  89.  39.]
 [ 43.  59.  65.  59. 332.]]

I - Epoch: 170
I - Training: 
	I - Batch: 50 | Loss: 0.044 | Acc: 99.750% | Wgt Acc: 99.601%
	I - Batch: 100 | Loss: 0.048 | Acc: 99.562% | Wgt Acc: 99.513%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.625% | Wgt Acc: 99.630%
	I - Batch: 200 | Loss: 0.039 | Acc: 99.625% | Wgt Acc: 99.641%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.600% | Wgt Acc: 99.636%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.604% | Wgt Acc: 99.642%
I - num batch: 313
I - Train -- Loss: 0.037 | Acc: 99.620% | Wgt Acc: 99.656% | LR: 1.250000e-04 | Dur: 192.72s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    6.]
 [   0.  333.    0.    1.    2.]
 [   0.    1.  487.    0.    2.]
 [   1.    0.    0.  716.    2.]
 [   2.    0.    0.    1. 2754.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.487 | Acc: 50.250% | Wgt Acc: 42.253%
I - num batch: 70
I - Val -- Loss: 2.389 | Acc: 53.501% | Wgt Acc: 44.701% | Dur: 33.31s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   1.   2.  32.  15.]
 [  2.  25.  18.   7.  13.]
 [  1.  42.  54.  13.  28.]
 [ 39.  14.  16.  88.  40.]
 [ 63.  52.  56.  64. 335.]]

I - Epoch: 171
I - Training: 
	I - Batch: 50 | Loss: 0.036 | Acc: 99.625% | Wgt Acc: 99.682%
	I - Batch: 100 | Loss: 0.032 | Acc: 99.688% | Wgt Acc: 99.771%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.708% | Wgt Acc: 99.754%
	I - Batch: 200 | Loss: 0.032 | Acc: 99.656% | Wgt Acc: 99.711%
	I - Batch: 250 | Loss: 0.032 | Acc: 99.675% | Wgt Acc: 99.718%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.562% | Wgt Acc: 99.605%
I - num batch: 313
I - Train -- Loss: 0.036 | Acc: 99.560% | Wgt Acc: 99.593% | LR: 1.250000e-04 | Dur: 193.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 693.    0.    0.    2.    4.]
 [   0.  333.    0.    1.    1.]
 [   0.    0.  484.    0.    7.]
 [   1.    1.    0.  716.    2.]
 [   0.    0.    3.    0. 2752.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.842 | Acc: 50.125% | Wgt Acc: 39.250%
I - num batch: 70
I - Val -- Loss: 2.761 | Acc: 53.411% | Wgt Acc: 41.679% | Dur: 33.71s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   1.   1.  41.  15.]
 [  0.  16.  12.   5.   5.]
 [  0.  41.  46.  11.  25.]
 [ 19.   7.   9.  57.  14.]
 [ 76.  69.  78.  90. 372.]]

I - Epoch: 172
I - Training: 
	I - Batch: 50 | Loss: 0.036 | Acc: 99.875% | Wgt Acc: 99.932%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.562% | Wgt Acc: 99.512%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.458% | Wgt Acc: 99.307%
	I - Batch: 200 | Loss: 0.041 | Acc: 99.469% | Wgt Acc: 99.350%
	I - Batch: 250 | Loss: 0.047 | Acc: 99.225% | Wgt Acc: 99.040%
	I - Batch: 300 | Loss: 0.049 | Acc: 99.167% | Wgt Acc: 99.009%
I - num batch: 313
I - Train -- Loss: 0.050 | Acc: 99.100% | Wgt Acc: 98.951% | LR: 1.250000e-04 | Dur: 194.49s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    1.    4.]
 [   0.  327.    6.    1.    1.]
 [   0.    6.  479.    0.    8.]
 [   1.    1.    0.  714.    6.]
 [   5.    0.    2.    3. 2747.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.653 | Acc: 51.375% | Wgt Acc: 42.666%
I - num batch: 70
I - Val -- Loss: 2.545 | Acc: 54.039% | Wgt Acc: 44.505% | Dur: 33.75s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   1.   3.  40.  30.]
 [  1.  23.  17.   6.  13.]
 [  0.  38.  42.   7.  20.]
 [ 23.   9.  14.  75.  24.]
 [ 57.  63.  70.  76. 344.]]

I - Epoch: 173
I - Training: 
	I - Batch: 50 | Loss: 0.037 | Acc: 99.625% | Wgt Acc: 99.788%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.688% | Wgt Acc: 99.669%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.375% | Wgt Acc: 99.341%
	I - Batch: 200 | Loss: 0.046 | Acc: 99.188% | Wgt Acc: 99.168%
	I - Batch: 250 | Loss: 0.051 | Acc: 99.075% | Wgt Acc: 99.019%
	I - Batch: 300 | Loss: 0.053 | Acc: 99.042% | Wgt Acc: 98.982%
I - num batch: 313
I - Train -- Loss: 0.052 | Acc: 99.060% | Wgt Acc: 99.012% | LR: 1.250000e-04 | Dur: 194.65s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    6.]
 [   0.  330.    1.    3.    2.]
 [   0.    2.  481.    0.   10.]
 [   1.    2.    1.  709.    6.]
 [   2.    0.    4.    5. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.516 | Acc: 47.625% | Wgt Acc: 41.513%
I - num batch: 70
I - Val -- Loss: 2.433 | Acc: 50.718% | Wgt Acc: 43.595% | Dur: 33.77s
I - Confusion Matrix: [row->prediction - col->label]
[[ 87.   1.   2.  24.  20.]
 [  4.  26.  21.  16.  28.]
 [  4.  54.  61.  17.  44.]
 [ 50.   8.  16.  88.  36.]
 [ 54.  45.  46.  59. 303.]]

I - Epoch: 174
I - Training: 
	I - Batch: 50 | Loss: 0.039 | Acc: 99.500% | Wgt Acc: 99.497%
	I - Batch: 100 | Loss: 0.042 | Acc: 99.500% | Wgt Acc: 99.475%
	I - Batch: 150 | Loss: 0.059 | Acc: 98.792% | Wgt Acc: 98.811%
	I - Batch: 200 | Loss: 0.062 | Acc: 98.812% | Wgt Acc: 98.800%
	I - Batch: 250 | Loss: 0.062 | Acc: 98.825% | Wgt Acc: 98.831%
	I - Batch: 300 | Loss: 0.062 | Acc: 98.833% | Wgt Acc: 98.791%
I - num batch: 313
I - Train -- Loss: 0.063 | Acc: 98.800% | Wgt Acc: 98.777% | LR: 1.250000e-04 | Dur: 194.52s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    5.    9.]
 [   0.  329.    3.    1.    3.]
 [   0.    5.  478.    0.   14.]
 [   2.    0.    0.  710.    7.]
 [   2.    0.    6.    3. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.689 | Acc: 50.375% | Wgt Acc: 41.478%
I - num batch: 70
I - Val -- Loss: 2.607 | Acc: 52.962% | Wgt Acc: 42.912% | Dur: 33.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 94.   1.   3.  30.  11.]
 [  0.  31.  21.   9.  18.]
 [  1.  44.  47.  10.  24.]
 [ 24.   6.  11.  66.  26.]
 [ 80.  52.  64.  89. 352.]]

I - Epoch: 175
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 99.500% | Wgt Acc: 99.620%
	I - Batch: 100 | Loss: 0.045 | Acc: 99.312% | Wgt Acc: 99.348%
	I - Batch: 150 | Loss: 0.043 | Acc: 99.292% | Wgt Acc: 99.302%
	I - Batch: 200 | Loss: 0.045 | Acc: 99.219% | Wgt Acc: 99.248%
	I - Batch: 250 | Loss: 0.046 | Acc: 99.200% | Wgt Acc: 99.178%
	I - Batch: 300 | Loss: 0.047 | Acc: 99.188% | Wgt Acc: 99.153%
I - num batch: 313
I - Train -- Loss: 0.049 | Acc: 99.200% | Wgt Acc: 99.153% | LR: 1.250000e-04 | Dur: 193.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    2.    7.]
 [   0.  332.    4.    0.    1.]
 [   0.    1.  480.    1.    8.]
 [   2.    1.    0.  714.    4.]
 [   4.    0.    3.    2. 2746.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.727 | Acc: 49.250% | Wgt Acc: 39.781%
I - num batch: 70
I - Val -- Loss: 2.645 | Acc: 52.424% | Wgt Acc: 41.854% | Dur: 33.38s
I - Confusion Matrix: [row->prediction - col->label]
[[ 91.   1.   2.  31.   8.]
 [  2.  24.  22.   9.  21.]
 [  1.  44.  47.  15.  26.]
 [ 25.   6.  10.  67.  21.]
 [ 80.  59.  65.  82. 355.]]

I - Epoch: 176
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 98.500% | Wgt Acc: 98.805%
	I - Batch: 100 | Loss: 0.063 | Acc: 98.500% | Wgt Acc: 98.736%
	I - Batch: 150 | Loss: 0.061 | Acc: 98.667% | Wgt Acc: 98.819%
	I - Batch: 200 | Loss: 0.057 | Acc: 98.781% | Wgt Acc: 98.934%
	I - Batch: 250 | Loss: 0.053 | Acc: 98.925% | Wgt Acc: 99.065%
	I - Batch: 300 | Loss: 0.051 | Acc: 98.979% | Wgt Acc: 99.109%
I - num batch: 313
I - Train -- Loss: 0.050 | Acc: 99.020% | Wgt Acc: 99.145% | LR: 1.250000e-04 | Dur: 192.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    1.   11.]
 [   0.  333.    0.    3.    1.]
 [   0.    0.  483.    0.   17.]
 [   1.    1.    0.  713.    4.]
 [   4.    0.    4.    2. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.773 | Acc: 49.250% | Wgt Acc: 41.122%
I - num batch: 70
I - Val -- Loss: 2.660 | Acc: 52.334% | Wgt Acc: 43.018% | Dur: 33.33s
I - Confusion Matrix: [row->prediction - col->label]
[[131.   4.   4.  56.  44.]
 [  0.  12.  11.   2.   9.]
 [  3.  34.  39.   9.  22.]
 [ 21.  13.  15.  71.  26.]
 [ 44.  71.  77.  66. 330.]]

I - Epoch: 177
I - Training: 
	I - Batch: 50 | Loss: 0.048 | Acc: 99.250% | Wgt Acc: 99.366%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.500% | Wgt Acc: 99.610%
	I - Batch: 150 | Loss: 0.033 | Acc: 99.625% | Wgt Acc: 99.714%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.594% | Wgt Acc: 99.654%
	I - Batch: 250 | Loss: 0.035 | Acc: 99.600% | Wgt Acc: 99.637%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.542% | Wgt Acc: 99.581%
I - num batch: 313
I - Train -- Loss: 0.036 | Acc: 99.540% | Wgt Acc: 99.564% | LR: 1.250000e-04 | Dur: 192.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    8.]
 [   0.  333.    2.    0.    1.]
 [   0.    1.  484.    0.    2.]
 [   1.    0.    0.  717.    3.]
 [   2.    0.    1.    1. 2752.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.693 | Acc: 48.125% | Wgt Acc: 39.362%
I - num batch: 70
I - Val -- Loss: 2.660 | Acc: 51.167% | Wgt Acc: 41.235% | Dur: 33.42s
I - Confusion Matrix: [row->prediction - col->label]
[[ 72.   1.   1.  20.   7.]
 [  1.  18.  17.   8.  14.]
 [  5.  55.  64.  24.  46.]
 [ 34.   8.  12.  73.  21.]
 [ 87.  52.  52.  79. 343.]]

I - Epoch: 178
I - Training: 
	I - Batch: 50 | Loss: 0.042 | Acc: 99.500% | Wgt Acc: 99.596%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.562% | Wgt Acc: 99.635%
	I - Batch: 150 | Loss: 0.038 | Acc: 99.458% | Wgt Acc: 99.432%
	I - Batch: 200 | Loss: 0.043 | Acc: 99.375% | Wgt Acc: 99.328%
	I - Batch: 250 | Loss: 0.049 | Acc: 99.050% | Wgt Acc: 99.085%
	I - Batch: 300 | Loss: 0.049 | Acc: 99.083% | Wgt Acc: 99.113%
I - num batch: 313
I - Train -- Loss: 0.049 | Acc: 99.100% | Wgt Acc: 99.120% | LR: 1.250000e-04 | Dur: 192.99s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    2.    8.]
 [   0.  332.    2.    2.    3.]
 [   0.    2.  481.    0.    9.]
 [   3.    0.    0.  712.    6.]
 [   1.    0.    4.    3. 2740.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.503 | Acc: 49.000% | Wgt Acc: 42.232%
I - num batch: 70
I - Val -- Loss: 2.410 | Acc: 52.154% | Wgt Acc: 44.129% | Dur: 33.46s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   1.   1.  33.  15.]
 [  1.  29.  21.   6.  15.]
 [  2.  43.  60.  18.  42.]
 [ 40.  11.  15.  78.  37.]
 [ 64.  50.  49.  69. 322.]]

I - Epoch: 179
I - Training: 
	I - Batch: 50 | Loss: 0.036 | Acc: 99.500% | Wgt Acc: 99.722%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.500% | Wgt Acc: 99.582%
	I - Batch: 150 | Loss: 0.038 | Acc: 99.500% | Wgt Acc: 99.628%
	I - Batch: 200 | Loss: 0.040 | Acc: 99.562% | Wgt Acc: 99.623%
	I - Batch: 250 | Loss: 0.038 | Acc: 99.600% | Wgt Acc: 99.651%
	I - Batch: 300 | Loss: 0.037 | Acc: 99.604% | Wgt Acc: 99.649%
I - num batch: 313
I - Train -- Loss: 0.037 | Acc: 99.600% | Wgt Acc: 99.634% | LR: 1.250000e-04 | Dur: 192.68s
I - Confusion Matrix: [row->prediction - col->label]
[[ 693.    0.    0.    1.    3.]
 [   0.  332.    1.    1.    2.]
 [   0.    1.  486.    0.    2.]
 [   1.    1.    0.  716.    6.]
 [   0.    0.    0.    1. 2753.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.778 | Acc: 49.375% | Wgt Acc: 39.117%
I - num batch: 70
I - Val -- Loss: 2.665 | Acc: 52.783% | Wgt Acc: 41.526% | Dur: 33.30s
I - Confusion Matrix: [row->prediction - col->label]
[[ 92.   1.   3.  36.  14.]
 [  0.  12.  12.   2.   6.]
 [  2.  47.  53.  11.  25.]
 [ 25.   7.  11.  68.  23.]
 [ 80.  67.  67.  87. 363.]]

I - Epoch: 180
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 99.500% | Wgt Acc: 99.301%
	I - Batch: 100 | Loss: 0.036 | Acc: 99.438% | Wgt Acc: 99.371%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.458% | Wgt Acc: 99.403%
	I - Batch: 200 | Loss: 0.038 | Acc: 99.375% | Wgt Acc: 99.333%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.375% | Wgt Acc: 99.319%
	I - Batch: 300 | Loss: 0.041 | Acc: 99.292% | Wgt Acc: 99.233%
I - num batch: 313
I - Train -- Loss: 0.041 | Acc: 99.280% | Wgt Acc: 99.242% | LR: 1.250000e-04 | Dur: 192.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    5.]
 [   0.  330.    1.    1.    0.]
 [   0.    2.  481.    1.   11.]
 [   1.    2.    0.  715.    3.]
 [   2.    0.    5.    0. 2747.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.445 | Acc: 51.750% | Wgt Acc: 46.011%
I - num batch: 70
I - Val -- Loss: 2.390 | Acc: 52.693% | Wgt Acc: 46.135% | Dur: 33.24s
I - Confusion Matrix: [row->prediction - col->label]
[[117.   3.   5.  37.  29.]
 [  0.  23.  17.   8.  23.]
 [  1.  47.  59.  15.  45.]
 [ 35.  13.  11.  88.  34.]
 [ 46.  48.  54.  56. 300.]]

I - Epoch: 181
I - Training: 
	I - Batch: 50 | Loss: 0.056 | Acc: 98.500% | Wgt Acc: 98.678%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.188% | Wgt Acc: 99.291%
	I - Batch: 150 | Loss: 0.037 | Acc: 99.375% | Wgt Acc: 99.479%
	I - Batch: 200 | Loss: 0.038 | Acc: 99.438% | Wgt Acc: 99.518%
	I - Batch: 250 | Loss: 0.040 | Acc: 99.425% | Wgt Acc: 99.500%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.458% | Wgt Acc: 99.531%
I - num batch: 313
I - Train -- Loss: 0.039 | Acc: 99.460% | Wgt Acc: 99.521% | LR: 1.250000e-04 | Dur: 192.58s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    3.]
 [   0.  332.    0.    1.    2.]
 [   0.    2.  486.    0.    8.]
 [   1.    0.    0.  716.    5.]
 [   2.    0.    1.    1. 2748.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.786 | Acc: 46.250% | Wgt Acc: 37.336%
I - num batch: 70
I - Val -- Loss: 2.699 | Acc: 49.461% | Wgt Acc: 39.409% | Dur: 33.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 76.   1.   2.  24.   9.]
 [  1.  15.  11.  12.  19.]
 [  3.  57.  61.  23.  44.]
 [ 36.   5.  10.  62.  22.]
 [ 83.  56.  62.  83. 337.]]

I - Epoch: 182
I - Training: 
	I - Batch: 50 | Loss: 0.031 | Acc: 99.500% | Wgt Acc: 99.363%
	I - Batch: 100 | Loss: 0.034 | Acc: 99.500% | Wgt Acc: 99.483%
	I - Batch: 150 | Loss: 0.031 | Acc: 99.667% | Wgt Acc: 99.656%
	I - Batch: 200 | Loss: 0.031 | Acc: 99.688% | Wgt Acc: 99.646%
	I - Batch: 250 | Loss: 0.032 | Acc: 99.600% | Wgt Acc: 99.605%
	I - Batch: 300 | Loss: 0.032 | Acc: 99.646% | Wgt Acc: 99.633%
I - num batch: 313
I - Train -- Loss: 0.031 | Acc: 99.660% | Wgt Acc: 99.648% | LR: 1.250000e-04 | Dur: 191.81s
I - Confusion Matrix: [row->prediction - col->label]
[[ 693.    0.    0.    2.    1.]
 [   0.  333.    1.    1.    0.]
 [   0.    1.  484.    0.    6.]
 [   1.    0.    0.  716.    2.]
 [   0.    0.    2.    0. 2757.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.546 | Acc: 50.625% | Wgt Acc: 43.043%
I - num batch: 70
I - Val -- Loss: 2.486 | Acc: 52.334% | Wgt Acc: 43.981% | Dur: 32.88s
I - Confusion Matrix: [row->prediction - col->label]
[[111.   1.   3.  40.  27.]
 [  0.  19.  17.  11.  19.]
 [  2.  43.  49.   6.  24.]
 [ 35.  18.  14.  83.  40.]
 [ 51.  53.  63.  64. 321.]]

I - Epoch: 183
I - Training: 
	I - Batch: 50 | Loss: 0.037 | Acc: 99.750% | Wgt Acc: 99.751%
	I - Batch: 100 | Loss: 0.033 | Acc: 99.750% | Wgt Acc: 99.807%
	I - Batch: 150 | Loss: 0.034 | Acc: 99.792% | Wgt Acc: 99.812%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.656% | Wgt Acc: 99.700%
	I - Batch: 250 | Loss: 0.034 | Acc: 99.600% | Wgt Acc: 99.639%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.500% | Wgt Acc: 99.527%
I - num batch: 313
I - Train -- Loss: 0.037 | Acc: 99.480% | Wgt Acc: 99.523% | LR: 1.250000e-04 | Dur: 190.71s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    2.    9.]
 [   0.  334.    0.    0.    0.]
 [   0.    0.  485.    0.    5.]
 [   3.    0.    0.  716.    2.]
 [   2.    0.    2.    1. 2750.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.626 | Acc: 50.250% | Wgt Acc: 42.945%
I - num batch: 70
I - Val -- Loss: 2.521 | Acc: 52.244% | Wgt Acc: 44.590% | Dur: 32.88s
I - Confusion Matrix: [row->prediction - col->label]
[[ 97.   3.   2.  34.  26.]
 [  2.  27.  17.   8.  12.]
 [  2.  42.  55.   6.  28.]
 [ 46.  16.  20.  88.  50.]
 [ 52.  46.  52.  68. 315.]]

I - Epoch: 184
I - Training: 
	I - Batch: 50 | Loss: 0.047 | Acc: 99.500% | Wgt Acc: 99.599%
	I - Batch: 100 | Loss: 0.045 | Acc: 99.500% | Wgt Acc: 99.550%
	I - Batch: 150 | Loss: 0.037 | Acc: 99.667% | Wgt Acc: 99.701%
	I - Batch: 200 | Loss: 0.035 | Acc: 99.656% | Wgt Acc: 99.725%
	I - Batch: 250 | Loss: 0.035 | Acc: 99.575% | Wgt Acc: 99.599%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.479% | Wgt Acc: 99.491%
I - num batch: 313
I - Train -- Loss: 0.037 | Acc: 99.420% | Wgt Acc: 99.431% | LR: 1.250000e-04 | Dur: 190.92s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    3.    4.]
 [   0.  332.    0.    1.    0.]
 [   0.    0.  487.    0.    8.]
 [   2.    2.    0.  712.    4.]
 [   2.    0.    0.    3. 2750.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.502 | Acc: 51.500% | Wgt Acc: 45.634%
I - num batch: 70
I - Val -- Loss: 2.457 | Acc: 53.501% | Wgt Acc: 46.854% | Dur: 33.13s
I - Confusion Matrix: [row->prediction - col->label]
[[121.   1.   3.  36.  34.]
 [  1.  18.  12.   6.  14.]
 [  2.  58.  67.  21.  49.]
 [ 34.   9.  15.  86.  30.]
 [ 41.  48.  49.  55. 304.]]

I - Epoch: 185
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 98.875% | Wgt Acc: 98.612%
	I - Batch: 100 | Loss: 0.048 | Acc: 98.938% | Wgt Acc: 98.767%
	I - Batch: 150 | Loss: 0.052 | Acc: 98.833% | Wgt Acc: 98.620%
	I - Batch: 200 | Loss: 0.048 | Acc: 99.000% | Wgt Acc: 98.785%
	I - Batch: 250 | Loss: 0.050 | Acc: 98.975% | Wgt Acc: 98.830%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.979% | Wgt Acc: 98.836%
I - num batch: 313
I - Train -- Loss: 0.052 | Acc: 98.980% | Wgt Acc: 98.844% | LR: 1.250000e-04 | Dur: 192.22s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.    8.]
 [   0.  327.    5.    2.    2.]
 [   0.    5.  478.    0.    9.]
 [   3.    2.    0.  715.    4.]
 [   5.    0.    4.    0. 2743.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.543 | Acc: 49.000% | Wgt Acc: 41.876%
I - num batch: 70
I - Val -- Loss: 2.523 | Acc: 51.346% | Wgt Acc: 43.187% | Dur: 33.25s
I - Confusion Matrix: [row->prediction - col->label]
[[100.   1.   2.  38.  26.]
 [  2.  17.  16.   7.  12.]
 [  1.  59.  62.  15.  50.]
 [ 37.   7.  13.  76.  26.]
 [ 59.  50.  53.  68. 317.]]

I - Epoch: 186
I - Training: 
	I - Batch: 50 | Loss: 0.088 | Acc: 97.625% | Wgt Acc: 97.367%
	I - Batch: 100 | Loss: 0.109 | Acc: 97.000% | Wgt Acc: 96.858%
	I - Batch: 150 | Loss: 0.116 | Acc: 96.667% | Wgt Acc: 96.389%
	I - Batch: 200 | Loss: 0.115 | Acc: 96.531% | Wgt Acc: 96.450%
	I - Batch: 250 | Loss: 0.110 | Acc: 96.650% | Wgt Acc: 96.676%
	I - Batch: 300 | Loss: 0.105 | Acc: 96.875% | Wgt Acc: 96.905%
I - num batch: 313
I - Train -- Loss: 0.103 | Acc: 96.980% | Wgt Acc: 97.018% | LR: 1.250000e-04 | Dur: 194.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 683.    0.    0.    5.   21.]
 [   0.  324.    6.    6.    5.]
 [   0.    7.  462.    1.   46.]
 [   5.    3.    1.  702.   16.]
 [   6.    0.   18.    5. 2678.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.569 | Acc: 52.375% | Wgt Acc: 45.439%
I - num batch: 70
I - Val -- Loss: 2.487 | Acc: 53.591% | Wgt Acc: 46.299% | Dur: 33.45s
I - Confusion Matrix: [row->prediction - col->label]
[[113.   2.   1.  37.  38.]
 [  0.  22.  15.   3.  10.]
 [  0.  27.  40.   3.  13.]
 [ 58.  20.  27. 113.  61.]
 [ 28.  63.  63.  48. 309.]]

I - Epoch: 187
I - Training: 
	I - Batch: 50 | Loss: 0.043 | Acc: 99.375% | Wgt Acc: 99.544%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.375% | Wgt Acc: 99.596%
	I - Batch: 150 | Loss: 0.039 | Acc: 99.458% | Wgt Acc: 99.665%
	I - Batch: 200 | Loss: 0.057 | Acc: 98.844% | Wgt Acc: 98.878%
	I - Batch: 250 | Loss: 0.061 | Acc: 98.750% | Wgt Acc: 98.779%
	I - Batch: 300 | Loss: 0.060 | Acc: 98.688% | Wgt Acc: 98.793%
I - num batch: 313
I - Train -- Loss: 0.061 | Acc: 98.720% | Wgt Acc: 98.808% | LR: 1.250000e-04 | Dur: 194.87s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    3.   16.]
 [   0.  331.    3.    2.    2.]
 [   0.    2.  480.    0.   17.]
 [   1.    0.    0.  713.    5.]
 [   7.    1.    4.    1. 2726.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.602 | Acc: 51.875% | Wgt Acc: 43.259%
I - num batch: 70
I - Val -- Loss: 2.518 | Acc: 54.309% | Wgt Acc: 44.764% | Dur: 33.92s
I - Confusion Matrix: [row->prediction - col->label]
[[104.   1.   3.  37.  20.]
 [  1.  22.  14.   6.  16.]
 [  4.  49.  52.  20.  24.]
 [ 30.   8.  15.  80.  24.]
 [ 60.  54.  62.  61. 347.]]

I - Epoch: 188
I - Training: 
	I - Batch: 50 | Loss: 0.050 | Acc: 98.625% | Wgt Acc: 99.132%
	I - Batch: 100 | Loss: 0.054 | Acc: 98.562% | Wgt Acc: 98.761%
	I - Batch: 150 | Loss: 0.054 | Acc: 98.792% | Wgt Acc: 98.881%
	I - Batch: 200 | Loss: 0.052 | Acc: 98.875% | Wgt Acc: 98.874%
	I - Batch: 250 | Loss: 0.051 | Acc: 98.875% | Wgt Acc: 98.896%
	I - Batch: 300 | Loss: 0.052 | Acc: 98.854% | Wgt Acc: 98.861%
I - num batch: 313
I - Train -- Loss: 0.052 | Acc: 98.840% | Wgt Acc: 98.875% | LR: 1.250000e-04 | Dur: 194.17s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.   13.]
 [   0.  331.    4.    3.    1.]
 [   0.    2.  480.    0.   14.]
 [   2.    1.    0.  713.    6.]
 [   6.    0.    3.    1. 2732.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.536 | Acc: 51.500% | Wgt Acc: 43.539%
I - num batch: 70
I - Val -- Loss: 2.489 | Acc: 53.680% | Wgt Acc: 44.939% | Dur: 33.39s
I - Confusion Matrix: [row->prediction - col->label]
[[108.   1.   4.  47.  24.]
 [  1.  17.  14.   4.   9.]
 [  2.  55.  64.  19.  39.]
 [ 39.   7.   9.  75.  25.]
 [ 49.  54.  55.  59. 334.]]

I - Epoch: 189
I - Training: 
	I - Batch: 50 | Loss: 0.047 | Acc: 99.375% | Wgt Acc: 99.238%
	I - Batch: 100 | Loss: 0.044 | Acc: 99.438% | Wgt Acc: 99.426%
	I - Batch: 150 | Loss: 0.044 | Acc: 99.333% | Wgt Acc: 99.377%
	I - Batch: 200 | Loss: 0.047 | Acc: 99.094% | Wgt Acc: 99.067%
	I - Batch: 250 | Loss: 0.046 | Acc: 99.125% | Wgt Acc: 99.173%
	I - Batch: 300 | Loss: 0.045 | Acc: 99.125% | Wgt Acc: 99.160%
I - num batch: 313
I - Train -- Loss: 0.044 | Acc: 99.160% | Wgt Acc: 99.195% | LR: 1.250000e-04 | Dur: 193.23s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    3.    5.]
 [   0.  331.    2.    1.    2.]
 [   0.    3.  484.    1.   10.]
 [   1.    0.    0.  712.    8.]
 [   3.    0.    1.    2. 2741.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.626 | Acc: 51.750% | Wgt Acc: 43.762%
I - num batch: 70
I - Val -- Loss: 2.546 | Acc: 54.039% | Wgt Acc: 45.119% | Dur: 33.48s
I - Confusion Matrix: [row->prediction - col->label]
[[118.   3.   5.  54.  30.]
 [  0.  20.  15.   2.  14.]
 [  1.  40.  51.   8.  25.]
 [ 30.   7.  11.  77.  26.]
 [ 50.  64.  64.  63. 336.]]

I - Epoch: 190
I - Training: 
	I - Batch: 50 | Loss: 0.041 | Acc: 99.125% | Wgt Acc: 98.835%
	I - Batch: 100 | Loss: 0.049 | Acc: 98.938% | Wgt Acc: 98.774%
	I - Batch: 150 | Loss: 0.042 | Acc: 99.083% | Wgt Acc: 99.061%
	I - Batch: 200 | Loss: 0.043 | Acc: 99.219% | Wgt Acc: 99.186%
	I - Batch: 250 | Loss: 0.040 | Acc: 99.325% | Wgt Acc: 99.322%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.417% | Wgt Acc: 99.399%
I - num batch: 313
I - Train -- Loss: 0.038 | Acc: 99.420% | Wgt Acc: 99.411% | LR: 1.250000e-04 | Dur: 191.89s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    1.    6.]
 [   0.  331.    2.    1.    1.]
 [   0.    3.  484.    0.    5.]
 [   2.    0.    0.  715.    4.]
 [   1.    0.    1.    2. 2750.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.709 | Acc: 49.375% | Wgt Acc: 40.968%
I - num batch: 70
I - Val -- Loss: 2.581 | Acc: 52.424% | Wgt Acc: 43.362% | Dur: 33.04s
I - Confusion Matrix: [row->prediction - col->label]
[[ 93.   1.   4.  39.  21.]
 [  0.  29.  20.   3.  24.]
 [  1.  32.  47.  15.  22.]
 [ 29.  11.  15.  80.  29.]
 [ 76.  61.  60.  67. 335.]]

I - Epoch: 191
I - Training: 
	I - Batch: 50 | Loss: 0.040 | Acc: 99.375% | Wgt Acc: 99.177%
	I - Batch: 100 | Loss: 0.041 | Acc: 99.375% | Wgt Acc: 99.290%
	I - Batch: 150 | Loss: 0.039 | Acc: 99.417% | Wgt Acc: 99.401%
	I - Batch: 200 | Loss: 0.038 | Acc: 99.406% | Wgt Acc: 99.346%
	I - Batch: 250 | Loss: 0.039 | Acc: 99.375% | Wgt Acc: 99.347%
	I - Batch: 300 | Loss: 0.039 | Acc: 99.396% | Wgt Acc: 99.371%
I - num batch: 313
I - Train -- Loss: 0.039 | Acc: 99.400% | Wgt Acc: 99.367% | LR: 1.250000e-04 | Dur: 191.15s
I - Confusion Matrix: [row->prediction - col->label]
[[ 686.    0.    0.    2.    5.]
 [   0.  334.    1.    1.    1.]
 [   0.    0.  484.    0.    4.]
 [   2.    0.    0.  714.    4.]
 [   6.    0.    2.    2. 2752.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.584 | Acc: 48.875% | Wgt Acc: 41.492%
I - num batch: 70
I - Val -- Loss: 2.498 | Acc: 51.436% | Wgt Acc: 43.214% | Dur: 32.80s
I - Confusion Matrix: [row->prediction - col->label]
[[ 98.   1.   3.  35.  27.]
 [  1.  13.  12.   5.   8.]
 [  0.  51.  59.  14.  39.]
 [ 48.  14.  14.  87.  41.]
 [ 52.  55.  58.  63. 316.]]

I - Epoch: 192
I - Training: 
	I - Batch: 50 | Loss: 0.059 | Acc: 98.750% | Wgt Acc: 98.369%
	I - Batch: 100 | Loss: 0.057 | Acc: 98.688% | Wgt Acc: 98.399%
	I - Batch: 150 | Loss: 0.052 | Acc: 98.875% | Wgt Acc: 98.710%
	I - Batch: 200 | Loss: 0.055 | Acc: 98.844% | Wgt Acc: 98.695%
	I - Batch: 250 | Loss: 0.063 | Acc: 98.575% | Wgt Acc: 98.494%
	I - Batch: 300 | Loss: 0.064 | Acc: 98.479% | Wgt Acc: 98.388%
I - num batch: 313
I - Train -- Loss: 0.063 | Acc: 98.500% | Wgt Acc: 98.433% | LR: 1.250000e-04 | Dur: 190.44s
I - Confusion Matrix: [row->prediction - col->label]
[[ 685.    0.    0.    2.   13.]
 [   0.  328.    5.    3.    3.]
 [   0.    4.  476.    1.   16.]
 [   4.    1.    0.  709.    7.]
 [   5.    1.    6.    4. 2727.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.693 | Acc: 48.625% | Wgt Acc: 40.319%
I - num batch: 70
I - Val -- Loss: 2.643 | Acc: 51.077% | Wgt Acc: 41.679% | Dur: 32.79s
I - Confusion Matrix: [row->prediction - col->label]
[[ 83.   1.   1.  29.   8.]
 [  0.  17.  14.   3.  15.]
 [  3.  52.  66.  15.  52.]
 [ 24.   9.   9.  68.  21.]
 [ 89.  55.  56.  89. 335.]]

I - Epoch: 193
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 98.875% | Wgt Acc: 98.745%
	I - Batch: 100 | Loss: 0.062 | Acc: 98.500% | Wgt Acc: 98.411%
	I - Batch: 150 | Loss: 0.056 | Acc: 98.792% | Wgt Acc: 98.687%
	I - Batch: 200 | Loss: 0.057 | Acc: 98.844% | Wgt Acc: 98.739%
	I - Batch: 250 | Loss: 0.066 | Acc: 98.600% | Wgt Acc: 98.412%
	I - Batch: 300 | Loss: 0.069 | Acc: 98.542% | Wgt Acc: 98.318%
I - num batch: 313
I - Train -- Loss: 0.068 | Acc: 98.580% | Wgt Acc: 98.373% | LR: 1.250000e-04 | Dur: 190.39s
I - Confusion Matrix: [row->prediction - col->label]
[[ 690.    0.    0.    1.    7.]
 [   0.  323.   11.    0.    3.]
 [   0.    7.  468.    0.   18.]
 [   1.    3.    0.  715.    5.]
 [   3.    1.    8.    3. 2733.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.572 | Acc: 49.000% | Wgt Acc: 41.269%
I - num batch: 70
I - Val -- Loss: 2.507 | Acc: 52.154% | Wgt Acc: 43.357% | Dur: 32.82s
I - Confusion Matrix: [row->prediction - col->label]
[[ 77.   1.   0.  25.  13.]
 [  2.  29.  17.  14.  21.]
 [  4.  49.  59.  18.  43.]
 [ 47.   5.  12.  83.  21.]
 [ 69.  50.  58.  64. 333.]]

I - Epoch: 194
I - Training: 
	I - Batch: 50 | Loss: 0.055 | Acc: 98.750% | Wgt Acc: 98.627%
	I - Batch: 100 | Loss: 0.051 | Acc: 98.938% | Wgt Acc: 98.971%
	I - Batch: 150 | Loss: 0.048 | Acc: 99.042% | Wgt Acc: 99.044%
	I - Batch: 200 | Loss: 0.047 | Acc: 99.031% | Wgt Acc: 99.058%
	I - Batch: 250 | Loss: 0.046 | Acc: 99.075% | Wgt Acc: 99.137%
	I - Batch: 300 | Loss: 0.046 | Acc: 99.125% | Wgt Acc: 99.142%
I - num batch: 313
I - Train -- Loss: 0.046 | Acc: 99.140% | Wgt Acc: 99.146% | LR: 1.250000e-04 | Dur: 190.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 688.    0.    0.    2.    8.]
 [   0.  332.    3.    1.    1.]
 [   0.    2.  482.    1.    8.]
 [   1.    0.    0.  713.    7.]
 [   5.    0.    2.    2. 2742.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.565 | Acc: 49.875% | Wgt Acc: 42.121%
I - num batch: 70
I - Val -- Loss: 2.476 | Acc: 52.334% | Wgt Acc: 44.076% | Dur: 32.84s
I - Confusion Matrix: [row->prediction - col->label]
[[106.   1.   5.  40.  37.]
 [  0.  16.  13.   3.   9.]
 [  1.  42.  47.   8.  30.]
 [ 50.  18.  21.  96.  37.]
 [ 42.  57.  60.  57. 318.]]

I - Epoch: 195
I - Training: 
	I - Batch: 50 | Loss: 0.060 | Acc: 98.750% | Wgt Acc: 98.969%
	I - Batch: 100 | Loss: 0.045 | Acc: 99.250% | Wgt Acc: 99.419%
	I - Batch: 150 | Loss: 0.052 | Acc: 99.000% | Wgt Acc: 99.051%
	I - Batch: 200 | Loss: 0.050 | Acc: 99.000% | Wgt Acc: 99.051%
	I - Batch: 250 | Loss: 0.051 | Acc: 99.050% | Wgt Acc: 99.021%
	I - Batch: 300 | Loss: 0.048 | Acc: 99.083% | Wgt Acc: 99.059%
I - num batch: 313
I - Train -- Loss: 0.047 | Acc: 99.100% | Wgt Acc: 99.068% | LR: 1.250000e-04 | Dur: 190.50s
I - Confusion Matrix: [row->prediction - col->label]
[[ 687.    0.    0.    3.    9.]
 [   0.  331.    1.    2.    0.]
 [   0.    1.  483.    0.    7.]
 [   2.    2.    0.  711.    7.]
 [   5.    0.    3.    3. 2743.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.523 | Acc: 50.875% | Wgt Acc: 43.692%
I - num batch: 70
I - Val -- Loss: 2.459 | Acc: 53.770% | Wgt Acc: 46.018% | Dur: 32.81s
I - Confusion Matrix: [row->prediction - col->label]
[[109.   1.   2.  38.  32.]
 [  1.  21.  16.   3.  17.]
 [  1.  42.  49.  11.  25.]
 [ 45.  16.  22. 102.  39.]
 [ 43.  54.  57.  50. 318.]]

I - Epoch: 196
I - Training: 
	I - Batch: 50 | Loss: 0.033 | Acc: 99.375% | Wgt Acc: 99.235%
	I - Batch: 100 | Loss: 0.030 | Acc: 99.500% | Wgt Acc: 99.307%
	I - Batch: 150 | Loss: 0.038 | Acc: 99.250% | Wgt Acc: 99.031%
	I - Batch: 200 | Loss: 0.041 | Acc: 99.094% | Wgt Acc: 99.001%
	I - Batch: 250 | Loss: 0.044 | Acc: 99.100% | Wgt Acc: 98.975%
	I - Batch: 300 | Loss: 0.042 | Acc: 99.167% | Wgt Acc: 99.078%
I - num batch: 313
I - Train -- Loss: 0.042 | Acc: 99.200% | Wgt Acc: 99.115% | LR: 1.250000e-04 | Dur: 190.34s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    3.    2.]
 [   0.  329.    4.    0.    2.]
 [   0.    3.  480.    0.   10.]
 [   2.    2.    0.  713.    5.]
 [   1.    0.    3.    3. 2747.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.719 | Acc: 49.875% | Wgt Acc: 40.675%
I - num batch: 70
I - Val -- Loss: 2.625 | Acc: 52.513% | Wgt Acc: 42.388% | Dur: 32.76s
I - Confusion Matrix: [row->prediction - col->label]
[[ 99.   1.   1.  38.  21.]
 [  0.  16.  13.   7.  10.]
 [  1.  46.  48.  12.  28.]
 [ 38.   7.  13.  76.  26.]
 [ 61.  64.  71.  71. 346.]]

I - Epoch: 197
I - Training: 
	I - Batch: 50 | Loss: 0.023 | Acc: 99.750% | Wgt Acc: 99.860%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.688% | Wgt Acc: 99.657%
	I - Batch: 150 | Loss: 0.032 | Acc: 99.667% | Wgt Acc: 99.666%
	I - Batch: 200 | Loss: 0.029 | Acc: 99.750% | Wgt Acc: 99.750%
	I - Batch: 250 | Loss: 0.028 | Acc: 99.775% | Wgt Acc: 99.755%
	I - Batch: 300 | Loss: 0.027 | Acc: 99.771% | Wgt Acc: 99.772%
I - num batch: 313
I - Train -- Loss: 0.027 | Acc: 99.760% | Wgt Acc: 99.745% | LR: 1.250000e-04 | Dur: 191.26s
I - Confusion Matrix: [row->prediction - col->label]
[[ 693.    0.    0.    1.    3.]
 [   0.  332.    0.    0.    0.]
 [   0.    2.  487.    0.    2.]
 [   1.    0.    0.  716.    1.]
 [   0.    0.    0.    2. 2760.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.703 | Acc: 50.375% | Wgt Acc: 41.667%
I - num batch: 70
I - Val -- Loss: 2.637 | Acc: 53.321% | Wgt Acc: 43.531% | Dur: 32.94s
I - Confusion Matrix: [row->prediction - col->label]
[[ 96.   1.   1.  38.  15.]
 [  0.  20.  16.   4.  15.]
 [  1.  39.  46.   8.  24.]
 [ 40.  15.  18.  87.  32.]
 [ 62.  59.  65.  67. 345.]]

I - Epoch: 198
I - Training: 
	I - Batch: 50 | Loss: 0.022 | Acc: 99.875% | Wgt Acc: 99.820%
	I - Batch: 100 | Loss: 0.031 | Acc: 99.562% | Wgt Acc: 99.565%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.500% | Wgt Acc: 99.513%
	I - Batch: 200 | Loss: 0.033 | Acc: 99.562% | Wgt Acc: 99.598%
	I - Batch: 250 | Loss: 0.036 | Acc: 99.500% | Wgt Acc: 99.496%
	I - Batch: 300 | Loss: 0.038 | Acc: 99.458% | Wgt Acc: 99.450%
I - num batch: 313
I - Train -- Loss: 0.038 | Acc: 99.440% | Wgt Acc: 99.432% | LR: 1.250000e-04 | Dur: 190.33s
I - Confusion Matrix: [row->prediction - col->label]
[[ 691.    0.    0.    2.    2.]
 [   0.  333.    2.    1.    0.]
 [   0.    0.  483.    0.   10.]
 [   1.    1.    0.  714.    3.]
 [   2.    0.    2.    2. 2751.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.575 | Acc: 49.250% | Wgt Acc: 41.485%
I - num batch: 70
I - Val -- Loss: 2.498 | Acc: 51.616% | Wgt Acc: 43.277% | Dur: 32.76s
I - Confusion Matrix: [row->prediction - col->label]
[[103.   2.   4.  43.  25.]
 [  0.  19.  17.   5.  15.]
 [  1.  42.  52.  16.  37.]
 [ 35.  15.  18.  82.  35.]
 [ 60.  56.  55.  58. 319.]]

I - Epoch: 199
I - Training: 
	I - Batch: 50 | Loss: 0.049 | Acc: 99.125% | Wgt Acc: 99.170%
	I - Batch: 100 | Loss: 0.038 | Acc: 99.312% | Wgt Acc: 99.395%
	I - Batch: 150 | Loss: 0.035 | Acc: 99.375% | Wgt Acc: 99.502%
	I - Batch: 200 | Loss: 0.036 | Acc: 99.344% | Wgt Acc: 99.410%
	I - Batch: 250 | Loss: 0.035 | Acc: 99.400% | Wgt Acc: 99.464%
	I - Batch: 300 | Loss: 0.036 | Acc: 99.333% | Wgt Acc: 99.405%
I - num batch: 313
I - Train -- Loss: 0.036 | Acc: 99.360% | Wgt Acc: 99.429% | LR: 1.250000e-04 | Dur: 190.40s
I - Confusion Matrix: [row->prediction - col->label]
[[ 689.    0.    0.    1.    7.]
 [   0.  334.    0.    1.    0.]
 [   0.    0.  487.    0.    6.]
 [   3.    0.    0.  712.    7.]
 [   2.    0.    0.    5. 2746.]]

I - Validation: 
	I - Batch: 50 | Loss: 2.592 | Acc: 50.000% | Wgt Acc: 43.713%
I - num batch: 70
I - Val -- Loss: 2.518 | Acc: 52.693% | Wgt Acc: 45.621% | Dur: 32.84s
I - Confusion Matrix: [row->prediction - col->label]
[[134.   4.   3.  67.  54.]
 [  0.  19.  13.   8.  13.]
 [  3.  44.  55.   7.  22.]
 [ 24.   7.  19.  74.  37.]
 [ 38.  60.  56.  48. 305.]]

I - Maximum validation set accuracy in current training:  56.37
